{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## The raw data is a list of tuples:\n",
        "* each tuple represents an article's id, conference, year, title, authors"
      ],
      "metadata": {
        "id": "PGD79jdihgOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "#LINK TO DATASET - https://github.com/dev7saxena/LIS875/blob/main/Data/875_week2_acm_articles.csv\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "CqNHo-n4GyDU",
        "outputId": "7508b512-e89e-4695-aedc-0c53263c0e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-088856df-940a-40f0-b268-8c6e9358d16f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-088856df-940a-40f0-b268-8c6e9358d16f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 875_week2_acm_articles.csv to 875_week2_acm_articles.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('875_week2_acm_articles.csv', header=0, keep_default_na=False).values.tolist()"
      ],
      "metadata": {
        "id": "aM-ECt2eG9b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [ (x[0], x[1], x[2], x[3], x[4]) for x in data ]"
      ],
      "metadata": {
        "id": "uM4z3aEINGjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The raw data is stored as a list of tuples.\n",
        "\n",
        "type(data)"
      ],
      "metadata": {
        "id": "h2CTzelbWC0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c4503a4-3fa1-4d4e-e4e4-abcd6ad4baeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it includes 277,933 articles' metadata in total\n",
        "\n",
        "len(data)"
      ],
      "metadata": {
        "id": "jfxG5KeBWxJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e20e5d43-61dd-420c-f96b-2130e96d8a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "277933"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPHAdKcLMNkw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd84c925-f1f8-41d2-8a10-def664a42d53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1526756,\n",
              " \"WWW '09\",\n",
              " 2009,\n",
              " 'Visual diversification of image search results',\n",
              " 'Reinier H. van Leuken;Lluis Garcia;Ximena Olivares;Roelof van Zwol')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# the first article's information: id, conference, year, title, authors (seperated using ;)\n",
        "\n",
        "data[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a dict:\n",
        "* key: each article's id\n",
        "* value: an article (stored also as a dict)"
      ],
      "metadata": {
        "id": "uT78vr8Ihy8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# it's more informative if we represent an article's information as a dict (instead of a list), e.g.:\n",
        "\n",
        "{ 'id': data[0][0], 'conf': data[0][1], 'year': data[0][2], 'title': data[0][3], 'authors': data[0][4] }"
      ],
      "metadata": {
        "id": "3pu1KmLXVYlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's do it better by splitting the author names into a list\n",
        "\n",
        "{ 'id': data[0][0], 'conf': data[0][1], 'year': data[0][2], 'title': data[0][3], 'authors': data[0][4].split(';') }"
      ],
      "metadata": {
        "id": "oo7MUfKbXDCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# okay, now let's transform the whole data list into a list of dicts\n",
        "\n",
        "[ { 'id': x[0], 'conf': x[1], 'year': x[2], 'title': x[3], 'authors': x[4].split(';') } for x in data ]"
      ],
      "metadata": {
        "id": "_2brBo5VXC_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now let's make it better by organizing the articles from a data list into a dict, where the key is each article's id, and the value is a dict representing the article\n",
        "\n",
        "articles = { x[0]: { 'id': x[0], 'conf': x[1], 'year': x[2], 'title': x[3], 'authors': x[4].split(';') } for x in data }\n",
        "articles"
      ],
      "metadata": {
        "id": "GY7deegdXC52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we can access each article from the dict by the article's id (instead of using list index)\n",
        "\n",
        "articles[1531840]"
      ],
      "metadata": {
        "id": "hLOGtk_FXC3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we can access an article's information using informative key names (instead of using list index)\n",
        "\n",
        "articles[1531840]['title']"
      ],
      "metadata": {
        "id": "jDpAKviGXC0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we can access an article's information using informative key names (instead of using list index)\n",
        "\n",
        "articles[1531840]['authors']"
      ],
      "metadata": {
        "id": "egpHSmhAXCxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a dict:\n",
        "* key: a conference\n",
        "* value: a list of articles published in that conference"
      ],
      "metadata": {
        "id": "hV7ITChdfm0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get all the conferences\n",
        "\n",
        "[x['conf'] for x in articles.values()]"
      ],
      "metadata": {
        "id": "HKXnyQN-fg_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's remove duplicate ones by resolving them into a set\n",
        "\n",
        "set([x['conf'] for x in articles.values()])"
      ],
      "metadata": {
        "id": "RtgCaLZ4f9lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5977 unique conferences in total\n",
        "\n",
        "len(set([x['conf'] for x in articles.values()]))"
      ],
      "metadata": {
        "id": "0NFp3Cp9gC_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now let's write a quick list comprehension ... \n",
        "\n",
        "{ conf:[ x for x in articles.values() if x['conf']==conf ] for conf in set([x['conf'] for x in articles.values()]) }\n",
        "\n",
        "# wait ... why it takes so long to finish ????? omg!!!!\n",
        "# let's stop running the loop and think about what's wrong"
      ],
      "metadata": {
        "id": "x4ImG1_LgLst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now let's look into the loops to figure out the reason ...\n",
        "# the above list comprehension is equivalent to the following ...\n",
        "\n",
        "tmp = {}\n",
        "\n",
        "for conf in set([x['conf'] for x in articles.values()]): # 5977 items\n",
        "    tmp[conf] = []\n",
        "    for x in articles.values(): # 277933 items\n",
        "        if x['conf']==conf:\n",
        "            tmp[conf].append(x)\n",
        "\n",
        "# 5977 * 277933 = 1,661,205,541 \n",
        "# that's why it takes so long to finish ..."
      ],
      "metadata": {
        "id": "Boz4hj9Bg1Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a better solution\n",
        "\n",
        "conf_articles = { conf:[] for conf in set([x['conf'] for x in articles.values()]) }  # 5977 items\n",
        "\n",
        "for x in articles.values(): # 277933 items\n",
        "    conf_articles[x['conf']].append(x)"
      ],
      "metadata": {
        "id": "EglMdekXdpZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now let's count how many articles were published in each conference\n",
        "\n",
        "[(conf, len(conf_articles[conf]))for conf in conf_articles]"
      ],
      "metadata": {
        "id": "hLvoXomxeG4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In-class Exercise (10 min)\n",
        "\n",
        "Create a dict:\n",
        "* key: an author (let's not consider the case that two different authors have the same name)\n",
        "* value: a list of articles the author has published\n",
        "\n",
        "Then, count the number of articles each author has published.\n",
        "\n",
        "Get the top 50 most productive authors (by the number of articles they have published)."
      ],
      "metadata": {
        "id": "bkidlcqdjdXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# store the results into author_articles\n",
        "\n",
        "author_articles = {}"
      ],
      "metadata": {
        "id": "vpZWiN_RkHRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step 1: get the unique list of authors\n",
        "allauthors = set( [ au for x in articles.values() for au in x['authors'] ] )\n",
        "len(allauthors)"
      ],
      "metadata": {
        "id": "9GRvBSpyXCo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step 2: scan the data once and create the dict\n",
        "author_articles = { au:[] for au in allauthors }\n",
        "for x in articles.values():\n",
        "    for au in x['authors']:\n",
        "        author_articles[au].append(x)\n"
      ],
      "metadata": {
        "id": "HJlni3x7jTwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# counting the number of articles each author has published\n",
        "\n",
        "numarts = [ (au, len(author_articles[au])) for au in author_articles ]\n",
        "numarts.sort(key=lambda x:x[1], reverse=True)\n",
        "numarts[0:50]"
      ],
      "metadata": {
        "id": "AN6lfnvHjTtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In-class Exercise (10 min)\n",
        "\n",
        "Now let's create an even more complex dict:\n",
        "* key: a year\n",
        "* value: a dict that the key is an author and the value is the set of conferences the author has published at least one article in\n",
        "\n",
        "Then, count the 50 authors who have published in the greatest number of conferences in 2010."
      ],
      "metadata": {
        "id": "EJ7X65nmq-_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your solution here\n",
        "\n",
        "allyears = set( [ x['year'] for x in articles.values() ] )\n",
        "\n",
        "year_author_confs = { y:{} for y in allyears }\n",
        "for x in articles.values():\n",
        "    for au in x['authors']:\n",
        "        if au not in year_author_confs[x['year']]:\n",
        "            year_author_confs[x['year']][au] = set()\n",
        "        year_author_confs[x['year']][au].add(x['conf'])\n",
        "\n",
        "stats2010 = [ (au, len(year_author_confs[2010][au])) for au in year_author_confs[2010] ]\n",
        "stats2010.sort(key=lambda x:x[1], reverse=True)\n",
        "stats2010[0:50]"
      ],
      "metadata": {
        "id": "j8pzLcjvq_p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## List vs. Set\n",
        "\n",
        "If you need to constantly check if an item is in a collection of items, use set instead of list. The latter is much slower for the in operation.\n",
        "\n",
        "Let's look at an example as follows. Here we divide the articles into those published in the SIGIR conference and those in other conferences. Then, we further extract the SIGIR articles whose authors did never publish in any other conferences.\n",
        "\n",
        "TL;DR\n",
        "* item in list: O(n)\n",
        "* item in set: O(1)"
      ],
      "metadata": {
        "id": "o14CTaRY-Q7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can check if an item is within a collection of items using \"in\". This works for both list and set (and other collections).\n",
        "\n",
        "1 in [4,2,3,1,5]"
      ],
      "metadata": {
        "id": "NEDryyAECTrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1 in {4,2,3,1,5}"
      ],
      "metadata": {
        "id": "Pmb_06UGCgLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# divide the articles into two parts: those published in SIGIR, and those in other conferences\n",
        "\n",
        "articles_sigir = { id:articles[id] for id in articles if articles[id]['conf'].startswith('SIGIR') }\n",
        "articles_other = { id:articles[id] for id in articles if not articles[id]['conf'].startswith('SIGIR') }\n",
        "\n",
        "articles_sigir"
      ],
      "metadata": {
        "id": "K8xL7KWN-Qg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(articles_sigir), len(articles_other))"
      ],
      "metadata": {
        "id": "KDhzTHvn-odk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get the list of authors who published in conferences other than SIGIR.\n",
        "# Let's store it as a set first.\n",
        "\n",
        "names_exclude = set( [ au for x in articles_other.values() for au in x['authors'] ] )\n",
        "len(names_exclude)"
      ],
      "metadata": {
        "id": "RDx8K4GG-xM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The following extract the list of SIGIR articles whose authors did never publish in other conferences.\n",
        "\n",
        "[ x for x in articles_sigir.values() if np.sum( [ 1 for au in x['authors'] if au in names_exclude ] ) == 0 ]"
      ],
      "metadata": {
        "id": "EjzUoHFw-yJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's take a look at how fast it is.\n",
        "\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "[ x for x in articles_sigir.values() if np.sum( [ 1 for au in x['authors'] if au in names_exclude ] ) == 0 ]\n",
        "end = time.time()\n",
        "\n",
        "print(end - start)"
      ],
      "metadata": {
        "id": "YPqLoU3kApfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Now let's use a list to store the set of names to exclude. It takes way much longer to finish.\n",
        "names_excludelist = list(names_exclude)\n",
        "\n",
        "start = time.time()\n",
        "[ x for x in articles_sigir.values() if np.sum( [ 1 for au in x['authors'] if au in names_excludelist ] ) == 0 ]\n",
        "end = time.time()\n",
        "\n",
        "print(end - start)"
      ],
      "metadata": {
        "id": "hj2VA8dOApSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function and lambda"
      ],
      "metadata": {
        "id": "YwnWbcdPm_W8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate an author name abbreviation: first + middle name initial + last name\n",
        "\n",
        "# a function can have 0 to many inputs and 0 to many outputs\n",
        "def abbr(name):\n",
        "    xs = name.split()\n",
        "    abbr = ''.join([x[0].upper() for x in xs[0:-1]]) + ' ' + xs[-1].title() if len(xs)>=1 else name\n",
        "    return abbr.strip()"
      ],
      "metadata": {
        "id": "56V8suKsjToH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abbr('W. Bruce Croft')"
      ],
      "metadata": {
        "id": "pPD6PtUrqXRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can use lambda for simple functions that can be finished within one line without too much logic control\n",
        "\n",
        "# the following labmda defines a function that returns the apa abbreviated style of a reference\n",
        "refabbr = lambda x : x['authors'][0].split()[-1] + ' et al. (' + str(x['year']) + ')'"
      ],
      "metadata": {
        "id": "M3I6-4GkjTlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "articles[1533074]"
      ],
      "metadata": {
        "id": "s5UGm6_hjTiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refabbr(articles[1533074])"
      ],
      "metadata": {
        "id": "-ghvyBXQqQlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In-class Exercise (5 min)\n",
        "\n",
        "Write a function called get_conf_articles:\n",
        "* input: the raw data (a list of tuples, where each tuple is an article)\n",
        "* output: a dict where the key is conference and the value is a list of articles published in that conference\n"
      ],
      "metadata": {
        "id": "UZgcuul8sZ39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_conf_articles(data):\n",
        "    allconfs = set( [ x[1] for x in data ] )\n",
        "    results = { c:[] for c in allconfs }\n",
        "    for x in data:\n",
        "        results[x[1]].append(x)\n",
        "    return results\n",
        "\n",
        "get_conf_articles(data)[\"SIGIR '10\"]"
      ],
      "metadata": {
        "id": "RHEVKg-ZsYQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sorting a list"
      ],
      "metadata": {
        "id": "q307Nu2G7nya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alist = [3,-2,-4,5]\n",
        "alist.sort()\n",
        "alist"
      ],
      "metadata": {
        "id": "oZOsfI1psYNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alist.sort(reverse=True)\n",
        "alist"
      ],
      "metadata": {
        "id": "_cTqzyiusYKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you can provide a personalized function for sorting too\n",
        "import math\n",
        "\n",
        "alist.sort(key=lambda x:math.pow(x,2))  # the lambda function tells the sort function to sort by x squared\n",
        "alist"
      ],
      "metadata": {
        "id": "0gx79ENHsYHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.sort(key=lambda x:x[0]) # sort the raw data (a list of tuples) by id\n",
        "data[0:10]"
      ],
      "metadata": {
        "id": "WpePuLj3sX6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.sort(key=lambda x:x[4]) # sort the raw data (a list of tuples) by authors\n",
        "data[0:10]"
      ],
      "metadata": {
        "id": "mXfF_GAn8b6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.sort(reverse=True, key=lambda x:x[4]) # sort the raw data (a list of tuples) by authors\n",
        "data[0:10]"
      ],
      "metadata": {
        "id": "cQCB2U5M8326"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In-class Exercise (5 min)\n",
        "\n",
        "Sort the raw data by the number of total authors in an article in a reverse order (from the highest number to the lowest one). Then, get the top 10 articles with the greatest number of authors."
      ],
      "metadata": {
        "id": "IhQTGpJN9HsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your solution here\n",
        "\n",
        "data.sort(key=lambda x:len(x[4].split(';')), reverse=True)\n",
        "[ (x, len(x[4].split(';'))) for x in data[0:10] ]"
      ],
      "metadata": {
        "id": "0DuHc1xI9Azy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6xdMSEw_9jST"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}