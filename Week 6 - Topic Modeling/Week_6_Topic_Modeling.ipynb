{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0ybY83VaUk7"
      },
      "source": [
        "# LIS 875 (Week 6): -- Topic Modeling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30Nr89RWLNV4"
      },
      "source": [
        "## 1 Set Up Environment in Google Colab\n",
        "\n",
        "Run the following cells to install/upgrade the required packages and check if the installed versions meet the requirements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDtg_c89K91S"
      },
      "source": [
        "# make sure the required python packages are installed\n",
        "\n",
        "# install nltk (we'll use 3.6.7 in Fall 2022)\n",
        "!pip install nltk==3.6.7 --upgrade\n",
        "\n",
        "# install spacy (we'll use 3.2.1 in Fall 2022)\n",
        "!pip install spacy==3.2.1 --upgrade\n",
        "\n",
        "# install spacy (we'll use 4.1.2 in Fall 2022)\n",
        "!pip install gensim==4.1.2 --upgrade\n",
        "\n",
        "# download the spacy en_core_web_sm model (3.2.0 version)\n",
        "!python -m spacy download en_core_web_sm-3.2.0 --direct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "iX9N76wAaUlA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a7bc873-c93d-411d-ee63-0fff1445ead5"
      },
      "source": [
        "# Set up the work folder in Google Drive.\n",
        "# Follow the prompt to authenticate your Google credentials.\n",
        "import os \n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "workdir = '/content/drive/MyDrive/LIS875 Fall22/week05'\n",
        "\n",
        " # change the workdir according to your work folder in your Google Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFBOpSz-gdLr"
      },
      "source": [
        "## 2 Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHSh8KylaUlA"
      },
      "source": [
        "# Load a spacy NLP pipeline (without dependency parsing and named entity recognition) -- \n",
        "# we won't use them and they would slow down the speed of processing the texts.\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check working dir\n",
        "workdir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PUhwFmtdMvEf",
        "outputId": "67130eae-2e73-40fd-99d2-1628e74be78c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/LIS875 Fall22/week05'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0FXi_voaUlB"
      },
      "source": [
        "# Let's load a dataset 'CHI.tsv' located in the work folder.\n",
        "# This dataset included research articles published in the CHI conference (a top conference for human-computer interaction).\n",
        "import pandas\n",
        "\n",
        "data = pandas.read_csv(os.path.join(workdir, 'CHI.tsv'), sep='\\t', header=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "H2M3JR4FmybH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "83a56b40-bba9-4e4a-f400-5b4d18d9789c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   YEAR                                              TITLE  \\\n",
              "0  2000                  Intelligent gaze-added interfaces   \n",
              "1  2000                 Evaluation of eye gaze interaction   \n",
              "2  2000  Enriching buyers' experiences: the SmartClient...   \n",
              "3  2000  Quality is in the eye of the beholder: meeting...   \n",
              "4  2000  What makes Internet users visit cyber stores a...   \n",
              "\n",
              "                                            ABSTRACT  \n",
              "0  We discuss a novel type of interface, the inte...  \n",
              "1  Eye gaze interaction can provide a convenient ...  \n",
              "2  In electronic commerce, a satisfying buyer exp...  \n",
              "3  Growing usage and diversity of applications on...  \n",
              "4  Retaining customer loyalty is crucial in elect...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1916b548-6835-40e7-99cd-dec8e36ebd82\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>Intelligent gaze-added interfaces</td>\n",
              "      <td>We discuss a novel type of interface, the inte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "      <td>Evaluation of eye gaze interaction</td>\n",
              "      <td>Eye gaze interaction can provide a convenient ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000</td>\n",
              "      <td>Enriching buyers' experiences: the SmartClient...</td>\n",
              "      <td>In electronic commerce, a satisfying buyer exp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000</td>\n",
              "      <td>Quality is in the eye of the beholder: meeting...</td>\n",
              "      <td>Growing usage and diversity of applications on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000</td>\n",
              "      <td>What makes Internet users visit cyber stores a...</td>\n",
              "      <td>Retaining customer loyalty is crucial in elect...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1916b548-6835-40e7-99cd-dec8e36ebd82')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1916b548-6835-40e7-99cd-dec8e36ebd82 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1916b548-6835-40e7-99cd-dec8e36ebd82');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fav_Dh7zaUlB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "61036428-54f0-4660-8b4c-2bb1bb3e336a"
      },
      "source": [
        "# Let's concatenate the title and abstract together as the text information of an article.\n",
        "# We will use the title and abstract information to train LDA topic models.\n",
        "data['TEXT'] = data['TITLE'] + '. ' + data['ABSTRACT']\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      YEAR                                              TITLE  \\\n",
              "0     2000                  Intelligent gaze-added interfaces   \n",
              "1     2000                 Evaluation of eye gaze interaction   \n",
              "2     2000  Enriching buyers' experiences: the SmartClient...   \n",
              "3     2000  Quality is in the eye of the beholder: meeting...   \n",
              "4     2000  What makes Internet users visit cyber stores a...   \n",
              "...    ...                                                ...   \n",
              "4061  1999  Mutual disambiguation of recognition errors in...   \n",
              "4062  1999  Model-based and empirical evaluation of multim...   \n",
              "4063  1999  Cooperative inquiry: developing new technologi...   \n",
              "4064  1999  Projected realities: conceptual design for cul...   \n",
              "4065  1999  Customer-focused design data in a large, multi...   \n",
              "\n",
              "                                               ABSTRACT  \\\n",
              "0     We discuss a novel type of interface, the inte...   \n",
              "1     Eye gaze interaction can provide a convenient ...   \n",
              "2     In electronic commerce, a satisfying buyer exp...   \n",
              "3     Growing usage and diversity of applications on...   \n",
              "4     Retaining customer loyalty is crucial in elect...   \n",
              "...                                                 ...   \n",
              "4061  As a new generation of multimodal/media system...   \n",
              "4062  Our research addresses the problem of error co...   \n",
              "4063  In todays homes and schools, children are emer...   \n",
              "4064  As a part of a European Union sponsored projec...   \n",
              "4065  Qualitative user-centered design processes suc...   \n",
              "\n",
              "                                                   TEXT  \n",
              "0     Intelligent gaze-added interfaces. We discuss ...  \n",
              "1     Evaluation of eye gaze interaction. Eye gaze i...  \n",
              "2     Enriching buyers' experiences: the SmartClient...  \n",
              "3     Quality is in the eye of the beholder: meeting...  \n",
              "4     What makes Internet users visit cyber stores a...  \n",
              "...                                                 ...  \n",
              "4061  Mutual disambiguation of recognition errors in...  \n",
              "4062  Model-based and empirical evaluation of multim...  \n",
              "4063  Cooperative inquiry: developing new technologi...  \n",
              "4064  Projected realities: conceptual design for cul...  \n",
              "4065  Customer-focused design data in a large, multi...  \n",
              "\n",
              "[4066 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c530995-cdb2-4d67-a015-c2c46f09df0b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>TITLE</th>\n",
              "      <th>ABSTRACT</th>\n",
              "      <th>TEXT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>Intelligent gaze-added interfaces</td>\n",
              "      <td>We discuss a novel type of interface, the inte...</td>\n",
              "      <td>Intelligent gaze-added interfaces. We discuss ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "      <td>Evaluation of eye gaze interaction</td>\n",
              "      <td>Eye gaze interaction can provide a convenient ...</td>\n",
              "      <td>Evaluation of eye gaze interaction. Eye gaze i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000</td>\n",
              "      <td>Enriching buyers' experiences: the SmartClient...</td>\n",
              "      <td>In electronic commerce, a satisfying buyer exp...</td>\n",
              "      <td>Enriching buyers' experiences: the SmartClient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000</td>\n",
              "      <td>Quality is in the eye of the beholder: meeting...</td>\n",
              "      <td>Growing usage and diversity of applications on...</td>\n",
              "      <td>Quality is in the eye of the beholder: meeting...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000</td>\n",
              "      <td>What makes Internet users visit cyber stores a...</td>\n",
              "      <td>Retaining customer loyalty is crucial in elect...</td>\n",
              "      <td>What makes Internet users visit cyber stores a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4061</th>\n",
              "      <td>1999</td>\n",
              "      <td>Mutual disambiguation of recognition errors in...</td>\n",
              "      <td>As a new generation of multimodal/media system...</td>\n",
              "      <td>Mutual disambiguation of recognition errors in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4062</th>\n",
              "      <td>1999</td>\n",
              "      <td>Model-based and empirical evaluation of multim...</td>\n",
              "      <td>Our research addresses the problem of error co...</td>\n",
              "      <td>Model-based and empirical evaluation of multim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4063</th>\n",
              "      <td>1999</td>\n",
              "      <td>Cooperative inquiry: developing new technologi...</td>\n",
              "      <td>In todays homes and schools, children are emer...</td>\n",
              "      <td>Cooperative inquiry: developing new technologi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4064</th>\n",
              "      <td>1999</td>\n",
              "      <td>Projected realities: conceptual design for cul...</td>\n",
              "      <td>As a part of a European Union sponsored projec...</td>\n",
              "      <td>Projected realities: conceptual design for cul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4065</th>\n",
              "      <td>1999</td>\n",
              "      <td>Customer-focused design data in a large, multi...</td>\n",
              "      <td>Qualitative user-centered design processes suc...</td>\n",
              "      <td>Customer-focused design data in a large, multi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4066 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c530995-cdb2-4d67-a015-c2c46f09df0b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c530995-cdb2-4d67-a015-c2c46f09df0b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c530995-cdb2-4d67-a015-c2c46f09df0b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gruwlN1aUlB"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# A text preprocessing function similar to what we did before.\n",
        "# Process a raw text and returns a list of processed word tokens \n",
        "# (removes stopwords and punctuations, applies casefolding and stemming)\n",
        "def text2words(rawtext, nlp):\n",
        "  text = nlp(rawtext)\n",
        "  return [token.lemma_.lower() for token in text if not token.is_stop and not token.is_punct]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X85nYGxraUlC"
      },
      "source": [
        "# Process the whole corpus (over 4,000 articles). It may take a few minutes.\n",
        "corpus = [ text2words(text, nlp) for text in data['TEXT']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "XAdSxb77aUlC"
      },
      "source": [
        "# Let's take a look at a processed article, which includes a list of word tokens.\n",
        "corpus[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TIVYI16ggbT"
      },
      "source": [
        "## 3 Train LDA Topic Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvY4TWk1aUlC"
      },
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "\n",
        "# Let's extract a vocabulary from the corpus (all the unique words in the articles).\n",
        "voc = corpora.Dictionary(corpus)\n",
        "\n",
        "# Count bag-of-words models (will use word ids instead of texts).\n",
        "corpusbow = [ voc.doc2bow(text) for text in corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpusbow[0]"
      ],
      "metadata": {
        "id": "pi4oVwzTq9gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "m0fHqlxIaUlD"
      },
      "source": [
        "# let's take a look at the bow results.\n",
        "# each tuple include a word id and its frequency in the article\n",
        "corpusbow[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "h1-WN854aUlD"
      },
      "source": [
        "import logging\n",
        "\n",
        "# you can turn on the debug information such that you know your model is still being trained (it takes a while to train a model)\n",
        "logging.basicConfig( format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO )\n",
        "\n",
        "# Some important parameters for training your LDA models.\n",
        "# Make sure NUM_PASSES and NUM_ITERATIONS are large enough (very important).\n",
        "NUM_TOPICS = 20 # the number of topics\n",
        "NUM_PASSES = 10 # the number of passes to scan through the data; use a large number for a small corpus (such as our example)\n",
        "NUM_ITERATIONS = 100 # the number of times to iterate each document in a single pass (the default number of iteration is 50)\n",
        "\n",
        "# Training LDA\n",
        "\n",
        "lda = gensim.models.ldamodel.LdaModel(\n",
        "    corpusbow,\n",
        "    id2word = voc,\n",
        "    num_topics = NUM_TOPICS,\n",
        "    passes = NUM_PASSES,\n",
        "    iterations = NUM_ITERATIONS\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "GpjPSp8iaUlD"
      },
      "source": [
        "# You can store the trained LDA topic models to your hard drive,\n",
        "# such that you just need to load it next time you hope to use it.\n",
        "# This is how we provide you with the pre-trained LDA topic models in your HW2.\n",
        "\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "path = datapath(os.path.join(workdir, 'HCI_topics'))\n",
        "lda.save(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqTe7mUig5l0"
      },
      "source": [
        "## 4 Access LDA Topic Models\n",
        "*   Load pre-trained models from files\n",
        "*   Access word probability for a topic: P(w|topic)\n",
        "*   Access topic distribution for an article in the corpus: P(topic|$\\theta_d$)\n",
        "*   Infer topic distribution for a new article (not exist in the corpus)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOkMGQwOaUlD"
      },
      "source": [
        "# let's load a LDA topic model we have trained before.\n",
        "\n",
        "\n",
        "# note that you may need to change the file path in the following two lines to your local file path\n",
        "voc = corpora.Dictionary.load(os.path.join(workdir, 'HCI_topics.id2word')) # load the dictionary (note it is a file ends with .id2word)\n",
        "lda = gensim.models.ldamulticore.LdaMulticore.load(os.path.join(workdir, 'HCI_topics')) # load the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DEYeis2DaUlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78713df3-2d70-4791-fa18-cac86d5e5d4b"
      },
      "source": [
        "# show all the topics and the most important 20 words in each topic\n",
        "lda.show_topics(num_topics=NUM_TOPICS, num_words=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.041*\"user\" + 0.031*\"interface\" + 0.025*\"system\" + 0.023*\"design\" + 0.022*\"application\" + 0.018*\"tool\" + 0.014*\"datum\" + 0.012*\"information\" + 0.011*\"base\" + 0.009*\"context\" + 0.008*\"computer\" + 0.008*\"task\" + 0.008*\"approach\" + 0.008*\"support\" + 0.007*\"interactive\" + 0.007*\"develop\" + 0.006*\"use\" + 0.006*\"center\" + 0.006*\"build\" + 0.006*\"work\"'),\n",
              " (1,\n",
              "  '0.045*\"design\" + 0.025*\"game\" + 0.011*\"experience\" + 0.010*\"study\" + 0.009*\"user\" + 0.009*\"hci\" + 0.007*\"paper\" + 0.007*\"value\" + 0.007*\"material\" + 0.007*\"present\" + 0.006*\"player\" + 0.006*\"practice\" + 0.006*\"finding\" + 0.006*\"provide\" + 0.005*\"explore\" + 0.005*\"field\" + 0.005*\"construction\" + 0.005*\"concept\" + 0.005*\"work\" + 0.005*\"context\"'),\n",
              " (2,\n",
              "  '0.062*\"student\" + 0.046*\"use\" + 0.043*\"strategy\" + 0.031*\"strategic\" + 0.027*\"course\" + 0.026*\"efficient\" + 0.025*\"training\" + 0.023*\"teach\" + 0.022*\"learn\" + 0.020*\"cooperative\" + 0.018*\"recognize\" + 0.018*\"result\" + 0.018*\"bone\" + 0.017*\"study\" + 0.016*\"experiment\" + 0.016*\"effect\" + 0.015*\"computer\" + 0.015*\"present\" + 0.014*\"approach\" + 0.014*\"opportunity\"'),\n",
              " (3,\n",
              "  '0.041*\"recognition\" + 0.040*\"time\" + 0.037*\"speech\" + 0.030*\"system\" + 0.026*\"speaker\" + 0.024*\"multimedia\" + 0.021*\"compression\" + 0.020*\"native\" + 0.019*\"multimodal\" + 0.016*\"study\" + 0.015*\"result\" + 0.014*\"non\" + 0.014*\"video\" + 0.013*\"work\" + 0.013*\"show\" + 0.012*\"half\" + 0.012*\"pair\" + 0.012*\"pattern\" + 0.012*\"benefit\" + 0.012*\"error\"'),\n",
              " (4,\n",
              "  '0.053*\"video\" + 0.032*\"system\" + 0.024*\"communication\" + 0.016*\"image\" + 0.015*\"collaboration\" + 0.014*\"gaze\" + 0.014*\"mediate\" + 0.011*\"paper\" + 0.011*\"use\" + 0.010*\"multiparty\" + 0.009*\"convey\" + 0.009*\"awareness\" + 0.009*\"robot\" + 0.009*\"group\" + 0.008*\"remote\" + 0.008*\"share\" + 0.008*\"person\" + 0.008*\"cue\" + 0.008*\"sound\" + 0.008*\"interface\"'),\n",
              " (5,\n",
              "  '0.063*\"menu\" + 0.039*\"model\" + 0.028*\"item\" + 0.023*\"location\" + 0.020*\"design\" + 0.018*\"application\" + 0.016*\"gui\" + 0.015*\"widget\" + 0.011*\"time\" + 0.011*\"single\" + 0.010*\"know\" + 0.010*\"large\" + 0.010*\"cognitive\" + 0.010*\"datum\" + 0.009*\"support\" + 0.009*\"person\" + 0.009*\"pull\" + 0.009*\"people\" + 0.009*\"present\" + 0.009*\"traditional\"'),\n",
              " (6,\n",
              "  '0.038*\"interface\" + 0.025*\"human\" + 0.023*\"design\" + 0.020*\"behavior\" + 0.020*\"base\" + 0.020*\"virtual\" + 0.016*\"character\" + 0.015*\"interactive\" + 0.015*\"environment\" + 0.013*\"present\" + 0.013*\"paper\" + 0.012*\"computer\" + 0.011*\"support\" + 0.011*\"child\" + 0.010*\"system\" + 0.010*\"agent\" + 0.010*\"user\" + 0.009*\"interaction\" + 0.009*\"conversational\" + 0.009*\"blind\"'),\n",
              " (7,\n",
              "  '0.032*\"social\" + 0.016*\"people\" + 0.014*\"participant\" + 0.013*\"study\" + 0.010*\"message\" + 0.010*\"finding\" + 0.010*\"emotion\" + 0.010*\"suggest\" + 0.009*\"result\" + 0.009*\"privacy\" + 0.009*\"share\" + 0.009*\"affect\" + 0.009*\"activity\" + 0.009*\"pet\" + 0.008*\"experience\" + 0.008*\"emotional\" + 0.008*\"personal\" + 0.008*\"interaction\" + 0.007*\"play\" + 0.007*\"self\"'),\n",
              " (8,\n",
              "  '0.039*\"worker\" + 0.038*\"information\" + 0.034*\"interruption\" + 0.030*\"wearable\" + 0.030*\"contextual\" + 0.021*\"radio\" + 0.019*\"technique\" + 0.019*\"computing\" + 0.018*\"model\" + 0.018*\"local\" + 0.018*\"action\" + 0.014*\"access\" + 0.014*\"minimize\" + 0.013*\"current\" + 0.012*\"platform\" + 0.011*\"need\" + 0.011*\"stress\" + 0.010*\"fulfil\" + 0.010*\"wikipedia\" + 0.010*\"bubble\"'),\n",
              " (9,\n",
              "  '0.106*\"language\" + 0.097*\"error\" + 0.055*\"natural\" + 0.038*\"command\" + 0.028*\"programming\" + 0.024*\"english\" + 0.021*\"user\" + 0.020*\"like\" + 0.018*\"total\" + 0.018*\"correct\" + 0.015*\"word\" + 0.014*\"issue\" + 0.013*\"knowledge\" + 0.013*\"define\" + 0.013*\"leverage\" + 0.012*\"observe\" + 0.011*\"program\" + 0.010*\"programmer\" + 0.010*\"end\" + 0.010*\"mode\"'),\n",
              " (10,\n",
              "  '0.020*\"design\" + 0.016*\"study\" + 0.012*\"research\" + 0.010*\"paper\" + 0.010*\"work\" + 0.009*\"support\" + 0.008*\"computer\" + 0.008*\"designer\" + 0.008*\"provide\" + 0.008*\"project\" + 0.008*\"new\" + 0.008*\"method\" + 0.007*\"information\" + 0.007*\"use\" + 0.007*\"system\" + 0.007*\"describe\" + 0.007*\"datum\" + 0.007*\"factor\" + 0.006*\"practice\" + 0.006*\"interaction\"'),\n",
              " (11,\n",
              "  '0.027*\"user\" + 0.023*\"task\" + 0.019*\"performance\" + 0.018*\"system\" + 0.017*\"result\" + 0.014*\"study\" + 0.012*\"model\" + 0.012*\"usability\" + 0.010*\"display\" + 0.009*\"use\" + 0.008*\"evaluate\" + 0.008*\"time\" + 0.007*\"evaluation\" + 0.007*\"office\" + 0.007*\"effect\" + 0.007*\"paper\" + 0.007*\"find\" + 0.007*\"compare\" + 0.007*\"difference\" + 0.007*\"high\"'),\n",
              " (12,\n",
              "  '0.031*\"user\" + 0.024*\"task\" + 0.017*\"model\" + 0.017*\"interface\" + 0.014*\"web\" + 0.013*\"base\" + 0.012*\"eye\" + 0.012*\"result\" + 0.011*\"study\" + 0.010*\"page\" + 0.010*\"correction\" + 0.008*\"search\" + 0.008*\"movement\" + 0.008*\"technique\" + 0.008*\"navigation\" + 0.008*\"perform\" + 0.007*\"information\" + 0.007*\"evaluation\" + 0.007*\"use\" + 0.006*\"law\"'),\n",
              " (13,\n",
              "  '0.037*\"audio\" + 0.034*\"mobile\" + 0.024*\"user\" + 0.022*\"narrative\" + 0.020*\"system\" + 0.017*\"support\" + 0.016*\"multimodal\" + 0.015*\"feedback\" + 0.014*\"design\" + 0.014*\"different\" + 0.013*\"notification\" + 0.012*\"device\" + 0.012*\"attachment\" + 0.012*\"provide\" + 0.011*\"phone\" + 0.010*\"space\" + 0.010*\"communication\" + 0.009*\"architecture\" + 0.008*\"accent\" + 0.008*\"level\"'),\n",
              " (14,\n",
              "  '0.050*\"device\" + 0.031*\"input\" + 0.027*\"user\" + 0.020*\"pointing\" + 0.017*\"performance\" + 0.016*\"technique\" + 0.015*\"visual\" + 0.013*\"gaze\" + 0.012*\"voice\" + 0.011*\"hand\" + 0.009*\"manual\" + 0.009*\"computer\" + 0.009*\"finger\" + 0.008*\"cursor\" + 0.008*\"orientation\" + 0.008*\"target\" + 0.008*\"wrist\" + 0.007*\"task\" + 0.007*\"selection\" + 0.007*\"magic\"'),\n",
              " (15,\n",
              "  '0.056*\"site\" + 0.020*\"social\" + 0.020*\"network\" + 0.020*\"topic\" + 0.020*\"reader\" + 0.018*\"web\" + 0.018*\"reading\" + 0.017*\"online\" + 0.016*\"community\" + 0.015*\"content\" + 0.014*\"datum\" + 0.014*\"relevant\" + 0.013*\"user\" + 0.013*\"information\" + 0.011*\"support\" + 0.011*\"large\" + 0.011*\"analysis\" + 0.010*\"help\" + 0.010*\"link\" + 0.009*\"tool\"'),\n",
              " (16,\n",
              "  '0.033*\"user\" + 0.028*\"interaction\" + 0.027*\"physical\" + 0.024*\"object\" + 0.020*\"touch\" + 0.018*\"display\" + 0.018*\"control\" + 0.017*\"direct\" + 0.015*\"interface\" + 0.014*\"gesture\" + 0.013*\"paper\" + 0.013*\"present\" + 0.013*\"use\" + 0.012*\"surface\" + 0.012*\"tangible\" + 0.011*\"technique\" + 0.011*\"computer\" + 0.011*\"novel\" + 0.011*\"combination\" + 0.010*\"sensor\"'),\n",
              " (17,\n",
              "  '0.036*\"document\" + 0.026*\"note\" + 0.024*\"information\" + 0.022*\"system\" + 0.020*\"group\" + 0.016*\"presentation\" + 0.015*\"new\" + 0.013*\"use\" + 0.012*\"interface\" + 0.011*\"give\" + 0.011*\"paper\" + 0.010*\"computer\" + 0.010*\"context\" + 0.010*\"member\" + 0.010*\"base\" + 0.010*\"noise\" + 0.009*\"palette\" + 0.009*\"call\" + 0.008*\"take\" + 0.008*\"handset\"'),\n",
              " (18,\n",
              "  '0.052*\"child\" + 0.047*\"technology\" + 0.023*\"design\" + 0.016*\"home\" + 0.014*\"process\" + 0.012*\"describe\" + 0.012*\"develop\" + 0.012*\"paper\" + 0.011*\"adult\" + 0.011*\"research\" + 0.010*\"build\" + 0.010*\"family\" + 0.010*\"young\" + 0.010*\"old\" + 0.009*\"story\" + 0.009*\"life\" + 0.009*\"development\" + 0.009*\"approach\" + 0.008*\"school\" + 0.008*\"inquiry\"'),\n",
              " (19,\n",
              "  '0.042*\"process\" + 0.034*\"learner\" + 0.026*\"design\" + 0.017*\"need\" + 0.014*\"new\" + 0.014*\"site\" + 0.013*\"work\" + 0.013*\"set\" + 0.013*\"space\" + 0.013*\"symphony\" + 0.012*\"discuss\" + 0.012*\"help\" + 0.012*\"science\" + 0.012*\"identify\" + 0.012*\"analyze\" + 0.011*\"engage\" + 0.011*\"tool\" + 0.011*\"center\" + 0.010*\"study\" + 0.009*\"approach\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kf8Hrq2uaUlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3304fce-5944-4228-b973-d9cda3927b14"
      },
      "source": [
        "# check topic#1 and show the most important 100 words\n",
        "lda.show_topic( 0, topn=100 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('user', 0.041085735),\n",
              " ('interface', 0.030522605),\n",
              " ('system', 0.024684656),\n",
              " ('design', 0.022877011),\n",
              " ('application', 0.022382043),\n",
              " ('tool', 0.01840892),\n",
              " ('datum', 0.013578498),\n",
              " ('information', 0.011545972),\n",
              " ('base', 0.011243712),\n",
              " ('context', 0.009158233),\n",
              " ('computer', 0.007977735),\n",
              " ('task', 0.007876852),\n",
              " ('approach', 0.0077653895),\n",
              " ('support', 0.007756525),\n",
              " ('interactive', 0.0074110245),\n",
              " ('develop', 0.0071438057),\n",
              " ('use', 0.0064468463),\n",
              " ('center', 0.006417939),\n",
              " ('build', 0.006319943),\n",
              " ('work', 0.00625102),\n",
              " ('describe', 0.0061360737),\n",
              " ('software', 0.006053359),\n",
              " ('program', 0.0060454896),\n",
              " ('provide', 0.0060333945),\n",
              " ('object', 0.005975107),\n",
              " ('create', 0.0056849057),\n",
              " ('widget', 0.005659753),\n",
              " ('graphical', 0.005615658),\n",
              " ('organization', 0.0055324063),\n",
              " ('new', 0.005347468),\n",
              " ('interaction', 0.0052519827),\n",
              " ('building', 0.005149192),\n",
              " ('goal', 0.005091789),\n",
              " ('allow', 0.005062639),\n",
              " ('include', 0.004897512),\n",
              " ('enable', 0.0046067275),\n",
              " ('demonstrate', 0.0045157988),\n",
              " ('way', 0.004474706),\n",
              " ('history', 0.004466855),\n",
              " ('structure', 0.0044271564),\n",
              " ('whisper', 0.0043873526),\n",
              " ('technique', 0.0043693944),\n",
              " ('development', 0.0042997072),\n",
              " ('difficult', 0.0042816396),\n",
              " ('distribute', 0.0042229076),\n",
              " ('environment', 0.0041114613),\n",
              " ('retrieval', 0.0040622405),\n",
              " ('example', 0.00402195),\n",
              " ('present', 0.0037687365),\n",
              " ('concept', 0.0037362452),\n",
              " ('exist', 0.003649417),\n",
              " ('metaphor', 0.003612647),\n",
              " ('method', 0.0034845555),\n",
              " ('programming', 0.0034665405),\n",
              " ('visual', 0.0034420511),\n",
              " ('add', 0.0033865524),\n",
              " ('editor', 0.0033118804),\n",
              " ('analysis', 0.0032202667),\n",
              " ('process', 0.003152245),\n",
              " ('important', 0.0031163238),\n",
              " ('human', 0.003101531),\n",
              " ('mobile', 0.0031000676),\n",
              " ('knowledge', 0.0030706802),\n",
              " ('mastery', 0.0030458695),\n",
              " ('model', 0.0030443948),\n",
              " ('world', 0.0029555897),\n",
              " ('multi', 0.00294093),\n",
              " ('specific', 0.0027766542),\n",
              " ('toolkit', 0.0027764225),\n",
              " ('need', 0.002766809),\n",
              " ('relationship', 0.0027171995),\n",
              " ('representation', 0.0027122095),\n",
              " ('understanding', 0.002710944),\n",
              " ('paper', 0.0026592214),\n",
              " ('rich', 0.0026546905),\n",
              " ('effective', 0.0026496341),\n",
              " ('guide', 0.0026429775),\n",
              " ('collection', 0.002610196),\n",
              " ('programmer', 0.0025772098),\n",
              " ('browse', 0.0025731535),\n",
              " ('file', 0.0025677623),\n",
              " ('discuss', 0.0025568458),\n",
              " ('effort', 0.0025317874),\n",
              " ('planning', 0.0024810578),\n",
              " ('code', 0.0024533255),\n",
              " ('library', 0.002452984),\n",
              " ('direct', 0.0024358446),\n",
              " ('show', 0.002426279),\n",
              " ('access', 0.0024223381),\n",
              " ('capability', 0.0024014215),\n",
              " ('recent', 0.0023918743),\n",
              " ('product', 0.0023759888),\n",
              " ('function', 0.002374416),\n",
              " ('sense', 0.002368001),\n",
              " ('developer', 0.0023363591),\n",
              " ('demonstration', 0.0023315183),\n",
              " ('component', 0.002304943),\n",
              " ('theory', 0.0022746706),\n",
              " ('help', 0.0022143093),\n",
              " ('learn', 0.0021973357)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4wGuakGUoVN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gyfw-HXaUlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aba1ce9-0ff0-489b-ae85-c802a507ac43"
      },
      "source": [
        "# let's get the topic distribution for the first article in the corpus\n",
        "# note that the input needs to be bow counts (and the words need to use ids in the vocabulary)\n",
        "lda.get_document_topics(corpusbow[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0.31118113),\n",
              " (4, 0.03645061),\n",
              " (6, 0.013331685),\n",
              " (7, 0.3256694),\n",
              " (12, 0.3054687)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiaT6zjEaUlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0611d57-15c7-40d7-b7f7-9277f837b18b"
      },
      "source": [
        "# you can get the list of topics by their strength of association with the article by sorting the outputs\n",
        "sorted(lda.get_document_topics(corpusbow[0]), key=lambda t:t[1], reverse=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(7, 0.32565862),\n",
              " (0, 0.31124032),\n",
              " (12, 0.30542347),\n",
              " (4, 0.03644967),\n",
              " (6, 0.013329453)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}