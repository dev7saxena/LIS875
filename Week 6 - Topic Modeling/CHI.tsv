YEAR	TITLE	ABSTRACT
2000	Intelligent gaze-added interfaces	We discuss a novel type of interface, the intelligent gaze-added interface, and describe the design and evaluation of a sample gaze-added operating-system interface. Gaze-added interfaces, like current gaze-based systems, allow users to execute commands using their eyes. However, while most gaze-based systems replace the functionality of other inputs with that of gaze, gaze-added interfaces simply add gaze functionality that the user can employ if and when desired. Intelligent gaze-added interfaces utilize a probabilistic algorithm and user model to interpret gaze focus and alleviate typical problems with eye-taking data. We extended a standard WIMP operating-system interface into a new interface, IGO, that incorporates intelligent gaze-added input. In a user study, we found that users quickly adapted to the new interface and utilized gaze effectively both alone and with other inputs.
2000	Evaluation of eye gaze interaction	Eye gaze interaction can provide a convenient and natural addition to user-computer dialogues. We have previously reported on our interaction techniques using eye gaze [10]. While our techniques seemed useful in demonstration, we now investigate their strengths and weaknesses in a controlled setting. In this paper, we present two experiments that compare an interaction technique we developed for object selection based on a where a person is looking with the most commonly used selection method using a mouse. We find that our eye gaze interaction technique is faster than selection with a mouse. The results show that our algorithm, which makes use of knowledge about how the eyes behave, preserves the natural quickness of the eye. Eye gaze interaction is a reasonable addition to computer interaction and is convenient in situations where it is important to use the hands for other tasks. It is particularly beneficial for the larger screen workspaces and virtual environments of the future, and it will become increasingly practical as eye tracker technology matures.
2000	Enriching buyers' experiences: the SmartClient approach	In electronic commerce, a satisfying buyer experience is a key competitive element. We show new techniques for better adapting interaction with an electronic catalog system to actual buying behavior. Our model replaces the sequential separation of needs identification and product brokering with a conversation in which both processes occur simultaneously. This conversation supports the buyer in formulating his or her needs, and in deciding which criteria to apply in selecting a product to buy. We have experimented with this approach in the area of travel planning and developed a system called SmartClient Travel which supports this process. It includes tools for need identification, visualization of alternatives, and choosing the most suitable one. We describe the system and its implementation, and report on user studies showing its advantages for electronic catalogs.
2000	Quality is in the eye of the beholder: meeting users' requirements for Internet quality of service	Growing usage and diversity of applications on the Internet makes Quality of Service (QoS) increasingly critical [15]. To date, the majority of research on QoS is systems oriented, focusing on traffic analysis, scheduling, and routing. Relatively minor attention has been paid to user-level QoS issues. It is not yet known how objective system quality relates to users' subjective perceptions of quality. This paper presents the results of quantitative experiments that establish a mapping between objective and perceived QoS in the context of Internet commerce. We also conducted focus groups to determine how contextual factors influence users' perceptions of QoS. We show that, while users' perceptions of World Wide Web QoS are influenced by a number of contextual factors, it is possible to correlate objective measures of QoS with subjective judgements made by users, and therefore influence system design. We argue that only by integrating users' requirements for QoS into system design can the utility of the future Internet be maximized.
2000	What makes Internet users visit cyber stores again? key design factors for customer loyalty	Retaining customer loyalty is crucial in electronic commerce because the value of an Internet store is largely determined by the number of its loyal customers. This paper proposes a multi-phased model of customer loyalty for Internet shopping, which fully takes the characteristics of the Internet and cyber shopping into consideration. In order to validate the model, we conducted a web-based survey of the customers of various Internet stores, and the data was processed using structural equation analysis. The results indicate that several factors can effectively increase customer loyalty towards an Internet store and that the relative importance of the identified factors varies according to the level of involvement with the product purchased through the store. We suggest several managerial implications in developing Internet stores for higher customer loyalty based on these results.
2000	Speak out and annoy someone: experience with intelligent kiosks	An intelligent kiosk is a public information kiosk that senses the presence of humans and communicates in a natural way. To examine issues of human-kiosk interaction, we have built and deployed two versions of intelligent kiosks. The first kiosk design combines machine vision to locate and track people in the vicinity with an animated talking head that focuses on clients and talks to them. The second kiosk design uses infrared and sonar sensors to sense clients and multiple interacting agents to communicate with the client. The foremost lessons learned from public trials include (1) people are attracted to an animated face that watches them, (2) small mobile agents interact better with kiosk content than a single fixed face, (3) speaker-independent speech recognition is only useful in targeted applications, and (4) the quality of the content on the kiosk strongly influences the client's evaluation of the quality of the technology.
2000	The effect of task conditions on the comprehensibility of synthetic speech	A study was conducted with 78 subjects to evaluate the comprehensibility of synthetic speech for various tasks ranging from short, simple e-mail messages to longer news articles on mostly obscure topics. Comprehension accuracy for each subject was measured for synthetic speech and for recorded human speech. Half the subjects were allowed to take notes while listening, the other half were not. Findings show that there was no significant difference in comprehension of synthetic speech among the five different text-to-speech engines used. Those subjects that did not take notes performed significantly worse for all synthetic voice tasks when compared to recorded speech tasks. Performance for synthetic speech in the non note-taking condition degraded as the task got longer and more complex. When taking notes, subjects also did significantly worse within the synthetic voice condition averaged across all six tasks. However, average performance scores for the last three tasks in this condition show comparable results for human and synthetic speech, reflective of a training effect.
2000	Does computer-generated speech manifest personality? an experimental test of similarity-attraction	This study examines whether people would interpret and respond to paralinguistic personality cues in computer-generated speech in the same way as they do human speech. Participants used a book-buying website and heard five book reviews in a 2 (synthesized voice personality: extrovert vs. introvert) by 2 (participant personality: extrovert vs. introvert) balanced, between-subjects experiment. Participants accurately recognized personality cues in TTS and showed strong similarity-attraction effects. Although the content was the same for all participants, when the personality of the computer voice matched their own personality: 1) participants regarded the computer voice as more attractive, credible, and informative; 2) the book review was evaluated more positively; 3) the reviewer was more attractive and credible; and 4) participants were more likely to buy the book. Match of user voice characteristics with TTS had no effect, confirming the social nature of the interaction. We discuss implications for HCI theory and design.
2000	A toolkit for strategic usability: results from workshops, panels, and surveys	This paper describes the organizational approaches and usability methodologies considered by HCI professionals to increase the strategic impact of usability research within companies. We collected the data from 134 HCI professionals at three conferences: CHI 98, CHI 99, and the Usability Professionals' Association 1999 conference. The results are the first steps towards a toolkit for the usability community that can help HCI practitioners learn from the experiences of others in similar situations.
2000	Measuring usability: are effectiveness, efficiency, and satisfaction really correlated?	Usability comprises the aspects effectiveness, efficiency, and satisfaction. The correlations between these aspects are not well understood for complex tasks. We present data from an experiment where 87 subjects solved 20 information retrieval tasks concerning programming problems. The correlation between efficiency, as indicated by task completion time, and effectiveness, as indicated by quality of solution, was negligible. Generally, the correlations among the usability aspects depend in a complex way on the application domain, the user's experience, and the use context. Going through three years of CHI Proceedings, we find that 11 out of 19 experimental studies involving complex tasks account for only one or two aspects of usability. When these studies make claims concerning overall usability, they rely on risky assumptions about correlations between usability aspects. Unless domain specific studies suggest otherwise, effectiveness, efficiency, and satisfaction should be considered independent aspect of usability and all be included in usability testing.
2000	The streamlined cognitive walkthrough method, working around social constraints encountered in a software development company	The cognitive walkthrough method described by Wharton et al. may be difficult to apply in a large software development company because of social constraints that exist in such companies. Managers, developers, and other team members are pressured for time, tend to lapse into lengthy design discussions, and are sometimes defensive about their user-interface designs. By enforcing four ground rules, explicitly defusing defensiveness, and streamlining the cognitive walkthrough method and data collection procedures, these social constraints can be overcome, and useful, valid data can be obtained. This paper describes a modified cognitive walkthrough process that accomplishes these goals, and has been applied in a large software development company.
2000	Visual similarity of pen gestures	Pen-based user interfaces are becoming ever more popular. Gestures (i.e., marks made with a pen to invoke a command) are a valuable aspect of pen-based UIs, but they also have drawbacks. The challenge in designing good gestures is to make them easy for people to learn and remember. With the goal of better gesture design, we performed a pair of experiments to determine why users find gestures similar. From these experiments, we have derived a computational model for predicting perceived gesture similarity that correlates 0.56 with observation. We will incorporate the results of these experiments into a gesture design tool, which will aid the pen-based UI designer in creating gesture sets that are easier to learn and more memorable.
2000	Providing integrated toolkit-level support for ambiguity in recognition-based interfaces	Interfaces based on recognition technologies are used extensively in both the commercial and research worlds. But recognizers are still error-prone, and this results in human performance problems, brittle dialogues, and other barriers to acceptance and utility of recognition systems. Interface techniques specialized to recognition systems can help reduce the burden of recognition errors, but building these interfaces depends on knowledge about the ambiguity inherent in recognition. We have extended a user interface toolkit in order to model and to provide structured support for ambiguity at the input event level. This makes it possible to build re-usable interface components for resolving ambiguity and dealing with recognition errors. These interfaces can help to reduce the negative effects of recognition errors. By providing these components at a toolkit level, we make it easier for application writers to provide good support for error handling. Further, with this robust support, we are able to explore new types of interfaces for resolving a more varied range of ambiguity.
2000	Programming and enjoying music with your eyes closed	Design and user evaluation of a multimodal interaction style for music programming is described. User requirements were instant usability and optional use of a visual display . The interaction style consists of a visual roller metaphor. User control of the rollers proceeds by manipulating a force feedback trackball. Tactual and auditory cues strengthen the roller impression and support use without a visual display. The evaluation investigated task performance and procedural learning when performing music programming tasks with and without a visual display. No procedural instructions were provided. Tasks could be completed successfully with and without a visual display, though programming without a display needed more time to complete. Prior experience with a visual display did not improve performance without a visual display. When working without a display, procedures have to be acquired and remembered explicitly, as more procedures were remembered after working without a visual display. It is demonstrated that multimodality provides new ways to interact with music.
2000	Presenting to local and remote audiences: design and use of the TELEP system	The current generation of desktop computers and networks are bringing streaming audio and video into widespread use. A small investment allows presentations or lectures to be multicast, enabling passive viewing from offices or rooms. We surveyed experienced viewers of multicast presentations and designed a lightweight system that creates greater awareness in the presentation room of remote viewers and allows remote viewers to interact with each other and the speaker. We report on the design, use, and modification of the system, and discuss design tradeoffs.
2000	Coming to the wrong decision quickly: why awareness tools must be matched with appropriate tasks	This paper presents an awareness tool designed to help distributed, asynchronous groups solve problems quickly. Using a lab study, it was found that groups that used the awareness tool tended to converge and agree upon a solution more quickly. However, it was also found that individuals who did not use the awareness tool got closer to the correct solution. Implications for the design of awareness tools are discussed, with particular attention paid to the importance of matching the features of an awareness tool with a workgroup's tasks and goals.
2000	Gaze communication using semantically consistent spaces	This paper presents a design for a user interface that supports improved gaze communication in multi-point video conferencing. We set out to use traditional computer displays to mediate the gaze of remote participants in a realistic manner. Previous approaches typically assume immersive displays, and use live video to animate avatars in a shared 3D virtual world. This shared world is then rendered from the viewpoint of the appropriate avatar to yield the required views of the virtual meeting. We show why such views of a shared space do not convey gaze information realistically when using traditional computer displays. We describe a new approach that uses a different arrangement of the avatars for each participant in order to preserve the semantic significance of gaze. We present a design process for arranging these avatars. Finally, we demonstrate the effectiveness of the new interface with experimental results.
2000	Eye-hand co-ordination with force feedback	The term Eye-hand co-ordination refers to hand movements controlled with visual feedback and reinforced by hand contact with objects. A correct perspective view of a virtual environment enables normal eye-hand co-ordination skills to be applied. But is it necessary for rapid interaction with 3D objects? A study of rapid hand movements is reported using an apparatus designed so that the user can touch a virtual object in the same place where he or she sees it. A Fitts tapping task is used to assess the effect of both contact with virtual objects and real-time update of the centre of perspective based on the user's actual eye position. A Polhemus tracker is used to measure the user's head position and from this estimate their eye position. In half of the conditions, head tracked perspective is employed so that visual feedback is accurate while in the other half a fixed eye-position is assumed. A Phantom force feedback device is used to make it possible to touch the targets in selected conditions. Subjects were required to change their viewing position periodically to assess the importance of correct perspective and of touching the targets in maintaining eye-hand co-ordination, The results show that accurate perspective improves performance by an average of 9\% and contact improves it a further 12\%. A more detailed analysis shows the advantages of head tracking to be greater for whole arm movements in comparison with movements from the elbow.
2000	Putting the feel in ’look and feel‘	Haptic devices are now commercially available and thus touch has become a potentially realistic solution to a variety of interaction design challenges. We report on an investigation of the use of touch as a way of reducing visual overload in the conventional desktop. In a two-phase study, we investigated the use of the PHANToM haptic device as a means of interacting with a conventional graphical user interface. The first experiment compared the effects of four different haptic augmentations on usability in a simple targeting task. The second experiment involved a more ecologically-oriented searching and scrolling task. Results indicated that the haptic effects did not improve users performance in terms of task completion time. However, the number of errors made was significantly reduced. Subjective workload measures showed that participants perceived many aspects of workload as significantly less with haptics. The results are described and the implications for the use of haptics in user interface design are discussed.
2000	Force-feedback improves performance for steering and combined steering-targeting tasks	The introduction of a force-feedback mouse, which provides high fidelity tactile cues via force output, may represent a long-awaited technological breakthrough in pointing device designs. However, there have been few studies examining the benefits of force-feedback for the desktop computer human interface. Ten adults performed eighty steering tasks, where the participants moved the cursor through a small tunnel with varying indices of difficulty using a conventional and force-feedback mouse. For the force-feedback condition, the mouse displayed force that pulled the cursor to the center of the tunnel. The tasks required both horizontal and vertical screen movements of the cursor. Movement times were on average 52 percent faster during the force-feedback condition when compared to the conventional mouse. Furthermore, for the conventional mouse vertical movements required more time to complete than horizontal screen movements. Another ten adults completed a combined steering and targeting task, where the participants navigated through a tunnel and then clicked a small box at the end of the tunnel. Again, force-feedback improved times to complete the task. Although movement times were slower than the pure steering task, the steering index of difficulty dominated the steering-targeting relationship. These results further support that human computer interfaces benefit from the additional sensory input of tactile cues to the human user.
2000	Power browser: efficient Web browsing for PDAs	We have designed and implemented new Web browsing facilities to support effective navigation on Personal Digital Assistants (PDAs) with limited capabilities: low bandwidth, small display, and slow CPU. The implementation supports wireless browsing from 3Com's Palm Pilot. An HTTP proxy fetches web pages on the client's behalf and dynamically generates summary views to be transmitted to the client. These summaries represent both the link structure and contents of a set of web pages, using information about link importance. We discuss the architecture, user interface facilities, and the results of comparative performance evaluations. We measured a 45\% gain in browsing speed, and a 42\% reduction in required pen movements.
2000	A diary study of information capture in working life	Despite the increasing number of new devices entering the market allowing the capture or recording of information (whether it be marks on paper, scene, sound or moving images), there has been little study of when and why people want to do these kinds of activities. In an effort to systematically explore design requirements for new kinds of information capture devices, we devised a diary study of 22 individuals in a range of different jobs. The data were used to construct a taxonomy as a framework for design and analysis. Design implications are drawn from the framework and applied to the design of digital cameras and hand held scanners.
2000	Instrumental interaction: an interaction model for designing post-WIMP user interfaces	This article introduces a new interaction model called Instrumental Interaction that extends and generalizes the principles of direct manipulation. It covers existing interaction styles, including traditional WIMP interfaces, as well as new interaction styles such as two-handed input and augmented reality. It defines a design space for new interaction techniques and a set of properties for comparing them. Instrumental Interaction describes graphical user interfaces in terms of domain objects and interaction instruments . Interaction between users and domain objects is mediated by interaction instruments, similar to the tools and instruments we use in the real world to interact with physical objects. The article presents the model, applies it to describe and compare a number of interaction techniques, and shows how it was used to create a new interface for searching and replacing text.
2000	Anchored conversations: chatting in the context of a document	This paper describes an application-independent tool called Anchored Conversations that brings together text-based conversations and documents. The design of Anchored Conversations is based on our observations of the use of documents and text chats in collaborative settings. We observed that chat spaces support work conversations, but they do not allow the close integration of conversations with work documents that can be seen when people are working together face-to-face. Anchored Conversations directly addresses this problem by allowing text chats to be anchored into documents. Anchored Conversations also facilitates document sharing; accepting an invitation to an anchored conversation results in the document being automatically uploaded. In addition, Anchored Conversations provides support for review, catch-up and asynchronous communications through a database. In this paper we describe motivating fieldwork, the design of Anchored Conversations, a scenario of use, and some preliminary results from a user study.
2000	The social life of small graphical chat spaces	This paper provides a unique quantitative analysis of the social dynamics of three chat rooms in the Microsoft V-Chat graphical chat system. Survey and behavioral data were used to study user experience and activity. 150 V-Chat participants completed a web-based survey, and data logs were collected from three V-Chat rooms over the course of 119 days. This data illustrates the usage patterns of graphical chat systems, and highlights the ways physical proxemics are translated into social interactions in online environments. V-Chat participants actively used gestures, avatars, and movement as part of their social interactions. Analyses of clustering patterns and movement data show that avatars were used to provide nonverbal cues similar to those found in face-to-face interactions. However, use of some graphical features, in particular gestures, declined as users became more experienced with the system. These findings have implications for the design and study of online interactive environments.
2000	The effect of communication modality on cooperation in online environments	One of the most robust findings in the sociological literature is the positive effect of communication on cooperation and trust. When individuals are able to communicate, cooperation increases significantly. How does the choice of communication modality influence this effect? We adapt the social dilemma research paradigm to quantitatively analyze different modes of communication. Using this method, we compare four forms of communication: no communication, text-chat, text-to-speech, and voice. We found statistically significant differences between different forms of communication, with the voice condition resulting in the highest levels of cooperation. Our results highlight the importance of striving towards the use of more immediate forms of communication in online environments, especially where trust and cooperation are essential. In addition, our research demonstrates the applicability of the social dilemma paradigm in testing the extent to which communication modalities promote the development of trust and cooperation.
2000	Using a large projection screen as an alternative to head-mounted displays for virtual environments	Head-mounted displays for virtual environments facilitate an immersive experience that seems more real than an experience provided by a desk-top monitor [18]; however, the cost of head-mounted displays can prohibit their use. An empirical study was conducted investigating differences in spatial knowledge learned for a virtual environment presented in three viewing conditions: head-mounted display, large projection screen, and desk-top monitor. Participants in each condition were asked to reproduce their cognitive map of a virtual environment, which had been developed during individual exploration of the environment along a predetermined course. Error scores were calculated, indicating the degree to which each participant's map differed from the actual layout of the virtual environment. No statistically significant difference was found between the head-mounted display and large projection screen conditions. An implication of this result is that a large projection screen may be an effective, inexpensive substitute for a head-mounted display.
2000	Alice: lessons learned from building a 3D system for novices	We present lessons learned from developing Alice, a 3D graphics programming environment designed for undergraduates with no 3D graphics or programming experience. Alice is a Windows 95/NT tool for describing the time-based and interactive behavior of 3D objects, not a CAD tool for creating object geometry. Our observations and conclusions come from formal and informal observations of hundreds of users. Primary results include the use of LOGO-style egocentric coordinate systems, the use of arbitrary objects as lightweight coordinate systems, the launching of implicit threads of execution, extensive function overloading for a small set of commands, the careful choice of command names, and the ubiquitous use of animation and undo.
2000	The Task Gallery: a 3D window manager	The Task Gallery is a window manager that uses interactive 3D graphics to provide direct support for task management and document comparison, lacking from many systems implementing the desktop metaphor. User tasks appear as artwork hung on the walls of a virtual art gallery, with the selected task on a stage. Multiple documents can be selected and displayed side-by-side using 3D space to provide uniform and intuitive scaling. The Task Gallery hosts any Windows application, using a novel redirection mechanism that routes input and output between the 3D environment and unmodified 2D Windows applications. User studies suggest that the Task Gallery helps with task management, is enjoyable to use, and that the 3D metaphor evokes spatial memory and cognition.
2000	A comparison of tools for building GOMS models	We compare three tools for creating GOMS models, QGOMS [2), CATHCI (17) and GLEAN3 [12], along several dimensions. We examine the representation and available constructs in each tool, the qualitative and quantitative design information provided, the support for building cognitively plausible models, and pragmatics about using each tool (e.g., how easy it is to modify a model). While each tool has its strengths, they all leave something to be desired as a practical UI design tool.
2000	DENIM: finding a tighter fit between tools and practice for Web site design	Through a study of web site design practice, we observed that web site designers design sites at different levels of refinement—site map, storyboard, and individual page—and that designers sketch at all levels during the early stages of design. However, existing web design tools do not support these tasks very well. Informed by these observations, we created DENIM, a system that helps web site designers in the early stages of design. DENIM supports sketching input, allows design at different refinement levels, and unifies the levels through zooming. We performed an informal evaluation with seven professional designers and found that they reacted positively to the concept and were interested in using such a system in their work.
2000	Tool support for cooperative object-oriented design: gesture based modelling on an electronic whiteboard	Modeling is important in object-oriented software development. Although a number of Computer Aided Software Engineering (CASE) tools are available, and even though some are technically advanced, few developers use them. This paper describes our attempt to examine the requirements needed to provide tool support for the development process, and describes and evaluates a tool, Knight, which has been developed based on these requirements. The tool is based on a direct, whiteboard-like interaction achieved using gesture input on a large electronic whiteboard. So far the evaluations have been successful and the tool shows the potential of greatly enhancing current support for object-oriented modeling.
2000	The cubic mouse: a new device for three-dimensional input	We have developed a new input device that allows users to intuitively specify three-dimensional coordinates in graphics applications. The device consists of a cube-shaped box with three perpendicular rods passing through the center and buttons on the top for additional control. The rods represent the X, Y, and Z axes of a given coordinate system. Pushing and pulling the rods specifies constrained motion along the corresponding axes. Embedded within the device is a six degree of freedom tracking sensor, which allows the rods to be continually aligned with a coordinate system located in a virtual world. We have integrated the device into two visualization prototypes for crash engineers and geologists from oil and gas companies. In these systems the Cubic Mouse controls the position and orientation of a virtual model and the rods move three orthogonal cutting or slicing planes through the model. We have evaluated the device with experts from these domains, who were enthusiastic about its ease of use.
2000	The role of contextual haptic and visual constraints on object manipulation in virtual environments	An experiment was conducted to investigate the role of surrounding haptic and visual information on object manipulation in a virtual environment. The contextual haptic constraints were implemented with a physical table and the contextual visual constraints included a checkerboard background (“virtual table”). It was found that the contextual haptic constraints (the physical table surface) dramatically increased object manipulation speed, but slightly reduced spatial accuracy, compared to free space. The contextual visual constraints (presence of the checkerboard) actually showed detrimental effects on both object manipulation speed and accuracy. Implications of these findings for human-computer interaction design are discussed.
2000	Non-isomorphic 3D rotational techniques	This paper demonstrates how non-isomorphic rotational mappings and interaction techniques can be designed and used to build effective spatial 3D user interfaces. In this paper, we develop a mathematical framework allowing us to design non-isomorphic 3D rotational mappings and techniques, investigate their usability properties, and evaluate their user performance characteristics. The results suggest that non-isomorphic rotational mappings can be an effective tool in building high-quality manipulation dialogs in 3D interfaces, allowing our subjects to accomplish experimental tasks 13\% faster without a statistically detectable loss in accuracy. The current paper will help interface designers to use non-isomorphic rotational mappings effectively.
2000	Joking, storytelling, artsharing, expressing affection: a field trial of how children and their social network communicate with digital images in leisure time	Increasing use of mobile phones in leisure and communication with digital images are important and current issues in the field of telecommunications. However, little is known about how images would be used in leisure related communication. According to our experience field trials are the best way of studying it. In this paper, we describe a field-trial case study of leisure related communication with digital images. Moreover, we discuss the advantages of conducting field trials as part of product concept design process.
2000	Designing storytelling technologies to encouraging collaboration between young children	We describe the iterative design of two collaborative storytelling technologies for young children, KidPad and the Klump. We focus on the idea of designing interfaces to subtly encourage collaboration so that children are invited to discover the added benefits of working together. This idea has been motivated by our experiences of using early versions of our technologies in schools in Sweden and the UK. We compare the approach of encouraging collaboration with other approaches to synchronizing shared interfaces. We describe how we have revised the technologies to encourage collaboration and to reflect design suggestions made by the children themselves.
2000	Storytelling with digital photographs	Photographs play a central role in many types of informal storytelling. This paper describes an easy-to-use device that enables digital photos to be used in a manner similar to print photos for sharing personal stories. A portable form factor combined with a novel interface supports local sharing like a conventional photo album as well as recording of stories that can be sent to distant friends and relatives. User tests validate the design and reveal that people alternate between “photo-driven” and “story-driven” strategies when telling stories about their photos.
2000	Unleashed: Web tablet integration into the home	To understand how web access from a portable tablet appliance changes the way people use the Internet, MediaOne gave families pen-based tablet computers with a wireless connection to our high-speed data network. We used ethnographic and usability methods to understand how tablets would be integrated into household activities and to define user requirements for such devices. Participants viewed the tablet as conceptually different from a PC. The tablet enabled a high degree of multitasking with household activities, yet flaws in form and function affected use. Results suggest that correctly designed portable Internet appliances will fill a special role in peoples' daily lives, particularly if these devices share information with each other. They will allow spontaneous access to information and communication anywhere.
2000	Predicting text entry speed on mobile phones	We present a model for predicting expert text entry rates for several input methods on a 12-key mobile phone keypad. The model includes a movement component based on Fitts' law and a linguistic component based on digraph, or letter-pair, probabilities. Predictions are provided for one-handed thumb and two-handed index finger input. For the traditional multi-press method or the lesser-used two-key method, predicted expert rates vary from about 21 to 27 words per minute (wpm). The relatively new T9 method works with a disambiguating algorithm and inputs each character with a single key press. Predicted expert rates vary from 41 wpm for one-handed thumb input to 46 wpm for two-handed index finger input. These figures are degraded somewhat depending on the user's strategy in coping with less-than-perfect disambiguation. Analyses of these strategies are presented.
2000	Developing a context-aware electronic tourist guide: some issues and experiences	In this paper, we describe our experiences of developing and evaluating GUIDE, an intelligent electronic tourist guide. The GUIDE system has been built to overcome many of the limitations of the traditional information and navigation tools available to city visitors. For example, group-based tours are inherently inflexible with fixed starting times and fixed durations and (like most guidebooks) are constrained by the need to satisfy the interests of the majority rather than the specific interests of individuals. Following a period of requirements capture, involving experts in the field of tourism, we developed and installed a system for use by visitors to Lancaster. The system combines mobile computing technologies with a wireless infrastructure to present city visitors with information tailored to both their personal and environmental contexts. In this paper we present an evaluation of GUIDE, focusing on the quality of the visitor's experience when using the system.
2000	Measuring the allocation of control in a 6 degree-of-freedom docking experiment	Coordination definitions and metrics are reviewed from the motor control, biomedical, and human factors literature. This paper presents an alternative measurement called the M -metric, the product of the simultaneity and efficiency of a trajectory, as a means of quantifying allocation of control within a docking task. A 6 degree-of-freedom (DOF) longitudinal virtual docking task experiment was conducted to address how control is allocated across six DOFs, how allocation of control changes with extended practice, and if differences in the allocation of control are input device dependent. The results show that operators, rather than controlling all 6 DOFs equally, allocate their control to the rotational and translational DOFs separately, and switch control between the two groups. With practice, allocation of control within the translational and rotational subsets increases at a faster rate than across all 6 DOFs together.
2000	Symmetric bimanual interaction	We present experimental work that explores the factors governing symmetric bimanual interaction in a two-handed task that requires the user to track a pair of targets, one target with each hand. A symmetric bimanual task is a two-handed task in which each hand is assigned an identical role. In this context, we explore three main experimental factors. We vary the distance between the pair of targets to track: as the targets become further apart, visual diversion increases, forcing the user to divide attention between the two targets. We also vary the demands of the task by using both a slow and a fast tracking speed . Finally, we explore visual integration of sub-tasks: in one condition, the two targets to track are connected by a line segment which visually links the targets, while in the other condition there is no connecting line. Our results indicate that all three experimental factors affect the degree of parallelism, which we quantify using a new metric of bimanual parallelism. However, differences in tracking error between the two hands are affected only by the visual integration factor.
2000	Two-handed input using a PDA and a mouse	We performed several experiments using a Personal Digital Assistant (PDA) as an input device in the non-dominant hand along with a mouse in the dominant hand. A PDA is a small hand-held palm-size computer like a 3Com Palm Pilot or a Windows CE device. These are becoming widely available and are easily connected to a PC. Results of our experiments indicate that people can accurately and quickly select among a small numbers of buttons on the PDA using the left hand without looking, and that, as predicted, performance does decrease as the number of buttons increases. Homing times to move both hands between the keyboard and devices are only about 10\% to 15\% slower than times to move a single hand to the mouse, suggesting that acquiring two devices does not cause a large penalty. In an application task, we found that scrolling web pages using buttons or a scroller on the PDA matched the speed of using a mouse with a conventional scroll bar, and beat the best two-handed times reported in an earlier experiment. These results will help make two-handed interactions with computers more widely available and more effective.
2000	The effects of animated characters on anxiety, task performance, and evaluations of user interfaces	Animated characters are common in user interfaces, but important questions remain about whether characters work in all situations and for all users. This experiment tested the effects of different character presentations on user anxiety, task performance, and subjective evaluations of two commerce websites. There were three character conditions (no character, a character that ignored the user, and a character that closely monitored work on the website). Users were separated into two groups that had different attitudes about accepting help from others: people with control orientations that were external (users thought that other people controlled their success) and those with internal orientations (users thought they were in control). Results showed that the effects of monitoring and individual differences in thoughts about control worked as they do in real life. Users felt more anxious when characters monitored their website work and this effect was strongest for users with an external control orientation. Monitoring characters also decreased task performance, but increased trust in website content. Results are discussed in terms of design considerations that maximize the positive influence of animated agents.
2000	Helper agent: designing an assistant for human-human interaction in a virtual meeting space	This paper introduces a new application area for agents in the computer interface: the support of human-human interaction. We discuss an interface agent prototype that is designed to support human-human communication in virtual environments. The prototype interacts with users strategically during conversation, spending most of its time listening. The prototype mimics a party host, trying to find a safe common topic for guests whose conversation has lagged. We performed an experimental evaluation of the prototype's ability to assist in cross-cultural conversations. We designed the prototype to introduce safe or unsafe topics to conversation pairs, through a series of questions and suggestions. The agent made positive contributions to participants' experience of the conversation, influenced their perception of each other and of each others' national group, and even seemed to effect their style of behavior. We discuss the implications of our research for the design of social agents to support human-human interaction.
2000	Agents to assist in finding help	When a novice needs help, often the best solution is to find a human expert who is capable of answering the novice's questions. But often, novices have difficulty characterizing their own questions and expertise and finding appropriate experts. Previous attempts to assist expertise location have provided matchmaking services, but leave the task of classifying knowledge and queries to be performed manually by the participants. We introduce Expert Finder , an agent that automatically classifies both novice and expert knowledge by autonomously analyzing documents created in the course of routine work. Expert Finder works in the domain of Java programming, where it relates a user's Java class usage to an independent domain model. User models are automatically generated that allow accurate matching of query to expert without either the novice or expert filling out skill questionnaires. Testing showed that automatically generated profiles matched well with experts' own evaluation of their skills, and we achieved a high rate of matching novice questions with appropriate experts.
2000	Lurker demographics: counting the silent	As online groups grow in number and type, understanding lurking is becoming increasingly important. Recent reports indicate that lurkers make up over 90\% of online groups, yet little is known about them. This paper presents a demographic study of lurking in email-based discussion lists (DLs) with an emphasis on health and software-support DLs. Four primary questions are examined. One, how prevalent is lurking, and do health and software-support DLs differ? Two, how do lurking levels vary as the definition is broadened from zero posts in 12 weeks to 3 or fewer posts in 12 weeks? Three, is there a relationship between lurking and the size of the DL, and four, is there a relationship between lurking and traffic level? When lurking is defined as no posts, the mean lurking level for all DLs is lower than the reported 90\%. Health-support DLs have on average significantly fewer lurkers (46\%) than software-support DLs (82\%). Lurking varies widely ranging from 0 to 99\%. The relationships between lurking, group size and traffic are also examined.
2000	Talking in circles: designing a spatially-grounded audioconferencing environment	This paper presents Talking in Circles , a multimodal audioconferencing environment whose novel design emphasizes spatial grounding with the aim of supporting naturalistic group interaction behaviors. Participants communicate primarily by speech and are represented as colored circles in a two-dimensional space. Behaviors such as subgroup conversations and social navigation are supported through circle mobility as mediated by the environment and the crowd and distance-based attenuation of the audio. The circles serve as platforms for the display of identity, presence and activity: graphics are synchronized to participants' speech to aid in speech-source identification and participants can sketch in their circle, allowing a pictorial and gestural channel to complement the audio. We note user experiences through informal studies as well as design challenges we have faced in the creation of a rich environment for computer-mediated communication.
2000	Jotmail: a voicemail interface that enables you to see what was said	Voicemail is a pervasive, but under-researched tool for workplace communication. Despite potential advantages of voicemail over email, current phone-based voicemail UIs are highly problematic for users. We present a novel, Web-based, voicemail interface, Jotmail. The design was based on data from several studies of voicemail tasks and user strategies. The GUI has two main elements: (a) personal annotations that serve as a visual analogue to underlying speech; (b) automatically derived message header information. We evaluated Jotmail in an 8-week field trial, where people used it as their only means for accessing voicemail. Jotmail was successful in supporting most key voicemail tasks, although users' electronic annotation and archiving behaviors were different from our initial predictions. Our results argue for the utility of a combination of annotation based indexing and automatically derived information, as a general technique for accessing speech archives.
2000	Instructional interventions in computer-based tutoring: differential impact on learning time and accuracy	We can reliably build “second generation” intelligent computer tutors that are approximately half as effective as human tutors. This paper evaluates two interface enhancements designed to improve the effectiveness of one successful second generation tutor, the ACT Programming Tutor. One enhancement employs animated feedback to make key data structure relationships salient. The second enhancement employs subgoal scaffolding to support students in developing simple programming plans. Both interventions were successful, but had very different impacts on student effort required to achieve mastery in the tutor environment and on subsequent posttest accuracy. These results represent a step forward in closing the gap between computer tutors and human tutors.
2000	Keystroke level analysis of email message organization	Organization of email messages takes an increasing amount of time for many email users. Research has demonstrated that users develop very different strategies to handle this organization. In this paper, the relationship between the different organization strategies and the time necessary to use a certain strategy is illustrated by a mathematical model based on keystroke-level analysis. The model estimates time usage for archiving and retrieving email messages for individual users. Besides explaining why users develop different strategies to organize email messages, the model can also be used to advise users individually when to start using folders, clean messages, learn the search functionality, and using filters to store messages. Similar models could assist evaluation of different interface designs where the number of items increase with time.
2000	Using naming time to evaluate quality predictors for model simplification	Model simplification researchers require quality heuristics to guide simplification, and quality predictors to allow comparison of different simplification algorithms. However, there has been little evaluation of these heuristics or predictors. We present an evaluation of quality predictors. Our standard of comparison is naming time, a well established measure of recognition from cognitive psychology. Thirty participants named models of familiar objects at three levels of simplification. Results confirm that naming time is sensitive to model simplification. Correlations indicate that view-dependent image quality predictors are most effective for drastic simplifications, while view-independent three-dimensional predictors are better for more moderate simplifications.
2000	Interactive textbook and interactive Venn diagram: natural and intuitive interfaces on augmented desk system	This paper describes two interface prototypes which we have developed on our augmented desk interface system, EnhancedDesk. The first application is Interactive Textbook, which is aimed at providing an effective learning environment. When a student opens a page which describes experiments or simulations, Interactive Textbook automatically retrieves digital contents from its database and projects them onto the desk. Interactive Textbook also allows the student hands-on ability to interact with the digital contents. The second application is the Interactive Venn Diagram, which is aimed at supporting effective information retrieval. Instead of keywords, the system uses real objects such as books or CDs as keys for retrieval. The system projects a circle around each book; data corresponding the book are then retrieved and projected inside the circle. By moving two or more circles so that the circles intersect each other, the user can compose a Venn diagram interactively on the desk. We also describe the new technologies introduced in EnhancedDesk which enable us to implement these applications.
2000	curlybot : designing a new class of computational toys	We introduce an educational toy, called curlybot , as the basis for a new class of toys aimed at children in their early stages of development — ages four and up. curlybot is an autonomous two-wheeled vehicle with embedded electronics that can record how it has been moved on any flat surface and then play back that motion accurately and repeatedly. Children can use curlybot to develop intuitions for advanced mathematical and computational concepts, like differential geometry, through play away from a traditional computer. In our preliminary studies, we found that children learn to use curlybot quickly. They readily establish an affective and body syntonic connection with curlybot , because of its ability to remember all of the intricacies of their original gesture; every pause, acceleration, and even the shaking in their hand is recorded. Programming by example in this context makes the educational ideas implicit in the design of curlybot accessible to young children.
2000	HandSCAPE: a vectorizing tape measure for on-site measuring applications	We introduce HandSCAPE, an orientation-aware digital tape measure, as an input device for digitizing field measurements, and visualizing the volume of the resulting vectors with computer graphics. Using embedded orientation-sensing hardware, HandSCAPE captures relevant vectors on each linear measurements and transmits this data wirelessly to a remote computer in real-time. To guide us in design, we have closely studied the intended users, their tasks, and the physical workplaces to extract the needs from real worlds. In this paper, we first describe the potential utility of HandSCAPE for three on-site application areas: archeological surveys, interior design, and storage space allocation. We then describe the overall system which includes orientation sensing, vector calculation, and primitive modeling. With exploratory usage results, we conclude our paper for interface design issues and future developments.
2000	Bringing order to the Web: automatically categorizing search results	We developed a user interface that organizes Web search results into hierarchical categories. Text classification algorithms were used to automatically classify arbitrary search results into an existing category structure on-the-fly. A user study compared our new category interface with the typical ranked list interface of search results. The study showed that the category interface is superior both in objective and subjective measures. Subjects liked the category interface much better than the list interface, and they were 50\% faster at finding information that was organized into categories. Organizing search results allows users to focus on items in categories of interest rather than having to browse through all the results sequentially.
2000	Enhancing a digital book with a reading recommender	Digital books can significantly enhance the reading experience, providing many functions not available in printed books. In this paper we study a particular augmentation of digital books that provides readers with customized recommendations. We systematically explore the application of spreading activation over text and citation data to generate useful recommendations. Our findings reveal that for the tasks performed in our corpus, spreading activation over text is more useful than citation data. Further, fusing text and citation data via spreading activation results in the most useful recommendations. The fused spreading activation techniques outperform traditional text-based retrieval methods. Finally, we introduce a preliminary user interface for the display of recommendations from these algorithms.
2000	The scent of a site: a system for analyzing and predicting information scent, usage, and usability of a Web site	Designers and researchers of users' interactions with the World Wide Web need tools that permit the rapid exploration of hypotheses about complex interactions of user goals, user behaviors, and Web site designs. We present an architecture and system for the analysis and prediction of user behavior and Web site usability. The system integrates research on human information foraging theory, a reference model of information visualization and Web data-mining techniques. The system also incorporates new methods of Web site visualization (Dome Tree, Usage Based Layouts), a new predictive modeling technique for Web site use (Web User Flow by Information Scent, WUFIS), and new Web usability metrics.
2000	Browsing digital video	Video in digital format played on programmable devices presents opportunities for significantly enhancing the user's viewing experience. For example, time compression and pause removal can shorten the viewing time for a video, textual and visual indices can allow personalized navigation through the content, and random-access digital storage allows instantaneous seeks into the content. To understand user behavior when such capabilities are available, we built a software video browsing application that combines many such features. We present results from a user study where users browsed video in six different categories: classroom lectures, conference presentations, entertainment shows, news, sports, and travel. Our results show that the most frequently used features were time compression, pause removal, and navigation using shot boundaries. Also, the behavior was different depending on the content type, and we present a classification. Finally, the users found the browser to be very useful. Two main reasons were: i) the ability to save time and ii) the feeling of control over what content they watched.
2000	Comparing presentation summaries: slides vs. reading vs. listening	As more audio and video technical presentations go online, it becomes imperative to give users effective summarization and skimming tools so that they can find the presentation they want and browse through it quickly. In a previous study, we reported three automated methods for generating audio-video summaries and a user evaluation of those methods. An open question remained about how well various text/image only techniques will compare to the audio-video summarizations. This study attempts to fill that gap. This paper reports a user study that compares four possible ways of allowing a user to skim a presentation: 1) PowerPoint slides used by the speaker during the presentation, 2) the text transcript created by professional transcribers from the presentation, 3) the transcript with important points highlighted by the speaker, and 4) a audio-video summary created by the speaker. Results show that although some text-only conditions can match the audio-video summary, users have a marginal preference for audio-video (ANOVA f=3.067, p=0.087). Furthermore, different styles of slide-authoring (e.g., detailed vs. big-points only) can have a big impact on their effectiveness as summaries, raising a dilemma for some speakers in authoring for on-demand previewing versus that for live audiences.
2000	An interactive comic book presentation for exploring video	This paper presents a method for generating compact pictorial summarizations of video. We developed a novel approach for selecting still images from a video suitable for summarizing the video and for providing entry points into it. Images are laid out in a compact, visually pleasing display reminiscent of a comic book or Japanese manga. Users can explore the video by interacting with the presented summary. Links from each keyframe start video playback and/or present additional detail. Captions can be added to presentation frames to include commentary or descriptions such as the minutes of a recorded meeting. We conducted a study to compare variants of our summarization technique. The study participants judged the manga summary to be significantly better than the other two conditions with respect to their suitability for summaries and navigation, and their visual appeal.
2000	Face to interface: facial affect in (hu)man and machine	Facial expression of emotion (or “facial affect”) is rapidly becoming an area of intense interest in the computer science and interaction design communities. Ironically, this interest comes at a time when the classic findings on perception of human facial affect are being challenged in the psychological research literature, largely on methodological grounds. This paper presents two studies on perception of facial affect. Experiment 1 provides new data on the recognition of human facial expressions, using experimental methods and analyses designed to systematically address the criticisms and help resolve this controversy. Experiment 2 is a user study on affect in a prototype robot face; the results are compared to the human data of Experiment 1. Together they provide a demonstration of how basic and more applied research can mutually contribute to this rapidly developing field.
2000	Hedonic and ergonomic quality aspects determine a software's appeal	The present study examines the role of subjectively perceived ergonomic quality (e.g. simplicity, controllability) and hedonic quality (e.g. novelty, originality) of a software system in forming a judgement of appeal. A hypothesised research model is presented. The two main research question are: (1) Are ergonomic and hedonic quality subjectively different quality aspects that can be independently perceived by the users? and (2) Is the judgement of appeal formed by combining and weighting ergonomic and hedonic quality and which weights are assigned? The results suggest that both quality aspects can be independently perceived by users. Moreover, they almost equally contributed to the appeal of the tested software prototypes. A simple averaging model implies that both quality aspects will compensate each other. Limitations and practical implication of the results are discussed.
2000	Alternatives: exploring information appliances through conceptual design proposals	As a way of mapping a design space for a project on information appliances, we produced a workbook describing about twenty conceptual design proposals. On the one hand, they serve as suggestions that digital devices might embody values apart from those traditionally associated with functionality and usefulness. On the other, they are examples of research through design, balancing concreteness with openness to spur the imagination, and using multiplicity to allow the emergence of a new design space. Here we describe them both in terms of content and process, discussing first the values they address and then how they were crafted to encourage a broad discussion with our partners that could inform future stages of design.
2000	An observational study of how objects support engineering design thinking and communication: implications for the design of tangible media	There has been an increasing interest in objects within the HCI field particularly with a view to designing tangible interfaces. However, little is known about how people make sense of objects and how objects support thinking. This paper presents a study of groups of engineers using physical objects to prototype designs, and articulates the roles that physical objects play in supporting their design thinking and communications. The study finds that design thinking is heavily dependent upon physical objects, that designers are active and opportunistic in seeking out physical props and that the interpretation and use of an object depends heavily on the activity. The paper discusses the trade-offs that designers make between speed and accuracy of models, and specificity and generality in choice of representations. Implications for design of tangible interfaces are discussed.
2000	Tagged handles: merging discrete and continuous manual control	Discrete and continuous modes of manual control are fundamentally different: buttons select or change state, while handles persistently modulate an analog parameter. User interfaces for many electronically aided tasks afford only one of these modes when both are needed. We describe an integration of two kinds of physical interfaces (tagged objects and force feedback) that enables seamless execution of such multimodal tasks while applying the benefits of physicality; and demonstrate application scenarios with conceptual and engineering prototypes. Our emphasis is on sharing insights gained in a design case study, including expert user reactions.
2000	Traversable interfaces between real and virtual worlds	Traversable interfaces establish the illusion that virtual and physical worlds are joined together and that users can physically cross from one to the other. Our design for a traversable interface combines work on tele-embodiment, mixed reality boundaries and virtual environments. It also exploits non-solid projection surfaces, of which we describe four examples. Our design accommodates the perspectives of users who traverse the interface and also observers who are present in the connected physical and virtual worlds, an important consideration for performance and entertainment applications. A demonstrator supports encounters between members of our laboratory and remote visitors.
2000	Tradeoffs in displaying peripheral information	Peripheral information is information that is not central to a person's current task, but provides the person the opportunity to learn more, to do a better job, or to keep track of less important tasks. Though peripheral information displays are ubiquitous, they have been rarely studied. For computer users, a common peripheral display is a scrolling text display that provides announcements, sports scores, stock prices, or other news. In this paper, we investigate how to design peripheral displays so that they provide the most information while having the least impact on the user's performance on the main task. We report a series of experiments on scrolling displays aimed at examining tradeoffs between distraction of scrolling motion and memorability of information displayed. Overall, we found that continuously scrolling displays are more distracting than displays that start and stop, but information in both is remembered equally well. These results are summarized in a set of design recommendations.
2000	The impact of fluid documents on reading and browsing: an observational study	Fluid Documents incorporate additional information into a page by adjusting typography using interactive animation. One application is to support hypertext browsing by providing glosses for link anchors. This paper describes an observational study of the impact of Fluid Documents on reading and browsing. The study involved six conditions that differ along several dimensions, including the degree of typographic adjustment and the distance glosses are placed from anchors. Six subjects read and answered questions about two hypertext corpora while being monitored by an eyetracker. The eyetracking data revealed no substantial differenccs in eye behavior between conditions. Gloss placement was significant: subjects required less time to use nearby glosses. Finally, the reaction to the conditions was highly varied, with several conditions receiving both a best and worst rating on the subjective questionnaires. These results suggest implications for the design of dynamic reading environments.
2000	Effects of contextual navigation aids on browsing diverse Web systems	In spite of the radical enhancement of web technologies, many users still continue to experience severe difficulties in navigating web systems. One way to reduce the navigation difficulties is to provide context information that explains the current situation of users in the web systems. In this study, we empirically examined the effects of two types of context information, namely, structural and temporal context. In the experiment, we evaluated the effectiveness of the contextual navigation aids in two different types of web systems: an electronic commerce system and a content dissemination system. In our experiment, subjects performed several browsing tasks and answered a set of post-questionnaires. The results of the experiment reveal that the two types of contextual navigation aids significantly improved the performance of browsing tasks regardless of different web systems. Moreover, context information changed the users' navigation patterns, and increased their subjective ease of navigation. This study concludes with implications for understanding the users' browsing patterns and for developing effective navigation systems.
2000	Interacting with eye movements in virtual environments	Eye movement-based interaction offers the potential of easy, natural, and fast ways of interacting in virtual environments. However, there is little empirical evidence about the advantages or disadvantages of this approach. We developed a new interaction technique for eye movement interaction in a virtual environment and compared it to more conventional 3-D pointing. We conducted an experiment to compare performance of the two interaction types and to assess their impacts on spatial memory of subjects and to explore subjects' satisfaction with the two types of interactions. We found that the eye movement-based interaction was faster than pointing, especially for distant objects. However, subjects' ability to recall spatial information was weaker in the eye condition than the pointing one. Subjects reported equal satisfaction with both types of interactions, despite the technology limitations of current eye tracking equipment.
2001	Orchestrating a mixed reality performance	A study of a professional touring mixed reality performance called Desert Rain yields insights into how performers orchestrate players' engagement in an interactive experience. Six players at a time journey through an extended physical and virtual set. Each sees a virtual world projected onto a screen made from a fine water spray. This acts as a traversable interface, supporting the illusion that performers physically pass between real and virtual worlds. Live and video-based observations of Desert Rain, coupled with interviews with players and the production team, have revealed how the performers create conditions for the willing suspension of disbelief, and how they monitor and intervene in the players experience without breaking their engagement. This involves carefully timed performances and “off-face” and “virtual” interventions. In turn, these are supported by the ability to monitor players' physical and virtual activity through asymmetric interfaces.
2001	Cookies and Web browser design: toward realizing informed consent online	We first provide criteria for assessing informed consent online. Then we examine how cookie technology and Web browser designs have responded to concerns about informed consent. Specifically, we document relevant design changes in Netscape Navigator and Internet Explorer over a 5-year period, starting in 1995. Our retrospective analyses leads us to conclude that while cookie technology has improved over time regarding informed consent, some startling problems remain. We specify six of these problems and offer design remedies. This work fits within the emerging field of Value-Sensitive Design.
2001	Empirically validated web page design metrics	A quantitative analysis of a large collection of expert-rated web sites reveals that page-level metrics can accurately predict if a site will be highly rated. The analysis also provides empirical evidence that important metrics, including page composition, page formatting, and overall page characteristics, differ among web site categories such as education, community, living, and finance. These results provide an empirical foundation for web site design guidelines and also suggest which metrics can be most important for evaluation via user studies.
2001	What makes Web sites credible?: a report on a large quantitative study	The credibility of web sites is becoming an increasingly important area to understand. To expand knowledge in this domain, we conducted an online study that investigated how different elements of Web sites affect people's perception of credibility. Over 1400 people participated in this study, both from the U.S. and Europe, evaluating 51 different Web site elements. The data showed which elements boost and which elements hurt perceptions of Web credibility. Through analysis we found these elements fell into one of seven factors. In order of impact, the five types of elements that increased credibility perceptions were “real-world feel”, “ease of use”, “expertise”, “trustworthiness”, and “tailoring”. The two types of elements that hurt credibility were “commercial implications&rdquo ;and “amateurism”. This large-scale study lays the groundwork for further research into the elements that affect Web credibility. The results also suggest implications for designing credible Web sites.
2001	Improving the performance of the cyberlink mental interface with “yes / no program”	We summarise the results of the first studies to investigate the Cyberlink brain body interface as an assistive technology. Three phases of studies and a contextual inquiry were performed with a range of users. A focus group was formed from brain-injured users with locked-in syndrome who have no other method of communication or control of a computer than the Cyberlink. Versions of a Yes/No program were then created to allow communication and have achieved some success with the focus group. The purpose of this paper is to discuss how this program has been improved and what steps need to be taken to create communication programs for persons with severe motor impairment. As a result of our experiences, we have been able to develop a set of design guidelines for brain-body interface operated Yes/No programs. These are presented and justified on the basis of our experiences. We also raise some general issues for assistive technologies of this nature.
2001	Responding to subtle, fleeting changes in the user's internal state	In human-to-human interaction, people sometimes are able to pick up and respond sensitively to the other's internal state as it shifts moment by moment over the course of an exchange. To find out whether such an ability is worthwhile for computer human interfaces, we built a semi-automated tutoring-type spoken dialog system. The system inferred information about the user's \scare{ephemeral emotions}, such as confidence, confusion, pleasure, and dependency, from the prosody of his utterances and the context. It used this information to select the most appropriate acknowledgement form at each moment. In doing so the system was following some of the basic social conventions for real-time interaction. Users rated the system with this ability more highly than a version without.
2001	An “independent visual background” reduced balance disturbance envoked by visual scene motion: implication for alleviating simulator sickness	Simulator sickness (SS) / virtual environment (VE) sickness is expected to become increasingly troublesome as VE technology evolves [20]. Procedures to alleviate SS / VE sickness have been of limited value [12]. This paper investigated a possible procedure to reduce SS and VE sickness. Postural disturbance was evoked by visual scene motion at different frequencies. Differences in disturbance were examined as a function of simultaneous exposure to an “independent visual background” (IVB). Eight subjects were tested at two scene motion frequencies and three different IVB conditions using a within-subjects design. An expected statistically significant interaction between IVB condition and frequency was observed. For low frequency scene movements, subjects exhibited less balance disturbance when the IVB was presented. We suggest that an IVB may alleviate disturbance when conflicting visual and inertial cues are likely to result in simulator or VE sickness.
2001	Layered participatory analysis: new developments in the CARD technique	CARD (Collaborative Analysis of Requirements and Design) is an influential technique for participatory design and participatory analysis that is in use on three continents. This paper reviews three case studies that document the development of a layered CARD approach, which distinguishes among the following: (1) observable, formal components, (2) skill and craft, and (3) interpretative description. The layered approach simplifies the CARD materials, and moves the deliberately informal technique toward a more principled analysis.
2001	Building a human factors “knowledge shelf” as a collaborative information tool for designers	Human factors professionals have long been challenged with finding an effective way of communicating critical human factors design information to product designers. The authors have created a tool called a “Knowledge Shelf” for providing human factors information to designers in a very easy to use manner. The Knowledge Shelf is an interactive virtual library of information on human factors methodologies and data relevant to the specific product development needs of designers. Available through the Motorola Intranet, the Knowledge Shelf is designed to make human factors design information easily accessible. Providing these types of information to designers positively impacts the product development process, by facilitating more user-centered design practices.
2001	Global-software development lifecycle: an exploratory study	This study was conducted to explore the efficacy of the global-software development lifecycle (global-SDLC), which comprises design, implementation and usability evaluation phase. A spreadsheet was adapted using the global-SDLC process to accommodate a number of cultures. The design and implementation phases were efficacious. However, in the usability evaluation phase, the usability evaluation techniques were only efficacious when participants, who were experienced computer users and participants who were familiar with the experimenter, were employed. Explanations, from cultural literature such as Hofstede, are presented and implications of these findings on the usability evaluation phase and the global-SDLC are also described.
2001	Ignoring perfect knowledge in-the-world for imperfect knowledge in-the-head	Memory can be internal or external - knowledge in-the-world or knowledge in-the-head. Making needed information available in an interface may seem the perfect alternative to relying on imperfect memory. However, the rational analysis framework (Anderson, 1990) suggests that least-effort tradeoffs may lead to imperfect performance even when perfect knowledge in-the-world is readily available. The implications of rational analysis for interactive behavior are investigated in two experiments. In experiment 1 we varied the perceptual-motor effort of accessing knowledge in-the-world as well as the cognitive effort of retrieving items from memory. In experiment 2 we replicated one of the experiment 1 conditions to collect eye movement data. The results suggest that milliseconds matter. Least-effort tradeoffs are adopted even when the absolute difference in effort between a perceptual-motor versus a memory strategy is small, and even when adopting a memory strategy results in a higher error rate and lower performance.
2001	Predicting the effects of in-car interfaces on driver behavior using a cognitive architecture	When designing and evaluating in-car user interfaces for drivers, it is essential to determine what effects these interfaces may have on driver behavior and performance. This paper describes a novel approach to predicting effects of in-car interfaces by modeling behavior in a cognitive architecture. A cognitive architecture is a theoretical frame-work for building computational models of cognition and performance. The proposed approach centers on integrating a user model for the interface with an existing driver model that accounts for basic aspects of driver behavior (e.g., steering and speed control). By running the integrated model and having it interact with the interface while driving, we can generate a priori predictions of the effects of interface use on driver performance. The paper illustrates the approach by comparing four representative dialing interfaces for an in-car, hands-free cellular phone. It also presents an empirical study that validates several of the qualitative and quantitative predictions of the model.
2001	Towards demystification of direct manipulation: cognitive modeling charts the gulf of execution	Direct manipulation involves a large number of interacting psychological mechanisms that make the performance of a given interface hard to predict on intuitive or informal grounds. This paper applies cognitive modeling to explain the subtle effects produced by using a keypad versus a touchscreen in a performance-critical laboratory task.
2001	Visualization components for persistent conversations	An appropriately designed interface to persistent, threaded conversations could reinforce socially beneficial behavior by prominently featuring how frequently and to what degree each user exhibits such behaviors. Based on the data generated by the Netscan data-mining project [9], we have developed a set of tools for illustrating the structure of discussion threads like those found in Usenet newsgroups and the patterns of participation within the discussions. We describe the benefits and challenges of integrating these tools into a multi-faceted dashboard for navigating and reading discussions in social cyberspaces like Usenet and related interaction media. Visualizations of the structure of online discussions have applications for research into the sociology of online groups as well as possible interface designs for their members.
2001	Time Aura: interfaces for pacing	Historically one of the visions for human-computer symbiosis has been to augment human intelligence and extend people's cognitive abilities. In this paper, we present two visually-based systems to enhance a person's ability to flexibly control their pace while engaged in a cognitively demanding activity. In these investigations, we explore pacing interfaces that minimize the cognitive demands for assessing a current pace, provide ambient cues that can be quickly interpreted without incurring significant interruption from the current task, and place knowledge in the world to flexibly support different pacing strategies. Evaluation of our pacing interfaces shows that technology can successfully support pacing.
2001	Doom as an interface for process management	This paper explores a novel interface to a system administration task. Instead of creating an interface de novo for the task, the author modified a popular computer game, Doom, to perform useful work. The game was chosen for its appeal to the target audience of system administrators. The implementation described is not a mature application, but it illustrates important points about user interfaces and our relationship with computers. The applications relies on a computer game vernacular rather than the simulations of physical reality found in typical navigable virtual environments. Using a computer game vocabulary may broaden an application's audience by providing sn intuitive environment for children and non-technical users. In addition, the application highlights the adversarial relationships that exist in a computer and suggests a new resource allocation scheme.
2001	Effects of spatial audio on memory, comprehension, and preference during desktop conferences	An experiment was conducted to determine the effect of spatial audio on memory, focal assurance, perceived comprehension and listener preferences during desktop conferences. Nineteen participants listened to six, pre-recorded, desktop conferences. Each conference was presented using either non-spatial audio, co-located spatial audio, or scaled spatial audio, and during half of the conferences, static visual representations of the conferees were present. In the co-located condition, each conferees voice originated from directly above their image on the screen, and in the scaled spatial audio condition, the spatial separation between conferee voices was increased beyond the visual separation. Results showed that spatial audio improved all measures, increasing memory, focal assurance, and perceived comprehension. In addition, participants preferred spatial audio to non-spatial audio. No strong differences were found in the visual conditions, or between the co-located spatial condition and the scaled spatial conditions.
2001	Quiet calls: talking silently on mobile phones	Quiet Calls is a technology allowing mobile telephone users to respond to telephone conversations without talking aloud. QC-Hold, a Quiet Calls prototype, combines three buttons for responding to calls with a PDA/mobile phone unit to silently send pre-recorded audio directly into the phone. This permits a mixed-mode communication where callers in public settings use a quiet means of communication, and other callers experience a voice telephone call. An evaluation of QC-Hold shows that it is easily used and suggests ways in which Quiet Calls offers a new form of communication, extending the choices offered by synchronous phone calling and asynchronous voicemail.
2001	The audio notebook: paper and pen interaction with structured speech	This paper addresses the problem that a listener experiences when attempting to capture information presented during a lecture, meeting, or interview. Listeners must divide their attention between the talker and their notetaking activity. We propose a new device-the Audio Notebook-for taking notes and interacting with a speech recording. The Audio Notebook is a combination of a digital audio recorder and paper notebook, all in one device. Audio recordings are structured using two techniques: user structuring based on notetaking activity, and acoustic structuring based on a talker's changes in pitch, pausing, and energy. A field study showed that the interaction techniques enabled a range of usage styles, from detailed review to high speed skimming. The study motivated the addition of phrase detection and topic suggestions to improve access to the audio recordings. Through these audio interaction techniques, the Audio Notebook defines a new approach for navigation in the audio domain.
2001	Does organisation by similarity assist image browsing?	In current systems for browsing image collections, users are presented with sets of thumbnail images arranged in some default order on the screen. We are investigating whether it benefits users to have sets of thumbnails arranged according to their mutual similarity, so images that are alike are placed together. There are, of course, many possible definitions of “similarity”: so far we have explored measurements based on low-level visual features, and on the textual captions assigned to the images. Here we describe two experiments, both involving designers as the participants, examining whether similarity-based arrangements of the candidate images are helpful for a picture selection task. Firstly, the two types of similarity-based arrangement were informally compared. Then, an arrangement based on visual similarity was more formally compared with a control of a random arrangement. We believe this work should be of interest to anyone designing a system that involves presenting sets of images to users.
2001	Using thumbnails to search the Web	We introduce a technique for creating novel, textually-enhanced thumbnails of Web pages. These thumbnails combine the advantages of image thumbnails and text summaries to provide consistent performance on a variety of tasks. We conducted a study in which participants used three different types of summaries (enhanced thumbnails, plain thumbnails, and text summaries) to search Web pages to find several different types of information. Participants took an average of 67, 86, and 95 seconds to find the answer with enhanced thumbnails, plain thumbnails, and text summaries, respectively. We found a strong effect of question category. For some questions, text outperformed plain thumbnails, while for other questions, plain thumbnails outperformed text. Enhanced thumbnails (which combine the features of text summaries and plain thumbnails) were more consistent than either text summaries or plain thumbnails, having for all categories the best performance or performance that was statistically indistinguishable from the best.
2001	On the road and on the Web?: comprehension of synthetic and human speech while driving	In this study 24 participants drove a simulator while listening to three types of messages in both synthesized speech and recorded human speech. The messages consisted of short navigation messages, medium length (approximately 100 words) email messages, and longer news stories (approximately 200 words). After each message the participant was presented with a series of multiple choice questions to measure comprehension of the message. Driving performance was recorded. Findings show that for the low driving workload conditions in the study, (cruise control, predictable two-lane road with no intersections, invariant lead car) driving performance was not affected by listening to messages. This was true for both the synthesized speech and natural speech. Comprehension of messages in synthetic speech was significantly lower than for recorded human speech for all message types.
2001	Accordion summarization for end-game browsing on PDAs and cellular phones	We demonstrate a new browsing technique for devices with small displays such as PDAs or cellular phones. We concentrate on end-game browsing, where the user is close to or on the target page. We make browsing more efficient and easier by Accordion Summarization. In this technique the Web page is first represented as a short summary. The user can then drill down to discover relevant parts of the page. If desired, keywords can be highlighted and exposed automatically. We discuss our techniques, architecture, interface facilities, and the result of user evaluations. We measured a 57\% improvement in browsing speed and 75\% reduction in input effort.
2001	ConNexus to awarenex: extending awareness to mobile users	We explored the use of awareness information to facilitate communication by developing a series of prototypes. The ConNexus prototype integrates awareness information, instant messaging, and other communication channels in an interface that runs on a desktop computer. The Awarenex prototype extends that functionality to wireless handheld devices, such as a Palm. A speech interface also enables callers to make use of the awareness information over the telephone. While the prototypes offer similar functionality, the interfaces reflect the different design affordances and use context of each platform. We discuss the design implications of providing awareness information on devices with varying interface and network characteristics.
2001	Beyond command knowledge: identifying and teaching strategic knowledge for using complex computer applications	Despite experience, many users do not make efficient use of complex computer applications. We argue that this is caused by a lack of strategic knowledge that is difficult to acquire just by knowing how to use commands. To address this problem, we present efficient and general strategies for using computer applications, and identify the components of strategic knowledge required to use them. We propose a framework for teaching strategic knowledge, and show how we implemented it in a course for freshman students. In a controlled study, we compared our approach to the traditional approach of just teaching commands. The results show that efficient and general strategies can in fact be taught to students of diverse backgrounds in a limited time without harming command knowledge. The experiment also pinpointed those strategies that can be automatically learned just from learning commands, and those that require more practice than we provided. These results are important to universities and companies that wish to foster more efficient use of complex computer applications.
2001	Teachers as simulation programmers: minimalist learning and reuse	Five public school teachers were observed during two self-study sessions where they learned to use Visual AgenTalk (VAT). The first session emphasized the basic visual programming skills, while the second introduced ways to reuse existing simulations. Two versions of the reuse tutorial were developed, one offering a concrete example world for reuse, and the second an abstract world. During their learning and reuse sessions, the teachers thought out loud as they worked, enabling a detailed analysis of their goals, reactions, problems, and successes. After each session, the teachers also completed user reaction questionnaires. Although all teachers succeeded in learning the basics of VAT, they varied considerably in their reuse of the example simulations. It appears that the simplified components of the abstract world supported reuse to a greater degree than those of the concrete example world.
2001	Locus of feedback control in computer-based tutoring: impact on learning rate, achievement and attitudes	The advent of second-generation intelligent computer tutors raises an important instructional design question: when should tutorial advice be presented in problem solving? This paper examines four feedback conditions in the ACT Programming Tutor. Three versions offer the student different levels of control over error feedback and correction: (a) immediate feedback and immediate error correction; (b) immediate error flagging and student control of error correction; (c) feedback on demand and student control of error correction. A fourth, No-tutor condition offers no stepby-step problem solving support. The immediate feedback group with greatest tutor control of problem solving yielded the most efficient learning. These students completed the tutor problems fastest, and the three tutor-supported groups performed equivalently on tests. Questionnaires revealed little student preference among the four conditions. These results suggest that students will need explicit guidance to benefit from learning opportunities that arise when they have greater control over tutorial assistance.
2001	Sensetable: a wireless object tracking platform for tangible user interfaces	In this paper we present a system that electromagnetically tracks the positions and orientations of multiple wireless objects on a tabletop display surface. The system offers two types of improvements over existing tracking approaches such as computer vision. First, the system tracks objects quickly and accurately without susceptibility to occlusion or changes in lighting conditions. Second, the tracked objects have state that can be modified by attaching physical dials and modifiers. The system can detect these changes in real-time. We present several new interaction techniques developed in the context of this system. Finally, we present two applications of the system: chemistry and system dynamics simulation.
2001	Surface drawing: creating organic 3D shapes with the hand and tangible tools	Surface Drawing is a system for creating organic 3D shapes in a manner which supports the needs and interests of artists. This medium facilitates the early stages of creative design which many 3D modeling programs neglect. Much like traditional media such as line drawing and painting, Surface Drawing lets users construct shapes through repeated marking. In our case, the hand is used to mark 3D space in a semi-immersive virtual environment. The interface is completed with tangible tools to edit and manipulate models. We introduce the use of tongs to move and scale 3D shapes and demonstrate a magnet tool which is comfortably held without restricting hand motion. We evaluated our system through collaboration with artists and designers, exhibition before hundreds of users, our own extensive exploration of the medium, and an informal user study. Response was especially positive from users with an artistic background.
2001	DataTiles: a modular platform for mixed physical and graphical interactions	The DataTiles system integrates the benefits of two major interaction paradigms: graphical and physical user interfaces. Tagged transparent tiles are used as modular construction units. These tiles are augmented by dynamic graphical information when they are placed on a sensor-enhanced flat panel display. They can be used independently or can be combined into more complex configurations, similar to the way language can express complex concepts through a sequence of simple words. In this paper, we discuss our design principles for mixing physical and graphical interface techniques, and describe the system architecture and example applications of the DataTiles system.
2001	Optimizing search by showing results in context	We developed and evaluated seven interfaces for integrating semantic category information with Web search results. List interfaces were based on the familiar ranked-listing of search results, sometimes augmented with a category name for each result. Category interfaces also showed page titles and/or category names, but re-organized the search results so that items in the same category were grouped together visually. Our user studies show that all Category interfaces were more effective than List interfaces even when lists were augmented with category names for each result. The best category performance was obtained when both category names and individual page titles were presented. Either alone is better than a list presentation, but both together provide the most effective means for allowing users to quickly examining search results. These results provide a better understanding of the perceptual and cognitive factors underlying the advantage of category groupings and provide some practical guidance to Web search interface designers.
2001	Robust annotation positioning in digital documents	Increasingly, documents exist primarily in digital form. System designers have recently focused on making it easier to read digital documents, with annotation as an important new feature. But supporting annotation well is difficult because digital documents are frequently modified, making it challenging to correctly reposition annotations in modified versions. Few systems have addressed this issue, and even fewer have approached the problem from the users' point of view. This paper reports the results of two studies examining user expectations for robust annotation positioning in modified documents. We explore how users react to lost annotations, the relationship between types of document modifications and user expectations, and whether users pay attention to text surrounding their annotations. Our results could contribute substantially to effective digital document annotation systems.
2001	Reading of electronic documents: the usability of linear, fisheye, and overview+detail interfaces	Reading of electronic documents is becoming increasingly important as more information is disseminated electronically. We present an experiment that compares the usability of a linear, a fisheye, and an overview+detail interface for electronic documents. Using these interfaces, 20 subjects wrote essays and answered questions about scientific documents. Essays written using the overview+detail interface received higher grades, while subjects using the fisheye interface read documents faster. However, subjects used more time to answer questions with the overview+detail interface. All but one subject preferred the overview+detail interface. The most common interface in practical use, the linear interface, is found to be inferior to the fisheye and overview+detail interfaces regarding most aspects of usability. We recommend using overview+detail interfaces for electronic documents, while fisheye interfaces mainly should be considered for time-critical tasks.
2001	Eye gaze patterns in conversations: there is more to conversational agents than meets the eyes	In multi-agent, multi-user environments, users as well as agents should have a means of establishing who is talking to whom. In this paper, we present an experiment aimed at evaluating whether gaze directional cues of users could be used for this purpose. Using an eye tracker, we measured subject gaze at the faces of conversational partners during four-person conversations. Results indicate that when someone is listening or speaking to individuals, there is indeed a high probability that the person looked at is the person listened (p=88\%) or spoken to (p=77\%). We conclude that gaze is an excellent predictor of conversational attention in multiparty conversations. As such, it may form a reliable source of input for conversational systems that need to establish whom the user is speaking or listening to. We implemented our findings in FRED, a multi-agent conversational system that uses eye input to gauge which agent the user is listening or speaking to.
2001	The impact of eye gaze on communication using humanoid avatars	In this paper we describe an experiment designed to investigate the importance of eye gaze in humanoid avatar's representing people engaged in conversation. We compare responses to dyadic conversations in four mediated conditions: video, audio-only, and two avatar conditions. The avatar conditions differed only in their treatment of eye gaze. In the random-gaze condition the avatars head and eye animations were unrelated to conversational flow. In the informed-gaze condition, they were related to turn-taking during the conversation. The head animations were tracked and the eye animations were inferred from the audio stream. Our comparative analysis of 100 post-experiment questionnaires showed that the random-gaze avatar did not improve on audio-only communication. The informed-gaze avatar significantly outperformed the random-gaze model and also outperformed audio-only on several response measures. We conclude that an avatar whose gaze behaviour is related to the conversation provides a marked improvement on an avatar that merely exhibits liveliness.
2001	The dynamics of mass online marketplaces: a case study of an online auction	The Internet has dramatically changed how people sell and buy goods. In recent years we have seen the emergence of electronic marketplaces that leverage information technology to create more efficient markets such as online auctions to bring together buyers and sellers with greater effectiveness at a massive scale. Despite the growing interest and importance of such marketplaces, our understanding of how the design of the marketplace affects buyer and seller behavior at the individual level and the market effectiveness at the aggregate level is still quite limited. This paper presents a detailed case study of a currently operational massive scale online auction marketplace. The main focus is to gain initial insights into the effects of the design of the marketplace. The results of the study point to several important considerations and implications not only for the design of online marketplaces but also for the design of large-scale websites where effective locating of information is key to user success.
2001	Digital family portraits: supporting peace of mind for extended family members	A growing social problem in the U.S., and elsewhere, is supporting older adults who want to continue living independently, as opposed to moving to an institutional care setting. One key part of this complex problem is providing awareness of senior adults day-to-day activities, promoting peace of mind for extended family members. In this paper, we introduce the concept of a digital family portrait that provides qualitative visualizations of a family members daily life. Leveraging a familiar household object, the picture frame, our design populates the frame with iconic imagery summarizing 28 days. In a final implementation, the digital family portrait would gather information from sensors in the home.
2001	Social navigation of food recipes	The term Social Navigation captures every-day behaviour used to find information, people, and places - namely through watching, following, and talking to people. We discuss how to design information spaces to allow for social navigation. We applied our ideas in a recipe recommendation system. In a follow-up user study, subjects state that social navigation adds value to the service: it provides for social affordance, and it helps turning a space into a social place. The study also reveals some unresolved design issues, such as the snowball effect where more and more users follow each other down the wrong path, and privacy issues.
2001	Chinese input with keyboard and eye-tracking: an anatomical study	Chinese input presents unique challenges to the field of human computer interaction. This study provides an anatomical analysis of today's standard Chinese input process, which is based on pinyin, a phonetic spelling system in Roman characters. Through a combination of human performance modeling and experimentation, our study decomposed the Chinese input process into sub-tasks and found that choice reaction time and numeric keying, two component resulted from the large number of homophones in Chinese, were the major usability bottlenecks. Choice reaction alone took 36\% of the total input time in our experiment. Numeric keying for multiple candidates selection tends to take the user's attention away from the computer visual screen. We designed and implemented the EASE (Eye Assisted Selection and Entry) system to help maintaining complete touch-typing experience without diverting visual (spacebar) and implicit eye-tracking to replace the numeric keystrokes. Our experiment showed that such a system could indeed work, even with today's imperfecteye-tracking technology.
2001	Model for unistroke writing time	Unistrokes are a viable form of text input in pen-based user interfaces. However, they are a very heterogeneous group of gestures the only common feature being that all are drawn with a single stroke. Several unistroke alphabets have been proposed including the original Unistrokes, Graffiti, Allegro, T-Cube and MDITIM. Comparing these methods usually requires a lengthy study with many writers and even then the results are biased by the earlier handwriting experience that the writers have. Therefore, a simple descriptive model for predicting the writing time for an expert user on any given unistroke alphabet thus enabling sounder argumentation on the properties of different writing methods.
2001	Text input for mobile devices: comparing model prediction to actual performance	A study was conducted to obtain performance data for entering text on a mobile phone in order to compare it to performance predictions based on two different mathematical models. Speed data was obtained for two text input methods, T9 Text Input and Multi-tap. While the direction of the results was the same for both the performance data and both model predicitons (with predictive text entry being faster than Multi-tap text entry), the results for all three differed in magnitude. Suggestions for this discrepancy are provided. In addition, in order to help shape future models, additional results are presented for both input methods to show how both accuracy and speed performance varies based on user experience and text subject matter.
2001	Better home shopping or new democracy?: evaluating community network outcomes	This is a perspective paper on community networks - socio-technical infrastructures supporting villages, towns, and neighborhoods. Community networking is well-established, world wide, and addresses critical societal issues, such as the “crisis of community” and the sociality of the Internet. However, community network projects have not emphasized evaluation. Relatively little is known about the economic, social, and psychological consequences of community networks for the individuals, groups, and communities served. Evaluating community networks is a momentous mutual opportunity for the development of CHI evaluation methodologies and for bringing technical CHI expertise to bear on societal issues.
2001	Identity construction environments: supporting a virtual therapeutic community of pediatric patients undergoing dialysis	We describe a five-month pilot project conducted in the dialysis unit at Boston's Children's Hospital. Pediatric patients with renal disease used the Zora graphical multi-user environment while facing hemodialysis. Zora is an identity construciton environment specifically designed to help young people explore issues of identity, while engaging in a participatory virtual community. This paper presents the experience and evaluates the feasibility and safety of using Zora in a hospital setting. It describes how Zora facilitated explorations of identity and mutual patient support and interaction. Finally it also presents design recommendations for future interventions of this kind. More generally, this paper explores the potential of technology specifically designed with therapeutic purposes to help patients cope with their illness.
2001	GeneyTM: designing a collaborative activity for the palmTM handheld computer	This paper describes a project to explore issues surrouding the development of a collaborative handheld educational application for children. A user-centered, iterative design process was used to develop GeneyTM, a collaborative problem solving application to help children explore genetic concepts using PalmTM handheld computers. The design methodology utilized mock-ups of representative tasks and scenarios, pre-design meetings with targets users, prototype development, and feedback sessions with target users. The results of this work identify an effective way of utilizing handheld computers for collaborative learning and provide important insights into the design of handheld applications for children. This work also illustrates the necessity of user-centered design when new user groups are targeted, especially when novel user interface paradigms are employed that go beyond current windows-based interfaces.
2001	Relational agents: a model and implementation of building user trust	Building trust with users is crucial in a wide range of applications, such as financial transactions, and some minimal degree of trust is required in all applications to even initiate and maintain an interaction with a user. Humans use a variety of relational conversational strategies, including small talk, to establish trusting relationships with each other. We argue that such strategies can also be used by interface agents, and that embodied conversational agents are ideally suited for this task given the myriad cues available to them for signaling trustworthiness. We describe a model of social dialogue, an implementation in an embodied conversation agent, and an experiment in which social dialogue was demonstrated to have an effect on trust, for users with a disposition to be extroverts.
2001	An empirical study of human Web assistants: implications for user support in Web information systems	User support is an important element in reaching the goal of universal usability for Web information systems. Recent developments indicate that human involvement in user support is a step towards this goal. However, most such efforts are currently being pursued on a purely intuitive basis. This, empirical findings about the role of human assistants are important. In this paper we present the findings from a field study of a general user support model for Web information systems. We show that integrating human assistance into Web systems is a way to provide efficient user support. Further, this integration makes a Web site more fun to use and increases the user's trust in the site. The support also improves the site atmosphere. Our findings are summarised as recommendations and design guidelines for decision-makers and developers Web systems.
2001	Social presence in Web surveys	Social interface theory has widespread influence in the field of human-computer interaction. The basic thesis is that humanizing cues in a computer interface can engender responses from users similar to human-human interaction. In contrast, the survey interviewing literature suggests that computer administration of surveys on highly sensitive topics reduces or eliminates social desirability effect, even when such humanizing features as voice are used. In attempting to reconcile these apparently contradictory findings, we varied features of the interface in a Web survey (n=3047). In one treatment, we presented an image of 1) a male researcher, 2) a female researcher, or 3) the study logo at several points. In another, we varied the extent of personal feedback provided. We find little support for the soical interface hypothesis. We describe our study and discuss possible reasons for the contradictory evidence on social interfaces
2001	Exploring 3D navigation: combining speed-coupled flying with orbiting	We present a task-based taxonomy of navigation techniques for 3D virtual environments, used to categorize existing techniques, drive exploration of the design space, and inspire new techniques. We briefly discuss several new techniques, and describe in detail one new techniques, Speed-coupled Flying with Orbiting. This technique couples control of movement speed to camera height and tilt, allowing users to seamlessly transition between local environment-views and global overviews. Users can also orbit specific objects for inspection. Results from two competitive user studies suggest users performed better with Speed-coupled Flying with Orbiting over alternatives, with performance also enhanced by a large display.
2001	Reaching movements to augmented and graphic objects in virtual environments	This work explores how the availability of visual and haptic feedback affects and kinematics of reaching performance in a tabletop virtual environment. Eight subjects performed reach-to-grasp movements toward target objects of various sites in conitions where visual and haptic feedback were either present or absent. It was found that movement time was slower when visual feedback of the moving limb was not available. Further MT varied systematically with target size when haptic feedback was available (i.e. augmented targets), and thus followed Fitts' law. However, movement times were constant regardless of target size when haptic feedback was removed. In depth analysis of the reaching kinematics revealed that subjects spent longer decelerating toward smaller targets in conditions where haptic feedback was available. In contrast, deceleration time was constant when haptic feedback was absent. These results suggest that visual feedback about the moving limb and veridical haptic feedback about object contract are extremely important for humans to effectively work in virtual environments.
2001	3D or not 3D?: evaluating the effect of the third dimension in a document management system	Several recent research systems have provided interactive three-dimensional (3D) visualisations for supporting everyday work such as file and document management. But what improvements do these 3D interfaces offer over their traditional 2D counterparts? This paper describes the comparative evaluation of two document management systems that differ only in the number of dimensions used for displaying and interacting with the data. The 3D system is heavily based on Robertson et al.'s Data Mountain, which supports users in storing, organising and retrieving “thumbnail” representations of documents such as bookmarked Web-pages. Results show that our subjects were faster at storing and retrieving pages in the display when using the 2D interface, but not significantly so. As expected, retrieval times significantly increased as the number of thumbnails increased. Despite the lack of significant differences between the 2D and 3D interfaces, subjective assessments showed a significant preference for the 3D interface.
2001	Automating camera management for lecture room environments	Given rapid improvements in network infrastructure and streaming-media technologies, a large number of corporations and universities are recording lectures and making them available online for anytime, anywhere access. However, producing high-quality lecture videos is still labor intensive and expensive. Fortunately, recent technology advances are making it feasible to build automated camera management systems to capture lectures. In this paper we report on our design, implementation and study of such a system. Compared to previous work-which has tended to be technology centric-we started with interviews with professional video producers and used their knowledge and expertise to create video production rules. We then targeted technology components that allowed us to implement a substantial portion of these rules, including the design of a virtual video director. The system's performance was compared to that of a human operator via a user study. Results suggest that our system's quality in close to that of a human-controlled system. In fact most remote audience members could not tell if the video was produced by a computer or a person.
2001	Viewing meeting captured by an omni-directional camera	One vision of future technology is the ability to easily and inexpensively capture any group meeting that occurs, store it, and make it available for people to view anytime and anywhere on the network. One barrier to achieving this vision has been the design of low-cost camera systems that can capture important aspects of the meeting without needing a human camera operator. A promising solution that has emerged recently is omni-directional cameras that can capture a 360-degree video of the entire meeting. The panoramic capability provided by these cameras raises both new opportunities and new issues for the interfaces provided for post-meeting viewers — for example, do we show all meeting participants all the time or do we just show the person who is speaking, how much control do we provide to the end-user in selecting the view, and will providing this control distract them from their task. These are not just user interface issues, they also raise tradeoffs for the client-server systems used to deliver such content. They impact how much data needs to be stored on the disk, what computation can be done on the server vs. the client, and how much bandwidth is needed. We report on a rototype system built using an omni-directional camera and results from user studies of interface preferences expressed by viewers.
2001	Partitioning digital worlds: focal and peripheral awareness in multiple monitor use	Software today does not help us partition our digital worlds effectively. We must organize them ourselves. This field study of users of multiple monitors examines how people with a lot of display space arrange information. Second monitors are generally used for secondary activities related to principal tasks, for peripheral awareness of information that is not the main focus, and for easy access to resources. A second monitor improves efficiency in ways that are difficult to measure yet can have substantial subjective benefit. The study concludes with illustrations of shortcomings of today's systems and applications: the way we work could be improved at relatively low cost.
2001	Folk computing: revisiting oral tradition as a scaffold for co-present communities	In this paper, we introduce Folk Computing: an approach for using technology to support co-present community building inspired by the concept of folklore. We also introduce a new technology, called “i-balls,” whose design helped fashion this approach. The design of the i-ball environment is explained in terms of our effort to simultaneously preserve what works about folklore while also using technology to expand its power as a medium for community building.
2001	Designing palaver tree online: supporting social roles in a community of oral history	As a more diverse population of users moves online, understanding how to help those groups work together and leverage their diverse skills poses a significant challenge for human-computer interaction. This paper presents a case study of the design of an online community that supports kids interviewing elders to build up a shared database of oral history. Two pilot studies with existing technology are presented, and a software design based on those studies is described, along with future work. This work shows the value of prototyping with existing technology in order to uncover user needs in an onine environment.
2001	Classroom collaboration in the design of tangible interfaces for storytelling	We describe the design of tangible interfaces to the KidPad collaborative drawing tool. Our aims are to support the re-enactment of stories to audiences, and integration within real classroom environments. A six-month iterative design process, working with children and teachers in school, has produced the “magic carpet”, an interface that uses pressure mats and video-tracked and barcoded physical props to navigate a story in KidPad. Reflecting on this process, we propose four guidelines for the design of tangible interfaces for the classroom. (1) Use physical size and shysical props to encourage collaboration. (2) Be aware of how different interfaces emphasize different actions. (3) Be aware that superficial changes to the design can produce very different physical interactions. (4) Focus on open low-tech technologies rather than (over) polished products.
2001	Using information scent to model user information needs and actions and the Web	On the Web, users typically forage for information by navigating from page to page along Web links. Their surfing patterns or actions are guided by their information needs. Researchers need tools to explore the complex interactions between user needs, user actions, and the structures and contents of the Web. In this paper, we describe two computational methods for understanding the relationship between user needs and user actions. First, for a particular pattern of surfing, we seek to infer the associated information need. Second, given an information need, and some pages as starting pints, we attempt to predict the expected surfing patterns. The algorithms use a concept called “information scent”, which is the subjective sense of value and cost of accessing a page based on perceptual cues. We present an empirical evaluation of these two algorithms, and show their effectiveness.
2001	Information scent as a driver of Web behavior graphs: results of a protocol analysis method for Web usability	The purpose of this paper is to introduce a replicable WWW protocol analysis methodology illustrated by application to data collected in the laboratory. The methodology uses instrumentation to obtain detailed recordings of user actions with a browser, caches Web pages encoutered, and videotapes talk-aloud protocols. We apply the current form of the method to the analysis of eight Web protocols, visualizing the structure of the interaction and showing the strong effect of information scent in determining the path followed.
2001	Visual information foraging in a focus + context visualization	Eye tracking studies of the Hyperbolic Tree browser [10] suggest that visual search in focus+context displays is highly affected by information scent (i.e., local cues, such as text summaries, used to assess and navigate toward distal information sources). When users detected a strong information scent, they were able to reach their goal faster with the Hyperbolic Tree browser than with a conventional browser. When users detected a weak scent or no scent, users exhibited less efficient search of areas with a high density of visual items. In order to interpret these results we present an integration of the CODE Theory of Visual Attention (CTVA) with information foraging theory. Development of the CTVA-foraging theory could lead to deeper analysis of interaction with visual displays of content, such as the World Wide Web or information visualizations.
2001	The notification collage: posting information to public and personal displays	The Notification Collage (NC) is a groupware system where distributed and co-located colleagues comprising a small community post media elements onto a real-time collaborative surface that all members can see. Akin to collages of information found on public bulletin boards, NC randomly places incoming elements onto this surface. People can post assorted media: live video from desktop cameras; editable sticky notes; activity indicator; slide shows displaying a series of digital photos, snapshots of a person's digitial desktop, and Web page thumbnails. User experiences show that NC becomes a rich resource for awareness and collaboration. Community members indicate their presence to others by posting live video. They regularly act on this information by engaging in text and video conversations. Because all people can overhear conversations, these become active opportunities to join in. People also post items they believe will be interesting to others, such as desktop snapshots and vacation photos. Finally, people use NC somewhat differently when it is displayed on a large public screen than when it appears on a personal computer.
2001	Single display privacyware: augmenting public displays with private information	The research area of Single Display Groupware (SDG) confronts the standard model of computing interaction, one user working on one computer, by investigating how the best support groups of users interacting with a shared display. One problem that has arisen in SDG research concerns access to private information. Previously, private information could not be displayed on a shared display, it could only be accessed on external devices, such as private monitors or Personal Digital Assistants (PDAs). This paper discusses Single Display Privacyware (SDP), an interaction technique that allows private information to be shown within the context of a shared display. A description of the hardware and software components of our prototype SDP system is given, as are the results of a user study performed to investigate users interacting in the environment. Conclusions concerning future research in the area of SDP are discussed.
2001	Linking public spaces: technical and social issues	Three public spaces frequency used by members of a single organization who are distributed across different floors of two buildings were linked by constantly-running video and audio connections. We discuss the design of the system, including issues in providing low-latency, full-duplex audio-video connectivity, ways to increase possibilities for interaction while addressing privacy concerns, and the introduction of the system to the community. We report on responses to the system and lessions learned, including unexpected issues, such as creative decorations of the spaces and assertions by a vocal minority of employees about the private nature of “public space.”
2001	Scale effects in steering law tasks	Interaction tasks on a computer screen can technically be scaled to a much larger or much smaller sized input control area by adjusting the input device's control gain or the control-display (C-D) ratio. However, human performance as a function of movement scale is not a well concluded topic. This study introduces a new task paradigm to study the scale effect in the framework of the steering law. The results confirmed a U-shaped performance-scale function and rejected straight-line or no-effect hypotheses in the literature. We found a significant scale effect in path steering performance, although its impact was less than that of the steering law's index of difficulty. We analyzed the scale effects in two plausible causes: movement joints shift and motor precision limitation. The theoretical implications of the scale effects to the validity of the steering law, and the practical implications of input device size and zooming functions are discussed in the paper.
2001	Accuracy measures for evaluating computer pointing devices	In view of the difficulties in evaluating computer pointing devices across different tasks within dynamic and complex systems, new performance measures are needed. This paper proposes seven new accuracy measures to elicit (sometimes subtle) differences among devices in precision pointing tasks. The measures are target re-entry, task axis crossing, movement direction change, orthogonal direction change, movement variability, movement error, and movement offset. Unlike movement time, error rate, and throughput, which are based on a single measurement per trial, the new measures capture aspects of movement behaviour during a trial. The theoretical basis and computational techniques for the measures are described, with examples given. An evaluation with four pointing devices was conducted to validate the measures. A causal relationship to pointing device efficiency (viz. throughput) was found, as was an ability to discriminate among devices in situations where differences did not otherwise appear. Implications for pointing device research are discussed.
2001	Laser pointer interaction	Group meetings and other non-desk situations require that people be able to interact at a distance from a display surface. This paper describes a technique using a laser pointer and a camera to accomplish just such interactions. Calibration techniques are given to synchronize the display and camera coordinates. A series of interactive techniques are described for navigation and entry of numbers, times, dates, text, enumerations and lists of items. The issues of hand jitter, detection error, slow sampling and latency are discussed in each of the interactive techniques.
2001	Listen reader: an electronically augmented paper-based book	While predictions abound that electronic books will supplant traditional paper-based books, many people bemoan the coming loss of the book as cultural artifact. In this project we deliberately keep the affordances of paper books while adding electronic augmentation. The Listen Reader combines the look and feel of a real book - a beautiful binding, paper pages and printed images and text - with the rich, evocative quality of a movie soundtrack. The book's multi-layered interactive soundtrack consists of music and sound effects. Electric field sensors located in the book binding sense the proximity of the reader's hands and control audio parameters, while RFID tags embedded in each page allow fast, robust page identification. Three different Listen Readers were built as part of a six-month museum exhibit, with more than 350,000 visitors. This paper discusses design, implementation, and lessons learned through the iterative design process, observation, and visitor interviews.
2001	Exploiting interactivity, influence, space and time to explore non-linear drama in virtual worlds	We present four contrasting interfaces to allow multiple viewers to explore 3D recordings of dramas in on-line virtual worlds. The first is an on-line promenade performance to an audience of avatars. The second is a form of immersive cinema, with multiple simultaneous viewpoints. The third is a tabletop projection surface that allows viewers to select detailed views from a bird's-eye overview. The fourth is a linear television broadcast created by a director or editor. A comparison of these examples shows how a viewing audience can exploit four general resources - interactivity, influence, space, and time - to make sense of complex, non-linear virtual drama. These resources provide interaction designers with a general framework for defining the relationship between the audience and the 3D content.
2001	Casablanca: designing social communication devices for the home	The Casablanca project explored how media space concepts could be incorporated into households and family life. This effort included prototypes built for the researchers' own home use, field studies of households, and consumer testing of design concepts. A number of previously unreported consumer preferences and concerns were uncovered and incorporated into several original prototypes, most notably ScanBoard and the Intentional Presence Lamp. Casablanca also resulted in conclusions about designing household social communication devices.
2002	Where do web sites come from?: capturing and interacting with design history	To form a deep understanding of the present; we need to ?nd and engage history. We present an informal history capture and retrieval mechanism for collaborative, early-stage information design. This history system is implemented in the context of the Designers' Outpost, a wall-scale, tangible interface for collaborative web site design. The interface elements in this history system are designed to be ?uid and comfortable for early-phase design. As demonstrated by an informal lab study with six professional designers, this history system enhances the design process itself, and provides new opportunities for reasoning about the design of complex artifacts
2002	The augurscope: a mixed reality interface for outdoors	The augurscope is a portable mixed reality interface for outdoors. A tripod-mounted display is wheeled to different locations and rotated and tilted to view a virtual environment that is aligned with the physical background. Video from an onboard camera is embedded into this virtual environment. Our design encompasses physical form, interaction and the combination of a GPS receiver, electronic compass, accelerometer and rotary encoder for tracking. An initial application involves the public exploring a medieval castle from the site of its modern replacement. Analysis of use reveals problems with lighting, movement and relating virtual and physical viewpoints, and shows how environmental factors and physical form affect interaction. We suggest that problems might be accommodated by carefully constructing virtual and physical content
2002	Movement model, hits distribution and learning in virtual keyboarding	In a ten-session experiment, six participants practiced typing with an expanding rehearsal method on an optimized virtual keyboard. Based on a large amount of in-situ performance data, this paper reports the following findings. First, the Fitts-digraph movement efficiency model of virtual keyboards is revised. The format and parameters of Fitts' law used previously in virtual keyboards research were incorrect. Second, performance limit predictions of various layouts are calculated with the new model. Third, learning with expanding rehearsal intervals for maximum memory benefits is effective, but many improvements of the training algorithm used can be made in the future. Finally, increased visual load when typing previously practiced text did not significantly change users' performance at this stage of learning, but typing unpracticed text did have a performance effect, suggesting a certain degree of text specific learning when typing on virtual keyboards
2002	Comparison of two touchpad-based methods for numeric entry	Small hand-held touchpads can be used to replace stylus-based digitizing tablets when the use of a stylus is not convenient. In text entry tasks where the writing surface is held in a hand the error rate becomes a problem. The small size of strokes compared to the width of the fingertip and the additional imprecision caused by the interaction of the pad and finger movements make input very imprecise. We describe a new improved clock-face based stroke system for entering numbers with a touchpad. In a 20-session user study with 6 users we found slightly better throughput of successfully entered numbers with the proposed new system. This advantage was mainly due to lower error rate with the new system. User preference similarly slightly favored the new system over an earlier straightforward proposal based on the clock metaphor
2002	Interacting at a distance: measuring the performance of laser pointers and other devices	It is difficult to interact with computer displays that are across the room. A popular approach is to use laser pointers tracked by a camera, but interaction techniques using laser pointers tend to be imprecise, error-prone, and slow. Although many previous papers discuss laser pointer interaction techniques, none seem to have performed user studies to help inform the design. This paper reports on two studies of laser pointer interactions that answer some of the questions related to interacting with objects using a laser pointer. The first experiment evaluates various parameters of laser pointers. For example, the time to acquire a target is about 1 second, and the jitter due to hand unsteadiness is about Â±8 pixels, which can be reduced to about Â±2 to Â±4 pixels by filtering. We compared 7 different ways to hold various kinds of laser pointers, and found that a laser pointer built into a PalmOS device was the most stable. The second experiment compared 4 different ways to select objects on a large projected display. We found that tapping directly on a wall-size SmartBoard was the fastest and most accurate method, followed by a new interaction technique that copies the area of interest from the big screen to a handheld. Third in speed was the conventional mouse, and the laser pointer came in last, with a time almost twice as long as tapping on the SmartBoard
2002	Messages embedded in gaze of interface agents --- impression management with agent's gaze	We propose a gaze movement model that enables an embodied interface agent to convey different impressions to users. Managing one's own impression to influence the behaviors of others plays an important role in human communications. To create a new application area which involves agents in this kind of social interaction, interface agents that manage their impressions are required. For this purpose, we build the gaze movement model based on three gaze parameters picked from a large number of psychological studies: amount of gaze , mean duration of gaze , and gaze points while averted . In this paper, we introduce the gaze movement model and gaze parameters. We then present an experiment in which subjects evaluated the impressions created by nine gaze patterns produced by altering the gaze parameters. The results indicate that reproducible relations exist between the gaze parameters and impressions, which shows the validity of the model
2002	Leveraging the asymmetric sensitivity of eye contact for videoconference	Eye contact is a natural and often essential element in the language of visual communication. Unfortunately, perceiving eye contact is difficult in most video-conferencing systems and hence limits their effectiveness. We conducted experiments to determine how accurately people perceive eye contact. We discovered that the sensitivity to eye contact is asymmetric, in that we are an order of magnitude less sensitive to eye contact when people look below our eyes than when they look to the left, right, or above our eyes. Additional experiments support a theory that people are prone to perceive eye contact, that is, we will think that someone is making eye contact with us unless we are certain that the person is not looking into our eyes. These experimental results suggest parameters for the design of videoconferencing systems. As a demonstration, we were able to construct from commodity components a simple dyadic videoconferencing prototype that supports eye contact
2002	Acquisition of expanding targets	There exist several user interface widgets that dynamically grow in size in response to the user's focus of attention. Some of these, such as icons in toolbars, expand to facilitate their selection - allowing for a reduced initial size in an attempt to optimize screen space use. However, selection performance may be degraded by this decreased initial widget size. We describe an experiment which explores the effects of varying parameters of expansion techniques in a selection task. Our results suggest that Fitts' law can model and predict performance in such tasks. They also indicate that performance is governed by the target's final size, not its initial one. Further, performance is dependent on the target's final size even when the target only begins expanding as late as after 90\% of the movement towards the target has already been completed. These results indicate that expanding widgets can be used without sacrificing performance
2002	Quantitative analysis of scrolling techniques	We propose a formal experimental paradigm designed to help evaluate scrolling interaction techniques. Such a method is needed by interaction designers to quantify scrolling performance, thereby providing a tool to evaluate and improve upon new techniques. We systematically vary the scrolling distance as well as the required tolerance of scrolling. Distance and tolerance are the parameters of Fitts' Law, which traditionally has been applied to the evaluation of pointing devices in tasks involving rapid, aimed movement to visible targets. Scrolling involves acquisition of targets well beyond the edges of the screen, yet Fitts' Law models our experimental data very wellWe apply our paradigm to the IBM ScrollPoint and the IntelliMouse Wheel. Our experimental approach reveals a crossover effect in performance versus distance, with the Wheel performing best at short distances but the ScrollPoint performing best at long distances. We also demonstrate that the performance of the Wheel can be significantly improved using an acceleration algorithm. These results show that our approach yields a practical and rigorous method for the evaluation of scrolling techniques.
2002	More than dotting the i's --- foundations for crossing-based interfaces	Today's graphical interactive systems largely depend upon pointing actions, i.e. entering an object and selecting it. In this paper we explore whether an alternate paradigm --- crossing boundaries --- may substitute or complement pointing as another fundamental interaction method. We describe an experiment in which we systematically evaluate two target-pointing tasks and four goal-crossing tasks, which differ by the direction of the movement variability constraint (collinear vs. orthogonal) and by the nature of the action (pointing vs. crossing, discrete vs. continuous). We found that participants' temporal performance in each of the six tasks was dependent on the index of difficulty formulated in the same way as in Fitts' law, but that the parameters differ by task. We also found that goal crossing completion time was shorter or no longer than pointing performance under the same index of difficulty. These regularities, as well as qualitative characterizations of crossing actions and their application in HCI, lay the foundation for designing crossing-based user interfaces
2002	A Case Study to Distill Structural Scaffolding Guidelines for Scaffolded Software Environments	A challenge for HCI researchers and designers involves developing software tools for learners to support them in mindfully doing and learning complex new work practices. Such "learner-centered" tools incorporate scaffolds-software features that address the cognitive obstacles learners face so they can engage in the work in an educationally productive manner. However, designers still lack specific scaffolding design guidelines for developing effective scaffolded tools. The HCI contribution of this paper is a set of scaffolding guidelines distilled from an empirical case study. The study evaluated Symphony, a scaffolded environment for high school students learning science inquiry. The study evaluated the "effects with" the Symphony scaffolds, which described how students worked with the scaffolds to do their science work. The scaffolds were evaluated using several usability and learner-centered criteria, and the resulting information was correlated with structural characteristics of the scaffolds to distill a set of structural scaffolding guidelines
2002	Notification for shared annotation of digital documents	Notification and shared annotations go hand-in-hand. Notification of activity in a shared document system is known to support awareness and improve asynchronous collaboration, but few studies have examined user needs and explored design tradeoffs. We examined large-scale use of notifications in a commercial system and found it lacking. We designed and deployed enhancements to the system, then conducted a field study to gauge their effect. We found that providing more information in notification messages, supporting multiple communication channels through which notifications can be received, and allowing customization of notification messages are particularly important. Overall awareness of annotation activity on software specifications increased with our enhancements
2002	I'd be overwhelmed, but it's just one more thing to do: availability and interruption in research management	Many CSCW projects dealing with individual availability and interruption filtering achieve only limited success. Perhaps this is because designers of such systems have limited evidence to draw upon; most data on interruption management is at least a decade old. This study uses an empirical sampling method and qualitative interviews to examine attitudes toward availability and interruption. Specifically, we analyze how corporate research managers spend their time and look at how their attitudes toward interruption relate to their various activities. Attitudes toward interruption are marked by a complex tension between wanting to avoid interruption and appreciating its usefulness. We conclude by discussing the implications of these findings for design, suggesting that the notion of socially translucent systems may be a fruitful approach
2002	Comparing voodoo dolls and HOMER: exploring the importance of feedback in virtual environments	When creating techniques for manipulating objects at a distance in immersive virtual environments, researchers have primarily focused on increasing selection range, placement range, and placement accuracy. This focus has led researchers to create and formally study a series of "arm-extension" techniques, which dynamically scale the user's arm to allow him to manipulate distant objects. Researchers have also developed representation-based techniques, which allow users to manipulate a distant object by manipulating a copy of it in a handheld representation. However, researchers have not yet formally established the relative value of these techniques. In this paper we present a formal study comparing Voodoo Dolls, a best-practice representation-based technique, with HOMER, a best-practice arm-extension technique. We found that the Voodoo Dolls technique, which provides better feedback by allowing users to view a manipulated object both up close and at a distance, allowed users to both position and orient objects more accurately. Our results suggest that researchers should focus on improving feedback for 3D manipulation techniques
2002	SmartSkin: an infrastructure for freehand manipulation on interactive surfaces	This paper introduces a new sensor architecture for making interactive surfaces that are sensitive to human hand and finger gestures. This sensor recognizes multiple hand positions and shapes and calculates the distance between the hand and the surface by using capacitive sensing and a mesh-shaped antenna. In contrast to camera-based gesture recognition systems, all sensing elements can be integrated within the surface, and this method does not suffer from lighting and occlusion problems. This paper describes the sensor architecture, as well as two working prototype systems: a table-size system and a tablet-size system. It also describes several interaction techniques that would be difficult to perform without using this architecture
2002	Creating principal 3D curves with digital tape drawing	Previous systems have explored the challenges of designing an interface for automotive styling which combine the metaphor of 2D drawing using physical tape with the simultaneous creation and management of a corresponding virtual 3D model. These systems have been limited to only 2D planar curves while typically the principal characteristic curves of an automotive design are three dimensional and non-planar. We present a system which addresses this limitation. Our system allows a designer to construct these non-planar 3D curves by drawing a series of 2D curves using the 2D tape drawing technique and interaction style. These results are generally applicable to the interface design of 3D modeling applications and also to the design of arm's length interaction on large scale display systems
2002	Adaptive testing: effects on user performance	This study examines the effects of interface adaptation on user performance in HCI and CMC. No studies to date have explored the psychological effects of a combination of software performance monitoring and adaptation. This combination is the focus of the present study. Two competing possible effects of adaptive interfaces are presented: 1) Social facilitation, according to which users with high task confidence should perform better, and users with low task confidence should perform less well because their performance is monitored by the interface; and 2) "choking", according to which users with high task confidence should perform less well, and users with low task confidence should perform better because the interface adapts to their performance. A 2 (adaptive vs. non-adaptive) x 2 (high user task confidence vs. low task confidence) x 2 (HCI vs. CMC) laboratory experiment was conducted. Results indicate that for CMC, the social facilitation explanation holds true, while results for HCI were consistent with the "choking" explanation. Implications for the theory and design of adaptive interfaces are discussed
2002	Effects of four computer-mediated communications channels on trust development	When virtual teams need to establish trust at a distance, it is advantageous for them to use rich media to communicate. We studied the emergence of trust in a social dilemma game in four different communication situations: face-to-face, video, audio, and text chat. All three of the richer conditions were significant improvements over text chat. Video and audio conferencing groups were nearly as good as face-to-face, but both did show some evidence of what we term delayed trust (slower progress toward full cooperation) and fragile trust (vulnerability to opportunistic behavior)
2002	Trust without touch: jumpstarting long-distance trust with initial social activities	Computer-mediated communication (CMC) is thought to be inadequate when one needs to establish trust. If, however, people meet before using CMC, they trust each other, trust being established through touch. Here we show that if participants do not meet beforehand but rather engage in various getting-acquainted activities over a network, trust is much higher than if they do nothing beforehand, nearly as good as a prior meeting. Using text-chat to get acquainted is nearly as good as meeting, and even just seeing a picture is better than nothing
2002	Automating CPM-GOMS	CPM-GOMS is a modeling method that combines the task decomposition of a GOMS analysis with a model of human resource usage at the level of cognitive, perceptual, and motor operations. CPM-GOMS models have made accurate predictions about skilled user behavior in routine tasks, but developing such models is tedious and error-prone. We describe a process for automatically generating CPM-GOMS models from a hierarchical task decomposition expressed in a cognitive modeling tool called Apex. Resource scheduling in Apex automates the difficult task of interleaving the cognitive, perceptual, and motor resources underlying common task operators (e.g. mouse move-and-click). Apex's UI automatically generates PERT charts, which allow modelers to visualize a model's complex parallel behavior. Because interleaving and visualization is now automated, it is feasible to construct arbitrarily long sequences of behavior. To demonstrate the process, we present a model of automated teller interactions in Apex and discuss implications for user modeling
2002	Investigating human-computer optimization	Scheduling, routing, and layout tasks are examples of hard optimization problems with broad application in industry. Past research in this area has focused on algorithmic issues. However, this approach neglects many important human-computer interaction issues that must be addressed to provide people with practical solutions to optimization problems. Automatic methods do not leverage human expertise and can only find solutions that are optimal with regard to an invariably over-simplified problem description. Furthermore, users must understand the generated solutions in order to implement, justify, or modify them. Interactive optimization helps address these issues but has not previously been studied in detail. This paper describes experiments on an interactive optimization system that explore the most appropriate way to combine the respective strengths of people and computers. Our results show that users can successfully identify promising areas of the search space as well as manage the amount of computational effort expended on different subproblems
2002	An evaluation of a multiple interface design solution for bloated software	This study examines a novel interface design for heavily-featured productivity software. The design includes two interfaces between which the user can easily toggle: (1) an interface personalized by the user containing desired features only, and (2) the default interface with all the standard features. This design was prototyped as a front-end to a commercial word processor and evaluated in a comprehensive field study. The study tested the effects of different interface designs on users' satisfaction and their perceived ability to navigate, control, and learn the software. There were two conditions: a commercial word processor with adaptive menus and our two-interface prototype with adaptable menus for the same word processor. Results showed that participants were better able to navigate through the menus and toolbars and were better able to learn with our prototype. There were also significant differences in satisfaction and control with our design
2002	Introducing instant messaging and chat in the workplace	We report on our experiences of introducing an instant messaging and group chat application into geographically distributed workgroups. We describe a number of issues we encountered, including privacy concerns, individual versus group training, and focusing on teams or individuals. The perception of the tool's utility was a complex issue, depending both on users' views of the importance of informal communication, and their perceptions of the nature of cross-site communication issues. Finally, we conclude with a discussion of critical mass, which is related to the features each user actually uses. More generally, we encountered a dilemma that imposes serious challenges for user-centered design of groupware systems
2002	Hubbub: a sound-enhanced mobile instant messenger that supports awareness and opportunistic interactions	There have been many attempts to support awareness and lightweight interactions using video and audio, but few have been built on widely available infrastructure. Text-based systems have become more popular, but few support awareness, opportunistic conversations, and mobility, three important elements of distributed collaboration. We built on the popularity of text-based Instant Messengers (IM) by building a mobile IM called Hubbub that tries to provide all three, notably through the use of earcons. In a 5.5-month use study, we found that Hubbub helped people feel connected to colleagues in other locations and supported opportunistic interactions. The sounds provided effective awareness cues, although some found them annoying. It was more important to support graceful transitions between multiple fixed locations than to support wireless access, although both were useful
2002	When conventions collide: the tensions of instant messaging attributed	We discuss findings from observation, interviews, and textual analysis of instant messaging use in a university research lab setting. We propose a method for characterizing the tensions that permeate instant messaging texts and that expose the collision between conventions of verbal and written communication. Given this method, we suggest a design space for exploring potential design choices in instant messaging clients. Finally, we recommend an analysis of communicative conventions as a fruitful lens through which designers might anticipate or circumvent design tensions in emergent computer-mediated communication technologies
2002	Women take a wider view	Published reports suggest that males significantly outperform females in navigating virtual environments. A novel navigation technique reported in CHI 2001, when combined with a large display and wide field of view, appeared to reduce that gender bias. That work has been extended with two navigation studies in order to understand the finding under carefully controlled conditions. The first study replicated the finding that a wide field of view coupled with a large display benefits both male and female users and reduces gender bias. The second study suggested that wide fields of view on a large display were useful to females despite a more densely populated virtual world. Implications for design of virtual worlds and large displays are discussed. Specifically, women take a wider field of view to achieve similar virtual environment navigation performance to men
2002	Evaluating the effectiveness of spatial memory in 2D and 3D physical and virtual environments	User interfaces can improve task performance by exploiting the powerful human capabilities for spatial cognition. This opportunity has been demonstrated by many prior experiments. It is tempting to believe that providing greater spatial flexibility-by moving from flat 2D to 3D user interfaces-will further enhance user performance. This paper describes an experiment that investigates the effectiveness of spatial memory in real-world physical models and in equivalent computer-based virtual systems. The different models vary the user's freedom to use depth and perspective in spatial arrangements of images representing web pages. Results show that the subjects' performance deteriorated in both the physical and virtual systems as their freedom to locate items in the third dimension increased. Subjective measures reinforce the performance measures, indicating that users found interfaces with higher dimensions more 'cluttered' and less efficient
2002	Learning where to look: location learning in graphical user interfaces	A theoretical account is presented on how locations of interface objects are learned and how the mechanisms underlying location learning interact with the representativeness of object labels. The account is embodied in a computational cognitive model built within the ACT-R/PM cognitive architecture [1, 2] and is supported by point-of-gaze and performance data collected in empirical research. The model interacts with the same software under the same experimental task conditions as study participants and replicates both performance and the finer-grained point-of-gaze data. Drawing from the data and model, location learning is characterized as a process that occurs as a by-product of interaction such that, without specific intent to do so, users can gradually learn the locations of the interface objects to which they attend. Characteristics of the user interface shape this learning process, however, by constraining the set of possible strategies for interaction. Locations are learned more quickly when the least-effortful strategy available in the interface explicitly requires retrieval of location knowledge
2002	SmartSkip: consumer level browsing and skipping of digital video content	In this paper, we describe an interface for browsing and skipping digital video content in a consumer setting; that is, sitting and watching television from a couch using a standard remote control. We compare this interface with two other interfaces that are in common use today and found that subjective satisfaction was statistically better with the new interface. Performance metrics however, like time to task completion and number of clicks were worse.
2002	How knowledge workers use the web	We report on a diary study of how and why knowledge workers use the World Wide Web. By examining in detail a complete two-day set of Web activities from each of 24 people, we construct a framework with which to describe the different tasks knowledge workers undertake. By looking at the characteristics of each type of activity, we can see how certain activities are unsuited to particular kinds of technologies (e.g., mobile devices); how Web tools might be incrementally improved; and how we might better support knowledge workers' Web tasks in the future
2002	Applying patterns of cooperative interaction to work (re)design: e-government and planning	This paper presents patterns of cooperative interaction derived from ethnographic studies of cooperative work as devices for generalisation, re-use and design. These patterns consist of examples of similar social and interactional phenomena found in different studies that serve as resources for defining and envisaging design concepts, and potential work process and technical solutions. We outline new pattern examples and demonstrate their use in application to a complex setting: e-government in local government planning
2002	Separating the swarm: categorization methods for user sessions on the web	Understanding user behaviors on Web sites enables site owners to make sites more usable, ultimately helping users to achieve their goals more quickly. Accordingly, researchers have devised methods for categorizing user sessions in hopes of revealing user interests. These techniques build user profiles by combining users' navigation paths with other data features, such as page viewing time, hyperlink structure, and page content. Previously, we have presented complex techniques of combining many of these data features to cluster user profiles. In this paper, we introduce a user study and a systematic evaluation of these different data features and their associated weighting schemes. We present the results of our study, including accuracy measures for a number of clustering approaches, and offer recommendations for Web analysts. While further investigation over more sites is needed to definitively settle on a robust scheme, we have characterized this analytic space
2002	Popout prism: adding perceptual principles to overview+detail document interfaces	We present an overview+detail document interface that draws on perceptual principles to help users work with documents. Central to our approach is the use of improved document overviews. Our approach also includes novel highlighting in the full representation of documents, as well as techniques to help users smoothly transition from the overview to the full representation of the document. We present a specific implementation of our design for Web browsing. We also present a qualitative user study that indicates that our perceptual design principles are effective and that users prefer our interface to traditional "find" and highlighting techniques. Our user study additionally reveals interesting tasks and strategies supported in our framework that have implications for overview+detail document interfaces in general
2002	Keeping things in context: a comparative evaluation of focus plus context screens, overviews, and zooming	Users working with documents that are too large and detailed to fit on the user's screen (e.g. chip designs) have the choice between zooming or applying appropriate visualization techniques. In this paper, we present a comparison of three such techniques. The first, focus plus context screens, are wall-size low-resolution displays with an embedded high-resolution display region. This technique is compared with overview plus detail and zooming/panning. We interviewed fourteen visual surveillance and design professionals from different areas (graphic design, chip design, air traffic control, etc.) in order to create a repre sentative sample of tasks to be used in two experimental comparison studies. In the first experiment, subjects using focus plus context screens to extract information from large static documents completed the two experimental tasks on average 21\% and 36\% faster than when they used the other interfaces. In the second experiment, focus plus context screens allowed subjects to reduce their error rate in a driving simulation to less than one third of the error rate of the competing overview plus detail setup
2002	Improving focus targeting in interactive fisheye views	Fisheye views allow people to see both a focus region and the surrounding context in the same window. However, the magnification effects of the fisheye lens can cause several problems for users. One of these is focus-targeting, where a user moves the focus to a new location. Magnification makes focus-targeting difficult because objects appear to move as the focus point approaches them. This paper examines how the distortion of a fisheye view affects focus-targeting performance, and present a technique called speed-coupled flattening (SCF) as a way to improve focus targeting in distortion-oriented views. SCF dynamically reduces the distortion level of a fisheye based on pointer velocity and acceleration. In an experiment, the technique resulted in significant reductions in both targeting time and targeting errors. By adjusting distortion based on the user's activity, we can improve usability without requiring the user to manipulate any additional view controls
2002	SCANMail: a voicemail interface that makes speech browsable, readable and searchable	Increasing amounts of public, corporate, and private speech data are now available on-line. These are limited in their usefulness, however, by the lack of tools to permit their browsing and search. The goal of our research is to provide tools to overcome the inherent difficulties of speech access, by supporting visual scanning, search, and information extraction. We describe a novel principle for the design of UIs to speech data: What You See Is Almost What You Hear (WYSIAWYH) . In WYSIAWYH , automatic speech recognition (ASR) generates a transcript of the speech data. The transcript is then used as a visual analogue to that underlying data. A graphical user interface allows users to visually scan, read, annotate and search these transcripts. Users can also use the transcript to access and play specific regions of the underlying message. We first summarize previous studies of voicemail usage that motivated the WYSIAWYH principle, and describe a voicemail UI, SCANMail, that embodies WYSIAWYH . We report on a laboratory experiment and a two-month field trial evaluation. SCANMail outperformed a state of the art voicemail system on core voicemail tasks. This was attributable to SCANMail's support for visual scanning, search and information extraction. While the ASR transcripts contain errors, they nevertheless improve the efficiency of voicemail processing. Transcripts either provide enough information for users to extract key points or to navigate to important regions of the underlying speech, which they can then play directly
2002	A comparative study of speech in the call center: natural language call routing vs. touch-tone menus	This paper presents a field study that compares natural language call routing with standard touch-tone menus. Call routing is the task of getting callers to the right place in the call center, which could be the appropriate live agent or automated service. Natural language call routing lets callers describe the reason for their call in their own words, instead of presenting them with a list of menu options to select from using the telephone touch-tone keypad. The field study was conducted in a call center of a large telecommunication service provider. Results show that with natural language call routing, more callers respond to the main routing prompt, more callers are routed to a specific destination (instead of defaulting to a general operator who may have to transfer them), and more callers are routed to the correct agent. Our survey data show that callers overwhelmingly prefer natural language call routing over standard touch-tone menus. Furthermore, natural language call routing can also deliver significant cost savings to call centers
2002	Gestural and audio metaphors as a means of control for mobile devices	This paper discusses the use of gesture and non-speech audio as ways to improve the user interface of a mobile music player. Their key advantages mean that users could use a player without having to look at its controls when on the move. Two very different evaluations of the player took place: one based on a standard usability experiment (comparing the new player to a standard design) and the other a video analysis of the player in use. Both of these showed significant usability improvements for the gesture/audio-based interface over a standard visual/pen-based display. The similarities and differences in the results produced by the two studies are discussed
2002	Physical programming: designing tools for children to create physical interactive environments	Physical interactive environments can come in many forms: museum installations, amusement parks, experimental theaters, and more. Programming these environments has historically been done by adults, and children, as the visiting participants, have been offered few pre-created choices to explore. Given these creative limitations, the goal of our research has been to develop programming tools for physical interactive environments that are appropriate for use by young children (ages 4-6). We have explored numerous design approaches over the past two years. Recently we began focusing on a "physical programming" approach and developed a wizard-of-oz prototype for young children. This paper presents the motivation for this research, the evolution of our programming approach, and our recent explorations with children
2002	A visual language for sketching large and complex interactive designs	Informal, sketch-based design tools closely match the work practices of user interface designers. Current tools, however, are limited in the size and complexity of interaction that can be specified. We have created an advanced sketch-based visual language that allows for easy prototyping of large, complex interactive designs. In its current embodiment in the denim web design tool, the visual language allows designers to sketch reusable components for recurring page elements, such as navigation bars, as well as conditionals to illustrate and test transitions that depend on a user's input. Designers can also specify sites that accept richer user input than simple clicking. Our informal evaluation shows that these features allow designers with little programming experience to quickly create prototypes of large, complex web sites while still working inside an informal, sketch-based environment
2002	Specifying preferences based on user history	Many applications require users to specify preferences. We support users in this task by letting them define preferences relative to their personal history or that of other users. We implement this idea using a graphical technique called control shadows, which we have implemented on both a desktop computer and on a cell phone with a small, grayscale display. An empirical study compared user performance on the graphical interface and a text table interface with identical functionality. On the desktop, users completed their tasks more quickly and effectively and strongly preferred the graphical interface. On the cell phone, there was no significant difference between the graphical and table interfaces. Finally, personal history proved useful in specifying preferences, but history of other users was not helpful
2002	Observed behavior and perceived value of authors in usenet newsgroups: bridging the gap	In this paper we describe an evaluation of behavioral descriptors generated from an analysis of a large collection of Usenet newsgroup messages. The metrics describe aspects of newsgroup authors' behavior over time; such information can aid in filtering, sorting, and recommending content from public discussion spaces like newsgroups. To assess the value of a variety of these behavioral descriptors, we compared 22 participants' subjective evaluations of authors whose messages they read to behavioral metrics describing the same authors. We found that many metrics, particularly the longevity and frequency of participation, the number of newsgroups to which authors contribute messages, and the amount they contribute to each thread, correlate highly with readers' subjective evaluations of the authors
2002	Diffusing information in organizational settings: learning from experience	Recommender systems selectively circulate information enriched with comments and feedback based on people's experience. These systems filter information in a semi-automatic and high-quality way in order to support a community during their work or leisure practices. However recommender systems are usually separate tools that require a degree of effort to be used, both when receiving information and to insert new feedback. In this paper we present our informal experiences with the use of multiple user interfaces (interactive large screen, email, paper and PDA) as means to improve the diffusion of information through an organizational unit and to improve access to information stored within an existing recommender system
2002	A tangible interface for organizing information using a grid	The task of organizing information is typically performed either by physically manipulating note cards or sticky notes or by arranging icons on a computer with a graphical user interface. We present a new tangible interface platform for manipulating discrete pieces of abstract information, which attempts to combine the benefits of each of these two alternatives into a single system. We developed interaction techniques and an example application for organizing conference papers. We assessed the effectiveness of our system by experimentally comparing it to both graphical and paper interfaces. The results suggest that our tangible interface can provide a more effective means of organizing, grouping, and manipulating data than either physical operations or graphical computer interaction alone
2002	Cognitive cubes: a tangible user interface for cognitive assessment	Assessments of spatial, constructional ability are used widely in cognitive research and in clinical diagnosis of disease or injury. Some believe that three-dimensional (3D) forms of these assessments would be particularly sensitive, but difficulties with consistency in administration and scoring have limited their use. We describe Cognitive Cubes, a novel computerized tool for 3D constructional assessment that increases consistency and promises improvements in flexibility, reliability, sensitivity and control. Cognitive Cubes makes use of ActiveCube, a novel tangible user interface for describing 3D shape. In testing, Cognitive Cubes was sensitive to differences in cognitive ability and task, and correlated well to a standard paper-and-pencil 3D spatial assessment
2002	Illuminating clay: a 3-D tangible interface for landscape analysis	This paper describes a novel system for the real-time computational analysis of landscape models. Users of the system - called Illuminating Clay - alter the topography of a clay landscape model while the changing geometry is captured in real-time by a ceiling-mounted laser scanner. A depth image of the model serves as an input to a library of landscape analysis functions. The results of this analysis are projected back into the workspace and registered with the surfaces of the model.We describe a scenario for which this kind of tool has been developed and we review past work that has taken a similar approach. We describe our system architecture and highlight specific technical issues in its implementation.We conclude with a discussion of the benefits of the system in combining the tangible immediacy of physical models with the dynamic capabilities of computational simulations.
2002	Designing online banner advertisements: should we animate?	A common medium for advertising on the Internet is the use of banner ads. This study investigates recall and recognition of animated banner advertisements in an attempt to identify design guidelines. It was hypothesized that animation would increase recall and recognition of novel ads by increasing user awareness. No significant relationships were found between the use of animation and ability to recall and recognize banner ads. Results indicate that animation does not enhance user memory of online banner advertisements.
2002	Statistical profiles of highly-rated web sites	We are creating an interactive tool to help non-professional web site builders create high quality designs. We have previously reported that quantitative measures of web page structure can predict whether a site will be highly or poorly rated by experts, with accuracies ranging from 67--80\%. In this paper we extend that work in several ways. First, we compute a much larger set of measures (157 versus 11), over a much larger collection of pages (5300 vs. 1900), achieving much higher overall accuracy (94\% on average) when contrasting good, average, and poor pages. Second, we introduce new classes of measures that can make assessments at the site level and according to page type (home page, content page, etc.). Finally, we create statistical profiles of good sites, and apply them to an existing design, showing how that design can be changed to better match high-quality designs
2002	HutchWorld: clinical study of computer-mediated social support for cancer patients and their caregivers	To address the needs of cancer patients and their caregivers, Microsoft Research and the Fred Hutchinson Cancer Research Center developed HutchWorld, an online community environment, to provide computer-mediated social and informational support. In a controlled clinical study, we deployed HutchWorld to bone marrow transplant patients and their caregivers and assessed the impact of Internet access and HutchWorld on their quality of life. We found that Internet access and the use of HutchWorld helped to buffer study participants against reductions in life satisfaction and social support following the transplant procedure. In particular, participants used the Internet to seek out support from family and friends
2002	Design as a minority discipline in a software company: toward requirements for a community of practice	This paper provides a description of designers' work practices in a software company. We describe a participatory analysis of the diversity of working relations and roles of designers of IBM's Lotus software products. Designers are an example of a minority discipline - that is, a discipline whose members are often isolated in their work teams among coworkers with different training, backgrounds, and career paths. We explore differences between the practices of designers of Lotus software products and the published reports of design practices in group settings
2002	Designing for improved social responsibility, user participation and content in on-line communities	Web sites face difficult challenges in supporting successful communities. In this paper we discuss 2 operating web sites, identically designed but with different and distinct audiences. These sites collect user data from site activity and feed it back to the user community in novel ways. The sites are highly active and growing, and have fostered socially conscious, easily navigable and comprehensible on-line communities with little cost and maintenance. The practice of user data collection and re-purposing we describe works particularly well in highly contextual or information /resource-driven communities. These sites also integrate custom content authoring tools and track their use. The authoring tools were designed to quickly grow a specialized "knowledge base" of content created by users and published to a larger audience. A status system encourages the participation of users to contribute to this knowledge base, while increasing social awareness and responsibility in areas of high user interaction. All user activity, communications, and feedback are tracked. Then data is compiled and re-incorporated into scalable solutions for better navigability, content filtering, and presentation of contents to a larger audience. This practice creates a uniquely high quality of interaction within web communities
2002	Unremarkable computing	In this paper, we seek to contribute to the Ubiquitous Computing agenda by focusing on one of its earliest, but most difficult, design ambitions - making technology "invisible in use". We draw on field studies of domestic life as this domain is becoming increasingly important for new technologies and challenges many of the assumptions we take for granted in the design of technologies for the workplace. We use some examples of domestic routines to identify a number of insights into what it means for features of activities to be "unremarkable". We conclude by using these insights to critique some of the current emphases in Ubiquitous Computing research, and suggest how we might better understand the HCI issues of what will be required to develop technologies that really are "invisible in use"
2002	Comparing paper and tangible, multimodal tools	In command posts, officers maintain situational awareness using paper maps, Post-it notes, and hand-written annotations. They do so because paper is robust to failure, it is portable, it offers a flexible means of capturing information, it has ultra-high resolution, and it readily supports face-to-face collaboration. We report herein on an evaluation comparing maps and Post-its with a tangible multimodal system called Rasa. Rasa augments these paper tools with sensors, enabling it to recognize the multimodal language (both written and spoken) that naturally occurs on them. In this study, we found that not only do users prefer Rasa to paper alone, they find it as easy or easier to use than paper tools. Moreover, Rasa introduces no discernible overhead in its operation other than error repair, yet grants the benefits inherent in digital systems. Finally, subjects confirmed that by combining physical and computational tools, Rasa is resistant to computational failure
2002	Making sense of sensing systems: five questions for designers and researchers	This paper borrows ideas from social science to inform the design of novel "sensing" user-interfaces for computing technology. Specifically, we present five design challenges inspired by analysis of human-human communication that are mundanely addressed by traditional graphical user interface designs (GUIs). Although classic GUI conventions allow us to finesse these questions, recent research into innovative interaction techniques such as 'Ubiquitous Computing' and 'Tangible Interfaces' has begun to expose the interaction challenges and problems they pose. By making them explicit we open a discourse on how an approach similar to that used by social scientists in studying human-human interaction might inform the design of novel interaction mechanisms that can be used to handle human-computer communication accomplishments
2002	Polyarchy visualization: visualizing multiple intersecting hierarchies	We describe a new information structure composed of multiple intersecting hierarchies, which we call Polyarchies. Visualizing polyarchies enables use of novel views for discovery of relationships which are very difficult using existing hierarchy visualization tools. This paper will describe the visualization design and system architecture challenges as well as our current solutions. A Mid-Tier Cache architecture is used as a "polyarchy server" which supports a novel web-based polyarchy visualization technique, called Visual Pivot. A series of five user studies guided iterative design of Visual Pivot
2002	Sotto voce: exploring the interplay of conversation and mobile audio spaces	In addition to providing information to individual visitors, electronic guidebooks have the potential to facilitate social interaction between visitors and their companions. However, many systems impede visitor interaction. By contrast, our electronic guidebook, Sotto Voce , has social interaction as a primary design goal. The system enables visitors to share audio information - specifically, they can hear each other's guidebook activity using a technologically mediated audio eavesdropping mechanism. We conducted a study of visitors using Sotto Voce while touring a historic house. The results indicate that visitors are able to use the system effectively, both as a conversational resource and as an information appliance. More surprisingly, our results suggest that the technologically mediated audio often cohered the visitors' conversation and activity to a far greater degree than audio delivered through the open air
2002	Age-old practices in the 'new world': a study of gift-giving between teenage mobile phone users	In this paper, we present an overview of the data collected from an ethnographic study of teenagers and their use of mobile phones. Through the data, we suggest that teenagers use their phones to participate in social practices that closely resemble forms of ritualised gift-giving. Such practices, we claim, shape the way teenagers understand and thus use their phones. We go onto show that this insight into everyday, phone-mediated activities has practical implications for mobile phone design. Using an example, we describe how teenagers' gift-giving practices can inform design, providing an initial means to conceptualise future emerging technologies
2002	Finding others online: reputation systems for social online spaces	In this paper, we examine what types of reputation information users find valuable when selecting someone to interact with in online environments. In an online experiment, we asked users to imagine that they were looking for a partner for a social chat. We found that similarity to the user and ratings from the user's friends were the most valuable pieces of reputation information when selecting chat partners. The context in which reputations were used (social chat, game or newsgroup) affected the self-reported utility of the pieces of reputation information
2002	Groupware walkthrough: adding context to groupware usability evaluation	Discount usability evaluation methods have recently been introduced as a way to assess groupware systems. However, one criticism of these techniques is that they do not make use of information about users and their work contexts. To address this problem, we developed groupware walkthrough, a new usability inspection technique for groupware. The technique is a substantive modification of cognitive walkthrough to include consideration for the complexities of teamwork. The two components of groupware walkthrough are a task model for identifying and analysing real-world collaborative tasks, and a walkthrough process for assessing a system's support for those tasks. Groupware walkthrough is a low-cost technique that can identify collaboration-specific usability problems and can find problems that would not be revealed through other inspection methods
2002	Cognitive walkthrough for the web	This paper proposes a transformation of the Cognitive Walkthrough (CW), a theory-based usability inspection method that has proven useful in designing applications that support use by exploration. The new Cognitive Walkthrough for the Web (CWW) is superior for evaluating how well websites support users' navigation and information search tasks. The CWW uses Latent Semantic Analysis to objectively estimate the degree of semantic similarity (information scent) between representative user goal statements (100-200 words) and heading/link texts on each web page. Using an actual website, the paper shows how the CWW identifies three types of problems in web page designs. Three experiments test CWW predictions of users' success rates in accomplishing goals, verifying the value of CWW for identifying these usability problems
2002	A survey of user-centered design practice	This paper reports the results of a recent survey of user-centered design (UCD) practitioners. The survey involved over a hundred respondents who were CHI'2000 attendees or current UPA members. The paper identifies the most widely used methods and processes, the key factors that predict success, and the critical tradeoffs practitioners must make in applying UCD methods and processes. Results show that cost-benefit tradeoffs are a key consideration in the adoption of UCD methods. Measures of UCD effectiveness are lacking and rarely applied. There is also a major discrepancy between the commonly cited measures and the actually applied ones. These results have implications for the introduction, deployment, and execution of UCD projects
2002	SHS Orcas: the first integrated information system for long-term healthcare facility management	SHS.com (Shared Healthcare Systems) provides software solutions and services for the senior healthcare market. In 1998, SHS engaged Cooper to help design a next-generation healthcare information system that would for the first time provide true integration of clinical, financial, and case management information, allowing comprehensive management of long-term healthcare facilities.Cooper had an opportunity to design a product that not only improved the efficiency of healthcare facilities, but also helped improve the quality of care given to their residents. The system needed to help facility staff make sense of data as well as capture it.To address these important issues, Cooper interviewed and observed healthcare facility staff and residents during an intensive ethnographic research period. The research and analysis culminated in a set of user archetypes, called personas. The team used persona- and scenario-based methods to drive the design of an integrated suite of clinical, case management, and financial tools.
2002	Climb Meru: an integrated brand experience	Small innovative design firm tackles the challenge of creating complex cross-channel brand experiences through the application of Experience Design methodology.The key findings -The development of an experience design methodology supports a rapid and cost effective brand marketing campaign focused on defining and delivering user experiences.An integrated marketing campaign leveraging multiple marketing channels, proves extremely effective at reaching key, difficult to reach customer segments.A Web site at the core of an integrated marketing campaign fosters participatory relationships with core customer constituents while prolonging existing relationships.Testing user assumptions early and often is necessary to identify and negate detrimental usability variables.The release of various media through complementary delivery channels at specific intervals of a project lifecycle, creates a holistic brand experience for target users.
2002	Making joining easy: case of an entertainment club website	The goal of this project was to design a site that would make the online process of joining the Columbia House Music or DVD club faster and easier. Faced with low conversion rates from online advertising, our challenge was to quickly solve the main problems with the existing join process, which were identified through user testing and site data logs.In response we designed a separate mini-site that reduced the entire process to 3 steps (and as many pages). The Club-based ecommerce experience is unique: the number of products a user selects is fixed, allowing us to implement a unique and transparent interaction model for the shopping cart design.The project was extremely successful. Conversion rates increased 180\%. The design work for this project then set direction for subsequent visual and interface design projects for Columbiahouse.com.
2002	Data visualization for strategic decision making	Organizations large and small continuously strive to improve strategic decision-making. Strategic decision-making (distinguished from operational decision making) involves making substantial investments of resources over long periods of time before results are evident. These decisions are made using quantitative and qualitative information - experience, intuition, and subjective assessment. These are people decisions, not decisions made by machines.So, how can data interfaces be designed to support these most critical decisions of the organization?This case study looks at approaches taken with one R&D (research and development) client to address their key strategic decisions: whether to move research efforts into the next stage of development or cancel the project. We will discuss how we've used web-based interface technologies to create visual metaphors for data including: visualizing time, collaborating, and modeling scenarios. We'll also demonstrate approaches to embedding more abstract constructs like decision theory, statistical analysis, and competitive advantage into these interfaces.
2002	Transforming the content management process at IBM.com	This case study explores the evolution of the Franklin Content Management System, developed by IBM's Internet Technology Group. Franklin began as a technology-driven process to provide a web content management solution with the following goals: content reusability, simplified management of content and design that enforces integrity and consistency, the customization of content to individual users, and the delivery of content to a variety of display devices.These goals were met in part by the decomposition of information into reusable fragments represented in XML. This approach provides unique opportunities in a content management system. However, it also raises some interesting challenges in the deployment of such a tool and the education of its users.The development of Franklin evolved over a two year period and has culminated in the deployment of 62 country portals within the ibm.com domain. Furthermore, concepts from the Franklin project are influencing the strategy and design of IBM offerings.
2003	Understanding sequence and reply relationships within email conversations: a mixed-model visualization	It has been proposed that email clients could be improved if they presented messages grouped into conversations. An email conversation is the tree of related messages that arises from the use of the reply operation. We propose two models of conversation. The first model characterizes a conversation as a chronological sequence of messages; the second as a tree based on the reply relationship. We show how existing email clients and prior research projects implicitly support each model to a greater or lesser degree depending on their design, but none fully supports both models simultaneously. We present a mixed-model visualization that simultaneously presents sequence and reply relationships among the messages of a conversation, making both visible at a glance. We describe the integration of the visualization into a working prototype email client. A usability study indicates that the system meets our usability goals and verifies that the visualization fully conveys both types of relationships within the messages of an email conversation.
2003	Using pixel rewrites for shape-rich interaction	This paper introduces new interactive ways to create, manipulate and analyze shapes, even when those shapes do not have simple algebraic generators. This is made possible by using pixel-pattern rewrites to compute directly with bitmap representations. Such rewrites also permit the definition of functionality maps, bitmaps that specify the spatial scope of application functionality, and organic-widgets, implemented right in the pixels to have arbitrary form, integrated with the shape needs of the applications. Together these features should increase our capabilities for working with rich spatial domains.
2003	The kinedit system: affective messages using dynamic texts	Kinetic (dynamic) typography has demonstrated the ability to add significant emotive content and appeal to expressive text, allowing some of the qualities normally found in film and the spoken word to be added to static text. Kinetic typography has been widely and successfully used in film title sequences as well as television and computer-based advertising. However, its communicative abilities have not been widely studied, and its potential has rarely been exploited outside these areas. This is partly due to the difficulty in creating kinetic typography with current tools, often requiring hours of work to animate a single sentence.In this paper, we present the Kinedit system, a basic authoring tool that takes initial steps toward remedying this situation and hence promoting exploration of the communicative potential of kinetic typography for personal communication. Kinedit is informed by systematic study and characterization of a corpus of examples, and iterative involvement and validation by designers throughout the development process. We describe the tool and its underlying technology, usage experiences, lessons learned, and next steps.
2003	Reflowing digital ink annotations	Annotating paper documents with a pen is a familiar and indispensable activity across a wide variety of work and educational settings. Recent developments in pen-based computing promise to bring this experience to digital documents. However, digital documents are more flexible than their paper counterparts. When a digital document is edited, or displayed on different devices, its layout adapts to the new situation. Freeform digital ink annotations made on such a document must likewise adapt, or "reflow." But their unconstrained nature yields only vague guidelines for how these annotations should be transformed. Few systems have considered this issue, and still fewer have addressed it from a user's point of view. This paper reports the results of a study of user expectations for reflowing digital ink annotations. We explore user reaction to reflow in common cases, how sensitive users are to reflow errors, and how important it is that personal style survive reflow. Our findings can help designers and system builders support freeform annotation more effectively.
2003	Strategy hubs: next-generation domain portals with search procedures	Current search tools on the Web, such as general-purpose search engines (e.g. Google) and domain-specific portals (e.g. MEDLINEplus), do not provide search procedures that guide users to form appropriately ordered sub-goals. The lack of such procedural knowledge often leads users searching in unfamiliar domains to retrieve incomplete information. In critical domains such as in healthcare, such ineffective searches can have dangerous consequences. To address this situation, we developed a new type of domain portal called a Strategy Hub. Strategy Hubs provide the critical search procedures and associated high-quality links that enable users to find comprehensive and accurate information. This paper describes how we collaborated with skin cancer physicians to systematically identify generalizeable search procedures to find comprehensive information about melanoma, and how these search procedures were made available through the Strategy Hub for healthcare. A pilot study suggests that this approach can improve the efficacy, efficiency, and satisfaction of even expert searchers. We conclude with insights on how to refine the design of the Strategy Hub, and how it can be used to provide search procedures across domains.
2003	Faceted metadata for image search and browsing	There are currently two dominant interface types for searching and browsing large image collections: keyword-based search, and searching by overall similarity to sample images. We present an alternative based on enabling users to navigate along conceptual dimensions that describe the images. The interface makes use of hierarchical faceted metadata and dynamically generated query previews. A usability study, in which 32 art history students explored a collection of 35,000 fine arts images, compares this approach to a standard image search interface. Despite the unfamiliarity and power of the interface (attributes that often lead to rejection of new search interfaces), the study results show that 90\% of the participants preferred the metadata approach overall, 97\% said that it helped them learn more about the collection, 75\% found it more flexible, and 72\% found it easier to use than a standard baseline system. These results indicate that a category-based approach is a successful way to provide access to image collections.
2003	How do people manage their digital photographs?	In this paper we present and discuss the findings of a study that investigated how people manage their collections of digital photographs. The six-month, 13-participant study included interviews, questionnaires, and analysis of usage statistics gathered from an instrumented digital photograph management tool called Shoebox. Alongside simple browsing features such as folders, thumbnails and timelines, Shoebox has some advanced multimedia features: content-based image retrieval and speech recognition applied to voice annotations. Our results suggest that participants found their digital photos much easier to manage than their non-digital ones, but that this advantage was almost entirely due to the simple browsing features. The advanced features were not used very often and their perceived utility was low. These results should help to inform the design of improved tools for managing personal digital photographs.
2003	Things happening in the brain while humans learn to use new tools	In this paper, we propose a new technique based on recent neuroimaging studies as a tool for the assessment of interactive systems. For this purpose, we analyze the mental process that takes place while human subjects learn to use new tools by using two different approaches. One is an experiment on task performance based on the conventional direct testing method of a user interface, and the other is an indirect method based on recent neuroimaging studies that indirectly estimate the process of interaction through the observation of the human brain activities. The results obtained from the direct experiment on performance evaluation are compared with those from the indirect analysis of the human brain activity, which is measured by a non-invasive neuroimaging measuring method. The process of acquisition of internal models while subjects learn to use new tools is also discussed.
2003	The mad hatter's cocktail party: a social mobile audio space supporting multiple simultaneous conversations	This paper presents a mobile audio space intended for use by gelled social groups. In face-to-face interactions in such social groups, conversational floors change frequently, e.g., two participants split off to form a new conversational floor, a participant moves from one conversational floor to another, etc. To date, audio spaces have provided little support for such dynamic regroupings of participants, either requiring that the participants explicitly specify with whom they wish to talk or simply presenting all participants as though they are in a single floor. By contrast, the audio space described here monitors participant behavior to identify conversational floors as they emerge. The system dynamically modifies the audio delivered to each participant to enhance the salience of the participants with whom they are currently conversing. We report a user study of the system, focusing on conversation analytic results.
2003	Mobile phones for the next generation: device designs for teenagers	In this paper, we demonstrate how ethnographic fieldwork studies can be used to inform the design of third generation mobile phones. We draw on a field study of teenage mobile phone users and, specifically, their participation in gift-giving practices to design the user interface and form of a concept mobile phone. The concept device is designed to support teenagers' social practices through a novel multimedia messaging system and the augmentation of the phone's address book. We report on the process adopted to design the concept and briefly describe preliminary reactions from potential users. To conclude the paper, we comment on the lessons we have learnt in applying ethnographic findings to design.
2003	Wan2tlk?: everyday text messaging	Texting--using a mobile phone to send text messages--has become a form of mass communication. Building on studies that described how British teenagers have incorporated text messaging into their lives, we examine the purposes and nature of the conversations themselves. We also present findings that suggest that teenagers do not have many simultaneous multiple conversations via text messaging; end most text messaging conversations by switching to another medium; and, that, despite popular beliefs, communicate with surprisingly few friends via their mobile phones. Finally we describe how and what words they shorten in their text messages.
2003	A design tool for camera-based interaction	Cameras provide an appealing new input medium for interaction. The creation of camera-based interfaces is outside the skill-set of most programmers and completely beyond the skills of most interface designers. Image Processing with Crayons is a tool for creating new camera-based interfaces using a simple painting metaphor. A transparent layers model is used to present the designer with all of the necessary information. Traditional machine learning algorithms have been modified to accommodate the rapid response time required of an interactive design tool.
2003	Videography for telepresentations	Our goal is to help automate the capture and broadcast of lectures to remote audiences. There are two inter-related components to the design of such systems. The technology component includes the hardware (e.g., video cameras) and associated software (e.g., speaker-tracking). The aesthetic component embodies the rules and idioms that human videographers follow to make a video visually engaging. We present a lecture room automation system and a substantial number of new video-production rules obtained from professional videographers who critiqued it. We also describe rules for a variety of lecture room environments differing in the numbers and types of cameras. We further discuss gaps between what professional videographers do and what is technologically feasible today.
2003	A low-latency lip-synchronized videoconferencing system	Audio is presented ahead of video in some videoconferencing systems since audio requires less time to process. Audio could be delayed to synchronize with video to achieve lip synchronization; however, the overall audio latency might then become unacceptable. We built a videoconferencing system to achieve lip synchronization with minimal perceived audio latency. Instead of adding a fixed audio delay, our system time-stretches the audio at the beginning of each utterance until the audio is synchronized with the video. We conducted user studies and found that (1) audio could lead video by roughly 50 msec and still be perceived as synchronized; (2) audio could lead video by 300 msec and still be perceived as synchronized if the audio was time-stretched to synchronization within a short period; and (3) our algorithm appears to strike a favorable balance between minimizing audio latency and supporting lip synchronization.
2003	Multimodal 'eyes-free' interaction techniques for wearable devices	Mobile and wearable computers present input/output prob-lems due to limited screen space and interaction techniques. When mobile, users typically focus their visual attention on navigating their environment - making visually demanding interface designs hard to operate. This paper presents two multimodal interaction techniques designed to overcome these problems and allow truly mobile, 'eyes-free' device use. The first is a 3D audio radial pie menu that uses head gestures for selecting items. An evaluation of a range of different audio designs showed that egocentric sounds re-duced task completion time, perceived annoyance, and al-lowed users to walk closer to their preferred walking speed. The second is a sonically enhanced 2D gesture recognition system for use on a belt-mounted PDA. An evaluation of the system with and without audio feedback showed users' ges-tures were more accurate when dynamically guided by au-dio-feedback. These novel interaction techniques demon-strate effective alternatives to visual-centric interface de-signs on mobile devices.
2003	Halo: a technique for visualizing off-screen objects	As users pan and zoom, display content can disappear into off-screen space, particularly on small-screen devices. The clipping of locations, such as relevant places on a map, can make spatial cognition tasks harder. Halo is a visualization technique that supports spatial cognition by showing users the location of off-screen objects. Halo accomplishes this by surrounding off-screen objects with rings that are just large enough to reach into the border region of the display window. From the portion of the ring that is visible on-screen, users can infer the off-screen location of the object at the center of the ring. We report the results of a user study comparing Halo with an arrow-based visualization technique with respect to four types of map-based route planning tasks. When using the Halo interface, users completed tasks 16-33\% faster, while there were no significant differences in error rate for three out of four tasks in our study.
2003	The bull's-eye: a framework for web application user interface design guidelines	A multi-leveled framework for user interface design guidelines of Web applications is presented. User interface design guidelines tend to provide information that is either too general, so that it is difficult to apply to a specific case, or too specific, so that a wide range of products is not supported. The framework presented is unique in that it provides a bridge between the two extremes. It has been dubbed the 'Bull's-Eye' due to its five layers, represented as concentric circles. The center of the Bull's-Eye is the Component layer, followed by Page Templates, Page Flows, Interface Models and Patterns, and Overarching Features and Principles. To support this approach, requirements were gathered from user interface designers, product managers, UI developers, and product developers. Also, usability testing of the guidelines occurred on several levels, from broad guideline tests to more specific product tests. The guidelines and lessons learned are intended to serve as examples for others seeking to design families of Web applications or Web sites.
2003	Repairing usability problems identified by the cognitive walkthrough for the web	Methods for identifying usability problems in web page designs should ideally also provide practical methods for repairing the problems found. Blackmon et al. [2] proved the usefulness of the Cognitive Walkthrough for the Web (CWW) for identifying three types of problems that interfere with users' navigation and information search tasks. Extending that work, this paper reports a series of two experiments that develop and prove the effectiveness of both full-scale and quick-fix CWW repair methods. CWW repairs, like CWW problem identification, use Latent Semantic Analysis (LSA) to objectively estimate the degree of semantic similarity (information scent) between representative user goal statements (100-200 words) and heading/link texts on each web page. In addition to proving the effectiveness of CWW repairs, the experiments reported here replicate CWW predictions that users will face serious difficulties if web developers fail to repair the usability problems that CWW identifies in web page designs [2].
2003	The bloodhound project: automating discovery of web usability issues using the InfoScent? simulator	According to usability experts, the top user issue for Web sites is difficult navigation. We have been developing auto-mated usability tools for several years, and here we describe a prototype service called InfoScent™ Bloodhound Simula-tor, a push-button navigation analysis system, which auto-matically analyzes the information cues on a Web site to produce a usability report. We further build upon previous algorithms to create a method called Information Scent Absorption Rate, which measures the navigability of a site by computing the probability of users reaching the desired destinations on the site. Lastly, we present a user study involving 244 subjects over 1385 user sessions that show how Bloodhound correlates with real users surfing for in-formation on four Web sites. The hope is that, by using a simulation of user surfing behavior, we can reduce the need for human labor during usability testing, thus dramatically lower testing costs, and ultimately improving user experience. The Bloodhound Project is unique in that we apply a concrete HCI theory directly to a real-world prob-lem. The lack of empirically validated HCI theoretical model has plagued the development of our field, and this is a step toward that direction.
2003	Effects of head-mounted and scene-oriented video systems on remote collaboration on physical tasks	This study assessed the value of two video configurations-a head-mounted camera with eye tracking capability and a scene camera providing a view of the work environment-on remote collaboration on physical (3D) tasks. Pairs of participants performed five robot construction tasks in five media conditions: side-by-side, audio-only, head-mounted camera, scene camera, and scene plus head cameras. Task completion times were shortest in the side-by-side condition, and shorter with the scene camera than in the audio-only condition. Participants rated their work quality highest when side-by-side, intermediate with the scene camera, and worst in the audio-only and head-camera conditions. Similarly, helpers' self-rated ability to assist workers and pairs' communication efficiency were highest in the side-by-side condition, but significantly higher with the scene camera than in the audio-only condition. The results demonstrate the value of a shared view of the work environment for remote collaboration on physical tasks.
2003	GAZE-2: conveying eye contact in group video conferencing using eye-controlled camera direction	GAZE-2 is a novel group video conferencing system that uses eye-controlled camera direction to ensure parallax-free transmission of eye contact. To convey eye contact, GAZE-2 employs a video tunnel that allows placement of cameras behind participant images on the screen. To avoid parallax, GAZE-2 automatically directs the cameras in this video tunnel using an eye tracker, selecting a single camera closest to where the user is looking for broadcast. Images of users are displayed in a virtual meeting room, and rotated towards the participant each user looks at. This way, eye contact can be conveyed to any number of users with only a single video stream per user. We empirically evaluated whether eye contact perception is affected by automated camera direction, which causes angular shifts in the transmitted images. Findings suggest camera shifts do not affect eye contact perception, and are not considered highly distractive.
2003	The impact of avatar realism and eye gaze control on perceived quality of communication in a shared immersive virtual environment	This paper presents an experiment designed to investigate the impact of scommunication in an immersive virtual environment.Participants were paired by gender and were randomly assigned to a CAVE-like system or a head-mounted display. Both were represented by a humanoid avatar in the shared 3D environment. The visual appearance of the avatars was either basic and genderless (like a "match-stick" figure), or more photorealistic and gender-specific. Similarly, eye gaze behavior was either random or inferred from voice, to reflect different levels of behavioral realism.Our comparative analysis of 48 post-experiment questionnaires confirms earlier findings from non-immersive studies using semi-photorealistic avatars, where inferred gaze significantly outperformed random gaze. However responses to the lower-realism avatar are adversely affected by inferred gaze, revealing a significant interaction effect between appearance and behavior. We discuss the importance of aligning visual and behavioral realism for increased avatar effectiveness.
2003	iStuff: a physical user interface toolkit for ubiquitous computing environments	The iStuff toolkit of physical devices, and the flexible software infrastructure to support it, were designed to simplify the exploration of novel interaction techniques in the post-desktop era of multiple users, devices, systems and applications collaborating in an interactive environment. The toolkit leverages an existing interactive workspace in-frastructure, making it lightweight and platform independent. The supporting software framework includes a dynamically configurable intermediary to simplify the mapping of devices to applications. We describe the iStuff architecture and provide several examples of iStuff, organized into a design space of ubiquitous computing interaction components. The main contribution is a physical toolkit for distributed, heterogeneous environments with run-time retargetable device data flow. We conclude with some insights and experiences derived from using this toolkit and framework to prototype experimental interaction techniques for ubiquitous computing environments.
2003	XWand: UI for intelligent spaces	The XWand is a novel wireless sensor package that enables styles of natural interaction with intelligent environments. For example, a user may point the wand at a device and control it using simple gestures. The XWand system leverages the intelligence of the environment to best determine the user's intention. We detail the hardware device, signal processing algorithms to recover position and orientation, gesture recognition techniques, a multimodal (wand and speech) computational architecture and a preliminary user study examining pointing performance under conditions of tracking availability and audio feedback.
2003	Two worlds apart: bridging the gap between physical and virtual media for distributed design collaboration	A tension exists between designers' comfort with physical artifacts and the need for effective remote collaboration: physical objects live in one place. Previous research and technologies to support remote collaboration have focused on shared electronic media. Current technologies force distributed teams to choose between the physical tools they prefer and the electronic communication mechanisms available. We present Distributed Designers' Outpost, a remote collaboration system based on The Designers' Outpost, a collaborative web site design tool that employs physical Post-it notes as interaction primitives. We extended the system for synchronous remote collaboration and introduced two awareness mechanisms: transient ink input for gestures and a blue shadow of the remote collaborator for presence. We informally evaluated this system with six professional designers. Designers were excited by the prospect of physical remote collaboration but found some coordination challenges in the interaction with shared artifacts.
2003	Exertion interfaces: sports over a distance for social bonding and fun	An Exertion Interface is an interface that deliberately requires intense physical effort. Exertion Interfaces have applications in "Sports over a Distance", potentially capitalizing on the power of traditional physical sports in supporting social bonding. We designed, developed, and evaluated an Exertion Interface that allows people who are miles apart to play a physically exhausting ball game together. Players interact through a life-size video-conference screen using a regular soccer ball as an input device. The Exertion Interface users said that they got to know the other player better, had more fun, became better friends, and were happier with the transmitted audio and video quality, in comparison to those who played the same game using a non-exertion keyboard interface. These results suggest that an Exertion Interface, as compared to a traditional interface, offers increased opportunities for connecting people socially, especially when they have never met before.
2003	Where on-line meets on the streets: experiences with mobile mixed reality games	We describe two games in which online participants collaborated with mobile participants on the city streets. In the first, the players were online and professional performers were on the streets. The second reversed this relationship. Analysis of these experiences yields new insights into the nature of context. We show how context is more socially than technically constructed. We show how players exploited (and resolved conflicts between) multiple indications of context including GPS, GPS error, audio talk, ambient audio, timing, local knowledge and trust. We recommend not overly relying on GPS, extensively using audio, and extending interfaces to represent GPS error.
2003	Lessons from the lighthouse: collaboration in a shared mixed reality system	Museums attract increasing numbers of online visitors along with their conventional physical visitors. This paper presents a study of a mixed reality system that allows web, virtual reality and physical visitors to share a museum visit together in real time. Our system allows visitors to share their location and orientation, communicate over a voice channel, and jointly navigate around a shared information space. Results from a study of 34 users of the system show that visiting with the system was highly interactive and retained many of the attractions of a traditional shared exhibition visit. Specifically, users could navigate together, collaborate around objects and discuss exhibits. These findings have implications for non-museum settings, in particular how location awareness is a powerful resource for collaboration, and how 'hybrid objects' can support collaboration at-a-distance.
2003	Is seeing believing?: how recommender system interfaces affect users' opinions	Recommender systems use people's opinions about items in an information domain to help people choose other items. These systems have succeeded in domains as diverse as movies, news articles, Web pages, and wines. The psychological literature on conformity suggests that in the course of helping people make choices, these systems probably affect users' opinions of the items. If opinions are influenced by recommendations, they might be less valuable for making recommendations for other users. Further, manipulators who seek to make the system generate artificially high or low recommendations might benefit if their efforts influence users to change the opinions they contribute to the recommender. We study two aspects of recommender system interfaces that may affect users' opinions: the rating scale and the display of predictions at the time users rate items. We find that users rate fairly consistently across rating scales. Users can be manipulated, though, tending to rate toward the prediction the system shows, whether the prediction is accurate or not. However, users can detect systems that manipulate predictions. We discuss how designers of recommender systems might react to these findings.
2003	Recommending collaboration with social networks: a comparative evaluation	Studies of information seeking and workplace collaboration often find that social relationships are a strong factor in determining who collaborates with whom. Social networks provide one means of visualizing existing and potential interaction in organizational settings. Groupware designers are using social networks to make systems more sensitive to social situations and guide users toward effective collaborations. Yet, the implications of embedding social networks in systems have not been systematically studied. This paper details an evaluation of two different social networks used in a system to recommend individuals for possible collaboration. The system matches people looking for expertise with individuals likely to have expertise. The effectiveness of social networks for matching individuals is evaluated and compared. One finding is that social networks embedded into systems do not match individuals' perceptions of their personal social network. This finding and others raise issues for the use of social networks in groupware. Based on the evaluation results, several design considerations are discussed.
2003	Peephole displays: pen interaction on spatially aware handheld computers	The small size of handheld computers provides theconvenience of mobility at the expense of reduced screen space for display and interaction. Prior research has identified the value of spatially aware displays, in which a position-tracked display provides a window on a larger virtual workspace. This paper builds on that work by suggesting two-handed interaction techniques combining pen input with spatially aware displays. Enabling simultaneous navigation and manipulation yields the ability to create and edit objects larger than the screen and to drag and drop in 3-D. Four prototypes of the Peephole Display hardware were built, and several Peephole-augmented applications were written, including a drawing program, map viewer, and calendar. Multiple applications can be embedded into a personal information space anchored to the user's physical reference frame. A usability study with 24 participants shows that the Peephole technique can be more effective than current methods for navigating information on handheld computers.
2003	The evolution of buildings and implications for the design of ubiquitous domestic environments	This paper considers how we may realize future ubiquitous domestic environments. Building upon previous work on how buildings evolve by Stewart Brand, we suggest the need to broaden existing considerations of interactive design for domestic environments. We identify a number of classes of research activity and the issues associated with these. We then consider the ways in which current buildings undergo continual change. In doing so we outline the stakeholders involved, the representations used and the way change is managed. We contrast our understanding of how buildings change with research activities before identifying new challenges that will need to be addressed by those involved in designing ubiquitous technologies for domestic environments.
2003	Technology probes: inspiring design for and with families	We describe a new method for use in the process of co-designing technologies with users called technology probes. Technology probes are simple, flexible, adaptable technologies with three interdisciplinary goals: the social science goal of understanding the needs and desires of users in a real-world setting, the engineering goal of field-testing the technology, and the design goal of inspiring users and researchers to think about new technologies. We present the results of designing and deploying two technology probes, the messageProbe and the videoProbe, with diverse families in France, Sweden, and the U.S. We conclude with our plans for creating new technologies for and with families based on our experiences.
2003	Design and user evaluation of a joystick-operated full-screen magnifier	The paper reports on two development cycles of a joystick-operated full-screen magnifier for visually impaired users. In the first cycle of evaluation, seven visually impaired computer users evaluated the system in comprehension-based sessions using text documents. After considering feedback from these evaluators, a second version of the system was produced and evaluated by a further six visually impaired users. The second evaluation was conducted using information-seeking tasks using Web pages. In both evaluations, the 'thinking aloud protocol' was used. This study makes several contributions to the field. First, it is perhaps the first published study investigating the use of a joystick as an absolute and relative pointing device to control a screen magnifier. Second, the present study revealed that for most of the visually impaired users who participated in the study the joystick had good spatial, cognitive and ergonomic attributes, even for those who had never before used a joystick.
2003	Older adults and visual impairment: what do exposure times and accuracy tell us about performance gains associated with multimodal feedback?	This study examines the effects of multimodal feedback on the performance of older adults with different visual abilities. Older adults possessing normal vision (n=29) and those who have been diagnosed with Age-Related Macular Degeneration (n=30) performed a series of drag-and-drop tasks under varying forms of feedback. User performance was assessed with measures of feedback exposure times and accuracy. Results indicated that for some cases, non-visual (e.g. auditory or haptic) and multimodal (bi- and trimodal) feedback forms demonstrated significant performance gains over the visual feedback form, for both AMD and normally sighted users. In addition to visual acuity, effects of manual dexterity and computer experience are considered.
2003	Multiple haptic targets for motion-impaired computer users	Although a number of studies have reported that force feedback gravity wells can improve performance in "point-and-click" tasks, there have been few studies addressing issues surrounding the use of gravity wells for multiple on-screen targets. This paper investigates the performance of users, both with and without motion-impairments, in a "point-and-click" task when an undesired haptic distractor is present. The importance of distractor location is studied explicitly. Results showed that gravity wells can still improve times and error rates, even on occasions when the cursor is pulled into a distractor. The greatest improvement is seen for the most impaired users. In addition to traditional measures such as time and errors, performance is studied in terms of measures of cursor movement along a path. Two cursor measures, angular distribution and temporal components, are proposed and their ability to explain performance differences is explored.
2003	Semi-public displays for small, co-located groups	The majority of systems using public displays to foster awareness have focused on providing information across remote locations or among people who are loosely connected and lack awareness of each other's activities or interests. We have, however, identified many potential benefits for an awareness system that displays information within a small, co-located group in which the members already possess some awareness of each other's activities. By using "Semi-Public Displays," public displays scoped for small groups, we can make certain types of information visible in the environment, promoting collaboration and providing lightweight information about group activity. Compared to designing for large, loosely connected groups, designing for Semi-Public Displays mitigates typically problematic issues in sustaining relevant content for the display and minimizing privacy concerns. We are using these applications to support and enhance the interactions and information that group members utilize to maintain awareness and collaborate.
2003	Designing novel interactional workspaces to support face to face consultations	This paper describes the design and deployment of a novel interactional workspace, intended to provide more effective support for face-to-face consultations between two parties. We focus on the initial consultations between customer and agent that take place during the development of complex products. Findings from an ethnographic study of the existing use of technological systems show the interaction during such consultations to be disjointed and not well supported. As an alternative approach, we developed a novel arrangement of multiple displays intended to promote shoulder-to-shoulder collaboration using a variety of interlinked representations and visualizations. The resulting interactional workspace was used by a travel company as part of a large international trade show attended by the general public. The many consultations that took place between agents and customers were quite different, proving to be more equitable, open, fluid and congenial.
2003	Social coordination around a situated display appliance	Advances in display technology are creating more opportunities for situating displays in our environment. While these displays share some common design principles with display-based interaction at the desktop PC, situated displays also have unique characteristics and values that raise particular design considerations and challenges. In order to further understand situated display design we present a field study of RoomWizard, an interactive room reservation display appliance designed to be mounted outside meeting rooms. The findings illustrate important ways that individual and social behaviours were oriented around the persistent situated displays. These observed behaviours are discussed in relation to particular design characteristics of RoomWizard. We conclude by highlighting more general themes supporting the design of other situated display technologies.
2003	Comparative effectiveness of augmented reality in object assembly	Although there has been much speculation about the potential of Augmented Reality (AR), there are very few empirical studies about its effectiveness. This paper describes an experiment that tested the relative effectiveness of AR instructions in an assembly task. Task information was displayed in user's field of view and registered with the workspace as 3D objects to explicitly demonstrate the exact execution of a procedure step. Three instructional media were compared with the AR system: a printed manual, computer assisted instruction (CAI) using a monitor-based display, and CAI utilizing a head-mounted display. Results indicate that overlaying 3D instructions on the actual work pieces reduced the error rate for an assembly task by 82\%, particularly diminishing cumulative errors - errors due to previous assembly mistakes. Measurement of mental effort indicated decreased mental effort in the AR condition, suggesting some of the mental calculation of the assembly task is offloaded to the system.
2003	Information use of service technicians in difficult cases	Service technicians in the field often come across difficult service problems that are new to them. They have a large number of resources that they can draw on to deal with such problems, including both people and documents. We have undertaken a detailed study of technicians' everyday work, and have discovered two distinct types of information use, reflecting two different problem-solving practices. The less frequently used problem-solving practice is instruction following, where technicians follow company-documented Repair Analysis Procedures (RAPs). The second, more common practice is gleaning, where the information is gathered from many sources -- including other technicians and informal tips, which are documents written by technicians describing their invented solutions to hard service problems. Our observations show how the informational and interface affordances of the system for accessing the tips support their easy incorporation into the gleaning approach for problem solving in difficult cases. We also recommend ways that RAPs can be augmented to provide affordances for gleaning, and more effective instruction following.
2003	Books with voices: paper transcripts as a physical interface to oral histories	Our contextual inquiry into the practices of oral historians unearthed a curious incongruity. While oral historians consider interview recordings a central historical artifact, these recordings sit unused after a written transcript is produced. We hypothesized that this is largely because books are more usable than recordings. Therefore, we created Books with Voices: bar-code augmented paper transcripts enabling fast, random access to digital video interviews on a PDA. We present quantitative results of an evaluation of this tangible interface with 13 participants. They found this lightweight, structured access to original recordings to offer substantial benefits with minimal overhead. Oral historians found a level of emotion in the video not available in the printed transcript. The video also helped readers clarify the text and observe nonverbal cues.
2003	Shorthand writing on stylus keyboard	We propose a method for computer-based speed writing, SHARK (shorthand aided rapid keyboarding), which augments stylus keyboarding with shorthand gesturing. SHARK defines a shorthand symbol for each word according to its movement pattern on an optimized stylus keyboard. The key principles for the SHARK design include high efficiency stemmed from layout optimization, duality of gesturing and stylus tapping, scale and location independent writing, Zipf's law, and skill transfer from tapping to shorthand writing due to pattern consistency. We developed a SHARK system based on a classic handwriting recognition algorithm. A user study demonstrated the feasibility of the SHARK method.
2003	High precision touch screen interaction	Bare hand pointing on touch screens both benefits and suffers from the nature of direct input. This work explores techniques to overcome its limitations. Our goal is to design interaction tools allowing pixel level pointing in a fast and efficient manner. Based on several cycles of iterative design and testing, we propose two techniques: Cross-Keys that uses discrete taps on virtual keys integrated with a crosshair cursor, and an analog Precision-Handle that uses a leverage (gain) effect to amplify movement precision from the user's finger tip to the end cursor. We conducted a formal experiment with these two techniques, in addition to the previously known Zoom-Pointing and Take-Off as baseline anchors. Both subjective and performance measurements indicate that Precision-Handle and Cross-Keys complement existing techniques for touch screen interaction.
2003	Metrics for text entry research: an evaluation of MSD and KSPC, and a new unified error metric	We describe and identify shortcomings in two statistics recently introduced to measure accuracy in text entry evaluations: the minimum string distance (MSD) error rate and keystrokes per character (KSPC). To overcome the weaknesses, a new framework for error analysis is developed and demonstrated. It combines the analysis of the presented text, input stream (keystrokes), and transcribed text. New statistics include a unified total error rate, combining two constituent error rates: the corrected error rate (errors committed but corrected) and the not corrected error rate (errors left in the transcribed text). The framework includes other measures including error correction efficiency, participant conscientiousness, utilised bandwidth, and wasted bandwidth. A text entry study demonstrating the new methodology is described.
2003	Shiny happy people building trust?: photos on e-commerce websites and consumer trust	Designing for trust in technology-mediated interaction is an increasing concern in CHI. In advertising, images of people have long been used to create positive attitudes to products or trust in brands. However, the evidence as to whether placing photographs of people on e-commerce web sites has the intended effect has been mixed. This paper reports a study that examined the effect of adding such photographs to 12 existing e-commerce sites, whose reputation had been established through customer ratings. In an experiment with 115 participants, trust was measured using methods that induced financial risk, adapted from experimental economics. Averaging across sites, neither the presence of a photo, nor trustworthiness of the person depicted, had a significant effect. However, the presence of photos reduced participants' ability to identify vendors with good and bad reputations -- the perceived trustworthiness of poorly performing vendors was increased, whereas that of vendors with good reputation was decreased. This result advocates caution when using photos on e-commerce sites to boost trustworthiness, and demonstrates the need for further research into interpersonal cues and on-line trust.
2003	Unpacking privacy for a networked world	Although privacy is broadly recognized as a dominant concern for the development of novel interactive technologies, our ability to reason analytically about privacy in real settings is limited. A lack of conceptual interpretive frameworks makes it difficult to unpack interrelated privacy issues in settings where information technology is also present. Building on theory developed by social psychologist Irwin Altman, we outline a model of privacy as a dynamic, dialectic process. We discuss three tensions that govern interpersonal privacy management in everyday life, and use these to explore select technology case studies drawn from the research literature. These suggest new ways for thinking about privacy in socio-technical environments as a practical matter.
2003	Usability and privacy: a study of Kazaa P2P file-sharing	P2P file sharing systems such as Gnutella, Freenet, and KaZaA, while primarily intended for sharing multimedia files, frequently allow other types of information to be shared. This raises serious concerns about the extent to which users may unknowingly be sharing private or personal information.In this paper, we report on a cognitive walkthrough and a laboratory user study of the KaZaA file sharing user interface. The majority of the users in our study were unable to tell what files they were sharing, and sometimes incorrectly assumed they were not sharing any files when in fact they were sharing all files on their hard drive. An analysis of the KaZaA network suggested that a large number of users appeared to be unwittingly sharing personal and private files, and that some users were indeed taking advantage of this and downloading files containing ostensibly private information.
2003	Electronic voting system usability issues	With recent troubles in U.S. elections, there has been a nationwide push to update voting systems. Municipalities are investing heavily in electronic voting systems, many of which use a touch screen. These systems offer the promise of faster and more accurate voting, but the current reality is that they are fraught with usability and systemic problems. This paper surveys issues relating to usability of electronic voting systems and reports on a series of studies, including one with 415 voters using new systems that the State of Maryland purchased. Our analysis shows these systems work well, but have several problems, and many voters have concerns about them.
2003	Usability and biometric verification at the ATM interface	This paper describes some of the consumer-driven usability research conducted by NCR Self Service Strategic Solutions in the development of an understanding of usability and user acceptance of leading-edge biometrics verification techniques. We discuss biometric techniques in general and focus upon the usability phases and issues, associated with iris verification technology at the Automated Teller Machine (ATM) user interface. The paper concludes with a review of some of the major research issues encountered, and an outline of future work in the area.
2003	Can you see what i hear?: the design and evaluation of a peripheral sound display for the deaf	We developed two visual displays for providing awareness of environmental audio to deaf individuals. Based on fieldwork with deaf and hearing participants, we focused on supporting awareness of non-speech audio sounds such as ringing phones and knocking in a work environment. Unlike past work, our designs support both monitoring and notification of sounds, support discovery of new sounds, and do not require a priori knowledge of sounds to be detected. Our Spectrograph design shows pitch and amplitude, while our Positional Ripples design shows amplitude and location of sounds. A controlled experiment involving deaf participants found neither display to be significantly distracting. However, users preferred the Positional Ripples display and found that display easier to monitor (notification sounds were detected with 90\% success in a laboratory setting). The Spectrograph display also supported successful detection in most cases, and was well received when deployed in the field.
2003	Heuristic evaluation of ambient displays	We present a technique for evaluating the usability and effectiveness of ambient displays. Ambient displays are abstract and aesthetic peripheral displays portraying non-critical information on the periphery of a user's attention. Although many innovative displays have been published, little existing work has focused on their evaluation, in part because evaluation of ambient displays is difficult and costly. We adapted a low-cost evaluation technique, heuristic evaluation, for use with ambient displays. With the help of ambient display designers, we defined a modified set of heuristics. We compared the performance of Nielsen's heuristics and our heuristics on two ambient displays. Evaluators using our heuristics found more, severe problems than evaluators using Nielsen's heuristics. Additionally, when using our heuristics, 3-5 evaluators were able to identify 40--60\% of known usability issues. This implies that heuristic evaluation is an effective technique for identifying usability issues with ambient displays.
2003	Human on-line response to target expansion	McGuffin and Balakrishnan (M&B) have recently reported evidence that target expansion during a reaching movement reduces pointing time even if the expansion occurs as late as in the last 10\% of the distance to be covered by the cursor. While M&B massed their static and expanding targets in separate blocks of trials, thus making expansion predictable for participants, we replicated their experiment with one new condition in which the target could unpredictably expand, shrink, or stay unchanged. Our results show that target expansion occurring as late as in M&B's experiment enhances pointing performance in the absence of expectation. We discuss these findings in terms of the basic human processes that underlie target-acquisition movements, and we address the implications for user interface design by introducing a revised design for the Mac OS X Dock.
2003	An interface for creating and manipulating curves using a high degree-of-freedom curve input device	Current interfaces for manipulating curves typically use a standard point cursor to indirectly adjust curve parameters. We present an interface for far more direct manipulation of curves using a specialized high degree-of-freedom curve input device, called ShapeTape. This device allows us to directly control the shape and position of a virtual curve widget. We describe the design and implementation of a variety of interaction techniques that use this curve widget to create and manipulate other virtual curves in 2D and 3D space. The input device is also used to sense a set of user gestures for invoking commands and tools. The result is an effective alternate user interface for curve manipulation that can be used in 2D and 3D graphics applications.
2003	Refining Fitts' law models for bivariate pointing	We investigate bivariate pointing in light of the recent progress in the modeling of univariate pointing. Unlike previous studies, we focus on the effect of target shape (width and height ratio) on pointing performance, particularly when such a ratio is between 1 and 2. Results showed unequal impact of amplitude and directional constraints, with the former dominating the latter. Investigating models based on the notion of weighted Lp norm, we found that our empirical findings were best captured by an Euclidean model with one free weight. This model significantly outperforms the best model to date.
2003	Fisheyes are good for large steering tasks	Fisheye views use distortion to provide both local detail and global context in a single continuous view. However, the distorted presentation can make it more difficult to interact with the data; it is therefore not clear whether fisheye views are good choices for interactive tasks. To investigate this question, we tested the effects of magnification and representation on user performance in a basic pointing activity called steering - where a user moves a pointer along a predefined path in the workspace. We looked specifically at magnified steering, where the entire path does not fit into one view. We tested three types of fisheye at several levels of distortion, and also compared the fisheyes with two non-distorting techniques. We found that increasing distortion did not reduce steering performance, and that the fisheyes were faster than the non-distorting techniques. Our results show that in situations where magnification is required, distortion-oriented views can be effective representations for interactive tasks.
2003	Women go with the (optical) flow	Previous research reported interesting gender effects involving specific benefits for females navigating with wider fields of view on large displays. However, it was not clear what was driving the 3D navigation performance gains, and whether or not the effect was more tightly coupled to gender or to spatial abilities. The study we report in this paper replicates and extends previous work, demonstrating that the gender-specific navigation benefits come from the presence of optical flow cues, which are better afforded by wider fields of view on large displays. The study also indicates that the effect may indeed be tied to gender, as opposed to spatial abilities. Together, the findings provide a significant contribution to the HCI community, as we provide strong recommendations for the design and presentation of 3D environments, backed by empirical data. Additionally, these recommendations reliably benefit females, without an accompanying detriment to male navigation performance.
2003	With similar visual angles, larger displays improve spatial performance	Large wall-sized displays are becoming prevalent. Although researchers have articulated qualitative benefits of group work on large displays, little work has been done to quantify the benefits for individual users. We ran two studies comparing the performance of users working on a large projected wall display to that of users working on a standard desktop monitor. In these studies, we held the visual angle constant by adjusting the viewing distance to each of the displays. Results from the first study indicate that although there was no significant difference in performance on a reading comprehension task, users performed about 26\% better on a spatial orientation task done on the large display. Results from the second study suggest that the large display affords a greater sense of presence, allowing users to treat the spatial task as an egocentric rather than an exocentric rotation. We discuss future work to extend our findings and formulate design principles for computer interfaces and physical workspaces.
2003	Design-oriented human-computer interaction	We argue that HCI has emerged as a design-oriented field of research, directed at large towards innovation, design, and construction of new kinds of information and interaction technology. But the understanding of such an attitude to research in terms of philosophical, theoretical, and methodological underpinnings seems however relatively poor within the field. This paper intends to specifically address what design 'is' and how it is related to HCI. First, three candidate accounts from design theory of what design 'is' are introduced; the conservative, the romantic, and the pragmatic. By examining the role of sketching in design, it is found that the designer becomes involved in a necessary dialogue, from which the design problem and its solution are worked out simultaneously as a closely coupled pair. In conclusion, it is proposed that we need to acknowledge, first, the role of design in HCI conduct, and second, the difference between the knowledge-generating Design-oriented Research and the artifact-generating conduct of Research-oriented Design.
2003	Ambiguity as a resource for design	Ambiguity is usually considered anathema in Human Computer Interaction. We argue, in contrast, that it is a resource for design that can be used to encourage close personal engagement with systems. We illustrate this with examples from contemporary arts and design practice, and distinguish three broad classes of ambiguity according to where uncertainty is located in the interpretative relationship linking person and artefact. Ambiguity of information finds its source in the artefact itself, ambiguity of context in the sociocultural discourses that are used to interpret it, and ambiguity of relationship in the interpretative and evaluative stance of the individual. For each of these categories, we describe tactics for emphasising ambiguity that may help designers and other practitioners understand and craft its use.
2003	Sense and sensibility: evaluation and interactive art	HCI evaluation methods are useful for improving the design of interactive systems, yet they may be rejected by nontraditional technology disciplines such as media art. We have developed a two-tiered evaluation model that responds to the concerns of interactive artists and have used it to improve the design of an interactive artwork, the Influencing Machine, exploring issues in affective computing. The method was interpretive, focusing on giving the artists a grounded feeling for how the machine was interpreted and their message was communicated. We describe the resulting design of the Influencing Machine and the reactions of users. The study itself is part of the art piece - together these activities achieve the goal of the artists: to provoke our cultural notions of whether a machine can "have emotions".
2003	Cognitive strategies and eye movements for searching hierarchical computer displays	This research investigates the cognitive strategies and eye movements that people use to search for a known item in a hierarchical computer display. Computational cognitive models were built to simulate the visual-perceptual and oculomotor processing required to search hierarchical and nonhierarchical displays. Eye movement data were collected and compared on over a dozen measures with the "a priori" predictions of the models. Though it is well accepted that hierarchical layouts are easier to search than nonhierarchical layouts, the underlying cognitive basis for this design heuristic has not yet been established. This work combines cognitive modeling and eye tracking to explain this and numerous other visual design guidelines. This research also demonstrates the power of cognitive modeling for predicting, explaining, and interpreting eye movement data, and how to use eye tracking data to confirm and disconfirm modeling details.
2003	Predicting human interruptibility with sensors: a Wizard of Oz feasibility study	A person seeking someone else's attention is normally able to quickly assess how interruptible they are. This assessment allows for behavior we perceive as natural, socially appropriate, or simply polite. On the other hand, today's computer systems are almost entirely oblivious to the human world they operate in, and typically have no way to take into account the interruptibility of the user. This paper presents a Wizard of Oz study exploring whether, and how, robust sensor-based predictions of interruptibility might be constructed, which sensors might be most useful to such predictions, and how simple such sensors might be.The study simulates a range of possible sensors through human coding of audio and video recordings. Experience sampling is used to simultaneously collect randomly distributed self-reports of interruptibility. Based on these simulated sensors, we construct statistical models predicting human interruptibility and compare their predictions with the collected self-report data. The results of these models, although covering a demographically limited sample, are very promising, with the overall accuracy of several models reaching about 78\%. Additionally, a model tuned to avoiding unwanted interruptions does so for 90\% of its predictions, while retaining 75\% overall accuracy.
2003	Simple cognitive modeling in a complex cognitive architecture	Cognitive modeling has evolved into a powerful tool for understanding and predicting user behavior. Higher-level modeling frameworks such as GOMS and its variants facilitate fast and easy model development but are sometimes limited in their ability to model detailed user behavior. Lower-level cognitive architectures such as EPIC, ACT-R, and Soar allow for greater precision and direct interaction with real-world systems but require significant modeling training and expertise. In this paper we present a modeling framework, ACT-Simple, that aims to combine the advantages of both approaches to cognitive modeling. ACT-Simple embodies a "compilation" approach in which a simple description language is compiled down to a core lower-level architecture (namely ACT-R). We present theoretical justification and empirical validation of the usefulness of the approach and framework.
2003	Hardware companions?: what online AIBO discussion forums reveal about the human-robotic relationship	In this study, we investigated people's relationships with AIBO, a robotic pet, through 6,438 spontaneous postings in online AIBO discussion forums. Results showed that AIBO psychologically engaged this group of participants, particularly by drawing forth conceptions of technological essences (75\%), life-like essences (49\%), mental states (60\%), and social rapport (59\%). However, participants seldom attributed moral standing to AIBO (e.g., that AIBO deserves respect, has rights, or can be held morally accountable for action). Our discussion focuses on how robotic pets (now and in the future) may (a) challenge traditional boundaries (e.g. between who or what can possess feelings), (b) extend our conceptions of self, companionship, and community, and (c) begin to replace interactions with live pets. We also discuss a concern that people in general, and children in particular, may fall prey to accepting robotic pets without the moral responsibilities (and moral developmental outcomes) that real, reciprocal companionship and cooperation involves. This research contributes to a growing literature on the human-robotic relationship.
2003	Media inequality in conversation: how people behave differently when interacting with computers and people	How is interacting with computer programs different from interacting with people? One answer in the literature is that these two types of interactions are similar. The present study challenges this perspective with a laboratory experiment grounded in the principles of Interpersonal Theory, a psychological approach to interpersonal dynamics. Participants had a text-based, structured conversation with a computer that gave scripted conversational responses. The main manipulation was whether participants were told that they were interacting with a computer program or a person in the room next door. Discourse analyses revealed a key difference in participants' behavior -- when participants believed they were talking to a person, they showed many more of the kinds of behaviors associated with establishing the interpersonal nature of a relationship. This finding has important implications for the design of technologies intended to take on social roles or characteristics.
2003	Designing social presence of social actors in human computer interaction	This study examines the interaction effect between user factors and media factors on feelings of social presence which are critical in the design of virtual reality systems and human computer interfaces. Both Experiment 1 and Experiment 2 show that matching synthesized voice personality to user personality positively affects users' (especially extrovert users') feelings of social presence. Experiment 2 also reveals that users feel a stronger sense of social presence when the personality of synthesized voice matches the personality of textual content than when those two are mismatched. In both experiments, extrovert voice induces a stronger sense of presence than introvert voice. These results provide strong evidence for human's automatic social responses to artificial representations possessing humanistic properties such as language and personality. Finally, we discuss various applications of these findings in the design of human computer interfaces, as well as in the study of presence.
2003	The challenges of user-centered design and evaluation for infrastructure	Infrastructure software comprises code libraries or runtime processes that support the development or operation of application software. A particular infrastructure system may support certain styles of application, and may even determine the features of applications built using it. This poses a challenge: although we have good techniques for designing and evaluating interactive applications, our techniques for designing and evaluating infrastructure intended to support these applications are much less well formed. In this paper, we reflect on case studies of two infrastructure systems for interactive applications. We look at how traditional user-centered techniques, while appropriate for application design and evaluation, fail to properly support infrastructure design and evaluation. We present a set of lessons from our experience, and conclude with suggestions for better user-centered design and evaluation of infrastructure software.
2003	Harnessing curiosity to increase correctness in end-user programming	Despite their ability to help with program correctness, assertions have been notoriously unpopular--even with professional programmers. End-user programmers seem even less likely to appreciate the value of assertions; yet end-user programs suffer from serious correctness problems that assertions could help detect. This leads to the following question: can end users be enticed to enter assertions? To investigate this question, we have devised a curiosity-centered approach to eliciting assertions from end users, built on a surprise-explain-reward strategy. Our follow-up work with end-user participants shows that the approach is effective in encouraging end users to enter assertions that help them find errors.
2003	Are informal tools better?: comparing DEMAIS, pencil and paper, and authorware for early multimedia design	DEMAIS is an informal design tool that we claim helps a multimedia designer explore and communicate temporal and interactive (behavioral) design ideas better than existing tools. This paper seeks to empirically validate our claim. We report on an evaluation comparing DEMAIS to pencil and paper and Authorware for the exploration and communication of behavior in early multimedia design. The main results are that (i) DEMAIS was better than Authorware for both exploring and communicating behavior, (ii) DEMAIS was better than pencil and paper for communicating behavior, and (iii) DEMAIS was able to capture most of a designer's behavioral design ideas. Our results show that DEMAIS bridges the early investment/communication gap that exists among current multimedia design tools.
2003	Pocket PiCoMap: a case study in designing and assessing a handheld concept mapping tool for learners	Our project explores the benefits and challenges of using handheld computers to support learners in creating concept maps (a type of visual outline). By synthesizing research on small user interfaces with guidelines for building desktop learning tools, we identified potential challenges to using handhelds for complex learning tasks and developed new design guidelines to address these issues. We applied these guidelines to the design of Pocket PiCoMap, a learner-centered concept mapping tool for handheld Pocket PCs. As part of a 9-month classroom study, students used both the handheld Pocket PiCoMap and a comparable desktop concept mapping tool called PiViT. The goal of this comparison between handheld and desktop tools was to better understand how the different form factors of these computers impact students' work processes and products. Our results suggest that students can successfully complete complex learning activities using handheld tools, and that specialized supports (called scaffolds) can be used to help students create better concept maps. This study also identifies several areas where handheld learning tools need further improvements, such as helping students organize their work within the confines of small handheld screens, and we discuss ways in which scaffolds might be used to improve future handheld learning tools.
2003	Navigating in a mobile XHTML application	The Internet has been a great success in the fixed world, whereas WAP (Wireless Application Protocol), the mobile Internet, has not fulfilled its promise. However, now the analysts have started to believe in a rise of the mobile Internet again. WAP 2.0, with XHTML Mobile Profile as its standard language, will enable sites to function both in the fixed and wireless worlds. In this paper, we analyze different ways to navigate XHTML sites with mobile phones and base our analysis on two usability evaluations with a total of 30 subjects from various countries. The results show that due to limitations of mobile devices (the limited display size, pointing methods, and bandwidth), not all navigation guidelines of the fixed Internet are applicable to the mobile Internet. It is important for developers to realize the effect of these limitations in order to build usable XHTML sites also for mobile use.
2003	Mobile computing in the retail arena	Although PDAs typically run applications in a "stand-alone" mode, they are increasingly equipped with wireless communications, which makes them useful in new domains. This capability for more powerful information exchange with larger information systems presents a new situated context for PDA applications, and provides new design and usability evaluation challenges.In this work we examine how grocery shopping could be aided by a mobile shopping application that consumers access via a PDA while in a store. The interactive relationship between the physical space of the store and the human activity of shopping are crucial when designing for this application. To better understand this interaction, we studied people's grocery shopping habits, designed and evaluated prototypes, and performed usability tests within the shopping environment. This paper reveals our design process for this problem and a framework for designing and evaluating situated applications for mobile handhelds.
2003	Taking email to task: the design and evaluation of a task management centered email tool	Email has come to play a central role in task management, yet email tool features have remained relatively static in recent years, lagging behind users? evolving practices. The Taskmaster system narrows this gap by recasting email as task management and embedding task-centric resources directly in the client. In this paper, we describe the field research that inspired Taskmaster and the principles behind its design. We then describe how user studies conducted with ?live? email data over a two-week period revealed the value of a task-centric approach to email system design and its potential benefits for overloaded users.
2003	UMEA: translating interaction histories into project contexts	Virtual environments based on the desktop metaphor provide limited support for creating and managing project-specific work contexts. The paper discusses existing approaches to supporting higher-level user activities and presents a system named UMEA (User-Monitoring Environment for Activities). The design of the system is informed by activity theory. The system: (a) organizes resources into project-related pools consisting of documents, folders, URLs, and contacts, (b) monitors user activities, (c) automatically adds new resources to pools associated with active projects, and (d) provides personal information management tools linked to individual projects. An empirical evaluation of the system is reported.
2004	Acquiring in situ training data for context-aware ubiquitous computing applications	Ubiquitous, context-aware computer systems may ultimately enable computer applications that naturally and usefully respond to a user's everyday activity. Although new algorithms that can automatically detect context from wearable and environmental sensor systems show promise, many of the most flexible and robust systems use probabilistic detection algorithms that require extensive libraries of training data with labeled examples. In this paper, we describe the need for such training data and some challenges we have identified when trying to collect it while testing three context-detection systems for ubiquitous computing and mobile applications.
2004	Analysis of combinatorial user effect in international usability tests	User effect in terms of influencing the validity and reliability of results derived from standard usability tests has been studied with different approaches during the last decade, but inconsistent findings were obtained. User effect is further complicated by other confounding variables. With the use of various computational models, we analyze the extent of user effect in a relatively complex arrangement of international usability tests in which four different European countries were involved. We explore five aspects of user effect, including optimality of sample size, evaluator effect, effect of heterogeneous subgroups, performance of task variants, and efficiency of problem discovery. Some implications for future research are drawn.
2004	Animaatiokone: an installation for creating clay animation	This paper describes Animaatiokone, an installation for experimenting and learning about stop-motion animation. Located in a movie theater, it allows people to create clay animation while waiting for a movie. Collaboration between users is supported, for example, by sharing of clay actors. The installation's user interface allows even beginners to create and edit animation with help of automatic onion-skinning and simple controls developed through iterative testing and prototyping. In test use, the installation has been popular and hundreds of animations have been created and made available via the installation's homepage http://www.animaatiokone.net
2004	Breaking the book: translating the chemistry lab book into a pervasive computing lab environment	The UK e-Science programme is relying on the evolution of the paper lab book into a pervasive data gathering lab system. To date take up of existing commercial or research lab book replacement systems has not been great. In this paper, we reconsider both the role of the lab book in the experimental cycle, as well as its affective and experiential properties as an artefact, in order to design an e-Science lab book that will be acceptable to the scientists who will use it. To this end we combined and extended existing design analysis models in order to assess the artefact functionally and experientially. We present the approach we developed, the prototype we designed based on our analysis, and the results of the formative study we performed of the artefact in real use. We show that our design elicitation method strongly contributed to the success of our prototype's take up.
2004	a CAPpella: programming by demonstration of context-aware applications	Context-aware applications are applications that implicitly take their context of use into account by adapting to changes in a user's activities and environments. No one has more intimate knowledge about these activities and environments than end-users themselves. Currently there is no support for end-users to build context-aware applications for these dynamic settings. To address this issue, we present a CAPpella , a programming by demonstration Context-Aware Prototyping environment intended for end-users. Users "program" their desired context-aware behavior (situation and associated action) in situ , without writing any code, by demonstrating it to a CAPpella and by annotating the relevant portions of the demonstration. Using a meeting and medicine-taking scenario, we illustrate how a user can demonstrate different behaviors to a CAPpella . We describe a CAPpella 's underlying system to explain how it supports users in building behaviors and present a study of 14 end-users to illustrate its feasibility and usability.
2004	Caretta : a system for supporting face-to-face collaboration by integrating personal and shared spaces	In this paper, a system called Caretta that integrates personal and shared spaces to support face-to-face collaboration is described. We use PDAs and a multiple-input sensing board for personal and shared spaces, respectively. Users of Caretta can discuss and negotiate with each other in the shared space by manipulating physical objects, while they individually examine their ideas in their own personal spaces. Caretta allows users to participate in group activities interchangeably and seamlessly using both these spaces. Caretta is applicable to various collaborative tasks. In this paper, it supports users in urban planning tasks. User studies of Caretta demonstrated that it allowed users to collaborate in a flexible fashion: users could work individually in their personal spaces at their own pace, cooperatively work together in the shared space, and smoothly transition between both of the spaces.
2004	Categorical imperative NOT : facial affect is perceived continuously	Facial affect (or emotion) recognition is a central issue for many VMC and naturalistic computing applications. Most computational models assume "categorical perception" of facial affect, in which a benign illusion promotes robust recognition of emotional expressions even under severe degradation conditions, including temporal compression. However, this applied interest in human facial affect perception is coming at a time when the evidence for categorical perception is being challenged in the basic research literature, largely on methodological grounds. The research presented here systematically addresses the classic evidence for categorical perception of facial affect, using high-quality digital imaging and display technologies and improved research methods. In doing so, it illustrates a fruitful convergence of basic and applied research. The evidence does NOT support categorical perception of facial affect, which in turn underlines the importance of preserving high-fidelity motion information in portraying emotion. This research provides new human behavioral data on facial affect perception, and underscores the importance of careful consideration of facial affect compression methods.
2004	Cluster-based find and replace	In current text editors, the find & replace command offers only two options: replace one match at a time prompting for confirmation, or replace all matches at once without any confirmation. Both approaches are prone to errors. This paper explores a third way: cluster-based find & replace , in which the matches are clustered by similarity and whole clusters can be replaced at once. We hypothesized that cluster-based find & replace would make find & replace tasks both faster and more accurate, but initial user studies suggest that clustering may improve speed on some tasks but not accuracy. Users also prefer using a perfect-selection strategy for find & replace, rather than an interleaved decision-action strategy.
2004	Collision warning design to mitigate driver distraction	As computers and other information technology move into cars and trucks, distraction-related crashes are likely to become an important problem. This paper begins to address this problem by examining how alert strategy (graded and single-stage) and alert modality (haptic and auditory) affect how well collision warning systems mitigate distraction and direct drivers attention to the car ahead when it unexpectedly brakes. We conducted two experiments in which drivers interacted with an in-vehicle email system and a collision warning system signaled a braking lead vehicle. The first experiment showed that graded alerts led to a greater safety margin and a lower rate of inappropriate responses to nuisance warnings. A second experiment focused on attitudes toward the collision warning system and found that graded alerts were more trusted than single stage alerts and that haptic alerts, a vibrating seat in these experiments, were perceived as less annoying and more appropriate. Graded haptic alerts offer a promising approach to developing context aware computing in a safety-critical application.
2004	Combining 2D and 3D views for orientation and relative position tasks	We compare 2D/3D combination displays to displays with 2D and 3D views alone. Combination displays we consider are: orientation icon (i.e., side-by-side), in-place methods (e.g., clip planes), and a new method called ExoVis. We specifically analyze performance differences (i.e., time and accuracy) for 3D orientation and relative position tasks. Empirical results show that 3D displays are effective for approximate navigation and relative positioning whereas 2D/3D combination displays (orientation icon and ExoVis) are useful for precise orientation and position tasks. Combination 2D/3D displays had as good or better performance as 2D displays. Clip planes were not effective for a 3D orientation task, but may be useful when only one slice is needed.
2004	A comparison of consecutive and concurrent input text entry techniques for mobile phones	The numeric keypads on mobile phones generally consist of 12 keys (0-9, *, #). Ambiguity arises when the 36-character alpha-numeric English alphabet is mapped onto this smaller number of keys. In this paper, we first present a taxonomy of the various techniques for resolving this ambiguity, dividing them into techniques that use consecutive actions to first select a character grouping and then a character from within that grouping, and those that use concurrent actions to achieve the same end. We then present the design and implementation of a chording approach to text entry that uses concurrent key presses. We conducted a controlled experiment that compared this chording technique to one-handed and two-handed versions of the commonly used MultiTap technique. The results show that the concurrent chording technique significantly outperforms both versions of the consecutive action MultiTap technique.
2004	A comparison of static, adaptive, and adaptable menus	Software applications continue to grow in terms of the number of features they offer, making personalization increasingly important. Research has shown that most users prefer the control afforded by an adaptable approach to personalization rather than a system-controlled adaptive approach. No study, however, has compared the efficiency of the two approaches. In a controlled lab study with 27 subjects we compared the measured and perceived efficiency of three menu conditions: static, adaptable and adaptive. Each was implemented as a split menu, in which the top four items remained static, were adaptable by the subject, or adapted according to the subject's frequently and recently used items. The static menu was found to be significantly faster than the adaptive menu, and the adaptable menu was found to be significantly faster than the adaptive menu under certain conditions. The majority of users preferred the adaptable menu overall. Implications for interface design are discussed.
2004	Computational GOMS modeling of a complex team task: lessons learned	This paper presents the lessons learned when a computational GOMS modeling tool was used to evaluate user interface concepts and team structure designs for a new class of military shipboard workstations. The lessons are both encouraging and cautionary: For example, computational GOMS models scaled well to a large and complex task involving teams of users. Interruptability and working memory constructs had to be added to conventional GOMS model concepts. However, two surprises emerged: First, the non-psychological aspects of the model construction were the practical bottleneck. Second, user testing data in this domain were difficult to collect and lacked definition, meaning that the model provided a better characterization of the design details than the user testing data. Included in these lessons are recommendations for future model applications and modeling methodology development.
2004	Connecting time-oriented data and information to a coherent interactive visualization	In modern intensive care units (ICUs), the medical staff has to monitor a huge amount of high-dimensional and time-oriented data, which needs to be visualized user- and task-specifically to ease diagnosis and treatment planning. Available visual representations, like diagrams or charts neglect the implicit information as well as a-priory or associated knowledge about the data and its meaning (for example, 38.5°C (101.3°F) is moderate fever and 41°C (105.8°F) is critical fever). Another challenge is to provide appropriate interaction techniques to explore and navigate the data and its temporal dimensions. In this context one major challenge is to connect time-oriented data and information to a coherent interactive visualization. In this paper we present different interactive visualization techniques which enable the users to reveal the data at several levels of detail and abstraction, ranging from a broad overview to the fine structure. We will also introduce a time visualization and navigation technique that connects overview+detail , pan+zoom , and focus+context features to one powerful time-browser.
2004	Constant, constant, multi-tasking craziness: managing multiple working spheres	Most current designs of information technology are based on the notion of supporting distinct tasks such as document production, email usage, and voice communication. In this paper we present empirical results that suggest that people organize their work in terms of much larger and thematically connected units of work. We present results of fieldwork observation of information workers in three different roles: analysts, software developers, and managers. We discovered that all of these types of workers experience a high level of discontinuity in the execution of their activities. People average about three minutes on a task and somewhat more than two minutes using any electronic tool or paper document before switching tasks. We introduce the concept of working spheres to explain the inherent way in which individuals conceptualize and organize their basic units of work. People worked in an average of ten different working spheres. Working spheres are also fragmented; people spend about 12 minutes in a working sphere before they switch to another. We argue that design of information technology needs to support people's continual switching between working spheres.
2004	A constraint satisfaction approach to predicting skilled interactive cognition	In this paper we report a new approach to generating predictions about skilled interactive cognition. The approach, which we call Cognitive Constraint Modeling, takes as input a description of the constraints on a task environment, on user strategies, and on the human cognitive architecture and generates as output a prediction of the time course of interaction. In the Cognitive Constraint Models that we have built this is achieved by encoding the assumptions inherent in CPM-GOMS as a set of constraints and reasoning about them using finite domain constraint satisfaction.
2004	Deception and design: the impact of communication technology on lying behavior	Social psychology has demonstrated that lying is an important, and frequent, part of everyday social interactions. As communication technologies become more ubiquitous in our daily interactions, an important question for developers is to determine how the design of these technologies affects lying behavior. The present research reports the results of a diary study, in which participants recorded all of their social interactions and lies for seven days. The data reveal that participants lied most on the telephone and least in email, and that lying rates in face-to-face and instant messaging interactions were approximately equal. This pattern of results suggests that the design features of communication technologies (e.g., synchronicity, recordability, and copresence) affect lying behavior in important ways, and that these features must be considered by both designers and users when issues of deception and trust arise. The implications for designing applications that increase, decrease or detect deception are discussed.
2004	Design guidelines for learner-centered handheld tools	Handheld computers are mobile, flexible devices that can provide real-time, one-to-one support for students from within the context of their learning activities. This paper describes the design of three learner-centered handheld tools used as part of a nine-month classroom study involving thirty-three eighth grade students. A review of related work identifies some of the challenges of building educational software within the constraints of handheld screens, and two broad design guidelines are synthesized to help address these challenges. The first design guideline focuses on decomposing the learning activity to identify salient tasks and the type of supports (or scaffolds) students need to engage in these tasks, then building separate handheld workspaces to support each task. The second guideline focuses on methods for implementing scaffolds within these task-based workspaces while preserving the usability of the overall handheld software.
2004	Designing a compelling user interface for morphing	We present a new user interface for the common morphing tool found in animation packages. Previously this interface has been based on the features of the underlying algorithm, with little regard to how artists actually use this feature. By careful design and analysis of a user study, we were able to design a novel user interface that greatly enhances the usability of the morphing tool for animation. Our improvements come in three areas: First, we replicate the artists' own ad-hoc annotation language and interaction techniques in the user interface. Second, we make the user experience more fluid and editable, to support exploration and iteration. Finally, we use the artists' morph expectations to redesign the morph algorithm itself to be more predictable. We conclude by discussing how our user study technique could help other interface design tasks.
2004	Designing the whyline: a debugging interface for asking questions about program behavior	Debugging is still among the most common and costly of programming activities. One reason is that current debugging tools do not directly support the inquisitive nature of the activity. Interrogative Debugging is a new debugging paradigm in which programmers can ask why did and even why didn't questions directly about their program's runtime failures. The Whyline is a prototype Interrogative Debugging interface for the Alice programming environment that visualizes answers in terms of runtime events directly relevant to a programmer's question. Comparisons of identical debugging scenarios from user tests with and without the Whyline showed that the Whyline reduced debugging time by nearly a factor of 8, and helped programmers complete 40\% more tasks.
2004	Designing to support awareness: a predictive, composite model	In this paper we propose an account of human/computer awareness for use in the (re)design of complex human/computer interaction, before empirically testing its utility. Specifically, having situated our work in the wider field of human/computer awareness research, we address the well-reported phenomenon of "situation awareness" breakdowns in the aviation domain. We assert the need for an explanatory and predictive model of the phenomenon if the frequency of such breakdowns is to be reduced and propose such a model. We then go on to investigate the utility of our model as a guide for design through the discussion of a recent experiment involving manipulations of an animated warning signal on a simulated cockpit control panel. Our results show initial support both for the model and for our assertion of its utility. We conclude that our composite view of awareness yields practical benefit in the design of human computer awareness support.
2004	DiamondSpin: an extensible toolkit for around-the-table interaction	DiamondSpin is a toolkit for the efficient prototyping of and experimentation with multi-person, concurrent interfaces for interactive shared displays. In this paper, we identify the fundamental functionality that tabletop user interfaces should embody, then present the toolkit's architecture and API. DiamondSpin provides a novel real-time polar to Cartesian transformation engine that has enabled new, around-the-table interaction metaphors to be implemented. DiamondSpin allows arbitrary document positioning and orientation on a tabletop surface. Polygonal tabletop layouts such as rectangular, octagonal, and circular tabletops can easily be constructed. DiamondSpin also supports multiple work areas within the same digital tabletop. Multi-user operations are offered through multi-threaded input event streams, multiple active objects, and multiple concurrent menus. We also discuss insights on tabletop interaction issues we have observed from a set of applications built with DiamondSpin.
2004	A diary study of task switching and interruptions	We report on a diary study of the activities of information workers aimed at characterizing how people interleave multiple tasks amidst interruptions. The week-long study revealed the type and complexity of activities performed, the nature of the interruptions experienced, and the difficulty of shifting among numerous tasks. We present key findings from the diary study and discuss implications of the findings. Finally, we describe promising directions in the design of software tools for task management, motivated by the findings.
2004	Dual ecologies of robot as communication media: thoughts on coordinating orientations and projectability	The aim of our study is to investigate systems for supporting remote instruction via a mobile robot. In the real world, instructions are typically given through words and body orientations such as head movements, which make it possible to project others' actions. Projectability is an important resource in organizing multiple actions among multiple participants in co-ordination with one another. It can likewise be said that in the case of robot-human collaboration, it is necessary to design a robot's head so that a local participant can project the robot's (and remote person's) actions. GestureMan is a robot that is designed to support such projectability properties. It is argued that a remote controlled mobile robot, designed as a communication medium, makes relevant dual ecologies: ecology at a remote (robot operator's) site and at a local participant's (robot's) site. In order to design a robot as a viable communication medium, it is essential to consider how these ecologies can be mediated and supported.
2004	Effects of instant messaging on the management of multiple project trajectories	We present a study of the effects of instant messaging (IM) on individuals' management of work across multiple collaborative projects. Groups of four participants completed four web design tasks. Each participant worked on two tasks, each task with a different partner who was either co-located or remote, connected via IM. In one condition, each participant had one co-located and one remote partner. In a second condition, both partners were remote. We examined communication, division of labor, and task performance as a function of condition. The results indicated that nearly all participants divided their time unequally between projects, but less unequally in the remote/remote condition. In the co-located/remote condition, participants favored the task with the co-located partner. The results show that the effects of IM differ depending on people's multiple tasks are distributed across space. We propose a new IM interface that promotes awareness of multiple collaborators on multiple tasks.
2004	Energy-aware user interfaces: an evaluation of user acceptance	The utility of a handheld device is often constrained by the battery life, particularly with recent usage patterns where the device is likely to be powered on at all times. The display component in these devices is a major consumer of battery energy and reducing its energy consumption can significantly enhance its utility. This primary research explores the impact of emerging technologies that provide energy-saving display modifications on perceived ease of use, quality, and overall user acceptance, and seeks to understand the tradeoffs between energy reduction and user acceptance for future interfaces. For our study, twelve handheld users reviewed energy-adaptive and standard display interfaces during five scenarios representing frequently performed tasks. The results show good acceptance of energy-aware user interfaces. While displays for tasks involving notifications and menus were deemed acceptable, primarily due to enhanced contrast levels, displays for longer tasks involving greater informational context need additional work.
2004	Examining the robustness of sensor-based statistical models of human interruptibility	Current systems often create socially awkward interruptions or unduly demand attention because they have no way of knowing if a person is busy and should not be interrupted. Previous work has examined the feasibility of using sensors and statistical models to estimate human interruptibility in an office environment, but left open some questions about the robustness of such an approach. This paper examines several dimensions of robustness in sensor-based statistical models of human interruptibility. We show that real sensors can be constructed with sufficient accuracy to drive the predictive models. We also create statistical models for a much broader group of people than was studied in prior work. Finally, we examine the effects of training data quantity on the accuracy of these models and consider tradeoffs associated with different combinations of sensors. As a whole, our analyses demonstrate that sensor-based statistical models of human interruptibility can provide robust estimates for a variety of office workers in a range of circumstances, and can do so with accuracy as good as or better than people. Integrating these models into systems could support a variety of advances in human computer interaction and computer-mediated communication.
2004	Exploring PC-telephone convergence with the enhanced telephony prototype	Industry trends suggest that the PC and telephone user experiences will converge over the next several years. This convergence raises important questions for the HCI community: how should the PC-phone user experience be designed, and how does PC-phone technology affect work practices? This paper focuses on the first question and provides some initial data on the second question. We describe a PC-phone prototype we built called Enhanced Telephony, and we report data from an eight month field deployment of Enhanced Telephony within our company where over 7,000 people installed the prototype. Results indicate that PC-phone software is a promising technology for the workplace and that the most valuable features may be those that help people manage their incoming calls.
2004	The familiar stranger: anxiety, comfort, and play in public places	As humans we live and interact across a wildly diverse set of physical spaces. We each formulate our own personal meaning of place using a myriad of observable cues such as public-private, large-small, daytime-nighttime, loud-quiet, and crowded-empty. Not surprisingly, it is the people with which we share such spaces that dominate our perception of place. Sometimes these people are friends, family and colleagues. More often, and particularly in public urban spaces we inhabit, the individuals who affect us are ones that we repeatedly observe and yet do not directly interact with - our Familiar Strangers . This paper explores our often ignored yet real relationships with Familiar Strangers. We describe several experiments and studies that led to designs for both a personal, body-worn, wireless device and a mobile phone based application that extend the Familiar Stranger relationship while respecting the delicate, yet important, constraints of our feelings and affinities with strangers in pubic places.
2004	Fan-out: measuring human control of multiple robots	A goal of human-robot interaction is to allow one user to operate multiple robots simultaneously. In such a scenario the robots provide leverage to the user's attention. The number of such robots that can be operated is called the fan-out of a human-robot team. Robots that have high neglect tolerance and lower interaction time will achieve higher fan-out. We define an equation that relates fan-out to a robot's activity time and its interaction time. We describe how to measure activity time and fan-out. We then use the fan-out equation to compute interaction effort. We can use this interaction effort as a measure of the effectiveness of a human-robot interaction design. We describe experiments that validate the fan-out equation and its use as a metric for improving human-robot interaction.
2004	Feeling bumps and holes without a haptic interface: the perception of pseudo-haptic textures	We present a new interaction technique to simulate textures in desktop applications without a haptic interface. The proposed technique consists in modifying the motion of the cursor on the computer screen - i.e. the Control/Display ratio. Assuming that the image displayed on the screen corresponds to a top view of the texture, an acceleration (or deceleration) of the cursor indicates a negative (or positive) slope of the texture. Experimental evaluations showed that participants could successfully identify macroscopic textures such as bumps and holes, by simply using the variations of the motion of the cursor. Furthermore, the participants were able to draw the different profiles of bumps and holes which were simulated, correctly. These results suggest that our technique enabled the participants to successfully conjure a mental image of the topography of the macroscopic textures. Applications for this technique are: the feeling of images (pictures, drawings) or GUI components (windows' edges, buttons), the improvement of navigation, or the visualization of scientific data.
2004	Finding meaningful uses for context-aware technologies: the humanistic research strategy	Human-computer interaction (HCI) is undergoing a paradigm change towards interaction that is contextually adapted to rich use situations taking place "beyond the desktop". Currently, however, there are only few successful applications of context-adapted HCI, arguably because use scenarios have not been based on holistic understanding of the society, users, and use situations. A humanistic research strategy, utilized at the Helsinki Institute for Information Technology, aims to structure the innovation and evaluation of scenarios for future technologies. Population trends and motivational needs are analyzed to recognize psycho-socially relevant design opportunities. Ethnography, ethnomethodology, bodystorming, and computer simulations of use situations are conducted to understand use situations. The goal of design is to empower users by supporting their autonomy and control. Three design cases illustrate the approach. The paper showcases an emerging framework for informed innovation of use potentials.
2004	Flat volume control: improving usability by hiding the volume control hierarchy in the user interface	The hardware-inspired volume user interface model that is in use across all of today's operating systems is the source of several usability issues. One of them is that restoring the volume of a muted application can require an inappropriately long troubleshooting process: in addition to manipulating the application's volume and mute controls, users may also have to visit the system's volume control panel to find and adjust additional controls there. The "flat" volume control model presented in this paper eliminates this and other problems by hiding the hardware-oriented volume model from the user. Using the flat model, users use one slider per application to indicate how loud they want the respective applications to play; the slider then internally adjusts all hardware volume variables necessary to obtain the requested output. By offering a single point of control for each application, the flat model simplifies controlling application volume and restoring muted applications. In our studies, participants completed all four volume control and mixing tasks faster and with less error when using the flat model than when using the existing hardware-oriented volume control model. Participants also indicated a subjective preference for the flat model over the existing model.
2004	Gummi: a bendable computer	Gummi is an interaction technique and device concept based on physical deformation of a handheld device. The device consists of several layers of flexible electronic components, including sensors measuring deformation of the device. Users interact with this device by a combination of bending and 2D position control. Gummi explores physical interaction techniques and screen interfaces for such a device. Its graphical user interface facilitates a wide range of interaction tasks, focused on browsing of visual information. We implemented both hardware and software prototypes to explore and evaluate the proposed interaction techniques.Our evaluations have shown that users can grasp Gummi's key interaction principles within minutes. Gummi demonstrates promising possibilities for new interaction techniques and devices based on flexible electronic components.
2004	If not now, when?: the effects of interruption at different moments within task execution	User attention is a scarce resource, and users are susceptible to interruption overload. Systems do not reason about the effects of interrupting a user during a task sequence. In this study, we measure effects of interrupting a user at different moments within task execution in terms of task performance, emotional state, and social attribution. Task models were developed using event perception techniques, and the resulting models were used to identify interruption timings based on a user's predicted cognitive load. Our results show that different interruption moments have different impacts on user emotional state and positive social attribution, and suggest that a system could enable a user to maintain a high level of awareness while mitigating the disruptive effects of interruption. We discuss implications of these results for the design of an attention manager.
2004	IM here: public instant messaging on large, shared displays for workgroup interactions	Instant messaging (IM) in the workplace has proven to be a valuable tool for facilitating informal communication. Its benefits, however, are generally limited to times when users are in front of their computers. Because so much work takes place while people are mobile within their workplace, we sought to extend the benefits of IM beyond people's personal machines and into publicly accessible groupware. We first conducted a study of large display groupware applications (LDGAs) to understand the affordances that large displays offer for groupware, and the factors surrounding their adoption. We developed the IM Here system for shared IM on large displays using the lessons learned from the study. In this paper, we present the findings of our LDGA study, the design of IM Here and the preliminary results of our evaluation of IM as a public resource for workgroups.
2004	Impact of interruption style on end-user debugging	Although researchers have begun to explicitly support end-user programmers' debugging by providing information to help them find bugs, there is little research addressing the proper mechanism to alert the user to this information. The choice of alerting mechanism can be important, because as previous research has shown, different interruption styles have different potential advantages and disadvantages. To explore impacts of interruptions in the end-user debugging domain, this paper describes an empirical comparison of two interruption styles that have been used to alert end-user programmers to debugging information. Our results show that negotiated-style interruptions were superior to immediate-style interruptions in several issues of importance to end-user debugging, and further suggest that a reason for this superiority may be that immediate-style interruptions encourage different debugging strategies.
2004	Improving speech playback using time-compression and speech recognition	Despite the ready availability of digital recording technology and the continually decreasing cost of digital storage, browsing audio recordings remains a tedious task. This paper presents evidence in support of a system designed to assist with information comprehension and retrieval tasks from a large collection of recorded speech. Two techniques are employed to assist users with these tasks. First, a speech recognizer creates necessarily error-laden transcripts of the recorded speech. Second, audio playback is time-compressed using the SOLAFS technique. When used together, subjects are able to perform comprehension tasks with more speed and accuracy.
2004	I/O brush: drawing with everyday objects as ink	We introduce I/O Brush, a new drawing tool aimed at young children, ages four and up, to explore colors, textures, and movements found in everyday materials by "picking up" and drawing with them. I/O Brush looks like a regular physical paintbrush but has a small video camera with lights and touch sensors embedded inside. Outside of the drawing canvas, the brush can pick up color, texture, and movement of a brushed surface. On the canvas, children can draw with the special "ink" they just picked up from their immediate environment. In our preliminary study with kindergarteners, we found that children not only produced complex works of art using I/O Brush, but they also engaged in explicit talk about patterns and features available in their environment. I/O Brush invites children to explore the transformation from concrete and familiar raw material into abstract concepts about patterns of colors, textures and movements.
2004	Isolating the effects of visual impairment: exploring the effect of AMD on the utility of multimodal feedback	This study examines the effects of multimodal feedback on the performance of older adults with an ocular disease, Age-Related Macular Degeneration (AMD), when completing a simple computer-based task. Visually healthy older users (n = 6) and older users with AMD (n = 6) performed a series of drag-and-drop tasks that incorporated a variety of different feedback modalities. The user groups were equivalent with respect to traditional visual function metrics and measured subject cofactors, aside from the presence or absence of AMD. Results indicate that users with AMD exhibited decreased performance, with respect to required feedback exposure time. Some non-visual and multimodal feedback forms show potential as solutions to enhance performance, for those with AMD as well as for visually healthy older adults.
2004	Labeling images with a computer game	We introduce a new interactive system: a game that is fun and can be used to create valuable output. When people play the game they help determine the contents of images by providing meaningful labels for them. If the game is played as much as popular online games, we estimate that most images on the Web can be labeled in a few months. Having proper labels associated with each image on the Web would allow for more accurate image search, improve the accessibility of sites (by providing descriptions of images to visually impaired individuals), and help users block inappropriate images. Our system makes a significant contribution because of its valuable output and because of the way it addresses the image-labeling problem. Rather than using computer vision techniques, which don't work well enough, we encourage people to do the work by taking advantage of their desire to be entertained.
2004	Manipulating music: multimodal interaction for DJs	In this paper we consider the general goal of supporting physical manipulation of digital audio in a specific context: the performance disk jockey (DJ) seeking to migrate from vinyl to digital media. We classify both the DJ's traditional processes and tools and the field's newest technology.D'Groove, our own technological contribution, is a force feedback turntable used to manipulate digital audio in novel ways. We present an observational study of professional DJ's using D'Groove, and discuss this approach's attributes and directions for future augmentation. Finally, we extend our conclusions about the DJ's emerging needs to the broader domain of digital audio manipulation.
2004	Master usability scaling: magnitude estimation and master scaling applied to usability measurement	Master Usability Scaling (MUS) is a measurement method for developing a universal usability continuum based on magnitude estimation and master scaling. The universal usability continuum allows true ratio comparisons, potentially between all items measurable by the construct of usability (attributes, tasks, or products -- software or hardware) that have contributed to the meta-set by following the procedures prescribed. This paper describes the background for MUS, data reduction, and cases studies in software usability assessment.MUS is based on a new measurement method of usability, Usability Magnitude Estimation (UME) [9], where users estimate usability magnitude according to an objective definition of usability. UME allows all items measured within a single usability activity to be compared across one continuum. MUS utilizes UME to assess standard reference tasks across different usability activities to construct one meta-set of data. This meta-set of data can be represented as a universal usability continuum. MUS is simple to administer, easy to comprehend, and with advanced underlying calculations, powerful to use. The MUS continuum has the potential to be a widespread, robust, universal measurement scale of usability.
2004	Model-based evaluation of cell phone menu interaction	Cell phone interfaces are now ubiquitous. In this paper, we describe concepts to support the analysis of cell phone menu hierarchies. We present an empirical study of user performance on five simple tasks of menu traversal on a cell phone. Two models we tested, based on GOMS and ACT-R, give very good predictions of behavior. We use the study results to motivate an effective evaluation process for menu hierarchies. Our work makes several contributions: a novel and timely study of a new, very common HCI task; new models for accurately predicting performance; novel development tools to support such modeling; and a search procedure to generate menu hierarchies that reduce traversal time, in simulation studies, by about a third.
2004	Model for non-expert text entry speed on 12-button phone keypads	In this paper we present a new model for predicting text entry speed on a 12-button mobile phone keypad. The proposed model can predict the performance of novice users. Like other models for text entry, the proposed model includes a movement component based on Fitts' law and a linguistic component based on letter digraph probabilities. It also adds cognitive delay times before key presses and takes into account the fact that Fitts' law cannot model multiple presses of the same key accurately. Finally, we compare the prediction of our model to previously published experimental results, demonstrate that it fits observed results for novices very well, and list some observations about learning.
2004	Mouse and touchscreen selection in the upper and lower visual fields	Neuroanatomical evidence indicates the human eye's visual field can be functionally divided into two vertical hemifields, each specialized for specific functions. The upper visual field (UVF) is specialized to support perceptual tasks in the distance, while the lower visual field (LVF) is specialized to support visually-guided motor tasks, such as pointing. We present a user study comparing mouse- and touchscreen-based pointing for items presented in the UVF and LVF on an interactive display. Consistent with the neuroscience literature, we found that mouse and touchscreen pointing were faster and more accurate for items presented in the LVF when compared to pointing at identical targets presented in the UVF. Further analysis found previously unreported performance differences between the visual fields for touchscreen pointing that were not observed for mouse pointing. This indicates that a placement of interactive items favorable to the LVF yields superior user performance, especially for systems dependent on direct touch interactions.
2004	Multiblending: displaying overlapping windows simultaneously without the drawbacks of alpha blending	Alpha blending allows the simultaneous display of overlapping windows-such as palette windows in visual workspaces. Although alpha blending has been used in some applications, such as games, it has not been widely adopted. One reason for the limited acceptance is that in many scenarios, alpha blending compromises the readability of content. We introduce a new blending mechanism called multiblending that uses a vector of blending weights, one for each class of features, rather than a single transparency value. Multiblending can in most cases be automatically optimized to preserve the most relevant features of both the palette and the background window. We present the results of a user study in which multiblended palettes provided higher recognizability of both the background and the palette than the best participating version of alpha blending.
2004	One-hundred days in an activity-centric collaboration environment based on shared objects	This paper describes a new collaboration technology that is carefully poised between informal, ad hoc, easy-to-initiate collaborative tools, vs. more formal, structured, and high-overhead collaborative applications. Our approach focuses on the support of lightweight, informally structured, opportunistic activities featuring heterogeneous threads of shared objects with dynamic membership. We introduce our design concepts, and we provide a detailed first look at data from the first 100 days of usage by 20 researchers and 13 interns, who both confirmed our hypotheses and surprised us by reinventing the technology in several ways.
2004	Off-task behavior in the cognitive tutor classroom: when students game the system	We investigate the prevalence and learning impact of different types of off-task behavior in classrooms where students are using intelligent tutoring software. We find that within the classrooms studied, no other type of off-task behavior is associated nearly so strongly with reduced learning as "gaming the system": behavior aimed at obtaining correct answers and advancing within the tutoring curriculum by systematically taking advantage of regularities in the software's feedback and help. A student's frequency of gaming the system correlates as strongly to post-test score as the student's prior domain knowledge and general academic achievement. Controlling for prior domain knowledge, students who frequently game the system score substantially lower on a post-test than students who never game the system. Analysis of students who choose to game the system suggests that learned helplessness or performance orientation might be better accounts for why students choose this behavior than lack of interest in the material. This analysis will inform the future re-design of tutors to respond appropriately when students game the system.
2004	Orchestrating a mixed reality game 'on the ground'	Successfully staging a mixed reality game in which online players are chased through a virtual city by runners located in the real world requires extensive orchestration work. An ethnographic study shows how this concerted achievement extends beyond the control room to the runners on the street. This, in turn, suggests the need to 'decentralize' orchestration and develop support for collaboration 'on the ground'. The study leads to design proposals for orchestration interfaces for mobile experiences that augment situational awareness and surreptitious monitoring among mobile participants and support troubleshooting in situations where participants are disconnected or are unable to access positioning systems such as GPS.
2004	Papier-Mache: toolkit support for tangible input	Tangible user interfaces (TUIs) augment the physical world by integrating digital information with everyday physical objects. Currently, building these UIs requires "getting down and dirty" with input technologies such as computer vision. Consequently, only a small cadre of technology experts can currently build these UIs. Based on a literature review and structured interviews with nine TUI researchers, we created Papier-Mâché, a toolkit for building tangible interfaces using computer vision, electronic tags, and barcodes. Papier-Mache introduces a high-level event model for working with these technologies that facilitates technology portability. For example, an application can be prototyped with computer vision and deployed with RFID. We present an evaluation of our toolkit with six class projects and a user study with seven programmers, finding the input abstractions, technology portability, and monitoring window to be highly effective.
2004	The participatory design of a sound and image enhanced daily planner for people with aphasia	Aphasia is a cognitive disorder that impairs speech and language. From interviews with aphasic individuals, their caregivers, and speech-language pathologists, the need was identified for a daily planner that allows aphasic users to independently manage their appointments. We used a participatory design approach to develop ESI Planner (the Enhanced with Sound and Images Planner) for use on a PDA and subsequently evaluated it in a lab study. This methodology was used in order to achieve both usable and adoptable technology. In addition to describing our experience in designing ESI Planner, two main contributions are provided: general guidelines for working with special populations in the development of technology, and design guidelines for accessible handheld technology.
2004	The perfect search engine is not enough: a study of orienteering behavior in directed search	This paper presents a modified diary study that investigated how people performed personally motivated searches in their email, in their files, and on the Web. Although earlier studies of directed search focused on keyword search, most of the search behavior we observed did not involve keyword search. Instead of jumping directly to their information target using keywords, our participants navigated to their target with small, local steps using their contextual knowledge as a guide, even when they knew exactly what they were looking for in advance. This stepping behavior was especially common for participants with unstructured information organization. The observed advantages of searching by taking small steps include that it allowed users to specify less of their information need and provided a context in which to understand their results. We discuss the implications of such advantages for the design of personal information management tools.
2004	Performance of menu-augmented soft keyboards	We report results on the performance of the combination of soft keyboards and marking menus. A model of expert user performance indicated an 11 - 37\% (depending on the keyboard layout) improvement in text entry rate over the same keyboard without the menu. To verify the advantage in real usage, we conducted two experiments using the QWERTY keyboard layout with and without the menu. The first experiment imitated nearly perfect cognitive performance and measured motor performance. Using the menu saved time. The second experiment measured performance in a realistic text entry task. Initially using the menu slows down text entry. By the end of the 20-session experiment both conditions were equally fast. With continued practice text entry is likely to be faster with the menu.
2004	Persistence matters: making the most of chat in tightly-coupled work	How much history of the dialogue should a chat client include? Some chat clients have minimized the dialogue history to deploy the space for other purposes. A theory of conversational coordination suggests that stripping away history raises the cost of conversational grounding, creating problems for both writers and readers. To test this proposition and inform design, we conducted an experiment in which one person instructed another on how to solve a simple puzzle. Participants had chat clients that showed either a single conversational turn or six of them. Having the dialogue history helped collaborators communicate efficiently and led to faster and better task performance. The dialogue history was most useful when the puzzles were more linguistically complex and when instructors could not see the work area. We present evidence of participants adapting their discourse to partially compensate for deficits in the communication media.
2004	Physically large displays improve path integration in 3D virtual navigation tasks	Previous results have shown that users perform better on spatial orientation tasks involving static 2D scenes when working on physically large displays as compared to small ones. This was found to be true even when the displays presented the same images at equivalent visual angles. Further investigation has suggested that large displays may provide a greater sense of presence, which biases users into adopting more efficient strategies to perform tasks. In this work, we extend those findings, demonstrating that users are more effective at performing 3D virtual navigation tasks on large displays. We also show that even though interacting with the environment affects performance, effects induced by interactivity are independent of those induced by physical display size. Together, these findings allow us to derive guidelines for the design and presentation of interactive 3D environments on physically large displays.
2004	Pointing at trivariate targets in 3D environments	We investigate pointing in true 3D environments where the target size varies in three spatial dimensions. We also study the effect of the user's physical movement angle on pointing performance. Results show that target size dimension along the primary axis of movement has a greater impact on performance than the other two dimensions. Movement angle also significantly affects performance, and changes the relative impact of the three target dimensions. Building upon recent results in the modeling of bivariate pointing, we propose and validate a new model that describes pointing at trivariate targets. This model also accounts for movement angle, and outperforms previously published models.
2004	Predictive human performance modeling made easy	Although engineering models of user behavior have enjoyed a rich history in HCI, they have yet to have a widespread impact due to the complexities of the modeling process. In this paper we describe a development system in which designers generate predictive cognitive models of user behavior simply by demonstrating tasks on HTML mock-ups of new interfaces. Keystroke-Level Models are produced automatically using new rules for placing mental operators, then implemented in the ACT-R cognitive architecture. They interact with the mock-up through integrated perceptual and motor modules, generating behavior that is automatically quantified and easily examined. Using a query-entry user interface as an example [19], we demonstrate that this new system enables more rapid development of predictive models, with more accurate results, than previously published models of these tasks.
2004	Presiding over accidents: system direction of human action	As human-computer interaction becomes more closely modeled on human-human interaction, new techniques and strategies for human-computer interaction are required. In response to the inevitable shortcomings of recognition technologies, researchers have studied mediation: interaction techniques by which users can resolve system ambiguity and error. In this paper we approach the human-computer dialogue from the other side, examining system-initiated direction and mediation of human action. We conducted contextual interviews with a variety of experts in fields involving human-human direction, including a film director, photographer, golf instructor, and 911 operator. Informed by these interviews and a review of prior work, we present strategies for directing physical human action and an associated design space for systems that perform such direction. We illustrate these concepts with excerpts from our interviews and with our implemented system for automated media capture or "Active Capture," in which an unaided computer system uses techniques identified in our design space to act as a photographer, film director, and cinematographer.
2004	Privacy policies as decision-making tools: an evaluation of online privacy notices	Studies have repeatedly shown that users are increasingly concerned about their privacy when they go online. In response to both public interest and regulatory pressures, privacy policies have become almost ubiquitous. An estimated 77\% of websites now post a privacy policy. These policies differ greatly from site to site, and often address issues that are different from those that users care about. They are in most cases the users' only source of information.This paper evaluates the usability of online privacy policies, as well as the practice of posting them. We analyze 64 current privacy policies, their accessibility, writing, content and evolution over time. We examine how well these policies meet user needs and how they can be improved. We determine that significant changes need to be made to current practice to meet regulatory and usability requirements.
2004	Putting the users center stage: role playing and low-fi prototyping enable end users to design mobile systems	This paper sums up lessons learned from a sequence of cooperative design workshops where end users were enabled to design mobile systems through scenario building, role playing, and low-fidelity prototyping. We present a resulting fixed workshop structure with well-chosen constraints that allows for end users to explore and design new technology and work practices. In these workshops, the systems developers get input to design from observing how users stage and act out current and future use scenarios and improvise new technology to fit their needs. A theoretical framework is presented to explain the creative processes involved and the workshop as a user-centered design method. Our findings encourage us to recommend the presented workshop structure for design projects involving mobility and computer-mediated communication, in particular project where the future use of the resulting products and services also needs to be designed.
2004	Pressure widgets	Current user interface widgets typically assume that the input device can only provide x-y position and binary button press information. Other inputs such as the continuous pressure data provided by styluses on tablets are rarely used. We explore the design space of using the continuous pressure sensing capabilities of styluses to operate multi-state widgets. We present the results of a controlled experiment that investigates human ability to perform discrete target selection tasks by varying a stylus' pressure, with full or partial visual feedback. The experiment also considers different techniques for confirming selection once the target is acquired. Based on the experimental results, we discuss implications for the design of pressure sensitive widgets. A taxonomy of pressure widgets is presented, along with a set of initial concept sketches of various pressure widget designs.
2004	RAW: conveying minimally-mediated impressions of everyday life with an audio-photographic tool	This paper traces the development of RAW, a system combining a tool and a process for capturing and conveying audiovisual impressions of everyday life. The project aims to enable a relationship between the user of the tool and an audience in a different place or time with an absolute minimum of editorial mediation by a third party. The tool itself incorporates a digital camera and a binaural audio recording device that captures the minute of sound before and after a picture is taken. To inform the design process, we tested prototypes in a progression of three studies within different cultural contexts in Ireland, France, and Mali. We present the results of these experiences, in which we observed among our participants an emerging set of ways of exploiting the tool for different purposes: social glances, depictions of activities, active documentation, and intentional discourses. We also discuss more generally the advantages and pitfalls of multicultural analyses of prototype technologies like the one we undertook.
2004	Revealing delay in collaborative environments	Delay is an unavoidable reality in collaborative environments. We propose an approach to dealing with delay in which 'decorators' are introduced into the interface. Decorators show the presence, magnitude and effects of delay so that participants can better understand its consequences and adopt their own natural coping strategies. Two experiments with different decorators show that this approach can significantly reduce errors in specific collaborative activities. We conclude that revealing delays is one way in which groupware can benefit from accepting and working with the reality of distributed systems, rather than trying to maintain the illusion of copresent interaction.
2004	Robotic camera control for remote exploration	A video stream from a single camera is often the foundation for situational awareness in teleoperation activities. Poor camera placement, narrow field-of-view and other camera properties can significantly impair the operator's perceptual link to the environment, inviting cognitive mistakes and general disorientation. This paper provides a brief overview of viewpoint control research for 3D virtual environments (VE) to motivate a user study that evaluates the effectiveness of viewpoint controls on a simulated robotic vehicle. Findings suggest that providing a camera that is controlled independently from the orientation of the vehicle may facilitate wayfinding tasks. Moreover, there is evidence to support the use of separate cameras and interfaces for different navigational subtasks.
2004	Semantic pointing: improving target acquisition with control-display ratio adaptation	We introduce semantic pointing, a novel interaction technique that improves target acquisition in graphical user interfaces (GUIs). Semantic pointing uses two independent sizes for each potential target presented to the user: one size in motor space adapted to its importance for the manipulation, and one size in visual space adapted to the amount of information it conveys. This decoupling between visual and motor size is achieved by changing the control-to-display ratio according to cursor distance to nearby targets. We present a controlled experiment supporting our hypothesis that the performance of semantic pointing is given by Fitts' index of difficulty in motor rather than visual space. We apply semantic pointing to the redesign of traditional GUI widgets by taking advantage of the independent manipulation of motor and visual widget sizes.
2004	Semantic speech editing	Editing speech data is currently time-consuming and error-prone. Speech editors rely on acoustic waveform representations, which force users to repeatedly sample the underlying speech to identify words and phrases to edit. Instead we developed a semantic editor that reduces the need for extensive sampling by providing access to meaning. The editor shows a time-aligned errorful transcript produced by applying automatic speech recognition (ASR) to the original speech. Users visually scan the words in the transcript to identify important phrases. They then edit the transcript directly using standard word processing 'cut and paste' operations, which extract the corresponding time-aligned speech. ASR errors mean that users must supplement what they read in the transcript by accessing the original speech. Even when there are transcript errors, however, the semantic representation still provides users with enough information to target what they edit and play, reducing the need for extensive sampling. A laboratory evaluation showed that semantic editing is more efficient than acoustic editing even when ASR is highly inaccurate.
2004	Sharp or smooth?: comparing the effects of quantization vs. frame rate for streamed video	We introduce a new methodology to evaluate the perceived quality of video with variable physical quality. The methodology is used to evaluate existing guidelines - that high frame rate is more important than quantization when watching high motion video, such as sports coverage. We test this claim in two studies that examine the relationship between these physical quality metrics and perceived quality. In Study 1, 41 soccer fans viewed CIF-sized images on a desktop computer. Study 2 repeated the experiment with 37 soccer fans, viewing the same content, in QCIF size, on a palmtop device. Contrary to existing guidelines, we found that users prefer high-resolution images to high frame rate. We conclude that the rule "high motion = high frame rate" does not apply to small screens. With small screen devices, reducing quantization removes important information about the players and the ball. These findings have important implications for service providers and designers of streamed video applications.
2004	Slash(dot) and burn: distributed moderation in a large online conversation space	Can a system of distributed moderation quickly and consistently separate high and low quality comments in an online conversation? Analysis of the site Slashdot.org suggests that the answer is a qualified yes, but that important challenges remain for designers of such systems. Thousands of users act as moderators. Final scores for comments are reasonably dispersed and the community generally agrees that moderations are fair. On the other hand, much of a conversation can pass before the best and worst comments are identified. Of those moderations that were judged unfair, only about half were subsequently counterbalanced by a moderation in the other direction. And comments with low scores, not at top-level, or posted late in a conversation were more likely to be overlooked by moderators.
2004	Social and temporal structures in everyday collaboration	Everyday work frequently involves coordinating and collaborating with others, but the structure of collaboration is largely invisible to conventional desktop applications. We are exploring ways to support everyday collaboration by allowing applications access to the social, organizational, and temporal settings within which work is conducted. In this paper, we present two generations of systems supporting everyday collaboration, focusing on ways to recover and represent the temporal and social structures of online activity.
2004	A social proxy for distributed tasks: design and evaluation of a working prototype	This paper describes an approach to managing tasks and processes that are distributed across a large number of people. The basic idea is to use a social visualization called a task proxy to create a shared awareness amongst the participants in a task or process. The process awareness provided by the task proxy enables its users to monitor the task state, the states of participants, and to communicate with those in particular states. We describe the concept, a first prototype, its evaluation, and discuss future directions.
2004	A study of digital ink in lecture presentation	Digital inking systems are becoming increasingly popular across a variety of domains. In particular, many systems now allow instructors to write on digital surfaces in the classroom. Yet, our understanding of how people actually use writing in these systems is limited. In this paper, we report on classroom use of writing in one such system, in which the instructor annotates projected slides using a Tablet PC. Through a detailed analysis of lecture archives, we identify key use patterns. In particular, we categorize a major use of ink as analogous to physical gestures and present a framework for analyzing this ink; we explore the relationship between the ephemeral meaning of many annotations and their persistent representation; and we observe that instructors make conservative use of the system's features. Finally, we discuss implications of our study to the design of future digital inking systems.
2004	Studying cooperation and conflict between authors with history flow visualizations	The Internet has fostered an unconventional and powerful style of collaboration: "wiki" web sites, where every visitor has the power to become an editor. In this paper we investigate the dynamics of Wikipedia, a prominent, thriving wiki. We make three contributions. First, we introduce a new exploratory data analysis tool, the history flow visualization, which is effective in revealing patterns within the wiki context and which we believe will be useful in other collaborative situations as well. Second, we discuss several collaboration patterns highlighted by this visualization tool and corroborate them with statistical analysis. Third, we discuss the implications of these patterns for the design and governance of online collaborative social spaces. We focus on the relevance of authorship, the value of community surveillance in ameliorating antisocial behavior, and how authors with competing perspectives negotiate their differences.
2004	Stuff goes into the computer and doesn't come out: a cross-tool study of personal information management	This paper reports a study of Personal Information Management (PIM), which advances research in two ways: (1) rather than focusing on one tool, we collected cross-tool data relating to file, email and web bookmark usage for each participant, and (2) we collected longitudinal data for a subset of the participants. We found that individuals employ a rich variety of strategies both within and across PIM tools, and we present new strategy classifications that reflect this behaviour. We discuss synergies and differences between tools that may be useful in guiding the design of tool integration. Our longitudinal data provides insight into how PIM behaviour evolves over time, and suggests how the supporting nature of PIM discourages reflection by users on their strategies. We discuss how the promotion of some reflection by tools and organizations may benefit users.
2004	A suggestive interface for image guided 3D sketching	We present an image guided pen-based suggestive interface for sketching 3D wireframe models. Rather than starting from a blank canvas, existing 2D images of similar objects serve as a guide to the user. Image based filters enable attraction, smoothing, and resampling of input curves, and allows for their selective application using pinning and gluing techniques. New input strokes also invoke suggestions of relevant geometry that can be used, reducing the need to explicitly draw all parts of the new model. All suggestions appear in-place with the model being built, in the user's focal attention space. A curve matching algorithm seamlessly augments basic suggestions with more complex ones from a database populated with previously used geometry. The interface also incorporates gestural command input, and interaction techniques for camera controls that enable smooth transitions between orthographic and perspective views.
2004	Supporting social presence through lightweight photo sharing on and off the desktop	Lightweight photo sharing, particularly via mobile devices, is fast becoming a common communication medium used for maintaining a presence in the lives of friends and family. How should such systems be designed to maximize this social presence while maintaining simplicity? An experimental photo sharing system was developed and tested that, compared to current systems, offers highly simplified, group-centric sharing, automatic and persistent people-centric organization, and tightly integrated desktop and mobile sharing and viewing. In an experimental field study, the photo sharing behaviors of groups of family or friends were studied using their normal photo sharing methods and with the prototype sharing system. Results showed that users found photo sharing easier and more fun, shared more photos, and had an enhanced sense of social presence when sharing with the experimental system. Results are discussed in the context of design principles for the rapidly increasing number of lightweight photo sharing systems.
2004	Tapping vs. circling selections on pen-based devices: evidence for different performance-shaping factors	Tapping-based selection methods for handheld devices may need to be supplemented with other approaches as increasingly complex tasks are carried out using those devices. Circling selection methods (such as the Lasso) allow users to select objects on a touch screen by circling with a pen. An experimental comparison of the selection time and accuracy between a circling method and a traditional tapping style of selection was carried out. The experiment used a two dimensional grid (varying in terms of the sizes and the distances of the targets). Analysis of variance showed that tapping selection time differed significantly depending on the size and spacing of the targets. In contrast, circling selection times differed significantly for different levels of target cohesiveness and shape complexity. The results are discussed in terms of implications for design of new pen-based selection methods for handheld devices, and also in terms of evaluation methodology for input selection methods.
2004	Telemurals: linking remote spaces with social catalysts	Telemurals is an abstract audio-video installation that seeks to initiate and sustain interaction between and within two remote spaces. Our goal is to improve the social aspects of casual mediated communications by incorporating events into the design of the communication medium that encourage people to engage in interaction when they otherwise would not. We call these events social catalysts, for they encourage people to initiate and sustain interaction. In this paper we discuss the design process and goals of our first Telemurals link between two public spaces, the building of Telemurals, and an ethnographic study describing how the system affected interaction between and within these two spaces based on the theories discussed in this paper.
2004	Telepresence control of the NASA/DARPA robonaut on a mobility platform	Engineers at the Johnson Space Center recently combined the upper body of the National Aeronautics and Space Administration (NASA) / Defense Advanced Research Projects Agency (DARPA) Robonaut system with a Robotic Mobility Platform (RMP) to make an extremely mobile humanoid robot designed to interact with human teammates. Virtual Reality gear that immerses a human operator into Robonaut's working environment provides the primary control pathway for remote operations. Human/robot interface challenges are addressed in the control system for teleoperators, console operators and humans working directly with the Robonaut. Multiple control modes are available for controlling the five fingered dexterous robot hands and operator selectable depending on the type of grasp required. A relative positioning system is used to maximize operator comfort during arm and head motions. Foot pedals control the mobility base. Initial tasks that include working with human rated tools, navigating hallways and cutting wires are presented and show the effectiveness of telepresence control for this class of robot.
2004	Think different: increasing online community participation using uniqueness and group dissimilarity	Online communities can help people form productive relationships. Unfortunately, this potential is not always fulfilled: many communities fail, and designers don't have a solid understanding of why. We know community activity begets activity. The trick, however, is to inspire participation in the first place. Social theories suggest methods to spark positive community participation. We carried out a field experiment that tested two such theories. We formed discussion communities around an existing movie recommendation web site, manipulating two factors: (1) similarity -we controlled how similar group members' movie ratings were; and (2) uniqueness -we told members how their movie ratings (with respect to a discussion topic) were unique within the group. Both factors positively influenced participation. The results offer a practical success story in applying social science theory to the design of online communities.
2004	TNT: a numeric keypad based text input method	With the evolving functionality in television-based (TV-based) information and entertainment appliances, there is an increased need to enable users input text through remote control devices. We present a novel text input method, The Numpad Typer (TNT), for interactive TV, multimedia home terminals or other similar applications. Embodied in a TV remote control and guided by a visual map on the TV screen, TNT was designed for consistent spatial Stimuli-Response (S-R) compatibility and consistency of use. Five users tested TNT in ten sessions of 45-minutes. This initial investigation showed that users on average could type 9.3 and 17.7 correct words per minute with TNT doing the slowest and the fastest session respectively. The study also showed that the users found the TNT method easy to grasp and fun to use. Subjectively the participants felt they mastered the method rather quickly in comparison to their actual speed improvement.
2004	Topobo: a constructive assembly system with kinetic memory	We introduce Topobo, a 3D constructive assembly system embedded with kinetic memory, the ability to record and playback physical motion. Unique among modeling systems is Topobo's coincident physical input and output behaviors. By snapping together a combination of Passive (static) and Active (motorized) components, people can quickly assemble dynamic biomorphic forms like animals and skeletons with Topobo,animate those forms by pushing, pulling, and twisting them, and observe the system repeatedly play back those motions. For example, a dog can be constructed and then taught to gesture and walk by twisting its body and legs. The dog will then repeat those movements and walk repeatedly.Our evaluation of Topobo in classrooms with children ages 5-13 suggests that children develop affective relationships with Topobo creations and that their experimentation with Topobo allows them to learn about movement and animal locomotion through comparisons of their creations to their own bodies. Eighth grade science students' abilities to quickly develop various types of walking robots suggests that a tangible interface can support understanding how balance, leverage and gravity affect moving structures because the interface itself responds to the forces of nature that constrain such systems.
2004	Transcendent communication: location-based guidance for large-scale public spaces	Many studies have been conducted on supporting communication in home and office spaces, but relatively few studies have explored supporting communication in large-scale public spaces, despite the importance of such environments in our daily lives. We propose a transcendent means of communication as an emerging style in this pervasive computing era: a system that allows administrative staff to effectively help visitors in large-scale public spaces. The visitors' context is used to provide a bird's-eye view of a simulated public space for the staff to grasp the situation and point at a particular location within the view to indicate the visitors they intend to address. The results of an experiment showed synergic effects between the bird's-eye view and the first-person one in determining the spatial movements of people. In indoor and outdoor large-scale public spaces, a central railway station and a park, we installed our prototypes and learned the implications of its use.
2004	Trust and mistrust of online health sites	Do different design and information content factors influence trust and mistrust of online health sites? Fifteen women faced with a risky health decision were observed while searching the Internet for information and advice over four consecutive weeks. In some sessions their searches were unstructured, whilst in other sessions they were directed to review specific sites, chosen for their trust design elements. Content analysis of concurrent verbalisations and group discussion protocols provided support for a staged model wherein design appeal predicted rejection (mistrust) and credibility of information and personalisation of content predicted selection (trust) of advice sites.
2004	Twiddler typing: one-handed chording text entry for mobile phones	An experienced user of the Twiddler, a one--handed chording keyboard, averages speeds of 60 words per minute with letter--by--letter typing of standard test phrases. This fast typing rate coupled with the Twiddler's 3x4 button design, similar to that of a standard mobile telephone, makes it a potential alternative to multi--tap for text entry on mobile phones. Despite this similarity, there is very little data on the Twiddler's performance and learnability. We present a longitudinal study of novice users' learning rates on the Twiddler. Ten participants typed for 20 sessions using two different methods. Each session is composed of 20 minutes of typing with multi--tap and 20 minutes of one--handed chording on the Twiddler. We found that users initially have a faster average typing rate with multi--tap; however, after four sessions the difference becomes negligible, and by the eighth session participants type faster with chording on the Twiddler. Furthermore, after 20 sessions typing rates for the Twiddler are still increasing.
2004	Ubiquitous computing for firefighters: field studies and prototypes of large displays for incident command	In this paper, we demonstrate how field studies, interviews, and low-fidelity prototypes can be used to inform the design of ubiquitous computing systems for firefighters. We describe the artifacts and processes used by firefighters to assess, plan, and communicate during emergency situations, showing how accountability affects these decisions, how their current Incident Command System supports these tasks, and some drawbacks of existing solutions. These factors informed the design of a large electronic display for supporting the incident commander, the person who coordinates the overall response strategy in an emergency. Although our focus was on firefighters, our results are applicable for other aspects of emergency response as well, due to common procedures and training.
2004	Understanding the micronote lifecycle: improving mobile support for informal note taking	People frequently write messages to themselves. These informal, hurried personal jottings serve as temporary storage for notable information as well as reminders for future action. Many mobile technologies have been designed specifically to support this ubiquitous behavior; however, adoption has been universally problematic. Despite its clear utility, the process of taking micronotes stubbornly resists computing support. This field study examines the lifecycles of the canonical micronote forms (immediate use, temporary storage, and prospective memory aid), pinpointing the behaviors that are mismatched with current mobile support. Implications for improving the design of these systems are presented, culminating in a vision for integrated paper-digital micronote systems. This shifts the development focus away from trying to support the entire micronote lifecycle, emphasizing instead the different behaviors best supported by the different technologies.
2004	Unintended effects: varying icon spacing changes users' visual search strategy	Users of modern GUIs routinely engage in visual searches for various control items, such as buttons and icons. Because this is so ubiquitous, it is important that the visual properties of user interfaces support such searches. The current research is aimed at deepening our understanding of how the visual spacing between icons affects visual search times. We constructed an experiment based on previous icon sets [8] where spacing between icons was systematically manipulated, and for which we had a computational cognitive model that predicted performance. In particular, the model predicted that larger spacing would lead to slower search times. While this prediction was borne out, there was an unanticipated finding: users in this new experiment were substantially slower than in previous similar experiments with smaller spacing. In fact, results from this new experiment were better fit with a model that employed a fundamentally different, and less efficient, search strategy. A second experiment was conducted to explicitly test the surprising result that this varied and larger icon spacing would lead to increased search times. Results were consistent with this hypothesis. These results imply that while small differences in visual layout may not intrinsically produce large differences in user performance, they may cause users to adopt suboptimal strategies that do produce such differences.
2004	The usability of massively multiplayer online roleplaying games: designing for new users	This study examines the usability challenges faced by new players of massively multiplayer online role-playing games (MMORPGs), one of the fastest-growing segments of the video game industry. Played in completely online worlds, these games allow players to communicate with one another, form groups and communities, and compete in a variety of fantasy environments.Nineteen subjects participated in an exploratory usability study of four games, three MMORPGs and a similar single-player game used for comparison. Results reveal that many people not usually considered as potential players of these games may be interested in them, but a wide variety of usability issues present serious problems for players inexperienced with the genre. Based on an analysis of the usability data and player feedback, specific recommendations are made to improve the experience of these games for new players. These results further demonstrate the applicability and importance of usability testing to video games.
2004	Variation in element and action: supporting simultaneous development of alternative solutions	The complexity of many problems necessitates creating and exploring multiple, alternative solutions. However, current user interfaces do not cleanly support creating alternatives at a time when they are likely to be discovered: as users interactively modify data. This paper presents Parallel Paths, a novel model of interaction that facilitates generating, manipulating, and comparing alternative solutions. In contrast to existing approaches such as automated history capture tools, Parallel Paths emphasizes the active, simultaneous development of multiple, alternative solutions. We demonstrate this model of interaction in Parallel Pies, a user interface mechanism developed for image manipulation tasks that allows users to: easily create solution alternatives as they interact with a command; embed the alternatives in the same workspace; manipulate the alternatives independently or simultaneously as if they were the same object; and perform side-by-side comparisons of each. Results from an initial evaluation are presented, along with implications for future designs.
2004	Virtual guiding avatar: an effective procedure to reduce simulator sickness in virtual environments	This study developed a new procedure, a Virtual Guiding Avatar (VGA), which combined self-motion prediction cues and an independent visual background (IVB) to alleviate simulator sickness (SS). The VGA, which was embodied as an abstract airplane, was designed to lead the participant along a horizontal motion trajectory through a virtual environment. Both motion prediction cues and IVBs, which provide an earth-fixed reference frame, reduced SS in separate previous studies. Participants were exposed to complex visual motion through a cartoon-like simulated environment in a very wide field of view driving simulator. Participants' responses to avatars with varying motion properties - fixed, rotation only or rotation plus translation - were assessed using a within-subjects experimental design. Results indicated that SS was reduced by a VGA that presented rotational cues alone or rotation plus translation. The VGA also increased participants' sense of presence and enjoyment relative to conditions lacking a VGA. The VGA procedure can be used to enhance user experiences in immersive virtual environments as well as to improve motion simulator design.
2004	WaveLens: a new view onto Internet search results	Internet search results are typically displayed as a list conforming to a static style sheet. The difficulty of perusing this list can be exacerbated when screen real estate is limited. When space is limited, either, few results are seen, or result descriptions are abbreviated, making it difficult to know whether to follow a particular web link. In this paper, we describe "WaveLens," a dynamic layout technique for displaying search results, which addresses these issues by combining a fisheye lens with progressive exposure of page content. Results from a usability study showed that participants performed faster and more accurately on a search task with one of two distinct parameter settings of WaveLens as compared to the typical static list. In a post-hoc questionnaire, participants favored that setting over both the static list and another setting which involved animated zoom. We discuss design implications for the retrieval and display of search results.
2004	What a to-do: studies of task management towards the design of a personal task list manager	This paper reports on the results of studies of task management to support the design of a task list manager. We examined the media used to record and organize to-dos and tracked how tasks are completed over time. Our work shows that, contrary to popular wisdom, people are not poor at prioritizing. Rather, they have well-honed strategies for tackling particular task management challenges. By illustrating what factors influence task completion and how representations function to support task management, we hope to provide a strong foundation for the design of a personal to-do list manager. We also present some preliminary efforts in this direction.
2005	The bubble cursor: enhancing target acquisition by dynamic resizing of the cursor's activation area	We present the bubble cursor - a new target acquisition technique based on area cursors. The bubble cursor improves upon area cursors by dynamically resizing its activation area depending on the proximity of surrounding targets, such that only one target is selectable at any time. We also present two controlled experiments that evaluate bubble cursor performance in 1D and 2D target acquisition tasks, in complex situations with multiple targets of varying layout densities. Results show that the bubble cursor significantly outperforms the point cursor and the object pointing technique [7], and that bubble cursor performance can be accurately modeled and predicted using Fitts' law.
2005	Comparing cursor orientations for mouse, pointer, and pen interaction	Most graphical user interfaces provide visual cursors to facilitate interaction with input devices such as mice, pointers, and pens. These cursors often include directional cues that could influence the stimulus-response compatibility of user input. We conducted a controlled evaluation of four cursor orientations and an orientation-neutral cursor in a circular menu selection task. Mouse interaction on a desktop, pointer (i.e. wand) interaction on a large screen, and pen interaction on a Tablet PC were evaluated. Our results suggest that choosing appropriate cursors is especially important for pointer interaction, but may be less important for mice or pens. Cursors oriented toward the lower-right corner of a display yielded the poorest performance overall while orientation-neutral cursors were generally the best. Advantages were found for orientations aligned with the direction of movement. We discuss these results and suggest guidelines for the appropriate use of cursors in various input and display configurations.
2005	Snap-and-go: helping users align objects without the modality of traditional snapping	Snapping is a widely used technique that helps users position graphical objects precisely, e.g., to align them with a grid or other graphical objects. Unfortunately, whenever users want to position a dragged object close to such an aligned location, they first need to deactivate snapping. We propose snap-and-go , a snapping technique that overcomes this limitation. By merely stopping dragged objects at aligned positions, rather than "warping" them there, snap-and-go helps users align objects, yet still allows placing dragged objects anywhere else. While this approach of inserting additional motor space renders snap-and-go slightly slower than traditional snapping, snap-and-go simplifies the user interface by eliminating the need for a deactivation option and thereby allows introducing snapping to application scenarios where traditional snapping is inapplicable. In our user studies, participants were able to align objects up to 138\% (1D) and 231\% (2D) faster with snap-and-go than without and snap-and-go proved robust against the presence of distracting snap targets.
2005	Towards an index of opportunity: understanding changes in mental workload during task execution	To contribute to systems that reason about human attention, our work empirically demonstrates how a user's mental workload changes during task execution. We conducted a study where users performed interactive, hierarchical tasks while mental workload was measured through the use of pupil size. Results show that (i) different types of subtasks impose different mental workload, (ii) workload decreases at subtask boundaries, (iii) workload decreases more at boundaries higher in a task model and less at boundaries lower in the model, (iv) workload changes among subtask boundaries within the same level of a task model, and (v) effective understanding of why changes in workload occur requires that the measure be tightly coupled to a validated task model. From the results, we show how to map mental workload onto a computational Index of Opportunity that systems can use to better reason about human attention.
2005	No task left behind?: examining the nature of fragmented work	We present data from detailed observation of 24 information workers that shows that they experience work fragmentation as common practice. We consider that work fragmentation has two components: length of time spent in an activity, and frequency of interruptions. We examined work fragmentation along three dimensions: effect of collocation, type of interruption, and resumption of work. We found work to be highly fragmented: people average little time in working spheres before switching and 57\% of their working spheres are interrupted. Collocated people work longer before switching but have more interruptions. Most internal interruptions are due to personal work whereas most external interruptions are due to central work. Though most interrupted work is resumed on the same day, more than two intervening activities occur before it is. We discuss implications for technology design: how our results can be used to support people to maintain continuity within a larger framework of their working spheres.
2005	Examining task engagement in sensor-based statistical models of human interruptibility	The computer and communication systems that office workers currently use tend to interrupt at inappropriate times or unduly demand attention because they have no way to determine when an interruption is appropriate. Sensor?based statistical models of human interruptibility offer a potential solution to this problem. Prior work to examine such models has primarily reported results related to social engagement, but it seems that task engagement is also important. Using an approach developed in our prior work on sensor?based statistical models of human interruptibility, we examine task engagement by studying programmers working on a realistic programming task. After examining many potential sensors, we implement a system to log low?level input events in a development environment. We then automatically extract features from these low?level event logs and build a statistical model of interruptibility. By correctly identifying situations in which programmers are non?interruptible and minimizing cases where the model incorrectly estimates that a programmer is non?interruptible, we can support a reduction in costly interruptions while still allowing systems to convey notifications in a timely manner.
2005	Urban probes: encountering our emerging urban atmospheres	Urban Atmospheres captures a unique, synergistic moment - expanding urban populations, rapid adoption of Bluetooth mobile devices, tiny ad hoc sensor networks, and the widespread influence of wireless technologies across our growing urban landscapes. The United Nations recently reported that 48 percent of the world's population current live in urban areas and that this number is expected to exceed the 50 percent mark world wide by 2007 [1]. In developed nations the number of urban dwellers is even more dramatic - expected to exceed 75\%. Current studies project Bluetooth-enabled devices to reach 5.4 billion units by 2005 - five times the number of mobile phones or Internet connections [2]. Mobile phone penetration already exceeds 80\% of the population in places like the European Union (EU) and parts of Asia [3]. WiFi hardware is being deployed at the astonishing rate of one every 4 seconds globally [4]. We argue that now is the time to initiate inspirational research into the very essence of these newly emerging technological urban spaces. We desire to move towards an improved understanding of the emotional experience of urban life. This paper describes Urban Probes - a lightweight, provocative, intervention methodology designed to rapidly deconstruct urban situations, reveal new opportunities for technology in urban spaces, and guide future long term research in urban computing. We also describe a completed Urban Probe exploring urban trash.
2005	DeDe: design and evaluation of a context-enhanced mobile messaging system	This paper presents the design, implementation and validation of an enhanced mobile phone messaging system (DeDe), allowing the sender to define the context in which the message will be delivered to the recipient. A field trial among a socially tight group of teenagers showed that the DeDe feature was incorporated as part of the participants' existing messaging culture. 11,4\% of their total messaging output made use of the DeDe feature. The most frequently used context parameters were location (based on network cell-ID) and time. Novel message practices emerged, as compared to 'normal' messaging, both in terms of timing of message sending, as well as creating content that specifically exploited the DeDe feature. Some use barriers were recognized, the most important being the sender's uncertainty of delivery success. Implications for design are discussed.
2005	The vacuum: facilitating the manipulation of distant objects	We present the design and evaluation of the vacuum, a new interaction technique that enables quick access to items on areas of a large display that are difficult for a user to reach without significant physical movement. The vacuum is a circular widget with a user controllable arc of influence that is centered at the widget's point of invocation and spans out to the edges of the display. Far away objects residing inside this influence arc are brought closer to the widget's centre in the form of proxies that can be manipulated in lieu of the original. We conducted two experiments which compare the vacuum to direct picking and an existing technique called drag-and-pick [2]. Results show that the vacuum outperforms existing techniques when selecting multiple targets in a sequence, performs similarly to existing techniques when selecting single targets located moderately far away, and slightly worse with single targets located very far away in the presence of distracter targets along the path.
2005	A comparison of techniques for multi-display reaching	Recent advances in multi-user collaboration have seen a proliferation of interaction techniques for moving digital objects from one device to another. However, little is known about how these techniques work in realistic situations, or how they compare to one another. We conducted a study to compare the efficiency of six techniques for moving objects from a tablet to a tabletop display. We compared the techniques in four different distance ranges and with three movement directions. We found that techniques like the Radar View and Pick-and-Drop, that have a control-to-display ratio of 1, are significantly faster for object movement than techniques that have smaller control-to-display ratios. We also found that using spatial manipulation of objects was faster than pressure-based manipulation.
2005	Extensible input handling in the subArctic toolkit	The subArctic user interface toolkit has extensibility as one of its central goals. It seeks not only to supply a powerful library of reusable interactive objects, but also make it easy to create new, unusual, and highly customized interactions tailored to the needs of particular interfaces or task domains. A central part of this extensibility is the input model used by the toolkit. The subArctic input model provides standard reusable components that implement many typical input handling patterns for the programmer, allows inputs to be handled in very flexible ways, and allows the details of how inputs are handled to be modified to meet custom needs. This paper will consider the structure and operation of the subArctic input handling mechanism. It will demonstrate the flexibility of the system through a series of examples, illustrating techniques that it enables - many of which would be very difficult to implement in most toolkits.
2005	Comparing usability problems and redesign proposals as input to practical systems development	Usability problems predicted by evaluation techniques are useful input to systems development; it is uncertain whether redesign proposals aimed at alleviating those problems are likewise useful. We present a study of how developers of a large web application assess usability problems and redesign proposals as input to their systems development. Problems and redesign proposals were generated by 43 evaluators using an inspection technique and think aloud testing. Developers assessed redesign proposals to have higher utility in their work than usability problems. In interviews they explained how redesign proposals gave them new ideas for tackling well known problems. Redesign proposals were also seen as constructive and concrete input. Few usability problems were new to developers, but the problems supported prioritizing ongoing development of the application and taking design decisions. No developers, however, wanted to receive only problems or redesigns. We suggest developing and using redesign proposals as an integral part of usability evaluation.
2005	A method to standardize usability metrics into a single score	Current methods to represent system or task usability in a single metric do not include all the ANSI and ISO defined usability aspects: effectiveness, efficiency & satisfaction. We propose a method to simplify all the ANSI and ISO aspects of usability into a single, standardized and summated usability metric (SUM). In four data sets, totaling 1860 task observations, we show that these aspects of usability are correlated and equally weighted and present a quantitative model for usability. Using standardization techniques from Six Sigma, we propose a scalable process for standardizing disparate usability metrics and show how Principal Components Analysis can be used to establish appropriate weighting for a summated model. SUM provides one continuous variable for summative usability evaluations that can be used in regression analysis, hypothesis testing and usability reporting.
2005	Supporting efficient development of cognitive models at multiple skill levels: exploring recent advances in constraint-based modeling	This paper presents X-PRT, a new cognitive modeling tool supporting activities ranging from interface design to basic cognitive research. X-PRT provides a graphical model development environment for the CORE constraint-based cognitive modeling engine [7,13,21]. X-PRT comprises a novel feature set: (a) it supports the automatic generation of predictive models at multiple skill levels from a single task-specification, (b) it supports a comprehensive set of modeling activities, and (c) it supports compositional reuse of existing cognitive/perceptual/motor skills by transforming high-level, hierarchical task descriptions into detailed performance predictions. Task hierarchies play a central role in X-PRT, serving as the organizing construct for task knowledge, the locus for compositionality, and the cognitive structures over which the learning theory is predicated. Empirical evidence supports the role of task hierarchies in routine skill acquisition.
2005	prefuse: a toolkit for interactive information visualization	Although information visualization (infovis) technologies have proven indispensable tools for making sense of complex data, wide-spread deployment has yet to take hold, as successful infovis applications are often difficult to author and require domain-specific customization. To address these issues, we have created prefuse, a software framework for creating dynamic visualizations of both structured and unstructured data. prefuse provides theoretically-motivated abstractions for the design of a wide range of visualization applications, enabling programmers to string together desired components quickly to create and customize working visualizations. To evaluate prefuse we have built both existing and novel visualizations testing the toolkit's flexibility and performance, and have run usability studies and usage surveys finding that programmers find the toolkit usable and effective.
2005	Visualization of mappings between schemas	In this paper we describe a novel approach to the visualization of the mapping between two schemas. Current approaches to visually defining such a mapping fail when the schemas or maps become large. The new approach uses various information visualization techniques to simplify the view, making it possible for users to effectively deal with much larger schemas and maps. A user study verifies that the new approach is useful, usable, and effective. The primary contribution is a demonstration of novel ways to effectively present highly complex information.
2005	Improving aviation safety with information visualization: a flight simulation study	Many aircraft accidents each year are caused by encounters with invisible airflow hazards. Recent advances in aviation sensor technology offer the potential for aircraft-based sensors that can gather large amounts of airflow velocity data in real-time. With this influx of data comes the need to study how best to present it to the pilot - a cognitively overloaded user focused on a primary task other than that of information visualization.We focus on one particular aviation application, but the results may be relevant to user interfaces in other operationally stressful environments.
2005	Design and analysis of delimiters for selection-action pen gesture phrases in scriboli	We present a quantitative analysis of delimiters for pen gestures. A delimiter is "something different" in the input stream that a computer can use to determine the structure of input phrases. We study four techniques for delimiting a selection-action gesture phrase consisting of lasso selection plus marking-menu-based command activation. Pigtail is a new technique that uses a small loop to delimit lasso selection from marking (Fig. 1). Handle adds a box to the end of the lasso, from which the user makes a second stroke for marking. Timeout uses dwelling with the pen to delimit the lasso from the mark. Button uses a button press to signal when to delimit the gesture. We describe the role of delimiters in our Scriboli pen interaction testbed, and show how Pigtail supports scope selection, command activation, and direct manipulation all in a single fluid pen gesture.
2005	Experimental analysis of mode switching techniques in pen-based user interfaces	Inking and gesturing are two central tasks in pen-based user interfaces. Switching between modes for entry of uninterpreted ink and entry of gestures is required by many pen-based user interfaces. Without an appropriate mode switching technique, pen-based interactions in such situations may be inefficient and cumbersome. In this paper, we investigate five techniques for switching between ink and gesture modes in pen interfaces, including a pen-pressure based mode switching technique that allows implicit mode transition. A quantitative experimental study was conducted to evaluate the performance of these techniques. The results suggest that pressing a button with the non-preferred hand offers the fastest performance, while the technique of holding the pen still is significantly slower and more prone to error than the other techniques. Pressure, while promising, did not perform as well as the non-preferred hand button with our current implementation.
2005	Mediating intimacy: designing technologies to support strong-tie relationships	Intimacy is a crucial element of domestic life, and many interactive technologies designed for other purposes have been appropriated for use within intimate relationships. However, there is a deficit in current understandings of how technologies are used within intimate relationships, and how to design technologies to support intimate acts. In this paper we report on work that has addressed these deficits. We used cultural probes and contextual interviews and other ethnographically informed techniques to investigate how interactive technologies are used within intimate relationships. From this empirical work we generated a thematic understanding of intimacy and the use of interactional technologies to support intimate acts. We used this understanding to inform the design of intimate technologies. A selection of our design concepts is also presented.
2005	Toward subtle intimate interfaces for mobile devices using an EMG controller	Using a mobile device in a social context should not cause embarrassment and disruption to the immediate environment. Interaction with mobile and wearable devices needs to be subtle, discreet and unobtrusive. Therefore, we promote the idea of "intimate interfaces": discrete interfaces that allow control of mobile devices through subtle gestures in order to gain social acceptance. To achieve this goal, we present an electromyogram (EMG) based wearable input device which recognizes isometric muscular activity: activity related to very subtle or no movement at all. In the online experiment reported, the EMG device, worn on an armband around the bicep, was able to reliably recognize a motionless gesture without calibration or training across users with different muscle volumes. Hence, EMG-based input devices can provide an effective solution for designing mobile interfaces that are subtle and intimate, and therefore socially acceptable.
2005	Emotions and heart rate while sitting on a chair	New methods for unobtrusive monitoring of computer users' emotion psychophysiology are very much needed in human-computer interaction research. The present aim was to study heart rate changes during emotionally provocative stimulation. Six-second long auditory, visual, and audiovisual emotionally negative, neutral, and positive stimuli were presented to 24 participants. Heart rate responses were measured with a regular office chair embedded with electromechanical film (the EMFi chair) and with traditional earlobe photoplethysmography (PPG). Ratings of the stimuli were also collected. The results showed that the two heart rate measurements were significantly correlated, r = 0.99. In line with other studies the results showed that, in general, heart rate decelerated in response to emotional stimulation and it decelerated the most in response to negative stimuli as compared with responses to positive and neutral stimuli. Especially, emotional stimulation caused significant changes in heart rate at the 6th second from the stimulus onset. We suggest that the EMFi chair could be used in human-computer interaction for unobtrusive measurement of the user's emotional reactions.
2005	A visual recipe book for persons with language impairments	Cooking is a daily activity for many people. However, traditional text recipes are often prohibitively difficult to follow for people with language disorders, such as aphasia. We have developed a multi-modal application that leverages the retained ability of aphasic individuals to recognize image-based representations of objects, providing a presentation format that can be more easily followed than a traditional text recipe. Through a systematic approach to developing a visual language for cooking, and the subsequent case study evaluation of a prototype developed according to this language, we show that a combination of visual instructions and navigational structure can help individuals with relatively large language deficits to cook more independently.
2005	Participatory design of an orientation aid for amnesics	We present the participatory design and evaluation of an orientation aid for individuals who have anterograde amnesia. Our design team included six amnesics who have extreme difficulty storing new memories. We describe the methods we used to enable the participation of individuals with such severe cognitive impairments. Through this process, we have conceived, designed, and developed the OrientingTool, a software application for Personal Digital Assistants that can be used by amnesics to orient themselves when feeling lost or disoriented. Two complementary studies were conducted to evaluate the effectiveness of this tool in ecologically valid contexts. Our findings suggest that the OrientingTool can improve an amnesic's independence and confidence in managing situations when disoriented, and that participatory design may be productively used with participants who have significant cognitive disabilities.
2005	Digital Family Portrait Field Trial: Support for Aging in Place	As the use of mobile data services has spread across the globe, the effect of cultural differences on user requirements has become important issue. To date, however, little research has been conducted on the role cultural factors play in the design of mobile data services. This paper proposes a set of critical design attributes for mobile data services that takes cross-cultural differences into account. To determine these attributes, we devised a qualitative method and conducted in-depth long interviews in Korea, Japan, and Finland. We found 52 attributes considered important by mobile data service users, and 11 critical attributes that showed a clear correlation with characteristics of the user's culture. The paper concludes with a discussion of limitations and of implications for developers of mobile data services.
2005	Livenotes: a system for cooperative and augmented note-taking in lectures	We describe Livenotes, a shared whiteboard system and educational practice that uses wireless communication and tablet computing to support real-time conversations within small groups of students during lectures, independent of class size. We present an interface design that enables group members to interact with one another by taking lecture notes cooperatively, as well as to augment student note-taking by providing instructor slides in the background to annotate over. Livenotes was designed to facilitate more efficient, stimulating modes of learning that other collaborative approaches do not. We report how the system impacts cooperative learning in an undergraduate class and how students interacted with background slides in the workspace. We conclude with directions for improving the system and learning practice.
2005	Stencils-based tutorials: design and evaluation	Users of traditional tutorials and help systems often have difficulty finding the components described or pictured in the procedural instructions. Users also unintentionally miss steps, and perform actions that the documentation's authors did not intend, moving the application into an unknown state. We introduce Stencils, an interaction technique for presenting tutorials that uses translucent colored stencils containing holes that direct the user's attention to the correct interface component and prevent the user from interacting with other components. Sticky notes on the stencil's surface provide necessary tutorial material in the context of the application. In a user study comparing a Stencils-based and paper-based version of the same tutorial in Alice, a complex software application designed to teach introductory computer programming, we found that users of a Stencils-based tutorial were able complete the tutorial 26\% faster, with fewer errors, and less reliance on human assistance. Users of the Stencils-based and paper-based tutorials attained statistically similar levels of learning.
2005	StudioBRIDGE: using group, location, and event information to bridge online and offline encounters for co-located learning groups	StudioBRIDGE is an awareness system, based on instant messaging (IM), developed for students working in open studio spaces in the Architecture Department at the Massachusetts Institute of Technology (MIT). The goal of StudioBRIDGE is to help students initiate online and offline interactions by giving them an awareness of nearby people, groups, locations, and events of the community. Even when students are working in close proximity to each other, they are often not aware of the activities and expertise of their colleagues nearby. We believe that this integrated awareness could lead to increased peer learning and expertise sharing by encouraging informal social communication, particularly in groups whose members have existing social and physical ties. In this paper, we describe the user community and the motivation, design, and initial pilot deployment of StudioBRIDGE.
2005	Calling while driving: effects of providing remote traffic context	Cell phone conversations distract drivers. This research explores the possibility of reducing distracting by providing callers with remote information about the driver's traffic. We asked whether providing such contextual information would change the caller's conversation such that drivers would be less distracted. In Experiment 1 we examined this question in a low-fidelity driving simulator; in Experiment 2 we examined this question in a higher fidelity simulator. In both experiments, remote callers and passengers were distracting. Providing traffic information to the remote caller significantly reduced crashes in the low fidelity tests and significantly reduced passing in the high fidelity tests, compared with the control conditions. We consider the implications for development of remote displays or signals to promote driving safety.
2005	Studying the effectiveness of MOVE: a contextually optimized in-vehicle navigation system	In-vehicle navigation has changed substantially in recent years, due to the advent of computer generated maps and directions. However, these maps are still problematic, due to a mismatch between the complexity of the maps and the attentional demands of driving. In response to this problem, we are developing the MOVE (Maps Optimized for Vehicular Environments) system. This system will provide situationally appropriate map information by presenting information that uses appropriate amounts of the driver's attention. In this paper, we describe our findings of studies to help shape the design of the MOVE system, including studies on map reading and in-vehicle navigation, and studies on the effectiveness of a variety of contextually optimized route map visualizations in a simulated driving context.Results show that contextually optimized displays designed for the MOVE system should significantly reduce perceptual load in the context of driving. In our laboratory experiment there was a six-fold decrease in the total map display fixation time and nearly threefold decrease in the number of glances needed to interpret the contextually optimized display compared to a static display.
2005	Distract-R: rapid prototyping and evaluation of in-vehicle interfaces	As driver distraction from in-vehicle devices increasingly becomes a concern on our roadways, researchers have searched for better scientific understanding of distraction along with better engineering tools to build less distracting devices. This paper presents a new system, Distract-R, that allows designers to rapidly prototype and evaluate new in-vehicle interfaces. The core engine of the system relies on a rigorous cognitive model of driver performance, which the system integrates with models of behavior on the prototyped interfaces to generate predictions of distraction. Distract-R allows a designer to prototype basic interfaces, demonstrate possible tasks on these interfaces, specify relevant driver characteristics and driving scenarios, and finally simulate, visualize, and analyze the resulting behavior as generated by the cognitive model. The paper includes two sample studies that demonstrate the system's ability to account for effects of input modality and driver age on performance.
2005	Paper windows: interaction techniques for digital paper	In this paper, we present Paper Windows, a prototype windowing environment that simulates the use of digital paper displays. By projecting windows on physical paper, Paper Windows allows the capturing of physical affordances of paper in a digital world. The system uses paper as an input device by tracking its motion and shape with a Vicon Motion Capturing System. We discuss the design of a number of interaction techniques for manipulating information on paper displays.
2005	Fluid integration of rotation and translation	Previous research has shown that rotation and orientation of items plays three major roles during collaboration: comprehension, coordination and communication. Based on these roles of orientation and advice from kinesiology research, we have designed the Rotate'N Translate (RNT) interaction mechanism, which provides integrated control of rotation and translation using only a single touch-point for input. We present an empirical evaluation comparing RNT to a common rotation mechanism that separates control of rotation and translation. Results of this study indicate RNT is more efficient than the separate mechanism and better supports the comprehension, coordination and communication roles of orientation.
2005	A study on the manipulation of 2D objects in a projector/camera-based augmented reality environment	Are the object manipulation techniques traditionally used in head-mounted displays (HMDs) applicable to augmented reality based projection systems? This paper examines the differences between HMD- and projector/camera-based AR interfaces in the light of a manipulation task involving documents and applications projected on common office surfaces such as tables, walls, cabinets, and floor. We report a Wizard of Oz study where subjects were first asked to create gesture/voice commands to move 2D objects on those surfaces and then exposed to gestures created by the authors. Among the options, subjects could select the object to be manipulated using voice command; touching, pointing, and grabbing gesture; or a virtual mouse. The results show a strong preference for a manipulation interface based on pointing gestures using small hand movements and involving minimal body movement. Direct touching of the object was also common when the object being manipulated was within the subjects' arm reach. Based on these results, we expect that the preferred interface resembles, in many ways, the egocentric model traditionally used in AR.
2005	Exploring technology adoption and use through the lens of residential mobility	One of the outcomes of massive adoption of technology is that much of daily technology use and consumption is embedded into "unremarkable" daily life routines. Occasionally, these routines undergo major shifts, often in conjunction with major life events such as marriage, birth of a child, or a residential move. We propose a model of settling into a new location as a function of balance between the pull of the things left behind and the demands of the new and unknown. It is through this experience of being unsettled that we explore the processes of behavior adjustment and re-evaluation of old patterns of technology use as it relates to the old location and the demands of the new location.
2005	Waterbot: exploring feedback and persuasive techniques at the sink	This paper presents an exploration of user interfaces, persuasive interfaces and feedback techniques in the domain of the sink. Waterbot is a system to inform and motivate behavior at the sink for the purpose of increasing safety and functionality and ultimately motivating behavior change. Waterbot can be adapted to many current sink scenarios and demonstrates the breadth of interaction possible at the point of use of water. It functions as a platform for experimenting with safety, hygiene and water conservation in a sink. This paper presents the feedback and persuasion techniques of augmented physical interfaces with value-added design, automation, just-in-time prompts, positive and negative reinforcement, social validation and adaptive interfaces. Four design iterations are presented to affect behavior at the increasing cognitive levels of safety, functionality and behavior change.
2005	Artful systems in the home	In this paper we introduce the idea of organizing systems. Through a number of examples from an ongoing ethnographic study of family life, we suggest that organizing systems come about through the artful design and use of informational artifacts in the home, such as calendars, paper notes, to-do lists, etc. These systems are not only seen to organize household routines and schedules, but also, crucially, to shape the social relations between family members. Drawing attention to the material properties of informational artifacts and how assemblies of these artifacts come to make up organizing systems, we discuss some general implications for designing information technology for the home. Most importantly, we suggest that technologies must be designed to accommodate the rich and diverse ways in which people organize their homes, providing them with the resources to artfully construct their own systems rather than enforcing ones that are removed from their own experiences.
2005	Applying the lessons of the attack on the world trade center, 11th September 2001, to the design and use of interactive evacuation simulations	The collapse of buildings, such as terminal 2E at Paris' Charles de Gaule Airport, and of fires, such as the Rhode Island, Station Night Club tragedy, has focused public attention on the safety of large public buildings. Initiatives in the United States and in Europe have led to the development of interactive simulators that model evacuation from these buildings. The tools avoid some of the ethical and legal problems from simulating evacuations; many people were injured during the 1993 evacuation of the World Trade Center (WTC) complex. They also use many concepts that originate within the CHI communities. For instance, some simulators use simple task models to represent the occupants' goal structures as they search for an available exit. However, the recent release of the report from the National Commission on Terrorist Attacks upon the United States (the '9/11 commission') has posed serious questions about the design and use of this particular class of interactive systems. This paper argues that simulation research needs to draw on insights from the CHI communities in order to meet some the challenges identified by the 9/11 commission.
2005	A qualitative cross-national study of cultural influences on mobile data service design	As the use of mobile data services has spread across the globe, the effect of cultural differences on user requirements has become important issue. To date, however, little research has been conducted on the role cultural factors play in the design of mobile data services. This paper proposes a set of critical design attributes for mobile data services that takes cross-cultural differences into account. To determine these attributes, we devised a qualitative method and conducted in-depth long interviews in Korea, Japan, and Finland. We found 52 attributes considered important by mobile data service users, and 11 critical attributes that showed a clear correlation with characteristics of the user's culture. The paper concludes with a discussion of limitations and of implications for developers of mobile data services.
2005	Learning user interest for image browsing on small-form-factor devices	Mobile devices which can capture and view pictures are becoming increasingly common in our life. The limitation of these small-form-factor devices makes the user experience of image browsing quite different from that on desktop PCs. In this paper, we first present a user study on how users interact with a mobile image browser with basic functions. We found that on small displays, users tend to use more zooming and scrolling actions in order to view interesting regions in detail. From this fact, we designed a new method to detect user interest maps and extract user attention objects from the image browsing log. This approach is more efficient than image-analysis based methods and can better represent users' actual interest. A smart image viewer was then developed based on user interest analysis. A second experiment was carried out to study how users behave with such a viewer. Experimental results demonstrate that the new smart features can improve the browsing efficiency and are a good compliment to traditional image browsers.
2005	Summary thumbnails: readable overviews for small screen web browsers	In order to display web pages designed for desktop-sized monitors, some small-screen web browsers provide single-column or thumbnail views. Both have limitations. Single-column views affect page layouts and require users to scroll significantly more. Thumbnail views tend to reduce contained text beyond readability, so differentiating visually similar areas requires users to zoom. In this paper, we present Summary Thumbnails -thumbnail views enhanced with readable text fragments. Summary Thumbnails help users identify viewed material and distinguish between visually similar areas. In our user study, participants located content in web pages about 41\% faster and with 71\% lower error rates when using the Summary Thumbnail interface than when using the Single-Column interface, and zoomed 59\% less than when using the Thumbnail interface. Nine of the eleven participants preferred Summary Thumbnails over both the Thumbnail and Single-Column interfaces.
2005	Understanding email use: predicting action on a message	Email consumes significant time and attention in the workplace. We conducted an organizational survey to understand how and why people attend to incoming email messages. We examined people's ratings of message importance and the actions they took on specific email messages, based on message characteristics and characteristics of receivers and senders. Respondents kept half of their new messages in the inbox and replied to about a third of them. They rated messages as important if they were about work and required action. Importance, in turn, had a modest impact on whether people replied to their incoming messages and whether they saved them. The results indicate that factors other than message importance (e.g., their social nature) also determine how people handle email. Overall, email usage reflects attentional differences due both to personal propensities and to work demands and relationships.
2005	How to make secure email easier to use	Cryptographically protected email has a justly deserved reputation of being difficult to use. Based on an analysis of the PEM, PGP and S/MIME standards and a survey of 470 merchants who sell products on Amazon.com, we argue that the vast majority of Internet users can start enjoying digitally signed email today. We present suggestions for the use of digitally signed mail in e-commerce and simple modifications to webmail systems that would significantly increase integrity, privacy and authorship guarantees that those systems make. We then show how to use the S/MIME standard to extend such protections Internet-wide. Finally, we argue that software vendors must make minor changes to the way that mail clients store email before unsophisticated users can safely handle mail that is sealed with encryption.
2005	Designing human friendly human interaction proofs (HIPs)	HIPs, or Human Interactive Proofs, are challenges meant to be easily solved by humans, while remaining too hard to be economically solved by computers. HIPs are increasingly used to protect services against automatic script attacks. To be effective, a HIP must be difficult enough to discourage script attacks by raising the computation and/or development cost of breaking the HIP to an unprofitable level. At the same time, the HIP must be easy enough to solve in order to not discourage humans from using the service. Early HIP designs have successfully met these criteria [1]. However, the growing sophistication of attackers and correspondingly increasing profit incentives have rendered most of the currently deployed HIPs vulnerable to attack [2,7,12]. Yet, most companies have been reluctant to increase the difficulty of their HIPs for fear of making them too complex or unappealing to humans. The purpose of this study is to find the visual distortions that are most effective at foiling computer attacks without hindering humans. The contribution of this research is that we discovered that 1) automatically generating HIPs by varying particular distortion parameters renders HIPs that are too easy for computer hackers to break, yet humans still have difficulty recognizing them, and 2) it is possible to build segmentation-based HIPs that are extremely difficult and expensive for computers to solve, while remaining relatively easy for humans.
2005	Life on the edge: supporting collaboration in location-based experiences	We study a collaborative location-based game in which groups of 'lions' hunt together on a virtual savannah that is overlaid on an open playing field. The game implements a straight-forward approach to location-based triggering in which players must be in the same spatial locale in order to share information and act together. Comparison of video recordings of physical play with system recordings of game events reveals subtle and complex interactions between highly dynamic player behavior and the underlying technology. While players exhibit a fluid approach to group formation, the system embodies a more rigid view, leading to difficulties with sharing context and coordinating actions, most notably when groups of players span virtual locale boundaries or initiate actions while on the move. We propose techniques for extending locales to support more flexible grouping and also discuss the broader implications of our findings for location-based applications in general.
2005	Improving orchestral conducting systems in public spaces: examining the temporal characteristics and conceptual models of conducting gestures	Designing interactive conducting exhibits for public spaces poses unique challenges, primarily because the conceptual model of conducting music varies amongst users. In a user study, we compared how conductors and non-conductors place their beats when conducting to a fixed orchestral recording of Radetzky March , and found significant differences between these two groups. Conductors lead the actual music beat with their gestures by an average of 150 ms, compared to 50 ms for non-conductors; non-conductors also vary their placement of the beat 50\% more than conductors. Furthermore, we found differences in how users conceptually mapped their gestures to the music, such as conducting to the musical rhythm rather than to the beat. We are incorporating these results into an upcoming conducting system for public spaces to increase its usability; we believe they also apply to a more general class of musical gestures such as dance.
2005	Designing the spectator experience	Interaction is increasingly a public affair, taking place in our theatres, galleries, museums, exhibitions and on the city streets. This raises a new design challenge for HCI - how should spectators experience a performer's interaction with a computer? We classify public interfaces (including examples from art, performance and exhibition design) according to the extent to which a performer's manipulations of an interface and their resulting effects are hidden, partially revealed, fully revealed or even amplified for spectators. Our taxonomy uncovers four broad design strategies: 'secretive,' where manipulations and effects are largely hidden; 'expressive,' where they tend to be revealed enabling the spectator to fully appreciate the performer's interaction; 'magical,' where effects are revealed but the manipulations that caused them are hidden; and finally 'suspenseful,' where manipulations are apparent but effects are only revealed as the spectator takes their turn.
2005	Values at play: design tradeoffs in socially-oriented game design	Significant work in the CHI community has focused on designing systems that support human values. Designers and engineers have also become increasingly aware of ways in which the artifacts they create can embody political, social, and ethical values. Despite such an awareness, there has been little work towards producing practical methodologies that systematically incorporate values into the design process. Many designers struggle to find a balance between their own values, those of users and other stakeholders, and those of the surrounding culture. In this paper, we present the RAPUNSEL project as a case study of game design in a values-rich context and describe our efforts toward navigating the complexities this entails. Additionally, we present initial steps toward the development of a systematic methodology for discovery, analysis, and integration of values in technology design in the hope that others may both benefit from and build upon this work.
2005	Feature congestion: a measure of display clutter	Management of clutter is an important factor in the design of user interfaces and information visualizations, allowing improved usability and aesthetics. However, clutter is not a well defined concept. In this paper, we present the Feature Congestion measure of display clutter. This measure is based upon extensive modeling of the saliency of elements of a display, and upon a new operational definition of clutter. The current implementation is based upon two features: color and luminance contrast. We have tested this measure on maps that observers ranked by perceived clutter. Results show good agreement between the observers' rankings and our measure of clutter. Furthermore, our measure can be used to make design suggestions in an automated UI critiquing tool.
2005	Improving revisitation in fisheye views with visit wear	The distortion caused by an interactive fisheye lens can make it difficult for people to remember items and locations in the data space. In this paper we introduce the idea of visit wear - a visual representation of the places that the user has previously visited - as a way to improve navigation in spaces affected by distortion. We outline the design dimensions of visit wear, and report on two studies. The first shows that increasing the distortion of a fisheye view does significantly reduce people's ability to remember object locations. The second study looks at the effects of visit wear on performance in revisitation tasks, and shows that both completion time and error rates are significantly improved when visit wear is present. Visit wear works by changing the revisitation problem from one of memory to one of visual search. Although there are limitations to the technique, visit wear has the potential to substantially improve the usability both of fisheye views and of graphical information spaces more generally.
2005	Martial arts in artificial reality	This paper presents Kick Ass Kung-Fu, a martial arts game installation where the player fights virtual enemies with kicks and punches as well as acrobatic moves such as cartwheels. Using real-time image processing and computer vision, the video image of the user is embedded inside 3D graphics. Compared to previous work, our system uses a profile view and two displays, which allows an improved view of many martial arts techniques. We also explore exaggerated motion and dynamic slow-motion effects to transform the aesthetic of kung-fu movies into an interactive, embodied experience. The system is described and analyzed based on results from testing the game in a theater, in a television show, and in a user study with 46 martial arts practitioners.
2005	Spotlight: directing users' attention on large displays	We describe a new interaction technique, called a spotlight, for directing the visual attention of an audience when viewing data or presentations on large wall-sized displays. A spotlight is simply a region of the display where the contents are displayed normally while the remainder of the display is somewhat darkened. In this paper we define the behavior of spotlights, show unique affordances of the technique, and discuss design characteristics. We also report on experiments that show the benefit of using the spotlight a large display and standard desktop configuration. Our results suggest that the spotlight is preferred over the standard cursor and outperforms it by a factor of 3.4 on a wall-sized display.
2005	MultiView: spatially faithful group video conferencing	MultiView is a new video conferencing system that supports collaboration between remote groups of people. MultiView accomplishes this by being spatially faithful . As a result, MultiView preserves a myriad of nonverbal cues, includ-ing gaze and gesture, in a way that should improve com-munication. Previous systems fail to support many of these cues because a single camera perspective warps spatial char-acteristics in group-to-group meetings. In this paper, we present a formal definition of spatial faithfulness. We then apply a metaphor-based design methodology to help us spec-ify and evaluate MultiView's support of spatial faithfulness. We then present results from a low-level user study to mea-sure MultiView's effectiveness at conveying gaze and ges-ture perception. MultiView is the first practical solution to spatially faithful group-to-group conferencing, one of the most common applications of video conferencing.
2005	Less visible and wireless: two experiments on the effects of microphone type on users' performance and perception	When devices become less visible and recede to the background, what kinds of influences would they have on users'? This paper presents two experiments (N=48 and N=96) that examine the effects of four different types of microphones (and voice vs. text output) on user's behaviors and attitudes. The microphones differ with respect to their visibility and users' mobility. Participants performed two different tasks: a standard creativity task and a standard disclosure task. Mobility facilitated creativity and disclosure of personal information. Recording reminder discouraged creativity and disclosure. Output modality had no significant effect. Implications for ubiquitous computing and voice user interfaces are discussed.
2005	Children and emerging wireless technologies: investigating the potential for spatial practice	In this paper, we describe design work with 36 children aged 9 and 10 in Bristol, United Kingdom. The design work was conducted using emerging mobile and wireless technology which has the potential to impact on the problematic issue of children's access to, use of, and safety within the wider urban environment. A series of workshops are described in which children were encouraged to think about their use of an outdoor space before their introduction to the technology. The children designed and created "soundscapes" in the outdoor environment. The future potential impact of the technology on children's spatial practice is discussed and the concept of children "tagging" environmental hazards is raised.
2005	Testing the media equation with children	Designers of children's technology are often more interested in user motivation than those who design systems for adults. Since children's technology often has aims such as education or practice, keeping the user engaged and interested is an important objective. The Media Equation - the idea that people respond socially to computers - shows potential for improving engagement and motivation. Studies have shown that people are more positive about both themselves and the computer when software exhibits certain social characteristics. To explore the possible value of the Media Equation as a design concept for children's software, we replicated two of the original Media Equation studies, concerning the effects of praise and team formation. Our results, however, were contrary to our expectations: we did not find evidence that children were significantly affected by social characteristics in software, and adults were influenced in only a few cases. These results raise questions about using the Media Equation as a design principle for children's software.
2005	Camera talk: making the camera a partial participant	In this paper, we describe how encouraging children to talk to the camera can structure their behavior and provide them opportunity for reflection. Encouraging "camera talk," interactions directed at the camera, can effectively elicit verbal comments from children participants. We describe a study in which children participants were told that they could tell the camera anything they wanted to about the designs they were making using a piece of educational software, but not to behave in a disruptive manner for the camera. By allowing children to interact with the camera in a particular way, rather than encouraging them to ignore its presence, we were able to elicit information about some children's design activities, thoughts, and struggles. The camera became an integral part of the socio-technical system for some children. This method may be useful to researchers interested in what children are thinking about in-the-moment as they work with software.
2005	The syntax or the story behind it?: a usability study of student work with computer-based programming environments in elementary science	This is a descriptive case study investigating the use of two computer-based programming environments (CPEs), MicroWorlds™ Logo (MW) and Stagecast Creator™ (SC) for collaborative scientific modeling. The purpose of the study was to investigate and comparatively describe student approaches to scientific modeling through the use of textual or graphical program languages (PL). I analyzed student activities and conversations in two after-school clubs, one working with MW and the other with SC, using contextual inquiry, analysis of student conversation and artifact analysis. The findings suggest that student work with CPEs differed between different PL. Students used SC to create games (focusing on the overall story) whereas MW students used MW through a frame of formal programming. Programming in SC was much easier than MW, whereas reading code in MW was more tangible. Findings suggest that differences in student approaches to scientific modeling through programming need to be considered by educators seeking to engage students in such activities and software developers seeking to develop CPEs for young learners.
2005	Extending tangible interfaces for education: digital montessori-inspired manipulatives	This paper introduces a new framework for thinking about tangible interfaces in education, with specific focus on abstract problem domains.Manipulatives are physical objects specifically designed to foster learning. We offer a new classification of Manipulatives: "Froebel-inspired Manipulatives" (FiMs) and "Montessori-inspired Manipulatives" (MiMs). We argue that FiMs are design materials, fostering modeling of real-world structures, while MiMs foster modeling of more abstract structures. We show that our classification extends to computationally enhanced versions of manipulatives.We present Digital MiMs - computationally enhanced building blocks. We describe two prototypical members of the Digital MiMs class: FlowBlocks and SystemBlocks, physical, modular interactive systems that serve as general-purpose modeling and simulation tools for dynamic behavior. We present findings from qualitative studies, and conclude that digital MiMs are accessible to young children, engaging, and encourage learning of abstract structures of dynamic behavior through an iterative process of hands-on modeling, simulating, and analogizing.
2005	Effectiveness of end-user debugging software features: are there gender issues?	Although gender differences in a technological world are receiving significant research attention, much of the research and practice has aimed at how society and education can impact the successes and retention of female computer science professionals-but the possibility of gender issues within software has received almost no attention. If gender issues exist with some types of software features, it is possible that accommodating them by changing these features can increase effectiveness, but only if we know what these issues are. In this paper, we empirically investigate gender differences for end users in the context of debugging spreadsheets. Our results uncover significant gender differences in self-efficacy and feature acceptance, with females exhibiting lower self-efficacy and lower feature acceptance. The results also show that these differences can significantly reduce females' effectiveness.
2005	Patterns of media use in an activity-centric collaborative environment	This paper describes a new collaboration technology that is based on the support of lightweight, informally structured, opportunistic activities featuring heterogeneous threads of shared items with dynamic membership. We introduce our design concepts, and we provide a detailed analysis of user behavior during a five month field study. We present the patterns of media use that we observed, using a variety of analytical methods including thread clustering and analysis. Major findings include four patterns of media use: communicating, exchanging mixed objects, coordinating, (e.g., of status reports), and semi-archival filing. We observed differential use of various media including highly variable use of chats and surprisingly informal uses of files. We discuss the implications for the design of mixed media collaborative tools to support the work activities of small to medium sized work teams.
2005	Assessing differential usage of usenet social accounting meta-data	We describe a usage study of NetscanTech, a system that generates and publishes daily a range of social metrics across three dimensions: newsgroup, author, and thread, for a set of approximately 15,000 technical newsgroups in Usenet. We bring together three interlinked datasets: survey data, usage log data and social accounting data from Usenet participation, to triangulate the relationship between various user roles and differential usage of social metrics in NetscanTech. We found our most frequent users focused on information related to individual authors far more than any other information provided. In contrast, users that visited less frequently focused more on information related to newsgroups and viewing newsgroup metrics. Our results suggest features that designers and developers of online communities may wish to include in their interfaces to support the cultivation of different community roles.
2005	When participants do the capturing: the role of media in diary studies	In this paper, we investigate how the choice of media for capture and access affects the diary study method. The diary study is a method of understanding participant behavior and intent in situ that minimizes the effects of observers on participants. We first situate diary studies within a framework of field studies and review related literature. We then report on three diary studies we conducted that involve photographs, audio recordings, location information and tangible artifacts. We then analyze our findings, specifically addressing the following questions: How do context information and episodic memory prompts captured by participants vary with media? In what way do different media "jog" memory? How do different media affect the diary study process? These questions are particularly important for diary studies because they can be especially useful as compared to other methods when a participant intends to do an action but does not or when actions are particularly difficult to sense. We also built and tested a tool based on participant and researcher frustrations with the method. Our contribution includes suggested modifications to traditional diary techniques that enable annotation and review of captured media; a new variation on the diary study appropriate for researchers using digital capture media; and a lightweight tool to support it, motivated by past work and findings from our studies.
2005	Using context-aware computing to reduce the perceived burden of interruptions from mobile devices	The potential for sensor-enabled mobile devices to proactively present information when and where users need it ranks among the greatest promises of ubiquitous computing. Unfortunately, mobile phones, PDAs, and other computing devices that compete for the user's attention can contribute to interruption irritability and feelings of information overload. Designers of mobile computing interfaces, therefore, require strategies for minimizing the perceived interruption burden of proactively delivered messages. In this work, a context-aware mobile computing device was developed that automatically detects postural and ambulatory activity transitions in real time using wireless accelerometers. This device was used to experimentally measure the receptivity to interruptions delivered at activity transitions relative to those delivered at random times. Messages delivered at activity transitions were found to be better received, thereby suggesting a viable strategy for context-aware message delivery in sensor-enabled mobile computing devices.
2005	Interaction in 4-second bursts: the fragmented nature of attentional resources in mobile HCI	When on the move, cognitive resources are reserved partly for passively monitoring and reacting to contexts and events, and partly for actively constructing them. The Re-source Competition Framework (RCF), building on the Multiple Resources Theory, explains how psychosocial tasks typical of mobile situations compete for cognitive resources and then suggests that this leads to the depletion of resources for task interaction and eventually results in the breakdown of fluent interaction. RCF predictions were tested in a semi-naturalistic field study measuring attention during the performance of assigned Web search tasks on mobile phone while moving through nine varied but typical urban situations. Notably, we discovered up to eight-fold differentials between micro-level measurements of atten-tional resource fragmentation, for example from spans of over 16 seconds in a laboratory condition dropping to bursts of just a few seconds in difficult mobile situations. By cali-brating perceptual sampling, reducing resources from tasks of secondary importance, and resisting the impulse to switch tasks before finalization, participants compensated for the resource depletion. The findings are compared to previous studies in office contexts. The work is valuable in many areas of HCI dealing with mobility.
2005	Collective efficacy as a measure of community	As human-computer interaction increasingly focuses on mediated interactions among groups of individuals, there is a need to develop techniques for measurement and analysis of groups that have been scoped at the level of the group. Bandura's construct of perceived self-efficacy has been used to understand individual behavior as a function of domain-specific beliefs about personal capacities. The construct of collective efficacy extends self-efficacy to organizations and groups, referring to beliefs about collective capacities in specific domains. We describe the development and refinement of a collective efficacy scale, the factor analysis of the construct, and its external validation in path models of community-oriented attitudes, beliefs, and behaviors.
2005	How oversight improves member-maintained communities	Online communities need regular maintenance activities such as moderation and data input, tasks that typically fall to community owners. Communities that allow all members to participate in maintenance tasks have the potential to be more robust and valuable. A key challenge in creating member-maintained communities is building interfaces, algorithms, and social structures that encourage people to provide high-quality contributions. We use Karau and Williams' collective effort model to predict how peer and expert editorial oversight affect members' contributions to a movie recommendation website and test these predictions in a field experiment with 87 contributors. Oversight increased both the quantity and quality of contributions while reducing antisocial behavior, and peers were as effective at oversight as experts. We draw design guidelines and suggest avenues for future work from our results.
2005	Grounding needs: achieving common ground via lightweight chat in large, distributed, ad-hoc groups	This paper reports on the emergent use of lightweight text chat to provide important grounding and facilitation information in a large, distributed, ad-hoc group of researchers participating in a live experiment. The success of chat in this setting suggests a critical re-examination and extension of Clark and Brennan's work on grounding in communication. Specifically, it is argued that there are some settings characterized by reduced information and clarification needs, where the use of extremely lightweight tools (such as basic text chat) can be sufficient for achieving common ground - even when conversational participants are unknown to each other. Theoretical and design implications are then presented.
2005	Tool for accurately predicting website navigation problems, non-problems, problem severity, and effectiveness of repairs	The Cognitive Walkthrough for the Web (CWW) is a partially automated usability evaluation method for identifying and repairing website navigation problems. Building on five earlier experiments [3,4], we first conducted two new experiments to create a sufficiently large dataset for multiple regression analysis. Then we devised automatable problem-identification rules and used multiple regression analysis on that large dataset to develop a new CWW formula for accurately predicting problem severity. We then conducted a third experiment to test the prediction formula and refined CWW against an independent dataset, resulting in full cross-validation of the formula. We conclude that CWW has high psychological validity, because CWW gives us (a) accurate measures of problem severity, (b) high success rates for repairs of identified problems (c) high hit rates and low false alarms for identifying problems, and (d) high rates of correct rejections and low rates of misses for identifying non-problems.
2005	Is your web page accessible?: a comparative study of methods for assessing web page accessibility for the blind	Web access for users with disabilities is an important goal and challenging problem for web content developers and designers. This paper presents a comparison of different methods for finding accessibility problems affecting users who are blind. Our comparison focuses on techniques that might be of use to Web developers without accessibility experience, a large and important group that represents a major source of inaccessible pages. We compare a laboratory study with blind users to an automated tool, expert review by web designers with and without a screen reader, and remote testing by blind users. Multiple developers, using a screen reader, were most consistently successful at finding most classes of problems, and tended to find about 50\% of known problems. Surprisingly, a remote study with blind users was one of the least effective methods. All of the techniques, however, had different, complementary strengths and weaknesses.
2005	A comparison of LSA, wordNet and PMI-IR for predicting user click behavior	A predictive tool to simulate human visual search behavior would help interface designers inform and validate their design. Such a tool would benefit from a semantic component that would help predict search behavior even in the absence of exact textual matches between goal and target. This paper discusses a comparison of three semantic systems-LSA, WordNet and PMI-IR-to evaluate their performance in predicting the link that people would select given an information goal and a webpage. PMI-IR best predicted human performance as observed in a user study.
2005	Modeling and improving selection in cascading pull-down menus using Fitts' law, the steering law and force fields	Selecting a menu item in a cascading pull-down menu is a frequent but time consuming and complex GUI task. This paper describes an approach aimed to support the user during selection in cascading pull-down menus when using an indirect pointing device. By enhancing such a cascading pull-down menu with "force fields", the cursor is attracted toward a certain direction, e.g. toward the right hand side within a menu item, which opens up a sub-menu, making the cursor steering task easier and faster. The experiment described here shows that the force fields can decrease selection times, on average by 18\%, when a mouse, a track point, or touch pad is used as input device. The results also suggest that selection times in cascading pull-down menus can be modeled using a combination of Fitts' law and the steering law. The proposed model proved to hold for all three devices, in both standard and in enhanced cascading pull-down menus, with correlations better than r 2 =0.90.
2005	Tuning and testing scrolling interfaces that automatically zoom	Speed dependent automatic zooming (SDAZ) is a promising refinement to scrolling in which documents are automatically zoomed-out as the scroll rate increases. By automatically zooming, the visual flow rate is reduced enabling rapid scrolling without motion blur. In order to aid SDAZ calibration we theoretically and empirically scrutinise human factors of the speed/zoom relationship. We then compare user performance with four alternative text-document scrolling systems, two of which employ automatic zooming. One of these systems, which we term 'DDAZ', is based on van Wijk and Nuij's recent and important theory that calculates optimal pan/zoom paths between known locations in 2D space. van Wijk and Nuij suggested that their theory could be applied to scrolling, but did not implement or test their formulaic suggestions. Participants in our evaluation (n=27) completed scrolling tasks most rapidly when using SDAZ, followed by DDAZ, normal scrollbars, and traditional rate-based scrolling. Workload assessments and preferences strongly favoured SDAZ. We finish by examining issues for consideration in commercial deployments.
2005	Location disclosure to social relations: why, when, & what people want to share	Advances in location-enhanced technology are making it easier for us to be located by others. These new technologies present a difficult privacy tradeoff, as disclosing one's location to another person or service could be risky, yet valuable. To explore whether and what users are willing to disclose about their location to social relations, we conducted a three-phased formative study. Our results show that the most important factors were who was requesting, why the requester wanted the participant's location, and what level of detail would be most useful to the requester. After determining these, participants were typically willing to disclose either the most useful detail or nothing about their location. From our findings, we reflect on the decision process for location disclosure. With these results, we hope to influence the design of future location-enhanced applications and services.
2005	Privacy and proportionality: adapting legal evaluation techniques to inform design in ubiquitous computing	We argue that an analytic proportionality assessment balancing usefulness and burden on individual or group privacy must be conducted throughout the design process to create acceptable ubiquitous computing (ubicomp) applications and services. We introduce the principle of proportionality, which originates within the legal and data protection communities. Inspired by this principle, we develop a design method for ubicomp applications, based on our own experience, and aimed at HCI practitioners and designers. We discuss the method in relation to real-world examples, user inquiry techniques and requirements engineering models. Finally, we report a sample application of the method, involving a ubiquitous, personal memory aid tool.
2005	Who gets to know what when: configuring privacy permissions in an awareness application	We report on a study (N=36) of user preferences for balancing awareness with privacy. Participants defined permissions for sharing of location, availability, calendar information and instant messaging (IM) activity within an application called mySpace. MySpace is an interactive visualization of the physical workplace that provides dynamic information about people, places and equipment. We found a significant preference for defining privacy permissions at the group level. While "family" received high levels of awareness sharing, interestingly, "team" was granted comparable levels during business hours at work. Surprisingly, presenting participants with a detailed list of all pieces of personal context to which the system had access, did not result in more conservative privacy settings. Although location was the most sensitive aspect of awareness, participants were comfortable disclosing room-level location information to their team members at work. Our findings suggest utilizing grouping mechanisms to balance privacy control with configuration burden, and argue for increased system transparency to build trust.
2005	Saving and using encountered information: implications for electronic periodicals	As part of a focus on electronic publications, we undertook an exploratory study of how people saved and used the information they encountered while reading. In particular, we wanted to understand the role of clipping and whether it would be a necessary form of interaction with electronic publications. We interviewed 20 diverse individuals at home and at work, bringing together narrative accounts and physical and digital examples to investigate how people currently collect and use clippings from their everyday reading. All study participants had examples of materials they had deliberately saved from periodicals, ranging from ads torn from newspapers and URLs received in email messages to large stacks of magazines. Participants rarely read periodicals specifically to clip but rather recognized items of interest when they were encountered. The work highlights the importance of encountering information as an activity distinct from task-focused browsing and searching and reveals design implications for online reading and clipping technologies.
2005	Documents at Hand: Learning from Paper to Improve Digital Technologies	In this paper the results of a two-year ethnographic study of the personal document management of 28 information workers is described. Both the paper and digital domain were taken into account during the study. The results reaffirmed that document management is strongly related to task management. Digital tools do not adequately support two important user needs related to task management, namely that documents should be embedded within meaningful (task-related) context information, and that they should be easily accessible for regrouping as the task goes on. In contrast, paper supports these needs very well. Following a discussion of personal document management using paper, email, and digital file folder structures, six implications are outlined for the design of digital document management systems that combine the advantages of both domains.
2005	Findex: search result categories help users when document ranking fails	Long web search result lists can be hard to browse. We demonstrated experimentally, in a previous study, the usefulness of a categorization algorithm and filtering interface. However, the nature of interaction in real settings is not known from an experiment in laboratory settings. To address this problem, we provided our categorizing web search user interface to 16 users for a two month period. The interactions with the system were logged and the users' opinions were elicited with two questionnaires. The results show that categories are successfully used as part of users' search habits. They are helpful when the result ranking of the search engine fails. In those cases, the users are able to access results that locate far in the rank order list with the categories. Users can also formulate simpler queries and find needed results with the help of the categories. In addition, the categories are beneficial when more than one result is needed like in an exploratory or undirected search task.
2005	Use of eye movements as feedforward training for a synthetic aircraft inspection task	Aircraft inspection is a vital element in assuring safety and reliability of the air transportation system. The human inspector performing visual inspection of an aircraft is the backbone of this process and training is an effective strategy for improving their inspection performance. Previous studies have shown offline feedback training to be effective in improving subsequent visual inspection performance. Because experienced inspectors are known to adopt a better inspection strategy than novices, providing visualization of experts' cognitive processes a priori can accelerate novices' adoption of the experts' strategy. Using eye tracking equipment, we record the point of regard of an expert inspector performing an inspection task in a virtual reality simulator. Analysis of their eye movements leads to a visualization of their scanpaths and allows us to display the inspector's visual search (hence cognitive) strategy. We show how providing this type of scanpath-based feedforward training of novices leads to improved accuracy performance in the simulator coupled with an observed speed-accuracy tradeoff. We contend that the tradeoff results from trained novices adopting a slower paced strategy through increased fixation durations, suggesting trained novices learn a more deliberate target search/discrimination strategy that requires more time to execute.
2005	EyeWindows: evaluation of eye-controlled zooming windows for focus selection	In this paper, we present an attentive windowing technique that uses eye tracking, rather than manual pointing, for focus window selection. We evaluated the performance of 4 focus selection techniques: eye tracking with key activation, eye tracking with automatic activation, mouse and hotkeys in a typing task with many open windows. We also evaluated a zooming windowing technique designed specifically for eye-based control, comparing its performance to that of a stan-dard tiled windowing environment. Results indicated that eye tracking with automatic activation was, on average, about twice as fast as mouse and hotkeys. Eye tracking with key activation was about 72\% faster than manual conditions, and preferred by most participants. We believe eye input performed well because it allows manual input to be provided in parallel to focus selection tasks. Results also suggested that zooming windows outperform static tiled windows by about 30\%. Furthermore, this performance gain scaled with the number of windows used. We conclude that eye-controlled zooming windows with key activation pro-vides an efficient and effective alternative to current focus window selection techniques.
2005	EyeDraw: enabling children with severe motor impairments to draw with their eyes	EyeDraw is a software program that, when run on a computer with an eye tracking device, enables children with severe motor disabilities to draw pictures by just moving their eyes. This paper discusses the motivation for building the software, how the program works, the iterative development of two versions of the software, user testing of the two versions by people with and without disabilities, and modifications to the software based on user testing. Feedback from both children and adults with disabilities, and from their caregivers, was especially helpful in the design process. The project identifies challenges that are unique to controlling a computer with the eyes, and unique to writing software for children with severe motor impairments.
2005	Six themes of the communicative appropriation of photographic images	In this paper, we explore the use of digital photographs in computer-mediated communication. We present Lascaux, an instant messaging client that serves as a research platform for studying visual communication with digital photographs. Through a combined analysis of the uses of images in Lascaux as well as the uses of images in other communicative contexts, we arrived at six themes of appropriation: the image as amplification, the image as narrative, the image as awareness, the image as local expression, the image as invitation, and the image as object/instrument. For each theme, we explore the ways in which a medium may be designed to support that class of appropriation. Finally, we reflect on the relationship between literacy, mastery, and appropriation.
2005	Making space for stories: ambiguity in the design of personal communication systems	Pervasive personal communication technologies offer the potential for important social benefits for individual users, but also the potential for significant social difficulties and costs. In research on face-to-face social interaction, ambiguity is often identified as an important resource for resolving social difficulties. In this paper, we discuss two design cases of personal communication systems, one based on fieldwork of a commercial system and another based on an unrealized design concept. The cases illustrate how user behavior concerning a particular social difficulty, unexplained unresponsiveness, can be influenced by technological issues that result in interactional ambiguity. The cases also highlight the need to balance the utility of ambiguity against the utility of usability and communicative clarity.
2005	Listening in: practices surrounding iTunes music sharing	This paper presents a descriptive account of the social practices surrounding the iTunes music sharing of 13 participants in one organizational setting. Specifically, we characterize adoption, critical mass, and privacy; impression management and access control; the musical impressions of others that are created as a result of music sharing; the ways in which participants attempted to make sense of the dynamic system; and implications of the overlaid technical, musical, and corporate topologies. We interleave design implications throughout our results and relate those results to broader themes in a music sharing design space.
2005	AppLens and launchTile: two designs for one-handed thumb use on small devices	We present two interfaces to support one-handed thumb use for PDAs and cell phones. Both use Scalable User Interface (ScUI) techniques to support multiple devices with different resolutions and aspect ratios. The designs use variations of zooming interface techniques to provide multiple views of application data: AppLens uses tabular fisheye to access nine applications, while LaunchTile uses pure zoom to access thirty-six applications. We introduce two sets of thumb gestures, each representing different philosophies for one-handed interaction. We conducted two studies to evaluate our designs. In the first study, we explored whether users could learn and execute the AppLens gesture set with minimal training. Participants performed more accurately and efficiently using gestures for directional navigation than using gestures for object interaction. In the second study, we gathered user reactions to each interface, as well as comparative preferences. With minimal exposure to each design, most users favored AppLens's tabular fisheye interface.
2005	Alphabetically constrained keypad designs for text entry on mobile devices	The creation of text will remain a necessary part of human-computer interaction with mobile devices, even as they continue to shrink in size. On mobile phones, text is often entered using keypads and predictive text entry techniques, which attempt to minimize the effort (e.g., number of key presses) needed to enter words. This research presents results from the design and testing of alphabetically-constrained keypads, optimized on various word lists, for predictive text entry on mobile devices. Complete enumeration and Genetic Algorithm-based heuristics were used to find keypad designs based on different numbers of keys. Results show that alphabetically-constrained designs can be found that are close to unconstrained designs in terms of performance. User testing supports the hypothesis that novice ease of learning, usability, and performance is greater for constrained designs when compared to unconstrained designs. The effect of different word lists on keypad design and performance is also discussed.
2005	Conversing with the user based on eye-gaze patterns	Motivated by and grounded in observations of eye-gaze patterns in human-human dialogue, this study explores using eye-gaze patterns in managing human-computer dialogue. We developed an interactive system, iTourist, for city trip planning, which encapsulated knowledge of eye-gaze patterns gained from studies of human-human collaboration systems. User study results show that it was possible to sense users' interest based on eye-gaze patterns and manage computer information output accordingly. Study participants could successfully plan their trip with iTourist and positively rated their experience of using it. We demonstrate that eye-gaze could play an important role in managing future multimodal human-computer dialogues.
2005	Effects of task properties, partner actions, and message content on eye gaze patterns in a collaborative task	Helpers providing guidance for collaborative physical tasks shift their gaze between the workspace, supply area, and instructions. Understanding when and why helpers gaze at each area is important both for a theoretical understanding of collaboration on physical tasks and for the design of automated video systems for remote collaboration. In a laboratory experiment using a collaborative puzzle task, we recorded helpers' gaze while manipulating task complexity and piece differentiability. Helpers gazed toward the pieces bay more frequently when pieces were difficult to differentiate and less frequently over repeated trials. Preliminary analyses of message content show that helpers tend to look at the pieces bay when describing the next piece and at the workspace when describing where it goes. The results are consistent with a grounding model of communication, in which helpers seek visual evidence of understanding unless they are confident that they have been understood. The results also suggest the feasibility of building automated video systems based on remote helpers' shifting visual requirements.
2005	Individual differences in multimodal integration patterns: what are they and why do they exist?	Techniques for information fusion are at the heart of multimodal system design. To develop new user-adaptive approaches for multimodal fusion, the present research investigated the stability and underlying cause of major individual differences that have been documented between users in their multimodal integration pattern. Longitudinal data were collected from 25 adults as they interacted with a map system over six weeks. Analyses of 1,100 multimodal constructions revealed that everyone had a dominant integration pattern, either simultaneous or sequential, which was 95-96\% consistent and remained stable over time. In addition, coherent behavioral and linguistic differences were identified between these two groups. Whereas performance speed was comparable, sequential integrators made only half as many errors and excelled during new or complex tasks. Sequential integrators also had more precise articulation (e.g., fewer disfluencies), although their speech rate was no slower. Finally, sequential integrators more often adopted terse and direct command-style language, with a smaller and less varied vocabulary, which appeared focused on achieving error-free communication. These distinct interaction patterns are interpreted as deriving from fundamental differences in reflective-impulsive cognitive style. Implications of these findings are discussed for the design of adaptive multimodal systems with substantially improved performance characteristics.
2005	tranSticks: physically manipulatable virtual connections	A virtually connected medium called tranStick is described that functions both as a "virtual wire" and as a "memory card" containing a shared space. A user can connect two networked devices by simply placing one of a pair of tranSticks with the same identifier into each device. The tranSticks provide feedback indicating that the devices are connected; the connection to be closed or changed in the same way it would be if the devices were connected by a physical cable. A user can also access to a shared space on a network as if the space were in the tranStick. Since tranSticks contain long secret keys, the process of finding another tranStick with the same identifier can be encrypted. The tranStick approach differs from other approaches in that it provides feedback from the connection as well as serving as a medium for establishing a connection, and it enables disconnection and switchover to be done intuitively because the operations are reversible.
2005	Discrete acceleration and personalised tiling as brain?body interface paradigms for neurorehabilitation	We present two studies that have advanced the design of brain-body interfaces for use in the rehabilitation of individuals with severe neurological impairment due to traumatic brain injury. We first developed and evaluated an adaptive cursor acceleration algorithm based on screen areas. This improved the initial design, but was too inflexible to let users make the most of their highly varied abilities. Only some individuals were well served by this adaptive interface. We therefore developed and evaluated an approach based on personalized tile layouts. The rationales for both designs are presented, along with details of their implementation. Evaluation studies for each are reported, which show that we have extended the user population who can use our interfaces relative to previous studies. We have also extended the usable functionality for some of our user group. We thus claim that personalized tiling with discrete acceleration has allowed us to extend the usable functionality of brain-body interfaces to a wider population with traumatic brain injury, thus creating new options for neurorehabiliation.
2005	Effectiveness of directional vibrotactile cuing on a building-clearing task	This paper presents empirical results to support the use of vibrotactile cues as a means of improving user performance on a spatial task. In a building-clearing exercise, directional vibrotactile cues were employed to alert subjects to areas of the building that they had not yet cleared, but were currently exposed to. Compared with performing the task without vibrotactile cues, subjects were exposed to uncleared areas a smaller percentage of time, and cleared more of the overall space, when given the added vibrotactile stimulus. The average length of each exposure was also significantly less when vibrotactile cues were present.
2006	Faster document navigation with space-filling thumbnails	Scrolling is the standard way to navigate through many types of digital documents. However, moving more than a few pages can be slow because all scrolling techniques constrain visual search to only a small document region. To improve document navigation, we developed Space-Filling Thumbnails (SFT), an overview display that eliminates most scrolling. SFT provides two views: a standard page view for reading, and a thumbnail view that shows all pages. We tested SFT in three experiments that involved finding pages in documents. The first study (n=13) compared seven current scrolling techniques, and showed that SFT is significantly faster than the other methods. The second and third studies (n=32 and n=14) were detailed comparisons of SFT with thumbnail-enhanced scrollbars (TES), which performed well in the first experiment. SFT was faster than TES across all document types and lengths, particularly when tasks involved revisitation. In addition, SFT was strongly preferred by participants.
2006	An evaluation of pan & zoom and rubber sheet navigation with and without an overview	We present a study that evaluates conventional Pan and Zoom Navigation and Rubber Sheet Navigation, a rectilinear Focus+Context technique. Each of the two navigation techniques was evaluated both with and without an overview. All interfaces guaranteed that regions of interest would remain visible, at least as a compressed landmark, independent of navigation actions. Interfaces implementing these techniques were used by 40 subjects to perform a task that involved navigating a large hierarchical tree dataset and making topological comparisons between nodes in the tree. Our results show that Pan and Zoom Navigation was significantly faster and required less mental effort than Rubber Sheet Navigation, independent of the presence or absence of an overview. Also, overviews did not appear to improve performance, but were still perceived as beneficial by users. We discuss the implications of our task and guaranteed visibility on the results and the limitations of our study, and we propose preliminary design guidelines and recommendations for future work.
2006	OrthoZoom scroller: 1D multi-scale navigation	This article introduces the OrthoZoom Scroller, a novel interaction technique that improves target acquisition in very large one-dimensional spaces. The OrthoZoom Scroller requires only a mouse to perform panning and zooming in a 1D space. Panning is performed along the slider dimension while zooming is performed along the orthogonal one. We present a controlled experiment showing that the OrthoZoom Scroller is about twice as fast as Speed Dependant Automatic Zooming to perform pointing tasks whose index of difficulty is in the 10-30 bits range. We also present an application to browse large textual documents with the OrthoZoom Scroller that uses semantic zooming and snapping on the structure.
2006	Time based patterns in mobile-internet surfing	In this paper we investigate environmental factors that can result in users having different preferences and behaviors at different times of the day. An analysis is carried out of a large sample of user data for Wireless Application Protocol (WAP) browsing to determine whether user surfing patterns vary depending on time. We examine traffic on an hourly and daily basis, and show that accesses to particular categories of pages vary relative to time. We also build Markov models, which are temporal; to predict user navigation, and illustrate those predictive models are more accurate and beneficial to mobile Internet users than traditional methods. This analysis provides insight into improving the effectiveness and efficiency of navigation prediction.
2006	Minimap: a web page visualization method for mobile phones	The Web has become available even on mobile phones, but the current methods to view large pages on small screens have not been highly usable. Current mobile phone browsers reformat Web pages to a single column that fits the screen width. Because not all content is comprehensible in this format, browsers provide a second mode for viewing pages in the same layout as on a PC. We have developed a modeless Web page visualization method called Minimap that shows pages in a modified Original layout. We conducted a long-term usability study with 20 participants to compare the state-of-the-art mobile phone browser with this new method. 18 participants preferred the new method, and it also scored better in more detailed usability ratings.
2006	An examination of the effects of a wearable display on informal face-to-face communication	Wearable computers have the potential to support our memory, facilitate our creativity, our communication and augment our physical senses [15] but, like email and cell-phones, they also have the potential to interrupt, displace or downgrade our social interactions. This paper presents the results of a simple laboratory-based study which examines the impact of a xybernaut head-mounted Shimadzu display on conversation between two people. We hypothesized that the wearable, by reducing eye-contact and attention in the wearer would have a detrimental effect. Pairs of friends discussed pre-defined topics under three conditions, no wearable, wearable present but inactive, wearable present and active. Likert scale statements were used to record the wearer's level of attention, concentration, listening, eye contact, naturalness and relaxation, and the impact of the wearable. The presence of the wearable without an active display did not have an effect on the conversation. The quality of the interaction was however impaired in the active wearable condition and eye-contact was effected. This effect may be the result of the nature of the information type, the interface used, the characteristics of its presentation or the novelty of the display to the user. Additional research to identify design implications is discussed.
2006	Peekaboom: a game for locating objects in images	We introduce Peekaboom, an entertaining web-based game that can help computers locate objects in images. People play the game because of its entertainment value, and as a side effect of them playing, we collect valuable image metadata, such as which pixels belong to which object in the image. The collected data could be applied towards constructing more accurate computer vision algorithms, which require massive amounts of training and testing data not currently available. Peekaboom has been played by thousands of people, some of whom have spent over 12 hours a day playing, and thus far has generated millions of data points. In addition to its purely utilitarian aspect, Peekaboom is an example of a new, emerging class of games, which not only bring people together for leisure purposes, but also exist to improve artificial intelligence. Such games appeal to a general audience, while providing answers to problems that computers cannot yet solve.
2006	Representation of interwoven surfaces in 2 1/2 D drawing	The state-of-the-art in computer drawing programs is based on a number of concepts that are over two decades old. One such concept is the use of layers for ordering the surfaces in a drawing from top to bottom. Unfortunately, the use of layers unnecessarily imposes a partial ordering on the depths of the surfaces and prevents the user from creating a large class of potential drawings, e.g., of Celtic knots and interwoven surfaces. In this paper we describe a novel approach which only requires local depth ordering of segments of the boundaries of surfaces in a drawing rather than a global depth relation between entire surfaces. Our program provides an intuitive user interface which allows a novice to create complex drawings of interwoven surfaces that would be difficult and time-consuming to create with standard drawing programs.
2006	Verbosity: a game for collecting common-sense facts	We address the problem of collecting a database of ""common-sense facts"" using a computer game. Informally, a common-sense fact is a true statement about the world that is known to most humans: ""milk is white,"" ""touching hot metal hurts,"" etc. Several efforts have been devoted to collecting common-sense knowledge for the purpose of making computer programs more intelligent. Such efforts, however, have not succeeded in amassing enough data because the manual process of entering these facts is tedious. We therefore introduce Verbosity, a novel interactive system in the form of an enjoyable game. People play Verbosity because it is fun, and as a side effect of them playing, we collect accurate common-sense knowledge. Verbosity is an example of a game that not only brings people together for leisure, but also collects useful data for computer science.
2006	Improving accessibility of the web with a computer game	Images on the Web present a major accessibility issue for the visually impaired, mainly because the majority of them do not have proper captions. This paper addresses the problem of attaching proper explanatory text descriptions to arbitrary images on the Web. To this end, we introduce Phetch, an enjoyable computer game that collects explanatory descriptions of images. People play the game because it is fun, and as a side effect of game play we collect valuable information. Given any image from the World Wide Web, Phetch can output a correct annotation for it. The collected data can be applied towards significantly improving Web accessibility. In addition to improving accessibility, Phetch is an example of a new class of games that provide entertainment in exchange for human processing power. In essence, we solve a typical computer vision problem with HCI tools alone.
2006	Evaluating interfaces for privacy policy rule authoring	Privacy policy rules are often written in organizations by a team of people in different roles. Currently, people in these roles have no technological tools to guide the creation of clear and implementable high-quality privacy policy rules. High-quality privacy rules can be the basis for verifiable automated privacy access decisions. An empirical study was conducted with 36 users who were novices in privacy policy authoring to evaluate the quality of rules created and user satisfaction with two experimental privacy authoring tools and a control condition. Results show that users presented with scenarios were able to author significantly higher quality rules using either the natural language with a privacy rule guide tool or a structured list tool as compared to an unguided natural language control condition. The significant differences in quality were found in both user self-ratings of rule quality and objective quality scores. Users ranked the two experimental tools significantly higher than the control condition. Implications of the research and future research directions are discussed.
2006	Putting people in their place: an anonymous and privacy-sensitive approach to collecting sensed data in location-based applications	The emergence of location-based computing promises new and compelling applications, but raises very real privacy risks. Existing approaches to privacy generally treat people as the entity of interest, often using a fidelity tradeoff to manage the costs and benefits of revealing a person's location. However, these approaches cannot be applied in some applications, as a reduction in precision can render location information useless. This is true of a category of applications that use location data collected from multiple people to infer such information as whether there is a traffic jam on a bridge, whether there are seats available in a nearby coffee shop, when the next bus will arrive, or if a particular conference room is currently empty. We present hitchhiking, a new approach that treats locations as the primary entity of interest. Hitchhiking removes the fidelity tradeoff by preserving the anonymity of reports without reducing the precision of location disclosures. We can therefore support the full functionality of an interesting class of location-based applications without introducing the privacy concerns that would otherwise arise.
2006	Advancing ambiguity	Ambiguity is an important concept for HCI because of its pervasiveness in everyday life, yet its emergent nature challenges the role of design. We examine these difficulties with regards to Aoki and Woodruff's [1] proposal to use ambiguity as a resource for designing space for stories in personal communication systems. We challenge certain assumptions about ambiguity and propose a set of design and evaluation guidelines that flow from this re-conceptualization of ambiguity and design.
2006	Girls, technology and privacy: is my mother listening?	This paper describes a study undertaken to explore the ways in which older teenage girls use technology to construct and maintain a sense of private space while living at home with parents. The study used blogging as an experimental and integral part of the research, in order to facilitate ongoing communication between researcher and participant.
2006	Dogear: Social bookmarking in the enterprise	We describe a social bookmarking service de-signed for a large enterprise. We discuss design principles addressing online identity, privacy, information discovery (including search and pivot browsing), and service extensi-bility based on a web-friendly architectural style. In addi-tion we describe the key design features of our implementa-tion. We provide the results of an eight week field trial of this enterprise social bookmarking service, including a de-scription of user activities, based on log file analysis. We share the results of a user survey focused on the benefits of the service. The feedback from the user trial, comprising survey results, log file analysis and informal communica-tions, is quite positive and suggests several promising en-hancements to the service. Finally, we discuss potential extension and integration of social bookmarking services with other corporate collaborative applications.
2006	Increasing user decision accuracy using suggestions	The internet presents people with an increasingly bewildering variety of choices. Online consumers have to rely on computerized search tools to find the most preferred option in a reasonable amount of time. Recommender systems address this problem by searching for options based on a model of the user's preferences. We consider example critiquing as a methodology for mixed-initiative recommender systems. In this technique, users volunteer their preferences as critiques on examples. It is thus important to stimulate their preference expression by selecting the proper examples, called suggestions. We describe the look-ahead principle for suggestions and describe several suggestion strategies based on it. We compare them in simulations and, for the first time, report a set of user studies which prove their effectiveness in increasing users' decision accuracy by up to 75\%.
2006	Co-authoring with structured annotations	Most co-authoring tools support basic annotations, such as edits and comments that are anchored at specific locations in the document. However, they do not support meta-commentary about a document (such as an author's summary of modifications) which gets separated from the document, often in the body of email messages. This causes unnecessary overhead in the write-review-edit workflow inherent in co-authoring. We present document-embedded structured annotations called "bundles" that incorporate the meta-commentary into a unified annotation model that meets a set of annotation requirements we identified through a small field investigation. A usability study with 20 subjects evaluated the annotation reviewing stage of co-authoring and showed that annotation bundles in our high-fidelity prototype reduced reviewing time and increased accuracy, compared to a system that only supports edits and comments.
2006	LINC-ing the family: the participatory design of an inkable family calendar	Families must continually organize, plan, and stay aware of the activities of their households in order to coordinate everyday life. Despite having organization schemes, many people still feel overwhelmed when it comes to family coordination. To help overcome this, we present our research efforts on LINC: an inkable family calendar designed for the kitchen. LINC was developed using a participatory design process involving interviews, paper prototyping, and a formative evaluation. Our work outlines key implications for digital family calendars and family coordination systems in general. We found that coordination is not typically done through the family calendar; rather, the family calendar is a tool that provides family members with an awareness of activities and changes that in turn enables coordination. Thus, digital family calendars should provide tools that enable families to use their own coordination routines which leverage the social affordances prominent in existing paper calendars.
2006	Participatory design with proxies: developing a desktop-PDA system to support people with aphasia	In this paper, we describe the design and preliminary evaluation of a hybrid desktop-handheld system developed to support individuals with aphasia, a disorder which impairs the ability to speak, read, write, or understand language. The system allows its users to develop speech communication through images and sound on a desktop computer and download this speech to a mobile device that can then support communication outside the home. Using a desktop computer for input addresses some of this population's difficulties interacting with handheld devices, while the mobile device addresses stigma and portability issues. A modified participatory design approach was used in which proxies, that is, speech-language pathologists who work with aphasic individuals, assumed the role normally filled by users. This was done because of the difficulties in communicating with the target population and the high variability in aphasic disorders. In addition, the paper presents a case study of the proxy-use participatory design process that illustrates how different interview techniques resulted in different user feedback.
2006	Participatory design in emergency medical service: designing for future practice	We describe our research-its approach, results and products-on Danish emergency medical service (EMS) field or "pre-hospital" work in minor and major incidents. We discuss how commitments to participatory design and attention to the qualitative differences between minor and major incidents address challenges identified by disaster sociolo-gists when designing for major incidents. Through qualitative research and participatory design, we have examined the features of EMS work and technology use in different emergency situations from the perspective of multiple actors. We conceptualize victims in incidents-and particularly in major incidents, where on-site medical as-sessments is highly incomplete-as boundary objects over which the complex and imperfect work of coordination is done. As an outcome of our participatory design approach, we describe a set of designs in support of future EMS work.
2006	A role for haptics in mobile interaction: initial design using a handheld tactile display prototype	Mobile interaction can potentially be enhanced with well-designed haptic control and display. However, advances have been limited by a vicious cycle whereby inadequate haptic technology obstructs inception of vitalizing applications. We present the first stages of a systematic design effort to break that cycle, beginning with specific usage scenarios and a new handheld display platform based on lateral skin stretch. Results of a perceptual device characterization inform mappings between device capabilities and specific roles in mobile interaction, and the next step of hardware re-engineering.
2006	The springboard: multiple modes in one spring-loaded control	Modes allow a few inputs to invoke many operations, yet if a user misclassifies or forgets the state of a system, modes can result in errors. Spring-loaded modes (quasimodes) maintain a mode while the user holds a control such as a button or key. The Springboard is an interaction technique for tablet computers that extends quasimodes to encompass multiple tool modes in a single spring-loaded control. The Springboard allows the user to continue holding down a nonpreferred-hand command button after selecting a tool from a menu as a way to repeatedly apply the same tool. We find the Springboard improves performance for both a local marking menu and for a non-local marking menu ("lagoon") at the lower left corner of the screen. Despite the round-trip costs incurred to move the pen to a tool lagoon, a keystroke-level analysis of the true cost of each technique reveals the local marking menu is not significantly faster.
2006	The GlobeFish and the GlobeMouse: two new six degree of freedom input devices for graphics applications	We introduce two new six degree of freedom desktop input devices based on the key concept of combining forceless isotonic rotational input with force-requiring elastic translational input. The GlobeFish consists of a custom three degrees of freedom trackball which is elastically connected to a frame. The trackball is accessible from the top and bottom and can be moved slightly in all spatial directions by using force. The GlobeMouse device works in a similar way. Here the trackball is placed on top of a movable base, which requires to change the grip on the device to switch between rotating the trackball and moving the base.Our devices are manipulated with the fingertips allowing precise interaction with virtual objects. The elastic translation allows uniform input for all three axes and the isotonic trackball provides a natural mapping for rotations. Our user study revealed that the new devices perform significantly better in a docking task in comparison to the SpaceMouse, an integrated six degrees of freedom controller. Subjective data confirmed these results.
2006	Making action visible in time-critical work	This paper presents descriptive accounts from an ethnographic study of time-critical work in the domain of emergency response and the operative work of fire crews. The verbal communication as part of such work creates difficulties in providing accountability of the fire crew's actions. The concept of work rhythms and temporal structures is used as an analytical framework. Design implications are presented suggesting that verbal communication should be made persistent, visible and accessible in order to support accountability. These design implications are discussed in relation to the fire crew's work practice.
2006	Support for activity-based computing in a personal computing operating system	Research has shown that computers are notoriously bad at supporting the management of parallel activities and interruptions, and that mobility increases the severity of these problems. This paper presents activity-based computing (ABC) which supplements the prevalent data- and application-oriented computing paradigm with technologies for handling multiple, parallel and mobile work activities. We present the design and implementation of ABC support embedded in the Windows XP operating system. This includes replacing the Windows Taskbar with an Activity Bar, support for handling Windows applications, a zoomable user interface, and support for moving activities across different computers. We report an evaluation of this Windows XP ABC system which is based on a multi-method approach, where perceived ease-of-use and usefulness was evaluated together with rich interview material. This evaluation showed that users found the ABC XP extension easy to use and likely to be useful in their own work.
2006	Share and share alike: exploring the user interface affordances of file sharing	With the rapid growth of personal computer networks and the Internet, sharing files has become a central activity in computer use. The ways in which users control the what, how, and with whom of sharing are dictated by the tools they use for sharing; there are a wide range of sharing practices, and hence a wide range of tools to support these practices. In practice, users' requirements for certain sharing features may dictate their choice of tool, even though the other affordances available through that tool may not be an ideal match to the desired manner of sharing.In this paper, we explore users' current practices in file sharing and examine the tools used to share files. Based on our findings, we unpack the features and affordances of these tools into a set of dimensions along which sharing tools can be characterized. Then, we present the set of user interface features we have prototyped in an interface called a sharing palette, which provides a platform for exploration and experimentation with new modalities of sharing. We briefly present the tool as a whole and then focus on the individual features of the sharing palette that support reported styles of sharing.
2006	Tinkering and gender in end-user programmers' debugging	Earlier research on gender effects with software features intended to help problem-solvers in end-user debugging environments has shown that females are less likely to use unfamiliar software features. This poses a serious problem because these features may be key to helping them with debugging problems. Contrasting this with research documenting males' inclination for tinkering in unfamiliar environments, the question arises as to whether encouraging tinkering with new features would help females overcome the factors, such as low self-efficacy, that led to the earlier results. In this paper, we present an experiment with males and females in an end-user debugging setting, and investigate how tinkering behavior impacts several measures of their debugging success. Our results show that the factors of tinkering, reflection, and self-efficacy, can combine in multiple ways to impact debugging effectiveness differently for males than for females.
2006	An evaluation of using programming by demonstration and guided walkthrough techniques for authoring and utilizing documentation	Much existing documentation is informal and serves to communicate "how-to" knowledge among restricted working groups. Using current practices, such documentation is both difficult to maintain and difficult to use properly.In this paper, we propose a documentation system, called DocWizards, that uses programming by demonstration to support low-cost authoring and guided walkthrough techniques to improve document usability.We report a comparative study between the use of DocWizards and traditional techniques for authoring and following documentation. The study participants showed significant gains in efficiency and reduction in error rates when using DocWizards. In addition, they expressed a clear preference for using the DocWizards tool, both for authoring and for following documentation.
2006	Providing support for adaptive scripting in an on-line collaborative learning environment	This paper describes results from a series of experimental studies to explore issues related to structuring productive group dynamics for collaborative learning using an adaptive support mechanism. The first study provides evidence in favor of the feasibility of the endeavor by demonstrating with a tightly controlled study that even without adaptive support, problem solving in pairs is significantly more effective for learning than problem solving alone. The results from a second study offer guidelines for strategic matching of students with learning partners. Furthermore, the results reveal specific areas for needed support. Based on the results from the second study, we present the design of an adaptive support mechanism, which we evaluate in a third study. The results from the third study provide evidence that certain aspects of our design for adaptive support in the form of strategic prompts are effective for manipulating student behavior in productive ways and for supporting learning. These results also motivate specific modifications to the original design.
2006	Fast, flexible filtering with phlat	Systems for fast search of personal information are rapidly becoming ubiquitous. Such systems promise to dramatically improve personal information management, yet most are modeled on Web search in which users know very little about the content that they are searching. We describe the design and deployment of a system called Phlat that optimizes search for personal information with an intuitive interface that merges search and browsing through a variety of associative and contextual cues. In addition, Phlat supports a unified tagging (labeling) scheme for organizing personal content across storage systems (files, email, etc.). The system has been deployed to hundreds of employees within our organization. We report on both quantitative and qualitative aspects of system use. Phlat is available as a free download at http://research.microsoft.com/adapt/phlat.
2006	The project fragmentation problem in personal information management	The project fragmentation problem in personal information management occurs when someone who is working on a single project stores and retrieves information items relating to that project from separate format-related collections (documents, emails and favorite Web sites). This study was aimed to test empirically users' working habits in order to shed light on the project fragmentation problem. Twenty personal computer users participated in the study. Data collection tools included an interview, screen captures and a questionnaire. Results indicate that users tend to store and retrieve project-related information items based on different formats in one project folder when the interface design encourages it. However, they store and retrieve project- related information items in different folders (documents, emails and favorite Web sites) when the design encourages such fragmentation. Two types of attempts to solve the project fragmentation problem are reviewed and a new possible solution is suggested.
2006	To have and to hold: exploring the personal archive	The personal archive is not only about efficient storage and retrieval of information. This paper describes a study of forty-eight academics and the techniques and tools they use to manage their digital and material archiving of papers, emails, documents, internet bookmarks, correspondence, and other artifacts. We present two sets of results: we first discuss rationales behind subjects' archiving, which go beyond information retrieval to include creating a legacy, sharing resources, confronting fears and anxieties, and identity construction. We then show how these rationales were mapped into our subjects' physical, social and electronic spaces, and discuss implications for development of digital tools that allow for personal archiving.
2006	Peripheral display of digital handwritten notes	We present a system for the peripheral display of digital handwritten notes, motivated by the joint observation that people seldom refer back to their notes and that these notes often contain useful information. We describe the user-led design of the system, incorporating interviews, paper prototypes, and interactive prototypes. A preliminary field trial of the system indicates that users derive value from the system both for low-distraction reminding and for serendipitous idea generation. These promising initial results suggest significant scope for future work.
2006	Perspective cursor: perspective-based interaction for multi-display environments	Multi-display environments and smart meeting rooms are now becoming more common. These environments build a shared display space from variety of devices: tablets, projected surfaces, tabletops, and traditional monitors. Since the different display surfaces are usually not organized in a single plane, traditional schemes for stitching the displays together can cause problems for interaction. However, there is a more natural way to compose display space -- using perspective. In this paper, we develop interaction techniques for multi-display environments that are based on the user's perspective on the room. We designed the Perspective Cursor, a mapping of cursor to display space that appears natural and logical from wherever the user is located. We conducted an experiment to compare two perspective-based techniques, the Perspective Cursor and a beam-based technique, with traditional stitched displays. We found that both perspective techniques were significantly faster for targeting tasks than the traditional technique, and that Perspective Cursor was the most preferred method. Our results show that integrating perspective into the design of multi-display environments can substantially improve performance.
2006	Improving selection of off-screen targets with hopping	Many systems provide the user with a limited viewport of a larger graphical workspace. In these systems, the user often needs to find and select targets that are in the workspace, but not visible in the current view. Standard methods for navigating to the off-screen targets include scrolling, panning, and zooming; however, these are laborious when users cannot see a target's direction or distance. Techniques such as halos can provide awareness of targets, but actually getting to the target is still slow with standard navigation. To improve off-screen target selection, we developed a new technique called hop, which combines halos with a teleportation mechanism that shows proxies of distant objects. Hop provides both awareness of off-screen targets and fast navigation to the target context. A study showed that users are significantly faster at selecting off-screen targets with hopping than with two-level zooming or grab-and-drag panning, and it is clear that hop will be faster than either halos or proxy-based techniques (like drag-and-pop or vacuum filtering) by themselves. Hop both improves on halo-based navigation and extends the value of proxies to small-screen environments.
2006	Effects of display position and control space orientation on user preference and performance	In many environments, it is often the case that input is made to displays that are positioned non-traditionally relative to one or more users. This typically requires users to perform interaction tasks under transformed input-display spatial mappings, and the literature is unclear as to how such transformations affect performance. We present two experiments that explore the impact of display space position and input control space orientation on user's subjective preference and objective performance in a docking task. Our results provide guidelines as to optimal display placement and control orientation in collaborative computing environments with one or more shared displays.
2006	The benefits of augmenting telephone voice menu navigation with visual browsing and search	Automatic interactive voice response (IVR) based telephone routing has long been recognized as a frustrating interaction experience. This paper presents a series of experiments examining the benefits of augmenting telephone voice menus with coordinated visual displays and keyword search. The first experiment qualitatively studied callers' experience of having a visual menu on a screen in synchronization with the telephone voice menu tree navigation. The second experiment quantitatively measured callers' performance in time and accuracy with and without visual display augmentation. The third experiment tested keyword search in comparison to visual browsing of telephone menu trees. Study participants uniformly and enthusiastically liked the visual augmentation of voice menus. On average with visual augmentation callers could navigate phone trees 36\% faster with 75\% fewer errors, and made choices ahead of the voice menu over 60\% of the time. Search vs. browsing had similar navigation performance but offered different and complementary user experiences. Overall our studies conclude that telephone voice menu navigation can be significantly improved with a visual channel augmentation, resulting in both business cost reduction and user experience satisfaction.
2006	Time is of the essence: an evaluation of temporal compression algorithms	Although speech is a potentially rich information source, a major barrier to exploiting speech archives is the lack of useful tools for efficiently accessing lengthy speech recordings. This paper develops and evaluates techniques for temporal compression - reducing the time people take to listen to a recording while still extracting critical information. We first describe an exploratory study that identifies novel excision techniques that remove unimportant words or utterances from the recording. We then develop a new method for evaluating how well temporal compression supports users in forming a general understanding of a recording. Applying this method, we demonstrate that excision techniques are generally more effective than standard compression techniques that simply speed up the entire recording.
2006	Error correction of voicemail transcripts in SCANMail	Despite its widespread use, voicemail presents numerous usability challenges: People must listen to messages in their entirety, they cannot search by keywords, and audio files do not naturally support visual skimming. SCANMail overcomes these flaws by automatically generating text transcripts of voicemail messages and presenting them in an email-like interface. Transcripts facilitate quick browsing and permanent archive. However, errors from the automatic speech recognition (ASR) hinder the usefulness of the transcripts. The work presented here specifically addresses these problems by evaluating user-initiated error correction of transcripts. User studies of two editor interfaces-a grammar-assisted menu and simple replacement by typing-reveal reduced audio playback times and an emphasis on editing important words with the menu, suggesting its value in mobile environments where limited input capabilities are the norm and user privacy is essential. The study also adds to the scarce body of work on ASR confidence shading, suggesting that shading may be more helpful than previously reported.
2006	symSpline: symmetric two-handed spline manipulation	We introduce symSpline: a symmetric, dual-mouse technique for the manipulation of spline curves. In symSpline, two cursors control the positions of the ends of the tangent to an edit point. By moving the tangent with both mice, the tangent and the edit point can be translated while the curvature of the spline is adjusted simultaneously, according to the length and angle of the tangent. We compare the symSpline technique to two asymmetric dual-mouse spline manipulation techniques and to a standard single-mouse technique. In a spline matching experiment, symSpline outperformed the two asymmetric dual-mouse techniques and all three dual-mouse techniques proved to be faster than the single-mouse technique. Additionally, symSpline was the technique most preferred by test participants.
2006	Effects of feedback, mobility and index of difficulty on deictic spatial audio target acquisition in the horizontal plane	We present the results of an empirical study investigating the effect of feedback, mobility and index of difficulty on a deictic spatial audio target acquisition task in the horizontal plane in front of a user. With audio feedback, spatial audio display elements are found to enable usable deictic interac-tion that can be described using Fitts law. Feedback does not affect perceived workload or preferred walking speed compared to interaction without feedback. Mobility is found to degrade interaction speed and accuracy by 20\%. Participants were able to perform deictic spatial audio target acquisition when mobile while walking at 73\% of their pre-ferred walking speed. The proposed feedback design is ex-amined in detail and the effects of variable target widths are quantified. Deictic interaction with a spatial audio display is found to be a feasible solution for future interface designs.
2006	Prototyping retractable string-based interaction techniques for dual-display mobile devices	Accessing information on mobile and wearable devices often requires the user's visual attention, and the precise operation of virtual or physical widgets. However, these interactions may sometimes be too time-consuming and socially inappropriate. To address this, we introduce a novel input/output device that is based on the manipulation of a retractable string in a polar coordinate frame. Depending on how the user pulls the string from its enclosure--to a particular length, at a particular angle--various system features may be directly accessed. Furthermore, we present our concept for a 1D pixel array, embedded in the string that may be used as a secondary 1D display. Since it is possible to unwind the display itself and trigger functionality with a single pull, information may be accessed and presented quickly, and perceived at a glance. We present scenarios for how the string input/output device may be used in conjunc-tion with the mobile device's primary 2D display and describe our augmented reality proof-of-concept prototype.
2006	Enhancing human-machine interactions: virtual interface alteration through wearable computers	This paper studies a novel approach advocating the virtual alteration of real-world interfaces through a form of augmented reality. Following an introduction reminding the need for easy to use and more consistent interfaces across our many day to day devices, this paper makes the case for using wearable computers to enhance the interactions between humans and conventional appliances. We present the rationale behind our research and summarize our current prototype's functionalities, architecture and implementation. Preliminary results suggest that virtually altering the interface of real world devices improves execution times for simple tasks using these devices.
2006	Evaluating a fisheye view of source code	Navigating and understanding the source code of a program are highly challenging activities. This paper introduces a fisheye view of source code to a Java programming environment. The fisheye view aims to support a programmer's navigation and understanding by displaying those parts of the source code that have the highest degree of interest given the current focus. An experiment was conducted which compared the usability of the fisheye view with a common, linear presentation of source code. Sixteen participants performed tasks significantly faster with the fisheye view, although results varied dependent on the task type. The participants generally preferred the interface with the fisheye view. We analyse participants' interaction with the fisheye view and suggest how to improve its performance. In the calculation of the degree of interest, we suggest to emphasize those parts of the source code that are semantically related to the programmer's current focus.
2006	Barista: An implementation framework for enabling new tools, interaction techniques and views in code editors	Recent advances in programming environments have focused on improving programmer productivity by utilizing the inherent structure in computer programs. However, because these environments represent code as plain text, it is difficult and sometimes impossible to embed interactive tools, annotations, and alternative views in the code itself. Barista is an implementation framework that enables the creation of such user interfaces by simplifying the implementation of editors that represent code internally as an abstract syntax tree and maintain a corresponding, fully structured visual representation on-screen. Barista also provides designers of editors with a standard text-editing interaction technique that closely mimics that of conventional text editors, overcoming a central usability issue of previous structured code editors.
2006	Answering why and why not questions in user interfaces	Modern applications such as Microsoft Word have many automatic features and hidden dependencies that are frequently helpful but can be mysterious to both novice and expert users. The ""Crystal"" application framework provides an architecture and interaction techniques that allow programmers to create applications that let the user ask a wide variety of questions about why things did and did not happen, and how to use the related features of the application without using natural language. A user can point to an object or a blank space and get a popup list of questions about it, or the user can ask about recent actions from a temporal list. Parts of a text editor were implemented to show that these techniques are feasible, and a user test suggests that they are helpful and well-liked.
2006	Alone together?: exploring the social dynamics of massively multiplayer online games	Massively Multiplayer Online Games (MMOGs) routinely attract millions of players but little empirical data is available to assess their players' social experiences. In this paper, we use longitudinal data collected directly from the game to examine play and grouping patterns in one of the largest MMOGs: World of Warcraft. Our observations show that the prevalence and extent of social activities in MMOGs might have been previously over-estimated, and that gaming communities face important challenges affecting their cohesion and eventual longevity. We discuss the implications of our findings for the design of future games and other online social spaces.
2006	Interweaving mobile games with everyday life	We introduce a location--based game called Feeding Yoshi that provides an example of seamful design, in which key characteristics of its underlying technologies-the coverage and security characteristics of WiFi-are exposed as a core element of gameplay. Feeding Yoshi is also a long--term, wide--area game, being played over a week between three different cities during an initial user study. The study, drawing on participant diaries and interviews, supported by observation and analysis of system logs, reveals players' reactions to the game. We see the different ways in which they embedded play into the patterns of their daily lives, augmenting existing practices and creating new ones, and observe the impact of varying location on both the ease and feel of play. We identify potential design extensions to Feeding Yoshi and conclude that seamful design provides a route to creating engaging experiences that are well adapted to their underlying technologies.
2006	The Frame of the Game: Blurring the Boundary between Fiction and Reality in Mobile Experiences	Mobile experiences that take place in public settings such as on city streets create new opportunities for interweaving the fictional world of a performance or game with the everyday physical world. A study of a touring performance reveals how designers generated excitement and dramatic tension by implicating bystanders and encouraging the (apparent) crossing of normal boundaries of behaviour. The study also shows how designers dealt with associated risks through a process of careful orchestration. Consequently, we extend an existing framework for designing spectator interfaces with the concept of performance frames, enabling us to distinguish audience from bystanders. We conclude that using ambiguity to blur the frame can be a powerful design tactic, empowering players to willingly suspend disbelief, so long as a safety-net of orchestration ensures that they do not stray into genuine difficulty.
2006	Getting a grip on tangible interaction: a framework on physical space and social interaction	Our current understanding of human interaction with hybrid or augmented environments is very limited. Here we focus on 'tangible interaction', denoting systems that rely on embodied interaction, tangible manipulation, physical representation of data, and embeddedness in real space. This synthesis of prior 'tangible' definitions enables us to address a larger design space and to integrate approaches from different disciplines. We introduce a framework that focuses on the interweaving of the material/physical and the social, contributes to understanding the (social) user experience of tangible interaction, and provides concepts and perspectives for considering the social aspects of tangible interaction. This understanding lays the ground for evolving knowledge on collaboration-sensitive tangible interaction design. Lastly, we analyze three case studies, using the framework, thereby illustrating the concepts and demonstrating their utility as analytical tools.
2006	Finding design qualities in a tangible programming space	We reflect upon the process of developing a tangible space for children's collaborative construction of screen-based systems. As in all design work, the design process involved continual refinements of initial ideas and their practical realisation. We discuss how some widely held assumptions often put forward with tangible interfaces were given up in favour of reaching overall goals of interaction. In particular our design involved a shift from a focus on persistent representation and readability of tangible code structures, to instead focus on achieving reusability of programming resources. On a general level, our results illustrate a view on tangibles as resources for action instead of only as alternative forms of data representation. Importantly, this view includes action directed towards the computer as well as off-line socially oriented action conducted with the tangible artefacts.
2006	Design requirements for technologies that encourage physical activity	Overweight and obesity are a global epidemic, with over one billion overweight adults worldwide (300+ million of whom are obese). Obesity is linked to several serious health problems and medical conditions. Medical experts agree that physical activity is critical to maintaining fitness, reducing weight, and improving health, yet many people have difficulty increasing and maintaining physical activity in everyday life. Clinical studies have shown that health benefits can occur from simply increasing the number of steps one takes each day and that social support can motivate people to stay active. In this paper, we describe Houston, a prototype mobile phone application for encouraging activity by sharing step count with friends. We also present four design requirements for technologies that encourage physical activity that we derived from a three-week long in situ pilot study that was conducted with women who wanted to increase their physical activity.
2006	An intuitive text input method for touch wheels	In this paper we describe a new method for doing text input with touch sensitive wheels. The method is called Transparent User guided Prediction (TUP). With TUP all characters are assigned to fixed positions on the wheel. A language prediction algorithm is used to make it easy to select the most likely characters. The use of the prediction algorithm is transparent for the users, which makes the use of TUP very intuitive. A prototype of TUP is evaluated against the date stamp method for doing wheel text input. Text entry speed for TUP is about 6-7 words per minute for novice users. This is approximately 30\% faster than the date stamp method.
2006	A new error metric for text entry method evaluation	On devices such as mobile phones, text is often entered using keypads and predictive text entry techniques. Current metrics used for measuring text entry error rates have limitations in terms of the types of errors they account for, and cannot easily distinguish between different types of errors. This research proposes a new text entry error metric that addresses some of the outstanding issues that exist with current metrics. Specifically, the metric accounts in detail for the way the user handles corrections during text entry, moving beyond current keystroke level error measurement. The feasibility and usefulness of this new metric is shown through the analysis of an experiment that tests an alphabetically constrained keypad design that includes upper and lower case letters, numbers, and punctuation marks.
2006	Text entry using a dual joystick game controller	We present a new bimanual text entry technique designed for today's dual-joystick game controllers. The left and right joysticks are used to independently select characters from the corresponding (left/right) half of an on-screen se-lection keyboard. Our dual-stick approach is analogous to typing on a standard keyboard, where each hand (left/right) presses keys on the corresponding side of the keyboard. We conducted a user study showing that our technique supports keyboarding skills transfer and is thereby readily learnable. Our technique increases entry speed significantly compared to the status quo single stick selection keyboard technique.
2006	Trackball text entry for people with motor impairments	We present a new gestural text entry method for trackballs. The method uses the mouse cursor and relies on crossing instead of pointing. A user writes in fluid Roman-like unistrokes by ""pulsing"" the trackball in desired letter patterns. We examine this method both theoretically using the Steering Law and empirically in two studies. Our studies show that able-bodied users who were unfamiliar with trackballs could write at about 10 wpm with <4\% total errors after 45 minutes. In eight sessions, a motor-impaired trackball user peaked at 7.11 wpm with 0\% uncorrected errors, compared to 5.95 wpm with 0\% uncorrected errors with an on-screen keyboard. Over sessions, his speeds were significantly faster with our gestural method than with an on-screen keyboard. A former 15-year veteran of on-screen keyboards, he now uses our gestural method instead.
2006	Few-key text entry revisited: mnemonic gestures on four keys	We present a new 4-key text entry method that, unlike most few-key methods, is gestural instead of selection-based. Importantly, its gestures mimic the writing of Roman letters for high learnability. We compare this new 4-key method to predominant 3-key and 5-key methods theoretically using KSPC and empirically using a longitudinal study of 5 subjects over 10 sessions. The study includes an evaluation of the 4-key method without any on-screen visualization-an impossible condition for the selection-based methods. Our results show that the new 4-key method is quickly learned, becoming faster than the 3-key and 5-key methods after just ~10 minutes of writing, although it produces more errors. Interestingly, removing a visualization of the gestures being made causes no detriment to the 4-key method, which is an advantage for eyes-free text entry.
2006	The effect of speech recognition accuracy rates on the usefulness and usability of webcast archives	The widespread availability of broadband connections has led to an increase in the use of Internet broadcasting (webcasting). Most webcasts are archived and accessed numerous times retrospectively. In the absence of transcripts of what was said, users have difficulty searching and scanning for specific topics. This research investigates user needs for transcription accuracy in webcast archives, and measures how the quality of transcripts affects user performance in a question-answering task, and how quality affects overall user experience. We tested 48 subjects in a within-subjects design under 4 conditions: perfect transcripts, transcripts with 25\% Word Error Rate (WER), transcripts with 45\% WER, and no transcript. Our data reveals that speech recognition accuracy linearly influences both user performance and experience, shows that transcripts with 45\% WER are unsatisfactory, and suggests that transcripts having a WER of 25\% or less would be useful and usable in webcast archives.
2006	Visual search and reading tasks using ClearType and regular displays: two experiments	Two experiments comparing user performance on ClearType and Regular displays are reported. In the first, 26 participants scanned a series of spreadsheets for target information. Speed of performance was significantly faster with ClearType. In the second experiment, 25 users read two articles for meaning. Reading speed was significantly faster for ClearType. In both experiments no differences in accuracy of performance or visual fatigue scores were observed. The data also reveal substantial individual differences in performance suggesting ClearType may not be universally beneficial to information workers.
2006	Using hybrid networks for the analysis of online software development communities	Social network-based systems usually suffer from two major limitations: they tend to rely on a single data source (e.g. email traffic), and the form of network patterns is often privileged over their content. To go beyond these limitations we describe a system we developed to visualize and navigate hybrid networks constructed from multiple data sources - with a direct link between formal representations and the raw content. We illustrate the benefits of our approach by analyzing patterns of collaboration in a large Open Source project, using hybrid networks to uncover important roles that would otherwise have been missed.
2006	Visualization of large hierarchical data by circle packing	In this paper a novel approach is described for tree visualization using nested circles. The brother nodes at the same level are represented by externally tangent circles; the tree nodes at different levels are displayed by using 2D nested circles or 3D nested cylinders. A new layout algorithm for tree structure is described. It provides a good overview for large data sets. It is easy to see all the branches and leaves of the tree. The new method has been applied to the visualization of file systems.
2006	Dispelling design as the black art of CHI	We discuss the legacy and processes of creative design, and differentiate it from the type of user-centered design commonly found in CHI. We provide an example of this process, and discuss how design practice constitutes an essential mode of inquiry. We argue the complementary nature of creative design and user-centered design practices. Syncretic disciplines shift and drift from their original practice. A key issue is how CHI is to respond to changes in acceptable design practice. A key contribution of this work is an illustrative example showing how designers can communicate their intellectual rigor to the CHI community.
2006	Interaction in creative tasks	The design of tools for creative activities affects the creative processes and output of users. In this paper we consider how an understanding of creative interaction can inform the design of support tools in a creative domain, and where creative needs cross domain boundaries. Using observations of musical composers we analyse the theoretical approaches to understanding creativity and their use to HCI. Cycles of ideation and evaluation are suggested as atomic elements of creative interactions, with the representation of ideas a central activity for individual and collaborating composers. A model of collaborative composition was developed, along with an analysis of the representational types used in the domain. This led to the design and evaluation of a prototype Sonic Sketchpad for musical idea representation.
2006	Implications for design	Although ethnography has become a common approach in HCI research and design, considerable confusion still attends both ethnographic practice and the criteria by which it should be evaluated in HCI. Often, ethnography is seen as an approach to field investigation that can generate requirements for systems development; by that token, the major evaluative criterion for an ethnographic study is the implications it can provide for design. Exploring the nature of ethnographic inquiry, this paper suggests that "implications for design" may not be the best metric for evaluation and may, indeed, fail to capture the value of ethnographic investigations.
2006	Mobile phones and paper documents: evaluating a new approach for capturing microfinance data in rural India	CAM is a user interface toolkit that allows a camera-equipped mobile phone to interact with paper documents. It is designed to automate inefficient, paper-intensive information processes in the developing world. In this paper we present a usability evaluation of an application built using CAM for collecting data from microfinance groups in rural India. This application serves an important and immediate need in the microfinance industry. Our quantitative results show that the user interface is efficient, accurate and can quickly be learned by rural users. The results were competitive with an equivalent PC-based UI. Qualitatively, the interface was found easy to use by almost all users. This shows that, with a properly designed user interface, mobile phones can be a preferred platform for many rural computing applications. Voice feedback and numeric data entry were particularly well-received by users. We are conducting a pilot of this application with 400 microfinance groups in India.
2006	Handling documents and discriminating objects in hybrid spaces	Recently a number of researchers have uncovered various ways in which paper documents support everyday work practice and have suggested how these may be reflected in the design of new technologies. In this paper we consider how activities on and around paper documents may be supported when participants are remote from each other. When we consider the uses of an experimental system that provides a number of resources for supporting work over documents, it becomes apparent how critical it is to support apparently simple pointing and referencing, and how complex such conduct can be. This suggests some considerations both for developers of enhanced media spaces and analysts of everyday conduct.Clarified descriptions of technology and fragments including changes to figures. Added points concerning the scope of the technology the conception of sequence and calrified the requirement regarding redundancy. Revised descriptions of fragments in an atempt to make thsee less dense Corrected several typographic errors including those mentioned by the reviewers' gesture.
2006	ButterflyNet: a mobile capture and access system for field biology research	Through a study of field biology practices, we observed that biology fieldwork generates a wealth of heterogeneous information, requiring substantial labor to coordinate and distill. To manage this data, biologists leverage a diverse set of tools, organizing their effort in paper notebooks. These observations motivated ButterflyNet, a mobile capture and access system that integrates paper notes with digital photographs captured during field research. Through ButterflyNet, the activity of leafing through a notebook expands to browsing all associated digital photos. ButterflyNet also facilitates the transfer of captured content to spreadsheets, enabling biologists to share their work. A first-use study with 14 biologists found this system to offer rich data capture and transformation, in a manner felicitous with current practice.
2006	Why phishing works	To build systems shielding users from fraudulent (or phishing) websites, designers need to know which attack strategies work and why. This paper provides the first empirical evidence about which malicious strategies are successful at deceiving general users. We first analyzed a large set of captured phishing attacks and developed a set of hypotheses about why these strategies might work. We then assessed these hypotheses with a usability study in which 22 participants were shown 20 web sites and asked to determine which ones were fraudulent. We found that 23\% of the participants did not look at browser-based cues such as the address bar, status bar and the security indicators, leading to incorrect choices 40\% of the time. We also found that some visual deception attacks can fool even the most sophisticated users. These results illustrate that standard security indicators are not effective for a substantial fraction of users, and suggest that alternative approaches are needed.
2006	Secrecy, flagging, and paranoia: adoption criteria in encrypted email	We consider the social context behind users' decisions about whether and when to encrypt email, interviewing a sample of users from an organization whose mission requires secrecy. Interview participants varied in their level of technical sophistication and in their involvement with secrets. We found that users saw universal, routine use of encryption as paranoid. Encryption flagged a message not only as confidential but also as urgent, so users found the encryption of mundane messages annoying. In general, decisions about encryption were driven not just by technical issues such as usability, but also by social factors. We argue that understanding these social factors is necessary to guide the design of encryption technologies that can be more widely adopted.
2006	Do security toolbars actually prevent phishing attacks?	Security toolbars in a web browser show security-related information about a website to help users detect phishing attacks. Because the toolbars are designed for humans to use, they should be evaluated for usability -- that is, whether these toolbars really prevent users from being tricked into providing personal information. We conducted two user studies of three security toolbars and other browser security indicators and found them all ineffective at preventing phishing attacks. Even though subjects were asked to pay attention to the toolbar, many failed to look at it; others disregarded or explained away the toolbars' warnings if the content of web pages looked legitimate. We found that many subjects do not understand phishing attacks or realize how sophisticated such attacks can be.
2006	UNIFORM: automatically generating consistent remote control user interfaces	A problem with many of today's appliance interfaces is that they are inconsistent. For example, the procedure for setting the time on alarm clocks and VCRs differs, even among different models made by the same manufacturer. Finding particular functions can also be a challenge, because appliances often organize their features differently. This paper presents a system, called Uniform, which approaches this problem by automatically generating remote control interfaces that take into account previous interfaces that the user has seen during the generation process. Uniform is able to automatically identify similarities between different devices and users may specify additional similarities. The similarity information allows the interface generator to use the same type of controls for similar functions, place similar functions so that they can be found with the same navigation steps, and create interfaces that have a similar visual appearance.
2006	Generating automated predictions of behavior strategically adapted to specific performance objectives	It has been well established in Cognitive Psychology that humans are able to strategically adapt performance, even highly skilled performance, to meet explicit task goals such as being accurate (rather than fast). This paper describes a new capability for generating multiple human performance predictions from a single task specification as a function of different performance objective functions. As a demonstration of this capability, the Cognitive Constraint Modeling approach was used to develop models for several tasks across two interfaces from the aviation domain. Performance objectives are explicitly declared as part of the model, and the CORE (Constraint-based Optimal Reasoning Engine) architecture itself formally derives the detailed strategies that are maximally adapted to these objectives. The models are analyzed for emergent strategic variation, comparing those optimized for task time with those optimized for working memory load. The approach has potential application in user interface and procedure design.
2006	Automated summative usability studies: an empirical evaluation	This paper evaluates a method for summative usability testing using an automated data collection system. We found automated summative testing to be a simple and effective alternative to lab-based summative testing and could be successfully conducted remotely. In our study, a web-based control window led participants through the summative study, provided tasks to perform, and asked follow up questions about the user experience. Using a within-group comparison, we found no major differences between data collected by a usability engineer and that collected through an automated testing system for performance metrics. Using a between-group comparison, we found automated summative studies could be conducted remotely with minor but acceptable differences in time on task and likelihood to give up on a task compared to lab-based testing. Task success and task satisfaction ratings were not different between remote and lab-based summative testing. Written comments provided by participants through the testing system were sufficient to identify the major usability problems that led to task failure but did not reveal as comprehensive a set of issues as did a usability engineer observing the sessions.
2006	Olfoto: designing a smell-based interaction	We present a study into the use of smell for searching digi-tal photo collections. Many people now have large photo libraries on their computers and effective search tools are needed. Smell has a strong link to memory and emotion so may be a good way to cue recall when searching. Our study compared text and smell based tagging. For the first stage we generated a set of smell and tag names from user de-scriptions of photos, participants then used these to tag pho-tos, returning two weeks later to answer questions on their photos. Results showed that participants could tag effec-tively with text labels, as this is a common and familiar task. Performance with smells was lower but participants performed significantly above chance, with some partici-pants using smells well. This suggests that smell has poten-tial. Results also showed that some smells were consistently identified and useful, but some were not and highlighted issues with smell delivery devices. We also discuss some practical issues of using smell for interaction.
2006	The television will be revolutionized: effects of PVRs and filesharing on television watching	This paper investigates television-watching practices amongst early adopters of personal hard-disk video recorders (PVRs such as TiVotm) and Internet downloading of shows. Through in-depth interviews with early adopters, we describe how the rhythms of television watching change when decoupled from broadcast TV. For both the PVR users and downloaders TV watching has become less of a passive process, with viewers instead actively gathered shows from the schedules or online, and watching shows from their stored collection. From these results we discuss the 'video media lifecycle', and three new design concepts for supporting TV watching.
2006	Personal vs. commercial content: the similarities between consumer use of photos and music	We describe the results of two ethnographic-style studies that investigated consumer use of photos and music respectively. Although the studies were designed, executed, and analyzed separately, in our findings we discovered striking similarities between the ways in which our participants used personally captured photos and commercially purchased music. These findings have implications for the design of future systems with respect to handling and sharing content in photo or music form. We discuss making allowances for satisficing behavior, sharing media as a way to reminisce or to communicate an experience (tell a story), getting sidetracked while browsing, and similarities in organizing behaviors.
2006	TAP: touch-and-play	An intuitive context aware service between two devices is possible using touch with the intrabody communication. Using this technology, users with multimedia devices may simply touch them to establish network connection, transfer data, and provide the required service; hence the name Touch-And-Play (TAP). Using TAP, users can disclose their context by touching the specific device. For instance, a user carrying a digital camera touches the TV to begin a slide show or a printer to print a photo. TAP is expected to enable the provision of intuitive, context-aware service. This paper discusses the feasibility of TAP and its application in user interface.
2006	Beyond record and play: backpacks: tangible modulators for kinetic behavior	Digital Manipulatives embed computation in familiar children's toys and provide means for children to design behavior. Some systems use "record and play" as a form of programming by demonstration that is intuitive and easy to learn. With others, children write symbolic programs with a GUI and download them into a toy, an approach that is conceptually extensible, but is inconsistent with the physicality of educational manipulatives. The challenge we address is to create a tangible interface that can retain the immediacy and emotional engagement of "record and play" and incorporate a mechanism for real time and direct modulation of behavior during program execution.We introduce the Backpacks, modular physical components that children can incorporate into robotic creations to modulate frequency, amplitude, phase and orientation of motion recordings. Using Backpacks, children can investigate basic kinematic principles that underly why their specific creations exhibit the specific behaviors they observe. We demonstrate that Backpacks make tangible some of the benefits of symbolic abstraction, and introduce sensors, feedback and behavior modulation to the record and play paradigm. Through our review of user studies with children ages 6-15, we argue that Backpacks extend the conceptual limits of record and play with an interface that is consistent with both the physicality of educational manipulatives and the local-global systems dynamics that are characteristic of complex robots.
2006	Embedded phenomena: supporting science learning with classroom-sized distributed simulations	'Embedded phenomena' is a learning technology framework in which simulated scientific phenomena are mapped onto the physical space of classrooms. Students monitor and control the local state of the simulation through distributed media positioned around the room, gathering and aggregating evidence to solve problems or answer questions related to those phenomena. Embedded phenomena are persistent, running continuously over weeks and months, creating information channels that are temporally and physically interleaved with, but asynchronous with respect to, the regular flow of instruction. In this paper, we describe the motivations for the framework, describe classroom experiences with three embedded phenomena in the domains of seismology, insect ecology, and astronomy, and situate embedded phenomena within the context of human-computer interaction research in co-located group interfaces and learning technologies.
2006	A large scale study of wireless search behavior: Google mobile search	We present a large scale study of search patterns on Google's mobile search interface. Our goal is to understand the current state of wireless search by analyzing over 1 Million hits to Google's mobile search sites. Our study also includes the examination of search queries and the general categories under which they fall. We follow users throughout multiple interactions to determine search behavior; we estimate how long they spend inputting a query, viewing the search results, and how often they click on a search result. We also compare and contrast search patterns between 12-key keypad phones (cellphones), phones with QWERTY keyboards (PDAs) and conventional computers.
2006	FaThumb: a facet-based interface for mobile search	In this paper we describe a novel approach for searching large data sets from a mobile phone. Existing interfaces for mobile search require keyword text entry and are not suited for browsing. Our alternative uses a hybrid model to de-emphasize tedious keyword entry in favor of iterative data filtering. We propose navigation and selection of hierarchical metadata (facet navigation), with incremental text entry to further narrow the results. We conducted a formative evaluation to understand the relative advantages of keyword entry versus facet navigation for both browse and search tasks on the phone. We found keyword entry to be more powerful when the name of the search target is known, while facet navigation is otherwise more effective and strongly preferred.
2006	Searching in audio: the utility of transcripts, dichotic presentation, and time-compression	Searching audio data can potentially be facilitated by the use of automatic speech recognition (ASR) technology to generate text transcripts which can then be easily queried. However, since current ASR technology cannot reliably generate 100\% accurate transcripts, additional techniques for fluid browsing and searching of the audio itself are required. We explore the impact of transcripts of various qualities, dichotic presentation, and time-compression on an audio search task. Results show that dichotic presentation and reasonably accurate transcripts can assist in the search process, but suggest that time-compression and low accuracy transcripts should be used carefully.
2006	Responsiveness in instant messaging: predictive models supporting inter-personal communication	For the majority of us, inter-personal communication is an essential part of our daily lives. Instant Messaging, or IM, has been growing in popularity for personal and work-related communication. The low cost of sending a message, combined with the limited awareness provided by current IM systems result in messages often arriving at inconvenient or disruptive times. In a step towards solving this problem, we created statistical models that successfully predict responsiveness to incoming instant messages -- simply put: whether the receiver is likely to respond to a message within a certain time period. These models were constructed using a large corpus of real IM interaction collected from 16 participants, including over 90,000 messages. The models we present can predict, with accuracy as high as 90.1\%, whether a message sent to begin a new session of communication would get a response within 30 seconds, 1, 2, 5, and 10 minutes. This type of prediction can be used, for example, to drive online-status indicators, or in services aimed at finding potential communicators.
2006	Leveraging characteristics of task structure to predict the cost of interruption	A challenge in building interruption reasoning systems is to compute an accurate cost of interruption (COI). Prior work has used interface events and other cues to predict COI, but ignore characteristics related to the structure of a task. This work investigates how well characteristics of task structure can predict COI, as objectively measured by resumption lag. In an experiment, users were interrupted during task execution at various boundaries to collect a large sample of resumption lag values. Statistical methods were employed to create a parsimonious model that uses characteristics of task structure to predict COI. A subsequent experiment with different tasks showed that the model can predict COI with reasonably high accuracy. Our model can be expediently applied to many goal-directed tasks, allowing systems to make more effective decisions about when to interrupt.
2006	A goal-oriented web browser	Many users are familiar with the interesting but limited functionality of Data Detector interfaces like Microsoft's Smart Tags and Google's AutoLink. In this paper we significantly expand the breadth and functionality of this type of user interface through the use of large-scale knowledge bases of semantic information. The result is a Web browser that is able to generate personalized semantic hypertext, providing a goal-oriented browsing experience.We present (1) Creo, a Programming by Example system for the Web that allows users to create a general-purpose procedure with a single example, and (2) Miro, a Data Detector that matches the content of a page to high-level user goals.An evaluation with 34 subjects found that they were more efficient using our system, and that the subjects would use features like these if they were integrated into their Web browser.
2006	Understanding photowork	In this paper we introduce the notion of "photowork" as the activities people perform with their digital photos after cap-ture but prior to end use such as sharing. Surprisingly, these processes of reviewing, downloading, organizing, editing, sorting and filing have received little attention in the litera-ture yet they form the context for a large amount of the 'search' and 'browse' activities so commonly referred to in studies of digital photo software. Through a deeper under-standing of photowork using field observation and inter-views, we seek to highlight its significance as an interaction practice. At the same time, we discover how "search" as it is usually defined may have much less relevance than new ways of browsing for the design of new digital photo tools, in particular, browsing in support of the photowork activi-ties we describe.
2006	Gaze-based interaction for semi-automatic photo cropping	We present an interactive method for cropping photographs given minimal information about important content location, provided by eye tracking. Cropping is formulated in a general optimization framework that facilitates adding new composition rules, and adapting the system to particular applications. Our system uses fixation data</ to identify important image content and compute the best crop for any given aspect ratio or size, enabling applications such as automatic snapshot recomposition, adaptive documents, and thumbnailing. We validate our approach with studies in which users compare our crops to ones produced by hand and by a completely automatic approach. Experiments show that viewers prefer our gaze-based crops to uncropped images and fully automatic crops.
2006	Tabletop sharing of digital photographs for the elderly	We have recently begun to see hardware support for the tabletop user interface, offering a number of new ways for humans to interact with computers. Tabletops offer great potential for face-to-face social interaction; advances in touch technology and computer graphics provide natural ways to directly manipulate virtual objects, which we can display on the tabletop surface. Such an interface has the potential to benefit a wide range of the population and it is important that we design for usability and learnability with diverse groups of people.This paper describes the design of SharePic -- a multiuser, multi-touch, gestural, collaborative digital photograph sharing application for a tabletop -- and our evaluation with both young adult and elderly user groups. We describe the guidelines we have developed for the design of tabletop interfaces for a range of adult users, including elders, and the user interface we have built based on them. Novel aspects of the interface include a design strongly influenced by the metaphor of physical photographs placed on the table with interaction techniques designed to be easy to learn and easy to remember. In our evaluation, we gave users the final task of creating a digital postcard from a collage of photographs and performed a realistic think-aloud with pairs of novice participants learning together, from a tutorial script.
2006	GUESS: a language and interface for graph exploration	As graph models are applied to more widely varying fields, researchers struggle with tools for exploring and analyzing these structures. We describe GUESS, a novel system for graph exploration that combines an interpreted language with a graphical front end that allows researchers to rapidly prototype and deploy new visualizations. GUESS also contains a novel, interactive interpreter that connects the language and interface in a way that facilities exploratory visualization tasks. Our language, Gython, is a domain-specific embedded language which provides all the advantages of Python with new, graph specific operators, primitives, and shortcuts. We highlight key aspects of the system in the context of a large user survey and specific, real-world, case studies ranging from social and knowledge networks to distributed computer network analysis.
2006	The Sandbox for analysis: concepts and methods	The Sandbox is a flexible and expressive thinking environment that supports both ad-hoc and more formal analytical tasks. It is the evidence marshalling and sense-making component for the analytical software environment called nSpace. This paper presents innovative Sandbox human information interaction capabilities and the rationale underlying them including direct observations of analysis work as well as structured interviews. Key capabilities for the Sandbox include "put-this-there" cognition, automatic process model templates, gestures for the fluid expression of thought, assertions with evidence and scalability mechanisms to support larger analysis tasks. The Sandbox integrates advanced computational linguistic functions using a Web Services interface and protocol. An independent third party evaluation experiment with the Sandbox has been completed. The experiment showed that analyst subjects using the Sandbox did higher quality analysis in less time than with standard tools. Usability test results indicated the analysts became proficient in using the Sandbox with three hours of training.
2006	Visual exploration of multivariate graphs	This paper introduces PivotGraph, a software tool that uses a new technique for visualizing and analyzing graph structures. The technique is designed specifically for graphs that are "multivariate," i.e., where each node is associated with several attributes. Unlike visualizations which emphasize global graph topology, PivotGraph uses a simple grid-based approach to focus on the relationship between node attributes and connections. The interaction technique is derived from an analogy with methods seen in spreadsheet pivot tables and in online analytical processing (OLAP). Finally, several examples are presented in which PivotGraph was applied to real-world data sets.
2006	Keeping up appearances: understanding the dimensions of incidental information privacy	We conducted a survey of 155 participants to examine privacy concerns relating to the viewing of incidental information (i.e. traces of previous activity unrelated to the task at hand) in web browsers. We have identified several dimensions of privacy for this domain. Results revealed the scope of this problem and how location and device affect web browsing activity and contribute to the types of incidental information that may be visible. We found that there are different privacy comfort levels inherent to the participant and dependent on the context of subsequent viewing of incidental information, including the sensitivity of the content, their relationship to the viewer and the level of control retained over input devices.
2006	Being watched or being special: how I learned to stop worrying and love being monitored, surveilled, and assessed	This paper explores the relationship between display of feedback (public vs. private) and the basis for evaluation (present vs. absent) of that feedback. Using a controlled, laboratory setting, we employ a fundamentally social, interpersonal context (speed-dating). Two participants (one male and one female) receive real-time performance feedback about either only themselves (private) or about both participants (public). We measure participant perceptions of monitoring, conformity, and self-consciousness about themselves and their dating partner. We also assess perceptions of system invasiveness, system competence, and system support. Results reveal a consistent pattern of significant interaction between feedback display and basis for evaluation conditions. In each of these interactions, public feedback with an added, trivial, basis for evaluation creates significantly lower perception of monitoring, conformity, self-consciousness, and system invasiveness, than the other three conditions. Additionally there is a main effect for basis for evaluation with respect to system competence and supportiveness. In each case, the presence of a basis produces more positive assessments than its absence. The experiment shows that reactions to being monitored and evaluated do not differ strictly along the dimension of public vs. private; basis for evaluation of feedback functions as a mediator and thus co-determines participant attitudinal responses. We discuss the implications of this at several levels, and present a broader cultural explanation in terms of the theory of rationalization. We also discuss the issues around and functionality of linking laboratory settings to larger cultural contexts in this and related fields of inquiry.
2006	Effectiveness of annotating by hand for non-alphabetical languages	Unlike documents, annotation for multimedia information needs to be input as text, not in the form of symbols such as underlines and circles. This is problematic with keyboard input for non-alphabetical languages, especially the East Asian languages such as Chinese and Japanese, because it is labor intensive and imposes a high cognitive load. This study provides a quantitative analysis of the effectiveness of making annotations by hand during a note-taking task in Japanese. Although the lessons learned from this study come from Japanese text input, they are also generally applicable to other East Asian Languages which use ideographic characters such as Chinese. In our study, we focused on both the ergonomic and cognitive aspects and found that during annotation and note-taking task input by hand is more effective than input by keyboard. Finally, we anatomized the keyboard input problem and discuss it in this paper.
2006	Speech pen: predictive handwriting based on ambient multimodal recognition	It is tedious to handwrite long passages of text by hand. To make this process more efficient, we propose predictive handwriting that provides input predictions when the user writes by hand. A predictive handwriting system presents possible next words as a list and allows the user to select one to skip manual writing. Since it is not clear if people are willing to use prediction, we first run a user study to compare handwriting and selecting from the list. The result shows that, in Japanese, people prefer to select, especially when the expected performance gain from using selection is large. Based on these observations, we designed a multimodal input system, called speech-pen, that assists digital writing during lectures or presentations with background speech and handwriting recognition. The system recognizes speech and handwriting in the background and provides the instructor with predictions for further writing. The speech-pen system also allows the sharing of context information for predictions among the instructor and the audience; the result of the instructor's speech recognition is sent to the audience to support their own note-taking. Our preliminary study shows the effectiveness of this system and the implications for further improvements.
2006	Hover widgets: using the tracking state to extend the capabilities of pen-operated devices	We present Hover Widgets, a new technique for increasing the capabilities of pen-based interfaces. Hover Widgets are implemented by using the pen movements above the display surface, in the tracking state. Short gestures while hovering, followed by a pen down, access the Hover Widgets, which can be used to activate localized interface widgets. By using the tracking state movements, Hover Widgets create a new command layer which is clearly distinct from the input layer of a pen interface. In a formal experiment Hover Widgets were found to be faster than a more traditional command activation technique, and also reduced errors due to divided attention.
2006	Everyday practices with mobile video telephony	The mobile phone allowed people to communicate when and where they wanted, dramatically changing how audio telephony was integrated into daily life. With video telephony services now available on everyday mobile phones, comparable arguments are being made that this will change how people relate to and use video telephony. The mobile and personal natures of mobile phones remove factors that previously hindered use of video telephony. Mobility also brings new challenges and concerns that may hinder use of video telephony in particular contexts. With this in mind, the paper revisits the notion of video telephony but within the context of mobile phones. A study is presented of people's everyday use of mobile video telephony using diary techniques and ethnographic interviews. The study uses real episodes to highlight key motivations and circumstances under which mobile video telephony was and wasn't used. Implications for adoption of design of mobile video phones are discussed.
2006	Sashay: designing for wonderment	No longer confined to our offices, schools, and homes, technology is expanding at an astonishing rate across our everyday public urban landscapes. From the visible (mobile phones, laptops, and blackberries) to the invisible (GPS, WiFi, GSM, and EVDO), we find the full spectrum of digital technologies transforming nearly every facet of our urban experience. Many current urban computing systems focus on improving our efficiency and productivity in the city by providing "location services" and/or interactive navigation and mapping tools. While agreeing with the need for such systems, we are reminded that urban life spans a much wider range of emotions and experiences. Our claim is that our successful future urban technological tools will be those that incorporate the full range of urban experiences -- from improving productivity and efficiency to promoting wonderment and daydreaming. We discuss intervention as a research strategy for understanding wonderment; demonstrate an example of such a study using a matchbook experiment to expose relationships between locations and emotions within a city; and use the results to develop Sashay -- a mobile phone application that promotes wonderment by visualizing an individual's personal patterns across the invisible, manufactured geography of mobile phone cellular towers.
2006	Urbanhermes: social signaling with electronic fashion	Humans use fashion signals to indicate access to information. While fashion is typically associated with clothing, fashion also transpires within the domain of electronic media: weblogs, discussion lists, and online communities teem continuously with fresh, digestible content. A fashionable status - well-informed and well-connected - is demonstrated through a consistent, timely, and meaningful display of newly acquired information. While production constraints of material-based fashions limit the signal refresh rate, ephemeral electronic fashions can cycle as quickly as the flow of information. The challenge we present is to develop physical objects that can go beyond the limitations of their materiality, and to signal with the rapidity of electronic fashions. We introduce the design of urbanhermes as a communicative accessory that integrates the fresh, dynamic, fluid nature of electronic-based fashion signals within the tactile, face-to-face environment of a physical space. This paper presents the design discussion within the framework of fashion as a social signal.
2006	Because I carry my cell phone anyway: functional location-based reminder applications	Although they have potential, to date location-based information systems have not radically improved the way we interact with our surroundings. To study related issues, we developed a location-based reminder system, PlaceMail, and demonstrate its utility in supporting everyday tasks through a month-long field study. We identify current tools and practices people use to manage distributed tasks and note problems with current methods, including the common "to-do list". Our field study shows that PlaceMail supports useful location-based reminders and functional place-based lists. The study also sheds rich and surprising light on a new issue: when and where to deliver location-based information. The traditional 'geofence' radius around a place proves insufficient. Instead, effective delivery depends on people's movement patterns through an area and the geographic layout of the space. Our results both provide a compelling demonstration of the utility of location-based information and raise significant new challenges for location-based information distribution.
2006	From awareness to connectedness: the design and deployment of presence displays	Computer displays can be helpful for making users aware of the remote presence of friends and family. In many of the research projects that have explored the use of novel displays, the real goal is to improve a user's sense of connectedness to those remote loved ones. However, very few have leveraged a user-centered design process or empirically studied the effects of using a display on users' sense of awareness and connectedness. In this paper, we present our multi-phase, user-centered design process for building displays that support awareness and connectedness: Presence Displays, which are physical, peripheral awareness displays of online presence of close friends or family. We present evidence, from a 5-week long field study, that these displays provide significantly better awareness of and connectedness to a loved one, than a traditional graphical display of online presence.
2006	Negotiating presence-in-absence: contact, content and context	On the basis of a longitudinal field study of domestic communication, we report some essential constituents of the user experience of awareness of others who are distant in space or time, i.e. presence-in-absence. We discuss presence-in-absence in terms of its social (Contact) and informational (Content) facets, and the circumstances of the experience (Context). The field evaluation of a prototype, 'The Cube', designed to support presence-in-absence, threw up issues in the interrelationships between contact, content and context; issues that the designers of similar social artifacts will need to address.
2006	Using linguistic features to measure presence in computer-mediated communication	We propose a method of measuring people's sense of presence in computer-mediated communication (CMC) systems) based on linguistic features of their dialogues. We create variations in presence by asking participants to collaborate on physical tasks in four CMC conditions. We then correlate self-reported feelings of presence with the use of specific linguistic features. Regression analyses show that 30\% of the variance in self-reported presence can be accounted for by a small number of task-independent linguistic features. Even better prediction can be obtained when self-reported coordination is added to the regression equation. We conclude that linguistic measures of presence have value for studies of CMC.
2006	The paradox of the assisted user: guidance can be counterproductive	This paper investigates the influence of interface styles on problem solving performance. It is often assumed that performance on problem solving tasks improves when users are assisted by externalizing task-related information on the interface. Although externalization requires less recall and relieves working memory, it does not instigate planning, understanding and knowledge acquisition. Without this assistance, task-information must be internalized, stored in the user's memory, leading to more planning and thinking and perhaps to better performance and knowledge. Another variable that can influence behavior is "Need for Cognition" (NFC), the tendency to engage in effortful cognitive tasks. We investigated the effects of interface style and cognitive style on performance using a conference planning application. Interface style influenced behavior and performance, but NFC did not. The internalization interface led to more planful behavior and smarter solutions. When planning and learning are the aim, designers should thus beware of giving a user (too) much assistance. Understanding how people react to interface information can be crucial in designing effective software, especially important in the areas of education and learning.
2006	Investigating health management practices of individuals with diabetes	Chronic diseases, endemic in the rapidly aging population, are stretching the capacity of healthcare resources. Increasingly, individuals need to adopt proactive health attitudes and contribute to the management of their own health. We investigate existing diabetes self-management practices and ways in which reflection on prior actions impacts future lifestyle choices. The findings suggest that individuals generate and evaluate hypotheses regarding health implications of their actions. Thus, health-monitoring applications can assist individuals in making educated choices by facilitating discovery of correlations between their past actions and health states. Deployment of an early prototype of a health-monitoring application demonstrated the need for careful presentation techniques to promote more robust understanding and to avoid reinforcement of biases.
2006	Tensions in designing capture technologies for an evidence-based care community	Evidence-based care is an increasingly popular process for long term diagnosis and monitoring of education and healthcare disabilities. Because this evidence must also be collected in everyday life, it is a technique that can greatly benefit from automated capture technologies. These solutions, however, can raise significant concerns about privacy, control, and surveillance. In this paper, we present an analysis of these concerns with regard to evidence-based care. This analysis underscores the need to consider community-based risk and reward analyses in addition to the traditionally used analyses for individual users when designing socially appropriate technologies.
2006	Pride and prejudice: learning how chronically ill people think about food	In this paper, we describe a formative study to learn how one chronically ill population thinks about food, mentally organizes food, and interprets consumption-level icons. We found that many participants let their pride influence their choices, resulting in preferred interfaces that they could not accurately interpret. The results indicate that participants organized food in similar ways, had difficulty reading from their preferred consumption-level icons, and wanted to combine multiple interface designs when searching for food.
2006	Insert movie reference here: a system to bridge conversation and item-oriented web sites	Item-oriented Web sites maintain repositories of information about things such as books, games, or products. Many of these Web sites offer discussion forums. However, these forums are often disconnected from the rich data available in the item repositories. We describe a system, movie linking, that bridges a movie recommendation Web site and a movie-oriented discussion forum. Through automatic detection and an interactive component, the system recognizes references to movies in the forum and adds recommendation data to the forums and conversation threads to movie pages. An eight week observational study shows that the system was able to identify movie references with precision of .93 and recall of .78. Though users reported that the feature was useful, their behavior indicates that the feature was more successful at enriching the interface than at integrating the system.
2006	Motivating participation by displaying the value of contribution	One of the important challenges faced by designers of online communities is eliciting sufficent contributions from community members. Users in online communities may have difficulty either in finding opportunities to add value, or in understanding the value of their contributions to the community. Various social science theories suggest that showing users different perspectives on the value they add to the community will lead to differing amounts of contribution. The present study investigates a design augmentation for an existing community Web site that could benefit from additional contribution. The augmented interface includes individualized opportunities for contribution and an estimate of the value of each contribution to the community. The value is computed in one of four different ways: (1) value to self; (2) value to a small group the user has affinity with; (3) value to a small group the user does not have affinity with; and (4) value to the entire user community. The study compares the effectiveness of the different notions of value to 160 community members.
2006	Talk to me: foundations for successful individual-group interactions in online communities	People come to online communities seeking information, encouragement, and conversation. When a community responds, participants benefit and become more committed. Yet interactions often fail. In a longitudinal sample of 6,172 messages from 8 Usenet newsgroups, 27\% of posts received no response. The information context, posters' prior engagement in the community, and the content of their posts all influenced the likelihood that they received a reply, and, as a result, their willingness to continue active participation. Posters were less likely to get a reply if they were newcomers. Posting ontopic, introducing oneself via autobiographical testimonials, asking questions, using less complex language and other features of the messages, increased replies. Results suggest ways that developers might increase the ability of online communities to support successful individual-group interactions.
2006	Routine patterns of internet use & psychological well-being: coping with a residential move	In this paper we examine how routine uses of the Internet for communication with family and friends and for entertainment may serve as indicators of overall levels of psychological well-being. Changes in psychological well-being in response to a major life event, such as a residential move, can drive changes in routine uses of the Internet, suggesting Internet-based coping strategies. Specifically, women who report high levels of depressive affect, decrease internet use for communication. Men with similar levels of depressive affect increase internet use for entertainment. We discuss implications of these findings for our understanding of the role of the Internet in everyday behavior and instances of coping with stressful situations.
2006	Visualizing email content: portraying relationships from conversational histories	We present Themail, a visualization that portrays relationships using the interaction histories preserved in email archives. Using the content of exchanged messages, it shows the words that characterize one's correspondence with an individual and how they change over the period of the relationship.This paper describes the interface and content-parsing algorithms in Themail. It also presents the results from a user study where two main interaction modes with the visualization emerged: exploration of "big picture" trends and themes in email (haystack mode) and more detail-oriented exploration (needle mode). Finally, the paper discusses the limitations of the content parsing approach in Themail and the implications for further research on email content visualization.
2006	Clipping lists and change borders: improving multitasking efficiency with peripheral information design	Information workers often have to balance many tasks and interruptions. In this work, we explore peripheral display techniques that improve multitasking efficiency by helping users maintain task flow, know when to resume tasks, and more easily reacquire tasks. Specifically, we compare two types of abstraction that provide different task information: semantic content extraction, which displays only the most relevant content in a window, and change detection, which signals when a change has occurred in a window (all de-signed as modifications to Scalable Fabric [17]). Results from our user study suggest that semantic content extraction improves multitasking performance more so than either change detection or our base case of scaling. Results also show that semantic content extraction provides significant benefits to task flow, resumption timing, and reacquisition. We discuss the implication of these findings on the design of peripheral interfaces that support multitasking.
2006	A fisheye follow-up: further reflections on focus + context	Information worlds continue to grow, posing daunting challenges for interfaces. This paper tries to increase our understanding of approaches to the problem, building on the Generalized Fisheye View framework. Three issues are discussed. First a number of existing techniques are unified by the commonality of what they show, certain fisheye-related subsets, with the techniques differing only in how they show those subsets. Then the elevated importance of these subsets, and their generality, is used to discuss the possibility of non-visual fisheye-views, to attack problems not so amenable to visualization. Finally, several models are given for why these subsets might be important in user interactions, with the goal of better informing design rationales.
2006	Prototyping and sampling experience to evaluate ubiquitous computing privacy in the real world	We developed an inquiry technique, which we called "paratype," based on experience prototyping and event-contingent experience sampling, to survey people in real-life situations about ubiquitous computing (ubicomp) technology. We used this tool to probe the opinions of the conversation partners of users of the Personal Audio Loop, a memory aid that can have a strong impact on their privacy. We present the findings of this study and their implications, specifically the need to broaden public awareness of ubicomp applications and the unfitness of traditional data protection guidelines for tackling the privacy issues of many ubicomp applications. We also point out benefits and methodological issues of paratypes and discuss why they are particularly fit for studying certain classes of mobile and ubicomp applications.
2006	Design and experimental analysis of continuous location tracking techniques for Wizard of Oz testing	Wizard of Oz (WOz) testing has shown promise as an effective way to test location-enhanced applications. However, it is challenging to conduct a location-based WOz test because of the dynamic nature of target settings in the field. In particular, continuous location tracking, a major task in such a test, requires a wizard to frequently update a user's location to simulate a location system. This imposes a heavy task load on a wizard. To ease wizards' tasks for location tracking, we designed two techniques, Directional Crossing and Steering, and conducted a field experiment to investigate the performance of the two techniques. A quantitative analysis shows that Directional Crossing and Steering significantly lowered a wizard's task load for location tracking without sacrificing accuracy.
2006	Measuring emotional valence during interactive experiences: boys at video game play	This paper describes the use of facial electromyography (EMG) as a measure of positive and negative emotional valence during interactive experience. Thirteen boys played a car racing video game on an Xbox platform while facial EMG data were collected. Through video review positive and negative events during play were identified. The zygomaticus muscle EMG, which controls smiling, was found to be significantly greater during positive events as compared to negative. The corrugator muscle EMG, which controls frowning, was found to be significantly greater during negative events. The results of this study demonstrate that positive valence can be measured during interactive experiences with physiologic measures. This study also found that the corrugator EMG can still measure negative valence during high intensity interactive play in spite of the confounding factor of mental effort. These methods appear useful for associating the player's emotion with game events, and could be applied to HCI in general.
2006	A continuous and objective evaluation of emotional experience with interactive play environments	Researchers are using emerging technologies to develop novel play environments, while established computer and console game markets continue to grow rapidly. Even so, evaluating the success of interactive play environments is still an open research challenge. Both subjective and objective techniques fall short due to limited evaluative bandwidth; there remains no corollary in play environments to task performance with productivity systems. This paper presents a method of modeling user emotional state, based on a user's physiology, for users interacting with play technologies. Modeled emotions are powerful because they capture usability and playability through metrics relevant to ludic experience; account for user emotion; are quantitative and objective; and are represented continuously over a session. Furthermore, our modeled emotions show the same trends as reported emotions for fun, boredom, and excitement; however, the modeled emotions revealed differences between three play conditions, while the differences between the subjective reports failed to reach significance.
2006	Using intelligent task routing and contribution review to help communities build artifacts of lasting value	Many online communities are emerging that, like Wikipedia, bring people together to build community-maintained artifacts of lasting value (CALVs). Motivating people to contribute is a key problem because the quantity and quality of contributions ultimately determine a CALV's value. We pose two related research questions: 1) How does intelligent task routing---matching people with work---affect the quantity of contributions? 2) How does reviewing contributions before accepting them affect the quality of contributions? A field experiment with 197 contributors shows that simple, intelligent task routing algorithms have large effects. We also model the effect of reviewing contributions on the value of CALVs. The model predicts, and experimental data shows, that value grows more slowly with review before acceptance. It also predicts, surprisingly, that a CALV will reach the same final value whether contributions are reviewed before or after they are made available to the community.
2006	groupTime: preference based group scheduling	As our business, academic, and personal lives continue to move at an ever-faster pace, finding times for busy people to meet has become an art. One of the most perplexing challenges facing groupware is effective asynchronous group scheduling (GS). This paper presents a lightweight interaction model for GS that can extend its reach beyond users of current group calendaring solutions. By expressing availability in terms of preferences, we create a flexible framework for GS that preserves plausible deniability while exerting social pressure to encourage honesty among users. We also propose an ontology that enables us to model user preferences with machine learning, predicting user responses to further lower cognitive load. The combination of visualization/direct manipulation with machine learning allows users to easily and efficiently optimize meeting times. We also suggest resulting design implications for this class of intelligent user interfaces.
2006	Accounting for taste: using profile similarity to improve recommender systems	Recommender systems have been developed to address the abundance of choice we face in taste domains (films, music, restaurants) when shopping or going out. However, consumers currently struggle to evaluate the appropriateness of recommendations offered. With collaborative filtering, recommendations are based on people's ratings of items. In this paper, we propose that the usefulness of recommender systems can be improved by including more information about recommenders. We conducted a laboratory online experiment with 100 participants simulating a movie recommender system to determine how familiarity of the recommender, profile similarity between decision-maker and recommender, and rating overlap with a particular recommender influence the choices of decision-makers in such a context. While familiarity in this experiment did not affect the participants' choices, profile similarity and rating overlap had a significant influence. These results help us understand the decision-making processes in an online context and form the basis for user-centered social recommender system design.
2006	Improving menu interaction: a comparison of standard, force enhanced and jumping menus	In this paper we show how a model centered analysis of the usage of the mouse click interaction action in graphical user interfaces can be used to create a new menu system. The analysis identifies a possible new usage of the click action in cascading pull-down menus which can make it easier for the user during menu navigation and selection. A new menu system which is easy to implement, the ""Jumping Menu"", is introduced. The new menu system warps the screen cursor to the right into open sub-menu levels when a mouse click is detected inside a parent item. The Jumping Menu was compared with standard pull-down menus and force enhanced menus in a user experiment. The results show that the Jumping Menu and a force enhanced menu can facilitate menu interaction and that they are promising alternatives to conventional menu systems. Based on the results, a prediction model for selection times in Jumping Menus is developed.
2006	Zone and polygon menus: using relative position to increase the breadth of multi-stroke marking menus	We present Zone and Polygon menus, two new variants of multi-stroke marking menus that consider both the relative position and orientation of strokes. Our menus are designed to increase menu breadth over the 8 item limit of status quo orientation-based marking menus. An experiment shows that Zone and Polygon menus can successfully increase breadth by a factor of 2 or more over orientation-based marking menus, while maintaining high selection speed and accuracy. We also discuss hybrid techniques that may further increase menu breadth and performance. Our techniques offer UI designers new options for balancing menu breadth and depth against selection speed and accuracy.
2006	Measuring the difficulty of steering through corners	The steering law is intended to predict the performance of cursor manipulations in user interfaces, but the law has been verified for only a few path shapes and should be verified for more if it is to be generalized. This study extends the steering law to paths with corners. Two experiments compare the movement times of negotiating paths with corners to straight paths with the same width and movement amplitude. The experimental results show a significant effect on the movement times due to the corners, extending far into the legs of the path's corner. Modeling the results using resource theory, a cognitive theory for divided attention, suggests that steering through corners is two simultaneous tasks: steering along the legs of the corner and aiming at the corner.
2006	Face-tracking as an augmented input in video games: enhancing presence, role-playing and control	Motion-detection only games have inherent limitations on game experience in that the systems cannot identify the player's existence and identity. A way of improvement is by introducing information such as a player's face or head into the system. We designed and implemented two game prototypes that apply real-time face position information as intrinsic elements of gameplay to enhance game experience. The first prototype augmented a typical motion-detection-based game. Face information was designed to enhance the sense of presence and role-playing. In the second prototype, face tracking is applied as a new axis of control in a First Person Shooter (FPS) game.Although Face detection and tracking technology has started utilizing in game scenarios, there was little systematic research on how user experience is leveraged by applying face information to video games. The results of our user tests on comparing camera-based video games with and without face tracking demonstrated that using face position information can effectively enhance presence and role-playing. In addition, an intuitive control that augmented by face-tracking in the FPS game also got positive feedbacks from the test.
2006	Direct pointer: direct manipulation for large-display interaction using handheld cameras	This paper describes the design and evaluation of a technique, Direct Pointer, that enables users to interact intuitively with large displays using cameras equipped on handheld devices, such as mobile phones and personal digital assistant (PDA). In contrast to many existing interaction methods that attempt to address the same problem, ours offers direct manipulation of the pointer position with continuous visual feedback. The primary advantage of this technique is that it only requires equipment that is readily available: an electronic display, a handheld digital camera, and a connection between the two. No special visual markers in the display content are needed, nor are fixed cameras pointing at the display. We evaluated the performance of Direct Pointer as an interaction product, showing that it performs as well as comparable techniques that require more sophisticated equipment.
2006	Interacting with communication appliances: an evaluation of two computer vision-based selection techniques	Communication appliances, intended for home settings, require intuitive forms of interaction. Computer vision offers a potential solution, but is not yet sufficiently accurate.As interaction designers, we need to know more than the absolute accuracy of such techniques: we must also be able to compare how they will work in our design settings, especially if we allow users to collaborate in the interpretation of their actions. We conducted a 2x4 within-subjects experiment to compare two interaction techniques based on computer vision: motion sensing, with EyeToy®-like feedback, and object tracking. Both techniques were 100\% accurate with 2 or 5 choices. With 21 choices, object-tracking had significantly fewer errors and took less time for an accurate selection. Participants' subjective preferences were divided equally between the two techniques. This study compares these techniques as they would be used in real-world applications, with integrated user feedback, allowing interface designers to choose the one that best suits the specific user requirements for their particular application.
2006	Attention funnel: omnidirectional 3D cursor for mobile augmented reality platforms	The attention funnel is a general purpose AR interface technique that interactively guides the attention of a user to any object, person, or place in space. The technique utilizes dynamic perceptual affordances to draw user attention "down" the funnel to the target location. Attention funnel can be used to cue objects completely out of sight including objects behind the user, or occluded by other objects or walls.An experiment evaluating user performance with the attention funnel and other conventional AR attention directing techniques found that the attention funnel increased the consistency of the user's search by 65\%, increased search speed by 22\%, and decreased mental workload by 18\%. The attention funnel has potential applicability as a general 3D cursor or cue in a wide array of spatially enabled mobile and AR systems, and for applications where systems can support users in visual search, object awareness, and emergency warning in indoor and outdoor spaces.
2006	Feeling what you hear: tactile feedback for navigation of audio graphs	Access to digitally stored numerical data is currently very limited for sight impaired people. Graphs and visualizations are often used to analyze relationships between numerical data, but the current methods of accessing them are highly visually mediated. Representing data using audio feedback is a common method of making data more accessible, but methods of navigating and accessing the data are often serial in nature and laborious. Tactile or haptic displays could be used to provide additional feedback to support a point-and-click type interaction for the visually impaired. A requirements capture conducted with sight impaired computer users produced a review of current accessibility technologies, and guidelines were extracted for using tactile feedback to aid navigation. The results of a qualitative evaluation with a prototype interface are also presented. Providing an absolute position input device and tactile feedback allowed the users to explore the graph using tactile and proprioceptive cues in a manner analogous to point-and-click techniques.
2006	Remote usability evaluations With disabled people	Finding participants for evaluations with specific demographics can be a problem for usability and user experience specialists. In particular, finding participants with disabilities is especially problematic, yet testing with disabled people is becoming increasingly important. Two case studies are presented that explore using asynchronous remote evaluation techniques with disabled participants. These show that while quantitative data are comparable, the amount and richness of qualitative data are not likely to be comparable. The implications for formative and summative evaluations are discussed and a set of principles for local and remote evaluations with disabled users is presented.
2006	Desperately seeking simplicity: how young adults with cognitive disabilities and their families adopt assistive technologies	A surprisingly high percentage of assistive technology devices (35\% or more) are purchased, but not successfully adopted. Through semi-structured interviews with a dozen families, we have come to understand the role technology plays in the lives of families who have a young adult with cognitive disabilities, and how families find, acquire, and use these technologies. This study addresses gaps in existing research and informs future efforts in assistive technology design. Design implications include the importance of simplicity not only in technology function but in configuration, documentation, maintenance, and upgrade or replacement; as well as the need for designers to use methods that consider the multiple individuals and stages involved in the technology adoption process.
2006	Can a virtual cat persuade you?: the role of gender and realism in speaker persuasiveness	This study examines the roles of gender and visual realism in the persuasiveness of speakers. Participants were presented with a persuasive passage delivered by a male or female person, virtual human, or virtual character. They were then assessed on attitude change and their ratings of the argument, message, and speaker. The results indicated that the virtual speakers were as effective at changing attitudes as real people. Male participants were more persuaded when the speaker was female than when the speaker was male, whereas female participants were more persuaded when the speaker was male than when the speaker was female. Cross gender interactions occurred across all conditions, suggesting that some of the gender stereotypes that occur with people may carry over to interaction with virtual characters. Ratings of the perceptions of the speaker were more favorable for virtual speakers than for human speakers. We discuss the application of these findings in the design of persuasive human computer interfaces.
2006	The sensual evaluation instrument: developing an affective evaluation tool	In this paper we describe the development and initial testing of a tool for self-assessment of affect while interacting with computer systems: the Sensual Evaluation Instrument. We discuss our research approach within the context of existing affective and HCI theory, and describe stages of evolution of the tool, and initial testing of its effectiveness.
2006	Listening to your inner voices: investigating means for voice notifications	Our research investigates notification qualities of different types of voices, moving toward interfaces that support optimal allocation of attention to maximize system utility. We conducted an experiment to determine the interruption, reaction, and comprehension values of three different voice categories: the user's voice, a familiar voice, and an unfamiliar voice. Initial testing showed significant and impactful results: unfamiliar voices are the least interruptive, and a user reacts most quickly to one's own voice. Motivated by these findings, we report on the development and deployment of a notification system that exploits the differences in familiarity of a voice.
2006	Adaptive language behavior in HCI: how expectations and beliefs about a system affect users' word choice	People display adaptive language behaviors in face-to-face conversations, but will computer users do the same during HCI? We report an experiment (N=20) demonstrating that users' use of language (in terms of lexical choice) is influenced by their beliefs and expectations about a system: When users believe that the system is unsophisticated and restricted in capability, they adapt their language to match the system's language more than when they believe the system is relatively sophisticated and capable. Moreover, this tendency is based entirely on users' expectations about the system; it is unaffected by the actual behavior that the system exhibits. Our results demonstrate that interface design engenders particular beliefs in users about a system's capabilities, and that these beliefs can determine the extent to which users adapt to the system. We argue that such effects can be leveraged to improve the quality and effectiveness of human-computer interactions.
2006	Collaborative coupling over tabletop displays	Designing collaborative interfaces for tabletops remains difficult because we do not fully understand how groups coordinate their actions when working collaboratively over tables. We present two observational studies of pairs completing independent and shared tasks that investigate collaborative coupling, or the manner in which collaborators are involved and occupied with each other's work. Our results indicate that individuals frequently and fluidly engage and disengage with group activity through several distinct, recognizable states with unique characteristics. We describe these states and explore the consequences of these states for tabletop interface design.
2006	Comparing remote gesture technologies for supporting collaborative physical tasks	The design of remote gesturing technologies is an area of growing interest. Current technologies have taken differing approaches to the representation of remote gesture. It is not clear which approach has the most benefit to task performance. This study therefore compared performance in a collaborative physical (assembly) task using remote gesture systems constructed with combinations of three different gesture formats (unmediated hands only, hands and sketch and digital sketch only) and two different gesture output locations (direct projection into a worker's task space or on an external monitor). Results indicated that gesturing with an unmediated representation of the hands leads to faster performance with no loss of accuracy. Comparison of gesture output locations did not find a significant difference between projecting gestures and presenting them on external monitors. These results are discussed in relation to theories of conversational grounding and the design of technologies from a 'mixed ecologies' perspective.
2006	Cooperative gestures: multi-user gestural interactions for co-located groupware	Multi-user, touch-sensing input devices create opportunities for the use of cooperative gestures -- multi-user gestural interactions for single display groupware. Cooperative gestures are interactions where the system interprets the gestures of more than one user as contributing to a single, combined command. Cooperative gestures can be used to enhance users' sense of teamwork, increase awareness of important system events, facilitate reachability and access control on large, shared displays, or add a unique touch to an entertainment-oriented activity. This paper discusses motivating scenarios for the use of cooperative gesturing and describes some initial experiences with CollabDraw, a system for collaborative art and photo manipulation. We identify design issues relevant to cooperative gesturing interfaces, and present a preliminary design framework. We conclude by identifying directions for future research on cooperative gesturing interaction techniques.
2006	Collective creation and sense-making of mobile media	Traditionally, mobile media sharing and messaging has been studied from the perspective of an individual author making media available to other users. With the aim of supporting spectator groups at large-scale events, we developed a messaging application for camera phones with the idea of collectively created albums called Media Stories. The field trial at a rally competition pointed out the collective and participative practices involved in the creation and sense-making of media, challenging the view of individual authorship. Members contributed actively to producing chains of messages in Media Stories, with more than half of the members as authors on average in each story. Observations indicate the centrality of collocated viewing and creation in the use of media. Design implications include providing a ""common space"" and possibilities of creating collective objects, adding features that enrich collocated collective use, and supporting the active construction of awareness and social presence through the created media.
2006	Watching the cars go round and round: designing for active spectating	Spectating at sport events is a common and popular leisure activity worldwide. Recently spectating has also become a topic of interest to CHI, particularly the design of technology for both performers and audiences. In this paper we describe an in-depth study of spectating, drawn from fieldwork of outdoor car rallies in the UK and Sweden. We describe three findings with relevance to design: the viewing paradox of spectating, active spectating and the role of sociability. We describe the MySplitTime prototype which address these issues while retaining the active sociable nature of the spectating experience.
2006	Ethnography in the kindergarten: examining children's play experiences	This paper describes an ethnographic study completed within a kindergarten environment with the view of gaining insights into the development of new technology for young children. Ethnography within HCI has primarily focused on studies of work practices. This project explored the effectiveness of ethnography in supporting the design of playful technology for a constantly changing, creative, and (sometimes) messy environment. The study was effective in drawing out patterns in observations and as such provides useful suggestions for the development of technology for kindergarten settings.
2006	Robot-human interaction with an anthropomorphic percussionist	The paper presents our approach for human-machine interaction with an anthropomorphic mechanical percussionist that can listen to live players, analyze perceptual musical aspects in real-time, and use the product of this analysis to play along in a collaborative manner. Our robot, named Haile, is designed to combine the benefits of computational power, perceptual modeling, and algorithmic music with the richness, visual interactivity, and expression of acoustic playing. We believe that when interacting with live players, Haile can facilitate a musical experience that is not possible by any other means, inspiring users to collaborate with it in novel and expressive manners. Haile can, therefore, serve a test-bed for novel forms of musical human-machine interaction, bringing perceptual aspects of computer music into the physical world both visually and acoustically.
2006	Breaking the fidelity barrier: an examination of our current characterization of prototypes and an example of a mixed-fidelity success	This paper presents a summary of the space of commonly-used HCI prototyping methods (low-fidelity to high-fidelity) and asserts that with a better understanding of this space, HCI practitioners will be better equipped to direct scarce prototyping resources toward an effort likely to yield specific results. It presents a set of five dimensions along which prototypes can be planned and characterized. The paper then describes an analysis of this space performed by members of the NASA Ames Human-Computer Interaction Group when considering prototyping approaches for a new set of tools for Mars mission planning and scheduling tools. A description is presented of a prototype that demonstrates design solutions that would have been particularly difficult to test given conventional low- or mid- fidelity prototyping methods. The prototype created was "mixed-fidelity," that is, high-fidelity on some dimensions and low-fidelity on others. The prototype is compared to a preexisting tool being redesigned and to a tool that has been developed using the prototype. Experimental data are presented that show the prototype to be a good predictor of eventual user performance with the final application. Given the relative cost of developing prototypes, it is critical to better characterize the space of fidelity in order to more precisely allocate design and development resources.
2006	Getting the right design and the design right	We present a study comparing usability testing of a single interface versus three functionally equivalent but stylistically distinct designs. We found that when presented with a single design, users give significantly higher ratings and were more reluctant to criticize than when presented with the same design in a group of three. Our results imply that by presenting users with alternative design solutions, subjective ratings are less prone to inflation and give rise to more and stronger criticisms when appropriate. Contrary to our expectations, our results also suggest that usability testing by itself, even when multiple designs are presented, is not an effective vehicle for soliciting constructive suggestions about how to improve the design from end users. It is a means to identify problems, not provide solutions.
2006	The validity of the stimulated retrospective think-aloud method as measured by eye tracking	Retrospective Think aloud (RTA) is a usability method that collects the verbalization of a user's performance after the performance is over. There has been little work done to investigate the validity and reliability of RTA. This paper reports on an experiment investigating these issues with a form of the method called stimulated RTA. By comparing subjects' verbalizations with their eye movements, we support the validity and reliability of stimulated RTA: the method provides a valid account of what people attended to in completing tasks, it has a low risk of introducing fabrications, and its validity isn't affected by task complexity. More detailed analysis of RTA shows that it also provides additional information about user's inferences and strategies in completing tasks. The findings of this study provide valuable support for usability practitioners to use RTA and to trust the users' performance information collected by this method in a usability study.
2006	Precise selection techniques for multi-touch screens	The size of human fingers and the lack of sensing precision can make precise touch screen interactions difficult. We present a set of five techniques, called Dual Finger Selections, which leverage the recent development of multi-touch sensitive displays to help users select very small targets. These techniques facilitate pixel-accurate targeting by adjusting the control-display ratio with a secondary finger while the primary finger controls the movement of the cursor. We also contribute a "clicking" technique, called SimPress, which reduces motion errors during clicking and allows us to simulate a hover state on devices unable to sense proximity. We implemented our techniques on a multi-touch tabletop prototype that offers computer vision-based tracking. In our formal user study, we tested the performance of our three most promising techniques (Stretch, X-Menu, and Slider) against our baseline (Offset), on four target sizes and three input noise levels. All three chosen techniques outperformed the control technique in terms of error rate reduction and were preferred by our participants, with Stretch being the overall performance and preference winner.
2006	TeamTag: exploring centralized versus replicated controls for co-located tabletop groupware	We explore how the placement of control widgets (such as menus) affects collaboration and usability for co-located tabletop groupware applications. We evaluated two design alternatives: a centralized set of controls shared by all users, and separate per-user controls replicated around the borders of the shared tabletop. We conducted this evaluation in the context of TeamTag, a system for collective annotation of digital photos. Our comparison of the two design alternatives found that users preferred replicated over shared controls. We discuss the cause of this preference, and also present data on the impact of these interface design variants on collaboration, as well as the role that orientation, co-touching, and the use of different regions of the table played in shaping users' behavior and preferences.
2006	Keepin' it real: pushing the desktop metaphor with physics, piles and the pen	We explore making virtual desktops behave in a more physically realistic manner by adding physics simulation and using piling instead of filing as the fundamental organizational structure. Objects can be casually dragged and tossed around, influenced by physical characteristics such as friction and mass, much like we would manipulate lightweight objects in the real world. We present a prototype, called BumpTop, that coherently integrates a variety of interaction and visualization techniques optimized for pen input we have developed to support this new style of desktop organization.
2006	Synchronous broadcast messaging: the use of ICT	IBM Community Tools (ICT) is a synchronous broadcast messaging system in use by a very large, globally distributed organization. ICT is interesting for a number of reasons, including its scale of use (thousands of users per day), its usage model of employing large scale broadcast to strangers to initiate small group interactions, and the fact that it is a synchronous system used across multiple time zones. In this paper we characterize the use of ICT in its context, examine the activities for which it is used, the motivations of its users, and the values they derive from it. We also explore problems with the system, and look at the social and technical ways in which users deal with them.
2006	The impact of delayed visual feedback on collaborative performance	When pairs work together on a physical task, seeing a common workspace benefits their performance and transforms their use of language. Previous results have demonstrated that visual information helps collaborative pairs to understand the current state of their task, ground their conversations, and communicate efficiently. However, collaborative technologies often impinge on the visual information needed to support successful collaboration. One example of this is the introduction of delayed visual feedback in a collaborative environment. We present results from two studies that detail the form of the function that describes the relationship between visual delay and collaborative task performance. The first study precisely demonstrates how a range of visual delays differentially impact performance and the collaborative strategies employed. The second study describes how parameters of the task, such as the dynamics of the visual environment, reduce the amount of delay that can be tolerated.
2006	Collocation bindness in partially distributed groups: is there a downside to being collocated?	Under what circumstances might a group member be better off as a long-distance participant rather than collocated? We ran a set of experiments to study how partially-distributed groups collaborate when skill sets are unequally distributed. Partially distributed groups are those where some collaborators work together in the same space (collocated) and some work remotely using computer-mediated communications. Previous experiments had shown that these groups tend to form semi-autonomous 'in-groups'. In this set of experiments the configuration was changed so that some player skills were located only in the collocated space, and some were located only remotely, creating local surplus of some skills and local scarcity of others in the collocated room. Players whose skills were locally in surplus performed significantly worse. They experienced 'collocation blindness' and failed to pay enough attention to collaborators outside of the room. In contrast, the remote players whose skills were scarce inside the collocated room did particularly well because they charged a high price for their skills.
2007	Matching attentional draw with utility in interruption	This research examines a design guideline that aims to increase the positive perception of interruptions. The guideline advocates matching the amount of attention attracted by an interruption's notification method (attentional draw) to the utility of the interruption content. Our first experiment examined a set of 10 visual notification signals in terms of their detection times and established a set of three significantly different signals along the spectrum of attentional draw. Our second experiment investigated matching these different signals to interruption content with different levels of utility. Results indicate that the matching strategy decreases annoyance and increases perception of benefit compared to a strategy that uses the same signal regardless of interruption utility, with no significant impact on workload or performance. Design implications arising from the second experiment as well as recommendations for future work are discussed.
2007	Biases in human estimation of interruptibility: effects and implications for practice	People have developed a variety of conventions for negotiating face to face interruptions. The physical distribution of teams, however, together with the use of computer mediated communication and awareness systems, fundamentally alters what information is available to a person considering an interruption of a remote collaborator. This paper presents a detailed comparison between self-reports of interruptibility, collected from participants over extended periods in their actual work environment, and estimates of this interruptibility, provided by a second set of participants based on audio and video recordings. Our results identify activities and environmental cues that affect participants' ability to correctly estimate interruptibility. We show, for example, that a closed office door had a significant effect on observers' estimation of interruptibility, but did not have an effect on participants' reports of their own interruptibility. We discuss our findings and their importance for successful design of computer-mediated communication and awareness systems.
2007	Understanding videowork	In this paper we elucidate the patterns of behavior of home movie makers through a study of 12 families and a separate focus group of 7 teenagers. Analogous to a similar study of photowork [13], the goal is to provide a deeper understanding of what people currently do with video technologies, balancing the preponderence of techno-centric work in the area with appropriate user-centric insight. From our analysis, we derive a videowork lifecycle to frame the practices users engage in when working with video technologies in the home, and uncover two broad types of video usage therein. This has implications for how we conceive of and devise tools to support these practices, as we discuss.
2007	Software or wetware?: discovering when and why people use digital prosthetic memory	Our lives are full of memorable and important moments, as well as important items of information. The last few years have seen the proliferation of digital devices intended to support prosthetic memory (PM), to help users recall experiences, conversations and retrieve personal information. We nevertheless have little systematic understanding of when and why people might use such devices, in preference to their own organic memory (OM). Although OM is fallible, it may be more efficient than accessing information from a complex PM device. We report a controlled lab study which investigates when and why people use PM and OM. We found that PM use depended on users' evaluation of the quality of their OM, as well as PM device properties. In particular, we found that users trade-off Accuracy and Efficiency, preferring rapid access to potentially inaccurate information over laborious access to accurate information. We discuss the implications of these results for future PM design and theory. Rather than replacing OM, future PM designs need to focus on allowing OM and PM to work in synergy.
2007	Do life-logging technologies support memory for the past?: an experimental study using sensecam	We report on the results of a study using SenseCam, a "life-logging" technology in the form of a wearable camera, which aims to capture data about everyday life in order to support people's memory for past, personal events. We find evidence that SenseCam images do facilitate people's ability to connect to their past, but that images do this in different ways. We make a distinction between "remembering" the past, and "knowing" about it, and provide evidence that SenseCam images work differently over time in these capacities. We also compare the efficacy of user-captured images with automatically captured images and discuss the implications of these findings and others for how we conceive of and make claims about life-logging technologies.
2007	An exploratory study of input configuration and group process in a negotiation task using a large display	This paper reports on an exploratory study of the effects of input configuration on group behavior and performance in a collaborative task performed by a collocated group using a large display. Twelve groups completed a mixed-motive negotiation task under two conditions: a single, shared mouse and one mouse per person. Results suggest that the multiple mouse condition allowed for more parallel work, but the quality of discussion was higher in the single mouse condition. Moreover, participants were more likely to act in their own best interest in the multiple mouse condition.
2007	Beyond visual acuity: the perceptual scalability of information visualizations for large displays	The scalability of information visualizations has typically been limited by the number of available display pixels. As displays become larger, the scalability limit may shift away from the number of pixels and toward human perceptual abilities. This work explores the effect of using large, high resolution displays to scale up information visualizations beyond potential visual acuity limitations. Displays that are beyond visual acuity require physical navigation to see all of the pixels. Participants performed various information visualization tasks using display sizes with a sufficient number of pixels to be within, equal to, or beyond visual acuity. Results showed that performance on most tasks was more efficient and sometimes more accurate because of the additional data that could be displayed, despite the physical navigation that was required. Visualization design issues on large displays are also discussed.
2007	White rooms and morphing don't mix: setting and the evaluation of visualization techniques	The results presented in this paper illustrate how a specific map visualization technique is sensitive to setting: a comparative evaluation of the technique gives conflicting results depending on where it takes place. While prior research has explored the impact of factors other than basic visual perception on visualization techniques, relatively little attention has been directed toward the physical setting in which the technique is used. We present results from a study involving 120 participants, comparing the effectiveness of two different geovisualization techniques in promoting recall of map layout. Recall was shown to be sensitive to setting, such that one technique in particular was more effective in a noisy public space than in a controlled, 'white-room' environment. The results have implications for the validation and measurement of information visualization techniques as a whole, and in particular for those employing motion as a communicative attribute.
2007	Shoogle: excitatory multimodal interaction on mobile devices	Shoogle is a novel, intuitive interface for sensing data withina mobile device, such as presence and properties of textmessages or remaining resources. It is based around activeexploration: devices are shaken, revealing the contents rattlingaround "inside". Vibrotactile display and realistic impactsonification create a compelling system. Inertial sensingis used for completely eyes-free, single-handed interactionthat is entirely natural. Prototypes are described runningboth on a PDA and on a mobile phone with a wireless sensorpack. Scenarios of use are explored where active sensing ismore appropriate than the dominant alert paradigm.
2007	Momento: support for situated ubicomp experimentation	We present the iterative design of Momento, a tool that providesintegrated support for situated evaluation of ubiquitouscomputing applications. We derived requirements for Momento from a user-centered design process that includedinterviews, observations and field studies of early versionsof the tool. Motivated by our findings, Momento supportsremote testing of ubicomp applications, helps with participantadoption and retention by minimizing the need for newhardware, and supports mid-to-long term studies to addressinfrequently occurring data. Also, Momento can gather logdata, experience sampling, diary, and other qualitative data.
2007	Toolkit support for developing and deploying sensor-based statistical models of human situations	Sensor based statistical models promise to support a variety of advances in human computer interaction, but building applications that use them is currently difficult and potential advances go unexplored. We present Subtle, a toolkit that removes some of the obstacles to developing and deploying applications using sensor based statistical models of human situations. Subtle provides an appropriate and extensible sensing library, continuous learning of personalized models, fully automated high level feature generation, and support for using learned models in deployed applications. By removing obstacles to developing and deploying sensor based statistical models, Subtle makes it easier to explore the design space surrounding sensor based statistical models of human situations. Subtle thus helps to move the focus of human computer interaction research onto applications and datasets, instead of the difficulties of developing and deploying sensor based statistical models.
2007	Authoring sensor-based interactions by demonstration with direct manipulation and pattern recognition	Sensors are becoming increasingly important in interaction design. Authoring a sensor-based interaction comprises three steps: choosing and connecting the appropriate hardware, creating application logic, and specifying the relationship between sensor values and application logic. Recent research has successfully addressed the first two issues. However, linking sensor input data to application logic remains an exercise in patience and trial-and-error testing for most designers. This paper introduces techniques for authoring sensor-based interactions by demonstration. A combination of direct manipulation and pattern recognition techniques enables designers to control how demonstrated examples are generalized to interaction rules. This approach emphasizes design exploration by enabling very rapid iterative demonstrate-edit-review cycles. This paper describes the manifestation of these techniques in a design tool, Exemplar, and presents evaluations through a first-use lab study and a theoretical analysis using the Cognitive Dimensions of Notation framework.
2007	Questions not answers : a novel mobile search technique	Mobile search is becoming an increasingly important user activity. In this paper, instead of investigating the most efficient and effective ways of providing search results, the answers , we consider the value of giving access to previous queries, the questions , relating to a user's location. By exposing what other people have searched for, the aim is to provide useful insights into a location's character. To consider the value of the approach we deployed two mobile probes in a large-scale field study involving 391 participants. Our experiences suggest that presenting users with other people's in situ queries influences their information seeking interactions positively.
2007	Tactile feedback for mobile interactions	We present a study investigating the use of vibrotactile feedback for touch-screen keyboards on PDAs. Such key-boards are hard to use when mobile as keys are very small. We conducted a laboratory study comparing standard but-tons to ones with tactile feedback added. Results showed that with tactile feedback users entered significantly more text, made fewer errors and corrected more of the errors they did make. We ran the study again with users seated on an underground train to see if the positive effects trans-ferred to realistic use. There were fewer beneficial effects, with only the number of errors corrected significantly im-proved by the tactile feedback. However, we found strong subjective feedback in favour of the tactile display. The results suggest that tactile feedback has a key role to play in improving interactions with touch screens.
2007	Revisiting and validating a model of two-thumb text entry	MacKenzie and Soukoreff have previously introduced a Fitts' Law-based performance model of expert two-thumb text entry on mini-QWERTY keyboards [4]. In this work we validate the original model using results from a longitudinal study of mini-QWERTY keyboards, and update the model to account for observed inter-key time data.
2007	Jump and refine for rapid pointing on mobile phones	Standard input devices for mobile phones are directional keys and discrete thumb-joysticks. These devices are dedicated to the discrete GUIs of the phones (eg. scroll lists and small icons arrays). Today, new mobile applications are arising and require adapted interfaces. In particular, the widespread of 3D applications will be favored if users can efficiently point on any part of thescreen. In this paper, we propose a new interaction technique called Jump and Refine for selection tasks on mobile phones. This technique is based on two levels of cursor displacement in order to reduce the number of keystrokes. The first level allows fast movements into an underlying grid. The second one can be used for accurate positioning into the selected area. We present a user study which shows that using a first coarse jump level decreases the selection completion times. The study also shows that the technique is widely accepted by the users. Finally, we discuss the optimal grid sizes.
2007	Usability of voting systems: baseline data for paper, punch cards, and lever machines	In the United States, computer-based voting machines are rapidly replacing other older technologies. While there is potential for this to be a usability improvement, particularly in terms of accessibility, the only way it is possible to know if usability has improved is to have baseline data on the usability of traditional technologies. We report an experiment assessing the usability of punch cards, lever machines, and two forms of paper ballot. There were no differences in ballot completion time between the four methods, but there were substantial effects on error rate, with the paper ballots superior to the other methods as well as an interaction with age of voters. Subjective usability was assessed with the System Usability Scale and showed a slight advantage for bubble-style paper ballots. Overall, paper ballots were found to be particularly usable, which raises important technological and policy issues.
2007	A game design methodology to incorporate social activist themes	Can a set of articulated and tested methodologies be created whose endpoint is the reliable capacity for taking activist social themes into account? In this paper we explore a variety of educational and activist game approaches, and look specifically at the themes emerging from recent projects involving game design for young women. We articulate here design practices in a methodology, Values at Play (VAP), that could be used in the creation of games as well as the teaching of game design.
2007	Move to improve: promoting physical navigation to increase user performance with large displays	In navigating large information spaces, previous work indicates potential advantages of physical navigation (moving eyes, head, body) over virtual navigation (zooming, panning, flying). However, there is also indication of users preferring or settling into the less efficient virtual navigation. We present a study that examines these issues in the context of large, high resolution displays. The study identifies specific relationships between display size, amount of physical and virtual navigation, and user task performance. Increased physical navigation on larger displays correlates with reduced virtual navigation and improved user performance. Analyzing the differences between this study and previous results helps to identify design factors that afford and promote the use of physical navigation in the user interface.
2007	Copy-and-paste between overlapping windows	Copy-and-paste, one of the fundamental operations of modern userinterfaces, can be performed through various means (e.g. using the keyboard, mouse-based direct manipulation or menus). When users copy-and-paste between two different windows, the process is complicated by window management tasks. In this paper, we propose two new window management techniques to facilitate these tasks in the particular case of partially overlapping windows. We describe an experiment comparing four commonly-used copy-and-paste techniques under four window management conditions -- non-overlapping windows, partially overlapping windows, and partially overlapping ones with one of our two window management techniques. Results show that our new window management techniques significantly reduce task completion time for all copy-and-paste techniques. They also show that X Window copy-and-paste is faster than the other three techniques under all four window management conditions.
2007	Consistency, multiple monitors, and multiple windows	We present an evaluation of mudibo, a prototype system for determining the position of dialog boxes in a multiple-monitor system. The analysis shows that, when compared to a standard approach, mudibo offered a 24\% decrease in time needed to begin interaction in a dialog box. Analysis of participant behavior in the evaluation provides insight into the way users perceive and act in multiple-monitor environments. Specifically, the notion of consistency changes for multiple-monitor systems and the prospect of adaptive algorithms becomes further complicated and intricate, especially for window management.
2007	How pairs interact over a multimodal digital table	Co-located collaborators often work over physical tabletops using combinations of expressive hand gestures and verbal utterances. This paper provides the first observations of how pairs of people communicated and interacted in a multimodal digital table environment built atop existing single user applications. We contribute to the understanding of these environments in two ways. First, we saw that speech and gesture commands served double duty as both commands to the computer, and as implicit communication to others. Second, in spite of limitations imposed by the underlying single-user application, people were able to work together simultaneously, and they performed interleaving acts: the graceful mixing of inter-person speech and gesture actions as commands to the system. This work contributes to the intricate understanding of multi-user multimodal digital table interaction.
2007	An observational study on information flow during nurses' shift change	We present an observational study that was conducted to guide the design and development of technologies to support information flow during nurses' shift change in a hospital ward. Our goal is to find out how the complex information sharing processes during nurses' brief shift change unfold in a hospital setting. Our study shows the multitude of information media that nurses access during the parallel processes of information assembly and disassembly: digital, paper-based, displayed and verbal media. An initial analysis reveals how the common information spaces, where information media are positioned and accessible by all participants, are actively used and how they interact with the personal information spaces ephemerally constructed by the participants. Several types of information are consistently transposed from the common information spaces to the personal information space including: demographics, historical data, reminders and to-dos, alerts, prompts, scheduling and reporting information. Information types are often enhanced with a variety of visual cues to help nurses carry out their tasks.
2007	Medical sensemaking with entity workspace	Knowledge workers making sense of a topic divide their time among activities including searching for information, reading, and taking notes. We have built a software system that supports and integrates these activities. To test its effectiveness, we conducted a study where subjects used it to perform medical question-answering tasks. Initial results indicate that subjects could use the system, but that the nature of this use depended on the subject's overall question-answering strategy. Two dominant strategies emerged that we call the Reader and Searcher strategies.
2007	A cognitive constraint model of dual-task trade-offs in a highly dynamic driving task	The paper describes an approach to modeling the strategic variations in performing secondary tasks while driving. In contrast to previous efforts that are based on simulation of a cognitive architecture interacting with a task environment, we take an approach that develops a cognitive constraint model of the interaction between the driver and the task environment in order to make inferences about dual-task performance. Analyses of driving performance data reveal that a set of simple equations can be used to accurately model changes in the lateral position of the vehicle within the lane. The model quantifies how the vehicle's deviation from lane center increases during periods of inattention, and how the vehicle returns to lane center during periods of active steering. We demonstrate the benefits of the approach by modeling the dialing of a cellular phone while driving, where drivers balance the speed in performing the dial task with accuracy (or safety) in keeping the vehicle centered in the roadway. In particular, we show how understanding, rather than simulating, the constraints imposed by the task environment can help to explain the costs and benefits of a range of strategies for interleaving dialing and steering. We show how particular strategies are sensitive to a combination of internal constraints (including switch costs) and the trade-off between the amount of time allocated to secondary task and the risk of extreme lane deviation.
2007	iPod distraction: effects of portable music-player use on driver performance	Portable music players such as Apple's iPod have become ubiquitous in many environments, but one environment in particular has elicited new safety concerns and challenges -- in-vehicle use while driving. We present the first study of portable music-player interaction while driving, examining the effects of iPod interaction by drivers navigating a typical roadway in a driving simulator. Results showed that selecting media on the iPod had a significant effect on driver performance as measured by lateral deviation from lane center; the effect was comparable to previously reported effects of dialing a cellular phone. In addition, selecting media and watching videos had a significant effect on car-following speed, resulting in speed reductions that presumably compensated for impaired lateral performance. Given that iPod interaction has become increasingly common while driving, these results serve as a first step toward understanding the potential effects of portable music-player interaction on driver behavior and performance.
2007	InkSeine: In Situ search for active note taking	Using a notebook to sketch designs, reflect on a topic, or capture and extend creative ideas are examples of active note taking tasks. Optimal experience for such tasks demands concentration without interruption. Yet active note taking may also require reference documents or emails from team members. InkSeine is a Tablet PC application that supports active note taking by coupling a pen-and-ink interface with an in situ search facility that flows directly from a user's ink notes (Fig. 1). InkSeine integrates four key concepts: it leverages preexisting ink to initiate a search; it provides tight coupling of search queries with application content; it persists search queries as first class objects that can be commingled with ink notes; and it enables a quick and flexible workflow where the user may freely interleave inking, searching, and gathering content. InkSeine offers these capabilities in an interface that is tailored to the unique demands of pen input, and that maintains the primacy of inking above all other tasks.
2007	Sharing a single expert among multiple partners	Expertise to assist people on complex tasks is often in short supply. One solution to this problem is to design systems that allow remote experts to help multiple people in simultaneously. As a first step towards building such a system, we studied experts' attention and communication as they assisted two novices at the same time in a co-located setting. We compared simultaneous instruction when the novices are being instructed to do the same task or different tasks. Using machine learning, we attempted to identify speech markers of upcoming attention shifts that could serve as input to a remote assistance system.
2007	Dynamic detection of novice vs. skilled use without a task model	If applications were able to detect a user's expertise, then software could automatically adapt to better match exper-tise. Detecting expertise is difficult because a user's skill changes as the user interacts with an application and differs across applications. This means that expertise must be sensed dynamically, continuously, and unobtrusively so as not to burden the user. We present an approach to this prob-lem that can operate without a task model based on low-level mouse and menu data which can typically be sensed across applications at the operating systems level. We have implemented and trained a classifier that can detect "nov-ice" or "skilled" use of an image editing program, the GNU Image Manipulation Program (GIMP), at 91\% accuracy, and tested it against real use. In particular, we developed and tested a prototype application that gives the user dy-namic application information that differs depending on her performance.
2007	Approaches to web search and navigation for older computer novices	A proof of concept web search and navigation system was developed for older people for whom the Internet is seen as an alien territory. A joint industry/academia team deployed User Sensitive Inclusive Design principles, focusing on the usability of the interface for this user group. The search and navigation system that was developed was significantly preferred by the user group to that provided by a standard commercial (Internet Service Provider) system; it scored highly for ease of use and the participants reported increased confidence in their ability to master the Internet. Recorded quantitative measures showed fewer task errors. The outcome of the development was a successful "proof of concept" search and navigation system for older novice computer users together with approaches to design and development for those who wish to design for this user group.
2007	Designing a mobile user interface for automated species identification	Biological research in the field is constrained by the speed and difficulty of species determination, as well as by access to relevant information about the species encountered. However, recent work on vision-based algorithms raises the promise of rapid botanical species identification. The potential for mobile vision-based identification provides opportunities for new user interface techniques. To explore these issues, we present LeafView, a Tablet-PC-based user interface for an electronic field guide that supports automated identification of botanical species in the field. We describe a user interface design based on an ethnographic study of botanists, field tests of working prototypes by botanists at the Smithsonian Institution on Plummers Island, Maryland, and observations at an internal exhibition at the Smithsonian at which other staff members tried the prototypes. We present functionality specific to mobile identification and collection in the electronic field guide and use this to motivate discussion of mobile identification in general.
2007	BrickRoad: a light-weight tool for spontaneous design of location-enhanced applications	It is difficult to design and test location-enhancedapplications. A large part of this difficulty is due to the added complexity of supporting location. Wizard of Oz (WOz) has become an effective technique for the early stage design of location-enhanced applications because it allows designers to test an application prototype bysimulating nonexistent components such as location sensing. However, existing WOz tools 1) require nontrivial effort from designers to specify how a prototype should behave before it can be tested with end users, and 2)support only limited control over application behavior during a test. BrickRoad is a WOz tool for spontaneousdesign of location-enhanced applications. It lowers the threshold to acquiring user feedback and exploring a design space. With BrickRoad, a designer does not need to specify any interaction logic and can experiment on-the-fly with different designs during testing. BrickRoad is a valuable complement to existing tool support for the early stage design of location-enhanced applications.
2007	Psychophysical elements of wearability	Wearable technology presents a wealth of new HCI issues. In particular, this paper addresses the impact of the physical interaction between the user's body and the device's physical form on the user's mental representation of self and cognitive abilities, a blend of HCI and ergonomics that is unique to wearable computing. We explore the human sensory mechanisms that facilitate perception of worn objects and the elements of sensation that influence the comfort of worn objects, and discuss the psychological elements that may cause worn objects to be forgotten or detected, wearable or not. We discuss the implications of un-wearability on attention and cognitive capability.
2007	The tilt cursor: enhancing stimulus-response compatibility by providing 3d orientation cue of pen	In order to improve stimulus-response compatibility of touchpad in pen-based user interface, we present the tilt cursor, i.e. a cursor dynamically reshapes itself to providing the 3D orientation cue of pen. We also present two experiments that evaluate the tilt cursor's performance in circular menu selection and specific marking menu selection tasks. Results show that in a specific marking menu selection task, the tilt cursor significantly outperforms the shape-fixed arrow cursor and the live cursor [4]. In addition, results show that by using the tilt cursor, the response latencies for adjusting drawing directions are smaller than that by using the other two kinds of cursors.
2007	How younger and older adults master the usage of hyperlinks in small screen devices	In this paper we describe an experiment, in which we examined older and younger adults when interacting with a simulated PDA (personal digital assistant). Independent variables were users' age (young vs. older) and device interface (hyperlink vs. no hyperlink). Dependent variables were the effectiveness and efficiency of menu navigation. To understand how user characteristics influence performance, spatial ability, verbal memory, computer expertise and technical self-confidence were determined. Technology experienced young and older adults (benchmark testing) took part. They had to solve four tasks either with hyperlink interface or without hyperlinks in the interface. The method to collect, to automatically analyze and to structure the data according to interaction sequences and presumed user intentions is a novel approach supported by the open source software tool Clever [12]. The tool is briefly described; more details can be found in [23]. Results revealed that hyperlink interfaces showed overall higher effectiveness. However, the impact of hyperlinks for efficiency was age-related. Younger adults strongly benefit from having hyperlinks. The contrary was the case for older adults, who showed higher menu disorientation when using hyperlinks.
2007	Modeling steering within above-the-surface interaction layers	Interaction techniques that utilize the space above the display surface to extend the functionalities of digitized surfaces continue to emerge. In such techniques, movements are constrained by the bounds of a layer. In addition, constraints imposed on the direction of movement within the layer may be present. Despite the presence of such techniques, there is limited understanding of human capabilities for performing the required steering task. In this paper we study and model user performance when steering through constrained and unconstrained paths in above-the-surface layers. Through a series of experiments we validate the derivation and applicability of our proposed models.
2007	Quantifying degree of goal directedness in document navigation: application to the evaluation of the perspective-drag technique	This article pursues a two-fold goal. First we introduce degree of goal directedness (DGD) , a novel quantitative dimension for the taxonomy of navigation tasks in general. As an attempt to operationalize the DGD concept in the context of electronic documents navigation, we introduce the serial target-acquisition (STA) experimental paradigm. We suggest that DGD and the STA paradigm may usefully enrich the conceptual toolkit of HCI research for the evaluation of navigation techniques. Our second goal is to illustrate the utility of the DGD concept by showing with a concrete example, Perspective Drag , the refinement it allows in evaluating navigation techniques. We report data obtained from two experiments with the STA paradigm that cast light on what Perspective Drag is specifically good for: it is particularly suitable in realistic task contexts where navigation is less than 100\% directed by its terminal goal, that is, where the user wants not only to reach a particular item but also to pick up information from the document during document traversal.
2007	PageLinker: integrating contextual bookmarks within a browser	PageLinker is a browser extension that allows to contextualise navigation by linking web pages together and to navigate through a network of related web pages without prior planning. The design is based on extensive interviews with biologists, which highlighted their difficulties finding previously visited web pages. They found current browser tools inadequate, resulting in poorly organised bookmarks and rarely used history lists. In a four-week controlled field experiment, PageLinker significantly reduced time, page loads and mouse clicks. By presenting links in context, PageLinker facilitates web page revisitation, is less prone to bookmark overload and is highly robust to change.
2007	Give and take: a study of consumer photo-sharing culture and practice	In this paper, we present initial findings from the study of a digital photo-sharing website: Flickr.com. In particular, we argue that Flickr.com appears to support-for some people-a different set of photography practices, socialization styles, and perspectives on privacy that are unlike those described in previous research on consumer and amateur photographers. Further, through our examination of digital photographers' photowork activities-organizing, finding, sharing and receiving-we suggest that privacy concerns and lack of integration with existing communication channels have the potential to prevent the 'Kodak Culture' from fully adopting current photo-sharing solutions.
2007	Over-exposed?: privacy patterns and considerations in online and mobile photo sharing	As sharing personal media online becomes easier and widely spread, new privacy concerns emerge - especially when the persistent nature of the media and associated context reveals details about the physical and social context in which the media items were created. In a first-of-its-kind study, we use context-aware camerephone devices to examine privacy decisions in mobile and online photo sharing. Through data analysis on a corpus of privacy decisions and associated context data from a real-world system, we identify relationships between location of photo capture and photo privacy settings. Our data analysis leads to further questions which we investigate through a set of interviews with 15 users. The interviews reveal common themes in privacy considerations: security, social disclosure, identity and convenience . Finally, we highlight several implications and opportunities for design of media sharing applications, including using past privacy patterns to prevent oversights and errors.
2007	EasyAlbum: an interactive photo annotation system based on face clustering and re-ranking	Digital photo management is becoming indispensable for the explosively growing family photo albums due to the rapid popularization of digital cameras and mobile phone cameras. In an effective photo management system photo annotation is the most challenging task. In this paper, we develop several innovative interaction techniques for semi-automatic photo annotation. Compared with traditional annotation systems, our approach provides the following new features: "cluster annotation" puts similar faces or photos with similar scene together, and enables user label them in one operation; "contextual re-ranking" boosts the labeling productivity by guessing the user intention; "ad hoc annotation" allows user label photos while they are browsing or searching, and improves system performance progressively through learning propagation. Our results show that these technologies provide a more user friendly interface for the annotation of person name, location, and event, and thus substantially improve the annotation performance especially for a large photo album.
2007	An exploration of web-based monitoring: implications for design	Monitoring occurs when users return to previously viewed web pages to view new or updated information. While tools exist to support web-based monitoring, we know little about the monitoring activities users engage in and the nature of the support needed. We have conducted 40 semi-structured interviews in order to better understand the types of information users monitor and the characteristics of different monitoring activities. Using the data collected during the interviews, we characterized monitoring as an activity within six web information tasks: Browsing, Communications, Fact Finding, Information Gathering, Maintenance, and Transactions. The results of our study have been used to provide general, as well as task specific, recommendations for the design of monitoring tools.
2007	Investigating attractiveness in web user interfaces	A theoretical framework for assessing the attractiveness of websites based on Adaptive Decision Making theory is introduced. The framework was developed into a questionnaire and used to evaluate three websites which shared the same brand and topic but differed in aesthetic design. The DSchool site was favoured overall and was best for aesthetics and usability. The subjective ratings of the sites were in conflict with the subject-reported comments on usability problems. Subjects were given two scenarios for their preference. They changed their preference from the DSchool to the HCI Group's site for the more serious (PhD study) scenario; however, design background students remained loyal to the DSchool. The implications of framing and halo effects on users' judgement of aesthetics are discussed.
2007	The relationship between accessibility and usability of websites	Accessibility and usability are well established concepts for user interfaces and websites. Usability is precisely defined, but there are different approaches to accessibility. In addition, different possible relationships could exist between problems encountered by disabled and non-disabled users, yet little empirical data have been gathered on this question. Guidelines for accessibility and usability of websites provide ratings of the importance of problems for users, yet little empirical data have been gathered to validate these ratings. A study investigated the accessibility of two websites with 6 disabled (blind) and 6 non-disabled (sighted) people. Problems encountered by the two groups comprised two intersecting sets, with approximately 15\% overlap. For one of the two websites, blind people rated problems significantly more severely than sighted people. There was high agreement between participants as to the severity of problems, and agreement between participants and researchers. However, there was no significant agreement between either participants or researchers and the importance/priority ratings provided by accessibility and usability guidelines. Practical and theoretical implications of these results are discussed.
2007	What are you looking for?: an eye-tracking study of information usage in web search	Web search services are among the most heavily used applications on the World Wide Web. Perhaps because search is used in such a huge variety of tasks and contexts, the user interface must strike a careful balance to meet all user needs. We describe a study that used eye tracking methodologies to explore the effects of changes in the presentation of search results. We found that adding information to the contextual snippet significantly improved performance for informational tasks but degraded performance for navigational tasks. We discuss possible reasons for this difference and the design implications for better presentation of search results.
2007	An eye tracking study of the effect of target rank on web search	Web search engines present search results in a rank ordered list. This works when what a user wants is near the top, but sometimes the information that the user really wants is located at the bottom of the page. This study examined how users' search behaviors vary when target results were displayed at various positions for informational and navigational tasks. We found that when targets were placed relatively low in the first page of search results, people spent more time searching and were less successful in finding the target, especially for informational tasks. Further analysis of eye movements showed that the decrease in search performance was partially due to the fact that users rarely looked at lower ranking results. The large decrease in performance for informational search is probably because users have high confidence in the search engine's ranking; in contrast to navigational tasks, where the target is more obvious from information presented in the results, in informational tasks, users try out the top ranked results even if these results are perceived as less relevant for the task.
2007	EyePoint: practical pointing and selection using gaze and keyboard	We present a practical technique for pointing and selection using a combination of eye gaze and keyboard triggers. EyePoint uses a two-step progressive refinement process fluidly stitched together in a look-press-look-release action, which makes it possible to compensate for the accuracy limitations of the current state-of-the-art eye gaze trackers. While research in gaze-based pointing has traditionally focused on disabled users, EyePoint makes gaze-based pointing effective and simple enough for even able-bodied users to use for their everyday computing tasks. As the cost of eye gaze tracking devices decreases, it will become possible for such gaze-based techniques to be used as a viable alternative for users who choose not to use a mouse depending on their abilities, tasks and preferences.
2007	A minimal model for predicting visual search in human-computer interaction	Visual search is an important part of human-computer interaction. It is critical that we build theory about how people visually search displays in order to better support the users' visual capabilities and limitations in everyday tasks. One way of building such theory is through computational cognitive modeling. The ultimate promise for cognitive modeling in HCI it to provide the science base needed for predictive interface analysis tools. This paper discusses computational cognitive modeling of the perceptual, strategic, and oculomotor processes people used in a visual search task. This work refines and rounds out previously reported cognitive modeling and eye tracking analysis. A revised "minimal model" of visual search is presented that explains a variety of eye movement data better than the original model. The revised model uses a parsimonious strategy that is not tied to a particular visual structure or feature beyond the location of objects. Three characteristics of the minimal strategy are discussed in detail.
2007	A familiar face(book): profile elements as signals in an online social network	Using data from a popular online social network site, this paper explores the relationship between profile structure (namely, which fields are completed) and number of friends, giving designers insight into the importance of the profile and how it works to encourage connections and articulated relationships between users. We describe a theoretical framework that draws on aspects of signaling theory, common ground theory, and transaction costs theory to generate an understanding of why certain profile fields may be more predictive of friendship articulation on the site. Using a dataset consisting of 30,773 Facebook profiles, we determine which profile elements are most likely to predict friendship links and discuss the theoretical and design implications of our findings.
2007	Constructing my online self: avatars that increase self-focused attention	Three studies investigated whether users' strategies for customising online avatars increase their self-focused attention, also known as private self-awareness. Study 1 showed that a high number of users adapt their avatars toreflect their own appearance. Study 2 demonstrated that users who perceive their avatars to be similar to their own appearance experience as a result heightened private self-awareness. In Study 3, private self-awareness pervadedsocial interaction taking place over time when users with representative avatars, compared to a control group, reported increased private self-awareness. Drawing from research in interpersonal communication, we suggest that avatars which increase their owners' self-focus may have an influence on online behavior in the context of social computing.
2007	The truth about lying in online dating profiles	Online dating is a popular new tool for initiating romantic relationships, although recent research and media reports suggest that it may also be fertile ground for deception. Unlike previous studies that rely solely on self-report data, the present study establishes ground truth for 80 online daters' height, weight and age, and compares ground truth data to the information provided in online dating profiles. The results suggest that deception is indeed frequently observed, but that the magnitude of the deceptions is usually small. As expected, deceptions differ by gender. Results are discussed in light of the Hyperpersonal model and the self-presentational tensions experienced by online dating participants.
2007	He says, she says: conflict and coordination in Wikipedia	Wikipedia, a wiki-based encyclopedia, has become one of the most successful experiments in collaborative knowledge building on the Internet. As Wikipedia continues to grow, the potential for conflict and the need for coordination increase as well. This article examines the growth of such non-direct work and describes the development of tools to characterize conflict and coordination costs in Wikipedia. The results may inform the design of new collaborative knowledge systems.
2007	Modeling pointing at targets of arbitrary shapes	We investigate pointing at graphical targets of arbitrary shapes. We first describe a previously proposed probabilistic Fitts' law model [7] which, unlike previous models that only account for rectangular targets, has the potential to handle arbitrary shapes. Three methods of defining the centers of arbitrarily shaped targets for use within the model are developed. We compare these methods of defining target centers, and validate the model using a pointing experiment in which the targets take on various shapes. Results show that the model can accurately account for the varying target shapes. We discuss the implications of our results to interface design.
2007	Perception of elementary graphical elements in tabletop and multi-surface environments	Information shown on a tabletop display can appear distorted when viewed by a seated user. Even worse, the impact of this distortion is different depending on the location of the information on the display. In this paper, we examine how this distortion affects the perception of the basic graphical elements of information visualization shown on displays at various angles. We first examine perception of these elements on a single display, and then compare this to perception across displays, in order to evaluate the effectiveness of various elements for use in a tabletop and multi-display environment. We found that the perception of some graphical elements is more robust to distortion than others. We then develop recommendations for building data visualizations for these environments.
2007	Exploring and reducing the effects of orientation on text readability in volumetric displays	Volumetric displays, which provide a 360° view of imagery illuminated in true 3D space, are a promising platform for interactive 3D applications. However, presenting text in volumetric displays can be a challenge, as the text may not be oriented towards the user. This is especially problematic with multiple viewers, as the text could, for example, appear forwards to one user, and backwards to another. In a first experiment we determined the effects of 3D rotations on text readability. Based on the results, we developed and evaluated a new technique which optimizes text orientation for multiple viewers. This technique provided 33\% faster group reading times in a collaborative experimental task.
2007	Research through design as a method for interaction design research in HCI	For years the HCI community has struggled to integrate design in research and practice. While design has gained a strong foothold in practice, it has had much less impact on the HCI research community. In this paper we propose a new model for interaction design research within HCI. Following a research through design approach, designers produce novel integrations of HCI research in an attempt to make the right thing: a product that transforms the world from its current state to a preferred state. This model allows interaction designers to make research contributions based on their strength in addressing under-constrained problems. To formalize this model, we provide a set of four lenses for evaluating the research contribution and a set of three examples to illustrate the benefits of this type of research.
2007	Sustainable interaction design: invention & disposal, renewal & reuse	This paper presents the perspective that sustainability can and should be a central focus of interaction design-a perspective that is termed Sustainable Interaction Design (SID). As a starting point for a perspective of sustainability, design is defined as an act of choosing among or informing choices of future ways of being . This perspective of sustainability is presented in terms of design values, methods, and reasoning. The paper proposes (i) a rubric for understanding the material effects of particular interaction design cases in terms of forms of use, reuse, and disposal, and (ii) several principles to guide SID. The paper illustrates--with particular examples of design critique for interactive products and appeals to secondary research--how two of these principles may be applied to move the effects of designs from less preferred forms of use to more preferred ones. Finally, a vision for incorporating sustainability into the research and practice of interaction design is described.
2007	Computational composites	Computational composite is introduced as a new type of composite material. Arguing that this is not just a metaphorical maneuver, we provide an analysis of computational technology as material in design, which shows how computers share important characteristics with other materials used in design and architecture. We argue that the notion of computational composites provides a precise understanding of the computer as material, and of how computations need to be combined with other materials to come to expression as material. Besides working as an analysis of computers from a designer's point of view, the notion of computational composites may also provide a link for computer science and human-computer interaction to an increasingly rapid development and use of new materials in design and architecture.
2007	Jogging the distance	People enjoy jogging with others for social and motivational reasons. However, as reported by forum participants, finding a compatible, local jogging partner who shares the ability to jog at the same pace for the same duration is not always easy. One possible way to overcome this challenge is to expand the range of potential jogging partners by allowing for interaction with remote joggers. We investigated whether a jogging experience supporting conversation between remote partners could be desirable and motivating. We conducted an experiment with 18 volunteers using conventional mobile phones with headsets to support conversations as participants jogged in disjoint, outdoor areas. Results show that a simple audio connection supports participants' need to socialize and allows partners to encourage each other.
2007	Sabbath day home automation: it's like mixing technology and religion	We present a qualitative study of 20 American Orthodox Jewish families' use of home automation for religious purposes. These lead users offer insight into real-life, long-term experience with home automation technologies. We discuss how automation was seen by participants to contribute to spiritual experience and how participants oriented to the use of automation as a religious custom. We also discuss the relationship of home automation to family life. We draw design implications for the broader population, including surrender of control as a design resource, home technologies that support long-term goals and lifestyle choices, and respite from technology.
2007	Enhancing ubiquitous computing with user interpretation: field testing the home health horoscope	Domestic ubiquitous computing systems often rely on inferences about activities in the home, but the open-ended, dynamic and heterogeneous nature of the home poses serious problems for such systems. In this paper, we propose that by shifting the responsibility for interpretation from the system to the user, we can build systems that interact with people at humanly meaningful levels, preserve privacy, and encourage engagement with suggested topics. We describe a system that embodies this hypothesis, using sensors and inferencing software to assess 'domestic wellbeing' and presenting the results to inhabitants through an output chosen for its ambiguity. In a three-month field study of the system, customised for a particular volunteer household, users engaged extensively with the system, discussing and challenging its outputs and responding to the particular topics it raised.
2007	Home networking and HCI: what hath god wrought?	For much of the industrialized world, network connectivity in the home is commonplace. Despite the large number of networked homes, even the most technically savvy people can have difficulties with home network installation and maintenance. We contend that these problems will not disappear over time as the networking industry matures, but rather are due to structural usability flaws inherent in the design of existing network infrastructure, devices, and protocols. The HCI community can offer a unique perspective to overcoming the challenges associated with home networking. This paper discusses why home networking is difficult, based on analysis of historical, social, and technical factors. It explores how the designs of existing home networking technologies have implications for usability, and examines a range of models for addressing these usability challenges. The paper concludes with a discussion of how these models may impact future research efforts in both HCI and networking.
2007	Let's go to the whiteboard: how and why software developers use drawings	Software developers are rooted in the written form of their code, yet they often draw diagrams representing their code. Unfortunately, we still know little about how and why they create these diagrams, and so there is little research to inform the design of visual tools to support developers' work. This paper presents findings from semi-structured interviews that have been validated with a structured survey. Results show that most of the diagrams had a transient nature because of the high cost of changing whiteboard sketches to electronic renderings. Diagrams that documented design decisions were often externalized in these temporary drawings and then subsequently lost. Current visualization tools and the software development practices that we observed do not solve these issues, but these results suggest several directions for future research.
2007	Aligning development tools with the way programmers think about code changes	Software developers must modify their programs to keepup with changing requirements and designs. Often, aconceptually simple change can require numerous editsthat are similar but not identical, leading to errors andomissions. Researchers have designed programming environmentsto address this problem, but most of thesesystems are counter-intuitive and difficult to use.By applying a task-centered design process, we developeda visual tool that allows programmers to makecomplex code transformations in an intuitive manner.This approach uses a representation that aligns wellwith programmers' mental models of programming structures.The visual language combines textual and graphicalelements and is expressive enough to support a broadrange of code-changing tasks. To simplify learning thesystem, its user interface scaffolds construction and executionof transformations. An evaluation with Java programmerssuggests that the interface is intuitive, easyto learn, and effective on a representative editing task.
2007	Task and social visualization in software development: evaluation of a prototype	As open source development has evolved, differentiation of roles and increased sophistication of collaborative processes has occurred. Recently, we described coordination issues in software development and an interactive visualization tool called the Social Health Overview (SHO) developed to address them [12]. This paper presents an empirical evaluation of SHO intended to identify its strengths and weaknesses. Eleven informants in various open source roles were interviewed about their work practices. Eight of these participated in an evaluation comparing three change management tasks in SHO and Bugzilla. Results are discussed with respect to task strategy with each tool and participants' roles.
2007	IGroup: presenting web image search results in semantic clusters	Current web image search engines still rely on user typing textual description: query word(s) for visual targets. As the queries are often short, general or even ambiguous, the images in resulting pages vary in content and style. Thus, browsing with these results is likely to be tedious, frustrating and unpredictable. IGroup, a proposed image search engine addresses these problems by presenting the result in semantic clusters. The original result set was clustered in semantic groups with a cluster name relevant to user typed queries. Instead of looking through the result pages or modifying queries, IGroup users can refine findings to the interested sub-result sets with a navigational panel, where each cluster (sub-result set) was listed with a cluster name and representative thumbnails of the cluster. We compared IGroup with a general web image search engine: MSN, in term of efficiency, coverage, and satisfaction with a substantial user study. Our tool shows significant improvement in such criteria.
2007	Web page revisitation revisited: implications of a long-term click-stream study of browser usage	This paper presents results of an extensive long-term click-stream study of Web browser usage. Focusing on character and challenges of page revisitation, previous findings from seven to thirteen years ago are updated. The term page re-visit had to be differentiated, since the recurrence rate--the key measure for the share of page revisits--turns out to strongly depend on interpretation. We identify different types of revisitation that allow assessing the quality of current user support and developing concepts for new tools. Individual navigation strategies differ dramatically and are strongly influenced by personal habits and type of site visited. Based on user action logs and interviews, we distinguished short-term revisits ( backtrack or undo ) from medium-term ( re-utilize or observe ) and long-term revisits ( rediscover ). We analyze current problems and provide suggestions for improving support for different revisitation types.
2007	Noticing notice: a large-scale experiment on the timing of software license agreements	Spyware is an increasing problem. Interestingly, many programs carrying spyware honestly disclose the activities of the software, but users install the software anyway. We report on a study of software installation to assess the effectiveness of different notices for helping people make better decisions on which software to install. Our study of 222 users showed that providing a short summary notice, in addition to the End User License Agreement (EULA), before the installation reduced the number of software installations significantly. We also found that providing the short summary notice after installation led to a significant number of uninstalls. However, even with the short notices, many users installed the program and later expressed regret for doing so. These results, along with a detailed analysis of installation, regret, and survey data about user behaviors informs our recommendations to policymakers and designers for assessing the "adequacy" of consent in the context of software that exhibits behaviors associated with spyware.
2007	Meta-analysis of correlations among usability measures	Understanding the relation between usability measures seems crucial to deepen our conception of usability and to select the right measures for usability studies. We present a meta-analysis of correlations among usability measures calculated from the raw data of 73 studies. Correlations are generally low: effectiveness measures (e.g., errors) and efficiency measures (e.g., time) have a correlation of .247 ± .059 (Pearson's product-moment correlation with 95\% confidence interval), efficiency and satisfaction (e.g., preference) one of .196 ± .064, and effectiveness and satisfaction one of .164 ± .062. Changes in task complexity do not influence these correlations, but use of more complex measures attenuates them. Standard questionnaires for measuring satisfaction appear more reliable than homegrown ones. Measures of users' perceptions of phenomena are generally not correlated with objective measures of the phenomena. Implications for how to measure usability are drawn and common models of usability are criticized.
2007	A predictive model of menu performance	Menus are a primary control in current interfaces, but there has been relatively little theoretical work to model their performance. We propose a model of menu performance that goes beyond previous work by incorporating components for Fitts' Law pointing time, visual search time when novice, Hick-Hyman Law decision time when expert, and for the transition from novice to expert behaviour. The model is able to predict performance for many different menu designs, including adaptive split menus, items with different frequencies and sizes, and multi-level menus. We tested the model by comparing predictions for four menu designs (traditional menus, recency and frequency based split menus, and an adaptive 'morphing' design) with empirical measures. The empirical data matched the predictions extremely well, suggesting that the model can be used to explore a wide range of menu possibilities before implementation.
2007	Endpoint prediction using motion kinematics	Recently proposed novel interaction techniques such as cursor jumping [1] and target expansion for tiled arrangements [13] are predicated on an ability to effectively estimate the endpoint of an input gesture prior to its completion. However, current endpoint estimation techniques lack the precision to make these interaction techniques possible. To address a recognized lack of effective endpoint prediction mechanisms, we propose a new technique for endpoint prediction that applies established laws of motion kinematics in a novel way to the identification of motion endpoint. The technique derives a model of speed over distance that permits extrapolation. We verify our model experimentally using stylus targeting tasks, and demonstrate that our endpoint prediction is almost twice as accurate as the previously tested technique [13] at points more than twice as distant from motion endpoint.
2007	Direct-touch vs. mouse input for tabletop displays	We investigate the differences -- in terms of bothquantitative performance and subjective preference -- between direct-touch and mouse input for unimanual andbimanual tasks on tabletop displays. The results of twoexperiments show that for bimanual tasks performed ontabletops, users benefit from direct-touch input. However,our results also indicate that mouse input may be moreappropriate for a single user working on tabletop tasksrequiring only single-point interaction.
2007	Shift: a technique for operating pen-based interfaces using touch	Retrieving the stylus of a pen-based device takes time and requires a second hand. Especially for short intermittent interactions many users therefore choose to use their bare fingers. Although convenient, this increases targeting times and error rates. We argue that the main reasons are the occlusion of the target by the user's finger and ambiguity about which part of the finger defines the selection point. We propose a pointing technique we call Shift that is designed to address these issues. When the user touches the screen, Shift creates a callout showing a copy of the occluded screen area and places it in a non-occluded location. The callout also shows a pointer representing the selection point of the finger. Using this visual feedback, users guide the pointer into the target by moving their finger on the screen surface and commit the target acquisition by lifting the finger. Unlike existing techniques, Shift is only invoked when necessary--over large targets no callout is created and users enjoy the full performance of an unaltered touch screen. We report the results of a user study showing that with Shift participants can select small targets with much lower error rates than an unaided touch screen and that Shift is faster than Offset Cursor for larger targets.
2007	An alternative to push, press, and tap-tap-tap: gesturing on an isometric joystick for mobile phone text entry	A gestural text entry method for mobile is presented. Unlike most mobile phone text entry methods, which rely on repeatedly pressing buttons, our gestural method uses an isometric joystick and the EdgeWrite alphabet to allow users to write by making letter-like "pressure strokes." In a 15-session study comparing character-level EdgeWrite to Multitap, subjects' speeds were statistically indistinguishable, reaching about 10 WPM. In a second 15-session study comparing word-level EdgeWrite to T9, the same subjects were again statistically indistinguishable, reaching about 16 WPM. Uncorrected errors were low, around 1\% or less for each method. In addition, subjective results favored EdgeWrite. Overall, results indicate that our isometric joystick-based method is highly competitive with two commercial keypad-based methods, opening the way for keypad-less designs and text entry on tiny devices. Additional results showed that a joystick on the back could be used at about 70\% of the speed of the front, and the front joystick could be used eyes-free at about 80\% of the speed of normal use.
2007	Disruption and recovery of computing tasks: field study, analysis, and directions	We report on a field study of the multitasking behavior of computer users focused on the suspension and resumption of tasks. Data was collected with a tool that logged users' interactions with software applications and their associated windows, as well as incoming instant messaging and email alerts. We describe methods, summarize results, and discuss design guidelines suggested by the findings.
2007	CAAD: an automatic task support system	Recent HCI research shows strong interest in task management systems (e.g. [19, 27]) that support the multi-tasked nature of information work [13]. These systems either require users to manually create and maintain task representations or they depend on explicit user cues to guide the creation and maintenance process. To access and use the task representations in these systems, users must also specify their current task. This interaction overhead inhibits the adoption of these systems. In this paper, we present a novel approach to task management that automates the creation and maintenance of task representations. Our system supports the user by making commonly used information more "ready-at-hand" through an intuitive visualization of their task representations. Users can correct and organize their task representations by directly manipulating the visualization; however, this interaction is not required. We describe a feasibility study that demonstrates the actual utility (in terms of overhead reduction) and perceived utility of our system.
2007	Understanding and developing models for detecting and differentiating breakpoints during interactive tasks	The ability to detect and differentiate breakpoints during task execution is critical for enabling defer-to-breakpoint policies within interruption management. In this work, we examine the feasibility of building statistical models that can detect and differentiate three granularities (types) of perceptually meaningful breakpoints during task execution, without having to recognize the underlying tasks. We collected ecological samples of task execution data, and asked observers to review the interaction in the collected videos and identify any perceived breakpoints and their type. Statistical methods were applied to learn models that map features of the interaction to each type of breakpoint. Results showed that the models were able to detect and differentiate breakpoints with reasonably high accuracy across tasks. Among many uses, our resulting models can enable interruption management systems to better realize defer-to-breakpoint policies for interactive, free-form tasks.
2007	Implicit coordination in firefighting practice: design implications for teaching fire emergency responders	Fire emergency response requires rapidly processing and communicating information to coordinate teams that protect lives and property. Students studying to become fire emergency responders must learn to communicate, process, and integrate information during dangerous, stressful, and time-sensitive work. We are performing an ethnographic investigation that includes interviews with experienced fire emergency responders and observations of team burn training exercises with students. We distill salient components of firefighting practice, which are relevant to the design of fire emergency response education systems. We derive design implications for systems that teach fire emergency responders to deal with issues surrounding the communication and integration of fireground information: the mixing of communication modalities, the distribution of information acquisition sources to create information differential and uncertainty, and audible clues.
2007	Back stage on the front lines: perspectives and performance in the combat information center	While tactical command. control and communication environments might appear to be entirely instrumental in nature, they nevertheless provide a setting for social interaction. This paper describes how such interaction occurs in a particular naval tactical command and control system, focusing on the shared perspectives created by the organizational, administrative and professional aspects of the environment and on issues of self-presentation. It is argued that the complexity and multiplicity of interactional regions in this environment lead to problematic situations for key actors, and that these problems may have relevance to future computing environments.
2007	Citizen communications in crisis: anticipating a future of ICT-supported public participation	Recent world-wide crisis events have drawn new attention to the role information communication technology (ICT) can play in warning and response activities. Drawing on disaster social science, we consider a critical aspect of post-impact disaster response that does not yet receive much information science research attention. Public participation is an emerging, large-scale arena for computer-mediated interaction that has implications for both informal and formal response. With a focus on persistent citizen communications as one form of interaction in this arena, we describe their spatial and temporal arrangements, and how the emerging information pathways that result serve different post-impact functions. However, command-and-control models do not easily adapt to the expanding data-generating and -seeking activities by the public. ICT in disaster contexts will give further rise to improvised activities and temporary organizations with which formal response organizations need to align.
2007	Transfer scenarios: grounding innovation with marginal practices	Transfer scenarios is a method developed to support the design of innovative interactive technology. Such a method should help the designer to come up with inventive ideas, and at the same time provide grounding in real human needs. In transfer scenarios, we use marginal practices to encourage a changed mindset throughout the design process. A marginal practice consists of individuals who share an activity that they find meaningful. We regard these individuals not as end-users, but as valuable input in the design process. We applied this method when designing novel applications for autonomous embodied agents, e.g. robots. Owners of unusual pets, such as snakes and spiders, were interviewed - not with the intention to design robot pets, but to determine underlying needs and interests of their practice. The results were then used to design a set of applications for more general users, including a dynamic living-room wall and a set of communicating hobby robots.
2007	Work-centered design: a case study of a mixed-initiative scheduler	We present the case study of a complex, mixed-initiative scheduling system to illustrate Work-Centered Design (WCD), a new approach for the design of information systems. WCD is based on theory of distributed cognition and extends established user-centered methods with abstract task modeling, using innovative techniques for work ontology and top-level algorithms to capture the logic of a human-computer interaction paradigm. WCD addresses a long-standing need for more effective methods of function allocation. The illustrating case study succeeded on a large, difficult problem for aircraft scheduling where prior expensive attempts failed. The new system, called Solver , reduces scheduling labor from 9 person-days a week to about 1 person-hour. These results were obtained from the first user test, demonstrating notable effectiveness of WCD. Further, the value of Solver's higher quality schedules is far-reaching. WCD extends HCI methods to fill an important need for technical problem-solving systems.
2007	Pointing lenses: facilitating stylus input through visual-and motor-space magnification	Using a stylus on a tablet computer to acquire small targets can be challenging. In this paper we present pointing lenses -- interaction techniques that help users acquire and select targets by presenting them with an enlarged visual and interaction area. We present and study three pointing lenses for pen-based systems and find that our proposed Pressure-Activated Lens is the top overall performer in terms of speed, accuracy and user preference. In addition, our experimental results not only show that participants find all pointing lenses beneficial for targets smaller than 5 pixels, but they also suggest that this benefit may extend to larger targets as well.
2007	Comparing physical, automatic and manual map rotation for pedestrian navigation	It is well-established finding that people find maps easier to use when they are aligned so that "up" on the map corresponds to the user's forward direction. With map-based applications on handheld mobile devices, this forward/up correspondence can be maintained in several ways: the device can be physically rotated within the user's hands or the user can manually operate buttons to digitally rotate the map; alternatively, the map can be rotated automatically using data from an electronic compass. This paper examines all three options. In a field experiment, each method is compared against a baseline north-up condition. The study provides strong evidence that physical rotation is the most effective with applications that present the user with a wider map. The paper concludes with some suggestions for design improvements.
2007	Senspectra: a computationally augmented physical modeling toolkit for sensing and visualization of structural strain	We present Senspectra, a computationally augmented physical modeling toolkit designed for sensing and visualization of structural strain. Senspectra seeks to explore a new direction in computational materiality, incorporating the material quality of malleable elements of an interface into its digital control structure. The system functions as a decentralized sensor network consisting of nodes, embedded with computational capabilities and a full spectrum LED, and flexible joints. Each joint functions as an omnidirectional bend sensing mechanism to sense and communicate mechanical strain between neighboring nodes. Using Senspectra, a user incrementally assembles and refines a physical 3D model of discrete elements with a real-time visualization of structural strain. While the Senspectra infrastructure provides a flexible modular sensor network platform, its primary application derives from the need to couple physical modeling techniques utilized in architecture and design disciplines with systems for structural engineering analysis. This offers direct manipulation augmented with visual feedback for an intuitive approach to physical real-time finite element analysis, particularly for organic forms.
2007	Tangible user interface for chemistry education: comparative evaluation and re-design	Augmented Chemistry (AC) is an application that utilizes a tangible user interface (TUI) for organic chemistry education. The empirical evaluation described in this paper compares learning effectiveness and user acceptance of AC versus the more traditional ball-and-stick model (BSM). Learning effectiveness results were almost the same for both learning environments. User preference and rankings, using NASA-TLX and SUMI, showed more differences and it was therefore decided to focus mainly on improving these aspects in a re-design of the AC system. For enhanced interaction, keyboard-free system configuration, and internal/external database (DB) access, a graphical user interface (GUI) has been incorporated into the TUI. Three-dimensional (3D) rendering has also been improved using shadows and related effects, thereby enhancing depth perception. The re-designed AC system was then compared to the old system by means of a small qualitative user study. This user study showed an improvement in subjective opinions a out the system's ease of use and ease of learning.
2007	Mechanical constraints as computational constraints in tabletop tangible interfaces	This paper presents a new type of human-computer interface called Pico (Physical Intervention in Computational Optimization) based on mechanical constraints that combines some of the tactile feedback and affordances of mechanical systems with the abstract computational power of modern computers. The interface is based on a tabletop interaction surface that can sense and move small objects on top of it. The positions of these physical objects represent and control parameters inside a software application, such as a system for optimizing the configuration of radio towers in a cellular telephone network. The computer autonomously attempts to optimize the network, moving the objects on the table as it changes their corresponding parameters in software. As these objects move, the user can constrain their motion with his or her hands, or many other kinds of physical objects. The interface provides ample opportunities for improvisation by allowing the user to employ a rich variety of everyday physical objects as mechanical constraints. This approach leverages the user's mechanical intuition for how objects respond to physical forces. As well, it allows the user to balance the numerical optimization performed by the computer with other goals that are difficult to quantify. Subjects in an evaluation were more effective at solving a complex spatial layout problem using this system than with either of two alternative interfaces that did not feature actuation.
2007	Intimate interfaces in action: assessing the usability and subtlety of emg-based motionless gestures	Mobile communication devices, such as mobile phones and networked personal digital assistants (PDAs), allow users to be constantly connected and communicate anywhere and at any time, often resulting in personal and private communication taking place in public spaces. This private -- public contrast can be problematic. As a remedy, we promote intimate interfaces : interfaces that allow subtle and minimal mobile interaction, without disruption of the surrounding environment. In particular, motionless gestures sensed through the electromyographic (EMG) signal have been proposed as a solution to allow subtle input in a mobile context. In this paper we present an expansion of the work on EMG-based motionless gestures including (1) a novel study of their usability in a mobile context for controlling a realistic, multimodal interface and (2) a formal assessment of how noticeable they are to informed observers. Experimental results confirm that subtle gestures can be profitably used within a multimodal interface and that it is difficult for observers to guess when someone is performing a gesture, confirming the hypothesis of subtlety.
2007	Project massive: self-regulation and problematic use of online gaming	A longitudinal design was employed to collect three waves of survey data over a 14 month period from 2790 online gamers. Respondents were asked questions about their gaming activity, motivations, personality, social and emotional environment, and the effect gaming has had on their lives. Prospective analysis was used to establish causal and temporal linkages among the repeatedly measured factors. While the data provide some indication that a player's reasons for playing do influence the development of problematic usage, these effects are overshadowed by the central importance of self-regulation in managing both the timing and amount of play. An individual's level of self-regulatory activity is shown to be very important in allowing them to avoid negative outcomes like problematic use. The role of depression is also discussed. With responsible use, online gaming appears to be a healthy recreational activity that provides millions of people with hours of social entertainment and adaptive diversion. However, failure to manage play behavior can lead to feelings of dependency.
2007	The life and death of online gaming communities: a look at guilds in world of warcraft	Massively multiplayer online games (MMOGs) can be fascinating laboratories to observe group dynamics online. In particular, players must form persistent associations or "guilds" to coordinate their actions and accomplish the games' toughest objectives. Managing a guild, however, is notoriously difficult and many do not survive very long. In this paper, we examine some of the factors that could explain the success or failure of a game guild based on more than a year of data collected from five World of Warcraft servers. Our focus is on structural properties of these groups, as represented by their social networks and other variables. We use this data to discuss what games can teach us about group dynamics online and, in particular, what tools and techniques could be used to better support gaming communities.
2007	Testing the technology: playing games with video conferencing	Video connections can establish a media space in which games may be played, just as people play games while collocated. Experiments with participants playing the game 'Mafia' indicate that people in a video condition have similar levels of satisfaction, fun, and frustration, to those that play while collocated. This finding holds for both those with prior experience using video systems and those without, suggesting it is not merely a "novelty effect." Results differ about whether there exist differences in focus of attention, suspicion/trust, and pointing for people playing the game while using a video system. Implications for both fun and work uses of video are suggested.
2007	Using heart rate to control an interactive game	This paper presents a novel way of using real-time heart rate information to control a physically interactive biathlon (skiing and shooting) computer game. Instead of interfacing the game to an exercise bike or other equipment with speed output, the skiing speed is directly proportional to heart rate. You can freely choose the form of physical exercise, which makes it easier for people with different skill levels and backgrounds to play together. The system can be used with any exercise machine or form. To make playing meaningful instead of simply exercising as hard as you can, a high heart rate impedes the shooting part of the game by making the sight less steady. This balancing mechanism lets the player try out different tactics, varying from very slow skiing and sharp shooting to fast skiing and random shooting. The game has been evaluated in a user study with eight participants. The results show that heart rate interaction is fun and usable interaction method.
2007	Consuming video on mobile devices	Mobile video is now an everyday possibility with a wide array of commercially available devices, services and content. These technologies promise to transform the way that people can consume video media in their lives beyond the familiar behaviours associated with fixed TV and video technologies. Building upon earlier studies of mobile video, this paper reports on a study using diary techniques and ethnographic interviews to better understand how people are using commercially available mobile video technologies in their everyday lives. Drawing on reported episodes of mobile video behaviour, the study identifies the social motivations and values underpinning these behaviours that help characterise mobile video consumption beyond the simplistic notion of viewing TV to kill time wherever you may be. Implications for adoption and design of mobile video technologies and services are discussed.
2007	Effects of audio and visual surrogates for making sense of digital video	Video surrogates are meant to help people quickly make sense of the content of a video before downloading or seeking more detailed information. In this paper we present the results of a study comparing the effectiveness of three different surrogates for objects in digital video libraries. Thirty-six people participated in a within subjects user study in which they did five tasks for each of three surrogate alternatives: visual alone (a storyboard), audio alone (spoken description), and combined visual and audio (a storyboard augmented with spoken description). The results show that combined surrogates are more effective, strongly preferred, and do not penalize efficiency. The results also demonstrate that spoken descriptions alone lead to better understanding of the video segments than do visual storyboards alone, although people like to have visual surrogates and use them to confirm interpretations and add context. Participants were able to easily use the combined surrogates even though they were not synchronized, suggesting that synchronization of different media channels may not be necessary in surrogates as it is in full video. The results suggest that multimodal surrogates should be incorporated into video retrieval user interfaces and audio surrogates should be used in small display interfaces. The study also raises questions about the need to synchronize different information channels in multimedia surrogates.
2007	Watching together: integrating text chat with video	Watching video online is becoming increasingly popular, and new video streaming technologies have the potential to transform video watching from a passive, isolating experience into an active, socially engaging experience. However, the viability of an active social experience is unclear: both chatting and watching video require attention, and may interfere with one another and detract from the experience. In this paper, we empirically examine the activity of chatting while watching video online. We examine how groups of friends and strangers interact, and find that chat has a positive influence on social relationships, and people chat despite being distracted. We discuss the benefits and opportunities provided by mixing chat and video, uncover some of the attentional and social challenges inherent in this combination of media, and provide guidance for structuring the viewing experience.
2007	Pictures at the ATM: exploring the usability of multiple graphical passwords	Users gain access to cash, confidential information and services at Automated Teller Machines (ATMs) via an authentication process involving a Personal Identification Number (PIN). These users frequently have many different PINs, and fail to remember them without recourse to insecure behaviours. This is not a failing of users. It is a usability failing in the ATM authentication mechanism. This paper describes research executed to evaluate whether users find multiple graphical passwords more memorable than multiple PINs. The research also investigates the success of two memory augmentation strategies in increasing memorability of graphical passwords. The results demonstrate that multiple graphical passwords are substantially more effective than multiple PIN numbers. Memorability is further improved by the use of mnemonics to aid their recall.This study will be of interest to HCI practitioners and information security researchers exploring approaches to usable security.
2007	Password sharing: implications for security design based on social practice	Current systems for banking authentication require that customers not reveal their access codes, even to members of the family. A study of banking and security in Australia shows that the practice of sharing passwords does not conform to this requirement. For married and de facto couples, password sharing is seen as a practical way of managing money and a demonstration of trust. Sharing Personal Identification Numbers (PINs) is a common practice among remote indigenous communities in Australia. In areas with poor banking access, this is the only way to access cash. People with certain disabilities have to share passwords with carers, and PIN numbers with retail clerks. In this paper we present the findings of a qualitative user study of banking and money management. We suggest design criteria for banking security systems, based on observed social and cultural practices of password and PIN number sharing.
2007	Protecting people from phishing: the design and evaluation of an embedded training email system	Phishing attacks, in which criminals lure Internet users to websites that impersonate legitimate sites, are occurring with increasing frequency and are causing considerable harm to victims. In this paper we describe the design and evaluation of an embedded training email system that teaches people about phishing during their normal use of email. We conducted lab experiments contrasting the effectiveness of standard security notices about phishing with two embedded training designs we developed. We found that embedded training works better than the current practice of sending security notices. We also derived sound design principles for embedded training systems.
2007	Studying antecedents of emotional experiences in interactive contexts	This paper describes a research approach to the experimental study of emotional experiences and their connections to other components of user experience in human-technology interaction. We present a model of user experience that integrates interaction characteristics, instrumental and non-instrumental quality perceptions, emotional user reactions and overall judgments of system quality. An experiment is reported to illustrate the application of our approach. System properties of an interactive prototype were varied to produce versions of different usability and aesthetics which in turn led to different perceptions of instrumental and non-instrumental qualities. The results indicate that both quality aspects significantly influence emotional reactions with respect to subjective feelings, facial expressions and physiological responses. These findings are consistent with the users' overall judgments of the systems and show that the perception of both, instrumental and non-instrumental qualities influences the appraisal of interactive systems.
2007	Patterns of empathy in online communication	This article presents an investigation of empathy within an online community for older people (SeniorNet). Qualitative content analysis of 400 messages from a discussion board about depression was used to determine how empathy is expressed and facilitated in online communication. Special emphasis was placed on determining the components of online empathy. A code scheme that we developed to analyse online empathy is also presented. The findings were compared to offline studies about empathy in order to investigate the influence that the mediating technology has on the phenomenon.
2007	Expressing emotion in text-based communication	Our ability to express and accurately assess emotional states is central to human life. The present study examines how people express and detect emotions during text-based communication, an environment that eliminates the nonverbal cues typically associated with emotion. The results from 40 dyadic interactions suggest that users relied on four strategies to express happiness versus sadness, including disagreement, negative affect terms, punctuation, and verbosity. Contrary to conventional wisdom, communication partners readily distinguished between positive and negative valence emotional communicators in this text-based context. The results are discussed with respect to the Social Information Processing model of strategic relational adaptation in mediated communication.
2007	Exploring affective design for physical controls	Physical controls such as knobs, sliders, and buttons are experiencing a revival as many computing systems progress from personal computing architectures towards ubiquitous computing architectures. We demonstrate a process for measuring and comparing visceral emotional responses of a physical control to performance results of a target acquisition task. In our user study, participants experienced mechanical and rendered friction, inertia, and detent dynamics as they turned a haptic knob towards graphical targets of two different widths and amplitudes. Together, this process and user study provide novel affect- and performance-based design guidance to developers of physical controls for emerging ubiquitous computing environments. Our work bridges extensive human factors work in mechanical systems that peaked in the 1960's, to contemporary trends, with a goal of integrating mechatronic controls into emerging ubiquitous computing systems.
2007	Koala: capture, share, automate, personalize business processes on the web	We present Koala, a system that enables users to capture, share, automate, and personalize business processes on the web. Koala is a collaborative programming-by-demonstration system that records, edits, and plays back user interactions as pseudo-natural language scripts that are both human- and machine-interpretable. Unlike previous programming by demonstration systems, Koala leverages sloppy programming that interprets pseudo-natural language instructions (as opposed to formal syntactic statements) in the context of a given web page's elements and actions. Koala scripts are automatically stored in the Koalescence wiki, where a community of users can share, run, and collaboratively develop their "how-to" knowledge. Koala also takes advantage of corporate and personal data stores to automatically generalize and instantiate user-specific data, so that scripts created by one user are automatically personalized for others. Our initial experiences suggest that Koala is surprisingly effective at interpreting instructions originally written for people.
2007	Understanding memory triggers for task tracking	Software can now track which computer applications and documents you use. This provides us with the potential to help end-users recall past activities for tasks such as status reporting. We describe findings from field observations of eight participants writing their status reports. We observed interesting trends, including the reliance on memory triggers, which were either retrieved from explicit self-reminders, from implicit breadcrumbs left while performing their tasks or directly from memory. Participants perceived spending relatively short amounts of time composing their status reports, suggesting that any technology solution must offer dramatic improvements over current practice.
2007	Exploring patterns of social commonality among file directories at work	We studied files stored by members of a work organization for patterns of social commonality. Discovering identical or similar documents, applications, developer libraries, or other files may suggest shared interests or experience among users. Examining actual file data revealed a number of individual and aggregate practices around file storage. For example, pairs of users typically have many (over 13,000) files in common. A prototype called LiveWire exploits this commonality to make file backup and restore more efficient for a work organization. We removed commonly shared files and focused on specific filetypes that represent user activity to find more meaningful files in common. The Consolidarity project explores how patterns of file commonality could encourage social networking in an organizational context. Mechanisms for addressing the privacy concerns raised by this approach are discussed.
2007	A study of out-of-turn interaction in menu-based, IVR, voicemail systems	We present the first user study of out-of-turn interaction inmenu-based, interactive voice-response systems. Out-of-turn interaction is atechnique which empowers the user (unable to respond to the current prompt) totake the conversational initiative by supplying information that is currentlyunsolicited, but expected later in the dialog. The technique permits the userto circumvent any flows of navigation hardwired into the design and navigatethe menus in a manner which reflects their model of the task. We conducted alaboratory experiment to measure the effect of the use of out-of-turninteraction on user performance and preference in a menu-based, voice interfaceto voicemail. Specifically, we compared two interfaces with the exact samehierarchical menu design: one with the capability of accepting out-of-turnutterances and one without this feature. The results indicate that out-of-turninteraction significantly reduces task completion time, improves usability, andis preferred to the baseline. This research studies an unexplored dimension ofthe design space for automated telephone services, namely the nature ofuser-addressable input (utterance) supplied (in-turn vs. out-of-turn), incontrast to more traditional dimensions such as input modality (touch-tone vs.text vs. voice) and style of interaction (menu-based vs. natural language).
2007	Why we tag: motivations for annotation in mobile and online media	Why do people tag? Users have mostly avoided annotating media such as photos -- both in desktop and mobile environments -- despite the many potential uses for annotations, including recall and retrieval. We investigate the incentives for annotation in Flickr, a popular web-based photo-sharing system, and ZoneTag, a cameraphone photo capture and annotation tool that uploads images to Flickr. In Flickr, annotation (as textual tags) serves both personal and social purposes, increasing incentives for tagging and resulting in a relatively high number of annotations. ZoneTag, in turn, makes it easier to tag cameraphone photos that are uploaded to Flickr by allowing annotation and suggesting relevant tags immediately after capture. A qualitative study of ZoneTag/Flickr users exposed various tagging patterns and emerging motivations for photo annotation. We offer a taxonomy of motivations for annotation in this system along two dimensions (sociality and function), and explore the various factors that people consider when tagging their photos. Our findings suggest implications for the design of digital photo organization and sharing applications, as well as other applications that incorporate user-based annotation.
2007	Selection-based note-taking applications	The increasing integration of education and technology has led to the development of a range of note-taking applications. Our project's goal is to provide empirical data to guide the design of such note-taking applications by evaluating the behavioral and learning outcomes of different note-taking functionality. The study reported here compares note-taking using a text editor and four interaction techniques. The two standard techniques are typing and copy-paste. The two novel techniques are restricted copy-paste and menu-selection, intended to increase attention and processing respectively. Hypothesized learning gains from the novel techniques were not observed. As implemented these techniques were less efficient and appeared to be more frustrating to use. However, data regarding differences in both note-taking efficiency and learning suggest several important implications for selection-based note-taking applications, such as pasting and highlighting. Our results also indicate that students have strong opinions regarding their note-taking practices, which may complicate potentially beneficial interventions.
2007	Mobile interaction with visual and RFID tags: a field study on user perceptions	In this paper, we present a study of user perceptions on mobile interaction with visual and RFID tags. Although mobile interaction with tags has been proposed in several earlier studies, user perceptions and usability comparisons of different tag technologies have not been intensively investigated. In contrast to earlier studies, which report on user studies with evaluating new concepts or interaction techniques, we take another approach and examine the current understanding of the techniques and user perceptions on them. Our field study of 50 users charts currently existing user perceptions and reveals potential usability risks that are due to the limited or erroneous understanding of the interaction technique.
2007	Getting our head in the clouds: toward evaluation studies of tagclouds	Tagclouds are visual presentations of a set of words, typically a set of "tags" selected by some rationale, in which attributes of the text such as size, weight, or color are used to represent features, such as frequency, of the associated terms. This note describes two studies to evaluate the effectiveness of differently constructed tagclouds for the various tasks they can be used to support, including searching, browsing, impression formation and recognition. Based on these studies, we propose a paradigm for evaluating tagclouds and ultimately guidelines for tagcloud construction.
2007	Supporting multi-point interaction in visual workspaces	Multi-point interaction tasks involve the manipulation of several mutually-dependent control points in a visual workspace -- for example, adjusting a selection rectangle in a drawing application. Multi-point interactions place conflicting requirements on the interface: the system must display objects at sufficient scale for detailed manipulation, but it must also provide an efficient means of navigating from one control point to another. Current interfaces lack any explicit support for tasks that combine these two requirements, forcing users to carry out sequences of zoom and pan actions. In this paper, we describe three novel mechanisms for view control that explicitly support multi-point interactions with a single mouse, and preserve both visibility and scale for multiple regions of interest. We carried out a study to compare two of the designs against standard zoom and pan techniques, and found that task completion time was significantly reduced with the new approaches. The study shows the potential of interfaces that combine support for both scale and navigation.
2007	Multimodal redundancy across handwriting and speech during computer mediated human-human interactions	Lecturers, presenters and meeting participants often say what they publicly handwrite. In this paper, we report on three empirical explorations of such multimodal redundancy -- during whiteboard presentations, during a spontaneous brainstorming meeting, and during the informal annotation and discussion of photographs. We show that redundantly presented words, compared to other words used during a presentation or meeting, tend to be topic specific and thus are likely to be out-of-vocabulary. We also show that they have significantly higher tf-idf ( term frequency-inverse document frequency ) weights than other words, which we argue supports the hypothesis that they are dialogue-critical words. We frame the import of these empirical findings by describing SHACER, our recently introduced Speech and HAndwriting reCognizER, which can combine information from instances of redundant handwriting and speech to dynamically learn new vocabulary.
2007	An empirical study of the use of visually enhanced voip audio conferencing: the case of IEAC	IBM Enhanced Audio Conferencing (IEAC) is a VoIP-based audio conferencing system that, like several other systems, provides a visualization showing who is present and their states (e.g., speaking, muted). This paper presents the first study of the use of such a system. Drawing on log files collected over six weeks of use by over 1300 corporate employees, and interviews with 10 of them, we look at how and why various features of the system are used and what sorts of practices are supported. Our findings shed light on the factors that drive the use of visual enhancements to audio conferencing, and suggest further research topics.
2007	Voyagers and voyeurs: supporting asynchronous collaborative information visualization	This paper describes mechanisms for asynchronous collaboration in the context of information visualization, recasting visualizations as not just analytic tools, but social spaces. We contribute the design and implementation of sense.us , a web site supporting asynchronous collaboration across a variety of visualization types. The site supports view sharing, discussion, graphical annotation, and social navigation and includes novel interaction elements. We report the results of user studies of the system, observing emergent patterns of social data analysis, including cycles of observation and hypothesis, and the complementary roles of social navigation and data-driven exploration.
2007	Turn it <u>this</u> way: grounding collaborative action with remote gestures	Remote gesture systems have been shown to provide a significant enhancement to performance in collaborative physical tasks, an effect ascribed to the ability of remote gestures to help ground deictic references. The argument that this effect works by replacing complex referential descriptions with simple pointing behaviours has been drawn into question by recent research. In this paper we significantly unpack the effects of remote gesturing on collaborative language, arguing for a more complex role for remote gestures in interaction. We demonstrate how remote gestures influence the structure of collaborative discourse, and how their use can also influence the temporal nature of the grounding process. Through generating a deeper understanding of these effects of remote gesturing on collaborative language we derive implications for the development and deployment of these technologies.
2007	The validity of a virtual human experience for interpersonal skills education	Any new tool introduced for education needs to be validated. We developed a virtual human experience called the Virtual Objective Structured Clinical Examination (VOSCE). In the VOSCE, a medical student examines a life-size virtual human who is presenting symptoms of an illness. The student is then graded on interview skills. As part of a medical school class requirement, thirty three second year medical students participated in a user study designed to determine the validity of the VOSCE for testing interview skills. In the study, participant performance in the VOSCE is compared to participant performance in the OSCE, an interview with a trained actor. There was a significant correlation (r(33)=.49, p<.005) between overall score in the VOSCE and overall score in the OSCE. This means that the interaction skills used with a virtual human translate to the interaction skills used with a real human. Comparing the experience of virtual human interaction to real human interaction is the critical validation step towards using virtual humans for interpersonal skills education.
2007	Modeling and understanding students' off-task behavior in intelligent tutoring systems	We present a machine-learned model that can automatically detect when a student using an intelligent tutoring system is off-task, i.e., engaged in behavior which does not involve the system or a learning task. This model was developed using only log files of system usage (i.e. no screen capture or audio/video data). We show that this model can both accurately identify each student's prevalence of off-task behavior and can distinguish off-task behavior from when the student is talking to the teacher or another student about the subject matter. We use this model in combination with motivational and attitudinal instruments, developing a profile of the attitudes and motivations associated with off-task behavior, and compare this profile to the attitudes and motivations associated with other behaviors in intelligent tutoring systems. We discuss how the model of off-task behavior can be used within interactive learning environments which respond to when students are off-task.
2007	Improvisation principles and techniques for design	Existing research addresses how designers create tools to support improvisation, yet little research explores how improvisation offers tools to support design work. This paper explores the potential relationship between improvisation and design, examining how design can benefit from improvisation. The paper argues that improvisation can build perspectives and skills that are critical for designers, such as creative collaboration, fostering innovation, supporting spontaneity, learning through error, and presenting ideas. The paper reviews the use of improvisation activities by designers in a multi-case study. The applications are analyzed to demonstrate individual and group level outcomes in design work.
2007	Supporting multidisciplinary collaboration: requirements from novel HCI education	Many collaborative design tools may suffer from being too generic to address the specific complexities inherent in multidisciplinary collaboration. We provide accounts of several multidisciplinary HCI courses at our institution, elaborating on the challenges student teams face when integrating design practice from a wide variety of disciplines. Of particular interest are the distinct approaches that these multidisciplinary teams adopt that differ from more common forms of collaborative design. We suggest reasons for the poor rate of adoption of existing collaborative support tools and outline specific suggestions for directions in both ethnographic studies of multidisciplinary collaboration and collaborative systems design.
2007	How HCI interprets the probes	We trace how cultural probes have been adopted and adapted by the HCI community. The flexibility of probes has been central to their uptake, resulting in a proliferation of divergent uses and derivatives. The varying patterns of adaptation of the probes reveal important underlying issues in HCI, suggesting underacknowledged disagreements about valid interpretation and the relationship between methods and their underlying methodology. With this analysis, we aim to clarify discussions around probes, and, more importantly, around how we define and evaluate methods in HCI, especially those grounded in unfamiliar conceptions of how research should be done.
2007	Social dynamics of early stage co-design in developing regions	Technology arguably has the potential to play a key role in improving the lives of people in developing regions. However, these communities are not well understood and designers must thoroughly investigate possibilities for technological innovations in these contexts. We describe findings from two field studies in India and one in Uganda where we explore technological solutions in the domains of communication, microfinance and education. Two common underlying themes emerge from these studies: (1) local stakeholders can contribute cultural information relevant to design such as needs and practices through interaction with technology artifacts and (2) unique social network structures embedded within communities are crucial to the acceptance and potential adoption of technology. We end with a synthesis of the three experiences that draws some practical lessons for ICT designers to elicit meaningful feedback and participation from local stakeholders in developing regions communities.
2007	Localized iterative design for language learning in underdeveloped regions: the PACE framework	Poor literacy remains a decisive barrier to the economic empowerment of many people in the developing world. Of particular importance is literacy in a widely spoken "world language" such as English, which is typically a second language for these speakers. For complex reasons, schools are often not effective as vehicles for second language learning. In this paper we explore game-like language learning on cell phones. We argue that phones are an excellent technology platform in the typical ecologies of developing countries. We present the PACE framework that is intended to support the rapid, scalable development of language learning software localized for a particular community of learners. These learners are usually skeptical of formal education and of cultural biases they encounter in learning "remote" languages in particular. Localization of content is crucial to make the language relevant to them and to encourage them to adopt it.
2007	iStuff mobile: rapidly prototyping new mobile phone interfaces for ubiquitous computing	iStuff Mobile is the first rapid prototyping framework that helps explore new sensor-based interfaces with existing mobile phones. It focuses on sensor-enhanced physical interfaces for ubiquitous computing scenarios. The framework includes sensor network platforms, mobile phone software, and a proven rapid prototyping framework. Interaction designers can use iStuff Mobile to quickly create and test functional prototypes of novel interfaces without making internal hardware or software modifications to the handset. A visual programming paradigm provides a low threshold for prototyping activities: the system is not difficult to learn. At the same time, the range of examples built using the toolkit demonstrates a high ceiling for prototyping activities: the toolkit places few limits on prototype complexity. A user study shows that the visual programming metaphor enables prototypes to be built faster and encourages more iterations than a previous approach.
2007	Appropriation of a MMS-based comic creator: from system functionalities to resources for action	Technologies can be used - or appropriated - in different ways by different users, but how do the use patterns evolve, and how can design facilitate such evolution? This paper approaches these questions in light of a case study in which a group of 8 high school students used Comeks, a mobile comic strip creator that enables users to exchange rich, expressive multimedia messages. A qualitative analysis of the use processes shows how users turned the functionalities embodied in Comeks into particular resources for communication during the 9-week trial period. The paper discusses the relationship of functionalities of the artifact and the development of resources by presenting how functionalities can be designed to support three ways to appropriate communication technologies: increasing technical mastery, re-channeling existing communication into the new medium and inventing new communicative acts between users.
2007	Mobile kits and laptop trays: managing multiple devices in mobile information work	A study at a large IT company shows that mobile information workers frequently migrate work across devices (here: smartphones, desktop PCs, laptops). While having multiple devices provides new opportunities to work in the face of changing resource deprivations, the management of devices is often problematic. The most salient problems are posed by 1) the physical effort demanded by various management tasks, 2) anticipating what data or functionality will be needed, and 3) aligning these efforts with work, mobility, and social situations. Workers' strategies of coping with these problems center on two interwoven activities: the physical handling of devices and cross-device synchronization. These aim at balancing risk and effort in immediate and subsequent use. Workers also exhibit subtle ways to handle devices in situ , appropriating their physical and operational properties. The design implications are discussed.
2007	Command strokes with and without preview: using pen gestures on keyboard for command selection	This paper presents a new command selection method that provides an alternative to pull-down menus in pen-based mobile interfaces. Its primary advantage is the ability forusers to directly select commands from a very large set without the need to traverse menu hierarchies. The proposed method maps the character strings representing the commands onto continuous pen-traces on a stylus keyboard. The user enters a command by stroking part of its character string. We call this method "command strokes." We present the results of three experiments assessing the usefulness of the technique. The first experiment shows that command strokes are 1.6 times faster than the de-facto standard pull-down menus and that users find command strokes more fun to use. The second and third experiments investigate the effect of displaying a visual preview of the currently recognized command while the user is still articulating the command stroke. These experiments show that visual preview does not slow users down and leads to significantly lower error rates and shorter gestures when users enter new unpracticed commands.
2007	Shallow-depth 3d interaction: design and evaluation of one-, two- and three-touch techniques	On traditional tables, people frequently use the third dimension to pile, sort and store objects. However, while effective and informative for organization, this use of the third dimension does not usually extend far above the table. To enrich interaction with digital tables, we present the concept of shallow-depth 3D -- 3D interaction with limited depth. Within this shallow-depth 3D environment several common interaction methods need to be reconsidered. Starting from any of one, two and three touch points, we present interaction techniques that provide control of all types of 3D rotation coupled with translation (6DOF) on a direct-touch tabletop display. The different techniques exemplify a wide range of interaction possibilities: from the one-touch technique, which is designed to be simple and natural, but inherits a degree of imprecision from its simplicity; through to three-touch interaction, which allows precise bimanual simultaneous control of multiple degrees of freedom, but at the cost of simplicity. To understand how these techniques support interaction in shallow-depth 3D, we present a user study that examines the efficiency of, and preferences for, the techniques developed. Results show that users are fastest and most accurate when using the three-touch technique and that their preferences were also strongly in favour of the expressive power available from three-touch.
2007	Affordances for manipulation of physical versus digital media on interactive surfaces	This work presents the results of a comparative study in which we investigate the ways manipulation of physical versus digital media are fundamentally different from one another. Participants carried out both a puzzle task and a photo sorting task in two different modes: in a physical 3-dimensional space and on a multi-touch, interactive tabletop in which the digital items resembled their physical counterparts in terms of appearance and behavior. By observing the interaction behaviors of 12 participants, we explore the main differences and discuss what this means for designing interactive surfaces which use aspects of the physical world as a design resource.
2007	Effects of presenting geographic context on tracking activity between cameras	A common video surveillance task is to keep track of people moving around the space being monitored. It is often difficult to track activity between cameras because locations such as hallways in office buildings can look quite similar and do not indicate the spatial proximity of the cameras. We describe a spatial video player that orients nearby video feeds with the field of view of the main playing video to aid in tracking between cameras. This is compared with the traditional bank of cameras with and without interactive maps for identifying and selecting cameras. We additionally explore the value of static and rotating maps for tracking activity between cameras. The study results show that both the spatial video player and the map improve user performance when compared to the camera-bank interface. Also, subjects change cameras more often with the spatial player than either the camera bank or the map, when available.
2007	Dynamic shared visual spaces: experimenting with automatic camera control in a remote repair task	We present an experimental study of automatic camera control in the performance of collaborative remote repair tasks using video-mediated communication. Twelve pairs of participants, one "helper" and one "worker," completed a series of Lego puzzle tasks using both a static camera and an automatic camera system that was guided in part by tracking the worker's hand position. Results show substantial performance benefits for the automatic system, particularly for complex tasks. The implications of these results are discussed, along with some lessons for the use of motion tracking as a driver for camera control.
2007	Look!: using the gaze direction of embodied agents	This paper describes the results of three studies investigating an embodied agent that supports its interaction with the user by gazing at corresponding objects within its close environment. Three experiments were conducted in order to research whether users can detect an agent's line of sight, whether the agent's gaze direction can help to guide the users' attention towards designated locations and whether such a setup can be used to improve realistic interaction situations. The results show that a) users can detect the agent's gaze direction quickly (within 200 ms) but not very exactly, b) the use of the agent's gaze direction can speed up but also slow down the detection of objects in dependence on their location and c) that the agent's gaze towards corresponding objects during the interaction can have counterproductive effects in realistic settings.
2007	Museum guide robot based on sociological interaction analysis	We are currently working on a museum guide robot with an emphasis on "friendly" human-robot interaction displayed through nonverbal behaviors. In this paper, we focus on head gestures during explanations of exhibits. The outline of our research is as follows. We first examined human head gestures through an experimental, sociological approach. From this research, we have discovered how human guides coordinate their head movement along with their talk when explaining exhibits. Second, we developed a robot system based on these findings. Third, we evaluated human-robot interaction, again using an experimental, sociological approach, and then modified the robot based on the results. Our experimental results suggest that robot head turning may lead to heightened engagement of museum visitors with the robot. Based on our preliminary findings, we will describe a museum guide robot that first works autonomously and, if necessary, can turn into remote-control mode operated by a human to engage in more complex interaction with visitors.
2007	Bubbling menus: a selective mechanism for accessing hierarchical drop-down menus	This paper introduces bubbling menus, a new design for cascading drop-down menus. Bubbling menus combine the bubble cursor [10] with directional mouse-gesture techniques to facilitate the access of certain items in a menu, such as frequently selected items. Through an extensive iterative design process, we explore bubbling menus in the context of adaptive and customizable user interfaces. Unlike other adaptation and customization techniques such as split menus, bubbling menus do not disrupt the original structure of menus and enable the activation of menus far from a menu bar. Results from two evaluation studies presented in the paper show that bubbling menus provide an effective alternative to accelerate menu selections tasks.
2007	Command line or pretty lines?: comparing textual and visual interfaces for intrusion detection	Intrusion detection (ID) is one of network security engineers' most important tasks. Textual (command-line) and visual interfaces are two common modalities used to support engineers in ID. We conducted a controlled experiment comparing a representative textual and visual interface for ID to develop a deeper understanding about the relative strengths and weaknesses of each. We found that the textual interface allows users to better control the analysis of details of the data through the use of rich, powerful, and flexible commands while the visual interface allows better discovery of new attacks by offering an overview of the current state of the network. With this understanding, we recommend designing a hybrid interface that combines the strengths of textual and visual interfaces for the next generation of tools used for intrusion detection.
2007	Pointing and beyond: an operationalization and preliminary evaluation of multi-scale searching	A number of experimental studies based on domain-specific tasks have evaluated the efficiency of navigation techniques for searching multi-scale worlds. The discrepancies among their results call for a more generic framework similar in spirit to Fitts' reciprocal pointing task, but adapted to a task that significantly differs from pure pointing. We introduce such a framework based on an abstract task and evaluate how four multi-scale navigation techniques perform in one particular multi-scale world configuration. Experimental findings indicate that, in this context, pan & zoom combined with an overview is the most efficient technique of all four, and that focus + context techniques perform better than classical pan & zoom. We relate these findings to more realistic situations, discuss their applicability, and how the framework can be used to cover a broad range of situations.
2007	Social practices in location-based collecting	The use of location-based technology to augment visitor experiences has received considerable attention over the years. In this paper, we take an alternative perspective on these kinds of location-based experiences by focussing on the collecting and keeping of location-based content as opposed to simply the in situ consumption of content. We describe a trial of a location-based experience at London zoo in which mobile camera phones were used to access digital content at particular animal enclosures around the zoo. Through the fieldwork we demonstrate ways in which collecting and keeping have important social values over and above simply consuming the content in situ. More specifically, the role of the collection of location-based content in identity work; in developing a sense of challenge and achievement; in defining a sense of group camaraderie; and in creating a playful sense of competition among group members. Further, we see how narratives told around the collected location-based content over time imbue it with additional value. These narratives become part of the resources through which relationships with family and friends get actively constructed. We discuss how these aspects have different design implications from the in-situ consumption model of location-based experiences and tensions this introduces.
2007	Capturing, sharing, and using local place information	With new technology, people can share information about everyday places they go; the resulting data helps others find and evaluate places. Recent applications like Dodgeball and Sharescape repurpose everyday place information: users create local place data for personal use, and the systems display it for public use. We explore both the opportunities -- new local knowledge, and concerns -- privacy risks, raised by this implicit information sharing. We conduct two empirical studies: subjects create place data when using PlaceMail, a location-based reminder system, and elect whether to share it on Sharescape, a community map-building system. We contribute by: (1) showing location-based reminders yield new local knowledge about a variety of places, (2) identifying heuristics people use when deciding what place-related information to share (and their prevalence), (3) detailing how these decision heuristics can inform local knowledge sharing system design, and (4) identifying new uses of shared place information, notably opportunistic errand planning.
2007	Show me the way to Monte Carlo: density-based trajectory navigation	We demonstrate the use of uncertain prediction in asystem for pedestrian navigation via audio with a combination ofGlobal Positioning System data, a music player, inertial sensing,magnetic bearing data and Monte Carlo sampling for a densityfollowing task, where a listener's music is modulated according tothe changing predictions of user position with respect to a targetdensity, in this case a trajectory or path. We show that this system enables eyes-free navigation around set trajectories or paths unfamiliar to the user and demonstrate that the system may be used effectively for varying trajectory width and context.
2007	Mapmover: a case study of design-oriented research into collective expression and constructed publics	In this paper we present the MapMover project as a case study into the use and design of an interactive system for collective expression. Informed by analysis and reflection we advance the concept of constructed publics: publics that are established, shaped, and maintained through the actions and influence of others. We conclude by discussing the relevance of constructed publics as a theorectical frame for the analysis and evaluation of projects in the domains of urban computing and exploratory design in HCI.
2007	Follow the reader: filtering comments on slashdot	Large-scale online communities need to manage the tension between critical mass and information overload. Slashdot is a news and discussion site that has used comment rating to allow massive participation while providing a mechanism for users to filter content. By default, comments with low ratings are hidden. Of users who changed the defaults, more than three times as many chose to use ratings for filtering or sorting as chose to suppress the use of comment ratings. Nearly half of registered users, however, never strayed from the default filtering settings, suggesting that the costs of exploring and selecting custom filter settings exceeds the expected benefit for many users. We recommend leveraging the efforts of the users that actively choose filter settings to reduce the cost of changing settings for all other users. One strategy is to create static schemas that capture the filtering preferences of different groups of readers. Another strategy is to dynamically set filtering thresholds for each conversation thread, based in part on the choices of previous readers. For predicting later readers' choices, the choices of previous readers are far more useful than content features such as the number of comments or the ratings of those comments.
2007	Recent shortcuts: using recent interactions to support shared activities	We present an empirical study of teams that revealed the amount of extraneous individual work needed to enable collaboration: finding references to other people, finding files to attach to email, managing incoming email attachments, managing the variety of files used in shared activities, and tracking what work is owed to others. Much of this work involves finding recently accessed objects that are needed again in the user's current task focus. These observations led to the design of Recent Shortcuts, a tool to help support coordination by making recently used objects easily accessible. Recent Shortcuts enables quick access to people (including groups of people), received attachments, files, and file folders that the user interacted with recently for re-use in the user's current context. Recent Shortcuts makes it easy to use these objects across applications with no additional user input and minimal changes to the user's applications or work practice. Early user experiences with a working prototype led to an extension that integrates recently accessed objects across multiple devices.
2007	Comedia: mobile group media for active spectatorship	Previous attempts to support spectators at large-scale events have concentrated separately on real-time event information, awareness cues, or media-sharing applications. CoMedia combines a group media space with event information and integrates reusable awareness elements throughout. In two field trials, one at a rally and the other at a music festival, we found that CoMedia facilitated onsite reporting to offsite members, coordination of group action, keeping up to date with others, spectating remotely, and joking. In these activities, media, awareness cues, and event information were often used in concert, albeit assuming differing roles. We show that the integrated approach better supports continuous interweaving of use with the changing interests and occurrences in large-scale events.
2007	Demonstrating the viability of automatically generated user interfaces	We conducted a user study that demonstrates that automatically generated interfaces can support better usability through increased flexibility in two dimensions. First, we show that automatic generation can improve usability by moving interfaces that are constrained by cost and poor interaction primitives to another device with better interactive capabilities: subjects were twice as fast and four times as successful at completing tasks with automatically generated interfaces on a PocketPC device as with the actual appliance interfaces. Second, we show that an automatic generator can improve usability by automatically ensuring that new interfaces are generated to be consistent with users' previous experience: subjects were also twice as fast using interfaces consistent with their experiences as compared to normally generated interfaces. These two results demonstrate that automatic interface generation is now viable and especially desirable where users will benefit from individualized interfaces or where human designers are constrained by cost and other factors.
2007	The role of choice and customization on users' interaction with embodied conversational agents: effects on perception and performance	We performed an empirical study exploring people's interactions with an embodied conversational agent (ECA) while performing two tasks. Conditions varied with respect to 1) whether participants were allowed to choose an agent and its characteristics and 2) the putative quality or appropriateness of the agent for the tasks. For both tasks, selection combined with the illusion of further customization significantly improved participants' overall subjective impressions of the ECAs while putative quality had little or no effect. Additionally, performance data revealed that the ECA's motivation and persuasion effects were significantly enhanced when participants chose agents to use. We found that user expectations about and perceptions of the interaction between themselves and an ECA depended very much on the individual's preconceived notions and preferences of various ECA characteristics and might deviate greatly from the models that ECA designers intend to portray.
2007	Seconds matter: improving distributed coordination bytracking and visualizing display trajectories	Pauses in distributed groupware activity can indicate anything from technical latency through infrastructure failure to a participant's thoughtful contemplation. Unraveling these ambiguities highlights mismatches between unseen off-screen activities and on-screen cursor behaviors. In this paper we suggest that groupware systems have typically been poor at representing off-screen activities, and introduce the concept of display trajectories to bridge the sensor gap between the display and its surrounding space. We consider requirements for display trajectories using the distributed social scientific analysis of video data as an example domain. Drawing on these requirements, we prototype a freeform whiteboard pen tracking and visualization technique around displays using ultrasound. We describe an experiment which inspects the impact of display trajectories on remote response efficiency. Our findings show that visualization of the display trajectory improves participants' ability to coordinate their actions by one second per interaction turn, reducing latency in organizing turn taking by a 'standard maximum' conversation pause.
2007	FASTDash: a visual dashboard for fostering awareness in software teams	Software developers spend significant time gaining and maintaining awareness of fellow developers' activities. FASTDash is a new interactive visualization that seeks to improve team activity awareness using a spatial representation of the shared code base that highlights team members' current activities. With FASTDash, a developer can quickly determine which team members have source files checked out, which files are being viewed, and what methods and classes are currently being changed. The visualization can be annotated, allowing programmers to supplement activity information with additional status details. It provides immediate awareness of potential conflict situations, such as two programmers editing the same source file. FASTDash was developed through user-centered design, including surveys, team interviews, and in situ observation. Results from a field study show that FASTDash improved team awareness, reduced reliance on shared artifacts, and increased project-related communication. Additionally, the team that participated in our field study continues to use FASTDash.
2007	A study of emergency response work: patterns of mobile phone interaction	This paper presents descriptive accounts of time-critical organizing in the domain of emergency response. Patterns of mobile phone interaction in such work is analyzed showing how the dyadic exchange of mobile phone numbers between the actors plays an important role in the social interactions in the organizing and sensemaking of the emergency. Enacted sensemaking is used as an analytical framework. Implications for design of emergency response information technology are outlined and discussed.
2007	ExperiScope: an analysis tool for interaction data	We present ExperiScope, an analytical tool to help designers and experimenters explore the results of quantitative evaluations of interaction techniques. ExperiScope combines a new visualization incorporating aspects of the KLM and the three-state model with an interface helping users to rapidly cluster similar patterns of interactions. The tool makes it easy to identify and compare key patterns of use encountered during data collection. This promotes a deeper understanding of the results of a given evaluation.We illustrate the advantages of this tool by revisiting the data collected for an experiment conducted by Hinckley et al. [19] which compared different mode switching techniques. Our results show that our tool complements the previously reported results by offering insights about error behavior and the impact of mode switching on user performance.By providing a more fine-grained analysis of the data gathered during empirical evaluations, we hope that our tool will improve researchers' understanding of existing and newly developed interaction techniques.
2007	Context & usability testing: user-modeled information presentation in easy and difficult driving conditions	A 2x2 enhanced Wizard-of-Oz experiment (N = 32) was conducted to compare two different approaches to presenting information to drivers in easy and difficult driving conditions. Data of driving safety, evaluation of the spoken dialogue system, and perception of self were analyzed. Results show that the user-modeled summarize-and-refine (UMSR) approach led to more efficient information retrieval than did the summarize-and-refine (SR) approach. However, depending on driving condition, higher efficiency did not always translate into pleasant subjective experience. Implications for usability testing and interface design were presented, followed by discussions of future research directions.
2007	Tracking the interaction of users with AJAX applications for usability testing	In this paper, we introduce an implementation for detailed monitoring of user actions on web pages. It addresses the problem that the log data recorded by standard web servers is not sufficient for the tracking of users on AJAX websites, e.g. to conduct a usability test. Using standard web technologies, our HTTP proxy can record very detailed usage information, such as mouse movements, clicks, key presses and scrolling, together with the exact HTML DOM tree objects involved. As we show in several case studies, the tracking also works across multiple websites, none of which needs to be under our control. This approach is much less invasive than previous efforts: The test person does not need to install software on her computer, and in certain operation modes, no configuration changes at all are required on her computer. Our research indicates that if the technology described in this paper is employed, arbitrary visitors of a website are more likely to take part in a usability test offered by that site -- this facilitates recruiting test participants over the Internet.
2007	Grow and know: understanding record-keeping needs for tracking the development of young children	From birth through age five, children undergo rapid development and learn skills that will influence them their entire lives. Regular visits to the pediatrician and detailed record-keeping can ensure that children are progressing and can identify early warning signs of developmental delay or disability. However, new parents are often overwhelmed with new responsibilities, and we believe there is an opportunity for computing technology to assist in this process. In this paper, we present a qualitative study aimed at uncovering some specific needs for record-keeping and analysis for new parents and their network of caregivers. Through interviews and focus groups, we have confirmed assumptions about the rationales parents have and the functions required for using technology for record-keeping. We also identify new themes, potential prototypes, and design guidelines for this domain.
2007	Sharing motion information with close family and friends	We present the Motion Presence application, an augmented phone book style application that allows close friends and family to view each other's current motion status ("moving" or "not moving") on their mobile phones. We performed a two week long field trial with 10 participants to observe usage and investigate any privacy concerns that might arise. We found that our participants used the motion information to infer location and activity as well as to plan communication, to help in coordinating in-person get-togethers, and to stay connected to patterns in each others' lives. Participants saw the motion data as mostly confirming their existing thoughts about the locations and activities of others and expressed few privacy concerns. In fact, they frequently asked for more information to be shared to make the application more compelling.
2007	Comicboarding: using comics as proxies for participatory design with children	Comicboarding is a participatory design method that uses specially created comic books to generate engaging, productive brainstorming sessions with children. By leveraging known plot formats, interaction styles, and characters in comics, researchers can elicit ideas even from children who are not accustomed to brainstorming, such as those from schools were rote learning is the norm. We conducted an experiment using two variants of the comicboarding methodology with 17 children in China, where traditional participatory design may fail in the face of local cultural practices. The results suggest that comicboarding holds promise for co-design with children.
2007	Pressure marks	Selections and actions in GUI's are often separated -- i.e. an action or command typically follows a selection. This sequence imposes a lower bound on the interaction time that is equal to or greater than the sum of its parts. In this paper, we introduce pressure marks -- pen strokes where the variations in pressure make it possible to indicate both a selection and an action simultaneously. We propose a series of design guidelines from which we develop a set of four basictypes of pressure marks. We first assess the viability of this set through an exploratory study that looks at the way users draw straight and lasso pressure marks of different sizes and orientations. We then present the results of a quantitative experiment that shows that users perform faster selection-action interactions with pressure marks than with a combination of lassos and pigtails. Based on these results, we present and discuss a number of interaction designs that incorporate pressure marks.
2007	Augmenting the mouse with pressure sensitive input	In this paper we investigate the use of a uni-pressure and dual-pressure augmented mouse. With a pressure augmented mouse users can simultaneously control cursor positions as well as multiple levels of discrete selection modes for common desktop application tasks. Two or more independent pressure sensors can be mounted onto several locations on the body of the mouse. To highlight the design potential of a pressure augmented mouse we conducted a multi-part study. In the first part we identified the number of maximum discrete levels controllable with a uni-pressure augmented mouse, the most appropriate locations for installing pressure sensors on the mouse, and the design of new interaction techniques to support selection with pressure-based input. In a follow-up design we introduced an additional sensor and two different types of selection techniques to control a larger number of discrete levels with two pressure sensors. Our results show that users can comfortably control up to 64 modes with a dual-pressure augmented mouse. We discuss the findings of our results in the context of several desktop interaction techniques and identify several design recommendations.
2007	Earpod: eyes-free menu selection using touch input and reactive audio feedback	We present the design and evaluation of earPod: an eyes-free menu technique using touch input and reactive auditory feedback. Studies comparing earPod with an iPod-like visual menu technique on reasonably-sized static menus indicate that they are comparable in accuracy. In terms of efficiency (speed), earPod is initially slower, but outperforms the visual technique within 30 minutes of practice. Our results indicate that earPod is potentially a reasonable eyes-free menu technique for general use, and is a particularly exciting technique for use in mobile device interfaces.
2007	What happened to remote usability testing?: an empirical study of three methods	The idea of conducting usability tests remotely emerged ten years ago. Since then, it has been studied empirically, and some software organizations employ remote methods. Yet there are still few comparisons involving more than one remote method. This paper presents results from a systematic empirical comparison of three methods for remote usability testing and a conventional laboratory-based think-aloud method. The three remote methods are a remote synchronous condition, where testing is conducted in real time but the test monitor is separated spatially from the test subjects, and two remote asynchronous conditions, where the test monitor and the test subjects are separated both spatially and temporally. The results show that the remote synchronous method is virtually equivalent to the conventional method. Thereby, it has the potential to conveniently involve broader user groups in usability testing and support new development approaches. The asynchronous methods are considerably more time-consuming for the test subjects and identify fewer usability problems, yet they may still be worthwhile.
2007	Usability testing: what have we overlooked?	For more than a decade, the number of usability test participants has been a major theme of debate among usability practitioners and researchers keen to improve usability test performance. This paper provides evidence suggesting that the focus be shifted to task coverage instead. Our data analysis of nine commercial usability test teams participating in the CUE-4 study revealed no significant correlation between the percentage of problems found or of new problems and number of test users, but correlations of both variables and number of user tasks used by each usability team were significant. The role of participant recruitment on usability test performance and future research directions are discussed.
2007	Touchstone: exploratory design of experiments	Touchstone is an open-source experiment design platform designed to help establish a solid research foundation for HCI in the area of novel interaction techniques. Touchstone includes a design platform for exploring alternative designs of controlled laboratory experiments, a run platform for running subjects and a limited analysis platform for advice and access to on-line statistics packages. Designed for HCI researchers and their students, Touchstone facilitates the process of creating new experiments, as well as replicating and extending experiments in the research literature. We tested Touchstone by designing two controlled experiments. One illustrates how to create a new experiment from scratch. The other replicates and extends a previous study of multiscale pointing interaction techniques: OrthoZoom was fastest, followed by bi-manual Pan & Zoom; SDAZ and traditional Pan & Zoom were consistently slower.
2007	Making mashups with marmite: towards end-user programming for the web	There is a tremendous amount of web content available today, but it is not always in a form that supports end-users' needs. In many cases, all of the data and services needed to accomplish a goal already exist, but are not in a form amenable to an end-user. To address this problem, we have developed an end-user programming tool called Marmite, which lets end-users create so-called mashups that re-purpose and combine existing web content and services. In this paper, we present the design, implementation, and evaluation of Marmite. An informal user study found that programmers and some spreadsheet users had little difficulty using the system.
2007	Vio: a mixed-initiative approach to learning and automating procedural update tasks	Today many workers spend too much of their time translating their co-workers' requests into structures that information systems can understand. This paper presents the novel interaction design and evaluation of VIO, an agent that helps workers trans late request. VIO monitors requests and makes suggestions to speed up the translation. VIO allows users to quickly correct agent errors. These corrections are used to improve agent performance as it learns to automate work. Our evaluations demonstrate that this type of agent can significantly reduce task completion time, freeing workers from mundane tasks.
2007	Storytelling alice motivates middle school girls to learn computer programming	We describe Storytelling Alice, a programming environment that introduces middle school girls to computer programming as a means to the end of creating 3D animated stories. Storytelling Alice supports story creation by providing 1) a set of high-level animations, that support the use of social characters who can interact with one another, 2) a collection of 3D characters and scenery designed to spark story ideas, and 3) a tutorial that introduces users to writing Alice programs using story-based examples. In a study comparing girls' experiences learning to program using Storytelling Alice and a version of Alice without storytelling support (Generic Alice), we found that users of Storytelling Alice and Generic Alice were equally successful at learning basic programming constructs. Participants found Storytelling Alice and Generic Alice equally easy to use and entertaining. Users of Storytelling Alice were more motivated to program; they spent 42\% more time programming, were more than 3 times as likely to sneak extra time to work on their programs, and expressed stronger interest in future use of Alice than users of Generic Alice.
2007	Multiview: improving trust in group video conferencing through spatial faithfulness	Video conferencing is still considered a poor alternative to face-to-face meetings. In the business setting, where these systems are most prevalent, the misuse of video conferencing systems can have detrimental results, especially in high-stakes communications. Prior work suggests that spatial distortions of nonverbal cues, particularly gaze and deixis, negatively impact many aspects of effective communication in dyadic communications. However, video conferencing systems are often used for group-to-group meetings where spatial distortions are exacerbated. Meanwhile, its effects on the group dynamic are not well understood. In this study, we examine the effects that spatial distortions of nonverbal cues have on inter-group trust formation. We conducted a large (169 participant) study of group conferencing under various conditions. We found that the use of systems that introduce spatial distortions negatively affect trust formation patterns. On the other hand, these effects are essentially eliminated by using a spatially faithful video conferencing system.
2007	Presence and engagement in an interactive drama	In this paper we present the results of a qualitative, empirical study exploring the impact of immersive technologies on presence and engagement, using the interactive drama Façade as the object of study. In this drama, players are situated in a married couple's apartment, and interact primarily through conversation with the characters and manipulation of objects in the space. We present participants' experiences across three different versions of Façade -- augmented reality (AR) and two desktop computing based implementations, one where players communicate using speech and the other using typed keyboard input. Through interviews and observations of players, we find that immersive AR can create an increased sense of presence, confirming generally held expectations. However, we demonstrate that increased presence does not necessarily lead to more engagement. Rather, mediation may be necessary for some players to fully engage with certain interactive media experiences.
2007	Engaging constable: revealing art with new technology	Museums increasingly deploy new technologies to enhance visitors' experience of their exhibitions. They primarily rely on touch-screen computer systems, PDAs and digital audio-guides. Tate Britain recently employed two innovative systems in one of their major exhibitions of John Constable's work; a gestural interface and a touch-screen panel, both connected to large projection screens. This paper reports on the analysis of video-recordings and field observations of visitors' action and interaction. It explores how people interact with and around the systems, how they configure the space around the installation and how they examine and discover their properties. It suggests that designers of interfaces and installations developed for museum exhibitions face particular challenges, such as the transparency of the relationship between people's actions and the system' response, the provision of opportunities for individual and collaborative experiences and the interweaving of technological and aesthetic experiences.
2007	Modeling human performance of pen stroke gestures	This paper presents a quantitative human performance model of making single-stroke pen gestures within certain error constraints in terms of production time. Computed from the properties of Curves, Line segments, and Corners (CLC) in a gesture stroke, the model may serve as a foundation for the design and evaluation of existing and future gesture-based user interfaces at the basic motor control efficiency level, similar to the role of previous "laws of action" played to pointing, crossing or steering-based user interfaces. We report and discuss our experimental results on establishing and validating the CLC model, together with other basic empirical findings in stroke gesture production.
2007	Keystroke-level model for advanced mobile phone interaction	The design of applications using mobile devices needs a different quality assessment than those known for desktop applications. Of the many aspects that have to be taken into account, one important criterion is the average time users need to complete a task. For interactions with the mouse, keyboard or touch screens, there exist models that predict interaction times like Fitts' law or the Keystroke-Level Model (KLM). This paper shows parallels to these models for advanced interactions with mobile phones targeted at pervasive services, including near field communication as well as built-in cameras and sensors. Applications can be evaluated with respect to user performance time without having a prototype running on the phone. To accomplish that, we extend the known KLM by identifying basic interaction elements for mobile phones and give estimates for expert user performance derived from several user tests.
2007	An extended keystroke level model (KLM) for predicting the visual demand of in-vehicle information systems	To assess the potential distraction of In-Vehicle Information Systems (IVIS), simple, low cost evaluation methods are required for use in early design stages. The occlusion technique evaluates IVIS tasks in interrupted vision conditions, aiming to predict likely visual demand. However, the technique necessitates performance-focused user trials utilising robust prototypes, and consequently has limitations as an economic evaluation method. HCI practitioners view the Keystroke Level Model (KLM) as a reliable and valid means of modelling human performance, not requiring empirical trials or working prototypes. This paper proposes an extended KLM, which aims to predict measures based on the occlusion protocol. To validate the new method, we compared results of an occlusion study with predictions based on the assumptions of the extended KLM. Analysis revealed significant correlations between observed and predicted results (R=0.93-0.98) and low error rates (7-13\%). In conclusion, the extended KLM shows considerable merit as a first-pass design tool.
2007	Towards developing assistive haptic feedback for visually impaired internet users	Haptic technologies are thought to have the potential to help blind individuals overcome the challenges experienced when accessing the Web. This paper proposes a structured participatory-based approach for developing targeted haptic sensations for purposes of web page exploration, and reports preliminary results showing how HTML elements can be represented through the use of force-feedback. Findings are then compared with mappings from previous studies, demonstrating the need for providing tailored haptic sensations for blind Internet users. This research aims to culminate in a framework, encompassing a vocabulary of haptic sensations with accompanying recommendations for designers to reference when developing inclusive web solutions.
2007	An interface to support color blind computer users	A new method for adapting digital images so that they are suitable for color blind viewers is presented. In contrast to earlier automatic methods which formulate the problem of adapting images for color blind observers as one of optimization, we demonstrate how it is possible to allow a user to compute a very wide range of adaptations in reasonable time under the control of a single variable. We demonstrate how the algorithm can be delivered as an adaptive technology via a simple interface, and evaluate the efficacy of our method using psychovisual experiments with simulated color blind users and a standard color vision test.
2007	An adaptive & adaptable approach to enhance web graphics accessibility for visually impaired people	To date, efforts have been made to enable visually impaired people to gain access to graphics on the Internet. However, these studies only offer a solution for a specific type of graphic by using a fixed set of hardware. To address this, a design approach of an adaptive and adaptable architecture is introduced which adapts to different graphical content, input/output devices (including assistive technologies) and user's profile and preferences. This system brings the opportunity to visually impaired people to gain access to graphics via different modalities by providing an adequate accessibility interface and interaction based on their profiles and needs.
2007	Modeling the impact of shared visual information on collaborative reference	A number of recent studies have demonstrated that groups benefit considerably from access to shared visual information. This is due, in part, to the communicative efficiencies provided by the shared visual context. However, a large gap exists between our current theoretical understanding and our existing models. We address this gap by developing a computational model that integrates linguistic cues with visual cues in a way that effectively models reference during tightly-coupled, task-oriented interactions. The results demonstrate that an integrated model significantly outperforms existing language-only and visual-only models. The findings can be used to inform and augment the development of conversational agents, applications that dynamically track discourse and collaborative interactions, and dialogue managers for natural language interfaces.
2007	Similarity is more important than expertise: accent effects in speech interfaces	In a balanced between-participants experiment (N = 96) American and Swedish participants listened to tourist information on a website about an American or Swedish city presented in English with either an American or Swedish accent and evaluated the speakers' knowledge of the topic, the voice characteristics, and the information characteristics. Users preferred accents similar to their own. Similarity-attraction effects were so powerful that same-accents speakers were viewed as being more knowledgeable than different-accent speakers even when the information would be much better-known by the opposite-accent speaker. Implications for similarity-attraction overwhelming expertise are discussed.
2007	Provoking sociability	In this study, we explore the potential usefulness of disturbing, uncomfortable systems, demonstrating that provocative technology can have a positive effect on social relationships. We designed and evaluated an agent-based system that collects user information by asking seemingly benign questions, and then uses it to spread false, strange gossip throughout an office space. We show that provocative interaction on-line can improve off-line sociability.
2007	Social responses to virtual humans: implications for future interface design	Do human-human social interactions carry over to human-virtual human social interactions? How does this affect future interface designers? We replicated classical tests of social influence known as the social facilitation and inhibition effects. Social facilitation/inhibition theory states that when in the presence of others, people perform simple tasks better and complex tasks worse. Participants were randomly assigned to perform both simple and complex tasks alone and in the presence of either a real human, a projected virtual human, or a virtual human in a head-mounted display. Our results showed participants were inhibited by the presence of others, whether real or virtual. That is, participants performed worse on the complex task, both in terms of percent correct and reaction times, when in the presence of others than when alone. Social facilitation did not occur with the real or virtual human. We discuss these results and their implications for future interface designers.
2007	Hard lessons: effort-inducing interfaces benefit spatial learning	Interface designers normally strive for a design that minimises the user's effort. However, when the design's objective is to train users to interact with interfaces that are highly dependent on spatial properties (e.g. keypad layout or gesture shapes) we contend that designers should consider explicitly increasing the mental effort of interaction. To test the hypothesis that effort aids spatial memory, we designed a "frost-brushing" interface that forces the user to mentally retrieve spatial information, or to physically brush away the frost to obtain visual guidance. We report results from two experiments using virtual keypad interfaces -- the first concerns spatial location learning of buttons on the keypad, and the second concerns both location and trajectory learning of gesture shape. The results support our hypothesis, showing that the frost-brushing design improved spatial learning. The participants' subjective responses emphasised the connections between effort, engagement, boredom, frustration, and enjoyment, suggesting that effort requires careful parameterisation to maximise its effectiveness.
2007	Multiple mice for retention tasks in disadvantaged schools	This study evaluates single-mouse and multiple-mice configurations for computer-aided learning in schools where access to computers is limited due to resource constraints. Multimouse , a single display groupware solution, developed to allow multiple mice to be used simultaneously on a single PC, is compared with single-user-single-mouse and multiple-user-single-mouse scenarios. Multimouse itself is trialed with two unique interaction designs -- one where competitive interaction among students is encouraged, and another where more collaborative interaction is expected. Experiments were conducted with 238 schoolchildren from underprivileged households in rural India on an English vocabulary retention task. On the whole, Multimouse configurations (five users each) were found to be at par with single-user scenarios in terms of actual words learned by students. This suggests that the value of a PC can be inexpensively multiplied by employing a multi-input shared-use design. Gender effects were found, where boys show significant differences in learning depending on interaction modality, whereas girls learned at similar rates across configurations. In addition, a comparison of the two Multimouse modes -- collaborative and competitive -- showed the striking difference in learning outcomes and user behavior that is possible due to even slight variations in interaction designs for multiple-mice.
2007	Strategies for accelerating on-line learning of hotkeys	Hotkeys are extremely useful in leveraging expert performance, but learning them is a slow process. This paper investigates alternative menu designs that can motivate and help users remember associations between menu commands and hotkeys. Building upon previous work on paired-associate learning, we suggest that the transition to expert use can be accelerated by manipulating feedback and cost associated with menu selection. We evaluate five designs in a pilot study and then two of the most promising ones in a formal experiment, showing that the speed of hotkey learning can indeed be significantly increased with little modifications to the standard menu/hotkey paradigm.
2007	A meta-analysis of the impact of the inclusion and realism of human-like faces on user experiences in interfaces	The use of embodied agents, defined as visual human-like representations accompanying a computer interface, is becoming prevalent in applications ranging from educational software to advertisements. In the current work, we assimilate previous empirical studies which compare interfaces with visually embodied agents to interfaces without agents, both using an informal, descriptive technique based on experimental results (46 studies) as well as a formal statistical meta-analysis (25 studies). Results revealed significantly larger effect sizes when analyzing subjective responses (i.e., questionnaire ratings, interviews) than when analyzing behavioral responses such as task performance and memory. Furthermore, the effects of adding an agent to an interface are larger than the effects of animating an agent to behave more realistically. However, the overall effect sizes were quite small (e.g., across studies, adding a face to an interface only explains approximately 2.5\% of the variance in results). We discuss the implications for both designers building interfaces as well as social scientists designing experiments to evaluate those interfaces.
2007	Improving recognition and characterization in groupware with rich embodiments	Embodiments are visual representations of people in a groupware system. Embodiments convey awareness information such as presence, location, and movement -- but they provide far less information than what is available from a real body in a face-to-face setting. As a result, it is often difficult to recognize and characterize other people in a groupware system without extensive communication. To address this problem, information-rich embodiments use ideas from multivariate information visualization to maximize the amount of information that is represented about a person. To investigate the feasibility of rich embodiment and their effects on group interaction, we carried out three studies. The first shows that users are able to recall and interpret a large set of variables that are graphically encoded on an embodiment. The second and third studies demonstrated rich embodiments in two groupware systems -- a multiplayer game and a drawing application -- and showed that the enhanced representations do improve recognition and characterization, and that they can enrich interaction in a variety of ways.
2007	Coordinating joint activity in avatar-mediated interaction	Massively multiplayer online games (MMOGs) currently represent the most widely used type of social 3D virtual worlds with millions of users worldwide. Although MMOGs take face-to-face conversation as their metaphor for user-to-user interaction, avatars currently give off much less information about what users are doing than real human bodies. Consequently, users routinely encounter slippages in coordination when engaging in joint courses of action. In this study, we analyze screen-capture video of user-to-user interaction in the game, City of Heroes, under two conditions: one with the game's standard awareness cues and the other with enhanced cues. We use conversation analysis to demonstrate interactional slippages caused by the absence of awareness cues, user practices that circumvent such limitations and ways in which enhanced cues can enable tighter coordination.
2007	How it works: a field study of non-technical users interacting with an intelligent system	In order to develop intelligent systems that attain the trust of their users, it is important to understand how users perceive such systems and develop those perceptions over time. We present an investigation into how users come to understand an intelligent system as they use it in their daily work. During a six-week field study, we interviewed eight office workers regarding the operation of a system that predicted their managers' interruptibility, comparing their mental models to the actual system model. Our results show that by the end of the study, participants were able to discount some of their initial misconceptions about what information the system used for reasoning about interruptibility. However, the overarching structures of their mental models stayed relatively stable over the course of the study. Lastly, we found that participants were able to give lay descriptions attributing simple machine learning concepts to the system despite their lack of technical knowledge. Our findings suggest an appropriate level of feedback for user interfaces of intelligent systems, provide a baseline level of complexity for user understanding, and highlight the challenges of making users aware of sensed inputs for such systems.
2008	The LilyPad Arduino: using computational textiles to investigate engagement, aesthetics, and diversity in computer science education	The advent of novel materials (such as conductive fibers) combined with accessible embedded computing platforms have made it possible to re-imagine the landscapes of fabric and electronic crafts--extending these landscapes with the creative range of electronic/computational textiles or e-textiles . This paper describes the LilyPad Arduino , a fabric-based construction kit that enables novices to design and build their own soft wearables and other textile artifacts. The kit consists of a microcontroller and an assortment of sensors and actuators in stitch-able packages; these elements can be sewn to cloth substrates and each other with conductive thread to build e-textiles. This paper will introduce the latest version of the kit; reflect on its affordances; present the results of our most recent user studies; and discuss possible directions for future work in the area of personalized e-textile design and its relation to technology education.
2008	A diary study of mobile information needs	Being mobile influences not only the types of information people seek but also the ways they attempt to access it. Mobile contexts present challenges of changing location and social context, restricted time for information access, and the need to share attentional resources among concurrent activities. Understanding mobile information needs and associated interaction challenges is fundamental to improving designs for mobile phones and related devices. We conducted a two-week diary study to better understand mobile information needs and how they are addressed. Our study revealed that depending on the time and resources available, as well as the situational context, people use diverse and, at times, ingenious ways to obtain needed information. We summarize key findings and discuss design implications for mobile technology.
2008	Tracking real-time user experience (TRUE): a comprehensive instrumentation solution for complex systems	Automatic recording of user behavior within a system (instrumentation) to develop and test theories has a rich history in psychology and system design. Often, researchers analyze instrumented behavior in isolation from other data. The problem with collecting instrumented behaviors without attitudinal, demographic, and contextual data is that researchers have no way to answer the 'why' behind the 'what'. We have combined the collection and analysis of behavioral instrumentation with other HCI methods to develop a system for Tracking Real-Time User Experience (TRUE). Using two case studies as examples, we demonstrate how we have evolved instrumentation methodology and analysis to extensively improve the design of video games. It is our hope that TRUE is adopted and adapted by the broader HCI community, becoming a useful tool for gaining deep insights into user behavior and improvement of design for other complex systems.
2008	Crowdsourcing user studies with Mechanical Turk	User studies are important for many aspects of the design process and involve techniques ranging from informal surveys to rigorous laboratory studies. However, the costs involved in engaging users often requires practitioners to trade off between sample size, time requirements, and monetary costs. Micro-task markets, such as Amazon's Mechanical Turk, offer a potential paradigm for engaging a large number of users for low time and monetary costs. Here we investigate the utility of a micro-task market for collecting user measurements, and discuss design considerations for developing remote micro user evaluation tasks. Although micro-task markets have great potential for rapidly collecting user measurements at low costs, we found that special care is needed in formulating tasks in order to harness the capabilities of the approach.
2008	Aligning temporal data by sentinel events: discovering patterns in electronic health records	Electronic Health Records (EHRs) and other temporal databases contain hidden patterns that reveal important cause-and-effect phenomena. Finding these patterns is a challenge when using traditional query languages and tabular displays. We present an interactive visual tool that complements query formulation by providing operations to align, rank and filter the results, and to visualize estimates of the intervals of validity of the data. Display of patient histories aligned on sentinel events (such as a first heart attack) enables users to spot precursor, co-occurring, and aftereffect events. A controlled study demonstrates the benefits of providing alignment (with a 61\% speed improvement for complex tasks). A qualitative study and interviews with medical professionals demonstrates that the interface can be learned quickly and seems to address their needs.
2008	Celebratory technology: new directions for food research in HCI	Food is a central part of our lives. Fundamentally, we need food to survive. Socially, food is something that brings people together-individuals interact through and around it. Culturally, food practices reflect our ethnicities and nationalities. Given the importance of food in our daily lives, it is important to understand what role technology currently plays and the roles it can be imagined to play in the future. In this paper we describe the existing and potential design space for HCI in the area of human-food interaction. We present ideas for future work on designing technologies in the area of human-food interaction that celebrate the positive interactions that people have with food as they eat and prepare foods in their everyday lives.
2008	MAHI: investigation of social scaffolding for reflective thinking in diabetes management	In the recent years, the number of individuals engaged in self-care of chronic diseases has grown exponentially. Advances in computing technologies help individuals with chronic diseases collect unprecedented volumes of health-related data. However, engaging in reflective analysis of the collected data may be challenging for the untrained individuals. We present MAHI, a health monitoring application that assists newly diagnosed individuals with diabetes in acquiring and developing reflective thinking skills through social interaction with diabetes educators. The deployment study with twenty five newly diagnosed individuals with diabetes demonstrated that MAHI significantly contributed to individuals' achievement of their diabetes management goals (changing diet). More importantly, MAHI inspired individuals to adopt Internal Locus of Control, which often leads to persistent engagement in self-care and positive health outcomes.
2008	Accountabilities of presence: reframing location-based systems	How do mobility and presence feature as aspects of social life? Using a case study of paroled offenders tracked via Global Positioning System (GPS), we explore the ways that location-based technologies frame people's everyday experiences of space. In particular, we focus on how access and presence are negotiated outside of traditional conceptions of "privacy." We introduce the notion of accountabilities of presence and suggest that it is a more useful concept than "privacy" for understanding the relationship between presence and sociality.
2008	From awareness to repartee: sharing location within social groups	This paper investigates emergent practices around 'microblogging', changing and sharing status within a social group. We present results from a trial of 'Connecto', a phone based status and location sharing application that allows a group to 'tag' areas and have individuals' locations shared automatically on a mobile phone. In use the system moved beyond being an awareness tool to a way of continuing the ongoing 'story' of conversations within the group. Through sharing status and location the system supported each groups' ongoing repartee - a site for social exchange, enjoyment and friendship.
2008	Lean and zoom: proximity-aware user interface and content magnification	The size and resolution of computer displays has increased dramatically, allowing more information than ever to be rendered on-screen. However, items can now be so small or screens so cluttered that users need to lean forward to properly examine them. This behavior may be detrimental to a user's posture and eyesight. Our Lean and Zoom system detects a user's proximity to the display using a camera and magnifies the on-screen content proportionally. This alleviates dramatic leaning and makes items more readable. Results from a user study indicate people find the technique natural and intuitive. Most participants found on-screen content easier to read, and believed the technique would improve both their performance and comfort.
2008	Stirring up experience through movement in game play: effects on engagement and social behaviour	The recent development of controllers designed around natural body movements has altered the nature of gaming and contributed towards it being marketed as a more social activity. The study reported here compares the use of Donkey Konga bongos with a standard controller to examine how affording motion through an input device affects social interaction. Levels of engagement with the game were also measured to explore whether increases in social behaviour in the 'real world' would result in reduced involvement with the 'game world'. Social interaction was significantly higher when the bongos were used, but this did not detract from engagement. Instead, engagement was also found to increase when body movement was afforded.
2008	Demonstrating the feasibility of using forearm electromyography for muscle-computer interfaces	We explore the feasibility of muscle-computer interfaces (muCIs): an interaction methodology that directly senses and decodes human muscular activity rather than relying on physical device actuation or user actions that are externally visible or audible. As a first step towards realizing the mu-CI concept, we conducted an experiment to explore the potential of exploiting muscular sensing and processing technologies for muCIs. We present results demonstrating accurate gesture classification with an off-the-shelf electromyography (EMG) device. Specifically, using 10 sensors worn in a narrow band around the upper forearm, we were able to differentiate position and pressure of finger presses, as well as classify tapping and lifting gestures across all five fingers. We conclude with discussion of the implications of our results for future muCI designs.
2008	Improving eye cursor's stability for eye pointing tasks	In order to improve the stability of eye cursor, we introduce three methods, force field (FF), speed reduction (SR), and warping to target center (TC) to modulate eye cursor trajectories by counteracting eye jitter, which is the main cause of destabilizing the eye cursor. We evaluate these methods using two controlled experiments. One is an attention task experiment, which indicates that both FF and SR significantly alleviate the instability of eye cursor, but TC is not as we anticipated. The other is a 2D pointing task experiment, which shows that FF and SR as well as the improved implementation of SR (iSR) indeed improve human performance in dominant dwell-based eye pointing tasks of eye-based interactions. The method iSR is especially effective to accelerate eye pointing (10.5\% and 8.5\%) and reduce error rate (6.1\% and 2.7\%) when target diameter D = 45 and 60 pixels.
2008	Detecting the direction of listening with the emg signals measured behind ears	In this paper, we describe the design of the ear tracker. The ear tracker detects the direction to which a person is listening. We propose the technique as a new form of an input device technology, which potentially allows the user to control machines with vague intention rather than explicit commands. Our ear tracker makes the detection with the electromyogram (EMG) signals probed behind ears. We have prototyped its hardware and algorithm. In our experiment, it shows 70\% accuracy for detecting whether the testee is listening to the left or right.
2008	Predicting postcompletion errors using eye movements	A postcompletion error is a distinct type of procedural error where one fails to complete the final step of a task. While redesigning interfaces and providing explicit cues have been shown to be effective in reducing the postcompletion error rate, these methods are not always feasible or well liked. This paper demonstrates how specific eye movement measures can be used to predict when a user will make a postcompletion error. We describe a real-time eye gaze system that provides cues to the user if and only if there is a high probability of the user making a postcompletion error.
2008	A user study of policy creation in a flexible access-control system	Significant effort has been invested in developing expressive and flexible access-control languages and systems. However, little has been done to evaluate these systems in practical situations with real users, and few attempts have been made to discover and analyze the access-control policies that users actually want to implement. We report on a user study in which we derive the ideal access policies desired by a group of users for physical security in an office environment. We compare these ideal policies to the policies the users actually implemented with keys and with a smartphone-based distributed access-control system. We develop a methodology that allows us to show quantitatively that the smartphone system allowed our users to implement their ideal policies more accurately and securely than they could with keys, and we describe where each system fell short.
2008	Competence articulation: alignment of competences and responsibilities in synchronous telemedical collaboration	Many studies and concepts within CSCW deal with the temporal, spatial, social, and computational aspects of supporting collaborative work. In this paper we want to pay attention to another central aspect to the achievement of collaborative work, namely the competence of the people involved. In particular, we want to look at the dynamic quality of competences, and investigate how competence is mutually developed in coordinated work. We have termed this process competence articulation, a concept which tries to emphasize competence as well as social development of competence as part of cooperation. The concept has emerged out of a longitudinal participatory design process investigating telemedical treatment of diabetic foot ulcers using video phones. We analyze the transitions occurring with the introduction of synchronous telemedical consultations and detail how the online video facilitates communication options for competence articulation, which again improve collaboration and thus the quality of the treatment.
2008	Results from deploying a participation incentive mechanism within the enterprise	Success and sustainability of social networking sites is highly dependent on user participation. To encourage contribution to an opt-in social networking site designed for employees, we have designed and implemented a feature that rewards contribution with points. In our evaluation of the impact of the system, we found that employees are initially motivated to add more content to the site. This paper presents the analysis and design of the point system, the results of our experiment, and our insights regarding future directions derived from our post-experiment user interviews.
2008	Automatic whiteout++: correcting mini-QWERTY typing errors using keypress timing	By analyzing features of users' typing, Automatic Whiteout++ detects and corrects up to 32.37\% of the errors made by typists while using a mini-QWERTY (RIM Blackberry style) keyboard. The system targets "off-by-one" errors where the user accidentally presses a key adjacent to the one intended. Using a database of typing from longitudinal tests on two different keyboards in a variety of contexts, we show that the system generalizes well across users, model of keyboard, user expertise, and keyboard visibility conditions. Since a goal of Automatic Whiteout++ is to embed it in the firmware of mini-QWERTY keyboards, it does not rely on a dictionary. This feature enables the system to correct errors mid-word instead of applying a correction after the word has been typed. Though we do not use a dictionary, we do examine the effect of varying levels of language context in the system's ability to detect and correct erroneous keypresses.
2008	EdgeWrite with integrated corner sequence help	We describe a system that informs the users of the shape of the EdgeWrite characters within the visual feedback area of EdgeWrite. We compared two versions (static and dynamic) of this design to a printed character chart in a five-session text entry experiment with three 8-participant groups. The participants were able to use EdgeWrite with the integrated help systems. There were no statistically significant differences in text entry rate between the group using the character chart and the two groups using the integrated help. However, the group with the dynamic help was faster than the group with the static help while maintaining a low corrected error rate.
2008	Interlaced QWERTY: accommodating ease of visual search and input flexibility in shape writing	Shape writing is an input technology for touch-screen mobile phones and pen-tablets. To shape write text, the user spells out word patterns by sliding a finger or stylus over a graphical keyboard. The user's trace is then recognized by a pattern recognizer. In this paper we analyze and evaluate various keyboard layouts, including alphabetic, optimized (ATOMIK), QWERTY, and interlaced QWERTY for shape writing. The goodness of a layout for shape writing has two aspects. For users' initial ease of use the letters should be easy to visually locate. For long term use, however, the layout should maximize the imprecision tolerance and writing flexibility for all words. We present empirical studies for the former and mathematical analyses for the latter. Our results led to a new layout, interlaced QWERTY, which offers excellent separation of word shapes, while still maintaining a low visual search time. Many of the findings in our study also apply to traditional soft keyboards tapped with a stylus or one finger.
2008	Design, adoption, and assessment of a socio-technical environment supporting independence for persons with cognitive disabilities	A significant fraction of persons with cognitive disabilities are potentially able to live more independently with the use of powerful tools embedded in their social environment. The Memory Aiding Prompting System (MAPS) provides an environment in which caregivers can create scripts that can be used by people with cognitive disabilities ("clients") to support them in carrying out tasks that they would not be able to achieve by themselves. To account for the great diversity among clients, MAPS was developed as a meta-design environment, empowering the caregivers to develop personalized prompting systems for the specific needs of individual clients.
2008	Ingimp: introducing instrumentation to an end-user open source application	Open source projects are gradually incorporating usability methods into their development practices, but there are still many unmet needs. One particular need for nearly any open source project is data that describes its user base, including information indicating how the software is actually used in practice. This paper presents the concept of open instrumentation, or the augmentation of an open source application to openly collect and publicly disseminate rich application usage data. We demonstrate the concept of open instrumentation in ingimp , a version of the open source GNU Image Manipulation Program that has been modified to collect end-user usage data. ingimp automatically collects five types of data: The commands used, high-level user interface events, overall features of the user's documents, summaries of the user's general computing environment, and users' own descriptions of their planned tasks. In the spirit of open source software, all collected data are made available for anyone to download and analyze. This paper's primary contributions lie in presenting the overall design of ingimp, with a particular focus on how the design addresses two prominent issues in open instrumentation: privacy and motivating use.
2008	Testing vs. code inspection vs. what else?: male and female end users' debugging strategies	Little is known about the strategies end-user programmers use in debugging their programs, and even less is known about gender differences that may exist in these strategies. Without this type of information, designers of end-user programming systems cannot know the "target" at which to aim, if they are to support male and female end-user programmers. We present a study investigating this issue. We asked end-user programmers to debug spreadsheets and to describe their debugging strategies. Using mixed methods, we analyzed their strategies and looked for relationships among participants' strategy choices, gender, and debugging success. Our results indicate that males and females debug in quite different ways, that opportunities for improving support for end-user debugging strategies for both genders are abundant, and that tools currently available to end-user debuggers may be especially deficient in supporting debugging strategies used by females.
2008	Designs on dignity: perceptions of technology among the homeless	Technology, it is argued, has the potential to improve everyone's life: from the workplace, to entertainment, to easing chores around the home. But what of people who have neither job nor home? We undertook a qualitative study of the homeless population in a metropolitan U.S. city to better understand what it means to be homeless and how technology--from cell phones to bus passes--affects their daily lives. The themes we identify provide an array of opportunities for technological interventions that can empower the homeless population. Our investigation also reveals the need to reexamine some of the assumptions made in HCI about the relationship people have with technology. We suggest a broader awareness of the social context of technology use as a critical component when considering design innovation for the homeless.
2008	Empathy and experience in HCI	For a decade HCI researchers and practitioners have been developing methods, practices and designs 'for the full range of human experience'. On the one hand, a variety of approaches to design, such as aesthetic, affective, and ludic that emphasize particular qualities and contexts of experience and particular approaches to intervening in interactive experience have become focal. On the other, a variety of approaches to understanding users and user experience, based on narrative, biography, and role-play have been developed and deployed. These developments can be viewed in terms of one of the seminal commitments of HCI, 'to know the user'. Empathy has been used as a defining characteristic of designer-user relationships when design is concerned with user experience. In this article, we use 'empathy' to help position some emerging design and user-experience methodologies in terms of dynamically shifting relationships between designers, users, and artefacts.
2008	Interactional empowerment	We propose that an interactional perspective on how emotion is constructed, shared and experienced, may be a good basis for designing affective interactional systems that do not infringe on privacy or autonomy, but instead empowers users. An interactional design perspective may make use of design elements such as open-ended, ambiguous, yet familiar, interaction surfaces that users can use as a basis to make sense of their own emotions and their communication with one-another. We describe the interactional view on design for emotional communication, and provide a set of orienting design concepts and methods for design and evaluation that help translate the interactional view into viable applications. From an embodied interaction theory perspective, we argue for a non-dualistic, non-reductionist view on affective interaction design.
2008	Experience sampling for building predictive user models: a comparative study	Experience sampling has been employed for decades to collect assessments of subjects' intentions, needs, and affective states. In recent years, investigators have employed automated experience sampling to collect data to build predictive user models. To date, most procedures have relied on random sampling or simple heuristics. We perform a comparative analysis of several automated strategies for guiding experience sampling, spanning a spectrum of sophistication, from a random sampling procedure to increasingly sophisticated active learning. The more sophisticated methods take a decision-theoretic approach, centering on the computation of the expected value of information of a probe, weighing the cost of the short-term disruptiveness of probes with their benefits in enhancing the long-term performance of predictive models. We test the different approaches in a field study, focused on the task of learning predictive models of the cost of interruption.
2008	Investigating statistical machine learning as a tool for software development	As statistical machine learning algorithms and techniques continue to mature, many researchers and developers see statistical machine learning not only as a topic of expert study, but also as a tool for software development. Extensive prior work has studied software development, but little prior work has studied software developers applying statistical machine learning. This paper presents interviews of eleven researchers experienced in applying statistical machine learning algorithms and techniques to human-computer interaction problems, as well as a study of ten participants working during a five-hour study to apply statistical machine learning algorithms and techniques to a realistic problem. We distill three related categories of difficulties that arise in applying statistical machine learning as a tool for software development: (1) difficulty pursuing statistical machine learning as an iterative and exploratory process , (2) difficulty understanding relationships between data and the behavior of statistical machine learning algorithms, and (3) difficulty evaluating the performance of statistical machine learning algorithms and techniques in the context of applications. This paper provides important new insight into these difficulties and the need for development tools that better support the application of statistical machine learning.
2008	CiteSense: supporting sensemaking of research literature	Making sense of research literature is a complicated process that involves various information seeking and compre-hension tasks. The lack of support for sensemaking in existing systems presents important design challenges and opportunities. This research proposes the design of an integral environment to support literature search, selection, organization and comprehension. Our system prototype, CiteSense, offers lightweight interaction tools and a smooth transition among various information activities. This research deepens our understanding of the design of systems that support the sensemaking of research literature.
2008	The personal project planner: planning to organize personal information	Prototyping and evaluation combine to explore ways that an effective, integrative organization of project-related information might emerge as a by-product of a person's efforts to plan a project. The Personal Project Planner works as an extension to the file manager -- providing people with rich-text overlays to their information. Document-like project plans provide a context in which to create or reference documents, email messages, web pages, etc. that are needed to complete the plan. The user can later locate an information item such as an email message with reference to the plan (e.g., as an alternative to searching through the inbox or sent mail). Results of an interim evaluation of the Planner are very promising and suggest special directions of focus for limited available prototyping resources.
2008	CareLog: a selective archiving tool for behavior management in schools	Identifying the function of problem behavior can lead to the development of more effective interventions. One way to identify the function is through functional behavior assessment (FBA). Teachers conduct FBA in schools. However, the task load of recording the data manually is high, and the challenge of accurately identifying antecedents and consequences is significant while interacting with students. These issues often result in imperfect information capture. CareLog allows teachers more easily to conduct FBAs and enhances the capture of relevant information. In this paper, we describe the design process that led to five design principles that governed the development of CareLog. We present results from a five-month, quasi-controlled study aimed at validating those design principles. We reflect on how various constraints imposed by special education settings impact the design and evaluation process for HCI practitioners and researchers.
2008	Observing presenters' use of visual aids to inform the design of classroom presentation software	Large classrooms have traditionally provided multiple blackboards on which an entire lecture could be visible. In recent decades, classrooms were augmented with a data projector and screen, allowing computer-generated slides to replace hand-written blackboard presentations and overhead transparencies as the medium of choice. Many lecture halls and conference rooms will soon be equipped with multiple projectors that provide large, high-resolution displays of comparable size to an old fashioned array of blackboards. The predominant presentation software, however, is still designed for a single medium-resolution projector. With the ultimate goal of designing rich presentation tools that take full advantage of increased screen resolution and real estate, we conducted an observational study to examine current practice with both traditional whiteboards and blackboards, and computer-generated slides. We identify several categories of observed usage, and highlight differences between traditional media and computer slides. We then present design guidelines for presentation software that capture the advantages of the old and the new and describe a working prototype based on those guidelines that more fully utilizes the capabilities of multiple displays.
2008	Readability of scanned books in digital libraries	Displaying scanned book pages in a web browser is difficult, due to an array of characteristics of the common user's configuration that compound to yield text that is degraded and illegibly small. For books which contain only text, this can often be solved by using OCR or manual transcription to extract and present the text alone, or by magnifying the page and presenting it in a scrolling panel. Books with rich illustrations, especially children's picture books, present a greater challenge because their enjoyment is dependent on reading the text in the context of the full page with its illustrations. We have created two novel prototypes for solving this problem by magnifying just the text, without magnifying the entire page. We present the results of a user study of these techniques. Users found our prototypes to be more effective than the dominant interface type for reading this kind of material and, in some cases, even preferable to the physical book itself.
2008	Choice: abidcating or exercising?	Many people today have access to enormous libraries of digital content. Increasingly these libraries contain personal content, consumed in support of people's non-instrumental needs. If current trends persist, these repositories will only increase. Having to choose from so much could be unpleasant especially in the absence of strong preferences. This raises some concerns for user experience (UX) design. Approaches for such interactions should not only be optimized for UX but must also support users' non-instrumental needs. People face this predicament during digital music listening and yet report positive experiences when listening in shuffle. Through an empirical study of digital music listening and close examination of people's listening practices and experiences, we argue that a shuffle-based approach--whereby people can abdicate choice to a random process while being able to modulate the randomness--not only mitigates the unpleasantness of choosing but also supports their non-instrumental needs while fostering desirable experiential outcomes.
2008	MySong: automatic accompaniment generation for vocal melodies	We introduce MySong, a system that automatically chooses chords to accompany a vocal melody. A user with no musical experience can create a song with instrumental accompaniment just by singing into a microphone, and can experiment with different styles and chord patterns using interactions designed to be intuitive to non-musicians. We describe the implementation of MySong, which trains a Hidden Markov Model using a music database and uses that model to select chords for new melodies. Model parameters are intuitively exposed to the user. We present results from a study demonstrating that chords assigned to melodies using MySong and chords assigned manually by musicians receive similar subjective ratings. We then present results from a second study showing that thirteen users with no background in music theory are able to rapidly create musical accompaniments using MySong, and that these accompaniments are rated positively by evaluators.
2008	PlaceAndPlay: a digital tool for children to create and record music	We present a novel interface for young children to interact with digital music. PlaceAndPlay provides an intuitive environment for children with no music creation experience. Multimodal interaction techniques and a unique approach to music layout accommodate physical and cognitive abilities of young children. The system was evaluated in user study settings at the different designing stages and the results were positive.
2008	The sound of touch: physical manipulation of digital sound	The Sound of Touch is a new tool for real-time capture and sensitive physical stimulation of sound samples using digital convolution. Our hand-held wand can be used to (1) record sound, then (2) play back the recording by brushing, scraping, striking or otherwise physically manipulating the wand against physical objects. During playback, the recorded sound is continuously filtered by the acoustic interaction of the wand and the material being touched. The Sound of Touch enables a physical and continuous sculpting of sound that is typical of acoustic musical instruments and interactions with natural objects and materials, but not available in GUI-based tools or most electronic music instruments. This paper reports the design of the system and observations of thousands of users interacting with it in an exhibition format. Preliminary user feedback suggests future applications to foley, professional sound design, and musical performance.
2008	Asynchronous remote medical consultation for Ghana	Computer-mediated communication systems can be used to bridge the gap between doctors in underserved regions with local shortages of medical expertise and medical specialists worldwide. To this end, we describe the design of a prototype remote consultation system intended to provide the social, institutional and infrastructural context for sustained, self-organizing growth of a globally-distributed Ghanaian medical community. The design is grounded in an iterative design process that included two rounds of extended design fieldwork throughout Ghana and draws on three key design principles (social networks as a framework on which to build incentives within a self-organizing network; optional and incremental integration with existing referral mechanisms; and a weakly-connected, distributed architecture that allows for a highly interactive, responsive system despite failures in connectivity). We discuss initial experiences from an ongoing trial deployment in southern Ghana.
2008	E-imci: improving pediatric health care in low-income countries	Every year almost 10 million children die before reaching the age of five despite the fact that two-thirds of these deaths could be prevented by effective low-cost interventions. To combat this, the World Health Organization (WHO) and UNICEF developed the Integrated Management of Childhood Illness (IMCI) treatment algorithms. In Tanzania, IMCI is the national policy for the treatment of childhood illness. This paper describes e-IMCI, a system for administering the IMCI protocol using a PDA. Our preliminary investigation in rural Tanzania suggests that e-IMCI is almost as fast as the common practice and potentially improves care by increasing adherence to the IMCI protocols. Additionally, we found clinicians could quickly be trained to use e-IMCI and were very enthusiastic about using it in the future.
2008	Participant and interviewer attitudes toward handheld computers in the context of HIV/AIDS programs in sub-Saharan Africa	Handheld computers have untapped potential to improve HIV/AIDS programs in sub-Saharan Africa, particularly in the collection of survey data. We conducted an experiment in three neighborhoods of Luanda, Angola to assess the impact of the technology on people's comfort and willingness to disclose sensitive personal information, such as sexual behavior. Participants were asked about their HIV/AIDS-related knowledge, attitudes, and practices by local interviewers using either handheld computers or paper surveys. T-tests showed no differences between participants' self-reported comfort across handheld and paper conditions. However, participants in the handheld condition were more likely to give socially desirable responses to the sexual behavior questions than participants in the paper condition. These results suggest that using handheld computers in data collection in sub-Saharan Africa may lead to biased reports of HIV/AIDS-related risk behaviors.
2008	It's on my other computer!: computing with multiple devices	The number of computing devices that people use is growing. To gain a better understanding of why and how people use multiple devices, we interviewed 27 people from academia and industry. From these interviews we distill four primary findings. First, associating a user's activities with a particular device is problematic for multiple device users because many activities span multiple devices. Second, device use varies by user and circumstance; users assign different roles to devices both by choice and by constraint. Third, users in industry want to separate work and personal activities across work and personal devices, but they have difficulty doing so in practice Finally, users employ a variety of techniques for accessing information across devices, but there is room for improvement: participants reported managing information across their devices as the most challenging aspect of using multiple devices. We suggest opportunities to improve the user experience by focusing on the user rather than the applications and devices; making devices aware of their roles; and providing lighter-weight methods for transferring information, including synchronization services that engender more trust from users.
2008	Targeting across displayless space	Multi-monitor displays and multi-display environments are now common. Cross-display cursor movement, in which a user moves the pointer from one display to another, occurs frequently in these settings. There are several techniques for supporting this kind of movement, and these differ in the way that they deal with displayless space (the physical space between displays). Stitching is the method used by most operating systems; in this technique, the cursor jumps from the edge of one display directly into the next display. In contrast, Mouse Ether maps the motor space of the mouse exactly to the physical space of the displays, meaning that the cursor has to travel across displayless space until it reaches the next display. To determine which of these approaches is best for cross-display movement, we carried out a study comparing Stitching, Mouse Ether, and a variant of Mouse Ether with Halo for off-screen feedback. We found that Stitching is equivalent to or faster than any variant of Mouse Ether, and that Halo improves Ether's performance (but not enough to outperform Stitching). Results also indicate that the larger the gap between displays, the longer the targeting takes --- even for Stitching. These findings provide valuable guidance for practitioners and raise new interesting questions for research.
2008	Wedge: clutter-free visualization of off-screen locations	To overcome display limitations of small-screen devices, researchers have proposed techniques that point users to objects located off-screen. Arrow-based techniques such as City Lights convey only direction. Halo conveys direction and distance, but is susceptible to clutter resulting from overlapping halos. We present Wedge , a visualization technique that conveys direction and distance, yet avoids overlap and clutter. Wedge represents each off-screen location using an acute isosceles triangle: the tip coincides with the off-screen locations, and the two corners are located on-screen. A wedge conveys location awareness primarily by means of its two legs pointing towards the target. Wedges avoid overlap programmatically by repelling each other, causing them to rotate until overlap is resolved. As a result, wedges can be applied to numbers and configurations of targets that would lead to clutter if visualized using halos. We report on a user study comparing Wedge and Halo for three off-screen tasks. Participants were significantly more accurate when using Wedge than when using Halo.
2008	Assessing attractiveness in online dating profiles	Online dating systems play a prominent role in the social lives of millions of their users, but little research has considered how users perceive one another through their personal profiles. We examined how users perceive attractiveness in online dating profiles, which provide their first exposure to a potential partner. Participants rated whole profiles and profile components on such qualities as how attractive, extraverted, and genuine and trustworthy they appeared. As past research in the psychology of attraction would suggest, the attractiveness and other qualities of the photograph were the strongest predictors of whole profile attractiveness, but they were not alone: the free-text component also played an important role in predicting overall attractiveness. In turn, numerous other qualities predicted the attractiveness ratings of photos and free-text components, albeit in different ways for men and women. The fixed-choice elements of a profile, however, were unrelated to attractiveness.
2008	Keeping in touch by technology: maintaining friendships after a residential move	Many observers have praised new communication technologies for providing convenient and affordable tools for maintaining relationships at a distance. Yet the precise role of mediated communication in relationship maintenance has been difficult to isolate. In this paper, we treat residential moves as natural experiments that threaten existing social relationships and often force people to rely on mediated communication to maintain their old relationships. Results from a 3-wave survey of 900 residential movers describing 1892 relationships shows that email and the telephone play different roles in social relationships. Email helps maintain social relationships, in the sense that relationships decline when email drops after the move. However increases in email are not associated with increases in the depth of the relationship or exchanges of support. In contrast, phone calls help movers grow relationships and exchange social support.
2008	Friends and foes: ideological social networking	Traditional online social network sites use a single monolithic "friends" relationship to link users. However, users may have more in common with strangers, suggesting the use of a "similarity network" to recommend content. This paper examines the usefulness of this distinction in propagating new content. Using both macroscopic and microscopic social dynamics, we present an analysis of Essembly, an ideological social network that semantically distinguishes between friends and ideological allies and nemeses . Although users have greater similarity with their allies than their friends and nemeses, surprisingly, the allies network does not affect voting behavior, despite being as large as the friends network. In contrast, users are influenced differently by their friends and nemeses, indicating that people use these networks for distinct purposes. We suggest resulting design implications for social content aggregation services and recommender systems.
2008	Life scheduling to support multiple social roles	We present the results of our study of 15 working parents, and how they manage their life scheduling needs, that is, how they manage their personal and professional schedules across settings and calendaring tools. In particular, we discuss how their dual roles of parent and employee compel them to record personal information on their professional calendars and we detail the tensions that arise in doing so. Finally, we present suggestions for future calendaring applications that better support working parents in managing their life scheduling needs.
2008	Collaborating to remember: a distributed cognition account of families coping with memory impairments	Individuals with cognitive deficits and their families are prime examples of collaborative "systems" that seek to perform everyday tasks together. Yet there has been little investigation into how these families communicate and coordinate in basic tasks like remembering appointments. In this paper we take a distributed cognition approach to studying ten families struggling with amnesia through nonparticipant observation and interviews. Our data show that the families work closely together as cognitive systems that must compensate for memory volatility in one of the members. We explore our participants' strategies for overcoming these difficulties and present lessons for the design of assistive technologies, highlighting the need for redundancy, easy and frequent synchronization, and awareness of updates. We conclude with implications for distributed cognition theory.
2008	Feasibility and pragmatics of classifying working memory load with an electroencephalograph	A reliable and unobtrusive measurement of working memory load could be used to evaluate the efficacy of interfaces and to provide real-time user-state information to adaptive systems. In this paper, we describe an experiment we con-ducted to explore some of the issues around using an elec-troencephalograph (EEG) for classifying working memory load. Within this experiment, we present our classification methodology, including a novel feature selection scheme that seems to alleviate the need for complex drift modeling and artifact rejection. We demonstrate classification accuracies of up to 99\% for 2 memory load levels and up to 88\% for 4 levels. We also present results suggesting that we can do this with shorter windows, much less training data, and a smaller number of EEG channels, than reported previously. Finally, we show results suggesting that the models we construct transfer across variants of the task, implying some level of generality. We believe these findings extend prior work and bring us a step closer to the use of such technologies in HCI research.
2008	Human-aided computing: utilizing implicit human processing to classify images	In this paper, we present Human-Aided Computing, an approach that uses an electroencephalograph (EEG) device to measure the presence and outcomes of implicit cognitive processing, processing that users perform automatically and may not even be aware of. We describe a classification system and present results from two experiments as proof-of-concept. Results from the first experiment showed that our system could classify whether a user was looking at an image of a face or not, even when the user was not explicitly trying to make this determination. Results from the second experiment extended this to animals and inanimate object categories as well, suggesting generality beyond face recognition. We further show that we can improve classification accuracies if we show images multiple times, potentially to multiple people, attaining well above 90\% classification accuracies with even just ten presentations.
2008	Framing the user experience: information biases on website quality judgement	Understanding the complexities of users' judgements and user experience is a prerequisite for informing HCI design. Current user experience (UX) research emphasises that, beyond usability, non-instrumental aspects of system quality contribute to overall judgement and that the user experience is subjective and variable. Based on judgement and decision-making theory, we have previously demonstrated that judgement of websites can be influenced by contextual factors. This paper explores the strength of such contextual influence by investigating framing effects on user judgement of website quality. Two experimental studies investigate how the presentation of information about a website influences the user experience and the relative importance of individual quality attributes for overall judgement. Theoretical implications for the emerging field of UX research and practical implications for design are discussed.
2008	Predictors of answer quality in online Q&A sites	Question and answer (Q&A) sites such as Yahoo! Answers are places where users ask questions and others answer them. In this paper, we investigate predictors of answer quality through a comparative, controlled field study of responses provided across several online Q&A sites. Along with several quantitative results concerning the effects of factors such as question topic and rhetorical strategy, we present two high-level messages. First, you get what you pay for in Q&A sites. Answer quality was typically higher in Google Answers (a fee-based site) than in the free sites we studied, and paying more money for an answer led to better outcomes. Second, we find that a Q&A site's community of users contributes to its success. Yahoo! Answers, a Q&A site where anybody can answer questions, outperformed sites that depend on specific individuals to answer questions, such as library reference services.
2008	AutoCardSorter: designing the information architecture of a web site using latent semantic analysis	In this paper, we describe an innovative tool that supports the design and evaluation of the information architecture of a Web site. The tool uses Latent Semantic Analysis and hierarchical clustering algorithms to provide optimal information navigation schemes in an automated manner. The proposed, tool-based, approach addresses the problem of reasonable content structuring, which established techniques such as card sorting also address. A real world case study depicted substantial effectiveness gain, without expense in the quality of results. We argue that such an approach could facilitate information-rich applications design, like most Web sites, by reducing time and resources required.
2008	Designing for bystanders: reflections on building a public digital forum	In this paper, we reflect on the design and deployment process of MAGICBoard, a public display deployed in a university setting that solicits the electronic votes and opinions of bystanders on trivial but amusing topics. We focus on the consequences of our design choices with respect to encouraging bystanders to interact with the public display. Bystanders are individuals around the large display who may never fully engage with the application itself, but are potential contributors to the system. Drawing on our recent experiences with MAGICBoard, we present a classification of bystanders , and then discuss three design themes relevant to the design of systems for bystander use: graduated proximal engagement, lowering barriers for interaction and supporting covert engagement .
2008	Electronic voting machines versus traditional methods: improved preference, similar performance	In the 2006 U.S. election, it was estimated that over 66 million people would be voting on direct recording electronic (DRE) systems in 34\% of the nation's counties [8]. Although these computer-based voting systems have been widely adopted, they have not been empirically proven to be more usable than their predecessors. The series of studies reported here compares usability data from a DRE with those from more traditional voting technologies (paper ballots, punch cards, and lever machines). Results indicate that there were little differences between the DRE and these older methods in efficiency or effectiveness. However, in terms of user satisfaction, the DRE was significantly better than the older methods. Paper ballots also perform well, but participants were much more satisfied with their experiences voting on the DRE. The disconnect between subjective and objective usability has potential policy ramifications.
2008	Introducing item response theory for measuring usability inspection processes	Usability evaluation methods have a long history of research. Latest contributions significantly raised the validity of method evaluation studies. But there is still a measurement model lacking that incorporates the relevant factors for inspection performance and accounts for the probabilistic nature of the process. This paper transfers a modern probabilistic approach from psychometric research, known as the Item Response Theory, to the domain of measuring usability evaluation processes. The basic concepts, assumptions and several advanced procedures are introduced and related to the domain of usability inspection. The practical use of the approach is exemplified in three scenarios from research and practice. These are also made available as simulation programs.
2008	Making use of business goals in usability evaluation: an experiment with novice evaluators	The utility and impact of a usability evaluation depend on how well its results align with the business goals of the system under evaluation. However, how to achieve such alignment is not well understood. We propose a simple technique that requires active consideration of a system's business goals in planning and reporting evaluations. The technique is tested in an experiment with 44 novice evaluators using think aloud testing. The evaluators considering business goals report fewer usability problems compared to evaluators that did not use the technique. The company commissioning the evaluation, however, assesses those problems 30-42\% higher on four dimensions of utility. We discuss how the findings may generalize to usability professionals, and how the technique may be used in realistic usability evaluations. More generally, we discuss how our results illustrate one of a variety of ways in which business goals and other facets of a system's context may enter into usability evaluations.
2008	Evaluating visual cues for window switching on large screens	An increasing number of users are adopting large, multi-monitor displays. The resulting setups cover such a broad viewing angle that users can no longer simultaneously perceive all parts of the screen. Changes outside the user's visual field often go unnoticed. As a result, users sometimes have trouble locating the active window, for example after switching focus. This paper surveys graphical cues designed to direct visual attention and adapts them to window switching. Visual cues include five types of frames and mask around the target window and four trails leading to the window. We report the results of two user studies. The first evaluates each cue in isolation. The second evaluates hybrid techniques created by combining the most successful candidates from the first study. The best cues were visually sparse --- combinations of curved frames which use color to pop-out and tapered trails with predictable origin.
2008	Impromptu: a new interaction framework for supporting collaboration in multiple display environments and its field evaluation for co-located software development	We present a new interaction framework for collaborating in multiple display environments (MDEs) and report results from a field study investigating its use in an authentic work setting. Our interaction framework, IMPROMPTU, allows users to share task information across displays via off-the-shelf applications, to jointly interact with information for focused problem solving and to place information on shared displays for discussion and reflection. Our framework also includes a lightweight interface for performing these and related actions. A three week field study of our framework was conducted in the domain of face-to-face group software development. Results show that teams utilized almost every feature of the framework in support of a wide range of development-related activities. The framework was used most to facilitate opportunistic collaboration involving task information. Teams reported wanting to continue using the framework as they found value in it overall.
2008	Ninja cursors: using multiple cursors to assist target acquisition on large screens	We propose the "ninja cursor" to improve the performance of target acquisition, particularly on large screens. This technique uses multiple distributed cursors to reduce the average distance to targets. Each cursor moves synchronously following mouse movement. We present the design and implementation of the proposed technique, including a method to resolve the ambiguity that results when multiple cursors indicate different targets simultaneously. We also conducted an experiment to assess the performance of the ninja cursor. The results indicate that it can generally reduce movement time. However, the performance is greatly affected by the number of cursors and target density. Based on these results, we discuss how our technique can be put into practical use. In addition to presenting a novel method to improve pointing performance, our study is the first to explore a variable number of cursors for performing pointing tasks.
2008	Generalized selection via interactive query relaxation	Selection is a fundamental task in interactive applications, typically performed by clicking or lassoing items of interest. However, users may require more nuanced forms of selection. Selecting regions or attributes may be more important than selecting individual items. Selections may be over dynamic items and selections might be more easily created by relaxing simpler selections (e.g., "select all items like this one"). Creating such selections requires that interfaces model the declarative structure of the selection, not just individually selected items. We present direct manipulation techniques that couple declarative selection queries with a query relaxation engine that enables users to interactively generalize their selections. We apply our selection techniques in both information visualization and graphics editing applications, enabling generalized selection over both static and dynamic interface objects. A controlled study finds that users create more accurate selection queries when using our generalization techniques.
2008	Implicit user-adaptive system engagement in speech and pen interfaces	As emphasis is placed on developing mobile, educational, and other applications that minimize cognitive load on users, it is becoming more essential to explore interfaces based on implicit engagement techniques so users can remain focused on their tasks. In this research, data were collected with 12 pairs of students who solved complex math problems using a tutorial system that they engaged over 100 times per session entirely implicitly via speech amplitude or pen pressure cues. Results revealed that users spontaneously, reliably, and substantially adapted these forms of communicative energy to designate and repair an intended interlocutor in a computer-mediated group setting. Furthermore, this behavior was harnessed to achieve system engagement accuracies of 75-86\%, with accuracies highest using speech amplitude. However, students had limited awareness of their own adaptations. Finally, while continually using these implicit engagement techniques, students maintained their performance level at solving complex mathematics problems throughout a one-hour session.
2008	Mixed-initiative dialog management for speech-based interaction with graphical user interfaces	Controlling graphical user interfaces (GUI) by speech is slow, but proves useful for disabled persons with limitations in operating mouse and keyboard. We present conversation-and-control, a new approach for using speech as input modality for GUIs, which facilitates direct manipulation of widget functions by spoken commands. Our approach is based on a command language, which provides a unique command for each specific widget function. For managing the interaction we propose a mixed-initiative dialog model, which can be generated from widget properties. Using heuristics for inferring the meaning of a recognition result and having the ability to ask clarification questions, our approach avoids the rejection of recognition errors. We hypothesized that conversation-and-control allows for shorter task completion times than conventional command-and-control approaches, due to a reduction of the average number of required commands. The results of a user experiment, which we present and discuss, indicate a 16.8\% reduction of task completion time achieved by our approach.
2008	Augmented information assimilation: social and algorithmic web aids for the information long tail	To understand how and why individuals make use of emerging information assimilation services on the Web as part of their daily routine, we combined video recordings of online activity with targeted interviews of eleven experienced web users. From these observations, we describe their choice of systems, the goals they are trying to achieve, their information diets, the basic process they use for assimilating information, and the impact of user interface speed.
2008	What to do when search fails: finding information by association	Sometimes people cannot remember the names or locations of things on their computer, but they can remember what other things are associated with them. We created Feldspar, the first system that fully supports this associative retrieval of personal information on the computer. Feldspar's contributions include (1) an intuitive user interface that allows users to find information by interactively and incrementally specifying multiple levels of associations as retrieval queries, such as: "find the file from the person who I met at an event in May "; and (2) algorithms for collecting the association information and for providing answers to associative queries in real-time. A user study showed that Feldspar is easy to use, and suggested that it might be faster than conventional browsing and searching for these kinds of retrieval tasks. Feldspar could be an important addition to search and browsing tools.
2008	Conversation pivots and double pivots	Many sites on the web offer collaborative databases that catalog items such as bands, events, products, or software modules. Conversation pivots allow readers to navigate from pages about these items to conversations about them on the same site or elsewhere on the Internet. Double pivots allow readers to navigate from item pages to pages about other items mentioned in the same conversations. Using text mining techniques specific to the collection it is possible to find references to collected items in online conversations. We implemented conversation pivots for the CPAN archive of Perl modules, and for Drupal.org, the reference site for the Drupal content management system.
2008	Query suggestions for mobile search: understanding usage patterns	Entering search terms on mobile phones is a time consuming and cumbersome task. In this paper, we explore the usage patterns of query entry interfaces that display suggestions. Our primary goal is to build a usage model of query suggestions in order to provide user interface guidelines for mobile text prediction interfaces. We find that users who were asked to enter queries on a search interface with query suggestions rated their workload lower and their enjoyment higher. They also saved, on average, approximately half of the key presses compared to users who were not shown suggestions, despite no associated decrease in time to enter a query. Surprisingly, users also accepted suggestions when the process of doing so resulted in an increase in the number of total key presses.
2008	Harvesting with SONAR: the value of aggregating social network information	Web 2.0 gives people a substantial role in content and metadata creation. New interpersonal connections are formed and existing connections become evident through Web 2.0 services. This newly created social network (SN) spans across multiple services and aggregating it could bring great value. In this work we present SONAR, an API for gathering and sharing SN information. We give a detailed description of SONAR, demonstrate its potential value through user scenarios, and show results from experiments we conducted with a SONAR-based social networking application. These suggest that aggregating SN information across diverse data sources enriches the SN picture and makes it more complete and useful for the end user.
2008	Looking at, looking up or keeping up with people?: motives and use of facebook	This paper investigates the uses of social networking site Facebook, and the gratifications users derive from those uses. In the first study, 137 users generated words or phrases to describe how they used Facebook, and what they enjoyed about their use. These phrases were coded into 46 items which were completed by 241 Facebook users in Study 2. Factor analysis identified seven unique uses and gratifications: social connection, shared identities, content, social investigation, social network surfing and status updating. User demographics, site visit patterns and the use of privacy settings were associated with different uses and gratifications.
2008	Lifting the veil: improving accountability and social transparency in Wikipedia with wikidashboard	Wikis are collaborative systems in which virtually anyone can edit anything. Although wikis have become highly popular in many domains, their mutable nature often leads them to be distrusted as a reliable source of information. Here we describe a social dynamic analysis tool called WikiDashboard which aims to improve social transparency and accountability on Wikipedia articles. Early reactions from users suggest that the increased transparency afforded by the tool can improve the interpretation, communication, and trustworthiness of Wikipedia articles.
2008	Social tagging roles: publishers, evangelists, leaders	Social tagging systems provide users with the opportunity to employ tags in a communicative manner. To explore the use of tags for communication in these systems, we report results from 33 user interviews and employ the concept of social roles to describe audience-oriented tagging, including roles of community-seeker, community-builder, evangelist, publisher, and team-leader. These roles contribute to our understanding of the motivations and rationales behind social tagging in an international company, and suggest new features and services to support social software in the enterprise.
2008	Sesame: informing user security decisions with system visualization	Non-expert users face a dilemma when making security decisions. Their security often cannot be fully automated for them, yet they generally lack both the motivation and technical knowledge to make informed security decisions on their own. To help users with this dilemma, we present a novel security user interface called Sesame. Sesame uses a concrete, spatial extension of the desktop metaphor to provide users with the security-related, visualized system-level information they need to make more informed decisions. It also provides users with actionable controls to affect a system's security state. Sesame graphically facilitates users' comprehension in making these decisions, and in doing so helps to lower the bar for motivating them to participate in the security of their system. In a controlled study, users with Sesame were found to make fewer errors than a control group which suggests that our novel security interface is a viable alternative approach to helping users with their dilemma.
2008	Talc: using desktop graffiti to fight software vulnerability	With the proliferation of computer security threats on the Internet, especially threats such as worms that automatically exploit software flaws, it is becoming more and more important that home users keep their computers secure from known software vulnerabilities. Unfortunately, keeping software up-to-date is notoriously difficult for home users. This paper introduces TALC, a system to encourage and help home users patch vulnerable software. TALC increases home users' awareness of software vulnerabilities and their motivation to patch their software; it does so by detecting unpatched software and then drawing graffiti on their computer's background wallpaper image to denote potential vulnerabilities. Users can "clean up" the graffiti by applying necessary patches, which TALC makes possible by assisting in the software patching process
2008	You've been warned: an empirical study of the effectiveness of web browser phishing warnings	Many popular web browsers are now including active phishing warnings after previous research has shown that passive warnings are often ignored. In this laboratory study we examine the effectiveness of these warnings and examine if, how, and why they fail users. We simulated a spear phishing attack to expose users to browser warnings. We found that 97\% of our sixty participants fell for at least one of the phishing messages that we sent them. However, we also found that when presented with the active warnings, 79\% of participants heeded them, which was not the case for the passive warning that we tested---where only one participant heeded the warnings. Using a model from the warning sciences we analyzed how users perceive warning messages and offer suggestions for creating more effective warning messages within the phishing context.
2008	The adaptation of visual search strategy to expected information gain	An important question for HCI is to understand how and why visual search strategy is adapted to the demands imposed by the task of searching the results of a search engine. There is emerging evidence that a key part of the answer concerns the expected information gain of each of the set of available information gathering actions. We build on previous research to show that people are acutely sensitive to differences in the spacing and in the number of items returned by the search engine. These factors cause shifts in the efficiency of the available information gathering actions. We focus on an image browsing task, and show that, as a consequence of changes to the efficiency of available actions, people make small but significant changes to eye-movement strategy.
2008	PeerChooser: visual interactive recommendation	Collaborative filtering (CF) has been successfully deployed over the years to compute predictions on items based on a user's correlation with a set of peers. The black-box nature of most CF applications leave the user wondering how the system arrived at its recommendation. This note introduces PeerChooser , a collaborative recommender system with an interactive graphical explanation interface . Users are provided with a visual explanation of the CF process and opportunity to manipulate their neighborhood at varying levels of granularity to reflect aspects of their current requirements. In this manner we overcome the problem of redundant profile information in CF systems, in addition to providing an explanation interface. Our layout algorithm produces an exact, noiseless graph representation of the underlying correlations between users. PeerChooser's prediction component uses this graph directly to yield the same results as the benchmark. User's then improve on these predictions by tweaking the graph to their current requirements. We present a user-survey in which PeerChooser compares favorably against a benchmark CF algorithm.
2008	Pick me!: link selection in expertise search results	Expertise locator systems have been designed to help find experts within organizations. While there are many examples of these systems in the literature, there has not been any systematic analysis of the factors that predict whether a particular expertise search result will be selected for further exploration. This paper describes a study of 67 employees from 21 countries that performed a specific expertise search to find an expert using an expertise locator system. Rank order and social connection information displayed in snippets of search results were found to significantly predict whether a user considers a particular search result for further exploration. Implications for the design of expertise location systems and future research directions are discussed.
2008	Searching for expertise	It is well established that there is a need to find experts to get answers or advice. A variety of expertise locator tools have emerged to help locate the right person. But there is little systematic study on what people are really looking for when such systems are used and how external factors such as job role may shape that search. We conducted a study of 75 employees who were current users of an expertise locator system. An analysis of the reasons for their search revealed that people in client facing roles are primarily seeking to have a dialog with an expert, while others are just as likely to seek answers to technical questions. We also surveyed various tools for finding experts and found that corporate directories and personal networks were most often cited as alternatives to an expertise locator. We discuss the implications of these results for the design of tools for finding experts and expert knowledge.
2008	What drives content tagging: the case of photos on Flickr	We examine tagging behavior on Flickr, a public photo-sharing website. We build on previous qualitative research that exposed a taxonomy of tagging motivations, as well as on social presence research. The motivation taxonomy suggests that motivations for tagging are tied to the intended target audience of the tags --- the users themselves, family and friends, or the general public. Using multiple data sources, including a survey and independent system data, we examine which motivations are associated with tagging level, and estimate the magnitude of their contribution. We find that the levels of the Self and Public motivations, together with social presence indicators, are positively correlated with tagging level; Family & Friends motivations are not significantly correlated with tagging. The findings and the use of survey method carry implications for designers of tagging and other social systems on the web.
2008	Don't look now, but we've created a bureaucracy: the nature and roles of policies and rules in wikipedia	Wikis are sites that support the development of emergent, collective infrastructures that are highly flexible and open, suggesting that the systems that use them will be egalitarian, free, and unstructured. Yet it is apparent that the flexible infrastructure of wikis allows the development and deployment of a wide range of structures. However, we find that the policies in Wikipedia and the systems and mechanisms that operate around them are multi-faceted. In this descriptive study, we draw on prior work on rules and policies in organizations to propose and apply a conceptual framework for understanding the natures and roles of policies in wikis. We conclude that wikis are capable of supporting a broader range of structures and activities than other collaborative platforms. Wikis allow for and, in fact, facilitate the creation of policies that serve a wide variety of functions.
2008	Exploring the role of the reader in the activity of blogging	Within the last decade, blogs have become an important element of popular culture, mass media, and the daily lives of countless Internet users. Despite the medium's interactive nature, most research on blogs focuses on either the blog itself or the blogger, rarely if at all focusing on the reader's impact. In order to gain a better understanding of the social practice of blogging, we must take into account the role, contributions, and significance of the reader. This paper presents the findings of a qualitative study of blog readers, including common blog reading practices, some of the dimensions along which reading practices vary, relationships between identity presentation and perception, the interpretation of temporality, and the ways in which readers feel that they are a part of the blogs they read. It also describes similarities to, and discrepancies with, previous work, and suggests a number of directions and implications for future work on blogging.
2008	Emotion rating from short blog texts	Being able to automatically perceive a variety of emotions from text alone has potentially important applications in CMC and HCI that range from identifying mood from online posts to enabling dynamically adaptive interfaces. However, such ability has not been proven in human raters or computational systems. Here we examine the ability of naive raters of emotion to detect one of eight emotional categories from 50 and 200 word samples of real blog text. Using expert raters as a 'gold standard', naive-expert rater agreement increased with longer texts, and was high for ratings of joy, disgust, anger and anticipation, but low for acceptance and 'neutral' texts. We discuss these findings in light of theories of CMC and potential applications in HCI.
2008	Word usage and posting behaviors: modeling blogs with unobtrusive data collection methods	We present a large-scale analysis of the content of weblogs dating back to the release of the Blogger program in 1999. Over one million blogs were analyzed from their conception through June 2006. These data was submitted to the Text Analysis: Word Counts program [12], which conducted a word-count analysis using Linguistic Inquiry and Word Counts (LIWC) dictionaries [20] to provide and analyze a representative sample of blogger word usage. Covariation among LIWC dictionaries suggests that blogs vary along five psychologically relevant linguistic dimensions: Melancholy, Socialness, Ranting, Metaphysicality, and Work-Relatedness. These variables and others were subjected to a cluster analysis in an attempt to extract natural usage groups to inform design of blogging systems, the results of which were mixed.
2008	Topobo in the wild: longitudinal evaluations of educators appropriating a tangible interface	What issues arise when designing and deploying tangibles for learning in long term evaluations? This paper reports on a series of studies in which the Topobo system, a 3D tangible construction kit with the ability to record and playback motion, was provided to educators and designers to use over extended periods of time in the context of their day-to-day work. Tangibles for learning - like all educational materials - must be evaluated in relation both to the student and the teacher, but most studies of tangibles for learning focus on the student as user. Here, we focus on the conception of the educator, and their use of the tangible interface in the absence of an inventor or HCI researcher. The results of this study identify design and pedagogical issues that arise in response to distribution of a tangible for learning in different educational environments.
2008	You can touch, but you can't look: interacting with in-vehicle systems	Car drivers are nowadays offered a wide array of in-vehicle systems i.e. route guidance systems, climate controls, music players. Such in-vehicle systems often require the driver's visual attention, but visual workload has shown significant less eyes-on-the-road time and affects driving performance. In this paper, we illustrate and compare three different interaction techniques for in-vehicle systems. We refer to them as tactile, touch, and gesture interaction. The focus of the techniques is the effects on drivers while driving cars. We evaluated the interaction techniques with 16 subjects in two settings. Our results showed that gesture interaction has a significant effect on the number of driver eye glances especially eye fixations of more seconds. However, gesture interaction still required rapid eye glances for hand/eye coordination. On the other hand, touch interaction leads to fast and efficient task completion while tactile interaction seemed inferior to the two other interaction techniques.
2008	Touchers and mousers: commonalities and differences in co-located collaboration with multiple input devices	We present new findings on commonalities and differences between touch and mouse input for co-located interaction between teams of two people who know each other. Twenty-two participants were instructed to work as co-located pairs on three sets of two concurrent digital jigsaw puzzles, displayed on a horizontal tabletop that allows for multiple concurrent input devices. They were advised to use their preference for, or any combination of, direct (touch) and indirect (mouse) input device to achieve the goal. We increased the task?s difficulty: In the second and third puzzle task, participants had to discover that pieces were mixed up between the two puzzle stacks. We used this 'hidden task' to trigger spontaneous transitions from individual to collaborative work. Based on a qualitative analysis of individual interaction trajectories of direct and indirect input devices, we discuss patterns of collaboration. This furthers scientific understanding of co-located collaboration with multiple input devices.
2008	Information distance and orientation in liquid layout	Liquid layout of web browser elements enables enterprise applications to adapt to larger windows on larger displays, but guidelines are needed to define layout rules for widescreen page content. The present study considers the impact of relative portlet distance and orientation in enterprise-type tasks. Eighteen analysts completed tasks in which critical information was located in two portlets separated by defined distances and orientations. Analysis of completion times, assists, errors, and subjective scales revealed a significant advantage for wider, horizontal information layouts over narrower, vertical layouts. The difference persisted, even when accounting for the influence of vertical scrolling. Horizontal layout in these dashboard-style tasks had a 5\%-25\% time savings over vertical layout, as separation distances increased to 2000 pixels. Differences in horizontal and vertical eye movement accuracy and velocity could account for these results. Widescreen design guidelines should include a preference for horizontal layout as horizontal screen distances increase.
2008	Activity-based serendipitous recommendations with the Magitti mobile leisure guide	This paper presents a context-aware mobile recommender system, codenamed Magitti . Magitti is unique in that it infers user activity from context and patterns of user behavior and, without its user having to issue a query, automatically generates recommendations for content matching. Extensive field studies of leisure time practices in an urban setting (Tokyo) motivated the idea, shaped the details of its design and provided data describing typical behavior patterns. The paper describes the fieldwork, user interface, system components and functionality, and an evaluation of the Magitti prototype.
2008	Performing thrill: designing telemetry systems and spectator interfaces for amusement rides	Fairground: Thrill Laboratory was a series of live events that augmented the experience of amusement rides. A wearable telemetry system captured video, audio, heart-rate and acceleration data, streaming them live to spectator interfaces and a watching audience. In this paper, we present a study of this event, which draws on video recordings and post-event interviews, and which highlights the experiences of riders, spectators and ride operators. Our study shows how the telemetry system transformed riders into performers, spectators into an audience, and how the role of ride operator began to include aspects of orchestration, with the relationship between all three roles also transformed. Critically, the introduction of a telemetry system seems to have had the potential to re-connect riders/performers back to operators/orchestrators and spectators/audience, re-introducing a closer relationship that used to be available with smaller rides. Introducing telemetry to a real-world situation also creates significant complexity, which we illustrate by focussing on a moment of perceived crisis.
2008	Understanding geocaching practices and motivations	Geocaching is a location-based activity that has been practiced for a number of years. As a sustained and established activity it represents an important opportunity for understanding everyday practices and motivations that can build up around a location-based activity. We present findings from a field study of everyday geocaching behaviour. In contrast to previous work, we take a broad perspective on the activity focussing beyond the in situ consumption of these experiences. We look too at the practices and motivations surrounding participants' creation of these experiences. Further we examine these behaviours within the social context of the on-line community that provides a significant basis for many of these behaviours. We use the findings to discuss broader implications for the design of future location-based experiences
2008	Large scale analysis of web revisitation patterns	Our work examines Web revisitation patterns. Everybody revisits Web pages, but their reasons for doing so can differ depending on the particular Web page, their topic of interest, and their intent. To characterize how people revisit Web content, we analyzed five weeks of Web interaction logs of over 612,000 users. We supplemented these findings by a survey intended to identify the intent behind the observed revisitation. Our analysis reveals four primary revisitation patterns, each with unique behavioral, content, and structural characteristics. Through our analysis we illustrate how understanding revisitation patterns can enable Web sites to provide improved navigation, Web browsers to predict users' destinations, and search engines to better support fast, fresh, and effective finding and re-finding.
2008	SearchBar: a search-centric web history for task resumption and information re-finding	Current user interfaces for Web search, including browsers and search engine sites, typically treat search as a transient activity. However, people often conduct complex, multi-query investigations that may span long durations and may be interrupted by other tasks. In this paper, we first present the results of a survey of users' search habits, which show that many search tasks span long periods of time. We then introduce SearchBar, a system for proactively and persistently storing query histories, browsing histories, and users' notes and ratings in an interrelated fashion. SearchBar supports multi-session investigations by assisting with task context resumption and information re-finding. We describe a user study comparing use of SearchBar to status-quo tools such as browser histories, and discuss our findings, which show that users find SearchBar valuable for task reacquisition. Our study also reveals the strategies employed by users of status-quo tools for handling multi-query, multi-session search tasks.
2008	Exploring multi-session web tasks	Users are now performing more sophisticated web tasks. In this work, we explore web tasks that require multiple web sessions to complete (multi-session tasks) to satisfy a goal. We conducted a web-based diary study and a field study that used a customized version of Firefox which logged the participants' interactions for multi-session tasks and all their web activity. We found that multi-session tasks occur frequently and that users utilize a variety of browser tools and actions to help complete these tasks.
2008	An exploratory study of visual information analysis	To design information visualization tools for collaborative use, we need to understand how teams engage with visualizations during their information analysis process. We report on an exploratory study of individuals, pairs, and triples engaged in information analysis tasks using paper-based visualizations. From our study results, we derive a framework that captures the analysis activities of co-located teams and individuals. Comparing this framework with existing models of the information analysis process suggests that information visualization tools may benefit from providing a flexible temporal flow of analysis actions.
2008	Do visualizations improve synchronous remote collaboration?	Information visualizations can improve collaborative problem solving, but this improvement may depend on whether visualizations promote communication. In an experiment on the effect of network visualizations, remote pairs worked synchronously to identify a serial killer. They discussed disparate evidence distributed across the pair using IM. Four conditions, respectively, offered (a) spreadsheet only (controls), (b) individual unshared visualizations, (c) view-only shared visualizations, and (d) a full-access shared visualization of all evidence. We examined collaborative performance, use of the visualization tool, and communication as a function of condition. All visualization conditions improved remote collaborators' performance over the control condition. Full access to a shared visualization best facilitated remote collaboration by encouraging tool use and fostering discussion between the partners. Shared visualization without full access impaired performance somewhat and made communication even more vital to identifying the serial killer. This study provides direct evidence of visualization tool features and partner behavior that promote collaboration.
2008	Supporting the analytical reasoning process in information visualization	This paper presents a new information visualization framework that supports the analytical reasoning process. It consists of three views - a data view, a knowledge view and a navigation view. The data view offers interactive information visualization tools. The knowledge view enables the analyst to record analysis artifacts such as findings, hypotheses and so on. The navigation view provides an overview of the exploration process by capturing the visualization states automatically. An analysis artifact recorded in the knowledge view can be linked to a visualization state in the navigation view. The analyst can revisit a visualization state from both the navigation and knowledge views to review the analysis and reuse it to look for alternate views. The whole analysis process can be saved along with the synthesized information. We present a user study and discuss the perceived usefulness of a prototype based on this framework that we have developed.
2008	Impact of screen size on performance, awareness, and user satisfaction with adaptive graphical user interfaces	Adaptive personalization, where the system adapts the interface to a user's needs, has the potential for significant performance benefits on small screen devices. However, research on adaptive interfaces has almost exclusively focused on desktop displays. To explore how well previous findings generalize to small screen devices, we conducted a study with 36 subjects to compare adaptive interfaces for small and desktop-sized screens. Results show that high accuracy adaptive menus have an even larger positive impact on performance and satisfaction when screen real estate is constrained. The drawback of the high accuracy menus, however, is that they reduce the user's awareness of the full set of items in the interface, potentially making it more difficult for users to learn about new features.
2008	Improving the performance of motor-impaired users with automatically-generated, ability-based interfaces	We evaluate two systems for automatically generating personalized interfaces adapted to the individual motor capabilities of users with motor impairments. The first system, SUPPLE, adapts to users' capabilities indirectly by first using the ARNAULD preference elicitation engine to model a user's preferences regarding how he or she likes the interfaces to be created. The second system, SUPPLE++, models a user's motor abilities directly from a set of one-time motor performance tests. In a study comparing these approaches to baseline interfaces, participants with motor impairments were 26.4\% faster using ability-based user interfaces generated by SUPPLE++. They also made 73\% fewer errors, strongly preferred those interfaces to the manufacturers' defaults, and found them more efficient, easier to use, and much less physically tiring. These findings indicate that rather than requiring some users with motor impairments to adapt themselves to software using separate assistive technologies, software can now adapt itself to the capabilities of its users.
2008	Evaluation of a role-based approach for customizing a complex development environment	Coarse-grained approaches to customization allow the user to enable or disable groups of features at once, rather than individual features. While this may reduce the complexity of customization and encourage more users to customize, the research challenges of designing such approaches have not been fully explored. To address this limitation, we conducted an interview study with 14 professional software developers who use an integrated development environment that provides a role-based, coarse-grained approach to customization. We identify challenges of designing coarse-grained customization models, including issues of functionality partitioning, presentation, and individual differences. These findings highlight potentially critical design choices, and provide direction for future work.
2008	Predictability and accuracy in adaptive user interfaces	While proponents of adaptive user interfaces tout potential performance gains, critics argue that adaptation's unpredictability may disorient users, causing more harm than good. We present a study that examines the relative effects of predictability and accuracy on the usability of adaptive UIs. Our results show that increasing predictability and accuracy led to strongly improved satisfaction. Increasing accuracy also resulted in improved performance and higher utilization of the adaptive interface. Contrary to our expectations, improvement in accuracy had a stronger effect on performance, utilization and some satisfaction ratings than the improvement in predictability.
2008	Indirect mappings of multi-touch input using one and two hands	Touchpad and touchscreen interaction using multiple fingers is emerging as a valuable form of high-degree-of-freedom input. While bimanual interaction has been extensively studied, touchpad interaction using multiple fingers of the same hand is not yet well understood. We describe two experiments on user perception and control of multi-touch interaction using one and two hands. The first experiment addresses how to maintain perceptual-motor compatibility in multi-touch interaction, while the second measures the separability of control of degrees-of-freedom in the hands and fingers. Results indicate that two-touch interaction using two hands is compatible with control of two points, while twotouch interaction using one hand is compatible with control of a position, orientation, and hand-span. A slight advantage is found for two hands in separating the control of two positions.
2008	It's Mine, Don't Touch!: interactions at a large multi-touch display in a city centre	We present data from detailed observations of CityWall, a large multi-touch display installed in a central location in Helsinki, Finland. During eight days of installation, 1199 persons interacted with the system in various social configurations. Videos of these encounters were examined qualitatively as well as quantitatively based on human coding of events. The data convey phenomena that arise uniquely in public use: crowding, massively parallel interaction, teamwork, games, negotiations of transitions and handovers, conflict management, gestures and overt remarks to co-present people, and "marking" the display for others. We analyze how public availability is achieved through social learning and negotiation, why interaction becomes performative and, finally, how the display restructures the public space. The multi-touch feature, gesture-based interaction, and the physical display size contributed differentially to these uses. Our findings on the social organization of the use of public displays can be useful for designing such systems for urban environments.
2008	PressureFish: a method to improve control of discrete pressure-based input	Studies investigating user control of pressure input have reported time-accuracy trade-offs of, on average, over 30\%, when interacting with a large number of pressure levels. To increase the level of control with pressure input, we designed and evaluated four different discretization functions: linear, fisheye, visual fisheye, and clustered. The fisheye discretization dynamically modifies the range of pressure values based on the position of the pressure cursor. Our results show that a fisheye function results in significantly lower error rates and a lower number of crossings than have been reported in the literature. Furthermore, the fisheye function improves control without compromising speed. We discuss the findings of our study and identify several design recommendations for integrating pressure control into common interface tasks.
2008	Stane: synthesized surfaces for tactile input	Stane is a hand-held interaction device controlled by tactile input: scratching or rubbing textured surfaces and tapping. The system has a range of sensors, including contact microphones, capacitive sensing and inertial sensing, and provides audio and vibrotactile feedback. The surface textures vary around the device, providing perceivably different textures to the user. We demonstrate that the vibration signals generated by stroking and scratching these surfaces can be reliably classified, and can be used as a very cheaply manufacturable way to control different aspects of interaction. The system is demonstrated as a control for a music player.
2008	Activity-based prototyping of ubicomp applications for long-lived, everyday human activities	We designed an activity-based prototyping process realized in the ActivityDesigner system that combines the theoretical framework of Activity-Centered Design with traditional iterative design. This process allows designers to leverage human activities as first class objects for design and is supported in ActivityDesigner by three novel features. First, this tool allows designers to model activities based on concrete scenarios collected from everyday lives. The models form a context for design and computational constructs for creating functional prototypes. Second, it allows designers to prototype interaction behaviors based on activity streams spanning time. Third, it allows designers to easily test these prototypes with real users continuously, in situ. We have garnered positive feedback from a series of laboratory user studies and several case studies in which ActivityDesigner was used in realistic design situations. ActivityDesigner was able to effectively streamline a ubicomp design process, and it allowed creating realistic ubicomp application prototypes at a low cost and testing them in everyday lives over an extended period.
2008	Employing patterns and layers for early-stage design and prototyping of cross-device user interfaces	Designing UIs that run across multiple devices is increasingly important. To address this, we have created a prototyping tool called Damask, which targets web UIs that run on PCs and mobile phones, and prompt-and-response style voice UIs. In Damask, designers sketch out their design for one device while using design patterns to specify higher-level concepts within their design. Damask's patterns include pre-built UI fragments that are already optimized for each device. Designers also use layers to specify which UI parts are common across devices and which are specific to one device. Damask uses the sketches and patterns to generate designs for the other devices, which the designers can refine. A study performed with 12 professional UI designers found that, in the early stages, designers using patterns and layers in Damask created cross-device UIs that are rated at least as good as those created without patterns and layers, without more time.
2008	Using information scent to model the dynamic foraging behavior of programmers in maintenance tasks	In recent years, the software engineering community has begun to study program navigation and tools to support it. Some of these navigation tools are very useful, but they lack a theoretical basis that could reduce the need for ad hoc tool building approaches by explaining what is fundamentally necessary in such tools. In this paper, we present PFIS (Programmer Flow by Information Scent), a model and algorithm of programmer navigation during software maintenance. We also describe an experimental study of expert programmers debugging real bugs described in real bug reports for a real Java application. We found that PFIS' performance was close to aggregated human decisions as to where to navigate, and was significantly better than individual programmers' decisions.
2008	Melange: space folding for multi-focus interaction	Interaction and navigation in large geometric spaces typically require a sequence of pan and zoom actions. This strategy is often ineffective and cumbersome, especially when trying to study several distant objects. We propose a new distortion technique that folds the intervening space to guarantee visibility of multiple focus regions. The folds themselves show contextual information and support unfolding and paging interactions. Compared to previous work, our method provides more context and distance awareness. We conducted a study comparing the space-folding technique to existing approaches, and found that participants performed significantly better with the new technique.
2008	Sigma lenses: focus-context transitions combining space, time and translucence	Focus + context techniques such as fisheye lenses are used to navigate and manipulate objects in multi-scale worlds. They provide in-place magnification of a region without requiring users to zoom the whole representation and consequently lose context. Their adoption is however hindered by usability problems mostly due to the nature of the transition between focus and context. Existing transitions are often based on a physical metaphor (magnifying glass, fisheye, rubber sheet), and are almost always achieved through a single dimension: space. We investigate how other dimensions, namely time and translucence, can be used to achieve more efficient transitions. We present an extension to Carpendale's framework for unifying presentation space accommodating these new dimensions. We define new lenses in that space, called Sigma lenses , and compare them to existing lenses through experiments based on a generic task: focus targeting. Results show that one new lens, the Speed-coupled flattening lens, significantly outperforms all others.
2008	FacetZoom: a continuous multi-scale widget for navigating hierarchical metadata	Faceted browsing is a promising way to incrementally refine data sets. Current approaches do not scale well in terms of screen size and have shortcomings in interacting with hierarchical facets. This paper introduces FacetZoom, a novel multi-scale widget combining facet browsing with zoomable user interfaces. Hierarchical facets are displayed as space-filling widgets which allow a fast traversal across all levels while simultaneously maintaining context. We contribute both a seamless continuous navigation and a quick tap-and-center interaction. Two prototypes are described which successfully apply the space-structuring widget to continuous, sampled data and an information collection. A formative user study of the latter indicates that the interface scales well to small screens. FacetZoom is versatile and offers consistent searching and browsing behaviors in a multitude of applications and device settings.
2008	LivOlay: interactive ad-hoc registration and overlapping of applications for collaborative visual exploration	The interoperability of disparate data types and sources has been a long standing problem and a hindering factor for the efficacy and efficiency in visual exploration applications. In this paper, we present a solution, called LivOlay, that enables the rapid visual overlay of live data rendered in different applications. Our tool addresses datasets in which visual registration of the information is necessary in order to allow for thorough understanding and visual analysis. We also discuss initial evaluation and user feedback of LivOlay.
2008	PieCursor : merging pointing and command selection for rapid in-place tool switching	We describe a new type of graphical user interface widget called the "PieCursor." The PieCursor is based on the Tracking Menu technique and consists of a radial cluster of command wedges, is roughly the size of a cursor, and replaces the traditional cursor. The PieCursor technique merges the normal cursor function of pointing with command selection into a single action. A controlled experiment was conducted to compare the performance of rapid command and target selection using the PieCursor against larger versions of Tracking Menus and a status quo Toolbar configuration. Results indicate that for small clusters of tools (4 and 8 command wedges) the PieCursor can outperform the toolbar by 20.8\% for coarse pointing. For fine pointing, the performance of the PieCursor degrades approximately to the performance found for the Toolbar condition.
2008	Tilt menu: using the 3D orientation information of pen devices to extend the selection capability of pen-based user interfaces	We present a new technique called 'Tilt Menu' for better extending selection capabilities of pen-based interfaces. The Tilt Menu is implemented by using 3D orientation information of pen devices while performing selection tasks. The Tilt Menu has the potential to aid traditional one-handed techniques as it simultaneously generates the secondary input (e.g., a command or parameter selection) while drawing/interacting with a pen tip without having to use the second hand or another device. We conduct two experiments to explore the performance of the Tilt Menu. In the first experiment, we analyze the effect of parameters of the Tilt Menu, such as the menu size and orientation of the item, on its usability. Results of the first experiment suggest some design guidelines for the Tilt Menu. In the second experiment, the Tilt Menu is compared to two types of techniques while performing connect-the-dot tasks using freeform drawing mechanism. Results of the second experiment show that the Tilt Menu perform better in comparison to the Tool Palette, and is as good as the Toolglass.
2008	AAMU: adaptive activation area menus for improving selection in cascading pull-down menus	Selecting items in cascading pull-down menus is a frequent task in most GUIs. These selections involve two major components: steering and selection, with the steering component being the most time-consuming and error-prone. We describe a new technique, called Adaptive Activation-Area Menu (AAMU) that eliminate corner steering. AAMUs contain an enlarged activation area which dynamically resizes itself providing a broader steering path for menu navigation. We also combined AAMUs with Force-field menus, to create Force-AAMUs. We empirically demonstrate that AAMUs and Force-AAMUs outperformed the current default menu. We also compared performances of various other menus including Enlarged activation area menus (EMUs) and Gesture based selection with mouse as an input device. Overall, users show higher satisfaction rates for AAMUs over other menu designs.
2008	Genetic algorithm can optimize hierarchical menus	Hierarchical menus are now ubiquitous. The performance of the menu depends on many factors: structure, layout, colors and so on. There has been extensive research on novel menus, but there has been little work on improving the performance by optimizing the menu's structure. This paper proposes an algorithm based on the genetic algorithm (GA) for optimizing the performance of menus. The algorithm aims to minimize the average selection time of menu items by considering movement and decision time. We show results on a static hierarchical menu of a cellular phone where a small screen and limited input device are assumed. Our work makes several contributions: a novel mathematical optimization model for hierarchical menus; novel optimization method based on the genetic algorithm (GA).
2008	Blindsight: eyes-free access to mobile phones	Many mobile phones integrate services such as personal calendars. Given the social nature of the stored data, however, users often need to access such information as part of a phone conversation. In typical non-headset use, this re-quires users to interrupt their conversations to look at the screen. We investigate a counter-intuitive solution: to avoid the need for interruption we replace the visual interface with one based on auditory feedback. Surprisingly, this can be done without interfering with the phone conversation. We present blindSight , a prototype application that replaces the traditionally visual in-call menu of a mobile phone. Users interact using the phone keypad, without looking at the screen. BlindSight responds with auditory feedback. This feedback is heard only by the user, not by the person on the other end of the line. We present the results of two user studies of our prototype. The first study verifies that useful keypress accuracy can be obtained for the phone-at-ear position. The second study compares the blindSight system against a visual baseline condition and finds a preference for blindSight.
2008	One-handed touchscreen input for legacy applications	Supporting one-handed thumb operation of touchscreen-based mobile devices presents a challenging tradeoff between visual expressivity and ease of interaction. ThumbSpace and Shift---two new application-independent, software-based interaction techniques---address this tradeoff in significantly different ways. ThumbSpace addresses distant objects while Shift addresses small object occlusion. We present two extensive, comparative user studies. The first compares ThumbSpace and Shift to peripheral hardware (directional pad and scrollwheel) and direct touchscreen input for selecting objects while standing and walking. The data favored the Shift design overall, but suggested ThumbSpace is promising for distant objects. Our second study examines the benefits and learnability of combining Shift and ThumbSpace on a device with a larger screen (3.5"). We found their combined use offered users better overall speed and accuracy in hitting small targets (3.6 mm2) than using either method alone.
2008	Target acquisition with camera phones when used as magic lenses	When camera phones are used as magic lenses in handheld augmented reality applications involving wall maps or posters, pointing can be divided into two phases: (1) an initial coarse physical pointing phase, in which the target can be directly observed on the background surface, and (2) a fine-control virtual pointing phase, in which the target can only be observed through the device display. In two studies, we show that performance cannot be adequately modeled with standard Fitts' law, but can be adequately modeled with a two-component modification. We chart the performance space and analyze users' target acquisition strategies in varying conditions. Moreover, we show that the standard Fitts' law model does hold for dynamic peephole pointing where there is no guiding background surface and hence the physical pointing component of the extended model is not needed. Finally, implications for the design of magic lens interfaces are considered.
2008	Sonic interventions: understanding and extending the domestic soundscape	This paper presents a new study of the role, importance and meaning of sound in the home. Drawing on interview data and sound recordings gathered from seven households, this study offers fresh insight into the ways in which the domestic soundscape is managed and understood. The data revealed that household members engaged in a wide variety of sound management practices to monitor and control the real-time flow of sonic information throughout the home. They also showed that families were sometimes surprised and delighted by the ability to record fragments of the soundscape for later use. These findings suggest a number of roles for technology in enhancing the domestic soundscape and its associated behaviors, which we present here in the form of example sonic interventions created in a design workshop at the end of the project.
2008	Threshold devices: looking out from the home	Threshold devices present information gathered from the home's surroundings to give new views on the domestic situation. We built two prototypes of different threshold devices and studied them in field trials with participant households. The Local Barometer displays online text and images related to the home's locality depending on the local wind conditions to give an impression of the sociocultural surroundings. The Plane Tracker tracks aircraft passing overhead and imagines their flights onscreen to resource an understanding of the home's global links. Our studies indicated that the experiences they provided were compelling, that participants could and did interpret the devices in various ways, that their form designs were appropriate for domestic environments, that using ready-made information contributed to the richness of the experiences, and that situating the information they provided with respect to the home and its locality was important for the ways people engaged with them.
2008	Requirements engineering for home care technology	The focus of this work is the requirements engineering process in the home care domain. The overall aim is to design and document a flexible methodology to facilitate the elicitation of complex, dynamic, multi-stakeholder requirements and needs. This paper details the complexity and uniqueness of the home care domain and outlines the features of home care that demand a new or tailored approach to requirements engineering. It concludes by presenting a consolidated list of features that must be available or supported in requirements engineering methods in the home care domain.
2008	Game over: learning by dying	This paper presents the design and evaluation of "Game Over!", which is the world's first universally inaccessible game (i.e., a game that can be played by no one). The game is meant to be used as an educational tool for disseminating and teaching game accessibility guidelines. This is achieved by providing game developers a first-hand (frustrating) experience of how it feels interacting with a game that is not accessible, due to the fact that important design rules were not considered or applied during its design. Both the overall concept and the approach followed were evaluated and validated through: (a) an on-line survey; (b) "live" feedback from players and developers; and (c) public opinions and critique collected from numerous Web sites and blogs where "Game Over!" was presented and discussed. The evaluation outcomes strongly suggest that computer games and humor constitute a perfect match for reaching out, motivating and educating the game developers' community in the subject of game accessibility.
2008	Heuristic evaluation for games: usability principles for video game design	Most video games require constant interaction, so game designers must pay careful attention to usability issues. However, there are few formal methods for evaluating the usability of game interfaces. In this paper, we introduce a new set of heuristics that can be used to carry out usability inspections of video games. The heuristics were developed to help identify usability problems in both early and functional game prototypes. We developed the heuristics by analyzing PC game reviews from a popular gaming website, and the review set covered 108 different games and included 18 from each of 6 major game genres. We analyzed the reviews and identified twelve common classes of usability problems seen in games. We developed ten usability heuristics based on the problem categories, and they describe how common game usability problems can be avoided. A preliminary evaluation of the heuristics suggests that they help identify game-specific usability problems that can easily be overlooked otherwise.
2008	Renegade gaming: practices surrounding social use of the Nintendo DS handheld gaming system	Today's handheld gaming systems allow players to engage in multiplayer games via ad-hoc, wireless networking. They are also now sufficiently commonplace that it is possible to study how portability and ad-hoc wireless networking have affected the social gaming practices of owners of these systems. In this paper, we report findings from a qualitative study investigating the collocated multiplayer gaming practices of Nintendo DS owners. Based on interviews of nine DS owners and observations of three organized gaming events, we identified three major themes surrounding the social, multiplayer gaming practices of Nintendo DS users: renegade gaming , or the notion that users reappropriate contexts traditionally hostile to game play; pragmatic and social barriers to the formation of ad-hoc pick-up games, despite a clear desire for multiplayer, collocated gaming; and private gaming spheres , or the observation that the handheld device's form factor creates individual, privatized gaming contexts within larger social contexts. These findings lead to a set of implications for the design of future handheld gaming systems.
2008	Expandable grids for visualizing and authoring computer security policies	We introduce the Expandable Grid, a novel interaction technique for creating, editing, and viewing many types of security policies. Security policies, such as file permissions policies, have traditionally been displayed and edited in user interfaces based on a list of rules, each of which can only be viewed or edited in isolation. These list-of-rules interfaces cause problems for users when multiple rules interact, because the interfaces have no means of conveying the interactions amongst rules to users. Instead, users are left to figure out these rule interactions themselves. An Expandable Grid is an interactive matrix visualization designed to address the problems that list-of-rules interfaces have in conveying policies to users. This paper describes the Expandable Grid concept, shows a system using an Expandable Grid for setting file permissions in the Microsoft Windows XP operating system, and gives results of a user study involving 36 participants in which the Expandable Grid approach vastly outperformed the native Windows XP file-permissions interface on a broad range of policy-authoring tasks.
2008	LiveRAC: interactive visual exploration of system management time-series data	We present LiveRAC, a visualization system that supports the analysis of large collections of system management time-series data consisting of hundreds of parameters across thousands of network devices. LiveRAC provides high information density using a reorderable matrix of charts, with semantic zooming adapting each chart's visual representation to the available space. LiveRAC allows side-by-side visual comparison of arbitrary groupings of devices and parameters at multiple levels of detail. A staged design and development process culminated in the deployment of LiveRAC in a production environment. We conducted an informal longitudinal evaluation of LiveRAC to better understand which proposed visualization techniques were most useful in the target environment.
2008	Metrics for measuring human interaction with interactive visualizations for information analysis	There is a lack of widely-accepted metrics for evaluating analysts' experiences with interactive visualizations (IV) for information analysis. We report an approach for developing analyst-centered IV metrics that is built upon understanding the workplace needs and experiences of information analysts with respect to IVs. We derive metrics from human-computer interaction heuristics, specializing the metrics to address the characteristics of IVs and analysts. When there are no existing heuristics, analysts' needs and experiences inform new heuristics.
2008	On the benefits of confidence visualization in speech recognition	In a typical speech dictation interface, the recognizer's best-guess is displayed as normal, unannotated text. This ignores potentially useful information about the recognizer's confidence in its recognition hypothesis. Using a confidence measure (which itself may sometimes be inaccurate), we investigated providing visual feedback about low-confidence portions of the recognition using shaded, red underlining. An evaluation showed, compared to a baseline without underlining, underlining low-confidence areas did not increase user's speed or accuracy in detecting errors. However, we found that when recognition errors were correctly underlined, they were discovered significantly more often than baseline. Conversely, when errors failed to be underlined, they were discovered less often. Our results indicate confidence visualization can be effective --- but only if the confidence measure has high accuracy. Further, since our results show that users tend to trust confidence visualization, designers should be careful in its application if a high accuracy confidence measure is not available.
2008	A latent semantic analysis methodology for the identification and creation of personas	A persona represents a group of target users that share common behavioral characteristics. By using a narrative, picture, and name, a persona provides HCI practitioners with a vivid and specific design target. This research develops a new methodology for the identification and creation of personas through the application of Latent Semantic Analysis (LSA). An application of the LSA methodology is provided in the context of the design of an Institutional Repository system. The LSA methodology helps overcome some of the drawbacks of current methods for the identification and creation of personas, and makes the process less subjective, more efficient, and less reliant on specialized skills.
2008	The effects of empathetic virtual characters on presence in narrative-centered learning environments	Recent years have seen a growing interest in the role that narrative can play in learning. With the emergence of narrative-centered learning environments that engage students by drawing them into rich interactions with compelling characters, we have begun to see the significant potential offered by immersive story-based learning experiences. In this paper we describe two studies that investigate the impact of empathetic characters on student perceptions of presence. A study was initially conducted with middle school students, and was then replicated with high school students. The results indicate that, for both populations, employing empathetic characters in narrative-centered learning environments significantly increases student perceptions of presence. The studies also reveal that empathetic characters contribute to a heightened sense of student involvement and control in learning situations.
2008	Data-driven persona development	Much has been written on creating personas --- both what they are good for, and how to create them. A common problem with personas is that they are not based on real customer data, and if they are, the data set is not of a sample size that can be considered statistically significant. In this paper, we describe a new method for creating and validating personas, based on the statistical analysis of data, which is fast and cost effective.
2008	Cross-channel mobile social software: an empirical study	In this paper, we introduce a prototype system designed to support mobile group socializing that has been appropriated for everyday use by 150 users over 18 months. The system supports cross-channel communication, allowing users to participate in group conversations using text messaging, instant messaging, email and the web. It does this with the "console," a uniform text-based syntax that enables the prototype to be used over a variety of mediums. We found that participants used the system mostly for ad-hoc coordination rather than chat, with pervasive, cross-channel group communication supporting an informal "half-invite" style of invitation. We examine why coordination dominates over chat, suggesting that cross-channel mobile group messaging serves a distinct role, different to traditional text messaging, instant messaging and email. Furthermore, we found differences in the content and usage habits across channels, for example messages sent from a computer were more likely to refer to time and location than those sent using a phone. We also discuss the usage of the prototype and compare it to other work.
2008	Social copresence in anonymous social interactions using a mobile video telephone	In this paper, we describe research exploring the effect of behavioral and visual realism of avatars on users' social copresence in emotionally engaged conversations conducted via a simulated mobile video telephone. We offer an elaborated definition of Social Copresence to better measure users' engagement with conversational partners in social interactions that do not involve specific tasks or concrete outcomes. We investigate ways to secure mobile telephone users' anonymity while preserving their most important nonverbal affective behaviors. Experimental results with 180 participants using different combinations of static and dynamic, high and low iconic (both video and graphically animated) avatars show increased Social Copresence with dynamic high-iconic (similar to the human communicator) avatars incorporating correct facial expressions, even when these are presented on the small screen of mobile telephones in such a way that individual identities are masked. The results point to an economical combination of behavioral and iconic realism of avatars that produces maximum emotional engagement in anonymous social interactions using mobile video telephones.
2008	Use and reuse of shared lists as a social content type	Social networking sites support a variety of shared content types such as photos, videos, or music. More structured or form-based social content types are not mainstream but we have started seeing sites evolve that support them. This paper describes the design and use of structured lists in an enterprise social networking system. As a major feature of our shared lists, we introduced the ability to reuse someone else's list. We report the results on the use and reuse of shared lists based on three months of usage data from 285 users and interviews with 9 users. Our findings suggest that despite the structured nature of lists, our users socialize more around lists than photos, and use lists as a medium for self-representation.
2008	Emotional and behavioral responses to haptic stimulation	A prototype of friction-based horizontally rotating fingertip stimulator was used to investigate emotional experiences and behavioral responses to haptic stimulation. The rotation style of 12 different stimuli was varied by burst length (i.e., 20, 50, 100 ms), continuity (i.e., continuous and discontinuous), and direction (e.g., forward and backward). Using these stimuli 528 stimulus pairs were presented to 12 subjects who were to distinguish if stimuli in each pair were the same or different. Then they rated the stimuli using four scales measuring the pleasantness, arousal, approachability, and dominance qualities of the 12 stimuli. The results showed that continuous forward-backward rotating stimuli were rated as significantly more unpleasant, arousing, avoidable, and dominating than other types of stimulations (e.g., discontinuous forward rotation). The reaction times to these stimuli were significantly faster than reaction times to discontinuous forward and backward rotating stimuli. The results clearly suggest that even simple haptic stimulation can carry emotional information. The results can be utilized when making use of haptics in human-technology interaction.
2008	Evaluating tactile feedback and direct vs. indirect stylus input in pointing and crossing selection tasks	We present a pair of experiments that explore the effects of tactile-feedback and direct vs. indirect pen input on pointing and crossing selection tasks. While previous work has demonstrated the validity of crossing as a useful selection mechanism for pen-based computing, those experiments were conducted using an indirect input device -- one in which the pen-input and display were separated. We investigate users' performance with pointing and crossing interfaces controlled via not only an indirect input device, but also a direct input device -- one in which the pen-input and display are co-located. Results show that direct input significantly outperforms indirect input for crossing selection, but the two modalities are essentially equivalent in pointing selection. A small amount of tactile feedback is shown to be beneficial for both pointing and crossing selection, most noticeably in crossing tasks when using direct input where visual feedback is often occluded by a hand or stylus.
2008	Investigating the effectiveness of tactile feedback for mobile touchscreens	This paper presents a study of finger-based text entry for mobile devices with touchscreens. Many devices are now coming to market that have no physical keyboards (the Apple iPhone being a very popular example). Touchscreen keyboards lack any tactile feedback and this may cause problems for entering text and phone numbers. We ran an experiment to compare devices with a physical keyboard, a standard touchscreen and a touchscreen with tactile feedback added. We tested this in both static and mobile environments. The results showed that the addition of tactile feedback to the touchscreen significantly improved finger-based text entry, bringing it close to the performance of a real physical keyboard. A second experiment showed that higher specification tactile actuators could improve performance even further. The results suggest that manufacturers should use tactile feedback in their touchscreen devices to regain some of the feeling lost when interacting on a touchscreen with a finger.
2008	A co-located interface for narration to support reconciliation in a conflict: initial results from Jewish and Palestinian youth	So called intractable conflicts may benefit from more modest and socially oriented approaches than those based on classical conflict resolution techniques. This paper is inspired by theories on small group intervention in a conflict. The general claim is that participants may achieve a greater understanding of and appreciation for the other's viewpoint under conditions that support partaking in a tangible joint task and creating a shared narration. Our goal was to design a methodology wherein the extent to which technology contributes to conflict negotiation and resolution could be assessed. Specifically, a co-located interface for producing a joint narration as a tool for favouring reconciliation is presented and discussed. The results of an initial set of studies where the interface was used by Arab and Jewish youth in Israel provided insight into the usability of the various components of the technology and of the paradigm.
2008	Cultural theory and real world design: Dystopian and Utopian Outcomes	When exploring a topic as intangible as the construction of mobile social networks it is necessary to look at how relationships are formed and at the way users identify themselves through their interactions. The theoretically informed discourses within cultural theory make an ideal lens for understanding these subtle nuances of use in terms of design. This paper describes a case study where the application of abstract cultural theory concepts to the practical act of analysing qualitative data from a user study resulted in the development of The Swarm mobile phone prototypes. By signposting the intersection of cultural theory within HCI, the value of a philosophically grounded mobile phone design space is highlighted. To uncover reactions to the design we explored the blogs that sprung up critiquing an online version of The Swarm and in doing so, discovered the at times subversive values (such as the need to lie) that users place on their mobile mediated interactions.
2008	The network in the garden: an empirical analysis of social media in rural life	History repeatedly demonstrates that rural communities have unique technological needs. Yet, we know little about how rural communities use modern technologies, so we lack knowledge on how to design for them. To address this gap, our empirical paper investigates behavioral differences between more than 3,000 rural and urban social media users. Using a dataset collected from a broadly popular social network site, we analyze users' profiles, 340,000 online friendships and 200,000 interpersonal messages. Using social capital theory, we predict differences between rural and urban users and find strong evidence supporting our hypotheses. Namely, rural people articulate far fewer friends online, and those friends live much closer to home. Our results also indicate that the groups have substantially different gender distributions and use privacy features differently. We conclude by discussing design implications drawn from our findings; most importantly, designers should reconsider the binary friend-or-not model to allow for incremental trust-building.
2008	An error model for pointing based on Fitts' law	For decades, Fitts' law (1954) has been used to model pointing time in user interfaces. As with any rapid motor act, faster pointing movements result in increased errors. But although prior work has examined accuracy as the "spread of hits," no work has formulated a predictive model for error rates (0-100\%) based on Fitts' law parameters. We show that Fitts' law mathematically implies a predictive error rate model, which we derive. We then describe an experiment in which target size, target distance, and movement time are manipulated. Our results show a strong model fit: a regression analysis of observed vs. predicted error rates yields a correlation of R 2 =.959 for N =90 points. Furthermore, we show that the effect on error rate of target size ( W ) is greater than that of target distance ( A ), indicating a departure from Fitts' law, which maintains that W and A contribute proportionally to index of difficulty ( ID ). Our error model can be used with Fitts' law to estimate and predict error rates along with speeds, providing a framework for unifying this dichotomy.
2008	Optimal parameters for efficient crossing-based dialog boxes	We present an empirical analysis of crossing-based dialog boxes. First, we study the spatial constraints required for efficient crossing-based interactions in the case of a simple multi-parameter dialog box. Through a series of 3 tasks, we establish the minimal value of the landing margin, the takeoff margin, and the column width. We also offer an estimation of the role of stroke shape on user performance. After studying the reasons for errors during our experiment, we propose a relaxed crossing semantic that combines aspects of pointing and crossing-based interfaces. To test our design, we compare a naïve dialog box implementation with our new implementation, as well as a standard point-and-click dialog box. Our results reveal that there is not a significant difference between the naïve crossing implementation and the standard point-and-click interface and that the new crossing semantic is faster than both the naïve crossing implementation and the point-and-click interface, despite a higher error rate. Together these two experiments establish that crossing-based dialog boxes can be as spatially efficient and faster than their point-and-click counterpart. Our new semantic provides the first step towards a smooth transition from point-and-click interfaces to crossing-based interfaces.
2008	Fitts' throughput and the speed-accuracy tradeoff	We describe an experiment to test the hypothesis that Fitts' throughput is independent of the speed-accuracy tradeoff. Eighteen participants used a mouse in performing a total of 5,400 target selection trials. Comparing nominal, speed-emphasis, and accuracy-emphasis conditions, significant main effects were found on movement time (ms) and error rate (\%), but not on throughput (bits/s). In the latter case, failure to reject the null hypothesis of "no significant difference" (i.e., .05
2008	Articulating common ground in cooperative work: content and process	We study the development of common ground in an emergency management planning task. Twelve three-person multi-role teams performed the task with a paper prototype in a controlled setting; each team completed three versions of the task. We use converging measures to document the development of common ground in the teams and present an in-depth analysis of the characteristics of the common ground development process. Our findings indicate that in complex collaborative work, process common ground increases, thus diminishing the need for acts like information querying or strategy discussions about how to organize the collaborative activities. However, content common ground is created and tested throughout the three runs; in fact dialogue acts used to clarify this content increase over time. Discussion of the implications of these findings for the theory of common ground and the design of collaborative systems follows.
2008	CoSearch: a system for co-located collaborative web search	Web search is often viewed as a solitary task; however, there are many situations in which groups of people gather around a single computer to jointly search for information online. We present the findings of interviews with teachers, librarians, and developing world researchers that provide details about users' collaborative search habits in shared-computer settings, revealing several limitations of this practice. We then introduce CoSearch, a system we developed to improve the experience of co-located collaborative Web search by leveraging readily available devices such as mobile phones and extra mice. Finally, we present an evaluation comparing CoSearch to status quo collaboration approaches, and show that CoSearch enabled distributed control and division of labor, thus reducing the frustrations associated with shared-computer searches, while still preserving the positive aspects of communication and collaboration associated with joint computer use.
2008	A survey of collaborative web search practices	Today's Web browsers provide limited support for rich information-seeking and information-sharing scenarios. A survey we conducted of 204 knowledge workers at a large technology company has revealed that a large proportion of users engage in searches that include collaborative activities. We present the results of the survey, and then review the implications of these findings for designing new Web search interfaces that provide tools for sharing.
2008	OpenMessenger: gradual initiation of interaction for distributed workgroups	The initiation of interaction in face-to-face environments is a gradual process, and takes place in a rich information landscape of awareness, attention, and social signals. One of the main benefits of this process is that people can be more sensitive to issues of privacy and interruption while they are moving towards interaction. However, on-line communication tools do not provide this subtlety, and often lead to unwanted interruptions. We have developed a prototype message system called OpenMessenger (OM) that adds the idea of gradual initiation of interaction to on-line communication. OpenMessenger provides multiple levels of awareness about people, and provides notification to those about whom information is being gathered. OpenMessenger allows people to negotiate interaction in a richer fashion than is possible with any other current messaging system. Preliminary evaluation data suggest the utility of the approach, but also shows that there are a number of issues yet to be resolved in this area.
2008	How accurate must an in-car information system be?: consequences of accurate and inaccurate information in cars	Driving requires focused attention and timely decision making for appropriate maneuvers. This relies on well-timed and accurate information. Designing an in-vehicle information system it is important to ensure that the information for the driver does not negatively affect cognitive processing and driving performance. This study investigates levels of information accuracy necessary in in-vehicle information systems to elicit positive behavioral and attitudinal responses from the driver. In a 2 (gender) by 5 (accuracy: 100\%, 88\%, 76\%, 64\% and no system) between-participants study, 100 participants drove in a driving simulator for 25 minutes with an in-vehicle information system designed to inform the driver of hazard and traffic events. Results show that decreasing the accuracy of the system decreased both driving performance and trust and liking of car and in-vehicle system. Female drivers in particular benefit from the in-vehicle system and show higher tolerance of inaccuracies. Design implications for in-vehicle systems are discussed.
2008	In-car gps navigation: engagement with and disengagement from the environment	Although in-car GPS navigation technology is proliferating, it is not well understood how its use alters the ways people interpret their environment and navigate through it. We argue that GPS-based car navigation might disengage people from their surrounding environment, but also has the potential to open up novel ways to engage with it. We present an ethnographically-informed study with GPS users, showing evidence for practices of disengagement as well as new opportunities for engagement, illustrating our findings using rich descriptions from the field. Grounded in our observations we propose design principles for GPS systems that support richer experiences of driving. We argue that for a fuller understanding of issues of disengagement and engagement with the environment we need to move beyond a focus on the (re)design of GPS devices, and point to future directions of work that embrace a broader perspective.
2008	In-car interaction using search-based user interfaces	Increasing functionality, growing media volumes and dynamic data in today's in-vehicle information systems bear new challenges for user interaction design. Traditional hierarchical and menu-based interaction can only provide limited support while new search-based approaches are promising. In this work we assess different search techniques and search-based user interfaces. In particular we compare free search across all data items with categorized search. Our experiments with functional prototypes show that free search is more efficient and easier to use than searching within categories. Tests in a driving simulator show promising results regarding safety and workload. Means for alphanumeric input appear to be essential for an efficient and safe search interaction while driving.
2008	Multi-flick: an evaluation of flick-based scrolling techniques for pen interfaces	Multi-flick , which consists of repeated flick actions, has received popular media attention as an intuitive and natural document-scrolling technique for stylus based systems. In this paper we put multi-flick to test, by designing several flick-based scrolling techniques. We first map out the de-sign space of multi-flick and identify mapping functions that make multi-flick a natural and intuitive technique for document navigation. In the first experiment we compare several multi-flick variations for navigating lists on three different devices -- a PDA, a tabletPC, and a large table. Our study shows that compound-multi-flick (CMF) is the most preferred technique and it is at least as fast, if not faster than the traditional scrollbar. In a follow-up experiment, we evaluate multi-flick for scrolling text-based documents. Results show that all implementations of multi-flick are as good as the scrollbar for short distances while CMF is the most preferred. We discuss the implications of our findings and present several design guidelines.
2008	Peephole pointing: modeling acquisition of dynamically revealed targets	Peephole interaction occurs when a spatially aware display is moved and acts as a viewport to reveal different parts of the virtual space that cannot all fit within the display at once. We investigate pointing within this peephole metaphor, where the targets may not be initially visible on the display, but are dynamically revealed by moving the display. We develop and experimentally validate a quantitative model for peephole pointing. Our results indicate that the model accurately accounts for peephole pointing for a variety of display sizes, both with and without users' having prior knowledge of the target location.
2008	The effect of spring stiffness and control gain with an elastic rate control pointing device	Isometric and elastic devices are most compatible with a rate control mapping. However, the effect of elastic stiffness has not been thoroughly investigated nor its interaction with control gain. In a controlled experiment, these factors are investigated along with user feedback regarding ease-of-use and fatigue. The results reveal a U-shaped profile of control gain vs. movement time, with different profiles for different stiffness levels. Using the optimum control gain for each stiffness level, performance across stiffness levels were similar. However, users preferred lower stiffness and lower control gain levels due to increased controller displacement. Based on these results, design guidelines for elastic rate control devices are given.
2008	CoScripter: automating & sharing how-to knowledge in the enterprise	Modern enterprises are replete with numerous online processes. Many must be performed frequently and are tedious, while others are done less frequently yet are complex or hard to remember. We present interviews with knowledge workers that reveal a need for mechanisms to automate the execution of and to share knowledge about these processes. In response, we have developed the CoScripter system (formerly Koala [11]), a collaborative scripting environment for recording, automating, and sharing web-based processes. We have deployed CoScripter within a large corporation for more than 10 months. Through usage log analysis and interviews with users, we show that CoScripter has addressed many user automation and sharing needs, to the extent that more than 50 employees have voluntarily incorporated it into their work practice. We also present ways people have used CoScripter and general issues for tools that support automation and sharing of how-to knowledge.
2008	The buzz: supporting user tailorability in awareness applications	Information awareness applications offer the exciting potential to help people to better manage the data they encounter on a routine basis, but customizing these applications is a difficult task. Most applications allow users to perform basic customizations or programmers to create advanced ones. We present an intermediate customization space and Cocoa Buzz, an application that demonstrates one way to bridge these two extremes. Cocoa Buzz runs on an extra display on the user's desktop or on a large shared display and cycles through different information sources customized by the user. We further demonstrate some of the customizations that have been made using this approach. We show some preliminary evidence to suggest that this approach may be useful at providing users with the ability to perform customizations across this spectrum.
2008	Photos on the go: a mobile application case study	We designed and iterated on a photo browsing application for high-end mobile phones. The application, Zurfer, supports viewing of photos from the user, their contacts, and the general user population. Photos are organized using a channel metaphor, driven by multiple dimensions: social, spatial and topical. Zurfer was deployed to over 500 users; extensive user research was conducted with nine participants. The data from the deployment and the study exposes general themes of mobile application use, as well as requirements for mobile applications in the photos domain, mobile social applications, and entertainment-driven mobile applications.
2008	Photospread: a spreadsheet for managing photos	PhotoSpread is a spreadsheet system for organizing and analyzing photo collections. It extends the current spreadsheet paradigm in two ways: (a) PhotoSpread accommodates sets of objects (e.g., photos) annotated with tags (attribute-value pairs). Formulas can manipulate object sets and refer to tags. (b) Photos can be reorganized (tags and location changed) by drag-and-drop operations on the spreadsheet. The PhotoSpread design was driven by the needs of field biologists who have large collections of annotated photos. The paper describes the PhotoSpread functionality and the design choices made.
2008	Picbreeder: evolving pictures collaboratively online	Picbreeder is an online service that allows users to collaboratively evolve images. Like in other Interactive Evolutionary Computation (IEC) programs, users evolve images on Picbreeder by selecting ones that appeal to them to produce a new generation. However, Picbreeder also offers an online community in which to share these images, and most importantly, the ability to continue evolving others' images. Through this process of branching from other images, and through continually increasing image complexity made possible by the NeuroEvolution of Augmenting Topologies (NEAT) algorithm, evolved images proliferate unlike in any other current IEC systems. Participation requires no explicit talent from the users, thereby opening Picbreeder to the entire Internet community. This paper details how Picbreeder encourages innovation, featuring images that were collaboratively evolved.
2008	Evaluating motion constraints for 3D wayfinding in immersive and desktop virtual environments	Motion constraints providing guidance for 3D navigation have recently been suggested as a way of offloading some of the cognitive effort of traversing complex 3D environments on a computer. We present findings from an evaluation of the benefits of this practice where users achieved significantly better results in memory recall and performance when given access to such a guidance method. The study was conducted on both standard desktop computers with mouse and keyboard, as well as on an immersive CAVE system. Interestingly, our results also show that the improvements were more dramatic for desktop users than for CAVE users, even outperforming the latter. Furthermore, the study indicates that allowing the users to retain local control over the navigation on the desktop platform helps them in familiarizing themselves with the 3D world.
2008	Navigation techniques for dual-display e-book readers	Existing e-book readers do not do a good job supporting many reading tasks that people perform, as ethnographers report that when reading, people frequently read from multiple display surfaces. In this paper we present our design of a dual display e-book reader and explore how it can be used to interact with electronic documents. Our design supports embodied interactions like folding, flipping, and fanning for local/lightweight navigation. We also show how mechanisms like Space Filling Thumbnails can use the increased display space to aid global navigation. Lastly, the detachable faces in our design can facilitate inter-document operations and flexible layout of documents in the workspace. Semi-directed interviews with seven users found that dual-displays have the potential to improve the reading experience by supporting several local navigation tasks better than a single display device. Users also identified many reading tasks for which the device would be valuable. Users did not find the embodied interface particularly useful when reading in our controlled lab setting, however.
2008	Idea navigation: structured browsing for unstructured text	Traditional interfaces for information access do not fully support queries that rely on semantic relationships between terms. To better support such queries, we introduce a system that automatically extracts subject-verb-object concepts from unstructured text documents and dynamically presents them to the user as navigable refinements. This approach, which we call "idea navigation," makes subject-verb-object querying as simple as selecting successive refinements. It also supports exploratory search by providing a view of the most common ideas in the current result set. First-time users of a prototype system successfully used idea navigation to solve realistic search tasks, demonstrating its effectiveness.
2008	Rendering navigation and information space with honeycomb™	The growing amount of available information poses challenges not only in the process of information retrieval. The usability of the rendered search process and results can be increased by appropriate visualization techniques or new interaction paradigms, or both. In this article we present the HoneyComb™ paradigm, an information visualization style that aims to render and manage large quantities of information items. We describe the design objectives and the prototype of HC™. Finally, we present a short evaluation of the HC™ paradigm in the context of search and browsing.
2008	Activity sensing in the wild: a field trial of ubifit garden	Recent advances in small inexpensive sensors, low-power processing, and activity modeling have enabled applications that use on-body sensing and machine learning to infer people's activities throughout everyday life. To address the growing rate of sedentary lifestyles, we have developed a system, UbiFit Garden, which uses these technologies and a personal, mobile display to encourage physical activity. We conducted a 3-week field trial in which 12 participants used the system and report findings focusing on their experiences with the sensing and activity inference. We discuss key implications for systems that use on-body sensing and activity inference to encourage physical activity.
2008	Healthcare in everyday life: designing healthcare services for daily life	Today the design of most healthcare technology is driven by the considerations of healthcare professionals and technology companies. This has several benefits, but we argue that there is a need for a supplementary design approach on the basis the citizen and his or her everyday life. An approach where the main focus is to develop healthcare technology that fits the routines of daily life and thus allows the citizens to continue with the activities they like and have grown used to -- also with an aging body or when managing a chronic condition. Thus, with this approach it is not just a matter of fixing a health condition, more importantly is the matter of sustaining everyday life as a whole. This argument is a result from our work -- using participatory design methods -- on the development of supportive healthcare technology for elderly people and for diabetic, pregnant women.
2008	SuperBreak: using interactivity to enhance ergonomic typing breaks	Repetitive strain injuries and ergonomics concerns have become increasingly significant health issues as a growing number of individuals frequently use computers for long periods of time. Currently, limited software mechanisms exist for managing ergonomics; the most well-known are "break-reminder" packages that schedule and recommend typing breaks. Yet despite the proven benefits of taking breaks, such packages are rarely adopted due to the over-head of introducing periodic interruptions into a user's workflow. In this paper, we describe SuperBreak , a break-reminder package that provides hands-free interactions during breaks, with the goal of encouraging users to take more breaks and enhancing the benefits of those breaks. In a field study of 26 knowledge workers, 85\% preferred SuperBreak over a traditional break-reminder system, and on average participants took a higher percentage of the interactive breaks suggested to them. Our results highlight the value of interactivity for improving the adoption and retention of ergonomic break practices.
2008	Ambient social tv: drawing people into a shared experience	We examine how ambient displays can augment social television. Social TV 2 is an interactive television solution that incorporates two ambient displays to convey to participants an aggregate view of their friends' current TV-watching status. Social TV 2 also allows users to see which television shows friends and family are watching and send lightweight messages from within the TV-viewing experience. Through a two-week field study we found the ambient displays to be an integral part of the experience. We present the results of our field study with a discussion of the implications for future social systems in the home.
2008	Re-placing faith: reconsidering the secular-religious use divide in the United States and Kenya	In this paper, we report on design-oriented fieldwork and design research conducted over a six-month period in urban centers in the United States and Kenya. The contributions of this work for the CHI/CSCW community are empirical and methodological. First, we describe how recent design discourse around "designing technology for religion" creates an artificial distinction between instrumental and religious ICT use, particularly in developing regions. As illustrative examples, we relate three themes developed in the course of our fieldwork, which we term mindfulness, watchfulness, and embeddedness, to both "secular" and "religious" aspects of life in the communities studied. Second, we make a methodological contribution by describing how we used design sketches of speculative design concepts to extend and complement our fieldwork. By producing these sketches and soliciting feedback, we elicited additional data about how participants viewed the relationship between religion and ICT and prompted self-reflection on our own ideas.
2008	From meiwaku to tokushita !: lessons for digital money design from japan	Based on ethnographically-inspired research in Japan, we report on people's experiences using digital money payment systems that use Sony's FeliCa near-field communication smartcard technology. As an example of ubiquitous computing in the here and now, the adoption of digital money is found to be messy and contingent, shot through with cultural and social factors that do not hinder this adoption but rather constitute its specific character. Adoption is strongly tied to Japanese conceptions of the aesthetic and moral virtue of smooth flow and avoidance of commotion, as well as the excitement at winning something for nothing. Implications for design of mobile payment systems stress the need to produce open-ended platforms that can serve as the vehicle for multiple meanings and experiences without foreclosing such possibilities in the name of efficiency.
2008	Human-Currency Interaction: learning from virtual currency use in China	What happens when the domains of HCI design and money intersect? This paper presents analyses from an ethnographic study of virtual currency use in China to discuss implications for game design, and HCI design more broadly. We found that how virtual currency is perceived, obtained, and spent can critically shape gamers' behavior and experience. Virtual and real currencies can interact in complex ways that promote, extend, and/or interfere with the value and character of game worlds. Bringing money into HCI design heightens existing issues of realness, trust, and fairness, and thus presents new challenges and opportunities for user experience innovation.
2008	CueFlik: interactive concept learning in image search	Web image search is difficult in part because a handful of keywords are generally insufficient for characterizing the visual properties of an image. Popular engines have begun to provide tags based on simple characteristics of images (such as tags for black and white images or images that contain a face), but such approaches are limited by the fact that it is unclear what tags end users want to be able to use in examining Web image search results. This paper presents CueFlik, a Web image search application that allows end users to quickly create their own rules for re ranking images based on their visual characteristics. End users can then re rank any future Web image search results according to their rule. In an experiment we present in this paper, end users quickly create effective rules for such concepts as "product photos", "portraits of people", and "clipart". When asked to conceive of and create their own rules, participants create such rules as "sports action shot" with images from queries for "basketball" and "football". CueFlik represents both a promising new approach to Web image search and an important study in end user interactive machine learning.
2008	Knowledge in the head and on the web: using topic expertise to aid search	The importance of background knowledge for effective searching on the Web is not well understood. Participants were given trivia questions on two topics and asked to answer them first using background knowledge and second by searching on the Web. Knowledge of a topic predicted search performance on that topic for all questions and, more importantly, for questions for which participants did not already know the answer. In terms of process, greater topic knowledge led to less time being spent on each Webpage, faster decisions to give up a line of inquiry and shorter queries being entered into the search engine. A more complete theory-led understanding of these effects would assist workers in a whole range of Web-related professions.
2008	MQSearch: image search by multi-class query	Image search is becoming prevalent in web search as the number of digital photos grows exponentially on the internet. For a successful image search system, removing outliers in the top ranked results is a challenging task. Typical content based image search engines take an input image from one class as a query and compute relevance between the query and images in a database. The results often contain a large number of outliers, since these outliers may be similar to the query image in some way. In this paper we present a novel search scheme using query images from multiple classes. Instead of conducting query search for one image class at a time, we conduct multi-class query search jointly. By using several query classes that are similar to each other for multi-class query, we can utilize information across similar classes to fine tune the similarity measure to remove outliers. This strategy can be used for any information search application. In this work, we use content based image search to illustrate the concept.
2008	AutoTopography: what can physical mementos tell us about digital memories?	Current technology makes it possible to capture huge amounts of information related to everyday experiences. Despite this, we know little about the processes by which people identify and manage mementos - objects which are directly meaningful to their memories. Among the millions of objects people encounter in a lifetime, few become such reminders of people, places or events. We report fieldwork where participants gave us a tour of their homes describing how and why particular objects become mementos. Our findings extend the existing digital memory literature; first our participants didn't view their activities as experiential 'capture', nor were mementos limited to pictorial representations of people and events; instead they included everyday objects. Furthermore, mementos were not only displayed and shared, but also integrated into everyday activities. Finally there were complex relations between house location and memento type. We discuss the theoretical and technical implications of our work.
2008	Mobile multimedia presentation editor: enabling creation of audio-visual stories on mobile devices	A mobile device provides an attractive tool for creating and sharing audio-visual stories. Earlier research has shown that the users enjoy creating digital stories with their mobile devices. However, designing editor interfaces that support creation of rich audio-visual presentations has been a major challenge due to the constrained input and output capabilities of mobile devices. In this paper, we present the design and evaluation of the Mobile Multimedia Presentation Editor, an application that makes it possible to author sophisticated multimedia presentations that integrate several different media types on mobile devices. Based on a user study, we present design principles for multimedia presentation editors on mobile devices. We describe an application design that supports these principles and so demonstrate that editing of sophisticated multimedia presentations is feasible on mobile devices. We report evaluations which indicate that the editor application was easy to use and supported the creativity of the mobile users well.
2008	Temporal trajectories in shared interactive narratives	Temporal trajectories can represent the complex mappings between story time and clock time that are to be found in shared interactive narratives such as computer games and interactive performances. There are three kinds. Canonical trajectories express an author's intended mapping of story time onto clock time as part of the plot and schedule of an experience. Participant trajectories reflect a participant's actual journey through story time and clock time as they interact with the experience. Historic trajectories represent the subsequent selection and reuse of segments of recorded participant trajectories to create histories of past events. We show how temporal trajectories help us analyse the nature of time in existing experiences and can also generate new approaches to dealing with temporal issues such as: disengagement and reengagement, adapting to different paces of interaction, synchronising different participants, and enabling encounters and travel across time.
2008	Communication chains and multitasking	There is a growing literature on managing multitasking and interruptions in the workplace. In an ethnographic study, we investigated the phenomenon of communication chains , the occurrence of interactions in quick succession. Focusing on chains enable us to better understand the role of communication in multitasking. Our results reveal that chains are prevalent in information workers, and that attributes such as the number of links, and the rate of media and organizational switching can be predicted from the first catalyzing link of the chain. When chains are triggered by external interruptions, they have more links, a trend for more media switches and more organizational switches. We also found that more switching of organizational contexts in communication is associated with higher levels of stress. We describe the role of communication chains as performing alignment in multitasking and discuss the implications of our results.
2008	Effects of intelligent notification management on users and their tasks	We present a novel system for notification management and report results from two studies testing its performance and impact. The system uses statistical models to realize defer-to-breakpoint policies for managing notifications. The first study tested how well the models detect three types of breakpoints within novel task sequences. Results show that the models detect breakpoints reasonably well, but struggle to differentiate their type. Our second study explored effects of managing notifications with our system on users and their tasks. Results showed that scheduling notifications at breakpoints reduces frustration and reaction time relative to delivering them immediately. We also found that the relevance of notification content determines the type of breakpoint at which it should be delivered. The core concept of scheduling notifications at breakpoints fits well with how users prefer notifications to be managed. This indicates that users would likely adopt the use of notification management systems in practice.
2008	Attention by proxy? issues in audience awareness for webcasts to distributed groups	Instructor/student interaction in e-learning environments can positively impact both student learning and instructor satisfaction. In online webcast lectures, however, interaction can be difficult because instructors lack basic awareness information about their remote students. Our goal is to better understand the kinds of awareness information that instructors should have if they are to interact frequently and effectively with their students in e-learning environments. We conducted an exploratory study -- via interviews and observations -- of instructor attention in face-to-face classrooms at a large university. Our results imply that a webcast system should provide instructors with overview and detailed data about their students, but that this detailed information should not be displayed publicly.
2008	The cost of interrupted work: more speed and stress	We performed an empirical study to investigate whether the context of interruptions makes a difference. We found that context does not make a difference but surprisingly, people completed interrupted tasks in less time with no difference in quality. Our data suggests that people compensate for interruptions by working faster, but this comes at a price: experiencing more stress, higher frustration, time pressure and effort. Individual differences exist in the management of interruptions: personality measures of openness to experience and need for personal structure predict disruption costs of interruptions. We discuss implications for how system design can support interrupted work.
2008	Usability evaluation considered harmful (some of the time)	Current practice in Human Computer Interaction as encouraged by educational institutes, academic review processes, and institutions with usability groups advocate usability evaluation as a critical part of every design process. This is for good reason: usability evaluation has a significant role to play when conditions warrant it. Yet evaluation can be ineffective and even harmful if naively done 'by rule' rather than 'by thought'. If done during early stage design, it can mute creative ideas that do not conform to current interface norms. If done to test radical innovations, the many interface issues that would likely arise from an immature technology can quash what could have been an inspired vision. If done to validate an academic prototype, it may incorrectly suggest a design's scientific worthiness rather than offer a meaningful critique of how it would be adopted and used in everyday practice. If done without regard to how cultures adopt technology over time, then today's reluctant reactions by users will forestall tomorrow's eager acceptance. The choice of evaluation methodology - if any - must arise from and be appropriate for the actual problem or research question under consideration.
2008	Exploring the use of tangible user interfaces for human-robot interaction: a comparative study	In this paper we suggest the use of tangible user interfaces (TUIs) for human-robot interaction (HRI) applications. We discuss the potential benefits of this approach while focusing on low-level of autonomy tasks. We present an experimental robotic interaction test bed to support our investigation. We use the test bed to explore two HRI-related task-sets: robotic navigation control and robotic posture control. We discuss the implementation of these two task-sets using an AIBO" robot dog. Both tasks were mapped to two different robotic control interfaces: keypad interface which resembles the interaction approach currently common in HRI, and a gesture input mechanism based on Nintendo Wii" game controllers. We discuss the interfaces implementation and conclude with a detailed user study for evaluating these different HRI techniques in the two robotic tasks-sets.
2008	Precision timing in human-robot interaction: coordination of head movement and utterance	As research over the last several decades has shown that non-verbal actions such as face and head movement play a crucial role in human interaction, such resources are also likely to play an important role in human-robot interaction. In developing a robotic system that employs embodied resources such as face and head movement, we cannot simply program the robot to move at random but rather we need to consider the ways these actions may be timed to specific points in the talk. This paper discusses our work in developing a museum guide robot that moves its head at interactionally significant points during its explanation of an exhibit. In order to proceed, we first examined the coordination of verbal and non-verbal actions in human guide-visitor interaction. Based on this analysis, we developed a robot that moves its head at interactionally significant points in its talk. We then conducted several experiments to examine human participant non-verbal responses to the robot's head and gaze turns. Our results show that participants are likely to display non-verbal actions, and do so with precision timing, when the robot turns its head and gaze at interactionally significant points than when the robot turns its head at not interactionally significant points. Based on these findings, we propose several suggestions for the design of a guide robot.
2008	The see-Puck: a platform for exploring human-robot relationships	We present the see-Puck , a round display module that extends an open robot platform, the e-Puck. It holds 148 LEDs (light emitting diodes) to enable the presentation of eye-catching visual animated patterns, while keeping hardware costs and energy consumption at a minimum. The see-Puck was a result of a study of future robot applications, where relationship and interaction qualities found in owners of unusual pets (e.g. spiders, snakes, and lizards) were transferred to the robotic domain. In our first proof-of-concept application, humans and robots can engage in a playful open ended interaction. We argue that open interactive robot platforms such as the see-Puck point to opportunities not only in robotics but also future user interfaces and ubiquitous computing.
2008	Explore! possibilities and challenges of mobile learning	This paper reports the experimental studies we have performed to evaluate Explore!, an m-learning system that supports middle school students during a visit to an archaeological park. It exploits a learning technique called excursion-game, whose aim is to help students to acquire historical notions while playing and to make archaeological visits more effective and exciting. In order to understand the potentials and limitations of Explore!, our studies compare the experience of playing the excursion-game with and without technological support. The design and evaluation of Explore! have provided knowledge on the advantages and pitfalls of m-learning that may be instrumental in informing the current debate on e-learning.
2008	Pause, predict, and ponder: use of narrative videos to improve cultural discussion and learning	Previous research shows that video viewing (a frequent activity in language courses) is more effective when students receive guidance. We investigate how to support students in an on-line environment in acquiring cultural knowledge and intercultural competence by viewing clips from feature films from the target culture. To test the effectiveness of a set of attention-focusing techniques (pause-predict-ponder), some of which have been shown to be effective in other contexts, we created ICCAT, a simple tutor that enhances an existing classroom model for the development of intercultural competence. We ran a study in two French Online classrooms with 35 participants, comparing ICCAT versions with and without attention-focusing techniques. We found that the addition of the pause-predict-ponder seemed to guide students in acquiring cultural knowledge and significantly increased students' ability to reason from an intercultural perspective. We discuss possible implications for intelligent tutoring systems in such difficult and ill-defined domains.
2008	WallCology: designing interaction affordances for learner engagement in authentic science inquiry	The broadening array of technologies available to support the design of classroom activity has the potential to reshape science learning in schools. This paper presents a ubiquitous computing application, WallCology, which situates a virtual ecosystem within the unseen space of classroom walls, presenting affordances for science learners to engage in investigations of ecological phenomena. Motivated by a desire to foster authenticity in classroom science inquiry, WallCology extends the "embedded phenomena" framework in three ways: by enabling collaborative investigations among distributed work teams, by increasing the physicality of investigation activities, and by expanding the loci of activity sites. Pilot studies in two urban classrooms provide qualified support for the effectiveness of WallCology in promoting more authentic inquiry practices, content learning, and attitudes regarding scientific investigations.
2008	Measuring trust in wi-fi hotspots	Pervasive systems provide services that are situated within specific contexts. An everyday example of this is Wi-Fi hotspots. Factors such as branding and presentation are known to affect whether users are prepared to invest trust in services, but little is known about trust in situated services. This paper describes an experiment to measure de facto trust in Wi-Fi hotspots in public places, as opposed to examining trust behaviour in a simulated lab setting. We investigated two hypotheses about the effect of location-specific images in the hotspot's pages on trust behaviours, compared to images of non-specific locations. We found a significant result which confirms that decisions to access an unfamiliar Wi-Fi hotspot can be affected by location-relevant images.
2008	Undercover: authentication usable in front of prying eyes	A number of recent scams and security attacks (phishing, spyware, fake terminals, ...) hinge on a crook's ability to observe user behavior. In this paper, we describe the design, implementation, and evaluation of a novel class of user authentication systems that are resilient to observation attacks. Our proposal is the first to rely on the human ability to simultaneously process multiple sensory inputs to authenticate, and is resilient to most observation attacks. We build a prototype based on user feedback gained through low fidelity tests. We conduct a within-subjects usability study of the prototype with 38 participants, which we complement with a security analysis. Our results show that users can authenticate within times comparable to that of graphical password schemes, with relatively low error rates, while being considerably better protected against observation attacks. Our design and evaluation process allows us to outline design principles for observation-resilient authentication systems.
2008	Access control by testing for shared knowledge	Controlling the privacy of online content is difficult and often confusing. We present a social access control where users devise simple questions testing shared knowledge instead of constructing authenticated accounts and explicit access control rules. We implemented a prototype and conducted studies to explore the context of photo sharing security, gauge the difficulty of creating shared knowledge questions, measure their resilience to adversarial attack, and evaluate user ability to understand and predict this resilience.
2008	Love and authentication	Passwords are ubiquitous, and users and service providers alike rely on them for their security. However, good passwords may sometimes be hard to remember. For years, security practitioners have battled with the dilemma of how to authenticate people who have forgotten their passwords. Existing approaches suffer from high false positive and false negative rates, where the former is often due to low entropy or public availability of information, whereas the latter often is due to unclear or changing answers, or ambiguous or fault prone entry of the same. Good security questions should be based on long-lived personal preferences and knowledge, and avoid publicly available information. We show that many of the questions used by online matchmaking services are suitable as security questions. We first describe a new user interface approach suitable to such security questions that is offering a reduced risks of incorrect entry. We then detail the findings of experiments aimed at quantifying the security of our proposed method.
2008	Reality-based interaction: a framework for post-WIMP interfaces	We are in the midst of an explosion of emerging human-computer interaction techniques that redefine our understanding of both computers and interaction. We propose the notion of Reality-Based Interaction (RBI) as a unifying concept that ties together a large subset of these emerging interaction styles. Based on this concept of RBI, we provide a framework that can be used to understand, compare, and relate current paths of recent HCI research as well as to analyze specific interaction designs. We believe that viewing interaction through the lens of RBI provides insights for design and uncovers gaps or opportunities for future research.
2008	Inflatable mouse: volume-adjustable mouse with air-pressure-sensitive input and haptic feedback	Inflatable Mouse is a volume-adjustable user interface. It can be inflated up to the volume of a familiar mouse, but be deflated and stored flat in a PC card slot of a laptop computer when not in use. Inflatable Mouse functions just like a typical mouse; moreover, it provides new interaction techniques by sensing the air pressure in the balloon of the mouse. It also addresses some issues associated with pressure-sensing interactions such as the lack of bi-directional input and the lack of effective feedback. Moreover, it can be used as both a control tool and a display tool. In this paper, the design of an Inflatable Mouse prototype is described and potential application scenarios such as zooming in/out and fast scrolling using pressure control are explained. We also discuss the potential use of Inflatable Mouse as an emotional communication tool.
2008	MightyTrace: multiuser tracking technology on lc-displays	In this paper, we present a new technology to perform multi Tangible User Interface (TUI) tracking on standard LC-displays. A lot of existing technologies for tangible user interface tracking use back- or front-projection setups, but they suffer from poor image quality, shadow casting, non-ergonomic interaction, and/or large installations. Thus, we introduce a principle that allows using the InfrActables' technology on a large LC-display. It combines simultaneous multiuser input on a display with the advantages of a large flat screen. We use infrared photodiodes (IR-LEDs) mounted behind the display's LC-matrix to track infrared diodes in front of the screen. After initial tests concerning the infrared transparency and sensor characteristics, we developed a proof of concept consisting of 384 sensors, which are addressed through a modular master-slave circuit. Using several interaction devices, multiuser interaction is possible.
2008	Quickdraw: the impact of mobility and on-body placement on device access time	We investigate the effect of placement and user mobility on the time required to access an on-body interface. In our study, a wrist-mounted system was significantly faster to access than a device stored in the pocket or mounted on the hip. In the latter two conditions, 78\% of the time it took to access the device was spent retrieving the device from its holder. As mobile devices are beginning to include peripherals (for example, Bluetooth headsets and watches connected to a mobile phone stored in the pocket), these results may help guide interface designers with respect to distributing functions across the body between peripherals.
2008	Using tags to assist near-synchronous communication	In this work, we introduce the use of tags to support the near synchronous use of instant messaging. As a proof-of-concept, we developed a plug-in in Lotus Sametime, an enterprise IM client. Our plug-in supports tasks that do not need immediate attention and tasks that have deadlines. A trial deployment and survey shows that users can see the potential usefulness of such a tagging system in their IM communication. Furthermore, users rated our design intuitive and easy to use. Longer study is needed to explore communication norms that results from its use.
2008	Improving meeting capture by applying television production principles with audio and motion detection	Video recordings of meetings are often monotonous and tedious to watch. In this paper, we report on the design, implementation and evaluation of an automated meeting capture system that applies television production principles to capture and present videos of small group meetings in a compelling manner. The system uses inputs from a motion capture system and microphones to drive multiple pan-tilt-zoom cameras and uses heuristics to frame shots and cut between them. An evaluation of the system indicates that its performance approaches that of a professional crew while requiring significantly fewer human resources.
2008	Video browsing by direct manipulation	We present a method for browsing videos by directly dragging their content. This method brings the benefits of direct manipulation to an activity typically mediated by widgets. We support this new type of interactivity by: 1) automatically extracting motion data from videos; and 2) a new technique called relative flow dragging that lets users control video playback by moving objects of interest along their visual trajectory. We show that this method can outperform the traditional seeker bar in video browsing tasks that focus on visual content rather than time.
2008	DRAGON: a direct manipulation interface for frame-accurate in-scene video navigation	We present DRAGON, a direct manipulation interaction technique for frame-accurate navigation in video scenes. This technique benefits tasks such as professional and amateur video editing, review of sports footage, and forensic analysis of video scenes. By directly dragging objects in the scene along their movement trajectory, DRAGON enables users to quickly and precisely navigate to a specific point in the video timeline where an object of interest is in a desired location. Examples include the specific frame where a sprinter crosses the finish line, or where a car passes a traffic light. Through a user study, we show that DRAGON significantly reduces task completion time for in-scene navigation tasks by an average of 19-42\% compared to a standard timeline slider. Qualitative feedback from users is also positive, with multiple users indicating that the DRAGON interaction felt more natural than the traditional timeline slider for in-scene navigation.
2008	Handsaw: tangible exploration of volumetric data by direct cut-plane projection	Tangible User Interfaces are well-suited to handling three-dimensional data sets by direct manipulation of real objects in space, but current interfaces can make it difficult to look inside dense volumes of information. This paper presents the Handsaw, a system that detects a virtual cut-plane projected by an outstretched hand or laser-line directly on an object or space and reveals sectional data on an adjacent display. By leaving the hands free and using a remote display, these techniques can be shared between multiple users and integrated into everyday practice. The Handsaw has been prototyped for scientific visualizations in medicine, engineering and urban design. User evaluations suggest that using a hand is more intuitive while projected light is more precise than keyboard and mouse control, and the Handsaw system has the potential to be used effectively by novices and in groups.
2008	Do I live in a flood basin?: synthesizing ten thousand maps	The recent introduction of simple, web-based geographic visualization interfaces has unleashed a tidal wave of new geographic content now available on the Internet. There has been enormous attention on the development of data interchange standards and programming interfaces that make all this content interoperable, but far less thought about how the user experience should change when users have their choice of 10,000 maps. To inform the design of online mapping systems, we investigate the case of queries that require correlation of multiple maps---that is, discovery and synthesis of several map layers. We based our study on interviews with expert users of maps: archivists and librarians. This paper describes our user-task taxonomy distilled from these interviews, and presents MapSynthesizer, a prototype system that allows users to efficiently query, discover, and integrate many maps from a corpus of thousands.
2008	Integrating statistics and visualization: case studies of gaining clarity during exploratory data analysis	Although both statistical methods and visualizations have been used by network analysts, exploratory data analysis remains a challenge. We propose that a tight integration of these technologies in an interactive exploratory tool could dramatically speed insight development. To test the power of this integrated approach, we created a novel social network analysis tool, SocialAction , and conducted four long-term case studies with domain experts, each working on unique data sets with unique problems. The structured replicated case studies show that the integrated approach in SocialAction led to significant discoveries by a political analyst, a bibliometrician, a healthcare consultant, and a counter-terrorism researcher. Our contributions demonstrate that the tight integration of statistics and visualizations improves exploratory data analysis, and that our evaluation methodology for long-term case studies captures the research strategies of data analysts.
2008	Your place or mine?: visualization as a community component	Many Eyes is a web site that provides collaborative visualization services, allowing users to upload data sets, visualize them, and comment on each other's visualizations. This paper describes a first interview-based study of Many Eyes users, which sheds light on user motivation for creating public visualizations. Users talked about data for many reasons, from scientific research to political advocacy to hobbies. One consistent theme across these different scenarios is the use of visualizations in communication and collaborative practices. Collaboration and conversation, however, often took place outside the site, leaving no traces on Many Eyes itself. In other words, despite spurring significant social activity, Many Eyes is not so much an online community as a "community component" which users insert into pre-existing online social systems.
2008	Escape: a target selection technique using visually-cued gestures	Many mobile devices have touch-sensitive screens that people interact with using fingers or thumbs. However, such interaction is difficult because targets become occluded, and because fingers and thumbs have low input resolution. Recent research has addressed occlusion through visual techniques. However, the poor resolution of finger and thumb selection still limits selection speed. In this paper, we address the selection speed problem through a new target selection technique called Escape. In Escape, targets are selected by gestures cued by icon position and appearance. A user study shows that for targets six to twelve pixels wide, Escape performs at a similar error rate and at least 30\% faster than Shift, an alternative technique, on a similar task. We evaluate Escape's performance in different circumstances, including different icon sizes, icon overlap, use of color, and gesture direction. We also describe an algorithm that assigns icons to targets, thereby improving Escape's performance.
2008	Rubbing and tapping for precise and rapid selection on touch-screen displays	We introduce two families of techniques, rubbing and tapping, that use zooming to make possible precise interaction on passive touch screens, and describe examples of each. Rub-Pointing uses a diagonal rubbing gesture to integrate pointing and zooming in a single-handed technique. In contrast, Zoom-Tapping is a two-handed technique in which the dominant hand points, while the non-dominant hand taps to zoom, simulating multi-touch functionality on a single-touch display. Rub-Tapping is a hybrid technique that integrates rubbing with the dominant hand to point and zoom, and tapping with the non-dominant hand to confirm selection. We describe the results of a formal user study comparing these techniques with each other and with the well-known Take-Off and Zoom-Pointing selection techniques. Rub-Pointing and Zoom-Tapping had significantly fewer errors than Take-Off for small targets, and were significantly faster than Take-Off and Zoom-Pointing. We show how the techniques can be used for fluid interaction in an image viewer and in Google Maps.
2008	Graffiti vs. unistrokes: an empirical comparison	Unistrokes and Graffiti are stylus-based text entry techniques. While Unistrokes is recognized in academia, Graffiti is commercially prevalent in PDAs. Though numerous studies have investigated the usability of Graffiti , none exists to compare its long-term performance with that of Unistrokes . This paper presents a longitudinal study comparing entry speed, correction rate, stroke duration, and preparation (i.e., inter-stroke) time of these two techniques. Over twenty fifteen-phrase sessions, performance increased from 4.0 wpm to 11.4 wpm for Graffiti and from 4.1 wpm to 15.8 wpm for Unistrokes . Correction rates were high for both techniques. However, rates for Graffiti remained relatively consistent at 26\%, while those for Unistrokes decreased from 43\% to 16\%.
2008	The cone and the lazy bubble: two efficient alternatives between the point cursor and the bubble cursor	We evaluated two cursor designs in the continuum between the traditional point cursor and the bubble cursor by Grossman and Balakrishnan. The lazy bubble cursor expanded to envelop the closest target when the ratio of the distances to the closest and the second closest target was less than 1:2. In addition to this lazy behavior the cone cursor had a tail that stayed on the last enveloped target until the next target was enveloped. In an experiment with 18 participants we found that the bubble cursor was faster than our cursors that had smaller target activation areas but the difference remained very small. Of the bubble cursor variants the lazy bubble exhibited higher error rate than the other two. Thus, the winners on the objective metrics were the bubble cursor and the cone cursor. The lazy bubble cursor and the bubble cursor were preferred in subjective ratings.
2008	A bright green perspective on sustainable choices	We present a qualitative study of 35 United States households whose occupants have made significant accommodations to their homes and behaviors in order to be more environmentally responsible. Our goal is to inform the design of future sustainable technologies through an exploration of existing "green" lifestyles. We describe the motivations, practices, and experiences of the participants. The participants had diverse motivations ranging from caring for the Earth to frugal minimalism, and most participants also evidenced a desire to be unique. Most participants actively and consciously managed their homes and their daily practices to optimize their environmental responsibility. Their efforts to be environmentally responsible typically required significant dedication of time, attention, and other resources. As this level of commitment and desire to be unique may not generalize readily to the broader population, we discuss the importance of interactive technologies that influence surrounding infrastructure and circumstances in order to facilitate environmental responsibility.
2008	Breaking the disposable technology paradigm: opportunities for sustainable interaction design for mobile phones	We present a qualitative study of mobile phone ownership, replacement and disposal practices geared towards identifying design opportunities towards sustainable mobile phone interfaces. Our work investigates how people understand the lifespan of their phones, what factors, such as style, service contracts, and functionality, affect how they attribute value to their phones, and their awareness and actions regarding mobile phone sustainability. Our findings reveal the complexity of the actions and decision-making processes involved in phone ownership and replacement. We use these findings to present open areas for sustainable interaction design and generate seed ideas for designs and services to provoke thought and further exploration towards more sustainable mobile phone interfaces and practices.
2008	Sustainable millennials: attitudes towards sustainability and the material effects of interactive technologies	This paper describes the design and interprets the results of a survey of 435 undergraduate students concerning the attitudes of this mainly millennial population towards sustainability apropos of the material effects of information technologies. This survey follows from earlier work on notions of Sustainable Interaction Design (SID)---that is the perspective that sustainability can and should be a central focus within HCI. In so doing it advances to some degree the empirical resources needed to scaffold an understanding of the theory and principles of SID. The interpretations offered yield key insights about understanding different notions of what it means to be successful in a material sense to this population and specific design principles for creating interactive designs differently such that more sustainable behaviors are palatable to individuals of varying attitudes.
2008	Children attribute moral standing to a personified agent	This paper describes the results of a study conducted to answer two questions: (1) Do children generalize their understanding of distinctions between conventional and moral violations in human-human interactions to human-agent interactions? and (2) Does the agent's ability to make claims to its own moral standing influence children's judgments? A two condition, between- and within-subjects study was conducted in which 60 eight and nine year-old children interacted with a personified agent and observed a researcher interacting with the same agent. A semi-structured interview was conducted to investigate the children's judgments and reasoning about the observed interactions as well as hypothetical human-human interactions. Results suggest that children do distinguish between conventional and moral violations in human-agent interactions and that the ability of the agent to express harm and make claims to its own rights significantly increases children's likelihood of identifying an act against the agent as a moral violation.
2008	Mischief: supporting remote teaching in developing regions	Mischief is a system to support traditional classroom practices between a remote instructor and a group of collocated students. Meant for developing regions, each student in the classroom is given a mouse and these are connected to a single machine and shared display. We present observations of teaching practices in rural Chinese classrooms that led to Mischief's design. Mischief's user interface, with which scores of collocated students can interact simultaneously, supports anonymous responses, communicates focus of attention, and maintains the role of the instructor. Mischief is an extensible platform in which Microsoft PowerPoint slides, used commonly in developing regions, are made interactive. We setup a controlled environment where Mischief was used by classrooms of children with a remote math instructor. The results from the study provided insight into the usability and capacity of the system to support traditional classroom interactions. These observations were also the impetus for a redesign of several components of Mischief and are also presented. These findings contribute both a novel system for synchronous distance education in an affordable manner and design insights for creators of related systems.
2008	Playful toothbrush: ubicomp technology for teaching tooth brushing to kindergarten children	This case study in UbiComp technology and design presents a "Playful Toothbrush" system for assisting parents and teachers to motivate kindergarten children to learn proper and thorough brushing skills. The system includes a vision-based motion tracker that recognizes different tooth brushing strokes and a tooth brushing game in which the child cleans a virtual, mirror picture of his/her dirty teeth by physically brushing his/her own teeth. The user study results suggest that Playful Toothbrush enhances the effectiveness of kindergarten children in brushing their teeth, as measured by number of brushing strokes, duration of brushing and thoroughness of teeth cleaning.
2008	Collaborative editing for improved usefulness and usability of transcript-enhanced webcasts	One challenge in facilitating skimming or browsing through archives of on-line recordings of webcast lectures is the lack of text transcripts of the recorded lecture. Ideally, transcripts would be obtainable through Automatic Speech Recognition (ASR). However, current ASR systems can only deliver, in realistic lecture conditions, a Word Error Rate of around 45\% -- above the accepted threshold of 25\%. In this paper, we present the iterative design of a webcast extension that engages users to collaborate in a wiki-like manner on editing the ASR-produced imperfect transcripts, and show that this is a feasible solution for improving the quality of lecture transcripts. We also present the findings of a field study carried out in a real lecture environment investigating how students use and edit the transcripts.
2008	Collaborative interaction with volumetric displays	Volumetric displays possess a number of unique properties which potentially make them particularly suitable for collaborative 3D applications. Because such displays have only recently become available, interaction techniques for collaborative usage have yet to be explored. In this paper, we initiate this exploration. We present a prototype collaborative 3D model viewing application, which served as a platform for our explorations. We outline three design goals, discuss the key interaction issues which were encountered, and describe a suite of new techniques in detail. In initial user observation sessions, we found that our techniques allowed users to successfully complete a variety of 3D tasks. Furthermore, interviews with experts in potential usage domains indicated that the techniques we developed can serve as a baseline for future collaborative applications for volumetric displays.
2008	Multimodal collaborative handwriting training for visually-impaired people	"McSig" is a multimodal teaching and learning environ-ment for visually-impaired students to learn character shapes, handwriting and signatures collaboratively with their teachers. It combines haptic and audio output to realize the teacher's pen input in parallel non-visual modalities. McSig is intended for teaching visually-impaired children how to handwrite characters (and from that signatures), something that is very difficult without visual feedback. We conducted an evaluation with eight visually-impaired children with a pretest to assess their current skills with a set of character shapes, a training phase using McSig and then a post-test of the same character shapes to see if there were any improvements. The children could all use McSig and we saw significant improvements in the character shapes drawn, particularly by the completely blind children (many of whom could draw almost none of the characters before the test). In particular, the blind participants all expressed enjoyment and excitement about the system and using a computer to learn to handwrite.
2008	ArtLinks: fostering social awareness and reflection in museums	Technologies in museums often support learning goals, providing information about exhibits. However, museum visitors also desire meaningful experiences and enjoy the social aspects of museum-going, values ignored by most museum technologies. We present ArtLinks, a visualization with three goals: helping visitors make connections to exhibits and other visitors by highlighting those visitors who share their thoughts; encouraging visitors' reflection on the social and liminal aspects of museum-going and their expectations of technology in museums; and doing this with transparency , aligning aesthetically pleasing elements of the design with the goals of connection and reflection. Deploying ArtLinks revealed that people have strong expectations of technology as an information appliance. Despite these expectations, people valued connections to other people, both for their own sake and as a way to support meaningful experience. We also found several of our design choices in the name of transparency led to unforeseen tradeoffs between the social and the liminal.
2008	K-sketch: a 'kinetic' sketch pad for novice animators	Because most animation tools are complex and time-consuming to learn and use, most animations today are created by experts. To help novices create a wide range of animations quickly, we have developed a general-purpose, informal, 2D animation sketching system called K-Sketch. Field studies investigating the needs of animators and would-be animators helped us collect a library of usage scenarios for our tool. A novel optimization technique enabled us to design an interface that is simultaneously fast, simple, and powerful. The result is a pen-based system that relies on users' intuitive sense of space and time while still supporting a wide range of uses. In a laboratory experiment that compared K-Sketch to a more formal animation tool (PowerPoint), participants worked three times faster, needed half the learning time, and had significantly lower cognitive load with K-Sketch.
2009	Hand occlusion with tablet-sized direct pen input	We present results from an experiment examining the area occluded by the hand when using a tablet-sized direct pen input device. Our results show that the pen, hand, and forearm can occlude up to 47\% of a 12 inch display. The shape of the occluded area varies between participants due to differences in pen grip rather than simply anatomical differences. For the most part, individuals adopt a consistent posture for long and short selection tasks. Overall, many occluded pixels are located higher relative to the pen than previously thought. From the experimental data, a five-parameter scalable circle and pivoting rectangle geometric model is presented which captures the general shape of the occluded area relative to the pen position. This model fits the experimental data much better than the simple bounding box model often used implicitly by designers. The space of fitted parameters also serves to quantify the shape of occlusion. Finally, an initial design for a predictive version of the model is discussed.
2009	Text entry performance of state of the art unconstrained handwriting recognition: a longitudinal user study	We report on a longitudinal study of unconstrained handwriting recognition performance. After 250 minutes of practice, participants had a mean text entry rate of 24.1 wpm. For the first four hours of usage, entry and error rates of handwriting recognition are about the same as for a baseline QWERTY software keyboard. Our results reveal that unconstrained handwriting is faster than what was previously assumed in the text entry literature.
2009	Wetpaint: scraping through multi-layered images	We introduce a technique for exploring multi-layered images by scraping arbitrary areas to determine meaningful relationships. Our system, called Wetpaint, uses perceptual depth cues to help users intuitively navigate between corresponding layers of an image, allowing a rapid assessment of changes and relationships between different views of the same area. Inspired by art diagnostic techniques, this tactile method could have distinct advantages in the general domain as shown by our user study. We propose that the physical metaphor of scraping facilitates the process of determining correlations between layers of an image because it compresses the process of planning, comparison and annotation into a single gesture. We discuss applications for geography, design, and medicine.
2009	Computer usage in daily life	In this paper we explore the use of computer at home. This work is based on the automatic recording of application focus data in natural situation from a wide representative panel of 661 households with 1,434 users at home over 19 months. To process these large-scale data, we build a two-level classification of PC applications describing the whole PC use. At the household level, we worked on computer usage temporality: we observed two strategies of PC usage reflecting a tension between synchronous and asynchronous usage profiles. At the individual level, we found out that software preferences and usage intensity are rather independent; therefore, we distinguished five specific profiles of users reflecting strong routine behaviors of computer usage at home. These observations tend to show the strength of routine behaviors in computer usage.
2009	Of social television comes home: a field study of communication choices and practices in tv-based text and voice chat	Social television applications have emerged as a potentially valuable convergence of media and communication, but questions remain about the utility and nature of the communication experiences they will provide. We present our study of STV3, an application that adds freeform text and voice chat capabilities to the conventional television-viewing experience. We conducted an in-depth field study of STV3 to understand how friends integrate communication through social television into their lives. Our results reveal users' choices of communication modality, their topics of conversation, and the sense of connectedness that was fostered through their use of STV3. Our findings indicate that participants overwhelmingly preferred text chat to voice chat, and that they often communicated about topics unrelated to the television content.
2009	Supporting the social uses of television: sociability heuristics for social tv	Various social television systems and applications, enabling remote communication and interaction between viewers, are currently in development. Although usability guidelines exist for interactive television to ensure a usable system, there are no sociability guidelines for designing or evaluating the social interaction these systems enable. In this paper we present twelve sociability heuristics for evaluating social TV, based on several user studies with social TV systems.
2009	An elementary social information foraging model	User interfaces and information systems have become increasingly social in recent years, aimed at supporting the decentralized, cooperative production and use of content. A theory that predicts the impact of interface and interaction designs on such factors as participation rates and knowledge discovery is likely to be useful. This paper reviews a variety of observed phenomena in social information foraging and sketches a framework extending Information Foraging Theory towards making predictions about the effects of diversity, interference, and cost-of-effort on performance time, participation rates, and utility of discoveries.
2009	Remembrance of things tagged: how tagging effort affects tag production and human memory	We developed a low-effort interaction method called Click2Tag for social bookmarking. Information foraging theory predicts that the production of tags will increase as the effort required to do so is lowered, while the amount of time invested decreases. However, models of human memory suggest that changes in the tagging process may affect subsequent human memory for the tagged material. We compared (1) low-effort tagging by mouse-clicking (Click2Tag), (2) traditional tagging by typing (type-to-tag), and (3) baseline, no tagging conditions. Our results suggest that (a) Click2Tag increases tagging rates, (b) Click2Tag improves recognition of facts from the tagged text when compared to type-to-tag, and (c) Click2Tag is comparable to the no-tagging baseline condition on recall measures. Results suggest that tagging by clicking strengthens the memory traces by repeated readings of relevant words in the text and, thus, improves recognition.
2009	Signpost from the masses: learning effects in an exploratory social tag search browser	Social tagging arose out of the need to organize found content that is worth revisiting. A significant side effect has been the use of social tagging sites as navigational signposts for interesting content. The collective behavior of users who tagged contents seems to offer a good basis for exploratory search interfaces, even for users who are not using social bookmarking sites. In this paper, we present the design of a tag-based exploratory system and detail an experiment in understanding its effectiveness. The tag-based search system allows users to utilize relevance feedback on tags to indicate their interest in various topics, enabling rapid exploration of the topic space. The experiment shows that the system seems to provide a kind of scaffold for users to learn new topics.
2009	The people-prototype problem: understanding the interaction between prototype format and user group	When gathering feedback about an envisioned system, prototypes communicate design ideas to user groups. However, it is unclear how user responses are affected by prototype format. We conducted a 2x2 quasi-experiment (video /storyboard format x older and younger user groups) to test for an interaction between prototype format and user group. We found a significant interaction between prototype format and responses across user groups. Our results indicate that differences in user responses can be misinterpreted as the result of user group characteristics. We advise using multiple prototype formats to counteract a 'media effect'. Alternatively, we advise using storyboards for a smaller 'media effect'.
2009	Accounting for diversity in subjective judgments	In this paper we argue against averaging as a common practice in the analysis of subjective attribute judgments, both across and within subjects. Previous work has raised awareness of the diversity between individuals' perceptions. In this paper it will furthermore become apparent that such diversity can also exist within a single individual, in the sense that different attribute judgments from a subject may reveal different, complementary, views. A Multi-Dimensional Scaling approach that accounts for the diverse views on a set of stimuli is proposed and its added value is illustrated using published data. We will illustrate that the averaging analysis provides insight to only 1/6th of the total number of attributes in the example dataset. The proposed approach accounts for more than double the information obtained from the average model, and provides richer and semantically diverse views on the set of stimuli.
2009	A survey of software learnability: metrics, methodologies and guidelines	It is well-accepted that learnability is an important aspect of usability, yet there is little agreement as to how learnability should be defined, measured, and evaluated. In this paper, we present a survey of the previous definitions, metrics, and evaluation methodologies which have been used for software learnability. Our survey of evaluation methodologies leads us to a new question-suggestion protocol, which, in a user study, was shown to expose a significantly higher number of learnability issues in comparison to a more traditional think-aloud protocol. Based on the issues identified in our study, we present a classification system of learnability issues, and demonstrate how these categories can lead to guidelines for addressing the associated challenges.
2009	Undo and erase events as indicators of usability problems	One approach to reducing the costs of usability testing is to facilitate the automatic detection of critical incidents: serious breakdowns in interaction that stand out during software use. This research evaluates the use of undo and erase events as indicators of critical incidents in Google SketchUp (a 3D-modeling application), measuring an indicator's usefulness by the numbers and types of usability problems discovered. We compared problems identified using undo and erase events to problems identified using the user-reported critical incident technique [Hartson and Castillo 1998]. In a within-subjects experiment with 35 participants, undo and erase episodes together revealed over 90\% of the problems rated as severe, several of which would not have been discovered by self-report alone. Moreover, problems found by all three methods were rated as significantly more severe than those identified by only a subset of methods. These results suggest that undo and erase events will serve as useful complements to user-reported critical incidents for low cost usability evaluation of creation-oriented applications like SketchUp.
2009	Cultural difference and adaptation of communication styles in computer-mediated group brainstorming	Supporting creativity via collaborative group brainstorming is a prevalent practice in organizations. Today's technology makes it easy for international and intercultural group members to brainstorm together remotely, but surprisingly little is known about how culture and medium shape the underlying brainstorming process. In a laboratory study, we examined the influences of individual cultural background (American versus Chinese), group cultural composition (same- versus mixed-culture groups), and communication medium (text-only versus video-enabled chatrooms) on group brainstorming conversations. Cultural differences and adaptation in conversational talkativeness and responsiveness were identified. The text-only medium reduced cultural differences in talkativeness. Working in a mixed-culture group led to cultural adaptation in the communication style of Chinese but not American participants. We discuss implications for international group brainstorming.
2009	Difficulties in establishing common ground in multiparty groups using machine translation	When people communicate in their native languages using machine translation, they face various problems in constructing common ground. This study investigates the difficulties of constructing common ground when multiparty groups (consisting of more than two language communities) communicate using machine translation. We compose triads whose members come from three different language communities--China, Korea, and Japan--and compare their referential communication under two conditions: in their shared second language (English) and in their native languages using machine translation. Consequently, our study suggests the importance of not only grounding between speaker and addressee but also grounding between addressees in constructing effective machine-translation-mediated communication. Furthermore, to successfully build common ground between addressees, it seems important for them to be able to monitor what is going on between a speaker and other addressees.
2009	Resilience through technology adoption: merging the old and the new in Iraq	Citizen response to disaster has begun to receive attention in the CHI community but little attention has so far been given to how citizens use technology to adapt when their country is at war. We report on an ethnographic interview study of how technology was adopted and used by citizens to be resilient during wartime. We interviewed 45 Iraqi citizens experiencing the current Iraq war. Based on our data we identified properties of resilience: reconfiguring social networks, self-organization, redundancy, proactive practices, and repairing trust in information. Technology supported people in being resilient by enabling them to control identity, to collaborate in travel, to create an organizational memory, and to provide alternative sources of news and information. As people adopted and used technology to be resilient we found a merging of old and new cultural practices. We discuss these systemic changes and describe implications for how technology can support people in being resilient in disrupted environments.
2009	Scientometric analysis of the CHI proceedings	The CHI conference has grown rapidly over the last 26 years. We present a quantitative analysis on the countries and organizations that contribute to its success. Only 7.8 percent of the countries are responsible for 80 percent of the papers in the CHI proceedings, and the USA is clearly the country with most papers. But the success of a country or organization does not depend only on the number of accepted papers, but also on their quality. We present a ranking of countries and organizations based on the h index, an indicator that tries to balance the quantity and quality of scientific output based on a bibliometric analysis. The bibliometric analysis also allowed us to demonstrate the difficulty of judging quality. The papers acknowledged by the best paper award committee were not cited more often than a random sample of papers from the same years. The merit of the award is therefore unclear, and it might be worthwhile to allow the visitor to the conference to vote for the best paper.
2009	From interaction to trajectories: designing coherent journeys through user experiences	The idea of interactional trajectories through interfaces has emerged as a sensitizing concept from recent studies of tangible interfaces and interaction in museums and galleries. We put this concept to work as a lens to reflect on published studies of complex user experiences that extend over space and time and involve multiple roles and interfaces. We develop a conceptual framework in which trajectories explain these user experiences as journeys through hybrid structures, punctuated by transitions, and in which interactivity and collaboration are orchestrated. Our framework is intended to sensitize future studies, help distill craft knowledge into design guidelines and patterns, identify technology requirements, and provide a boundary object to connect HCI with Performance Studies.
2009	Understanding, scoping and defining user experience: a survey approach	Despite the growing interest in user experience (UX), it has been hard to gain a common agreement on the nature and scope of UX. In this paper, we report a survey that gathered the views on UX of 275 researchers and practitioners from academia and industry. Most respondents agree that UX is dynamic, context-dependent, and subjective. With respect to the more controversial issues, the authors propose to delineate UX as something individual (instead of social) that emerges from interacting with a product, system, service or an object. The draft ISO definition on UX seems to be in line with the survey findings, although the issues of experiencing anticipated use and the object of UX will require further explication. The outcome of this survey lays ground for understanding, scoping, and defining the concept of user experience.
2009	User experience over time: an initial framework	A recent trend in Human-Computer Interaction (HCI) research addresses human needs that go beyond the instrumental, resulting in an increasing body of knowledge about how users form overall evaluative judgments on the quality of interactive products. An aspect largely neglected so far is that of temporality, i.e. how the quality of users' experience develops over time. This paper presents an in-depth, five-week ethnographic study that followed 6 individuals during an actual purchase of the Apple iPhone". We found prolonged use to be motivated by different qualities than the ones that provided positive initial experiences. Overall, while early experiences seemed to relate mostly to hedonic aspects of product use, prolonged experiences became increasingly more tied to aspects reflecting how the product becomes meaningful in one's life. Based on the findings, we promote three directions for CHI practice: designing for meaningful mediation, designing for daily rituals, and designing for the self.
2009	Computer help at home: methods and motivations for informal technical support	Prior research suggests that people may ask their family and friends for computer help. But what influences whether and how a "helper" will provide help? To answer this question, we conducted a qualitative investigation of people who participated in computer support activities with family and friends in the past year. We describe how factors including maintenance of one's personal identity as a computer expert and accountability to one's social network determine who receives help and the quality of help provided. We also discuss the complex, fractured relationship between the numerous stakeholders involved in the upkeep of home computing infrastructures. Based on our findings, we provide implications for the design of systems to support informal help-giving in residential settings.
2009	Extraordinary computing: religion as a lens for reconsidering the home	We present results from a study examining how American Protestant Christians' faith affects their domestic life. There are two contributions of this work for the HCI community. First, we provide empirical evidence demonstrating how topics of interest to HCI researchers (e.g., material artifacts, routines, and ICT use) are used for religious purposes. Our findings show how Christians distinguish these aspects of domestic life from their secular counterparts. Second, we use our findings to reflect on current directions of future domestic ICT applications. Specifically, we critically evaluate the "problem solving approaches dominating the design of future technologies, and present extraordinary computing or systems that promote and honor the special value accorded to some aspects of domestic life.
2009	Facts or friends?: distinguishing informational and conversational questions in social Q&A sites	Tens of thousands of questions are asked and answered every day on social question and answer (Q&A) Web sites such as Yahoo Answers. While these sites generate an enormous volume of searchable data, the problem of determining which questions and answers are archival quality has grown. One major component of this problem is the prevalence of conversational questions, identified both by Q&A sites and academic literature as questions that are intended simply to start discussion. For example, a conversational question such as "do you believe in evolution?" might successfully engage users in discussion, but probably will not yield a useful web page for users searching for information about evolution. Using data from three popular Q&A sites, we confirm that humans can reliably distinguish between these conversational questions and other informational questions, and present evidence that conversational questions typically have much lower potential archival value than informational questions. Further, we explore the use of machine learning techniques to automatically classify questions as conversational or informational, learning in the process about categorical, linguistic, and social differences between different question types. Our algorithms approach human performance, attaining 89.7\% classification accuracy in our experiments.
2009	mimir: a market-based real-time question and answer service	Community-based question and answer (Q&A) systems facilitate information exchange and enable the creation of reusable knowledge repositories. While these systems are growing in usage and are changing how people find and share information, current designs are inefficient, wasting the time and attention of their users. Furthermore, existing systems do not support signaling and screening of joking and non-serious questions. Coupling Q&A services with instant and text messaging for faster questions and answers may exacerbate these issues, causing Q&A services to incur high interruption costs on their users. In this paper we present the design and evaluation of a market-based real-time Q&A system. We compared its use to a similar Q&A system without a market. We found that while markets can reduce wasted resources by reducing the number of less important questions and low quality answers, it may also reduce the socially conducive questions and usages that are vital to sustaining a Q&A community.
2009	Questions in, knowledge in?: a study of naver's question answering community	Large general-purposed community question-answering sites are becoming popular as a new venue for generating knowledge and helping users in their information needs. In this paper we analyze the characteristics of knowledge generation and user participation behavior in the largest question-answering online community in South Korea, Naver Knowledge-iN. We collected and analyzed over 2.6 million question/answer pairs from fifteen categories between 2002 and 2007, and have interviewed twenty six users to gain insights into their motivations,roles, usage and expertise. We find altruism, learning, and competency are frequent motivations for top answerers to participate, but that participation is often highly intermittent. Using a simple measure of user performance, we find that higher levels of participation correlate with better performance. We also observe that users are motivated in part through a point system to build a comprehensive knowledge database. These and other insights have significant implications for future knowledge generating online communities.
2009	SmartPlayer: user-centric video fast-forwarding	In this paper we propose a new video interaction model called adaptive fast-forwarding to help people quickly browse videos with predefined semantic rules. This model is designed around the metaphor of scenic car driving, in which the driver slows down near areas of interest and speeds through unexciting areas. Results from a preliminary user study of our video player suggest the following: (1) the player should adaptively adjust the current playback speed based on the complexity of the present scene and predefined semantic events; (2) the player should learn user preferences about predefined event types as well as a suitable playback speed; (3) the player should fast-forward the video continuously with a playback rate acceptable to the user to avoid missing any undefined events or areas of interest. Furthermore, our user study results suggest that for certain types of video, our SmartPlayer yields better user experiences in browsing and fast-forwarding videos than existing video players' interaction models.
2009	Videolyzer: quality analysis of online informational video for bloggers and journalists	Tools to aid people in making sense of the information quality of online informational video are essential for media consumers seeking to be well informed. Our application, Videolyzer, addresses the information quality problem in video by allowing politically motivated bloggers or journalists to analyze, collect, and share criticisms of the information quality of online political videos. Our interface innovates by providing a fine-grained and tightly coupled interaction paradigm between the timeline, the time-synced transcript, and annotations. We also incorporate automatic textual and video content analysis to suggest areas of interest for further assessment by a person. We present an evaluation of Videolyzer looking at the user experience, usefulness, and behavior around the novel features of the UI as well as report on the collaborative dynamic of the discourse generated with the tool.
2009	What's next?: emergent storytelling from video collection	In the world of visual storytelling, narrative development relies on a particular temporal ordering of shots and sequences and scenes. Rarely is this ordering cast in stone. Rather, the particular ordering of a story reflects a myriad of interdependent decisions about the interplay of structure, narrative arc and character development. For storytellers, particularly those developing their narratives from large documentary archives, it would be helpful to have a visualization system partnered with them to present suggestions for the most compelling story path. We present Storied Navigation, a video editing system that helps authors compose a sequence of scenes that tell a story, by selecting from a corpus of annotated clips. The clips are annotated in unrestricted natural language. Authors can also type a story in unrestricted English, and the system finds possibilities for clips that best match high-level elements of the story. Beyond simple keyword matching, these elements can include the characters, emotions, themes, and story structure. Authors can also interactively replace existing scenes or predict the next scene to continue a story, based on these characteristics. Storied Navigation gives the author the feel of brainstorming about the story rather than simply editing the media.
2009	Mus ink : composing music through augmented drawing	We focus on the creative use of paper in the music composition process, particularly the interaction between paper and end-user programming. When expressing musical ideas, composers draw in a precise way, not just sketch. Working in close collaboration with composers, we designed Musink to provide them with a smooth transition between paper drawings and OpenMusic, a flexible music composition tool. Musink's built-in recognizers handle common needs, such as scoping and annotation. Users can also define new gestures and associate them with their own or predefined software functions. Musink supports semi-structured, delayed interpretation and serves as a customizable gesture browser, giving composers significant freedom to create their own, individualized composition languages and to experiment with music, on-paper and on-line.
2009	Passive photography from a creative perspective: If I would just shoot the same thing for seven days, it's like... What's the point?	This paper aims to contribute with an understanding of meaningful experiences of photography, to support reflection upon the design of future camera devices. We have conducted a study of a passive camera device called Sensecam, which previously has been investigated as a memory aid, a combination of life-logging and memory tool and as a resource for digital narratives. We take a creative perspective and show that even if a camera is designed to be forgotten in use (i.e. is worn as a necklace and takes pictures automatically) it can still be part of an engaging or active photographic experience. Because Sensecam is different from film cameras, camera phones and other digital cameras, it involves a different type of photographic experience, for example when moving through different social contexts and how the resulting pictures are appreciated. The findings stem from people who used the camera for a week. This is complemented with reflections from the researcher, who has been using the camera for a month.
2009	Urban pixels: painting the city with light	Urban environments are increasingly filled with digital display systems that are inflexible, flat, bounded, high-resolution, and unresponsive. In this paper, we explore the potential of physically instantiated pixels that enable flexible, reconfigurable, unbounded, low-resolution, and responsive urban displays. Urban Pixels are nodes in a wireless network of physical pixels for urban spaces. Each pixel unit includes a microcontroller, RF transceiver (433 MHz), LED module (ten bright, white LEDs), rechargeable Li-Ion battery pack, IR sensor and renewable energy source such as photo-voltaic cells. Two acrylic half-spheres (4-inch diameter) protect the components from the elements. No additional wiring is needed for communication and the units can be mounted individually to any surface. A small-scale prototype network of fifty Urban Pixels was displayed on a façade of Eden Court Theater in Inverness, Scotland from June 1 - June 7, 2008. The public was encouraged to change display patterns via SMS or to interact with individual units via flashlights. We observed and informally interviewed theater guests and passers-by interacting with the façade for several nights. Based on these results, we outline an exciting problem space for designing displays and lighting systems in cities.
2009	ESPranto SDK: an adaptive programming environment for tangible applications	This paper describes the ESPranto Software Development Kit, which supports the development of sensor/actuator based applications, most notably educational toys and games. It enables non-technical users, such as parents, teachers, game developers and psychologists, to specify applications by themselves. The SDK allows them to start off quickly with developing simple applications. Then, as their programming skills increase with experience, the SDK supports them to create more complex applications. This is achieved by offering a complete tool chain with one, consistent programming paradigm. Each link is a separate tool offering a tailored amount of flexibility and complexity. To ensure that users can understand the feedback the SDK provides them, it is given in terms of the tool currently used. Furthermore, by preventing runtime errors, a user can be sure a program will work correctly if it compiles. We validated the ESPranto SDK partially by tests, but mainly by monitoring users applying the SDK. In practice the ESPranto SDK indeed proved to meet its design goals for all of its intended users.
2009	Support for context-aware intelligibility and control	Intelligibility and control are important user concerns in context-aware applications. They allow a user to understand why an application is behaving a certain way, and to change its behavior. Because of their importance to end users, they must be addressed at an interface level. However, often the sensors or machine learning systems that users need to understand and control are created long before a specific application is built, or created separately from the application interface. Thus, supporting interface designers in building intelligibility and control into interfaces requires application logic and underlying infrastructure to be exposed in some structured fashion. As context-aware infrastructures do not provide generalized support for this, we extended one such infrastructure with Situations, components that appropriately exposes application logic, and supports debugging and simple intelligibility and control interfaces, while making it easier for an application developer to build context-aware applications and facilitating designer access to application state and behavior. We developed support for interface designers in Visual Basic and Flash. We demonstrate the usefulness of this support through an evaluation of programmers, an evaluation of the usability of the new infrastructure with interface designers, and the augmentation of three common context-aware applications.
2009	VIGO: instrumental interaction in multi-surface environments	This paper addresses interaction in multi-surface environments and questions whether the current application-centric approaches to user interfaces are adequate in this context, and presents an alternative approach based on instrumental interaction. The paper presents the VIGO (Views, Instruments, Governors and Objects) architecture and describes a prototype implementation. It then illustrates how to apply VIGO to support distributed interaction. Finally, it demonstrates how a classical Ubicomp interaction technique, Pick-and-Drop, can be easily implemented using VIGO.
2009	Ethnography considered harmful	We review the current status of ethnography in systems design. We focus particularly on new approaches to and understandings of ethnography that have emerged as the computer has moved out of the workplace. These seek to implement a different order of ethnographic study to that which has largely been employed in design to date. In doing so they reconfigure the relationship ethnography has to systems design, replacing detailed empirical studies of situated action with studies that provide cultural interpretations of action and critiques of the design process itself. We hold these new approaches to and understandings of ethnography in design up to scrutiny, with the purpose of enabling designers to appreciate the differences between new and existing approaches to ethnography in systems design and the practical implications this might have for design.
2009	A comprehensive study of frequency, interference, and training of multiple graphical passwords	Graphical password systems have received significant attention as one potential solution to the need for more usable authentication, but nearly all prior work makes the unrealistic assumption of studying a single password. This paper presents the first study of multiple graphical passwords to systematically examine frequency of access to a graphical password, interference resulting from interleaving access to multiple graphical passwords, and patterns of access while training multiple graphical passwords. We find that all of these factors significantly impact the ease of authenticating using multiple facial graphical passwords. For example, participants who accessed four different graphical passwords per week were ten times more likely to completely fail to authenticate than participants who accessed a single password once per week. Our results underscore the need for more realistic evaluations of the use of multiple graphical passwords, have a number of implications for the adoption of graphical password systems, and provide a new basis for comparing proposed graphical password systems.
2009	Real life challenges in access-control management	In this work we ask the question: what are the challenges of managing a physical or file system access-control policy for a large organization? To answer the question, we conducted a series of interviews with thirteen administrators who manage access-control policy for either a file system or a physical space. Based on these interviews we identified three sets of real-world requirements that are either ignored or inadequately addressed by technology: 1) policies are made/implemented by multiple people; 2) policy makers are distinct from policy implementers; and 3) access-control systems don't always have the capability to implement the desired policy. We present our interview results and propose several possible solutions to address the observed issues.
2009	Awareness, training and trust in interaction with adaptive spam filters	Even though adaptive (trainable) spam filters are a common example of systems that make (semi-)autonomous decisions on behalf of the user, trust in these filters has been underexplored. This paper reports a study of usage of spam filters in the daily workplace and user behaviour in training these filters (N=43). User observation, interview and survey techniques were applied to investigate attitudes towards two types of filters: a user-adaptive (trainable) and a rule-based filter. While many of our participants invested extensive effort in training their filters, training did not influence filter trust. Instead, the findings indicate that users' filter awareness and understanding seriously impacts attitudes and behaviour. Specific examples of difficulties related to awareness of filter activity and adaptivity are described showing concerns relevant to all adaptive and (semi-)autonomous systems that rely on explicit user feedback.
2009	Vibrapass: secure authentication based on shared lies	Authentication in public spaces is a risky task. Frauds on cash machines (ATMs) are not uncommon nowadays. The biggest group of attacks is observation attacks, which focus on recording the input done by the users. In this work, we present VibraPass, a system created to be resilient against observation attacks using tactile feedback provided by the users' own mobile devices. In this way, secret information is shared between the terminal and the users to add an over-head of 'lies' to the input which makes it hard for attackers to steal the real PIN or password. We present an evaluation, which shows that VibraPass has the potential to replace current authentication systems due to increased security combined with reasonable input speed and error rates.
2009	Graspables: grasp-recognition as a user interface	The Graspables project is an exploration of how measuring the way people hold and manipulate objects can be used as a user interface. As computational ability continues to be implemented in more and more objects and devices, new interaction methods need to be developed. The Graspables System is embodied by a physical set of sensors combined with pattern recognition software that can determine how users hold a device. The Graspables System has been implemented in two prototypes, the Bar of Soap and the Ball of Soap. Applications developed for these prototypes demonstrate the effectiveness of grasp-recognition as an interface in multiple scenarios.
2009	MicroRolls: expanding touch-screen input vocabulary by distinguishing rolls vs. slides of the thumb	The input vocabulary for touch-screen interaction on handhelds is dramatically limited, especially when the thumb must be used. To enrich that vocabulary we propose to discriminate, among thumb gestures, those we call MicroRolls, characterized by zero tangential velocity of the skin relative to the screen surface. Combining four categories of thumb gestures, Drags, Swipes, Rubbings and MicroRolls, with other classification dimensions, we show that at least 16 elemental gestures can be automatically recognized. We also report the results of two experiments showing that the roll vs. slide distinction facilitates thumb input in a realistic copy and paste task, relative to existing interaction techniques.
2009	Unravelling seams: improving mobile gesture recognition with visual feedback techniques	Gesture recognition is emerging as an engaging interaction technique in mobile scenarios, and high recognition rates promote user acceptance. Several factors influence recognition rates including the nature of the gesture set and the suitability of the gesture recognition algorithm. This work explores how seamfulness in gesture stroke visualization affects recognition rates. We present the results of a user evaluation of a gesture recognition system that shows that raw (seamful) visualization of low-delity gesture stroke data has recognition rates comparable to no feedback. Providing filtered (seamless) stroke visualization to the user, while retaining the un-filtered input data for recognition, resulted in a 34.9\% improvement in gesture recognition rate over raw stroke data. The results provide insights into the broader design space of seamful design, and identifies areas where seamlessness is advantageous.
2009	Where to locate wearable displays?: reaction time performance of visual alerts from tip to toe	Advances in electronics have brought the promise of wearable computers to near reality. Such systems can offer a highly personal and mobile information and communication infrastructure. Previous research has investigated where wearable computers can be located on the human body - critical for successful development and acceptance. However, for a location to be truly useful, it needs to not only be accessible for interaction, socially acceptable, comfortable and sufficiently stable for electronics, but also effective at conveying information. In this paper, we describe the results from a study that evaluated reaction time performance to visual stimuli at seven different body locations. Results indicate that there are numerous and statistically significant differences in the reaction time performance characteristics of these locations. We believe our findings can be used to inform the design and placement of future wearable computing applications and systems.
2009	Feed me: motivating newcomer contribution in social network sites	Social networking sites (SNS) are only as good as the content their users share. Therefore, designers of SNS seek to improve the overall user experience by encouraging members to contribute more content. However, user motivations for contribution in SNS are not well understood. This is particularly true for newcomers, who may not recognize the value of contribution. Using server log data from approximately 140,000 newcomers in Facebook, we predict long-term sharing based on the experiences the newcomers have in their first two weeks. We test four mechanisms: social learning, singling out, feedback, and distribution. In particular, we find support for social learning: newcomers who see their friends contributing go on to share more content themselves. For newcomers who are initially inclined to contribute, receiving feedback and having a wide audience are also predictors of increased sharing. On the other hand, singling out appears to affect only those newcomers who are not initially inclined to share. The paper concludes with design implications for motivating newcomer sharing in online communities.
2009	'Helpfulness' in online communities: a measure of message quality	Online communities displaying textual postings require measures to combat information overload. One popular approach is to ask participants whether or not messages are helpful in order to then guide others to interesting content. Adopting a well-established framework for assessing data quality, we examine the nature of "helpfulness."We study consumer reviews at Amazon.com, deriving 22 measures quantifying their textual properties, authors' reputations and product characteristics. Confirmatory factor analysis reveals five underlying quality dimensions representing reviewers' reputations in the community, the topical relevancy of the reviews, the ease of understanding them, their believability and objectivity. A correlation and regression analysis confirms that these dimensions are related to the helpfulness scores assigned by community participants. However, it also uncovers a strong relationship between the chronological ordering of reviews and helpfulness, which both community participants and designers should keep in mind when using this method of social navigation.
2009	The problem of conflicting social spheres: effects of network structure on experienced tension in social network sites	We propose that a fundamental property of human psychology, the need to maintain independent social spheres, imposes constraints on the use of social network sites (SNS). We particularly focus on the consequences of visibility of communications across social spheres, and we hypothesize that technological features of SNS may bring social spheres in conflict, thus leading to increased levels of online social tension. A survey study among Facebook users was conducted to test this hypothesis. Results showed that diversity of the Facebook network predicted online tension. Moreover, the number of kin in a Facebook network was a crucial component because it predicted online tension whereas number of work and social contacts did not. Further, evidence was found to support the idea that tension might impose an upper limit on network size. We conclude with a discussion of these findings and describe how they support the thrust of recent modifications to SNS designs.
2009	Comparing the use of tangible and graphical programming languages for informal science education	Much of the work done in the field of tangible interaction has focused on creating tools for learning; however, in many cases, little evidence has been provided that tangible interfaces offer educational benefits compared to more conventional interaction techniques. In this paper, we present a study comparing the use of a tangible and a graphical interface as part of an interactive computer programming and robotics exhibit that we designed for the Boston Museum of Science. In this study, we have collected observations of 260 museum visitors and conducted interviews with 13 family groups. Our results show that visitors found the tangible and the graphical systems equally easy to understand. However, with the tangible interface, visitors were significantly more likely to try the exhibit and significantly more likely to actively participate in groups. In turn, we show that regardless of the condition, involving multiple active participants leads to significantly longer interaction times. Finally, we examine the role of children and adults in each condition and present evidence that children are more actively involved in the tangible condition, an effect that seems to be especially strong for girls.
2009	Designers wanted: participation and the user experience in open source software development	We present design concepts and related mockups that support the user experience for projects hosted on CodePlex, an open source project hosting website. Rationale for the design concepts is grounded in the open source literature and a thirteen-week study with the CodePlex team. We propose that fostering ways to build trust, providing opportunities for merit, supporting crossover of work activities, and supporting user experience (UX) best practices in CodePlex will help dismantle the social and technological barriers for UX and encourage UX designer participation. We address UX designer motivation as a challenge for participation and conclude that the mockups presented are a first step in furthering the user experience in open source software development.
2009	Understanding how and why open source contributors use diagrams in the development of Ubuntu	Some of the most interesting differences between Open Source Software (OSS) development and commercial co-located software development lie in the communication and collaboration practices of these two groups of developers. One interesting practice is that of diagramming. Though well studied and important in many aspects of co-located software development (including communication and collaboration among developers), its role in OSS development has not been thoroughly studied. In this paper, we report our investigation on how and why Ubuntu contributors use diagrams in their work. Our study shows that diagrams are not actively used in many scenarios where they commonly would in co-located software development efforts. We describe differences in the use and practices of diagramming, their possible reasons, and present design considerations for potential systems aimed at better supporting diagram use in OSS development.
2009	Comparing usage of a large high-resolution display to single or dual desktop displays for daily work	With the ever increasing amount of digital information, users desire more screen real estate to process their daily computing work, and might well benefit from using a wall-size large high-resolution display instead of a desktop one. Unfortunately, we know very little about users' behaviors when using such a display for daily computing. We present a week-long study that investigates large display use in a personal desktop computing context by comparing it with single and dual desktop monitor use. Results show users' unanimous preference for using a large display: it facilitates multi-window and rich information tasks, enhances users' awareness of peripheral applications, and offers a more"immersive experience. Further, the data reveals distinct usage patterns in partitioning screen real estate and managing windows on a large display. Detailed analysis of these results provides insights into designing interaction techniques and window management systems more suited to a large display.
2009	DICE: designing conference rooms for usability	One of the core challenges now facing smart rooms is supporting realistic, everyday activities. While much research has been done to push forward the frontiers of novel interaction techniques, we argue that technology geared toward widespread adoption requires a design approach that emphasizes straightforward configuration and control, as well as flexibility. We examined the work practices of users of a large, multi-purpose conference room, and designed DICE, a system to help them use the room's capabilities. We describe the design process, and report findings about the system's usability and about people's use of a multi-purpose conference room.
2009	Arrow tag: a direction-key-based technique for rapidly selecting hyperlinks while gazing at a screen	Television sets and video game consoles equipped with a web browser have appeared, and we are now able to browse web pages on television screens. However, existing navigation techniques are too difficult in this situation. In this paper, we propose Arrow Tag, a new link selection technique for web browsers on TV. In this technique, sequences of arrow signs called Arrow Tags are assigned to the links of the web pages, so users can select the links by pushing the four direction keys a few times, while keeping her/his gaze fixed on the television screen. User studies show that Arrow Tag significantly outperforms the conventional techniques of Focus Move and Number Tag. Moreover, most participants preferred Arrow Tag over either Focus Move or Number Tag.
2009	What's this you say?: the use of local references on distant displays	This study explores how the design of visual display configurations relates to linguistic expressions. Twenty-five participants performed a series of object identification and narrative Description tasks on either a large wall-sized or small desktop display. Results revealed that during the Description tasks, large display users produced significantly greater rates of local deictic references than small display users, but in the identification tasks, the rates were similar for both large and small display users. Implications for the design of interactive technologies are discussed.
2009	It's not easy being green: understanding home computer power management	Although domestic computer use is increasing, most efforts to reduce energy use through improved power management have focused on computers in the workplace. We studied 20 households to understand how people use power management strategies on their home computers. We saw computers in the home, particularly desktop computers, are left on much more than they are actively used suggesting opportunities for economic and energy savings. However, for most of our participants, the economic incentives were too minor to motivate them to turn off devices when not in use, especially given other frustrations such as long boot up times. We suggest research directions for home computer power management that could help users be more green without having to dramatically change their home computing habits.
2009	UbiGreen: investigating a mobile tool for tracking and supporting green transportation habits	The greatest contributor of CO2 emissions in the average American household is personal transportation. Because transportation is inherently a mobile activity, mobile devices are well suited to sense and provide feedback about these activities. In this paper, we explore the use of personal ambient displays on mobile phones to give users feedback about sensed and self-reported transportation behaviors. We first present results from a set of formative studies exploring our respondents' existing transportation routines, willingness to engage in and maintain green transportation behavior, and reactions to early mobile phone "green" application design concepts. We then describe the results of a 3-week field study (N=13) of the UbiGreen Transportation Display prototype, a mobile phone application that semi-automatically senses and reveals information about transportation behavior. Our contributions include a working system for semi-automatically tracking transit activity, a visual design capable of engaging users in the goal of increasing green transportation, and the results of our studies, which have implications for the design of future green applications.
2009	Understanding why we preserve some things and discard others in the context of interaction design	This paper takes up the problem of understanding why we preserve some things passionately and discard others without thought. We briefly report on the theoretical literature relating to this question, both in terms of existing literature in HCI, as well as in terms of related literatures that can advance the understanding for the HCI community. We use this reading to refine our frameworks for understanding durability in digital artifice as an issue of sustainable interaction design in HCI. Next, we report in detail on our ongoing work in collecting personal inventories of digital artifice in the home context. We relate our prior and most current personal inventories collections to the framework that owes to our reading of the theoretical literature. Finally, we summarize the theoretical implications and findings of our personal inventories work in terms of implications for the design of digital artifice in a manner that is more durable.
2009	Empirical evaluation for finger input properties in multi-touch interaction	Current multi-touch interaction techniques typically only use the x-y coordinates of the human finger's contact with the screen. However, when fingers contact a touch-sensitive surface, they usually approach at an angle and cover a relatively large 2D area instead of a precise single point. In this paper, a Frustrated Total Internal Reflection (FTIR) based multi-touch device is used to collect the finger imprint data. We designed a series of experiments to explore human finger input properties and identified several useful properties such as contact area, contact shape and contact orientation which can be exploited to improve the performance of multi-touch selecting and pointing tasks. Based on the experimental results, we discuss some implications for the design of human finger input interfaces and propose several design prototypes which incorporate these implications. A set of raw data and several concrete recommendations which are useful for the research community are also presented.
2009	The design and evaluation of multi-finger mouse emulation techniques	We explore the use of multi-finger input to emulate full mouse functionality, such as the tracking state, three buttons, and chording. We first present the design space for such techniques, which serves as a guide for the systematic investigation of possible solutions. We then perform a series of pilot studies to come up with recommendations for the various aspects of the design space. These pilot studies allow us to arrive at a recommended technique, the SDMouse. In a formal study, the SDMouse was shown to significantly improve performance in comparison to previously developed mouse emulation techniques.
2009	User-defined gestures for surface computing	Many surface computing prototypes have employed gestures created by system designers. Although such gestures are appropriate for early investigations, they are not necessarily reflective of user behavior. We present an approach to designing tabletop gestures that relies on eliciting gestures from non-technical users by first portraying the effect of a gesture, and then asking users to perform its cause. In all, 1080 gestures from 20 participants were logged, analyzed, and paired with think-aloud data for 27 commands performed with 1 and 2 hands. Our findings indicate that users rarely care about the number of fingers they employ, that one hand is preferred to two, that desktop idioms strongly influence users' mental models, and that some commands elicit little gestural agreement, suggesting the need for on-screen widgets. We also present a complete user-defined gesture set, quantitative agreement scores, implications for surface technology, and a taxonomy of surface gestures. Our results will help designers create better gesture sets informed by user behavior.
2009	Improving visual search with image segmentation	People's ability to accurately locate target objects in images is severely affected by the prevalence of the sought objects. This negative effect greatly impacts critical real world tasks, such as baggage screening and cell slide pathology, in which target objects are rare. We present three novel image presentation techniques that are designed to improve visual search. Our techniques rely on the images being broken into image segments, which are then recombined or displayed in novel ways. The techniques and their underlying design reasoning are described in detail, and three experiments are presented that provide initial evidence that these techniques lead to better search performance in a simulated cell slide pathology task.
2009	PhotoScope: visualizing spatiotemporal coverage of photos for construction management	PhotoScope visualizes the spatiotemporal coverage of photos in a photo collection. It extends the standard photo browsing paradigm in two main ways: visualizing spatial coverage of photos, and indexing photos by a combination of spatial coverage, time, and content specifications. This approach enables users to browse and search space- and time-indexed photos more effectively. We designed PhotoScope specifically to address challenges in the construction management industry, where large photo collections are amassed to document project progress. These ideas may also apply to any photo collection that is spatially constrained and must be searched using spatial, temporal, and content criteria. We describe the design choices made when developing PhotoScope and the results of user evaluation.
2009	Graph sketcher: extending illustration to quantitative graphs	Scientists, engineers, and educators commonly need to make graphs that quickly illustrate quantitative ideas yet are not based on specific data sets. We call these graphs quantitative concept diagrams (QCDs). Existing charting and illustration programs make it possible to produce such graphs, but they are so time-consuming that users tend to sketch the graphs by hand instead. To reduce the cost of creating QCDs, we developed Graph Sketcher, a quantitative graphing tool that deeply integrates the data plotting capabilities of charting programs with the direct manipulation techniques of illustration programs. We show that our integrated interface substantially reduces the time needed to create QCDs, and we further show that real Graph Sketcher users both enjoy and take advantage of the interface improvements to create QCDs in a wide range of fields.
2009	SiteLens: situated visualization techniques for urban site visits	Urban designers and urban planners often conduct site visits prior to a design activity to search for patterns or better understand existing conditions. We introduce SiteLens, an experimental system and set of techniques for supporting site visits by visualizing relevant virtual data directly in the context of the physical site, which we call situated visualization. We address alternative visualization representations and techniques for data collection, curation, discovery, comparison, manipulation, and provenance. A real use scenario is presented and two iterations of evaluation with faculty and students from the Columbia University Graduate School of Architecture, Planning and Preservation provide directions and insight for further investigation.
2009	Design research as explanation: perceptions in the field	We report results from interviews with HCI design researchers on their perceptions of how their research relates to the more traditional scientific goal of providing explanations. Theories of explanation are prominent in the physical and natural sciences, psychology, the social sciences, and engineering. Little work though has so-far addressed the special case of how results from reflective design of interactive systems can help provide explanations. We found conceptions of explanation in design research to be broader and more inclusive than those commonly found in the philosophy of science. We synthesized concepts from the interviews into a framework which may help researchers understand how their contributions relate to both classical and emergent conceptions of explanation.
2009	Framing design in the third paradigm	This paper develops vocabulary to discuss the phenomena related to the new design paradigm, which considers designing as a situated and constructive activity of meaning making rather than as problem solving. The paper studies how design projects proceed from the fuzzy early phases towards the issues of central relevance to designing. A central concept is framing, and it is elaborated with examples from two case studies. Several aspects of framing are explicated, exploratory, anticipatory and social framing, and related concepts of 'focusing', 'priming', and 'grounding' are explained. The paper concludes that understanding designing as a situated and constructive making of meaning has bearings on how designing needs to be supported.
2009	Values as lived experience: evolving value sensitive design in support of value discovery	The Value Sensitive Design (VSD) methodology provides a comprehensive framework for advancing a value-centered research and design agenda. Although VSD provides helpful ways of thinking about and designing value-centered computational systems, we argue that the specific mechanics of VSD create thorny tensions with respect to value sensitivity. In particular, we examine limitations due to value classifications, inadequate guidance on empirical tools for design, and the ways in which the design process is ordered. In this paper, we propose ways of maturing the VSD methodology to overcome these limitations and present three empirical case studies that illustrate a family of methods to effectively engage local expressions of values. The findings from our case studies provide evidence of how we can mature the VSD methodology to mitigate the pitfalls of classification and engender a commitment to reflect on and respond to local contexts of design.
2009	Body and mind: a study of avatar personalization in three virtual worlds	An increasingly large number of users connect to virtual worlds on a regular basis to conduct activities ranging from gaming to business meetings. In all these worlds, users project themselves into the environment via an avatar: a 3D body which they control and whose appearance is often customizable. However, considering the prevalence of this form of embodiment, there is a surprising lack of data about how and why users customize their avatar, as well as how easy and satisfying the existing avatar creation tools are. In this paper, we report on a study investigating these issues through a questionnaire administered to more than a hundred users of three virtual worlds offering widely different avatar creation and customization systems (Maple Story, World of Warcraft, and Second Life). We illustrate the often-surprising choices users make when creating their digital representation and discuss the impact of our findings for the design of future avatar creation systems.
2009	Capturing and sharing memories in a virtual world	Virtual worlds (VWs) such as Second Life® (SL) contain a rich social culture where people engage in a multitude of experiences much like real life. With this comes the need to capture and share memories with others. To understand what tools people use to accomplish this and what limitations they may face, we conducted interviews with participants in SL. Our results identify two clusters of users - Casuals and Lifers - who differed in the ways in which they captured and shared memories. Here we describe the use of photos, landmarks, friend lists, and conversation logs. We also show how a lack of real life physical and social constraints in the VW affects user routines, and, in some cases, how it does not. This suggests design directions for memory tools in the VW and also real life that break the bounds of current everyday practice.
2009	In support of city exploration	The novel experience Anywhere allowed participants to explore an urban area, tying together information not normally available, new points of views and interaction embedded into physical places. Guided by 'unseen', on-the-street performers in an ongoing conversation maintained over mobile phones, they gained access to locative media and staged performances. Our analysis demonstrates how Anywhere produced engaging and uniquely personalised paths through a complex landscape of content, negotiated by the performer-participant pair around various conflicting constraints. We reflect our analysis through the lens of the key characteristics exhibited by mechanisms that support city exploration, before focussing on possible extensions to the technological support of teams of professional and amateur guides.
2009	Input-agreement: a new mechanism for collecting data using human computation games	Since its introduction at CHI 2004, the ESP Game has inspired many similar games that share the goal of gathering data from players. This paper introduces a new mechanism for collecting labeled data using "games with a purpose." In this mechanism, players are provided with either the same or a different object, and asked to describe that object to each other. Based on each other's descriptions, players must decide whether they have the same object or not. We explain why this new mechanism is superior for input data with certain characteristics, introduce an enjoyable new game called "TagATune" that collects tags for music clips via this mechanism, and present findings on the data that is collected by this game.
2009	Matchin: eliciting user preferences with an online game	Eliciting user preferences for large datasets and creating rankings based on these preferences has many practical applications in community-based sites. This paper gives a new method to elicit user preferences that does not ask users to tell what they prefer, but rather what a random person would prefer, and rewards them if their prediction is correct. We provide an implementation of our method as a two-player game in which each player is shown two images and asked to click on the image their partner would prefer. The game has proven to be enjoyable, has attracted tens of thousands of people and has already collected millions of judgments. We compare several algorithms for combining these relative judgments between pairs of images into a total ordering of all images and present a new algorithm to perform collaborative filtering on pair-wise relative judgments. In addition, we show how merely observing user preferences on a specially chosen set of images can predict a user's gender with high probability.
2009	Mixing it up: recommending collections of items	Recommender systems traditionally recommend individual items. We introduce the idea of collection recommender systems and describe a design space for them including 3 main aspects that contribute to the overall value of a collection: the value of the individual items, co-occurrence interaction effects, and order effects including placement and arrangement of items. We then describe an empirical study examining how people create mix tapes. The study found qualitative and quantitative evidence for order effects (e.g., first songs are rated higher than later songs; some songs go poorly together sequentially). We propose several ideas for research in this space, hoping to start a much longer conversation on collection recommender systems.
2009	Tabletop displays for small group study: affordances of paper and digital materials	In this paper we compare the affordances of presenting educational material on a tabletop display with presenting the same material using traditional paper handouts. Ten pairs of undergraduate students used digital or paper materials to prepare for exams during four one-hour study sessions over the course of a term. Students studying with the tabletop display solved problems on their own before resorting to answer keys and repeated activities more often than students studying with paper documents. We summarize study activities and discuss the benefits and drawbacks of each medium.
2009	WeSpace: the design development and deployment of a walk-up and share multi-surface visual collaboration system	We present WeSpace -- a collaborative work space that integrates a large data wall with a multi-user multi-touch table. WeSpace has been developed for a population of scientists who frequently meet in small groups for data exploration and visualization. It provides a low overhead walk-up and share environment for users with their own personal applications and laptops. We present our year-long effort from initial ethnographic studies, to iterations of design, development and user testing, to the current experiences of these scientists carrying out their collaborative research in the WeSpace. We shed light on the utility, the value of the multi-touch table, the manifestation, usage patterns and the changes in their workflow that WeSpace has brought about.
2009	CThru: exploration in a video-centered information space for educational purposes	We present CThru, a self-guided video-based educational environment in a large multi-display setting. We employ a video-centered approach, creating and combining multimedia contents of different formats with a story-telling education video. With the support of new display form factors in the environment, viewing a sequential educational video thread is replaced by the immersive learning experience of hands-on exploration and manipulation in a multi-dimensional information space. We demonstrate CThru with an animation clip in cellular biology, supplementing visible objects in the video with rich domain-specific multimedia information and interactive 3D models. We describe CThru's design rationale and implementation. We also discuss a pilot study and what it revealed with respect to CThru's interface and the usage pattern of the tabletop and the associated large wall display.
2009	Turning the tables: an interactive surface for vjing	In this paper we describe VPlay, a multi-touch tabletop application that allows users to mix and manipulate multiple video streams in real-time. Our aim is to explore how such an interactive surface can support and augment practices around VJing - a form of video performance art that is becoming increasingly popular in nightclubs and other music events. We conclude with observations from a field deployment, which highlight some initial thoughts and reflections on our design rationale.
2009	An experimental study of field dependency in altered Gz environments	Failure to address extreme environments constraints at the human-computer interaction level may lead to the commission of critical and potentially fatal errors. This experimental study addresses gaps in our current theoretical understanding of the impact of ±Gz accelerations and field dependency independency on task performance in human-computer interaction. It investigates the effects of ±Gz accelerations and field dependency independency on human performance in the completion of perceptual-motor tasks on a personal digital assistant (PDA). We report the results of a controlled experiment, conducted in an aerobatic aircraft under multiple ±Gz conditions, showing that cognitive style significantly impacts latency and accuracy in target acquisition for perceptual-motor tasks in altered ±Gz environments and propose design guidelines as countermeasures. Based on the results, we argue that developing design requirements taking into account cognitive differences in extreme environments will allow users to execute perceptual-motor tasks efficiently without unnecessarily increasing cognitive load and the probability of critical errors.
2009	Taking the time to care: empowering low health literacy hospital patients with virtual nurse agents	Ninety million Americans have inadequate health literacy, resulting in a reduced ability to read and follow directions in the healthcare environment. We describe an animated, empathic virtual nurse interface for educating and counseling hospital patients with inadequate health literacy in their hospital beds at the time of discharge. The development methodology, design rationale, and two iterations of user testing are described. Results indicate that hospital patients with low health literacy found the system easy to use, reported high levels of satisfaction, and most said they preferred receiving the discharge information from the agent over their doctor or nurse. Patients also expressed appreciation for the time and attention provided by the virtual nurse, and felt that it provided an additional authoritative source for their medical information.
2009	Evaluation of a tool-mounted guidance display for computer-assisted surgery	We attached a small LCD display and video camera to a surgical drill. The LCD shows the tool position with respect to a planned trajectory, overlaid on video captured by the camera. We performed a user study to determine whether such a tool-mounted guidance display yields faster and more accurate tool placement than the conventional guidance display on a separate computer monitor. Our study showed that the tool-mounted display provides better positional and angular accuracy than the conventional display but that the video camera provides no significant improvement in error.
2009	Towards human-centered support for indoor navigation	This paper presents a new perspective for the design of indoor navigation support. In contrast to technology oriented approaches coming from Context Awareness research, we argue for a wider focus that complements the technical question of providing precise indoor location with the development of more effective navigation practices based on technology available today. Starting from research on indoor navigation conducted with the Paris Fire Brigade, we present two design concepts aimed at supporting firefighters in creating and finding their own paths, together with some of the design strategies that informed the creation of these concepts.
2009	EnsembleMatrix: interactive visualization to support machine learning with multiple classifiers	Machine learning is an increasingly used computational tool within human-computer interaction research. While most researchers currently utilize an iterative approach to refining classifier models and performance, we propose that ensemble classification techniques may be a viable and even preferable alternative. In ensemble learning, algorithms combine multiple classifiers to build one that is superior to its components. In this paper, we present EnsembleMatrix, an interactive visualization system that presents a graphical view of confusion matrices to help users understand relative merits of various classifiers. EnsembleMatrix allows users to directly interact with the visualizations in order to explore and build combination models. We evaluate the efficacy of the system and the approach in a user study. Results show that users are able to quickly combine multiple classifiers operating on multiple feature sets to produce an ensemble classifier with accuracy that approaches best-reported performance classifying images in the CalTech-101 dataset.
2009	FacetLens: exposing trends and relationships to support sensemaking within faceted datasets	Previous research has shown that faceted browsing is effective and enjoyable in searching and browsing large collections of data. In this work, we explore the efficacy of interactive visualization systems in supporting exploration and sensemaking within faceted datasets. To do this, we developed an interactive visualization system called FacetLens, which exposes trends and relationships within faceted datasets. FacetLens implements linear facets to enable users not only to identify trends but also to easily compare several trends simultaneously. Furthermore, it offers pivot operations to allow users to navigate the faceted dataset using relationships between items. We evaluate the utility of the system through a description of insights gained while experts used the system to explore the CHI publication repository as well as a database of funding grant data, and report a formative user study that identified usability issues.
2009	Sizing the horizon: the effects of chart size and layering on the graphical perception of time series visualizations	We investigate techniques for visualizing time series data and evaluate their effect in value comparison tasks. We compare line charts with horizon graphs - a space-efficient time series visualization technique - across a range of chart sizes, measuring the speed and accuracy of subjects' estimates of value differences between charts. We identify transition points at which reducing the chart height results in significantly differing drops in estimation accuracy across the compared chart types, and we find optimal positions in the speed-accuracy tradeoff curve at which viewers performed quickly without attendant drops in accuracy. Based on these results, we propose approaches for increasing data density that optimize graphical perception.
2009	Call browser: a system to improve the caller experience by analyzing live calls end-to-end	This paper describes a system that empowers practitioners to substantially improve the user experience with call center automation and agents. Unlike other approaches we analyze the caller experience in live calls end-to-end, from dialing to hangup. A web-based solution, the Call Browser provides access to hundreds or thousands of live end-to-end calls, and empowers usability practitioners and call-center analysts to systematically and efficiently evaluate the caller experience and identify usability issues. Case studies from our consulting practice illustrate how this approach reveals issues that remain hidden to traditional methods, such as log analyses, lab user studies, focus groups, and design guidelines.
2009	Finding canonical behaviors in user protocols	While the collection of behavioral protocols has been common practice in human-computer interaction research for many years, the analysis of large protocol data sets is often extremely tedious and time-consuming, and automated analysis methods have been slow to develop. This paper proposes an automated method of protocol analysis to find canonical behaviors --- a small subset of protocols that is most representative of the full data set, providing a reasonable "big picture" view of the data with as few protocols as possible. The automated method takes advantage of recent algorithmic developments in computational vision, modifying them to allow for distance measures between behavioral protocols. The paper includes an application of the method to web-browsing protocols, showing how the canonical behaviors found by the method match well to sets of behaviors identified by expert human coders.
2009	Reduced empathizing skills increase challenges for user-centered design	User-Centered Design is surprisingly difficult. One of the biggest issues, certainly for those with no HCI or usability experience, is a lack of appreciation of how users think and work. Their assumption is that users will approach and solve problems in the same way as the designers and developers of an interactive solution. Extreme examples of this self-as-user outlook is the belief that interaction problems are either the direct fault of users or the failure of users to follow instructions (the 'RTFM' syndrome [9]). This paper explores a psychological explanation of the self-as-user outlook through Empathizing-Systemizing theory, including a large-scale study (n = 441) of men and women working in the Information Technology field. The study found that men whose role was technological had significantly lower empathizing scores. The results of the study help to explain the self-as-user outlook and how it needs to be overcome in the design process.
2009	An intuitive model of perceptual grouping for HCI design	Understanding and exploiting the abilities of the human visual system is an important part of the design of usable user interfaces and information visualizations. Good design enables quick, easy and veridical perception of key components of that design. An important facet of human vision is its ability to seemingly effortlessly perform "perceptual organization; it transforms individual feature estimates into perception of coherent regions, structures, and objects. We perceive regions grouped by proximity and feature similarity, grouping of curves by good continuation, and grouping of regions of coherent texture. In this paper, we discuss a simple model for a broad range of perceptual grouping phenomena. It takes as input an arbitrary image, and returns a structure describing the predicted visual organization of the image. We demonstrate that this model can capture aspects of traditional design rules, and predicts visual percepts in classic perceptual grouping displays.
2009	Development of decision rationale in complex group decision making	This study explores the characteristics of rationale development in a complex group decision making task and considers design implications for better supporting rationale development in group decision making. Twelve three-person, multi-role teams performed three instances of a collaborative decision making task with physical maps. We used rhetorical structure theory to analyze the structure of their decision making discourse. We found that groups begin their reasoning processing by stating and relating information and finish their reasoning through a point-counterpoint discussion. We also found that established groups reduced their need to analyze information during the last moments of a decision. Implications for the design of group decision support systems to encourage rationale development are presented.
2009	Learning to predict information needs: context-aware display as a cognitive aid and an assessment tool	We discuss the problem of assessing and aiding user performance in dynamic tasks that require rapid selection among multiple information sources. Motivated by research in human sequential learning, we develop a system that learns by observation to predict the information a user desires in different contexts. The model decides when the display should be updated, which is akin to the problem of scene segmentation, and then selects the situationally relevant information display. The model reduces the cognitive burden of selecting situation-relevant displays. We evaluate the system in a tank video game environment and find that the system boosts user performance. The fit of the model to user data provides a quantitative assessment of user behavior, which is useful in assessing individual differences and the progression from novice- to expert-level proficiency. We discuss the relative benefits of adopting a learning approach to predicting information preferences and possible avenues to reduce the negative consequences of automation.
2009	backchan.nl: integrating backchannels in physical space	In this paper, we describe backchan.nl, a web based backchannel system that focuses on providing greater audience participation during question and answer sessions. The system allows audience members to use a web-based service to propose questions and comments, and to vote on the questions of others. Top rated submissions are projected into the presentation space where audience members, moderators, and panelists can see them. We discuss the results of deploying this system at many different kinds of conferences and relate those results to the particular design of our system, demonstrating how backchannel systems can be more than just shared chat rooms. From our experience with this work, we discuss the broader implications of configurable mediated social spaces and how subtle design decisions can influence user experience
2009	Learning how: the search for craft knowledge on the internet	Communicating the subtleties of a craft technique, like putting a zipper into a garment or throwing a clay pot, can be challenging even when working side by side. Yet How-To content - including text, images, animations, and videos - is available online for a wide variety of crafts. We interviewed people engaged in various crafts to investigate how online resources contributed to their craft practice. We found that participants sought creative inspiration as well as technical clarification online. In this domain, keyword search can be difficult, so supplemental strategies are used. Participants sought information iteratively, because they often needed to enact their knowledge in order to evaluate it. Our description of people learning how allows us to elaborate existing understandings of information-seeking behavior by considering how search originates and is evaluated in knowledge domains involving physical objects and physical processes.
2009	Resonance on the web: web dynamics and revisitation patterns	The Web is a dynamic, ever-changing collection of information accessed in a dynamic way. This paper explores the relationship between Web page content change (obtained from an hourly crawl of over 40K pages) and people's revisitation to those pages (collected via a large scale log analysis of 2.3M users). We identify the relationship, or resonance, between revisitation behavior and the amount and type of changes on those pages. By coupling our large scale log analysis with a complementary user study we explore the intent behind the revisitation behavior we observed. Using the notion of resonance to identify the likely content of interest, we describe a number of ways interaction with changing and revisited information can be better supported. We illustrate how understanding the association between change and revisitation might improve browser, crawler, and search engine design, and present a specific example of how knowledge of both can enable relevant content to be highlighted.
2009	DynaSpot: speed-dependent area cursor	We present DynaSpot, a new technique for acquiring targets based on the area cursor. DynaSpot couples the cursor's activation area with its speed, behaving like a point cursor at low speed or when motionless. This technique minimizes visual distraction and allows pointing anywhere in empty space without requiring an explicit mode switch, thus enabling users to perform common interactions such as region selections seamlessly. The results of our controlled experiments show that the performance of DynaSpot can be modeled by Fitts' law, and that DynaSpot significantly outperforms the point cursor and achieves, in most conditions, the same level of performance as one of the most promising techniques to date, the Bubble cursor.
2009	The angle mouse: target-agnostic dynamic gain adjustment based on angular deviation	We present a novel method of dynamic C-D gain adaptation that improves target acquisition for users with motor impairments. Our method, called the Angle Mouse, adjusts the mouse C-D gain based on the deviation of angles sampled during movement. When angular deviation is low, the gain is kept high. When angular deviation is high, the gain is dropped, making the target bigger in motor-space. A key feature of the Angle Mouse is that, unlike most pointing facilitation techniques, it is target-agnostic, requiring no knowledge of target locations or dimensions. This means that the problem of distractor targets is avoided because adaptation is based solely on the user's behavior. In a study of 16 people, 8 of which had motor impairments, we found that the Angle Mouse improved motor-impaired pointing throughput by 10.3\% over the Windows default mouse and 11.0\% over sticky icons. For able-bodied users, there was no significant difference among the three techniques, as Angle Mouse throughput was within 1.2\% of the default. Thus, the Angle Mouse improved pointing performance for users with motor impairments while remaining unobtrusive for able-bodied users.
2009	Disambiguating ninja cursors with eye gaze	Ninja cursors aim to speed up target selection on large or multiple monitors. Several cursors are displayed on the screen with one of them selected as the active cursor. Eye tracking is used to choose the active cursor. An experiment with 13 participants showed that multiple cursors speed up the selection over long distances, but not over short distances. Participants felt the technique was fastest with 4 cursors per monitor, but still preferred to have only 1 cursor per monitor for their own use.
2009	Rake cursor: improving pointing performance with concurrent input channels	We investigate the use of two concurrent input channels to perform a pointing task. The first channel is the traditional mouse input device whereas the second one is the gaze position. The rake cursor interaction technique combines a grid of cursors controlled by the mouse and the selection of the active cursor by the gaze. A controlled experiment shows that rake cursor pointing drastically outperforms mouse-only pointing and also significantly outperforms the state of the art of pointing techniques mixing gaze and mouse input. A theory explaining the improvement is proposed: the global difficulty of a task is split between those two channels, and the sub-tasks could partly be performed concurrently.
2009	The Beauty Dilemma: beauty is valued but discounted in product choice	The empirical study of aesthetics in Human-Computer Interaction (HCI) is concerned with - among other topics - the relationship between beauty and usability and the general impact of beauty on product choice and use. Specifically, the present paper explores the notion of a "beauty dilemma" - the idea that people discount beauty in a choice situation, although they value it in general (i.e., they are not choosing what makes them happy). We explored this idea in three studies with a total of over 600 participants. Study 1 revealed a reluctance to pay for beauty due to its hedonic nature (i.e., associated with luxury etc.). Study 2 showed that people prefer a more beautiful product, but justify their choice by referring to spurious advantages in usability. Finally, Study 3 revealed that a choice situation which requires a trade-off between beauty and usability, and which offers no further way to justify choosing beauty, leads to a sharp increase in the preference of usability. The underlying reasons for this "beauty dilemma" and further implications are discussed.
2009	Enhancing remote participation in live auctions: an 'intelligent' gavel	Auctions, both traditional and electronic, are a pervasive social organisation for the valuation and exchange of goods and services. Despite the long-standing interest in integrating internet contributions into the more traditional auction such initiatives have remained problematic. We consider the organization of interaction of sales of fine art and antiques and develop a prototype 'intelligent' gavel system that is designed to enhance remote participation and ease the flexible ways in which internet contributions are legitimately integrated into live auctions. We present the findings of a quasi-naturalistic experiment involving the use of the system by auctioneers and its consequences for the general development of technologies to support internet participation in live co-located events.
2009	Revealing gauguin: engaging visitors in robot guide's explanation in an art museum	Designing technologies that support the explanation of museum exhibits is a challenging domain. In this paper we develop an innovative approach - providing a robot guide with resources to engage visitors in an interaction about an art exhibit. We draw upon ethnographical fieldwork in an art museum, focusing on how tour guides interrelate talk and visual conduct, specifically how they ask questions of different kinds to engage and involve visitors in lengthy explanations of an exhibit. From this analysis we have developed a robot guide that can coordinate its utterances and body movement to monitor the responses of visitors to these. Detailed analysis of the interaction between the robot and visitors in an art museum suggests that such simple devices derived from the study of human interaction might be useful in engaging visitors in explanations of complex artifacts.
2009	Social immersive media: pursuing best practices for multi-user interactive camera/projector exhibits	Based on ten years' experience developing interactive camera/projector systems for public science and culture exhibits, we define a distinct form of augmented reality focused on social interaction: social immersive media. Our work abandons GUI metaphors and builds on the language of cinema, casting users as actors within simulated narrative models. We articulate philosophical goals, design principles, and interaction techniques that create strong emotional responses and social engagement through visceral interaction. We describe approaches to clearly communicate cultural and scientific ideas through the medium. And we demonstrate how practitioners can design interactions that promote specific social behaviors in users.
2009	Contextual web history: using visual and contextual cues to improve web browser history	While most modern web browsers offer history functionality, few people use it to revisit previously viewed web pages. In this paper, we present the design and evaluation of Contextual Web History (CWH), a novel browser history implementation which improves the visibility of the history feature and helps people find previously visited web pages. We present the results of a formative user study to understand what factors helped people in finding past web pages. From this, we developed CWH to be more visible to users, and supported search, browsing, thumbnails, and metadata. Combined, these relatively simple features outperformed Mozilla Firefox 3's built-in browser history function, and greatly reduced the time and effort required to find and revisit a web page.
2009	Critical methods and user generated content: the iPhone on YouTube	Sites like YouTube offer vast sources of data for studies of human computer interaction. However, they also present a number of methodological challenges. This paper offers an example study of the initial reception of the iPhone 3G through YouTube. It begins with a quantitative account of the overall shape of the most frequently viewed returns for an iPhone 3G" search. A content analysis of the first hundred videos then explores the returns categorized by genre. Comments on the most popular video "Will It Blend"are analysed using grounded theory. It is argued that social science methods are not sufficient for a rich understanding of such material. The paper concludes with an analysis of"Will it Blend"that draws on cultural and critical theory. It is argued that a multi-methodological approach is necessary to exploit such data and also to address the challenges of next generation Human Computer Interaction (HCI).
2009	Note to self: examining personal information keeping in a lightweight note-taking tool	This paper describes a longitudinal field experiment in personal note-taking that examines how people capture and use information in short textual notes. Study participants used our tool, a simple browser-based textual note-taking utility, to capture personal information over the course of ten days. We examined the information they kept in notes using the tool, how this information was expressed, and aspects of note creation, editing, deletion, and search. We found that notes were recorded extremely quickly and tersely, combined information of multiple types, and were rarely revised or deleted. The results of the study demonstrate the need for a tool such as ours to support the rapid capture and retrieval of short notes-to-self, and afford insights into how users' actual note-keeping tendencies could be used to better support their needs in future PIM tools.
2009	What's mine is mine: territoriality in collaborative authoring	Territoriality, the expression of ownership towards an object, can emerge when social actors occupy a shared social space. In the case of Wikipedia, the prevailing cultural norm is one that warns against ownership of one's work. However, we observe the emergence of territoriality in online space with respect to a subset of articles that have been tagged with the Maintained template through a qualitative study of 15 editors who have self-designated as Maintainers. Our participants communicated ownership, demarcated boundaries and asserted their control over artifacts for the sake of quality by appropriating existing features of Wikipedia. We then suggest design strategies to support these behaviors in the proper context within collaborative authoring systems more generally.
2009	Coordinating tasks on the commons: designing for personal goals, expertise and serendipity	How is work created, assigned, and completed on large-scale, crowd-powered systems like Wikipedia? And what design principles might enable these federated online systems to be more effective? This paper reports on a qualitative study of work and task practices on Wikipedia. Despite the availability of tag-based community-wide task assignment mechanisms, informants reported that self-directed goals, within-topic expertise, and fortuitous discovery are more frequently used than community-tagged tasks. We examine how Wikipedia editors organize their actions and the actions of other participants, and what implications this has for understanding, and building tools for, crowd-powered systems, or any web site where the main force of production comes from a crowd of online participants. From these observations and insights, we developed WikiTasks, a tool that integrates with Wikipedia and supports both grassroots creation of site-wide tasks and self-selection of personal tasks, accepted from this larger pool of community tasks.
2009	Coordination in collective intelligence: the role of team structure and task interdependence	The success of Wikipedia has demonstrated the power of peer production in knowledge building. However, unlike many other examples of collective intelligence, tasks in Wikipedia can be deeply interdependent and may incur high coordination costs among editors. Increasing the number of editors increases the resources available to the system, but it also raises the costs of coordination. This suggests that the dependencies of tasks in Wikipedia may determine whether they benefit from increasing the number of editors involved. Specifically, we hypothesize that adding editors may benefit low-coordination tasks but have negative consequences for tasks requiring a high degree of coordination. Furthermore, concentrating the work to reduce coordination dependencies should enable more efficient work by many editors. Analyses of both article ratings and article review comments provide support for both hypotheses. These results suggest ways to better harness the efforts of many editors in social collaborative systems involving high coordination tasks.
2009	So you know you're getting the best possible information: a tool that increases Wikipedia credibility	An experiment was conducted to study how credibility judgments about Wikipedia are affected by providing users with an interactive visualization (WikiDashboard) of article and author editing history. Overall, users who self-reported higher use of Internet information and higher rates of Wikipedia usage tended to produce lower credibility judgments about Wikipedia articles and authors. However, use of WikiDashboard significantly increased article and author credibility judgments, with effect sizes larger than any other measured effects of background media usage and attitudes on Wikiepedia credibility. The results suggest that increased exposure to the editing/authoring histories of Wikipedia increases credibility judgments.
2009	What's in Wikipedia?: mapping topics and conflict using socially annotated category structure	Wikipedia is an online encyclopedia which has undergone tremendous growth. However, this same growth has made it difficult to characterize its content and coverage. In this paper we develop measures to map Wikipedia using its socially annotated, hierarchical category structure. We introduce a mapping technique that takes advantage of socially-annotated hierarchical categories while dealing with the inconsistencies and noise inherent in the distributed way that they are generated. The technique is demonstrated through two applications: mapping the distribution of topics in Wikipedia and how they have changed over time; and mapping the degree of conflict found in each topic area. We also discuss the utility of the approach for other applications and datasets involving collaboratively annotated category hierarchies.
2009	Auditory icon and earcon mobile service notifications: intuitiveness, learnability, memorability and preference	With an ever increasing number of mobile services, meaningful audio notifications could effectively inform users of the incoming services while minimising undesired and intrusive interruptions. Therefore, careful design of mobile service notification is needed. In this paper we evaluate two types of audio (auditory icons and earcons) as mobile service notifications, by comparing them on 4 measures: intuitiveness, learnability, memorability and user preference. A 4-stage longitudinal evaluation involving two lab experiments, a field study and a web-based experiment indicated that auditory icons performed significantly better in all measures. Implications for mobile audio notification design are presented.
2009	Bezel swipe: conflict-free scrolling and multiple selection on mobile touch screen devices	Zooming user interfaces are increasingly popular on mobile devices with touch screens. Swiping and pinching finger gestures anywhere on the screen manipulate the displayed portion of a page, and taps open objects within the page. This makes navigation easy but limits other manipulations of objects that would be supported naturally by the same gestures, notably cut and paste, multiple selection, and drag and drop. A popular device that suffers from this limitation is Apple's iPhone. In this paper, we present Bezel Swipe, an interaction technique that supports multiple selection, cut, copy, paste and other operations without interfering with zooming, panning, tapping and other pre-defined gestures. Participants of our user study found Bezel Swipe to be a viable alternative to direct touch selection.
2009	Exploring the potential of audio-tactile messaging for remote interpersonal communication	Shake2Talk is a mobile messaging system that allows users to send sounds and tactile sensations to one another via their mobile phones. Messages are created through gestures and then sent to the receiver's phone where they play upon arrival. This paper reports a study of the Shake2Talk system in use by six couples, and begins to uncover the types of messaging practices that occur, and the values and meanings that users ascribe to these messages.
2009	Gravity sphere: gestural audio-tactile interface for mobile music exploration	Current solutions for managing music in mobile contexts are inconvenient as they require considerable effort and visual attention. We describe a novel system for exploring music and generating playlists in mobile contexts, and present findings from our formative usability evaluations. The system provides audio-tactile feedback and is controlled by manipulating a device's orientation. The system plays songs associated with the current orientation. A spatial gesture or other command is then used to lock the orientation into a playlist. We evaluated two iterations of a prototype of the system and found that users were successful in exploring music and generating playlists with the system. We found that certain orientations are more common than others. Also, manipulating the prototype felt more natural while walking than sitting. Personalization of the music mapping was requested by users and seen as beneficial for usability.
2009	TouchBall: a design and evaluation of a hand-held trackball based touch-haptic interface	In this paper, we present a design and an evaluation of a hand-held trackball based touch-haptic interface, named "TouchBall." Using a trackball mechanism, the device provides flexibility in terms of directional degrees of freedom. It also has an advantage of a direct transfer of force feedback through frictional touch (with high sensitivity), thus requiring only relatively small amount of inertia. This leads to a compact hand-held design appropriate for mobile and 3D interactive applications. The device is evaluated for the detection thresholds for directions of the force feedback and the perceived amount of directional force. The refined directionality information should combine with other modalities with less sensory conflict, enriching the user experience for a given application.
2009	Design influence on social play in distributed exertion games	Exertion games are an emerging form of interactive games that require players to invest significant physical effort as part of the gameplay, rather than just pressing buttons. These exertion games have potential health benefits by promoting exercise. It is also believed that they can facilitate social play between players and that social play can improve participation in exertion games. However, there is currently a lack of understanding of how to design games to support these effects. In this paper, we present a qualitative case study that illustrates how networked environments support social play in exertion games and how this can help to gain an understanding of existing games and support the design of future games. This work offers a preliminary analytical and descriptive account of the relationship between exertion and social play in such a game and highlights the influence of design with the aim of utilizing the attributed benefits of exertion and social play.
2009	The three-sixty illusion: designing for immersion in pervasive games	Pervasive games are staged in reality and their main attractiveness is generated by using reality as a resource in the game. Yet, most pervasive games that use mobile and location-based technology use reality only in a weak sense, as the location for a computerized game. In this article we analyze two game practices, Nordic style live action role-playing (larp) and alternate reality games (ARG), that instead use reality as their main game resource. We analyze how they go about creating a believable game world and encourage the players to actively take part in this world. We present two example games that do the same with the support of technology, effectively realizing an immersive game world through a combination of physical play and technology-supported play.
2009	Wii all play: the console game as a computational meeting place	In this paper, we present results from a qualitative study of collocated group console gaming. We focus on motivations for, perceptions of, and practices surrounding the shared use of console games by a variety of established groups of gamers. These groups include both intragenerational groups of youth, adults, and elders as well as intergenerational families. Our analysis highlights the numerous ways that console games serve as a computational meeting place for a diverse population of gamers.
2009	Finding causes of program output with the Java Whyline	Debugging and diagnostic tools are some of the most important software development tools, but most expect developers choose the right code to inspect. Unfortunately, this rarely occurs. A new tool called the Whyline is described which avoids such speculation by allowing developers to select questions about a program's output. The tool then helps developers work backwards from output to its causes. The prototype, which supports Java programs, was evaluated in an experiment in which participants investigated two real bug reports from an open source project using either the Whyline or a breakpoint debugger. Whyline users were successful about three times as often and about twice as fast compared to the control group, and were extremely positive about the tool's ability to simplify diagnostic tasks in software development work.
2009	Fisheyes in the field: using method triangulation to study the adoption and use of a source code visualization	Information visualizations have been shown useful in numerous laboratory studies, but their adoption and use in real-life tasks are curiously under-researched. We present a field study of ten programmers who work with an editor extended with a fisheye view of source code. The study triangulates multiple methods (experience sampling, logging, thinking aloud, and interviews) to describe how the visualization is adopted and used. At the concrete level, our results suggest that the visualization was used as frequently as other tools in the programming environment. We also propose extensions to the interface and discuss features that were not used in practice. At the methodological level, the study identifies contributions distinct to individual methods and to their combination, and discusses the relative benefits of laboratory studies and field studies for the evaluation of information visualizations.
2009	Two studies of opportunistic programming: interleaving web foraging, learning, and writing code	This paper investigates the role of online resources in problem solving. We look specifically at how programmers - an exemplar form of knowledge workers - opportunistically interleave Web foraging, learning, and writing code. We describe two studies of how programmers use online resources. The first, conducted in the lab, observed participants' Web use while building an online chat room. We found that programmers leverage online resources with a range of intentions: They engage in just-in-time learning of new skills and approaches, clarify and extend their existing knowledge, and remind themselves of details deemed not worth remembering. The results also suggest that queries for different purposes have different styles and durations. Do programmers' queries "in the wild" have the same range of intentions, or is this result an artifact of the particular lab setting? We analyzed a month of queries to an online programming portal, examining the lexical structure, refinements made, and result pages visited. Here we also saw traits that suggest the Web is being used for learning and reminding. These results contribute to a theory of online resource usage in programming, and suggest opportunities for tools to facilitate online knowledge work.
2009	Comparison of three one-question, post-task usability questionnaires	Post-task ratings of difficulty in a usability test have the potential to provide diagnostic information and be an additional measure of user satisfaction. But the ratings need to be reliable as well as easy to use for both respondents and researchers. Three one-question rating types were compared in a study with 26 participants who attempted the same five tasks with two software applications. The types were a Likert scale, a Usability Magnitude Estimation (UME) judgment, and a Subjective Mental Effort Question (SMEQ). All three types could distinguish between the applications with 26 participants, but the Likert and SMEQ types were more sensitive with small sample sizes. Both the Likert and SMEQ types were easy to learn and quick to execute. The online version of the SMEQ question was highly correlated with other measures and had equal sensitivity to the Likert question type.
2009	Correlations among prototypical usability metrics: evidence for the construct of usability	Correlations between prototypical usability metrics from 90 distinct usability tests were strong when measured at the task-level (r between .44 and .60). Using test-level satisfaction ratings instead of task-level ratings attenuated the correlations (r between .16 and .24). The method of aggregating data from a usability test had a significant effect on the magnitude of the resulting correlations. The results of principal components and factor analyses on the prototypical usability metrics provided evidence for an underlying construct of general usability with objective and subjective factors.
2009	Let your users do the testing: a comparison of three remote asynchronous usability testing methods	Remote asynchronous usability testing is characterized by both a spatial and temporal separation of users and evaluators. This has the potential both to reduce practical problems with securing user attendance and to allow direct involvement of users in usability testing. In this paper, we report from an empirical study where we systematically compared three methods for remote asynchronous usability testing: user-reported critical incidents, forum-based online reporting and discussion, and diary-based longitudinal user reporting. In addition, conventional laboratory-based think-aloud testing was included as a benchmark for the remote methods. The results show that each remote asynchronous method supports identification of a considerable number of usability problems. Although this is only about half of the problems identified with the conventional method, it requires significantly less time. This makes remote asynchronous methods an appealing possibility for usability testing in many software projects.
2009	Focus on driving: how cognitive constraints shape the adaptation of strategy when dialing while driving	We investigate how people adapt their strategy for interleaving multiple concurrent tasks to varying objectives. A study was conducted in which participants drove a simulated vehicle and occasionally dialed a telephone number on a mobile phone. Experimental instructions and feedback encouraged participants to focus on either driving or dialing. Results show that participants adapted their task interleaving strategies to meet the required task objective, but in a manner that was nonetheless intricately shaped by internal psychological constraints. In particular, participants tended to steer in between dialing chunks of digits even when extreme vehicle drift implied that more reactive strategies would have generated better lane keeping. To better understand why drivers interleaved tasks at chunk boundaries, a modeling analysis was conducted to derive performance predictions for a range of dialing strategies. The analysis supported the idea that interleaving at chunk boundaries efficiently traded the time given up to dialing with the maintenance of a central lane position. We discuss the implications of this work in terms of contributions to understanding how cognitive constraints shape strategy adaptations in dynamic multitask environments.
2009	At home and with computer access: why and where people use cell phones to access the internet	We conducted a diary and interview study to investigate where and why people use cell phones to access the Internet. In more that 50\% of the cases, our participants chose a phone even though they had access to a computer, and the most frequent location for cell phone Internet access was the home.
2009	Bringing design considerations to the mobile phone and driving debate	Though legislation is increasingly discouraging drivers from holding on to their mobile phones while talking, hands-free devices do not improve driver safety. We offer two design alternatives to improve driver safety in the contexts of voice-based user interfaces and mobile phone conversations in cars' side tones (auditory feedback used in landline phones) and location of speakers. In a 2 (side tone: present vs. not) x 2 (location of speakers: headphones vs. dashboard) between-participants experiment (N=48), we investigated the impact of these features upon driver experience and performance on a simulated mobile phone conversation while driving. Participants became more verbally engaged in the conversation when side tones were present, but also experienced more cognitive load. Participants drove more safely when voices were projected from the dashboard rather than from headphones. Implications for driver user interface design are discussed.
2009	Can i borrow your phone?: understanding concerns when sharing mobile phones	Mobile phones are becoming increasingly personalized in terms of the data they store and the types of services they provide. At the same time, field studies have reported that there are a variety of situations in which it is natural for people to share their phones with others. However, most mobile phones support a binary security model that offers all-or-nothing access to the phone. We interviewed 12 smartphone users to explore how security and data privacy concerns affected their willingness to share their mobile phones. The diversity of guest user categorizations and associated security constraints expressed by the participants suggests the need for a security model richer than today's binary model.
2009	Social responses in mobile messaging: influence strategies, self-disclosure, and source orientation	This paper reports on a direct test of social responses to communication technologies theory (SRCT) with mobile messaging. SRCT predicts that people will mindlessly respond to computers in social ways that mirror their responses to humans. A field experiment (N=71) using participants' own mobile phones compared three influence strategies (direct request, flattery, and social norms) in the context of asking intimate questions of participants. These messages came from either an ostensibly human or computer sender. Flattery significantly increased self-disclosure when ostensibly sent by a human, but not when from a computer. The interaction effect for sender and influence strategy is inconsistent with SRCT's predictions. Implications for theories of source orientation, research methods, and future research are discussed.
2009	Ephemeral adaptation: the use of gradual onset to improve menu selection performance	We introduce ephemeral adaptation, a new adaptive GUI technique that improves performance by reducing visual search time while maintaining spatial consistency. Ephemeral adaptive interfaces employ gradual onset to draw the user's attention to predicted items: adaptively predicted items appear abruptly when the menu is opened, but non-predicted items fade in gradually. To demonstrate the benefit of ephemeral adaptation we conducted two experiments with a total of 48 users to show: (1) that ephemeral adaptive menus are faster than static menus when accuracy is high, and are not significantly slower when it is low and (2) that ephemeral adaptive menus are also faster than adaptive highlighting. While we focused on user-adaptive GUIs, ephemeral adaptation should be applicable to a broad range of visually complex tasks.
2009	Revisiting read wear: analysis, design, and evaluation of a footprints scrollbar	In this paper, we show that people frequently return to previously-visited regions within their documents, and that scrollbars can be enhanced to ease this task. We analysed 120 days of activity logs from Microsoft Word and Adobe Reader. Our analysis shows that region revisitation is a common activity that can be supported with relatively short recency lists. This establishes an empirical foundation for the design of an enhanced scrollbar containing scrollbar marks that helps people return to previously visited document regions. Two controlled experiments show that scrollbar marks decrease revisitation time, and that a large number of marks can be used effectively. We then design an enhanced Footprints scrollbar that supports revisitation with several features, including scrollbar marks and mark thumbnails. Two further experiments show that the Footprints scrollbar was frequently used and strongly preferred over traditional scrollbars.
2009	Power tools for copying and moving: useful stuff for your desktop	Copy and move operations have long been supported by interactive desktops through various means. But the growing number of on-screen objects makes these means harder to use. In this note, we present new tools and techniques to enhance the existing ones: a selection, copy and drag history manager; two techniques to expose the user's desk and leaf through stacks of overlapping windows; and a technique that integrates the previous two with conventional drag-and-drop.
2009	WikiFolders: augmenting the display of folders to better convey the meaning of files	Hierarchical file systems and file browsers offer powerful capabilities for managing and organizing folders and files. Yet they lack robust tools for annotating and documenting these files-individually or collectively-with descriptive text. In contrast, Web pages and wikis make it easy to create rich and meaningful narratives around digital artifacts, allowing files to be embedded within explanatory text and images. Unfortunately, considerable effort is required to manage files stored on Web servers and to ensure that the published content remains up-to-date. In this note, we describe WikiFolders, a hybrid system for annotating file folders that draws upon the strengths of both the hierarchical file system and wikis.
2009	Adaptive information search: age-dependent interactions between cognitive profiles and strategies	Previous research has shown that older adults performed worse in web search tasks, and attributed poorer performance to a decline in their cognitive abilities. We conducted a study involving younger and older adults to compare their web search behavior and performance in ill-defined and well-defined information tasks using a health information website. In ill-defined tasks, only a general description about information needs was given, while in well-defined tasks, information needs as well as the specific target information were given. We found that older adults performed worse than younger adults in well-defined tasks, but the reverse was true in ill-defined tasks. Older adults compensated for their lower cognitive abilities by adopting a top-down knowledge-driven strategy to achieve the same level of performance in the ill-defined tasks. Indeed, path models showed that cognitive abilities, health literacy, and knowledge influenced search strategies adopted by older and younger adults. Design implications are also discussed.
2009	Desiring to be in touch in a changing communications landscape: attitudes of older adults	This paper offers an exploration of the attitudes of older adults to keeping in touch with people who are important to them. We present findings from three focus groups with people from 55 to 81 years of age. Themes emerging from the findings suggest that older adults view the act of keeping in touch as being worthy of time and dedication, but also as being something that needs to be carefully managed within the context of daily life. Communication is seen as a means through which skill should be demonstrated and personality expressed, and is understood in a very different context to the lightweight interaction that is increasingly afforded by new technologies. The themes that emerged are used to elicit a number of design implications and to promote some illustrative design concepts for new communication devices.
2009	Knocking on elders' door: investigating the functional and emotional geography of their domestic space	The domestic environment is more than a place where to live. It is a territory of meaning, a place where pleasure, affect and aesthetics are deeply interwoven with the functional and utilitarian dimensions. With the aging process, the home is progressively invested with new meanings and functions, and becomes the emotional center of older people's life. This paper presents a user study based on cultural probes on how domestic spaces are managed and perceived by older adults, uncovering some of the complex interrelations among the daily activities, objects and meanings revolving around the home. The findings provide suggestions on how the dimensions of remembrance, perception of safety and environmental stability may affect the design of domestic technology for elderly people.
2009	Baby steps: evaluation of a system to support record-keeping for parents of young children	Parents of young children often want to keep a variety of records on their children's early years, for the purposes of preservation of memories or at the request of their pediatrician. However, time constraints, motivation, and forgetfulness may hinder their ability to keep consistent records. We developed a system, Baby Steps, which is designed to improve the record-keeping process. In this paper, we present the results of a 3-month deployment study of this technology with 8 families and their pediatricians. The study showed that when compared to a control condition, experimental design features of Baby Steps encouraged parents to more frequently collect and review records, provided higher confidence in reporting, and improved parent-pediatrician communication.
2009	Making history: intentional capture of future memories	Lifelogging' technology makes it possible to amass digital data about every aspect of our everyday lives. Instead of focusing on such technical possibilities, here we investigate the way people compose long-term mnemonic representations of their lives. We asked 10 families to create a time capsule, a collection of objects used to trigger remembering in the distant future. Our results show that contrary to the lifelogging view, people are less interested in exhaustively digitally recording their past than in reconstructing it from carefully selected cues that are often physical objects. Time capsules were highly expressive and personal, many objects were made explicitly for inclusion, however with little object annotation. We use these findings to propose principles for designing technology that supports the active reconstruction of our future past.
2009	Getting sidetracked: display design and occasioning photo-talk with the photohelix	In this paper we discuss some of our recent research work designing tabletop interfaces for co-located photo sharing. We draw particular attention to a specific feature of an interface design, which we have observed over an extensive number of uses, as facilitating an under-reported but none-the-less intriguing aspect of the photo-sharing experience - namely the process of 'getting sidetracked'. Through a series of vignettes of interaction during photo-sharing sessions we demonstrate how users of our tabletop photoware system used peripheral presentation of topically incoherent photos to artfully initiate new photo-talk sequences in on-going discourse. From this we draw implications for the design of tabletop photo applications, and for the experiential analysis of such devices.
2009	Reflections of everyday activities in spending data	In this paper we show that financial information can be used to sense many aspects of human activity. This simple technique gives people information about their daily lives, is easily accessible to many at no extra cost, requires little setup, and does not require the manufacture of any external devices. We will focus on how financial data can be used to show users where they spend their time, when they accomplish certain habits, and what the impact of their activities is on the environment. We validate our idea by implementing three demonstration applications intended for personal use. Finally, this paper discusses limitations of sensing using financial data and possible solutions.
2009	A comparison of mobile money-transfer UIs for non-literate and semi-literate users	Due to the increasing penetration of mobile phones even into poor communities, mobile payment schemes could bring formal financial services to the "unbanked". However, because poverty for the most part also correlates with low levels of formal education, there are questions as to whether electronic access to complex financial services is enough to bridge the gap, and if so, what sort of UI is best. In this paper, we present two studies that provide preliminary answers to these questions. We first investigated the usability of existing mobile payment services, through an ethnographic study involving 90 subjects in India, Kenya, the Philippines and South Africa. This was followed by a usability study with another 58 subjects in India, in which we compared non-literate and semi-literate subjects on three systems: text-based, spoken dialog (without text), and rich multimedia (also without text). Results confirm that non-text designs are strongly preferred over text-based designs and that while task-completion rates are better for the rich multimedia UI, speed is faster and less assistance is required on the spoken-dialog system.
2009	Comparing semiliterate and illiterate users' ability to transition from audio+text to text-only interaction	Multimodal interfaces with little or no text have been shown to be useful for users with low literacy. However, this research has not differentiated between the needs of the fully illiterate and semiliterate - those who have basic literacy but cannot read and write fluently. Text offers a fast and unambiguous mode of interaction for literate users and the exposure to text may allow for incidental improvement of reading skills. We conducted two studies that explore how semiliterate users with very little education might benefit from a combination of text and audio as compared to illiterate and literate users. Results show that semiliterate users reduced their use of audio support even during the first hour of use and over several hours this reduction was accompanied by a gain in visual word recognition; illiterate users showed no similar improvement. Semiliterate users should thus be treated differently from illiterate users in interface design.
2009	StoryBank: mobile digital storytelling in a development context	Mobile imaging and digital storytelling currently support a growing practice of multimedia communication in the West. In this paper we describe a project which explores their benefit in the East, to support non-textual information sharing in an Indian village. Local audiovisual story creation and sharing activities were carried out in a one month trial, using 10 customized cameraphones and a digital library of stories represented on a village display. The findings show that the system was usable by a cross-section of the community and valued for its ability to express a mixture of development and community information in an accessible form. Lessons for the role of HCI in this context are also discussed.
2009	CoSense: enhancing sensemaking for collaborative web search	Making sense of the information found during an investigational Web search task can be daunting. With the recent emergence of tools to support collaborative Web search, the associated sensemaking task has become even more complex, requiring sense to be made not only of the products of a search (i.e., results found) but of the process, as well (i.e., group division of labor and decision-making). We present the findings of a formative study illustrating the sensemaking challenges posed by collaborative search tools. Based on these findings, we created CoSense, a system that supports sensemaking for collaborative Web search tasks by providing several rich, interactive views of a group's search activities. We describe an evaluation of CoSense, reflecting on how its features supported different aspects of sensemaking, and how future collaborative search systems can benefit from these findings.
2009	PlayByPlay: collaborative web browsing for desktop and mobile devices	Collaborative web browsing tasks occur frequently, such as one user showing another how to use a web site, several users working together on a search task, or even one user sending an interesting link to another user. Unfortunately, tools for browsing the web are commonly designed for a single user. PlayByPlay is a general purpose web collaboration tool that uses the communication model of instant messaging to support a variety of collaborative browsing tasks. PlayByPlay also supports collaborative browsing between mobile and desktop users, which we believe is useful for on-the-go scenarios. We conducted user studies of the desktop and mobile versions of PlayByPlay and found the system to be usable and effective.
2009	Annotate once, appear anywhere: collective foraging for snippets of interest using paragraph fingerprinting	A common practice in work groups is to share links to interesting web pages. Moreover, passages in these web pages are often cut-and-pasted, and used in various other contexts. In this paper we report how we explore the idea of paragraph fingerprinting to achieve the goal of annotate once, appear anywhere"in a social annotation system called SparTag.us. This work was motivated by the prominence of redundant contents with different URLs on the Web and shared documents that are read and re-read within enterprises. Our technique attaches users' annotations to the contents of paragraphs, enabling annotations to move along with the paragraphs within dynamic live pages and travel across page boundary to other pages as long as the paragraph contents remain intact. We also describe how we use paragraph fingerprinting to facilitate the social sharing of information nuggets among our users.
2009	With a little help from my friends: examining the impact of social annotations in sensemaking tasks	In prior work we reported on the design of a social annotation system, SparTag.us, for use in sensemaking activities such as work-group reading and report writing. Previous studies of note-taking systems have demonstrated behavioral differences in social annotation practices, but are not clear in the actual performance gains provided by social features. This paper presents a laboratory study aimed at evaluating the learning effect of social features in SparTag.us. We found significant learning gains, and consider implications for design and for understanding the underlying mechanisms in play when people use social annotation systems.
2009	Self-interruption on the computer: a typology of discretionary task interleaving	The typical information worker is interrupted every 12 minutes, and half of the time they are interrupting themselves. However, most of the research on interruption in the area of human-computer interaction has focused on understanding and managing interruptions from external sources. Internal interruptions -- user-initiated switches away from a task prior to its completion -- are not well understood. In this paper we describe a qualitative study of self-interruption on the computer. Using a grounded theory approach, we identify seven categories of self-interruptions in computer-related activities. These categories are derived from direct observations of users, and describe the motivation, potential consequences, and benefits associated with each type of self-interruption observed. Our research extends the understanding of the self-interruption phenomenon, and informs the design of systems to support discretionary task interleaving on the computer.
2009	The problem of consistency in the design of Fitts' law experiments: consider either target distance and width or movement form and scale	An intriguing anomaly of the usual way of designing Fitts' law experiments in experimental psychology and HCI is exposed: experiments are traditionally designed so as to carefully balance two ancillary factors, target distance D and target width W, but not task difficulty, the factor unanimously thought to be crucial. Troubling factor confounds and hence quantitative estimation errors result from this inconsistency. The problem, it is suggested, may be fixed if the equivocalness of the fractional expression D/W that appears on the right-hand side of Fitts' law equations is acknowledged. This two-degree-of-freedom expression can be taken to specify either D and W or the form F and the scale S of the movement task. The paper ends up with practical recommendations for the design of consistent Fitts' law experiments. In most cases eliminating one factor will allow a safer estimation of Fitts' law parameters, while simplifying the experimental work.
2009	Toward a unified theory of the multitasking continuum: from concurrent performance to task switching, interruption, and resumption	Multitasking in user behavior can be represented along a continuum in terms of the time spent on one task before switching to another. In this paper, we present a theory of behavior along the multitasking continuum, from concurrent tasks with rapid switching to sequential tasks with longer time between switching. Our theory unifies several theoretical effects - the ACT-R cognitive architecture, the threaded cognition theory of concurrent multitasking, and the memory-for-goals theory of interruption and resumption - to better understand and predict multitasking behavior. We outline the theory and discuss how it accounts for numerous phenomena in the recent empirical literature.
2009	Evaluating existing audio CAPTCHAs and an interface optimized for non-visual use	Audio CAPTCHAs were introduced as an accessible alternative for those unable to use the more common visual CAPTCHAs, but anecdotal accounts have suggested that they may be more difficult to solve. This paper demonstrates in a large study of more than 150 participants that existing audio CAPTCHAs are clearly more difficult and time-consuming to complete as compared to visual CAPTCHAs for both blind and sighted users. In order to address this concern, we developed and evaluated a new interface for solving CAPTCHAs optimized for non-visual use that can be added in-place to existing audio CAPTCHAs. In a subsequent study, the optimized interface increased the success rate of blind participants by 59\% on audio CAPTCHAs, illustrating a broadly applicable principle of accessible design: the most usable audio interfaces are often not direct translations of existing visual interfaces.
2009	On the audio representation of distance for blind users	This study examines methods for displaying distance information to blind travellers using sound, focussing on abstractions of methods currently used in commercial Electronic Travel Aids (ETAs). Ten blind participants assessed three sound encodings commonly used to convey distance information by ETAs: sound frequency (Pitch), Ecological Distance (ED), and temporal variation or Beat Rate (BR). Response time and response correctness were chosen for measures.
2009	Amplifying community content creation with mixed initiative information extraction	Although existing work has explored both information extraction and community content creation, most research has focused on them in isolation. In contrast, we see the greatest leverage in the synergistic pairing of these methods as two interlocking feedback cycles. This paper explores the potential synergy promised if these cycles can be made to accelerate each other by exploiting the same edits to advance both community content creation and learning-based information extraction. We examine our proposed synergy in the context of Wikipedia infoboxes and the Kylin information extraction system. After developing and refining a set of interfaces to present the verification of Kylin extractions as a non primary task in the context of Wikipedia articles, we develop an innovative use of Web search advertising services to study people engaged in some other primary task. We demonstrate our proposed synergy by analyzing our deployment from two complementary perspectives: (1) we show we accelerate community content creation by using Kylin's information extraction to significantly increase the likelihood that a person visiting a Wikipedia article as a part of some other primary task will spontaneously choose to help improve the article's infobox, and (2) we show we accelerate information extraction by using contributions collected from people interacting with our designs to significantly improve Kylin's extraction performance.
2009	Attaching UI enhancements to websites with end users	We present reform, a step toward write-once apply-anywhere user interface enhancements. The reform system envisions roles for both programmers and end users in enhancing existing websites to support new goals. First, a programmer authors a traditional mashup or browser extension, but they do not write a web scraper. Instead they use reform, which allows novice end users to attach the enhancement to their favorite sites with a scraping by-example interface. reform makes enhancements easier to program while also carrying the benefit that end users can apply the enhancements to any number of new websites. We present reform's architecture, user interface, interactive by-example extraction algorithm for novices, and evaluation, along with five example reform enabled enhancements.
2009	User-created forms as an effective method of human-agent communication	A key challenge for mixed-initiative systems is to create a shared understanding of the task between human and agent. To address this challenge, we created a mixed-initiative interface called Mixer to aid administrators with automating tedious information-retrieval tasks. Users initiate communication with the agent by constructing a form, creating a structure to hold the information they require and to show context in order to interpret this information. They then populate the form with the desired results, demonstrating to the agent the steps required to retrieve the information. This method of form creation explicitly defines the shared understanding between human and agent. An evaluation of the interface shows that administrators can effectively create forms to communicate with the agent, that they are likely to accept this technology in their work environment, and that the agent's help can significantly reduce the time they spend on repeated information-retrieval tasks.
2009	Designable visual markers	Visual markers are graphic symbols designed to be easily recognised by machines. They are traditionally used to track goods, but there is increasing interest in their application to mobile HCI. By scanning a visual marker through a camera phone users can retrieve localised information and access mobile services. One missed opportunity in current visual marker systems is that the markers themselves cannot be visually designed, they are not expressive to humans, and thus fail to convey information before being scanned. This paper provides an overview of d-touch, an open source system that allows users to create their own markers, controlling their aesthetic qualities. The system runs in real-time on mobile phones and desktop computers. To increase computational efficiency d-touch imposes constraints on the design of the markers in terms of the relationship of dark and light regions in the symbols. We report a user study in which pairs of novice users generated between 3 and 27 valid and expressive markers within one hour of being introduced to the system, demonstrating its flexibility and ease of use.
2009	Like bees around the hive: a comparative study of a mobile augmented reality map	We present findings from field trials of MapLens, a mobile augmented reality (AR) map using a magic lens over a paper map. Twenty-six participants used MapLens to play a location-based game in a city centre. Comparisons to a group of 11 users with a standard 2D mobile map uncover phenomena that arise uniquely when interacting with AR features in the wild. The main finding is that AR features facilitate place-making by creating a constant need for referencing to the physical, and in that it allows for ease of bodily configurations for the group, encourages establishment of common ground, and thereby invites discussion, negotiation and public problem-solving. The main potential of AR maps lies in their use as a collaborative tool.
2009	Going my way: a user-aware route planner	Going My Way is a mobile user-aware route planner. The system collects GPS data of a user's everyday locations and provides directions from an automatically selected set of landmarks that are close to the destination, informed by the user's usual travel patterns. In this paper, we present a brief description of the system, the results of a preliminary experiment in memory and recognition of landmarks, in addition to the results of a user evaluation of the system.
2009	Inferring player engagement in a pervasive experience	We investigate the prediction of player engagement to address temporal issues arising from the long-term character of pervasive experiences such as interruptibility, mutual player state awareness, disengagement and synchronization on re-engagement. We introduce a model that operationalizes engagement in terms of the elapsed and response time in game messages. We designed and conducted an experiment based on the experience-sampling method to evaluate our model on the basis of a long-term SMS-based game called Day of the Figurines. Statistical analysis supports the hypothesis that player engagement can be predicted by the continuous data properties elapsed time and response time. Our findings point towards further research towards the adaptation of pervasive experiences to the player's temporal context.
2009	Back-of-device interaction allows creating very small touch devices	In this paper, we explore how to add pointing input capabilities to very small screen devices. On first sight, touchscreens seem to allow for particular compactness, because they integrate input and screen into the same physical space. The opposite is true, however, because the user's fingers occlude contents and prevent precision. We argue that the key to touch-enabling very small devices is to use touch on the device backside. In order to study this, we have created a 2.4" prototype device; we simulate screens smaller than that by masking the screen. We present a user study in which participants completed a pointing task successfully across display sizes when using a back-of device interface. The touchscreen-based control condition (enhanced with the shift technique), in contrast, failed for screen diagonals below 1 inch. We present four form factor concepts based on back-of-device interaction and provide design guidelines extracted from a second user study.
2009	Codex: a dual screen tablet computer	The Codex is a dual-screen tablet computer, about the size of a 4"x 6 day planner, with a self-supporting binding and embedded sensors. The device can be oriented in a variety of postures to support different nuances of individual work, ambient display, or collaboration with another user. In the context of a pen-operated note taking application, we demonstrate interaction techniques that support a fluid division of labor for tasks and information across the two displays while minimizing disruption to the primary experience of authoring notes.
2009	Tilt techniques: investigating the dexterity of wrist-based input	Most studies on tilt based interaction can be classified as point-designs that demonstrate the utility of wrist-tilt as an input medium; tilt parameters are tailored to suit the specific interaction at hand. In this paper, we systematically analyze the design space of wrist-based interactions and focus on the level of control possible with the wrist. In a first study, we investigate the various factors that can influence tilt control, separately along the three axes of wrist movement: flexion/extension, pronation/supination, and ulnar/radial deviation. Results show that users can control comfortably at least 16 levels on the pronation/supination axis and that using a quadratic mapping function for discretization of tilt space significantly improves user performance across all tilt axes. We discuss the findings of our results in the context of several interaction techniques and identify several general design recommendations.
2009	A tag in the hand: supporting semantic, social, and spatial navigation in museums	Designers of mobile, social systems must carefully think about how to help their users manage spatial, semantic, and social modes of navigation. Here, we describe our deployment of MobiTags, a system to help museum visitors interact with a collection of "open storage" exhibits, those where the museum provides little curatorial information. MobiTags integrates social tagging, art information, and a map to support navigation and collaborative curation of these open storage collections. We studied 23 people's use of MobiTags in a local museum, combining interview data with device use logs and tracking of people's movements to understand how MobiTags affected their navigation and experience in the museum. Despite a lack of social cues, people feel a strong sense of social presence--and social pressure--through seeing others' tags. The tight coupling of tags, item information, and map features also supported a rich set of practices around these modes of navigation.
2009	Familial collaborations in a museum	Studies of interactive systems in museums have raised important design considerations, but so far have failed to address sufficiently the particularities of family interaction and co-operation. This paper introduces qualitative video-based observations of Japanese families using an interactive portable guide system in a museum. Results show how unexpected usage can occur through particularities of interaction between family members. The paper highlights the necessity to more fully consider familial relationships in HCI.
2009	Supporting the creation of hybrid museum experiences	This paper presents the evolution of a tool to support the rapid prototyping of hybrid museum experiences by domain professionals. The developed tool uses visual markers to associate digital resources with physical artefacts. We present the iterative development of the tool through a user centred design process and demonstrate its use by domain experts to realise two distinct hybrid exhibits. The process of design and refinement of the tool highlights the need to adopt an experience oriented approach allowing authors to think in terms of the physical and digital "things" that comprise a hybrid experience rather than in terms of the underlying technical components.
2009	It's not what you know, but who you know: a social approach to last-resort authentication	Backup authentication mechanisms help users who have forgotten their passwords regain access to their accounts-or at least try. Today's systems fall short in meeting both security and reliability requirements. We designed, built, and tested a new backup authentication system that employs a social-authentication mechanism. The system employs trustees previously appointed by the account holder to verify the account holder's identity. We ran three experiments to determine whether the system could (1) reliably authenticate account holders, (2) resist email attacks that target trustees by impersonating account holders, and (3) resist phone-based attacks from individuals close to account holders. Results were encouraging: seventeen of the nineteen participants who made the effort to call trustees authenticated successfully. However, we also found that users must be reminded of who their trustees are. While email-based attacks were largely unsuccessful, stronger countermeasures will be required to counter highly-personalized phone-based attacks.
2009	When I am on Wi-Fi, I am fearless: privacy concerns & practices in eeryday Wi-Fi use	Increasingly, users access online services such as email, e-commerce, and social networking sites via 802.11-based wireless networks. As they do so, they expose a range of personal information such as their names, email addresses, and ZIP codes to anyone within broadcast range of the network. This paper presents results from an exploratory study that examined how users from the general public understand Wi-Fi, what their concerns are related to Wi-Fi use, and which practices they follow to counter perceived threats. Our results reveal that while users understand the practical details of Wi-Fi use reasonably well, they lack understanding of important privacy risks. In addition, users employ incomplete protective practices which results in a false sense of security and lack of concern while on Wi-Fi. Based on our results, we outline opportunities for technology to help address these problems.
2009	Who's viewed you?: the impact of feedback in a mobile location-sharing application	Feedback is viewed as an essential element of ubiquitous computing systems in the HCI literature for helping people manage their privacy. However, the success of online social networks and existing commercial systems for mobile location sharing which do not incorporate feedback would seem to call the importance of feedback into question. We investigated this issue in the context of a mobile location sharing system. Specifically, we report on the findings of a field de-ployment of Locyoution, a mobile location sharing system. In our study of 56 users, one group was given feedback in the form of a history of location requests, and a second group was given no feedback at all. Our major contribution has been to show that feedback is an important contributing factor towards improving user comfort levels and allaying privacy concerns. Participants' privacy concerns were reduced after using the mobile location sharing system. Additionally,our study suggests that peer opinion and technical savviness contribute most to whether or not participants thought they would continue to use a mobile location technology.
2009	Exploring websites through contextual facets	We present contextual facets, a novel user interface technique for navigating websites that publish large collections of semi-structured data. Contextual facets extend traditional faceted navigation techniques by transforming webpage elements into user interface components for filtering and retrieving related webpages. To investigate users' reactions to contextual facets, we built FacetPatch, a web browser that automatically generates contextual facet interfaces. As the user browses the web, FacetPatch automatically extracts semi-structured data from collections of webpages and overlays contextual facets on top of the current page. Participants in an exploratory user evaluation of FacetPatch were enthusiastic about contextual facets and often preferred them to an existing, familiar faceted navigation interface. We discuss how we improved the design of contextual facets and FacetPatch based on the results of this study.
2009	Visual snippets: summarizing web pages for search and revisitation	People regularly interact with different representations of Web pages. A person looking for new information may initially find a Web page represented as a short snippet rendered by a search engine. When he wants to return to the same page the next day, the page may instead be represented by a link in his browser history. Previous research has explored how to best represent Web pages in support of specific task types, but, as we find in this paper, consistency in representation across tasks is also important. We explore how different representations are used in a variety of contexts and present a compact representation that supports both the identification of new, relevant Web pages and the re-finding of previously viewed pages.
2009	From x-rays to silly putty via Uranus: serendipity and its role in web search	The act of encountering information unexpectedly has long been identified as valuable, both as a joy in itself and as part of task-focused problem solving. There has been a concern that highly accurate search engines and targeted personalization may reduce opportunities for serendipity on the Web. We examine whether there is the potential for serendipitous encounters during Web search, and whether improving search relevance through personalization reduces this potential. By studying Web search query logs and the results people judge relevant and interesting, we find many of the queries people perform return interesting (potentially serendipitous) results that are not directly relevant. Rather than harming serendipity, personalization appears to identify interesting results in addition to relevant ones.
2009	Semantically structured tag clouds: an empirical evaluation of clustered presentation approaches	Tag clouds have become a frequently used interaction technique in the web. Recently several approaches to present tag clouds with the tags semantically clustered have been proposed. However, it remains unclear whether the expected gains in performance and advantages in interaction actually can be realized as no empirical evaluations of such approaches are available yet. In this paper we describe a series of experiments designed to evaluate the effects of semantic versus alphabetical and random arrangements of tags in tag clouds. The results of our work indicate that semantically clustered tag clouds can provide improvements over random layouts in specific search tasks and that they tend to increase the attention towards tags in small fonts compared to other layouts. Also, semantically structured tag clouds were preferred by about half of the users for general search tasks. Tag cloud layout does not seem to influence the ability to remember tags.
2009	A mobile voice communication system in medical setting: love it or hate it?	Hospital work coordination and collaboration often requires mobility for acquiring proper information and resources. In turn, the spatial distribution and the mobility of clinicians can curtail the opportunities for effective communications making collaboration difficult. In this situation, a mobile hands-free voice communication system, Vocera, was introduced to enhance communication. It supports quick and impromptu conversations among coworkers for work coordination and collaboration anytime and anywhere. We study this deployment and present our findings concerning the impact of this communication system on the information flow. Our information flow framework's communication strategies help contrast the information processes before and after the deployment of Vocera.
2009	Clinical evaluations and collaborative design: developing new technologies for mental healthcare interventions	Ethical requirements, severe constraints on access to end users and the necessity of real-world clinical evaluations represent significant challenges to designers of new technologies in mental healthcare (MHC) settings. This paper describes the collaborative approaches, incorporating HCI methods with input for MHC professionals and MHC theory, which were applied in the development of Personal Investigator (PI), a 3D computer game developed to support adolescent mental health interventions. Different stages in the evaluation of PI are discussed and the lessons learned through a multi-site clinical evaluation are presented. This evaluation has provided strong initial evidence that games such as PI offer the potential to improve adolescent engagement in talk-based interventions. It has also provided an insight into factors which should be considered in future designs in the MHC domain, e.g. the need to incorporate high levels of adaptability in future systems. Based on the difficulties encountered and lessons learned critical aims for future research are outlined.
2009	I just don't know why it's gone : maintaining informal information use in inpatient care	We conducted a field-based study examining informal nursing information. We examined the use of this information before and after the adoption of a CPOE (Computerized Provider Order Entry) system in an inpatient unit of a large teaching hospital. Before CPOE adoption, nurses used paper working documents to detail psycho-social information about patients; after the CPOE adoption, they did not use paper or digital notes as was planned. The paper describes this process and analyses how several interlocked reasons contributed to the loss of this information in written form. We found that a change in physical location, sufficient convenience, visibility of the information, and permanency of information account for some, but not all, of the outcome. As well, we found that computerization of the nursing data led to a shift in the politics of the information itself - the nurses no longer had a cohesive agreement about the kinds of data to enter into the system. The findings address the requirements of healthcare computerization to support both formal and informal work practices, respecting the nature of nursing work and the politics of information inherent in complex medical work.
2009	Blogging at work and the corporate attention economy	The attention economy motivates participation in peer-produced sites on the Web like YouTube and Wikipedia. However, this economy appears to break down at work. We studied a large internal corporate blogging community using log files and interviews and found that employees expected to receive attention when they contributed to blogs, but these expectations often went unmet. Like in the external blogosphere, a few people received most of the attention, and many people received little or none. Employees expressed frustration if they invested time and received little or no perceived return on investment. While many corporations are looking to adopt Web-based communication tools like blogs, wikis, and forums, these efforts will fail unless employees are motivated to participate and contribute content. We identify where the attention economy breaks down in a corporate blog community and suggest mechanisms for improvement.
2009	Learning by seeing: photo viewing in the workplace	In this paper, we focus on the role that photo viewing plays within a large distributed enterprise. We describe the results of an analysis of users' viewing behavior through log activity and semi-structured interviews with respect to a photo sharing application embedded within an internal social networking site. Specifically, we investigate how these forms of expression can assist in the transmission of the norms and values associated with the culture of the organization through impression formation. We conclude by discussing how photos might act as a resource for newcomers to learn about the various aspects of the organizational culture and offer design suggestions for photo viewing systems within organizations.
2009	Exploring awareness needs and information display preferences between coworkers	Technology makes it possible to share many different types of information with coworkers. We conducted a large-scale survey (N=549) to better understand current sharing among coworkers, how people stay aware of collocated and remote coworkers, and whether their willingness to share different types of awareness information changes based on the location in which the information is displayed. Contrary to our expectations, the display location did not greatly affect what respondents were willing to share. Our results also suggest considerations for researchers building situated displays, as respondents had concerns about unintended viewers and encouraging people to visit their personal space when they were not present.
2009	Yours, mine and (not) ours: social influences on group information repositories	Group information repositories are systems for storing and organizing files in a central location all group members can access. The functionality and capabilities of these systems are essentially the same as the desktop metaphor of personal information management (PIM) systems. Using a case study of a group information repository, I argue that social factors affect the information structure of the repository, and how it grows and evolves over time. Users restrict their activities to files they own, are reluctant to delete files that might be useful to others, dislike the clutter that results, and can become demotivated if no one views files they uploaded.
2009	I'm sorry, Dave: i'm afraid i won't do that: social aspects of human-agent conflict	As computational agents become more sophisticated, it will frequently be necessary for the agents to disagree with users. In these cases, it might be useful for the agent to use politeness strategies that defuse the person's frustrations and preserve the human-computer relationship. One such strategy is distancing, which we implemented by spatially distancing an agent's voice from its body. In a 2 (agent disagreement: none vs. some) x 2 (agent voice location: on robotic body vs. in control box) between-participants experiment, we studied the effects of agent disagreement and agent voice location in a collaborative human-agent desert survival task (N=40). People changed their answers more often when agents disagreed with them and felt more similar to agents that always agreed with them, even when substantive content was identical. Strikingly, people felt more positively toward the disagreeing agent whose voice came from a separate control box rather than from its body; for agreement, the body-attached voice was preferred.
2009	Machine intelligence	Under certain conditions, we appear willing to see and interact with computing machines as though they exhibited intelligence, at least an intelligence of sorts. Using examples from AI and robotics research, as well as a selection of relevant art installations and anthropological fieldwork, this paper reflects on some of our interactions with the kinds of machines we seem ready to treat as intelligent. Broadly, it is suggested that ordinary, everyday ideas of intelligence are not fixed, but rather actively seen and enacted in the world. As such, intelligence does not just belong to the province of the human mind, but can emerge in quite different, unexpected forms in things. For HCI, it is proposed this opens up a new set of possibilities for design; examining the ways intelligence is seen and enacted gives rise to a very different way of thinking about the intersection between human and machine, and thus promotes some radically new types of interactions with computing machines.
2009	Why and why not explanations improve the intelligibility of context-aware intelligent systems	Context-aware intelligent systems employ implicit inputs, and make decisions based on complex rules and machine learning models that are rarely clear to users. Such lack of system intelligibility can lead to loss of user trust, satisfaction and acceptance of these systems. However, automatically providing explanations about a system's decision process can help mitigate this problem. In this paper we present results from a controlled study with over 200 participants in which the effectiveness of different types of explanations was examined. Participants were shown examples of a system's operation along with various automatically generated explanations, and then tested on their understanding of the system. We show, for example, that explanations describing why the system behaved a certain way resulted in better understanding and stronger feelings of trust. Explanations describing why the system did not behave a certain way, resulted in lower understanding yet adequate performance. We discuss implications for the use of our findings in real-world context-aware applications.
2009	An evaluation of coordination techniques for protecting objects and territories in tabletop groupware	Indirect input techniques allow users to quickly access all parts of tabletop workspaces without the need for physical access; however, indirect techniques restrict the available social cues that are seen on direct touch tables. This reduced awareness results in impoverished coordination; for example, the number of conflicts might increase since users are more likely to interact with objects that another person is planning to use. Conflicts may also arise because indirect techniques reduce territorial behavior, expanding the interaction space of each collaborator. In this paper, we introduce three new tabletop coordination techniques designed to reduce conflicts arising from indirect input, while still allowing users the flexibility of distant object control. Two techniques were designed to promote territoriality and to allow users to protect objects when they work near their personal areas, and the third technique lets users set their protection levels dynamically. We present the results of an evaluation, which shows that people prefer techniques that automatically provide protection for personal territories, and that these techniques also increase territorial behavior.
2009	Territorial coordination and workspace awareness in remote tabletop collaboration	There is growing interest in tabletop interfaces that enable remote collaboration by providing shared workspaces. This approach assumes that these remote tabletops afford the same beneficial work practices as co-located tabletop interfaces and traditional tables. This assumption has not been tested in practice. We explore two such work practices in remote tabletop collaboration: (a) coordination by territorial partitioning of space; and (b) transitioning between individual and group work within a shared task. We have evaluated co-located and remote tabletop collaboration. We found that remote collaborators did not coordinate territorially as co-located collaborators did. We found no differences between remote and co-located interfaces in their ability to afford individual and group work. However, certain interaction techniques impaired the ability to transition fluidly between these working styles. We discuss causes and the implications for the design and future study of these interfaces.
2009	Fighting for control: children's embodied interactions when using physical and digital representations	Tabletop and tangible interfaces are often described in terms of their support for shared access to digital resources. However, it is not always the case that collaborators want to share and help one another. In this paper we detail a video-analysis of a series of prototyping sessions with children who used both cardboard objects and an interactive tabletop surface. We show how the material qualities of the digital interface and physical objects affect the kinds of bodily strategies adopted by children to stop others from accessing them. We discuss how children fight for and maintain control of physical versus digital objects in terms of embodied interaction and what this means when designing collaborative applications for shareable interfaces.
2009	Measuring the impact of third place attachment on the adoption of a place-based community technology	CoCollage is a placed-based community technology that leverages the power of online social networking to facilitate awareness and face-to-face interactions in a third place. We adapted standardized measures of place attachment, social networks and psychological sense of community to provide a framework grounded in the social science literature for studying real world adoption of place-based community technologies. We found the standardized measures of place attachment and psychological sense of community meaningfully predicted likelihood of technology adoption and usage in a café. We discuss some lessons learned from our initial deployment of CoCollage in a real-world setting to support a nascent place-based community.
2009	A mischief of mice: examining children's performance in single display groupware systems with 1 to 32 mice	Mischief is a system for classroom interaction that allows multiple children to use individual mice and cursors to interact with a single large display [20]. While the system can support large groups of children, it is unclear how children's performance is affected as group size increases. We explore this question via a study involving two tasks, with children working in group sizes ranging from 1 to 32. The first required reciprocal selection of two on-screen targets, resembling a swarm pointing scenario that might be used in educational applications. The second, a more temporally and spatially distributed pointing task, had children entering different words by selecting characters on an on-screen keyboard. Results indicate that performance is significantly affected by group size only when targets are small. Further, group size had a smaller effect when pointing was spatially and temporally distributed than when everyone was concurrently aiming at the same targets.
2009	Mobile media in the social fabric of a kindergarten	At first blush, mobile media may appear a promising solution to the problem arising from the fact that parents in the present-day kindergarten institution rely almost solely on teachers' retrospective reports on their child's daily activities. However, a kindergarten is a delicate social fabric that mixes professional roles (the teachers') with socio-emotional relationships (parenting and caring) and involves stakeholders who are dependent on adults in the use of technology (the children). To date, no studies have been reported that critically examine the boundary conditions for successful mobile media applications in such settings. We present a study of Meaning, a one-button capture-and-push-to-Web solution that was used by a Finnish kindergarten for a month. Interviews and the amount of media sent suggest that the intervention was a success, and we report on seven uses of media. However, all uses were critically affected by the users' social fabric, in which the teachers were the nexus. We conclude by discussing various ways in which the heterogeneity of the user group affected mobile media use.
2009	Designing with children with severe motor impairments	Children with severe motor impairments such as with disabilities resulting from severe cerebral palsy benefit greatly from assistive technology, but very little guidance is available on how to collaborate with this population as partners in the design of such technology. To explore how to facilitate such collaborations, a field-based participant observation study, as well as structured and unstructured interviews, were conducted at a home for children with severe disabilities. Team-building collaborative design activities were pursued. Guidelines are proposed for how to collaborate with children with severe motor impairments.
2009	HeartBeat: an outdoor pervasive game for children	This paper reports the design of a pervasive game for children to demonstrate the design vision of Head-Up games, a genre of pervasive games that puts outdoors play center stage, combining the benefits of traditional outdoor games with the opportunities for richer experiences and innovation offered by new media. The design of the game, called HeartBeat, explores the use of physiological sensing and more specifically heart rate measurement as input to the game and as an approach to enhance the pervasive gaming experience. Evaluation with 32 children outdoors showed how the game promotes physical activity and social interaction between children in ways one would expect from traditional outdoor games.
2009	Brain measurement for usability testing and adaptive interfaces: an example of uncovering syntactic workload with functional near infrared spectroscopy	A well designed user interface (UI) should be transparent, allowing users to focus their mental workload on the task at hand. We hypothesize that the overall mental workload required to perform a task using a computer system is composed of a portion attributable to the difficulty of the underlying task plus a portion attributable to the complexity of operating the user interface. In this regard, we follow Shneiderman's theory of syntactic and semantic components of a UI. We present an experiment protocol that can be used to measure the workload experienced by users in their various cognitive resources while working with a computer. We then describe an experiment where we used the protocol to quantify the syntactic workload of two user interfaces. We use functional near infrared spectroscopy, a new brain imaging technology that is beginning to be used in HCI. We also discuss extensions of our techniques to adaptive interfaces.
2009	O' game, can you feel my frustration?: improving user's gaming experience via stresscam	One of the major challenges of video game design is to have appropriate difficulty levels for users in order to maximize the entertainment value of the game. Game players may lose interests if a game is either too easy or too difficult. This paper presents a novel methodology to improve user's experience in computer games by automatically adjusting the level of the game difficulty. The difficulty level is computed from measurements of the facial physiology of the players at a distance. The measurements are based on the assumption that the players' performance during the game-playing session alters blood flow in the supraorbital region, which is an indirect measurement of increased mental activities. This alters heat dissipation, which can be monitored in a contact-free manner through a thermal imaging-based stress monitoring and analysis system, known as StressCam. In this work, we investigated on two primary objectives: (1) the feasibility of utilizing the facial physiology in automatically adjusting the difficulty level of the game and (2) the capability of the automatic difficulty level adjustment in improving game players' experience. We employed and extended a XNA video game for this study, and performed an in-depth, comparative usability evaluation on it. Our results show that the automatic difficulty adjustable system successfully maintains game players' interests and substantially outperforms traditional fixed-difficulty mode games. Although a number of issues of this preliminary study remain to be investigated further, this research opens a new direction that utilizes non-contact stress measurements for monitoring and further enhancing a variety of user-centric, interactive entertainment activities.
2009	A performance model of selection techniques for p300-based brain-computer interfaces	In this paper, we propose a model to predict the performance of selection techniques using Brain-Computer Interfaces based on P300 signals. This model is based on Markov theory and can compute both the time required to select a target and the number of visual flashes needed. We illustrate how to use this model with three different interaction techniques to select a target. A first experimental evaluation with three healthy participants shows a good match between the model and the experimental data.
2009	Discriminating the relevance of web search results with measures of pupil size	The overwhelming amount of information on the web makes it critical for users to quickly and accurately evaluate the relevance of content. Here we tested whether pupil size can be used to discriminate the perceived relevance of web search results. Our findings revealed that measures of pupil size carry information that can be used to discriminate the relevance of text and image web search results, but the low signal-to-noise ratio poses challenges that need to be overcome when using this technique in naturalistic settings. Despite these challenges, our findings highlight the promise that pupillometry has as a technique that can be used to assess interest and relevance in web interaction in a non-intrusive and objective way.
2009	Anatomy of a failure: how we knew when our design went wrong, and what we learned from it	In this paper, we describe the failure of a novel sensor-based system intended to evoke user interpretation and appropriation in domestic settings. We contrast participants' interactions in this case study with those observed during more successful deployments to identify 'symptoms of failure' under four themes: engagement, reference, accommodation, and surprise and insight. These themes provide a set of sensitivities or orientations that may complement traditional task-based approaches to evaluation as well as the more open-ended ones we describe here. Our system showed symptoms of failure under each of these themes. We examine the reasons for this at three levels: problems particular to the specific design hypothesis; problems relevant for input-output mapping more generally; and problems in the design process we used. We conclude by noting that, although interpretive systems such as the one we describe here may succeed in a myriad of different ways, it is reassuring to know that they can also fail, and fail incontrovertibly, yet instructively.
2009	Getting there: six meta-principles and interaction design	Principled knowledge is a mark of any established disciplinary practice. Its derivation and validation of varies across disciplines, but HCI has tended towards posthoc ('a posteriori') syntheses. We present an alternative a priori approach that is relatively compact and open to inspection. We use John Heskett's position on the origins of design outcomes to derive six metaprinciples for all design processes: receptiveness, expressivity, committedness, credibility, inclusiveness and improvability. Although very abstract, these meta-principles generate critical insights into existing HCI approaches, identifying gaps in suitability and coverage. Practical value is increased by progressive instantiation of meta-principles to create first craft-specific, and ultimately project-specific, Interaction Design principles. A worth-centred approach is adopted to illustrate progressive instantiation towards a framework of adapted and novel HCI approaches. The internal coherence of the six metaprinciples is shown to provide direct effective support for synergistic progressive instantiation.
2009	On being supple: in search of rigor without rigidity in meeting new design and evaluation challenges for HCI practitioners	In this paper, we argue that HCI practitioners are facing new challenges in design and evaluation that can benefit from the establishment of commonly valued use qualities, with associated strategies for producing and rigorously evaluating work. We present a particular use quality 'suppleness' as an example. We describe ways that use qualities can help shape design and evaluation process, and propose tactics for the CHI community to use to encourage the evolution of bodies of knowledge around use qualities.
2009	Tactile motion instructions for physical activities	While learning new motor skills, we often rely on feedback from a trainer. Auditive feedback and demonstrations are used most frequently, but in many domains they are inappropriate or impractical. We introduce tactile instructions as an alternative to assist in correcting wrong posture during physical activities, and present a set of full-body vibrotactile patterns. An initial study informed the design of our tactile patterns, and determined appropriate locations for feedback on the body. A second experiment showed that users perceived and correctly classified our tactile instruction patterns in a relaxed setting and during a cognitively and physically demanding task. In a final experiment, snowboarders on the slope compared their perception of tactile instructions with audio instructions under real-world conditions. Tactile instructions achieved overall high recognition accuracy similar to audio instructions. Moreover, participants responded quicker to instructions delivered over the tactile channel than to instructions presented over the audio channel. Our findings suggest that these full-body tactile feedback patterns can replace audio instructions during physical activities.
2009	Audio or tactile feedback: which modality when?	When designing interfaces for mobile devices it is import-ant to take into account the variety of contexts of use. We present a study that examines how changing noise and dis-turbance in the environment affects user performance in a touchscreen typing task with the interface being presented through visual only, visual and tactile, or visual and audio feedback. The aim of the study is to show at what exact environmental levels audio or tactile feedback become inef-fective. The results show significant decreases in perform-ance for audio feedback at levels of 94dB and above as well as decreases in performance for tactile feedback at vibration levels of 9.18g/s. These results suggest that at these levels, feedback should be presented by a different modality. These findings will allow designers to take advantage of sensor enabled mobile devices to adapt the provided feed-back to the user's current context.
2009	Tactile feedback for predictive text entry	Predictive text entry provides a fast way to enter text on phones and other small devices. Early work on predictive text entry highlighted that the reaction time for checking the screen dominates text entry times. Improving accuracy of predictions brings a downside: as prediction gets better, users will drop the slow operation of checking the screen and will thus miss prediction errors and system feedback/suggestions. In this note, we present an experiment into the use of vibration to alert the user when word completion is likely to aid them, using a dynamic approach based on their current typing speed, and when there are no dictionary matches to their entry. Results show significantly faster entry rates for users with vibration alerts, raising speeds from 20wpm to 23wpm once practiced.
2009	Texture displays: a passive approach to tactile presentation	In this paper, we consider a passive approach to tactile presentation based on changing the surface textures of objects that might naturally be handled by a user. This may allow devices and other objects to convey small amounts of information in very unobtrusive ways and with little attention demand. This paper considers several possible uses for this style of display and explores implementation issues. We conclude with results from our user study, which indicate that users can detect upwards of four textural states accurately with even simple materials.
2009	TypeRight: a keyboard with tactile error prevention	TypeRight is a new tactile input device for text entry. It combines the advantages of tactile feedback with error prevention methods of word processors. TypeRight extends the standard keyboard so that the resistance to press each key becomes dynamically adjustable through software. Before each keystroke, the resistance of keys that would lead to a typing error according to dictionary and grammar rules is increased momentarily to make them harder to press, thus avoiding typing errors rather than indicating them after the fact. Two user studies showed that TypeRight decreases error correction rates by an average of 46\%.
2009	GestureBar: improving the approachability of gesture-based interfaces	GestureBar is a novel, approachable UI for learning gestural interactions that enables a walk-up-and-use experience which is in the same class as standard menu and toolbar interfaces. GestureBar leverages the familiar, clean look of a common toolbar, but in place of executing commands, richly discloses how to execute commands with gestures, through animated images, detail tips and an out-of-document practice area. GestureBar's simple design is also general enough for use with any recognition technique and for integration with standard, non-gestural UI components. We evaluate GestureBar in a formal experiment showing that users can perform complex, ecologically valid tasks in a purely gestural system without training, introduction, or prior gesture experience when using GestureBar, discovering and learning a high percentage of the gestures needed to perform the tasks optimally, and significantly outperforming a state of the art crib sheet. The relative contribution of the major design elements of GestureBar is also explored. A second experiment shows that GestureBar is preferred to a basic crib sheet and two enhanced crib sheet variations.
2009	Lean collaboration through video gestures: co-ordinating the production of live televised sport	This paper examines the work and interactions between camera operators and a vision mixer during an ice hockey match, and presents an interaction analysis using video data. We analyze video-mediated indexical gestures in the collaborative production of live sport on television between distributed team members. The findings demonstrate how video forms the topic, resource and product of collabora-tion: whilst it shapes the nature of the work (editing), it is simultaneously also the primary resource for supporting mutual orientation and negotiating shot transitions between remote participants (co-ordination), as well as its end prod-uct (broadcast). Our analysis of current professional activi-ties is used to develop implications for the design of future services for live collaborative video production.
2009	Using strokes as command shortcuts: cognitive benefits and toolkit support	This paper investigates using stroke gestures as shortcuts to menu selection. We first experimentally measured the performance and ease of learning of stroke shortcuts in comparison to keyboard shortcuts when there is no mnemonic link between the shortcut and the command. While both types of shortcuts had the same level of performance with enough practice, stroke shortcuts had substantial cognitive advantages in learning and recall. With the same amount of practice, users could successfully recall more shortcuts and make fewer errors with stroke shortcuts than with keyboard shortcuts. The second half of the paper focuses on UI development support and articulates guidelines for toolkits to implement stroke shortcuts in a wide range of software applications. We illustrate how to apply these guidelines by introducing the Stroke Shortcuts Toolkit (SST) which is a library for adding stroke shortcuts to Java Swing applications with just a few lines of code.
2009	A user study on visualizing directed edges in graphs	Graphs are often visualized using node-link representations: vertices are depicted as dots, edges are depicted as (poly)lines connecting two vertices. A directed edge running from vertex A to B is generally visualized using an arrow representation: a (poly)line with a triangular arrowhead at vertex B. Although this representation is intuitive, it is not guaranteed that a user is able to determine edge direction as quickly and unambiguously as possible; alternative representations that exhibit less occlusion and visual clutter might be better suited. To investigate this, we developed five additional directed-edge representations using combinations of shape and color. We performed a user study in which subjects performed different tasks on a collection of graphs using these representations and combinations thereof to investigate which representation is best in terms of speed and accuracy. We present our initial hypotheses, the outcome of the user studies, and recommendations regarding directed-edge visualization.
2009	Path selection: a novel interaction technique for mapping applications	Many online mapping applications let users define routes, perhaps for sharing a favorite bicycle commuting route or rating several contiguous city blocks. At the UI level, defining a route amounts to selecting a fairly large number of objects - the individual segments of roads and trails that make up the route. We present a novel interaction technique for this task called path selection. We implemented the technique and evaluated it experimentally, finding that adding path selection to a state-of-the-art technique for selecting individual objects reduced route definition time by about a factor of 2, reduced errors, and improved user satisfaction. Detailed analysis of the results showed path selection is most advantageous (a) for routes with long straight segments and (b) when objects that are optimal click targets also are visually attractive.
2009	Topology-aware navigation in large networks	Applications supporting navigation in large networks are used every days by millions of people. They include road map navigators, flight route visualization systems, and network visualization systems using node-link diagrams. These applications currently provide generic interaction methods for navigation: pan-and-zoom and sometimes bird's eye views. This article explores the idea of exploiting the connection information provided by the network to help navigate these large spaces. We visually augment two traditional navigation methods, and develop two special-purpose techniques. The first new technique, called "Link Sliding", provides guided panning when continuously dragging along a visible link. The second technique, called "Bring & Go", brings adjacent nodes nearby when pointing to a node. We compare the performance of these techniques in both an adjacency exploration task and a node revisiting task. This comparison illustrates the various advantages of content-aware network navigation techniques. A significant speed advantage is found for the Bring & Go technique over other methods.
2009	Sharing empty moments: design for remote couples	Many couples are forced to live apart, for work, school or other reasons. This paper describes our study of 13 such couples and what they lack from existing communication technologies. We explored what they wanted to share (presence, mood, environment, daily events and activities), how they wanted to share (simple, lightweight, playful, pleasant interaction), and when they wanted to share ('empty moments' such as waiting, walking, taking a break, waking up, eating, and going to sleep). 'Empty moments' provide a compelling new opportunity for design, requiring subtlety and flexibility to enable participants to share connection without explicit messages. We designed MissU as a technology probe to study empty moments in situ. Similar to a private radio station, MissU shares music and background sounds. Field studies produced results relevant to social science, technology and design: couples with established routines were comforted; characteristics such as ambiguity and 'movable' technology (situated in the home yet portable) provide support. These insights suggest a design space for supporting the sharing of empty moments.
2009	Supporting content and process common ground in computer-supported teamwork	We build on our prior work with computer-supported teams performing a complex decision-making task on maps, where the distinction between content and process common ground is proposed. In this paper we describe a distributed geo-collaboration software prototype. The system design rationale was gleaned from fieldwork, literature on team cognition, and an earlier lab study introducing a reference task with face-to-face teams. We report on a controlled experiment that evaluates this design rationale. Distinct sets of measures show that that the prototype supported both content and process common ground, offsetting the costs imposed by the distributed setting. We interpret the results in relation to prior work on common ground and draw implications for moving beyond current models of sharing and coordination.
2009	Conversation clusters: grouping conversation topics through human-computer dialog	Conversation Clusters explores the use of visualization to highlight salient moments of live conversation while archiving a meeting. Cheaper storage and easy access to recording devices allows extensive archival. However, as the size of the archive grows, retrieving the desired moments becomes increasingly difficult. We approach this problem from a socio-technical perspective and utilize human intuition aided by computer memory. We present computationally detected topics of conversation as visual summaries of discussion and as reference points into the archive. To further bootstrap the system, humans can participate in a dialog with the visualization of the clustering process and shape the development of clustering models.
2009	Effects of real-time transcription on non-native speaker's comprehension in computer-mediated communications	We performed an empirical study to understand the relative contributions of real-time transcription to a non-native speaker's comprehension in audio/video meetings. 48 participants were assigned to 2 presentation modes (audio, audio+video) and 3 transcription modes (no transcript, real-time transcripts in the streaming mode, transcripts with all past records) in a 3x2 factorial experimental design. The results suggest that comprehension can be significantly improved for both audio and audio+video conditions when real-time transcription is provided. Also, the participants reported positive subjective responses to the presence of real-time transcription in terms of usefulness, preference, and willingness to use such a feature if provided. No cognitive load issues were reported by the participants in the ability to synthesize across modalities. Implications for system development and design, as well as future work utilizing automation speech recognition to provide the transcripts are discussed.
2009	Interaction criticism and aesthetics	As HCI becomes more self-consciously implicated in cul-ture, theories from cultural studies, in particular aesthetics and critical theory, are increasingly working their way into the field. However, the use of aesthetics and critical theory in HCI remains both marginal and uneven in quality. This paper explores the state of the art of aesthetics and critical theory in the field, before going on to explore the role of these cultural theories in the analysis and deployment of the twin anchors of interaction: the user and the artifact. In concludes with a proposed mapping of aesthetics and criti-cal theory into interaction design, both as a practice and as a discipline.
2009	Understanding knowledge management practices for early design activity and its implications for reuse	Prior knowledge is a critical resource for design, especially when designers are striving to generate new ideas for complex problems. Systems that improve access to relevant prior knowledge and promote reuse can improve design efficiency and outcomes. Unfortunately, such systems have not been widely adopted indicating that user needs in this area have not been adequately understood. In this paper, we report the results of a contextual inquiry into the practices of and attitudes toward knowledge management and reuse during early design. The study consisted of interviews and surveys with professional designers in the creative domains. A novel aspect of our work is the focus on early design, which differs from but complements prior works' focus on knowledge reuse during later design and implementation phases. Our study yielded new findings and implications that, if applied, will help bring the benefits of knowledge management systems and reuse into early design activity.
2009	Correlating low-level image statistics with users - rapid aesthetic and affective judgments of web pages	In this paper, we report a study that examines the relationship between image-based computational analyses of web pages and users' aesthetic judgments about the same image material. Web pages were iteratively decomposed into quadrants of minimum entropy (quadtree decomposition) based on low-level image statistics, to permit a characterization of these pages in terms of their respective organizational symmetry, balance and equilibrium. These attributes were then evaluated for their correlation with human participants' subjective ratings of the same web pages on four aesthetic and affective dimensions. Several of these correlations were quite large and revealed interesting patterns in the relationship between low-level (i.e., pixel-level) image statistics and design-relevant dimensions.
2009	Exploring the analytical processes of intelligence analysts	We present an observational case study in which we investigate and analyze the analytical processes of intelligence analysts. Participating analysts in the study carry out two scenarios where they organize and triage information, conduct intelligence analysis, report results, and collaborate with one another. Through a combination of scenario-based analysis, artifact analysis, role-playing, interviews, and participant observations, we explore the space and boundaries in which intelligence analysts work and operate. We also assess the implications of our findings on the use and application of key information technologies.
2009	What do you see when you're surfing?: using eye tracking to predict salient regions of web pages	An understanding of how people allocate their visual attention when viewing Web pages is very important for Web authors, interface designers, advertisers and others. Such knowledge opens the door to a variety of innovations, ranging from improved Web page design to the creation of compact, yet recognizable, visual representations of long pages. We present an eye-tracking study in which 20 users viewed 361 Web pages while engaged in information foraging and page recognition tasks. From this data, we describe general location-based characteristics of visual attention for Web pages dependent on different tasks and demographics, and generate a model for predicting the visual attention that individual page elements may receive. Finally, we introduce the concept of fixation impact, a new method for mapping gaze data to visual scenes that is motivated by findings in vision research.
2009	Designing digital games for rural children: a study of traditional village games in India	Low educational levels hinder economic empowerment in developing countries. We make the case that educational games can impact children in the developing world. We report on exploratory studies with three communities in North and South India to show some problems with digital games that fail to match rural children's understanding of games, to highlight that there is much for us to learn about designing games that are culturally meaningful to them. We describe 28 traditional village games that they play, based on our contextual interviews. We analyze the mechanics in these games and compare these mechanics against existing videogames to show what makes traditional games unique. Our analysis has helped us to interpret the playability issues that we observed in our exploratory studies, and informed the design of a new videogame that rural children found to be more intuitive and engaging.
2009	Non-universal usability?: a survey of how usability is understood by Chinese and Danish users	Most research assumes that usability is understood similarly by users in different cultures, implying that the notion of usability, its aspects, and their interrelations are constant across cultures. The present study shows that this is not the case for a sample of 412 users from China and Denmark, who differ in how they understand and prioritize different aspects of usability. Chinese users appear to be more concerned with visual appearance, satisfaction, and fun than Danish users; Danish users prioritize effectiveness, efficiency, and lack of frustration higher than Chinese users. The results suggest that culture influences perceptions of usability. We discuss implications for usability research and for usability practice.
2009	A comparative study of speech and dialed input voice interfaces in rural India	In this paper we present a study comparing speech and dialed input voice user interfaces for farmers in Gujarat, India. We ran a controlled, between-subjects experiment with 45 participants. We found that the task completion rates were significantly higher with dialed input, particularly for subjects under age 30 and those with less than an eighth grade education. Additionally, participants using dialed input demonstrated a significantly greater performance improvement from the first to final task, and reported less difficulty providing input to the system.
2009	Sacred imagery in techno-spiritual design	Despite increased knowledge about how Information and Communications Technologies (ICTs) are used to support religious and spiritual practices, designers know little about how to design technologies for faith-related purposes. Our research suggests incorporating sacred imagery into techno-spiritual applications can be useful in guiding development. We illustrate this through the design and evaluation of a mobile phone application developed to support Islamic prayer practices. Our contribution is to show how religious imagery can be used in the design of applications that go beyond the provision of functionality to connect people to the experience of religion.
2009	Expert recommender systems in practice: evaluating semi-automatic profile generation	Expert recommender systems (ERS) are considered a promising technology in knowledge management. However, there are very few studies which evaluated their appropriation in practice. In this paper, we present results of a case study of expert recommender technology in a large European industrial association. Unlike existing expert recommender approaches, the system involves users in selecting textual documents for semi-automatic profile generation. Our study focuses on the appropriation of this functionality and discusses impacts from an organizational perspective.
2009	Making sense of strangers' expertise from signals in digital artifacts	Contemporary work increasingly involves interacting with strangers in technology-mediated environments. In this context, we come to rely on digital artifacts to infer characteristics of other people. This paper reports the results of a study conducted in a global company that used expertise search as a vehicle for exploring how people interpret a range of information available in online profiles in evaluating whom to interact with for expertise. Using signaling theory as a conceptual framework, we describe how certain 'signals' in various social software are hard to fake, and are thus more reliable indicators of expertise. Multi-level regression analysis revealed that participation in social software, social connection information, and self-described expertise in the corporate directory were significantly helpful in the decision to contact someone for expertise. Qualitative analysis provided further insights regarding the interpretations people form of others' expertise from digital artifacts. We conclude with suggestions on differentiating various types of information available within online profiles and implications for the design of expertise locator/recommender systems.
2009	An exploration of social requirements for exercise group formation	Exercising is often a social activity performed with other people, yet finding compatible exercise partners is difficult in practice. To gain a better understanding of the social requirements involved with forming exercise groups, we conducted a two-phased exploratory study involving an online web questionnaire with 96 respondents and two focus groups. Our results highlight various aspects of collaborating with exercise partners, but also indicate the limited utility of currently available systems to support such collaborations. We discuss implications for collaborative technologies supporting exercise group formation.
2009	Team analytics: understanding teams in the global workplace	Many medium and large companies maintain internal employee directories. Unfortunately, most directories only allow the lookup of individual profiles, one profile at a time. Team Analytics is a novel application that integrates information from disparate enterprise tools for groups of people. Besides accelerating the lookup process, Team Analytics also displays information that is only available in the group context, such as an organizational chart and time zone awareness. We present the Team Analytics application, its integration with our corporate email client, and results from a user survey that evaluates various aspects of the application.
2009	Getting inspired!: understanding how and why examples are used in creative design practice	The use of examples serves a critical role in creative design practice, but details of this process remain an enigma. This is problematic for both the understanding of design activity as well as for developing more effective design tools. In this paper, we report results of a study that understands and compares how designers (N=11) utilize, manage, and share examples to support the creative design process. The domains studied were Web, graphic, and product design. Our study shows that examples are a cornerstone of creative practice and are utilized for many reasons throughout the design process. Since examples are pivotal to the success of a project, more effective tools that support retrieval, storage, and dissemination of examples are needed. This paper contributes understanding of the benefits and roles of examples in the design process and implications for the design of more effective tools that support example usage.
2009	Using improvisation to enhance the effectiveness of brainstorming	Group brainstorming is a popular ideation method for design teams, yet brainstorming outcomes vary greatly. The method depends on individuals working collectively to generate ideas, and so group dynamics determine whether the method succeeds or fails. This paper explores how interaction designers used techniques from theatrical improvisation, or improv, to adhere to the rules of brainstorming thereby enhancing group interactions while collaborating. The usefulness of improvisation for brainstorming stems from the similarity of the goals of improvisation and brainstorming, the similarity of the recurrent problems that actors and designers encounter when collaborating, and the distinctness of the ways each have devised to resolve the problems that block the group's performance. This paper reflects on the individual- and group-level outcomes for design students and practitioners while brainstorming.
2009	Interactivity attributes: a new way of thinking and describing interactivity	We propose a new perspective, seeing interactivity that is the immaterial part of an interactive artifact as something concretely describable and perceivable as we do with physical materials. In order to examine the validity of this proposal, we extracted a set of interactivity attributes to be used as a design language for thinking and describing interactivity in a new way, and conducted an online survey with 14 Flash prototypes representing pairs of values of 7 interactivity attributes we extracted. The result showed that all the interactivity attributes were significant, and participants experienced distinctive and meaningful emotional effects for different interactivity attributes.
2009	PrintMarmoset: redesigning the print button for sustainability	In this paper, we discuss some unique challenges of sustainable interaction design (SID) and present our work that aims to reduce paper waste from web printing. We conducted a two-month field study of current behaviors and attitudes around printing, and the results confirmed the affordances of paper, but also revealed many problems associated with printing web content. We then designed and implemented a browser extension, PrintMarmoset, that targets these problems while simultaneously addressing user needs and environmental responsibility. It allows users to effortless select or remove web content for printing. We have also incorporated a data sharing mechanism into our solution to assist in the adoption of the tool and created visualizations to encourage user reflection and exploration.
2009	Design, implementation and evaluation of a novel public display for pedestrian navigation: the rotating compass	Important drawbacks of map-based navigation applications for mobile phones are their small screen size and that users have to associate the information provided by the mobile phone with the real word. Therefore, we designed, implemented and evaluated the Rotating Compass - a novel public display for pedestrian navigation. Here, a floor display continuously shows different directions (in a clockwise order) and the mobile phone informs the user when their desired direction is indicated. To inform the user, the mobile phone vibrates in synchronization with the indicated direction. We report an outdoor study that compares a conventional paper map, a navigation application running on a mobile device, navigation information provided by a public display, and the Rotating Compass. The results provide clear evidence of the advantages of the new interaction technique when considering task completion time, context switches, disorientation events, usability satisfaction, workload and multi-user support.
2009	EyeSpy: supporting navigation through play	This paper demonstrates how useful content can be generated as a by-product of an enjoyable mobile multiplayer game. In EyeSpy, players tag geographic locations with photos or text. By locating the places in which other players' tags were created and 'confirming' them, players earn points for themselves and verify the tags' locations. As a side effect of game-play, EyeSpy produces a collection of recognisable and findable geographic details, in the form of photographs and text tags, that can be repurposed to support navigation tasks. Two user trials of the game successfully produced an archive of geo-located photographs and tags, and in a follow-up experiment we compared performance in a navigation task using photographs from the game, with geo-referenced photos collected from the Flickr website. Our experiences with EyeSpy support reflection upon the design challenges presented by 'human computation' and the production of usable by-products through mobile game-play.
2009	Simulated augmented reality windshield display as a cognitive mapping aid for elder driver navigation	A common effect of aging is decline in spatial cognition. This is an issue for all elders, but particularly for elder drivers. To address this driving issue, we propose a novel concept of an in-vehicle navigation display system that displays navigation information directly onto the vehicle's windshield, superimposing it on the driver's view of the actual road. An evaluation of our simulated version of this display shows that it results in a significant reduction in navigation errors and distraction-related measures compared to a typical in-car navigation display for elder drivers. These results help us understand how context-sensitive information and a simulated augmented reality representation can be combined to minimize the cognitive load in translating between virtual/information spaces and the real world.
2009	PenLight: combining a mobile projector and a digital pen for dynamic visual overlay	Digital pen systems, originally designed to digitize annotations made on physical paper, are evolving to permit a wider variety of applications. Although the type and quality of pen feedback (e.g., haptic, audio, and visual) have a huge impact on advancing the digital pen technology, dynamic visual feedback has yet to be fully investigated. In parallel, miniature projectors are an emerging technology with the potential to enhance visual feedback for small mobile computing devices. In this paper we present the PenLight system, which is a testbed to explore the interaction design space and its accompanying interaction techniques in a digital pen embedded with a spatially-aware miniature projector. Using our prototype, that simulates a miniature projection (via a standard video projector), we visually augment paper documents, giving the user immediate access to additional information and computational tools. We also show how virtual ink can be managed in single and multi-user environments to aid collaboration and data management. User evaluation with professional architects indicated promise of our proposed techniques and their potential utility in the paper-intensive domain of architecture.
2009	To move or not to move: a comparison between steerable versus fixed focus region paradigms in multi-resolution tabletop display systems	Previous studies have outlined the advantages of multi-resolution large-area displays over their fixed-resolution counterparts, however the mobility of the focus region has up until the present time received little attention. To study this phenomenon further, we have developed a multi-resolution tabletop display system with a steerable high resolution focus region to compare the performance between steerable and fixed focus region systems under different working scenarios. We have classified these scenarios according to region of interest (ROI) with analogies to different eye movement types (fixed, saccadic, and pursuit ROI). Empirical data gathered during the course of a multi-faceted user study demonstrates that the steerable focus region system significantly outperforms the fixed focus region system. The former is shown to provide enhanced display manipulation and proves especially advantageous in cases where the user must maintain spatial awareness of the display content as is the case in which, within a single session, several regions of the display are to be visited.
2009	Transparent 2-D markers on an LCD tabletop system	Tabletop systems are currently being focused on and many applications using these systems are being developed. In such tabletop systems, how to recognize real objects on the table is an essential and important issue. In existing tabletop systems, 2-D markers have been often used. However, their black-and-white pattern, which means nothing to humans, spoils the appearance of the object. We developed transparent markers on a liquid crystal display (LCD) tabletop system by using the polarization features of the LCD and optical lms. In particular, through experiments with various kinds of optical films, we found that two halfwave plates make the markers rotation invariant. By using the transparent markers, tangible transparent Magic Lenses(TM) applications were developed.
2009	Magic cards: a paper tag interface for implicit robot control	Typical Human Robot Interaction (HRI) assumes that the user explicitly interacts with robots. However, explicit control with robots can be unnecessary or even undesirable in certain cases, such as dealing with domestic services (or housework). In this paper, we propose an alternative strategy of interaction: the user implicitly controls a robot by issuing commands on corresponding real world objects and the environment. Robots then discover these commands and complete them in the background. We implemented a paper-tag-based interface to support such implicit robot control in a sensor-augmented home environment. Our initial user studies indicated that the paper-tag-based interface is particularly simple to use and provides users with flexibility in planning and controlling their housework tasks in a simulated home environment.
2009	The VoiceBot: a voice controlled robot arm	We present a system whereby the human voice may specify continuous control signals to manipulate a simulated 2D robotic arm and a real 3D robotic arm. Our goal is to move towards making accessible the manipulation of everyday objects to individuals with motor impairments. Using our system, we performed several studies using control style variants for both the 2D and 3D arms. Results show that it is indeed possible for a user to learn to effectively manipulate real-world objects with a robotic arm using only non-verbal voice as a control mechanism. Our results provide strong evidence that the further development of non-verbal voice controlled robotics and prosthetic limbs will be successful.
2009	Pimp My Roomba: designing for personalization	We present a study of how householders personalize their domestic vacuuming robot, iRobot's Roomba". In particular, we build on Blom and Monk's [3] theory of personalization that argues that personalization does not only occur naturally but can also be induced by design choices. In this study, we created a personalization toolkit, which allowed people to customize their Roomba's appearance and distributed it to 15 households. Our observations of these households provide empirical support that personalization can facilitate positive experiences with a Roomba, and having materials to hand can increase the odds of customization. We conclude by discussing design implications for personalization.
2009	Sketch and run: a stroke-based interface for home robots	Numerous robots have been developed, and some of them are already being used in homes, institutions, and workplaces. Despite the development of useful robot functions, the focus so far has not been on user interfaces of robots. General users of robots find it hard to understand what the robots are doing and what kind of work they can do. This paper presents an interface for the commanding home robots by using stroke gestures on a computer screen. This interface allows the user to control robots and design their behaviors by sketching the robot's behaviors and actions on a top-down view from ceiling cameras. To convey a feeling of directly controlling the robots, our interface employs the live camera view. In this study, we focused on a house-cleaning task that is typical of home robots, and developed a sketch interface for designing behaviors of vacuuming robots.
2009	Make new friends, but keep the old: recommending people on social networking sites	This paper studies people recommendations designed to help users find known, offline contacts and discover new friends on social networking sites. We evaluated four recommender algorithms in an enterprise social networking site using a personalized survey of 500 users and a field study of 3,000 users. We found all algorithms effective in expanding users' friend lists. Algorithms based on social network information were able to produce better-received recommendations and find more known contacts for users, while algorithms using similarity of user-created content were stronger in discovering new friends. We also collected qualitative feedback from our survey users and draw several meaningful design implications.
2009	Predicting tie strength with social media	Social media treats all users the same: trusted friend or total stranger, with little or nothing in between. In reality, relationships fall everywhere along this spectrum, a topic social science has investigated for decades under the theme of tie strength. Our work bridges this gap between theory and practice. In this paper, we present a predictive model that maps social media data to tie strength. The model builds on a dataset of over 2,000 social media ties and performs quite well, distinguishing between strong and weak ties with over 85\% accuracy. We complement these quantitative findings with interviews that unpack the relationships we could not predict. The paper concludes by illustrating how modeling tie strength can improve social media design elements, including privacy controls, message routing, friend introductions and information prioritization.
2009	My Dating Site Thinks I'm a Loser: effects of personal photos and presentation intervals on perceptions of recommender systems	Receiving poor results from a personalized recommendation system is frustrating. When users try to compensate by putting on a "different face" and game the system, the results can be even more frustrating. This paper investigates how to improve the user experience of such systems by: 1) adding personal photos to increase self-awareness, and 2) providing recommendations interspersed with personal questions. A 2x2 web experiment (N=56) within the context of an online dating match recommendation system was used to assess these two effects. Displaying a person's photo stabilized both response strategies and liking of a recommender's poor suggestions. Additionally, presenting all of the results together at the end was less frustrating than spreading them out. These results demonstrate that simple interface design decisions can have profound effects on user behaviors and attitudes with personalized recommendation systems.
2009	The application of forgiveness in social system design	When an offence occurs, the victim and offender can overcome the harm done through forgiveness. This paper demonstrates how forgiveness can be supported in social system design. We first describe what forgiveness is, how it is motivated and what benefits follow from forgiveness. Based on this theoretical analysis, we propose five provisions to guide designers who want to encourage reparation in social systems.
2009	Friend or foe?: examining CAS use in mathematics research	Computer Algebra Systems (CAS) provide sophisticated functionality to assist with mathematical problem solving. Despite their widespread adoption, however, little work in the HCI community has examined the extent to which these computational tools support domain experts. In this paper, we report findings from a qualitative study investigating the work practices and tools of nine mathematicians in a research setting. Counter to our expectations, our data suggests that computational tools play only a minor role in their workflow, with the limited use of CAS owing primarily to four factors: (1) the need for transparency in CAS's reasoning to explain computed results; (2) the problem of rigidity and formality in CAS's input/output style dialogue; (3) the need for 2D input to support a wide range of annotations, diagrams, and in-place manipulation of objects of interest; and (4) the need for collaboration, particularly in early stages of problem solving. While grounded in the study of mathematicians, these findings (particularly the first) have implications for the design of computational systems intended to support complex problem solving.
2009	Pathfinder: an online collaboration environment for citizen scientists	For over a century, citizen scientists have volunteered to collect huge quantities of data for professional scientists to analyze. We designed Pathfinder, an online environment that challenges this traditional division of labor by providing tools for citizen scientists to collaboratively discuss and analyze the data they collect. We evaluated Pathfinder in a sustainability and commuting context using a mixed methods approach in both naturalistic and experimental settings. Our results showed that citizen scientists preferred Pathfinder to a standard wiki and were able to go beyond data collection and engage in deeper discussion and analyses. We also found that citizen scientists require special types of technological support because they generate original research. This paper offers an early example of the mutually beneficial relationship between HCI and citizen science.
2009	The TeeBoard: an education-friendly construction platform for e-textiles and wearable computing	The field of wearable computing and e-textiles has recently attracted much interest from the research and general community. Recent developments in this field raises the possibility of e-textile construction kits for hobbyists and novices alike. The unique nature of wearable computing and e-textiles also gives it a lot of potential as an educational computing topic, as it allows students to exercise their creativity and imagination while learning about computing and technology. However, there are numerous difficulties involved in deploying existing technology in an educational environment. Current state of the art technology and techniques are not yet robust or reliable enough to stand up to the demands of educational computing, and they require a high level of skill from the user. In this paper, we present the TeeBoard, a constructive platform for e-textiles and wearable computing that is designed specifically to "lower the floor" for the integration of e-textiles into educational computing.
2009	It feels better than filing: everyday work experiences in an activity-based computing system	Activity-based computing represents an alternative to the dominant application- and document-centric model at the foundation of most mainstream desktop computing interfaces. In this paper, we present in-depth results from an in situ, longitudinal study of an activity-based computing system, Giornata. We detail the ways that the specific features of this system influenced the everyday work experiences of a small cohort of knowledge workers. Our analysis provides contributions at several levels of granularity-we provide concrete design recommendations based on participants' reactions to the particular features of the Giornata system and a discussion about how our findings can provide insight about the broader understanding of knowledge work and activity within HCI.
2009	It's not that important: demoting personal information of low subjective importance using GrayArea	Users find it hard to delete unimportant personal information which often results in cluttered workspaces. We present a full design cycle for GrayArea, a novel interface that allows users to demote unimportant files by dragging them to a gray area at the bottom of their file folders. Demotion is an intermediate option between keeping and deleting. It combines the advantages of deletion (unimportant files don't compete for attention) and keeping (files are retrieved in their folder context). We developed the GrayArea working prototype using thorough iterative design. We evaluated it by asking 96 participants to 'clean' two folders with, and without, GrayArea. Using GrayArea reduced folder clutter by 13\%. Further, 81\% of participants found it easier to demote than delete files, and most indicated they would use GrayArea if provided in their operating systems. The results provide strong evidence for the demotion principle suggested by the user-subjective approach.
2009	Lightweight tagging expands information and activity management practices	Could people use tagging to manage day-to-day work in their personal computing environment? Could tagging be sufficiently generic and lightweight to support diverse ways of working and, perhaps, support new and efficient practices for managing applications and accessing documents? We investigate these issues by implementing the TAGtivity system that enables users to tag resources in the context of their ongoing work. We deployed TAGtivity and studied users' tagging practices in their actual work places over a three week period. Our analysis of interviews and logs reveals that affordances of the TAGtivity system supported users in a variety of information and activity management tasks. These include new practices for managing emerging activities and ephemeral information and accessing documents across application data silos.
2009	Motion-pointing: target selection using elliptical motions	We present a novel method called motion-pointing for selecting a set of visual items such as push-buttons without actually pointing to them. Instead, each potential target displays a rhythmically animated point we call the driver. To select a specific item, the user only has to imitate the motion of its driver using the input device. Once the motion has been recognized by the system, the user can confirm the selection to trigger the action. We consider cyclic motions on an elliptic trajectory with a specific period, and study the most effective methods for real-time matching such a trajectory, as well as the range of parameters a human can reliably reproduce. We then show how to implement motion-pointing in real applications using an interaction technique we call move-and-stroke. Finally, we measure the throughput and error rate of move-and-stroke in a controlled experiment. We show that the selection time is linearly proportional to the number of input bits conveyed up to 6 bits, confirming that motion-pointing is a practical input method.
2009	Providing dynamically changeable physical buttons on a visual display	Physical buttons have the unique ability to provide low-attention and vision-free interactions through their intuitive tactile clues. Unfortunately, the physicality of these interfaces makes them static, limiting the number and types of user interfaces they can support. On the other hand, touch screen technologies provide the ultimate interface flexibility, but offer no inherent tactile qualities. In this paper, we describe a technique that seeks to occupy the space between these two extremes - offering some of the flexibility of touch screens, while retaining the beneficial tactile properties of physical interfaces. The outcome of our investigations is a visual display that contains deformable areas, able to produce physical buttons and other interface elements. These tactile features can be dynamically brought into and out of the interface, and otherwise manipulated under program control. The surfaces we describe provide the full dynamics of a visual display (through rear projection) as well as allowing for multitouch input (though an infrared lighting and camera setup behind the display). To illustrate the tactile capabilities of the surfaces, we describe a number of variations we uncovered in our exploration and prototyping. These go beyond simple on/off actuation and can be combined to provide a range of different possible tactile expressions. A preliminary user study indicates that our dynamic buttons perform much like physical buttons in tactile search tasks.
2009	The performance of touch screen soft buttons	The introduction of a new generation of attractive touch screen-based devices raises many basic usability questions whose answers may influence future design and market direction. With a set of current mobile devices, we conducted three experiments focusing on one of the most basic interaction actions on touch screens: the operation of soft buttons. Issues investigated in this set of experiments include: a comparison of soft button and hard button performance; the impact of audio and vibrato-tactile feedback; the impact of different types of touch sensors on use, behavior, and performance; a quantitative comparison of finger and stylus operation; and an assessment of the impact of soft button sizes below the traditional 22 mm recommendation as well as below finger width.
2009	Timing is everything?: the effects of timing and placement of online privacy indicators	Many commerce websites post privacy policies to address Internet shoppers' privacy concerns. However, few users read or understand them. Iconic privacy indicators may make privacy policies more accessible and easier for users to understand: in this paper, we examine whether the timing and placement of online privacy indicators impact Internet users' browsing and purchasing decisions. We conducted a laboratory study where we controlled the placement of privacy information, the timing of its appearance, the privacy level of each website, and the price and items being purchased. We found that the timing of privacy information had a significant impact on how much of a premium users were willing to pay for privacy. We also found that timing had less impact when users were willing to examine multiple websites. Finally, we found that users paid more attention to privacy indicators when purchasing privacy-sensitive items than when purchasing items that raised minimal privacy concerns.
2009	Designing trustworthy situated services: an implicit and explicit assessment of locative images-effect on trust	This paper examines a visual design element unique to situated, hot-spot style, services: locativeness. This is the extent to which the media representing a service relates to its immediate physical environment. This paper explores the effect of locativeness on trust with two studies assessing user attitudes in depth. The first is an implicit, or preconscious, test and the second an explicit test based on voiced value judgments. To provide a richer context, the second study contrasts locativeness with other traditional aspects of design: branding and quality. The results indicate users have a strong implicit association between locative images and trust, and that this is partially reflected in their explicit choices. This is an important interface aspect that designers should consider in order to create trustworthy situated services.
2009	Social computing privacy concerns: antecedents and effects	Social computing systems are increasingly a part of people's social environment. Inherent to such communities is the collection and sharing of personal information, which in turn may raise concerns about privacy. In this study, we extend prior research on internet privacy to address questions about antecedents of privacy concerns in social computing communities, as well as the impact of privacy concerns in such communities. The results indicate that users' trust in other community members, and the community's information sharing norms have a negative impact on community-specific privacy concerns. We also find that community-specific privacy concerns not only lead users to adopt more restrictive information sharing settings, but also reduce the amount of information they share with the community. In addition, we find that information sharing is impacted by network centrality and the tenure of the user in the community. Implications of the study for research and practice are discussed.
2009	An enhanced musical experience for the deaf: design and evaluation of a music display and a haptic chair	Music is a multi-dimensional experience informed by much more than hearing alone, and is thus accessible to people of all hearing abilities. In this paper we describe a prototype system designed to enrich the experience of music for the deaf by enhancing sensory input of information via channels other than in-air audio reception by the ear. The system has two main components-a vibrating 'Haptic Chair' and a computer display of informative visual effects that correspond to features of the music. The Haptic Chair provides sensory input of vibrations via touch. This system was developed based on an initial concept guided by information obtained from a background survey conducted with deaf people from multi-ethnic backgrounds and feedback received from two profoundly deaf musicians. A formal user study with 43 deaf participants suggested that the prototype system enhances the musical experience of a deaf person. All of the users preferred either the Haptic Chair alone (54\%) or the Haptic Chair with the visual display (46\%). The prototype system, especially the Haptic Chair was so enthusiastically received by our subjects that it is possible this system might significantly change the way the deaf community experiences music.
2009	Longitudinal study of people learning to use continuous voice-based cursor control	We conducted a 2.5 week longitudinal study with five motor impaired (MI) and four non-impaired (NMI) participants, in which they learned to use the Vocal Joystick, a voice-based user interface control system. We found that the participants were able to learn the mapping between the vowel sounds and directions used by the Vocal Joystick, and showed marked improvement in their target acquisition performance. At the end of the ten session period, the NMI group reached the same level of performance as the previously measured "expert" Vocal Joystick performance, and the MI group was able to reach 70\% of that level. Two of the MI participants were also able to approach the performance of their preferred device, a touchpad. We report on a number of issues that can inform the development of further enhancements in the realm of voice-driven computer control.
2009	Fast gaze typing with an adjustable dwell time	Previous research shows that text entry by gaze using dwell time is slow, about 5-10 words per minute (wpm). These results are based on experiments with novices using a constant dwell time, typically between 450 and 1000 ms. We conducted a longitudinal study to find out how fast novices learn to type by gaze using an adjustable dwell time. Our results show that the text entry rate increased from 6.9 wpm in the first session to 19.9 wpm in the tenth session. Correspondingly, the dwell time decreased from an average of 876 ms to 282 ms, and the error rates decreased from 1.28\% to .36\%. The achieved typing speed of nearly 20 wpm is comparable with the result of 17.3 wpm achieved in an earlier, similar study with Dasher.
2009	How well do visual verbs work in daily communication for young and old adults?	In this paper we study how verbs are visually conveyed in daily communication contexts for both young and old adults. Four visual modes are compared: a single static image, a panel of four static images, an animation, and a video clip. The results reveal age effects, as well as performance differences introduced by lexical verb properties and visual cues. We also suggest guidelines for visual verb creation.
2009	A sustainable identity: the creativity of an everyday designer	In this paper we explore sustainability in interaction design by reframing concepts of user identity and use in a domestic setting. Building on our own work on everyday design and Blevis's Sustainable Interaction Design principles, we present examples from an ethnographic study of families in their homes which illustrate design-in-use: the creative and sustainable ways people appropriate and adapt designed artifacts. We claim that adopting a conception of the user as a creative everyday designer generates a new set of design principles that promote sustainable interaction design.
2009	A vehicle for research: using street sweepers to explore the landscape of environmental community action	Researchers are developing mobile sensing platforms to facilitate public awareness of environmental conditions. However, turning such awareness into practical community action and political change requires more than just collecting and presenting data. To inform research on mobile environmental sensing, we conducted design fieldwork with government, private, and public interest stakeholders. In parallel, we built an environmental air quality sensing system and deployed it on street sweeping vehicles in a major U.S. city; this served as a research vehicle"by grounding our interviews and affording us status as environmental action researchers. In this paper, we present a qualitative analysis of the landscape of environmental action, focusing on insights that will help researchers frame meaningful technological interventions.
2009	Nourishing the ground for sustainable HCI: considerations from ecologically engaged art	Sustainable HCI is now a recognized area of human-computer interaction drawing from a variety of disciplinary approaches, including the arts. How might HCI researchers working on sustainability productively understand the discourses and practices of ecologically engaged art as a means of enriching their own activities? We argue that an understanding of both the history of ecologically engaged art, and the art-historical and critical discourses surrounding it, provide a fruitful entry-point into a more critically aware sustainable HCI. We illustrate this through a consideration of frameworks from the arts, looking specifically at how these frameworks act more as generative devices than prescriptive recipes. Taking artistic influences seriously will require a concomitant rethinking of sustainable HCI standpoints - a potentially useful exercise for HCI research in general.
2009	Designing for the self: making products that help people become the person they desire to be	Product attachment theory describes how people learn to love certain possessions through a process of meaning making. It provides a rich and as yet untapped source of inspiration for driving the practice of experience design. However, there are currently no guidelines that describe how to apply this theory in design practice. Taking a research through design approach, I made many different products with the goal of helping people become the person they desire to be through their product interactions. Then, in order to better understand how the different design teams applied attachment theory, I created a set of design patterns that document the application of product attachment theory to the interaction design of each product. I clustered the patterns based on similarities across the different artifacts, and this produced six framing constructs, which work as specific perspectives designers can take when applying product attachment theory in an experience design project.
2009	Theory-driven design strategies for technologies that support behavior change in everyday life	In this paper, we propose design strategies for persuasive technologies that help people who want to change their everyday behaviors. Our strategies use theory and prior work to substantially extend a set of existing design goals. Our extensions specifically account for social characteristics and other tactics that should be supported by persuasive technologies that target long-term discretionary use throughout everyday life. We used these strategies to design and build a system that encourages people to lead a physically active lifestyle. Results from two field studies of the system - a three-week trial and a three-month experiment - have shown that the system was successful at helping people maintain a more physically active lifestyle and validate the usefulness of the strategies.
2009	(Perceived) interactivity: does interactivity increase enjoyment and creative identity in artistic spaces?	The HCI community often operates under the assumption that interactivity enhances the user experience. In this study we are particularly interested in whether interactivity enhances an artistic experience by either promoting or constraining an audience's enjoyment and creative identity. The goal of the study was to test two research questions in an experimental context: 1.) How does interactive art impact user satisfaction, and 2.) How does interactive art shape the self-concept of the user as creative? Participants interacted with the system in the Interaction"(34 pairs) or"No Interaction (37 pairs) condition. Findings reveal that perceptions of interactivity correlate with user satisfaction, but do not influence user identity.
2009	Learning from IKEA hacking: i'm not one to decoupage a tabletop and call it a day.	We present a qualitative study based on interviews with nine IKEA Hackers - people who go online to share the process of repurposing IKEA products to create personalized objects. Whether they were making a self-conscious artistic statement or simply modifying a towel rack to fit in a small bathroom, IKEA hackers illuminate an emergent practice that provides insights into contemporary changes in creativity. We discuss the motivations for IKEA hacking and explore the impact of information technology on do-it-yourself culture, design, and HCI.
2009	More than face-to-face: empathy effects of video framing	Video conferencing attempts to convey subtle cues of face-to-face interaction (F2F), but it is generally believed to be less effective than F2F. We argue that careful design based on an understanding of non-verbal communication can mitigate these differences. In this paper, we study the effects of video image framing in one-on-one meetings on empathy formation. We alter the video image by framing the display such that, in one condition, only the head is visible while, in the other condition, the entire upper body is visible. We include a F2F control case. We used two measures of dyad empathy and found a significant difference between head-only framing and both upper-body framing and F2F, but no significant difference between upper-body framing and F2F. Based on these and earlier results, we present some design heuristics for video conferencing systems. We revisit earlier negative experimental results on video systems in the light of these new experiments. We conclude that for systems that preserve both gaze and upper-body cues, there is no evidence of deficit in communication effectiveness compared to face-to-face meetings.
2009	Movable cameras enhance social telepresence in media spaces	Media space is a promising but still immature technology to connect distributed sites. We developed a simple additional function that moved a remote camera forward when a local user approached a display so that the approach was amplified by a remote person's expanding image accompanied by motion parallax. We conducted an experiment in which we observed that a movable camera enhanced social telepresence, which is the feeling of facing a remote person in the same room. Despite the camera's movement, subjects believed that the camera did not move and a zoom-in function expanded the image. Surprisingly, a zoom-in camera that expanded the image as the movable camera did, however, was ineffective probably because of a lack of motion parallax. Although we explained nothing about the camera, most subjects noticed that their walking caused the view's expansion. If a remote person initiated the camera's movement, social telepresence could not be enhanced.
2009	NewsCube: delivering multiple aspects of news to mitigate media bias	The bias in the news media is an inherent flaw of the news production process. The resulting bias often causes a sharp increase in political polarization and in the cost of conflict on social issues such as Iraq war. It is very difficult, if not impossible, for readers to have penetrating views on realities against such bias. This paper presents NewsCube, a novel Internet news service aiming at mitigating the effect of media bias. NewsCube automatically creates and promptly provides readers with multiple classified viewpoints on a news event of interest. As such, it effectively helps readers understand a fact from a plural of viewpoints and formulate their own, more balanced viewpoints. While media bias problem has been studied extensively in communications and social sciences, our work is the first to develop a news service as a solution and study its effect. We discuss the effect of the service through various user studies.
2009	Creating a spoken impact: encouraging vocalization through audio visual feedback in children with ASD	One hallmark difficulty of children with Autism Spectrum Disorder (ASD) centers on communication and speech. Research into computer visualizations of voice has been shown to influence conversational patterns and allow users to reflect upon their speech. In this paper, we present the Spoken Impact Project (SIP), an effort to examine the effect of audio and visual feedback on vocalizations in low-functioning children with ASD by providing them with additional means of understanding and exploring their voice. This research spans over 12 months, including the creation of multiple software packages and detailed analysis of more than 20 hours of experimental video. SIP demonstrates the potential of computer generated audio and visual feedback to encourage vocalizations of children with ASD.
2009	Autism online: a comparison of word usage in bloggers with and without autism spectrum disorders	The Internet has become a place of refuge for individuals with autism spectrum disorders (ASD). In particular, weblogs are a popular option for personal expression via the Internet. Perhaps this means of communication is well suited to bypassing deficits in social interaction and communication that characterize ASD. Using the Linguistic Inquiry and Word Count (LIWC) dictionaries [10], we compared blogs of individuals with ASD to the writing of neurotypical (NT) bloggers. We found that rates of word usage were nearly identical in the two groups with one exception - there was more variation in the use of social words in ASD compared to NT blogs. This similarity in language between ASD and NT authors suggests that communication deficits routinely found in people with ASD may be due to the social context in which their communication skills are tested, and that the affordances of asynchronous computer-mediated communication may offer alternative means of testing and expression.
2009	Design of haptic interfaces for therapy	Touch is fundamental to our emotional well-being. Medical science is starting to understand and develop touch-based therapies for autism spectrum, mood, anxiety and borderline disorders. Based on the most promising touch therapy protocols, we are presenting the first devices that simulate touch through haptic devices to bring relief and assist clinical therapy for mental health. We present several haptic systems that enable medical professionals to facilitate the collaboration between patients and doctors and potentially pave the way for a new form of non-invasive treatment that could be adapted from use in care-giving facilities to public use. We developed these prototypes working closely with a team of mental health professionals.
2009	Dynamic mapping of physical controls for tabletop groupware	Multi-touch interactions are a promising means of control for interactive tabletops. However, a lack of precision and tactile feedback makes multi-touch controls a poor fit for tasks where precision and feedback are crucial. We present an approach that offers precise control and tactile feedback for tabletop systems through the integration of dynamically re-mappable physical controllers with the multi-touch environment, and we demonstrate this approach in our collaborative tabletop audio editing environment. An observational user study demonstrates that our approach can provide needed precision and feedback, while preserving the collaborative benefits of a shared direct-manipulation surface. Our observations also suggest that direct touch and physical controllers can offer complementary benefits, and that providing both allows users to adjust their control strategy based on considerations including precision, convenience, visibility, and user role.
2009	SLAP widgets: bridging the gap between virtual and physical controls on tabletops	We present Silicone iLluminated Active Peripherals (SLAP), a system of tangible, translucent widgets for use on multitouch tabletops. SLAP Widgets are cast from silicone or made of acrylic, and include sliders, knobs, keyboards, and buttons. They add tactile feedback to multi-touch tables, improving input accuracy. Using rear projection, SLAP Widgets can be relabeled dynamically, providing inexpensive, battery-free, and untethered augmentations. Furthermore, SLAP combines the flexibility of virtual objects with physical affordances. We evaluate how SLAP Widgets influence the user experience on tabletops compared to virtual controls. Empirical studies show that SLAPWidgets are easy to use and outperform virtual controls significantly in terms of accuracy and overall interaction time.
2009	Touch and toys: new techniques for interaction with a remote group of robots	Interaction with a remote team of robots in real time is a difficult human-robot interaction (HRI) problem exacerbated by the complications of unpredictable real-world environments, with solutions often resorting to a larger-than-desirable ratio of operators to robots. We present two innovative interfaces that allow a single operator to interact with a group of remote robots. Using a tabletop computer the user can configure and manipulate groups of robots directly by either using their fingers (touch) or by manipulating a set of physical toys (tangible user interfaces). We recruited participants to partake in a user study that required them to interact with a small group of remote robots in simple tasks, and present our findings as a set of design considerations.
2009	Butler lies: awareness, deception and design	Instant messaging (IM) is a common and popular way for co-workers, friends, and family to stay in touch, but its"always-on properties can sometimes lead people to feel overexposed or too readily available to others for conversation. This, in turn, may lead people to deceive others about their actual status or availability. In this paper, we introduce the notion of the "butler lie to describe lies that allow for polite initiation and termination of conversations. We present results from a field study of 50 IM users, in which participants rated each of their messages at the time of sending to indicate whether or not it was deceptive. About one tenth of all IM messages were rated as lies and, of these, about one fifth were butler lies. These results suggest that butler lies are an important social practice in IM, and that existing approaches to interpersonal awareness, which focus on accurate assessment of availability, may need to take deception and other social practices into account.
2009	In CMC we trust: the role of similarity	This paper examines how different forms of linguistic similarity in a text-chat environment relate to the establishment of interpersonal trust. Sixty-two pairs played an iterative social dilemma investment game and periodically communicated via Instant Messenger (IM). Novel automated and manual analysis techniques identify linguistic similarity at content, structural and stylistic levels. Results reveal that certain types of content (some positive emotion words, task-related words), structural (verb tense, phrasal entrainment), and stylistic (emoticons) similarity characterize high trusting pairs while other types of similarity (e.g., negative emotion words) characterize low trusting pairs. Contrary to previous literature, this suggests that not all similarity is good similarity.
2009	Visualizing real-time language-based feedback on teamwork behavior in computer-mediated groups	While most collaboration technologies are concerned with supporting particular tasks such as workflows or meetings, many work groups do not have the teamwork skills essential to effective collaboration. One way to improve teamwork is to provide dynamic feedback generated by automated analyses of behavior, such as language use. Such feedback can lead members to reflect on and subsequently improve their collaborative behavior, but might also distract from the task at hand. We have experimented with GroupMeter - a chat-based system that presents visual feedback on team members' language use. Feedback on proportion of agreement words and overall word count was presented using two different designs. When receiving feedback, teams in our study expressed more agreement in their conversations and reported greater focus on language use as compared to when not receiving feedback. This suggests that automated, real-time linguistic feedback can elicit behavioral changes, offering opportunities for future research.
2009	Fly: a tool to author planar presentations	Modern presentation software is still built around interaction metaphors adapted from traditional slide projectors. We provide an analysis of the problems in this application genre that presentation authors face and present Fly, a presentation tool that is based on the idea of planar information structures. Inspired by the natural human thought processes of data chunking, association, and spatial memory, Fly explores authoring of presentation documents. Evaluation of a paper prototype showed that the planar UI is easily grasped by users, and leads to presentations more closely resembling the information structure of the original content, thus providing better authoring support than the slide metaphor. Our software prototype confirmed these results, and outperformed PowerPoint in a second study for tasks such as prototyping presentations and generating meaningful overviews. Users reported that this interface helped them better to express their concepts, and expressed significant preference for Fly over the traditional slide model.
2010	Estimating residual error rate in recognized handwritten documents using artificial error injection	Both handwriting recognition systems and their users are error prone. Handwriting recognizers make recognition errors, and users may miss those errors when verifying output. As a result, it is common for recognized documents to contain residual errors . Unfortunately, in some application domains (e.g. health informatics), tolerance for residual errors in recognized handwriting may be very low, and a desire might exist to maximize user accuracy during verification. In this paper, we present a technique that allows us to measure the performance of a user verifying recognizer output. We inject artificial errors into a set of recognized handwritten forms and show that the rate of injected errors and recognition errors caught is highly correlated in real time. Systems supporting user verification can make use of this measure of user accuracy in a variety of ways. For example, they can force users to slow down or can highlight injected errors that were missed, thus encouraging users to take more care.
2010	Predicting the cost of error correction in character-based text entry technologies	Researchers have developed many models to predict and understand human performance in text entry. Most of the models are specific to a technology or fail to account for human factors and variations in system parameters, and the relationship between them. Moreover, the process of fixing errors and its effects on text entry performance has not been studied. Here, we first analyze real-life text entry error correction behaviors. We then use our findings to develop a new model to predict the cost of error correction for character-based text entry technologies. We validate our model against quantities derived from the literature, as well as with a user study. Our study shows that the predicted and observed cost of error correction correspond well. At the end, we discuss potential applications of our new model.
2010	SHRIMP: solving collision and out of vocabulary problems in mobile predictive input with motion gesture	Dictionary-based disambiguation (DBD) is a very popular solution for text entry on mobile phone keypads but suffers from two problems: 1. the resolution of encoding collision (two or more words sharing the same numeric key sequence) and 2. entering out-of-vocabulary (OOV) words. In this paper, we present SHRIMP, a system and method that addresses these two problems by integrating DBD with camera based motion sensing that enables the user to express preference through a tilting or movement gesture. SHRIMP (Small Handheld Rapid Input with Motion and Prediction) runs on camera phones equipped with a standard 12-key keypad. SHRIMP maintains the speed advantage of DBD driven predictive text input while enabling the user to overcome DBD collision and OOV problems seamlessly without even a mode switch. An initial empirical study demonstrates that SHRIMP can be learned very quickly, performed immediately faster than MultiTap and handled OOV words more efficiently than DBD.
2010	Reactive information foraging for evolving goals	Information foraging models have predicted the navigation paths of people browsing the web and (more recently) of programmers while debugging, but these models do not explicitly model users' goals evolving over time. We present a new information foraging model called PFIS2 that does model information seeking with potentially evolving goals. We then evaluated variants of this model in a field study that analyzed programmers' daily navigations over a seven-month period. Our results were that PFIS2 predicted users' navigation remarkably well, even though the goals of navigation, and even the information landscape itself, were changing markedly during the pursuit of information.
2010	How does search behavior change as search becomes more difficult?	Search engines make it easy to check facts online, but finding some specific kinds of information sometimes proves to be difficult. We studied the behavioral signals that suggest that a user is having trouble in a search task. First, we ran a lab study with 23 users to gain a preliminary understanding on how users' behavior changes when they struggle finding the information they're looking for. The observations were then tested with 179 participants who all completed an average of 22.3 tasks from a pool of 100 tasks. The large-scale study provided quantitative support for our qualitative observations from the lab study. When having difficulty in finding information, users start to formulate more diverse queries, they use advanced operators more, and they spend a longer time on the search result page as compared to the successful tasks. The results complement the existing body of research focusing on successful search strategies.
2010	Effects of popularity and quality on the usage of query suggestions during information search	Many search systems provide users with recommended queries during online information seeking. Although usage statistics are often used to recommend queries, this information is usually not displayed to the user. In this study, we investigate how the presentation of this information impacts use of query suggestions. Twenty-three subjects used an experimental search system to find documents about four topics. Eight query suggestions were provided for each topic: four were high quality queries and four were low quality queries. Fake usage information indicating how many other people used the queries was also provided. For half the queries this information was high and for the other half this information was low. Results showed that subjects could distinguish between high and low quality queries and were not influenced by the usage information. Qualitative data revealed that subjects felt favorable about the suggestions, but the usage information was less important for the search task used in this study.
2010	Space to think: large high-resolution displays for sensemaking	Space supports human cognitive abilities in a myriad of ways. The note attached to the side of the monitor, the papers spread out on the desk, diagrams scrawled on a whiteboard, and even the keys left out on the counter are all examples of using space to recall, reveal relationships, and think. Technological advances have made it possible to construct large display environments in which space has real meaning. This paper examines how increased space affects the way displays are regarded and used within the context of the cognitively demanding task of sensemaking. A pair of studies were conducted demonstrating how the spatial environment supports sensemaking by becoming part of the distributed cognitive process, providing both external memory and a semantic layer.
2010	Effects of interior bezels of tiled-monitor large displays on visual search, tunnel steering, and target selection	Tiled-monitor large displays are widely used in various application domains. However, how their interior bezels affect user performance and behavior has not been fully understood. We conducted three controlled experiments to investigate effects of tiled-monitor interior bezels on visual search, straight-tunnel steering, and target selection tasks. The conclusions of our paper are: 1) interior bezels do not affect visual search time nor error rate; however, splitting objects across bezels is detrimental to search accuracy, 2) interior bezels are detrimental to straight-tunnel steering, but not to target selection. In addition, we discuss how inte-rior bezels affect user behaviors, and suggest guidelines for effectively using tiled-monitor large displays and designing user interfaces suited to them.
2010	Let's go from the whiteboard: supporting transitions in work through whiteboard capture and reuse	The use of whiteboards is pervasive across a wide range of work domains. But some of the qualities that make them successful--an intuitive interface, physical working space, and easy erasure--inherently make them poor tools for archival and reuse. If whiteboard content could be made available in times and spaces beyond those supported by the whiteboard alone, how might it be appropriated? We explore this question via ReBoard, a system that automatically captures whiteboard images and makes them accessible through a novel set of user-centered access tools. Through the lens of a seven week workplace field study, we found that by enabling new workflows, ReBoard increased the value of whiteboard content for collaboration.
2010	Multitasking and monotasking: the effects of mental workload on deferred task interruptions	Recent research has found that forced interruptions at points of higher mental workload are more disruptive than at points of lower workload. This paper investigates a complementary idea: when users experience deferrable interruptions at points of higher workload, they may tend to defer processing of the interruption until times of lower workload. In an experiment, users performed a mail-browser primary task while being occasionally interrupted by a secondary chat task, evenly distributed between points of higher and lower workload. Analysis showed that 94\% of the time, users switched to the interrupting task during periods of lower workload, versus only 6\% during periods of higher workload. The results suggest that when interruptions can be deferred, users have a strong tendency to ''monotask'' until primary-task mental workload has been minimized.
2010	On reconstruction of task context after interruption	Theoretical accounts of task resumption after interruption have almost exclusively argued for resumption as a primarily memory-based process. In contrast, for many task domains, resumption can more accurately be represented in terms of a process of reconstruction -perceptual re-encoding of the information necessary to perform the task. This paper discusses a theoretical, computational framework in which one can represent these reconstruction processes and account for aspects of performance, such as measures of resumption lag. The paper also describes computational models of two sample task domains that illustrate the sometimes complex relationship between reconstruction and more general human cognitive, perceptual, and motor processes.
2010	Evaluating cues for resuming interrupted programming tasks	Developers, like all modern knowledge workers, are frequently interrupted and blocked in their tasks. In this paper we present a contextual inquiry into developers' current strategies for resuming interrupted tasks and investigate the effect of automated cues on improving task resumption. We surveyed 371 programmers on the nature of their tasks, interruptions, task suspension and resumption strategies and found that they rely heavily on note-taking across several types of media. We then ran a controlled lab study to compare the effects of two different automated cues to note taking when resuming interrupted programming tasks. The two cues differed in (1) whether activities were summarized in aggregate or presented chronologically and (2) whether activities were presented as program symbols or as code snippets. Both cues performed well: developers using either cue completed their tasks with twice the success rate as those using note-taking alone. Despite the similar performance of the cues, developers strongly preferred the cue that presents activities chronologically as code snippets.
2010	Multitasking bar: prototype and evaluation of introducing the task concept into a browser	This paper clarifies two common patterns of multitasking on the Web, namely Multiple Tasks (MT) and Multiple Session Task (MST). To support both of these, the task concept needs to be introduced into a browser. An online pilot survey has revealed which attributes of the task concept are most significant to Web users and as a result a simple prototype, the Multitasking Bar (MB), is proposed based on these findings. The MB copes with the multitasking needs of both MT and MST in the browser by providing functions for task related Web page management and task schedule management. A two-session controlled experiment has been conducted to evaluate the MB and to compare user performance and experience when multitasking on the Web with and without support for MT and MST. Results show that support for both MST and MT significantly improves user task performance efficiency and greatly enhances the user experience when multitasking on the Web.
2010	Across boundaries of influence and accountability: the multiple scales of public sector information systems	The use of ICTs in the public sector has long been touted for its potential to transform the institutions that govern and provide social services. The focus, however, has largely been on systems that are used within particular scales of the public sector, such as at the scale of state or national government, the scale of regional or municipal entity, or at the scale of local service providers. The work presented here takes aim at examining ICT use that crosses these scales of influence and accountability. We report on a year long ethnographic investigation conducted at a variety of social service outlets to understand how a shared information system crosses the boundaries of these very distinct organizations. We put forward that such systems are central to the work done in the public sector and represent a class of collaborative work that has gone understudied.
2010	A case study of micro-blogging in the enterprise: use, value, and related issues	This is a case study about the early adoption and use of micro-blogging in a Fortune 500 company. The study used several independent data sources: five months of empirical micro-blogging data, user demographic information from corporate HR records, a web based survey, and targeted interviews. The results revealed that users vary in their posting activities, reading behaviors, and perceived benefits. The analysis also identified barriers to adoption, such as the noise-to-value ratio paradoxes. The findings can help both practitioners and scholars build an initial understanding of how knowledge workers are likely to use micro-blogging in the enterprise.
2010	Student socialization in the age of facebook	Most research regarding online social networks such as Facebook, MySpace, Linked-In and Friendster has looked at these networks in terms of activity within the online network, such as profile management and friending behavior. In this paper we are instead focusing on offline socializing structures around an online social network (exemplified by Facebook) and how this can facilitate in-person social life for students. Because students lead nomadic lives, they find Facebook a particularly useful tool for initiating and managing social gatherings, and as they adopt mobile technologies that can access online social networks, their ad-hoc social life is further enabled. We conclude that online social networks are a powerful tool for encouraging peripheral friendships, important in particular to students. We emphasize that the use of online social networks must be viewed from a perspective of use that involves both mobile and stationary platforms and that it is important to relate online and offline social practices.
2010	Independence and interaction: understanding seniors' privacy and awareness needs for aging in place	As America's baby boom population gets older, aging in place -- the idea that seniors can remain independent in a comfortable home environment while being monitored and receiving care from family and caregivers living elsewhere -- has received significant attention. Fostering a sense of independence while simultaneously enabling monitoring and frequent interaction can seem paradoxical, however. This raises questions of how we can design technologies that help seniors retain their independence and a sense of comfort, while still interacting with and being monitored regularly by others. We present results from an interview study of 30 seniors, caregivers and relatives in which we sought to understand how they managed their interactions, availability, privacy and independence. Results suggest that they rely on attributes of the physical environment, temporal structures such as routine conversations and activities, and technological mediation.
2010	Contravision: exploring users' reactions to futuristic technology	How can we best explore the range of users' reactions when developing future technologies that may be controversial, such as personal healthcare systems? Our approach -- ContraVision -- uses futuristic videos, or other narrative forms, that convey either negative or positive aspects of the proposed technology for the same scenarios. We conducted a user study to investigate what range of responses the different versions elicited. Our findings show that the use of two systematically comparable representations of the same technology can elicit a wider spectrum of reactions than a single representation can. We discuss why this is so and the value of obtaining breadth in user feedback for potentially controversial technologies.
2010	I don't mind being logged, but want to remain in control: a field study of mobile activity and context logging	People have a natural tendency to capture and share their experiences via stories, photos and other mementos. As users are increasingly carrying the enabling devices with them, capturing life events is becoming more spontaneous. The automatic and persistent collecting of information about one's life and behavior is called lifelogging. Lifelogging relieves the user from manually capturing events but also poses many challenges from the user's perspective. We conducted a field study to explore the user experience of mobile phone activity and context logging, a technically feasible form of lifelogging. Our results indicate that users quickly stop to pay attention to the logging, but they want to be in control of logging the most private information. Although logging personal content, such as text messages, is experienced as a possible privacy threat, browsing the content and getting insight to the revealed life patterns was considered interesting and fun.
2010	Catalyzing social support for breast cancer patients	Social support is a critical, yet underutilized resource when undergoing cancer care. Underutilization occurs in two conditions: (a) when patients fail to seek out information, material assistance, and emotional support from family and friends or (b) when family and friends fail to meet the individualized needs and preferences of patients. Social networks are most effective when kept up to date on the patient's status, yet updating everyone takes effort that patients cannot always put in. To improve this situation, we describe the results of our participatory design activities with breast cancer patients. During this process, we uncovered the information a social network needs to stay informed as well as a host of barriers to social support that technology could help break down. Our resulting prototype, built using Facebook Connect, includes explicit features to reduce these barriers and thus, promote the healthy outcomes associated with strong social support.
2010	Transforming clinic environments into information workspaces for patients	Although clinic environments are a primary location for exchanging information with clinicians, patients experience these spaces as harsh environments to access, use, exchange, and manage information. In this paper, we present results from an ethnographic-inspired study of breast cancer patients actively interacting with information in clinic environments. Through observations and interviews, we observed information interactions in awkward physical positions; inefficient use of existing clinical space; separation of patients from their information and lack of support for collaborative document viewing. These factors compromised patients' abilities to manage their information work when they experienced bursts of information exchange, lack of advance information, fragmented attention, and heightened stress in clinic environments. To overcome these challenges, we identify formative strategies to focus attention, encourage collaboration, and improve communication in clinical settings.
2010	Blowing in the wind: unanchored patient information work during cancer care	Patients do considerable information work. Technologies that help patients manage health information so they can play active roles in their health-care, such as personal health records, provide patients with effective support for focused and sustained personal health tasks. Yet, little attention has been paid to patients' needs for information management support while on the go and away from their personal health information collections. Through a qualitative field study, we investigated the information work that breast cancer patients do in such 'unanchored settings'. We report on the types of unanchored information work that patients do over the course of cancer treatment, reasons this work is challenging, and strategies used by patients to overcome those challenges. Our description of unanchored patient information work expands our understanding of patients' information practices and points to valuable design directions for supporting critical but unmet needs.
2010	Crowdsourcing graphical perception: using mechanical turk to assess visualization design	Understanding perception is critical to effective visualization design. With its low cost and scalability, crowdsourcing presents an attractive option for evaluating the large design space of visualizations; however, it first requires validation. In this paper, we assess the viability of Amazon's Mechanical Turk as a platform for graphical perception experiments. We replicate previous studies of spatial encoding and luminance contrast and compare our results. We also conduct new experiments on rectangular area perception (as in treemaps or cartograms) and on chart size and gridline spacing. Our results demonstrate that crowdsourced perception experiments are viable and contribute new insights for visualization design. Lastly, we report cost and performance data from our experiments and distill recommendations for the design of crowdsourced studies.
2010	ManyNets: an interface for multiple network analysis and visualization	Traditional network analysis tools support analysts in studying a single network. ManyNets offers these analysts a powerful new approach that enables them to work on multiple networks simultaneously. Several thousand networks can be presented as rows in a tabular visualization, and then inspected, sorted and filtered according to their attributes. The networks to be displayed can be obtained by subdivision of larger networks. Examples of meaningful subdivisions used by analysts include ego networks, community extraction, and time-based slices. Cell visualizations and interactive column overviews allow analysts to assess the distribution of attributes within particular sets of networks. Details, such as traditional node-link diagrams, are available on demand. We describe a case study analyzing a social network geared towards film recommendations by means of decomposition. A small usability study provides feedback on the use of the interface on a set of tasks issued from the case study.
2010	A comparative evaluation on tree visualization methods for hierarchical structures with large fan-outs	Hierarchical structures with large fan-outs are hard to browse and understand. In the conventional node-link tree visualization, the screen quickly becomes overcrowded as users open nodes that have too many child nodes to fit in one screen. To address this problem, we propose two extensions to the conventional node-link tree visualization: a list view with a scrollbar and a multi-column interface. We compared them against the conventional tree visualization interface in a user study. Results show that users are able to browse and understand the tree structure faster with the multi-column interface than the other two interfaces. Overall, they also liked the multi-column better than others.
2010	The rogue in the lovely black dress: intimacy in world of warcraft	In this paper we present a critical analysis of player accounts of intimacy and intimate experiences in the massively multiplayer online role-playing game World of Warcraft (WoW). Our analysis explores four characteristics that players articulated about their virtual intimate experiences: the permeability of intimacy across virtual and real worlds, the mundane as the origin of intimacy, the significance of reciprocity and exchange, and the formative role of temporality in shaping understandings and recollections of intimate experiences. We also consider the manifest ways that WoW's software features support and encourage these characteristics.
2010	Physical activity motivating games: virtual rewards for real activity	Contemporary lifestyle has become increasingly sedentary: little physical (sports, exercises) and much sedentary (TV, computers) activity. The nature of sedentary activity is self-reinforcing, such that increasing physical and decreasing sedentary activity is difficult. We present a novel approach aimed at combating this problem in the context of computer games. Rather than explicitly changing the amount of physical and sedentary activity a person sets out to perform, we propose a new game design that leverages user engagement to generate out of game motivation to perform physical activity while playing. In our design, players gain virtual game rewards in return for real physical activity performed. Here we present and evaluate an application of our design to the game Neverball. We adapted Neverball by reducing the time allocated to accomplish the game tasks and motivated players to perform physical activity by offering time based rewards. An empirical evaluation involving 180 participants shows that the participants performed more physical activity, decreased the amount of sedentary playing time, and did not report a decrease in perceived enjoyment of playing the activity motivating version of Neverball.
2010	Understanding and evaluating cooperative games	Cooperative design has been an integral part of many games. With the success of games like Left4Dead, many game designers and producers are currently exploring the addition of cooperative patterns within their games. Unfortunately, very little research investigated cooperative patterns or methods to evaluate them. In this paper, we present a set of cooperative patterns identified based on analysis of fourteen cooperative games. Additionally, we propose Cooperative Performance Metrics (CPM). To evaluate the use of these CPMs, we ran a study with a total of 60 participants, grouped in 2-3 participants per session. Participants were asked to play four cooperative games (Rock Band 2, Lego Star Wars, Kameo, and Little Big Planet). Videos of the play sessions were annotated using the CPMs, which were then mapped to cooperative patterns that caused them. Results, validated through inter-rater agreement, identify several effective cooperative patterns and lessons for future cooperative game designs.
2010	Occlusion-aware interfaces	We define occlusion-aware interfaces as interaction techniques which know what area of the display is currently occluded, and use this knowledge to counteract potential problems and/or utilize the hidden area. As a case study, we describe the Occlusion-Aware Viewer, which identifies important regions hidden beneath the hand and displays them in a non-occluded area using a bubble-like callout. To determine what is important, we use an application agnostic image processing layer. For the occluded area, we use a user configurable, real-time version of Vogel et al.'s [21] geometric model. In an evaluation with a simultaneous monitoring task, we find the technique can successfully mitigate the effects of occlusion, although issues with ambiguity and stability suggest further refinements. Finally, we present designs for three other occlusion-aware techniques for pop-ups, dragging, and a hidden widget.
2010	High-precision magnification lenses	Focus+context interfaces provide in-place magnification of a region of the display, smoothly integrating the focus of attention into its surroundings. Two representations of the data exist simultaneously at two different scales, providing an alternative to classical pan & zoom for navigating multi-scale interfaces. For many practical applications however, the magnification range of focus+context techniques is too limited. This paper addresses this limitation by exploring the quantization problem: the mismatch between visual and motor precision in the magnified region. We introduce three new interaction techniques that solve this problem by integrating fast navigation and high-precision interaction in the magnified region. Speed couples precision to navigation speed. Key and Ring use a discrete switch between precision levels, the former using a keyboard modifier, the latter by decoupling the cursor from the lens' center. We report on three experiments showing that our techniques make interacting with lenses easier while increasing the range of practical magnification factors, and that performance can be further improved by integrating speed-dependent visual behaviors.
2010	Quasi-qwerty soft keyboard optimization	It has been well understood that optimized soft keyboard layouts improve motor movement efficiency over the standard Qwerty layouts, but have the drawback of long initial visual search time for novice users. To ease the initial searching time on optimized soft keyboards, we explored "Quasi-Qwerty optimization" so that the resulting layouts are close to Qwerty. Our results show that a middle ground between the optimized but new, and the familiar (Qwerty) but inefficient does exist. We show that by allowing letters to move at most one step (key) away from their original positions on Qwerty in an optimization process, one can achieve about half of what free optimization could gain in movement efficiency. An experiment shows that due to users' familiarity with Qwerty, a layout with quasi Qwerty optimization could significantly reduce novice user's visual search time to a level between those of Qwerty and a freely optimized layout. The results in this work provide designers with a new quantitative understanding of the soft keyboard design space.
2010	An unobtrusive behavioral model of gross national happiness	I analyze the use of emotion words for approximately 100 million Facebook users since September of 2007. "Gross national happiness" is operationalized as a standardized difference between the use of positive and negative words, aggregated across days, and present a graph of this metric. I begin to validate this metric by showing that positive and negative word use in status updates covaries with self-reported satisfaction with life (convergent validity), and also note that the graph shows peaks and valleys on days that are culturally and emotionally significant (face validity). I discuss the development and computation of this metric, argue that this metric and graph serves as a representation of the overall emotional health of the nation, and discuss the importance of tracking such metrics.
2010	The tower of Babel meets web 2.0: user-generated content and its applications in a multilingual context	This study explores language's fragmenting effect on user-generated content by examining the diversity of knowledge representations across 25 different Wikipedia language editions. This diversity is measured at two levels: the concepts that are included in each edition and the ways in which these concepts are described. We demonstrate that the diversity present is greater than has been presumed in the literature and has a significant influence on applications that use Wikipedia as a source of world knowledge. We close by explicating how knowledge diversity can be beneficially leveraged to create "culturally-aware applications" and "hyperlingual applications".
2010	Indexicality of language and the art of creating treasures	The indexicality of language refers to the linkage between the language and the situation of use for determining the meaning of what is being said. In this paper I describe how a player of a location-based treasure hunt game called geocaching uses indexicality of language in creating clues when hiding treasures. Based on this account, the skill, I argue, in creating an exciting treasure depends on understanding the disjunction between the context in which the clue is first interpreted and the context in which it receives its final meaning. An interesting clue should therefore contain both a literal or conventional meaning and a situated meaning, and the situated meaning should only arise when the player is close enough to the treasure.
2010	Why pay?: exploring how financial incentives are used for question & answer	Electronic commerce has enabled a number of online pay-for-answer services. However, despite commercial interest, we still lack a comprehensive understanding of how financial incentives support question asking and answering. Using 800 questions randomly selected from a pay-for-answer site, along with site usage statistics, we examined what factors impact askers' decisions to pay. We also explored how financial rewards affect answers, and if question pricing can help organize Q&A exchanges for archival purposes. We found that askers' decisions are two-part--whether or not to pay and how much to pay. Askers are more likely to pay when requesting facts and will pay more when questions are more difficult. On the answer side, our results support prior findings that paying more may elicit a higher number of answers and answers that are longer, but may not elicit higher quality answers (as rated by the askers). Finally, we present evidence that questions with higher rewards have higher archival value, which suggests that pricing can be used to support archival use.
2010	Hidden markets: UI design for a P2P backup application	The Internet has allowed market-based systems to become increasingly pervasive. In this paper we explore the role of user interface (UI) design for these markets. Different UIs induce different mental models which in turn determine how users understand and interact with a market. Thus, the intersection of UI design and economics is a novel and important research area. We make three contributions at this intersection. First, we present a novel design paradigm which we call hidden markets . The primary goal of hidden markets is to hide as much of the market complexities as possible. Second, we explore this new design paradigm using one particular example: a P2P backup application. We explain the market underlying this system and provide a detailed description of the new UI we developed. Third, we present results from a formative usability study. Our findings indicate that a number of users could benefit from a market-based P2P backup system. Most users intuitively understood the give & take principle as well as the bundle constraints of the market. However, the pricing aspect was difficult to discover/understand for many users and thus needs further investigation. Overall, the results are encouraging and show promise for the hidden market paradigm.
2010	Re-examining price as a predictor of answer quality in an online q&a site	Online question-answering services provide mechanisms for knowledge exchange by allowing users to ask and answer questions on a wide range of topics. A key question for designing such services is whether charging a price has an effect on answer quality. Two field experiments using one such service, Google Answers, offer conflicting answers to this question. To resolve this inconsistency, we re-analyze data from Harper et al. [5] and Chen et al. [2] to study the price effect in greater depth. Decomposing the price effect into two different levels yields results that reconcile those of the two field experiments. Specifically, we find that: (1) a higher price significantly increases the likelihood that a question receives an answer and (2) for questions that receive an answer, there is no significant price effect on answer quality. Additionally, we find that the rater background makes a difference in evaluating answer quality.
2010	Why users of yahoo!: answers do not answer questions	Posing a question to an online question and answer community does not guarantee a response. Significant prior work has explored and identified members' motivations for contributing to communities of collective action ( e.g. , Yahoo! Answers); in contrast it is not well understood why members choose to not answer a question they have already read. To explore this issue, we surveyed 135 active members of Yahoo! Answers. We show that top and regular contributors experience the same reasons to not answer a question: subject nature and composition of the question; perception of how the questioner will receive, interpret and react to their response; and a belief that their response will lose its meaning and get lost in the crowd if too many responses have already been given. Informed by our results, we discuss opportunities to improve the efficacy of the question and answer process, and to encourage greater contributions through improved design.
2010	Crosstrainer: testing the use of multimodal interfaces in situ	We report the results of an exploratory 8-day field study of CrossTrainer: a mobile game with crossmodal audio and tactile feedback. Our research focuses on the longitudinal effects on performance with audio and tactile feedback, the impact of context such as location and situation on performance and personal modality preference. The results of this study indicate that crossmodal feedback can aid users in entering answers quickly and accurately using a variety of different widgets. Our study shows that there are times when audio is more appropriate than tactile and vice versa and for this reason devices should support both tactile and audio feedback to cover the widest range of environments, user preference, locations and tasks.
2010	Newport: enabling sharing during mobile calls	Newport is a collaborative application for sharing context (e.g. location) and content (e.g. photos and notes) during mobile phone calls. People can share during a phone call and sharing ends when the call ends. Newport also supports using a computer during a call to make it easier to share content from the phone or launch screen sharing if the caller is also at a computer. We describe Newport's system design and a formative evaluation with 12 participants to study their experience using Newport to share location, receive directions, share photos, and perform desktop sharing. Participants preferred using Newport to current methods for these tasks. They also preferred limiting sharing location to phone calls compared with publishing it continuously. Tying sharing to a phone call gives individuals a social sense of security, providing a mechanism for exchanging information with unknown people.
2010	Attractive phones don't have to work better: independent effects of attractiveness, effectiveness, and efficiency on perceived usability	Participants sometimes rate products high in usability despite experiencing obvious usability problems (low effectiveness or efficiency). Is it possible that this occurs because high product attractiveness compensates for low effectiveness/efficiency? Previous research has not investigated the interplay between attractiveness, effectiveness, and efficiency to determine whether attractiveness accounts for additional variance in usability ratings beyond that which is explained by effectiveness and efficiency. The present research provides the first test of this idea. Using data from usability testing, we demonstrate that attractiveness, effectiveness, and efficiency each has an independent influence on usability ratings and, in the present research, attractiveness had the largest impact. We report results of quantitative analyses that suggest multiple mechanisms could be responsible for the relationship between attractiveness and usability.
2010	Using reinforcement to strengthen users' secure behaviors	Users have a strong tendency toward dismissing security dialogs unthinkingly. Prior research has shown that users' responses to security dialogs become significantly more thoughtful when dialogs are polymorphic, and that further improvements can be obtained when dialogs are also audited and auditors penalize users who give unreasonable responses. We contribute an Operant Conditioning model that fits these observations, and, inspired by the model, propose Security Reinforcing Applications (SRAs). SRAs seek to reward users' secure behavior, instead of penalizing insecure behavior. User studies show that SRAs improve users' secure behaviors and that behaviors strengthened in this way do not extinguish after a period of several weeks in which users do not interact with SRAs. Moreover, inspired by Social Learning theory, we propose Vicarious Security Reinforcement (VSR). A user study shows that VSR accelerates SRA benefits.
2010	Who falls for phish?: a demographic analysis of phishing susceptibility and effectiveness of interventions	In this paper we present the results of a roleplay survey instrument administered to 1001 online survey respondents to study both the relationship between demographics and phishing susceptibility and the effectiveness of several anti-phishing educational materials. Our results suggest that women are more susceptible than men to phishing and participants between the ages of 18 and 25 are more susceptible to phishing than other age groups. We explain these demographic factors through a mediation analysis. Educational materials reduced users' tendency to enter information into phishing webpages by 40\% percent; however, some of the educational materials we tested also slightly decreased participants' tendency to click on legitimate links.
2010	The true cost of unusable password policies: password use in the wild	HCI research published 10 years ago pointed out that many users cannot cope with the number and complexity of passwords, and resort to insecure workarounds as a consequence. We present a study which re-examined password policies and password practice in the workplace today. 32 staff members in two organisations kept a password diary for 1 week, which produced a sample of 196 passwords. The diary was followed by an interview which covered details of each password, in its context of use. We find that users are in general concerned to maintain security, but that existing security policies are too inflexible to match their capabilities, and the tasks and contexts in which they operate. As a result, these password policies can place demands on users which impact negatively on their productivity and, ultimately, that of the organisation. We conclude that, rather than focussing password policies on maximizing password strength and enforcing frequency alone, policies should be designed using HCI principles to help the user to set an appropriately strong password in a specific context of use.
2010	Exploiting knowledge-in-the-head and knowledge-in-the-social-web: effects of domain expertise on exploratory search in individual and social search environments	Our study compared how experts and novices performed exploratory search using a traditional search engine and a social tagging system. As expected, results showed that social tagging systems could facilitate exploratory search for both experts and novices. We, however, also found that experts were better at interpreting the social tags and generating search keywords, which made them better at finding information in both interfaces. Specifically, experts found more general information than novices by better interpretation of social tags in the tagging system; and experts also found more domain-specific information by generating more of their own keywords. We found a dynamic interaction between knowledge-in-the-head and knowledge-in-the-social-web that although information seekers are more and more reliant on information from the social Web, domain expertise is still important in guiding them to find and evaluate the information. Implications on the design of social search systems that facilitate exploratory search are also discussed.
2010	Interactive effects of age and interface differences on search strategies and performance	We present results from an experiment that studied the information search behavior of younger and older adults in a medical decision-making task. To study how different combination of tasks and interfaces influenced search strategies and decision-making outcomes, we varied information structures of two interfaces and presented different task descriptions to participants. We found that younger adults tended to use different search strategies in different combination of tasks and interfaces, and older adults tended to use the same top-down strategies across conditions. We concluded that older adults were able to perform mental transformation of medical terms more effectively than younger adults. Thus older adults did not require changing strategies to maintain the same level of performance.
2010	Children's roles using keyword search interfaces at home	Children want to find information about their world, but there are barriers to finding what they seek. Young people have varying abilities to formulate multi-step queries and comprehend search results. Challenges in understanding where to type, confusion about what tools are available, and frustration with how to parse the results page all have led to a lack of perceived search success for children 7-11 years old. In this paper, we describe seven search roles children display as information seekers using Internet keyword interfaces, based on a home study of 83 children ages 7, 9, and 11. These roles are defined not only by the children's search actions, but also by who influences their searching, their perceived success, and trends in age and gender. These roles suggest a need for new interfaces that expand the notion of keywords, scaffold results, and develop a search culture among children.
2010	The infrastructure problem in HCI	HCI endeavors to create human-centered computer systems, but underlying technological infrastructures often stymie these efforts. We outline three specific classes of user experience difficulties caused by underlying technical infrastructures, which we term constrained possibilities , unmediated interaction , and interjected abstractions . We explore how prior approaches in HCI have addressed these issues, and discuss new approaches that will be required for future progress. We argue that the HCI community must become more deeply involved with the creation of technical infrastructures. Doing so, however, requires a substantial expansion to the methodological toolbox of HCI.
2010	BuzzWear: alert perception in wearable tactile displays on the wrist	We present two experiments to evaluate wrist-worn wearable tactile displays (WTDs) that provide easy to perceive alerts for on-the-go users. The first experiment (2304 trials, 12 participants) focuses on the perception sensitivity of tactile patterns and reveals that people discriminate our 24 tactile patterns with up to 99\% accuracy after 40 minutes of training. Among the four parameters (intensity, starting point, temporal pattern, and direction) that vary in the 24 patterns, intensity is the most difficult parameter to distinguish and temporal pattern is the easiest. The second experiment (9900 trials, 15 participants) focuses on dual task performance, exploring users' abilities to perceive three incoming alerts from two mobile devices (WTD and mobile phone) with and without visual distraction. The second experiment reveals that, when visually distracted, users' reactions to incoming alerts become slower for the mobile phone but not for the WTD.
2010	i*CATch: a scalable plug-n-play wearable computing framework for novices and children	There has been much recent work in wearable computing that is directed at democratization of the field, to make it more accessible to the general public and more easily used by the hobbyist user. As the field becomes more diversified, there has also been a shift away from the highly specialized functionality of earlier applications towards aesthetics, creativity, design and self-expression, as well as a push towards using wearable computing as an outreach tool to broaden interest and exposure in engineering and computing. This paper presents the design and development of the i*CATch wearable computing framework, which was developed specifically for children and novices to the field. The i*CATch framework is based upon a bus-based architecture, and is more scalable than the current alternatives. It consists of a set of plug-and-play components, a construction platform with a standardized interface, and an easy-to-use hybrid text-graphical integrated development environment. We will also present results of the evaluation of the i*CATch framework in real teaching environments.
2010	Skinput: appropriating the body as an input surface	We present Skinput, a technology that appropriates the human body for acoustic transmission, allowing the skin to be used as an input surface. In particular, we resolve the location of finger taps on the arm and hand by analyzing mechanical vibrations that propagate through the body. We collect these signals using a novel array of sensors worn as an armband. This approach provides an always available, naturally portable, and on-body finger input system. We assess the capabilities, accuracy and limitations of our technique through a two-part, twenty-participant user study. To further illustrate the utility of our approach, we conclude with several proof-of-concept applications we developed.
2010	Hand in hand with the material: designing for suppleness	Designing for a supple interaction, involving users bodily and emotionally into a 'dance' with a system is a challenging task. Any break-ups in interaction become fatal to the sensual, fluent, bodily and social experience sought. A user-centered, iterative design cycle is therefore required. But getting to know the affordances of the digital material used to build the application plays an equally important role in the design process. The 'feel' of the digital material properties sometimes even determines what the design should be. We describe three situations in which the properties and affordances of sensor network technologies guided our design process of FriendSense -- a system for expressing friendship and emotional closeness through movement. We show how the sensor node look and feel, choice of sensors, limitations of the radio signal strength and coverage, as well as iterative prototyping to properly exploit the software/algorithmic possibilities guided our design process.
2010	The Case of the Disappearing Ox: Seeing Through Digital Images to an Analysis of Ancient Texts	There are numerous settings where people examine, scrutinize and discuss the details of images in the course of their work. In most medical domains, scans and x-rays are used in the diagnosis of cases; in most areas of science, methods of visualization have been adopted to assist in the analysis of data; and images of different kinds are critical for many research fields in the social sciences and humanities. It is not surprising that recently technologies have been proposed to assist with the analysis and examination of images. In this paper, we consider requirements for technologies in a rather distinctive domain of research, the classics. Drawing upon an analysis of the detailed ways in which classicists work with digital images, we discuss the requirements for systems to support researchers in this domain, and also provide further considerations on the general development of image processing technologies and visualization techniques.
2010	The implications of improvisational acting and role-playing on design methodologies	For decades designers have used theatre metaphors to describe design methodologies and have used performance techniques to enhance the design process, two of which are improvisational acting and role-playing. Unfortunately, most design literature does not differentiate between these two practices even while using them in combination with various design methods. This paper discusses how improvisation and role-playing have been employed during the design process and why they are distinct from one another. The authors draw upon their current research involving improvisational acting and compare it with other role-playing research which examines role-playing from both a serious and entertainment angle. They conclude through this comparison that both performance techniques have their place in the design process and that more informed definitions of each technique can aid designers in deciding which technique's properties will benefit them the most.
2010	d.note: revising user interfaces through change tracking, annotations, and alternatives	Interaction designers typically revise user interface prototypes by adding unstructured notes to storyboards and screen printouts. How might computational tools increase the efficacy of UI revision? This paper introduces d.note, a revision tool for user interfaces expressed as control flow diagrams. d.note introduces a command set for modifying and annotating both appearance and behavior of user interfaces; it also defines execution semantics so proposed changes can be tested immediately. The paper reports two studies that compare production and interpretation of revisions in d.note to freeform sketching on static images (the status quo). The revision production study showed that testing of ideas during the revision process led to more concrete revisions, but that the tool also affected the type and number of suggested changes. The revision interpretation study showed that d.note revisions required fewer clarifications, and that additional techniques for expressing revision intent could be beneficial.
2010	FrameWire: a tool for automatically extracting interaction logic from paper prototyping tests	Paper prototyping offers unique affordances for interface design. However, due to its spontaneous nature and the limitations of paper, it is difficult to distill and communicate a paper prototype design and its user test findings to a wide audience. To address these issues, we created FrameWire, a computer vision-based system that automatically extracts interaction flows from the video recording of paper prototype user tests. Based on the extracted logic, FrameWire offers two distinct benefits for designers: a structural view of the video recording that allows a designer or a stakeholder to easily distill and understand the design concept and user interaction behaviors, and automatic generation of interactive HTML-based prototypes that can be easily tested with a larger group of users as well as "walked through" by other stakeholders. The extraction is achieved by automatically aggregating video frame sequences into an interaction flow graph based on frame similarities and a designer-guided clustering process. The results of evaluating FrameWire with realistic paper prototyping tests show that our extraction approach is feasible and FrameWire is a promising tool for enhancing existing prototyping practice.
2010	Example-centric programming: integrating web search into the development environment	The ready availability of online source-code examples has fundamentally changed programming practices. However, current search tools are not designed to assist with programming tasks and are wholly separate from editing tools. This paper proposes that embedding a task-specific search engine in the development environment can significantly reduce the cost of finding information and thus enable programmers to write better code more easily. This paper describes the design, implementation, and evaluation of Blueprint, a Web search interface integrated into the Adobe Flex Builder development environment that helps users locate example code. Blueprint automatically augments queries with code context, presents a code-centric view of search results, embeds the search experience into the editor, and retains a link between copied code and its source. A comparative laboratory study found that Blueprint enables participants to write significantly better code and find example code significantly faster than with a standard Web browser. Analysis of three months of usage logs with 2,024 users suggests that task-specific search interfaces can significantly change how and when people search the Web.
2010	Timeline collaboration	This paper explores timelines as a web-based tool for collaboration between citizens and municipal caseworkers. The paper takes its outset in a case study of planning and control of parental leave; a process that may involve surprisingly many actors. As part of the case study, a web-based timeline, CaseLine, was designed. This design crosses the boundaries between leisure and work, in ways that are different from what is often seen in current HCI. The timeline has several roles on these boundaries: It is a shared planning and visualization tool that may be used by parents and caseworkers alone or together, it serves as a contract and a sandbox, as a record and a plan, as inspiration for planning and an authoritative road, as a common information space and a fragmented exchange. Serving all these roles does not happen smoothly, and the paper discusses the challenges of such timeline interaction in, and beyond this case.
2010	Informal interactions in nonprofit networks	Nonprofit organizations often need to excel in coordinating with other organizations and must do so in a variety of contexts and levels from the informal to the formal. Their ability to accomplish their mission can critically depend on their efficacy in managing dependencies on others for tasks, accessing needed resources, raising their profile in the community, and achieving their goals. Although much research has been done to understand systems for supporting formal coordination between organizations, there is a gap in understanding how informal coordination can be supported by systems. As a first step towards addressing this gap, we conducted a field study of a network of nonprofit organizations, focusing specifically on informal interactions among them. Based on this study, we characterize informal coordination between organizations and the context for such interactions. Our findings point to a need to further explore a class of interorganizational interactions that may not be adequately explored or understood by our research community.
2010	Managing nomadic knowledge: a case study of the European social forum	In this paper we portray a specific type of knowledge which we term 'nomadic knowledge'. It is required periodically by different actors and travels along foreseeable paths between groups or communities of actors. This type of knowledge lets us question generally held assumptions about the way knowledge is enacted. We illustrate our point with an ethnographical field study analyzing the European Social Forum (ESF), a network of political activist organizations. In this network different actors organize a periodic (biannual) event in which some 13,000 activists participated in 2008. We investigate how knowledge about organizing and managing the ESF is transferred between two events respectively, the actors and communities involved. Our study highlights the specific challenges in sharing nomadic knowledge and the consequences of deficiencies on the organizing process. The paper contributes to a better understanding of knowledge sharing practices and opens new directions for technical support.
2010	Eliza meets the wizard-of-oz: blending machine and human control of embodied characters	What authoring possibilities arise by blending machine and human control of live embodied character experiences? This paper explores two different "behind-the-scenes" roles for human operators during a three-month gallery installation of an embodied character experience. In the Transcription role, human operators type players' spoken utterances; then, algorithms interpret the player's intention, choose from pre-authored dialogue based on local and global narrative contexts, and procedurally animate two embodied characters. In the Discourse role, human operators select from semantic categories to interpret player intention; algorithms use this "discourse act" to automate character dialogue and animation. We compare these two methods of blending control using game logs and interviews, and document how the amateur operators initially resisted having to learn the Discourse version, but eventually preferred having the authorial control it afforded. This paper also outlines a design space for blending machine and human control in live character experiences.
2010	A stage-based model of personal informatics systems	People strive to obtain self-knowledge. A class of systems called personal informatics is appearing that help people collect and reflect on personal information. However, there is no comprehensive list of problems that users experience using these systems, and no guidance for making these systems more effective. To address this, we conducted surveys and interviews with people who collect and reflect on personal information. We derived a stage-based model of personal informatics systems composed of five stages (preparation, collection, integration, reflection, and action) and identified barriers in each of the stages. These stages have four essential properties: barriers cascade to later stages; they are iterative; they are user-driven and/or system-driven; and they are uni-faceted or multi-faceted. From these properties, we recommend that personal informatics systems should 1) be designed in a holistic manner across the stages; 2) allow iteration between stages; 3) apply an appropriate balance of automated technology and user control within each stage to facilitate the user experience; and 4) explore support for associating multiple facets of people's lives to enrich the value of systems.
2010	Deception and magic in collaborative interaction	We explore the ways in which interfaces can be designed to deceive users so as to create the illusion of magic. We present a study of an experimental performance in which a magician used a computer vision system to conduct a series of illusions based on the well-known 'three cups' magic trick. We explain our findings in terms of the two broad strategies of misdirecting attention and setting false expectations, articulating specific tactics that were employed in each case. We draw on existing theories of collaborative and spectator interfaces, ambiguity and interpretation, and trajectories through experiences to explain our findings in broader HCI terms. We also extend and integrate current theory to provide refined sensitising concepts for analysing deceptive interactions.
2010	FingerCloud: uncertainty and autonomy handover incapacitive sensing	We describe a particle filtering approach to inferring finger movements on capacitive sensing arrays. This technique allows the efficient combination of human movement models with accurate sensing models, and gives high-fidelity results with low-resolution sensor grids and tracks finger height. Our model provides uncertainty estimates, which can be linked to the interaction to provide appropriately smoothed responses as sensing perfomance degrades; system autonomy is increased as estimates of user behaviour become less certain. We demonstrate the particle filter approach with a map browser running with a very small sensor board, where finger position uncertainty is linked to autonomy handover.
2010	The generalized perceived input point model and how to double touch accuracy by extracting fingerprints	It is generally assumed that touch input cannot be accurate because of the fat finger problem, i.e., the softness of the fingertip combined with the occlusion of the target by the finger. In this paper, we show that this is not the case. We base our argument on a new model of touch inaccuracy. Our model is not based on the fat finger problem, but on the perceived input point model. In its published form, this model states that touch screens report touch location at an offset from the intended target. We generalize this model so that it represents offsets for individual finger postures and users. We thereby switch from the traditional 2D model of touch to a model that considers touch a phenomenon in 3-space. We report a user study, in which the generalized model explained 67\% of the touch inaccuracy that was previously attributed to the fat finger problem. In the second half of this paper, we present two devices that exploit the new model in order to improve touch accuracy. Both model touch on per-posture and per-user basis in order to increase accuracy by applying respective offsets. Our RidgePad prototype extracts posture and user ID from the user's fingerprint during each touch interaction. In a user study, it achieved 1.8 times higher accuracy than a simulated capacitive baseline condition. A prototype based on optical tracking achieved even 3.3 times higher accuracy. The increase in accuracy can be used to make touch interfaces more reliable, to pack up to 3.3 2 > 10 times more controls into the same surface, or to bring touch input to very small mobile devices.
2010	Finger-count & radial-stroke shortcuts: 2 techniques for augmenting linear menus on multi-touch surfaces	We propose Radial-Stroke and Finger-Count Shortcuts, two techniques aimed at augmenting the menubar on multi-touch surfaces. We designed these multi-finger two-handed interaction techniques in an attempt to overcome the limitations of direct pointing on interactive surfaces, while maintaining compatibility with traditional interaction techniques. While Radial-Stroke Shortcuts exploit the well-known advantages of Radial Strokes, Finger-Count Shortcuts exploit multi-touch by simply counting the number of fingers of each hand in contact with the surface. We report the results of an experimental evaluation of our technique, focusing on expert-mode performance. Finger-Count Shortcuts outperformed Radial-Stroke Shortcuts in terms of both easiness of learning and performance speed.
2010	Speech dasher: fast writing using speech and gaze	Speech Dasher allows writing using a combination of speech and a zooming interface. Users first speak what they want to write and then they navigate through the space of recognition hypotheses to correct any errors. Speech Dasher's model combines information from a speech recognizer, from the user, and from a letter-based language model. This allows fast writing of anything predicted by the recognizer while also providing seamless fallback to letter-by-letter spelling for words not in the recognizer's predictions. In a formative user study, expert users wrote at 40 (corrected) words per minute. They did this despite a recognition word error rate of 22\%. Furthermore, they did this using only speech and the direction of their gaze (obtained via an eye tracker).
2010	NiCEBook: supporting natural note taking	In this paper, we present NiCEBook, a paper notebook that supports taking, structuring and reusing notes. Through a study of note-taking habits, we observed that different strategies are used to organize and share notes. Based on these observations, we developed a design for a notebook that combines different approaches to better support these activities. The details of our design were informed by an additional online survey. We emphasize the need to examine the characteristics of taking notes with paper notebooks in order to develop a digital system that resembles the quality of traditional writing. With NiCEBook, we present a solution that combines the flexibility and simplicity of taking notes on paper with the benefits of a digital representation. We demonstrate the capabilities of our system through customized views, searching and sharing functionality.
2010	The NiCE Discussion Room: Integrating Paper and Digital Media to Support Co-Located Group Meetings	Current technological solutions that enable content creation and sharing during group discussion meetings are often cumbersome to use, and are commonly abandoned for traditional paper-based tools, which provide flexibility in supporting a wide range of working styles and task activities that may occur in a given meeting. Paper-based tools, however, have their own drawbacks; paper-based content is difficult to modify or replicate. We introduce a novel digital meeting room design, the NiCE Discussion Room, which integrates digital and paper tools into a cohesive system with an intuitive pen-based interface. The combination of digital and paper media provides groups with a flexible design solution that enables them to create, access, and share information and media from a variety of sources to facilitate group discussions. This paper describes the design solution, along with results from a user study conducted to evaluate the usability and utility of the system.
2010	Weightless walls and the future office	In this paper we describe how future office environments can benefit from the addition of weightless walls virtual, sound blocking walls created using headsets. We particularly focus on exploring how different interaction techniques can be employed to efficiently create, erase, or edit the layouts of these walls, and envisioning how they could impact the overall office experience. Metaphorically, the end effect of integrating weightless walls into offices is that space will be treated in a way similar to how random access memory is treated in PCs; as a shared resource open to dynamic allocations, and whose usage is periodically optimized in real time according to the collective activities of the occupants. Furthermore, we view weightless walls as harbingers of the emergence of synthetic space the eventual fusion of the architectural environment with the distinctive properties of digital bits.
2010	Access Control for Home Data Sharing: Attitudes, Needs and Practices	As digital content becomes more prevalent in the home, non-technical users are increasingly interested in sharing that content with others and accessing it from multiple devices. Not much is known about how these users think about controlling access to this data. To better understand this, we conducted semi-structured, in-situ interviews with 33 users in 15 households. We found that users create ad-hoc access-control mechanisms that do not always work; that their ideal policies are complex and multi-dimensional; that a priori policy specification is often insufficient; and that people's mental models of access control and security are often misaligned with current systems. We detail these findings and present a set of associated guidelines for designing usable access-control systems for the home environment.
2010	Sharing conversation and sharing life: video conferencing in the home	Video conferencing is a technology that families and friends use to connect with each other over distance. However, even with such technology readily available, we still do not have a good understanding of how video conferencing systems are used by people as a part of their domestic communication practices. For this reason, we have conducted interviews with 21 adults in the United States to understand video conferencing routines in the home and to inform the design of future domestic communication technologies. Our findings illustrate the importance of discerning availability and willingness to video conference prior to calling, the need to share everyday life activities in addition to conversation, and a need for new privacy protecting strategies that focus on autonomy and solitude as opposed to confidentiality.
2010	Who's hogging the bandwidth: the consequences of revealing the invisible in the home	As more technologies enter the home, householders are burdened with the task of digital housekeeping-managing and sharing digital resources like bandwidth. In response to this, we created and evaluated a domestic tool for bandwidth management called Home Watcher. Our field trial showed that when resource contention amongst different household members is made visible, people's understanding of bandwidth changes and household politics are revealed. In this paper, we describe the consequences of showing real time resource usage in a home, and how this varies depending on the social make up of the household.
2010	Investigating narrative in mobile games for seniors	Narratives are an intimate part of our lives. Based on beha-vioral research suggesting that older adults tend to process text better at discourse level, this study investigates the im-pact of narrative structure on the enjoyment level of older game players. Two variations of a casual memory mobile game were built, one with a narrative and the other one without. Nineteen senior citizens, differentiated according to their play orientation, play-tested the games. Results show that embedding narratives in mobile games enhances the play experience of older adults, irrespective of their play style. This may have implications both for game developers and for seniors' acceptance of casual games.
2010	A study of tabbed browsing among mozilla firefox users	We present a study which investigated how and why users of Mozilla Firefox use multiple tabs and windows during web browsing. The detailed web browsing usage of 21 participants was logged over a period of 13 to 21 days each, and was supplemented by qualitative data from diary entries and interviews. Through an examination of several measures of their tab usage, we show that our participants had a strong preference for the use of tabs rather than multiple windows. We report the reasons they cited for using tabs, and the advantages over multiple windows. We identify several common tab usage patterns which browsers could explicitly support. Finally, we look at how tab usage affects web page revisitation. Most of our participants switched tabs more often than they used the back button, making tab switching the second most important navigation mechanism in the browser, after link clicking.
2010	Using text animated transitions to support navigation in document histories	This article examines the benefits of using text animated transitions for navigating in the revision history of textual documents. We propose an animation technique for smoothly transitioning between different text revisions, then present the Diffamation system. Diffamation supports rapid exploration of revision histories by combining text animated transitions with simple navigation and visualization tools. We finally describe a user study showing that smooth text animation allows users to track changes in the evolution of textual documents more effectively than flipping pages.
2010	Dynamic query interface for spatial proximity query with degree-of-interest varied by distance to query point	In this paper we present an interactive query interface called "TrapezoidBox" to support spatial proximity queries where users' degree of interest varies depending upon the degree of separation from the point of interest. Spatial proximity queries are commonly built in information seeking tasks especially on online maps. If not impossible, it is hard to formulate spatial proximity queries using existing dynamic query widgets such as range sliders. TrapezoidBox allows users to easily build spatial proximity queries by interactively adjusting a trapezoidal function. Our controlled user study results show that TrapezoidBox has several advantages over a baseline interface with range sliders.
2010	Learning on the job: characterizing the programming knowledge and learning strategies of web designers	This paper reports on a study of professional web designers and developers. We provide a detailed characterization of their knowledge of fundamental programming concepts elicited through card sorting. Additionally, we present qualitative findings regarding their motivation to learn new concepts and the learning strategies they employ. We find a high level of recognition of basic concepts, but we identify a number of concepts that they do not fully understand, consider difficult to learn, and use infrequently. We also note that their learning process is motivated by work projects and often follows a pattern of trial and error. We conclude with implications for end-user programming researchers.
2010	A strategy-centric approach to the design of end-user debugging tools	End-user programmers' code is notoriously buggy. This problem is amplified by the increasing complexity of end users' programs. To help end users catch errors early and reliably, we employ a novel approach for the design of end-user debugging tools: a focus on supporting end users' effective debugging strategies. This paper makes two contributions. We first demonstrate the potential of a strategy-centric approach to tool design by presenting StratCel, an add-in for Excel. Second, we show the benefits of this design approach: participants using StratCel found twice as many bugs as participants using standard Excel, they fixed four times as many bugs, and all this in only a small fraction of the time. Other contributions included: a boost in novices' debugging performance near experienced participants' improved levels, validated design guidelines, a discussion of the generalizability of this approach, and several opportunities for future research.
2010	Here's what i did: sharing and reusing web activity with ActionShot	ActionShot is an integrated web browser tool that creates a fine-grained history of users' browsing activities by continually recording their browsing actions at the level of interactions, such as button clicks and entries into form fields. ActionShot provides interfaces to facilitate browsing and searching through this history, sharing portions of the history through established social networking tools such as Facebook, and creating scripts that can be used to repeat previous interactions at a later time. ActionShot can also create short textual summaries for sequences of interactions. In this paper, we describe the ActionShot and our initial explorations of the tool through field deployments within our organization and a lab study. Overall, we found that ActionShot's history features provide value beyond typical browser history interfaces.
2010	Avaaj Otalo: a field study of an interactive voice forum for small farmers in rural India	In this paper we present the results of a field study of Avaaj Otalo (literally, "voice stoop"), an interactive voice application for small-scale farmers in Gujarat, India. Through usage data and interviews, we describe how 51 farmers used the system over a seven month pilot deployment. The most popular feature of Avaaj Otalo was a forum for asking questions and browsing others' questions and responses on a range of agricultural topics. The forum developed into a lively social space with the emergence of norms, persistent moderation, and a desire for both structured interaction with institutionally sanctioned authorities and open discussion with peers. For all 51 users this was the first experience participating in an online community of any sort. In terms of usability, simple menu-based navigation was readily learned, with users preferring numeric input over speech. We conclude by discussing implications of our findings for designing voice-based social media serving rural communities in India and elsewhere.
2010	An exploratory study of unsupervised mobile learning in rural India	Cellphones have the potential to improve education for the millions of underprivileged users in the developing world. However, mobile learning in developing countries remains under-studied. In this paper, we argue that cellphones are a perfect vehicle for making educational opportunities accessible to rural children in places and times that are more convenient than formal schooling. We carried out participant observations to identify the opportunities in their everyday lives for mobile learning. We next conducted a 26-week study to investigate the extent to which rural children will voluntarily make use of cellphones to access educational content. Our results show a reasonable level of academic learning and motivation. We also report on the social context around these results. Our goal is to examine the feasibility of mobile learning in out-of-school settings in rural, underdeveloped areas, and to help more researchers learn how to undertake similarly difficult studies around mobile computing in the developing world.
2010	Where there's a will there's a way: mobile media sharing in urban india	We present the results of a qualitative study of the sharing and consumption of entertainment media on low-cost mobile phones in urban India, a practice which has evolved into a vibrant, informal socio-technical ecosystem. This wide-ranging phenomenon includes end users, mobile phone shops, and content distributors, and exhibits remarkable ingenuity. Even more impressive is the number of obstacles which have been surmounted in its establishment, from the technical (interface complexity, limited Internet access, viruses), to the broader socioeconomic (cost, language, legality, institutional rules, lack of privacy), all seemingly due to a strong desire to be entertained. Our findings carry two implications for projects in HCI seeking to employ technology in service of social and economic development. First, although great attention is paid to the details of UI in many such projects, we find that sufficient user motivation towards a goal turns UI barriers into mere speed bumps. Second, we suggest that needs assessments carry an inherent bias towards what outsiders consider needs, and that identified "needs" may not be as strongly felt as perceived.
2010	Patterns of usage in an enterprise file-sharing service: publicizing, discovering, and telling the news	How do people use an enterprise file-sharing service? We describe patterns of usage in a social file-sharing service that was deployed in a large multinational enterprise. Factor analyses revealed four factors: Upload & Publicize (regarding one's own files); Annotate & Watch (add information to files and maintain awareness); Discover & Tell (find files uploaded by other users, and communicate to additional users about those files); and Refind (re-use one's own files). We explore the attributes of users who score highly on each of these factors, and we propose implications for design to encourage innovation in usage.
2010	The life and times of files and information: a study of desktop provenance	In the field of Human-Computer Interaction, provenance refers to the history and genealogy of a document or file. Provenance helps us to understand the evolution and relationships of files; how and when different versions of a document were created, or how different documents in a collection build on each other through copy-paste events. Though methods for tracking provenance and the subsequent use of this meta-data have been proposed and developed into tools, there have been no studies documenting the types and frequency of provenance events in typical computer use. This is knowledge essential for the design of efficient query methods and information displays. We conducted a longitudinal study of knowledge workers at Intel Corporation tracking provenance events in their computer use. We also interviewed knowledge workers to determine the effectiveness of provenance cues for document recall. Our data shows that provenance relationships are common, and provenance cues aid recall.
2010	The effect of audience design on labeling, organizing, and finding shared files	In an online experiment, I apply theory from psychology and communications to find out whether group information management tasks are governed by the same communication processes as conversation. This paper describes results that replicate previous research, and expand our knowledge about audience design and packaging for future reuse when communication is mediated by a co-constructed artifact like a file-and-folder hierarchy. Results indicate that it is easier for information consumers to search for files in hierarchies created by information producers who imagine their intended audience to be someone similar to them, independent of whether the producer and consumer actually share common ground. This research helps us better understand packaging choices made by information producers, and the direct implications of those choices for other users of group information systems.
2010	Fitting an activity-centric system into an ecology of workplace tools	Knowledge workers expend considerable effort managing fragmentation, characterized by constant switching among digital artifacts, when executing work activities. Activity-centric computing (ACC) systems attempt to address this problem by organizing activity-related artifacts together. But are ACC systems effective at reducing fragmentation? In this paper, we present a two-part study of workers using Lotus Activities, an ACC system deployed for over two years in a large company. First, we surveyed workers to understand the ecology of workplace tools they use for various tasks. Second, we interviewed 22 Lotus Activities users to investigate how this ACC tool fits amongst their ecology of existing collaboration tools and affects work fragmentation. Our results indicate that Lotus Activities works in concert with certain other tools to successfully ease fragmentation for a specific type of activity. We identify design characteristics that contribute to this result.
2010	Mobile music touch: mobile tactile stimulation for passive learning	Mobile Music Touch (MMT) helps teach users to play piano melodies while they perform other tasks. MMT is a lightweight, wireless haptic music instruction system consisting of fingerless gloves and a mobile Bluetooth enabled computing device, such as a mobile phone. Passages to be learned are loaded into the mobile phone and are played repeatedly while the user performs other tasks. As each note of the music plays, vibrators on each finger in the gloves activate, indicating which finger is used to play each note. We present two studies on the efficacy of MMT. The first measures 16 subjects' ability to play a passage after using MMT for 30 minutes while performing a reading comprehension test. The MMT system was significantly more effective than a control condition where the passage was played repeatedly but the subjects' fingers were not vibrated. The second study compares the amount of time required for 10 subjects to replay short, randomly generated passages using passive training versus active training. Participants with no piano experience could repeat the passages after passive training while subjects with piano experience often could not.
2010	Characteristics of pressure-based input for mobile devices	We conducted a series of user studies to understand and clarify the fundamental characteristics of pressure in user interfaces for mobile devices. We seek to provide insight to clarify a longstanding discussion on mapping functions for pressure input. Previous literature is conflicted about the correct transfer function to optimize user performance. Our study results suggest that the discrepancy can be explained by different signal conditioning circuitry and with improved signal conditioning the user-performed precision relationship is linear. We also explore the effects of hand pose when applying pressure to a mobile device from the front, the back, or simultaneously from both sides in a pinching movement. Our results indicate that grasping type input outperforms single-sided input and is competitive with pressure input against solid surfaces. Finally we provide an initial exploration of non-visual multimodal feedback, motivated by the desire for eyes-free use of mobile devices. The findings suggest that non-visual pressure input can be executed without degradation in selection time but suffers from accuracy problems.
2010	LayerPaint: a multi-layer interactive 3D painting interface	Painting on 3D surfaces is an important operation in computer graphics, virtual reality, and computer aided design. The painting styles in existing WYSIWYG systems can be awkward, due to the difficulty in rotating or aligning an object for proper viewing during the painting. This paper proposes a multi-layer approach to building a practical, robust, and novel WYSIWYG interface for efficient painting on 3D models. The paintable area is not limited to the front-most visible surface on the screen as in conventional WYSIWYG interfaces. We can efficiently and interactively draw long strokes across different depth layers, and unveil occluded regions that one would like to see or paint on. In addition, since the painting is now depth-sensitive, we can avoid various potential painting artifacts and limitations in the conventional painting interfaces. This multi-layer approach brings in several novel painting operations that contribute to a more compelling WYSIWYG 3D painting interface; this is particular useful when dealing with complicated objects with occluded parts and objects that cannot be easily parameterized. We evaluated our system with 23 users, including both artists and novice painters, and obtained positive experimental results and feedback from them. The user study results demonstrate the efficacy of our novel interface over conventional painting interfaces.
2010	The effects of diversity on group productivity and member withdrawal in online volunteer groups	The "wisdom of crowds" argument emphasizes the importance of diversity in online collaborations, such as open source projects and Wikipedia. However, decades of research on diversity in offline work groups have painted an inconclusive picture. On the one hand, the broader range of insights from a diverse group can lead to improved outcomes. On the other hand, individual differences can lead to conflict and diminished performance. In this paper, we examine the effects of group diversity on the amount of work accomplished and on member withdrawal behaviors in the context of WikiProjects. We find that increased diversity in experience with Wikipedia increases group productivity and decreases member withdrawal -- up to a point. Beyond that point, group productivity remains high, but members are more likely to withdraw. Strikingly, no such diminishing returns were observed for differences in member interest, which increases productivity and decreases member withdrawal in a linear fashion. Our results suggest that the low visibility of individual differences in online groups may allow them to harvest more of the benefits of diversity while bearing less of the cost. We discuss how our findings can inform further research of online collaboration.
2010	Gender demographic targeting in sponsored search	In this research, we evaluate the effect of gender in analyzing the performance of sponsored search advertising. We examine a log file with data comprised of nearly 7,000,000 records spanning 33 consecutive months of a search engine marketing campaign from a major US retailer. We classify key phrases selected for the campaign with a probability of being targeted for a specific gender and then compare the consumer actions using the critical sponsored search metrics of impressions, clicks, cost-per-click, sales revenue, orders, and items sold. Findings from our analysis show that the gender-orientation of the key phrase is a significant determinant in predicting behaviors and performance, with statistically different consumer behaviors for all attributes as the probability of a male or female keyword phrase changes. However, gender neutral phrases perform the best overall, calling into question the benefits of demographic targeting. Insight from this research could result in sponsored results being more effectively targeted to searchers and potential consumers.
2010	Exploring the workplace communication ecology	The modern workplace is inherently collaborative, and this collaboration relies on effective communication among co-workers. Many communication tools -- email, blogs, wikis, Twitter, etc. -- have become increasingly available and accepted in workplace communications. In this paper, we report on a study of communications technologies used over a one year period in a small US corporation. We found that participants used a large number of communication tools for different purposes, and that the introduction of new tools did not impact significantly the use of previously-adopted technologies. Further, we identified distinct classes of users based on patterns of tool use. This work has implications for the design of technology in the evolving ecology of communication tools.
2010	Making muscle-computer interfaces more practical	Recent work in muscle sensing has demonstrated the poten-tial of human-computer interfaces based on finger gestures sensed from electrodes on the upper forearm. While this approach holds much potential, previous work has given little attention to sensing finger gestures in the context of three important real-world requirements: sensing hardware suitable for mobile and off-desktop environments, elec-trodes that can be put on quickly without adhesives or gel, and gesture recognition techniques that require no new training or calibration after re-donning a muscle-sensing armband. In this note, we describe our approach to over-coming these challenges, and we demonstrate average clas-sification accuracies as high as 86\% for pinching with one of three fingers in a two-session, eight-person experiment.
2010	A novel brain-computer interface using a multi-touch surface	We present a novel integration of a brain-computer interface (BCI) with a multi-touch surface. BCIs based on the P300 paradigm often use a visual stimulus of a flashing character to elicit an event related potential in the brain's EEG signal. Traditionally, P300-based BCI paradigms use a grid layout of visual targets, commonly an alphabet, and allow users to select targets using their thoughts. In our new system a multi-touch table senses objects placed upon its surface and the system can highlight the objects on the table by flashing an area of light around them. This allows us to construct a P300-based BCI that uses a user-assembled collection of objects as targets, rather than a pre-determined grid layout. An experiment shows that our new paradigm works just as well as the traditional paradigms, thus highlighting the potential for BCIs to be integrated in a broader range of situations.
2010	The influence of implicit and explicit biofeedback in first-person shooter games	To understand how implicit and explicit biofeedback work in games, we developed a first-person shooter (FPS) game to experiment with different biofeedback techniques. While this area has seen plenty of discussion, there is little rigorous experimentation addressing how biofeedback can enhance human-computer interaction. In our two-part study, (N=36) subjects first played eight different game stages with two implicit biofeedback conditions, with two simulation-based comparison and repetition rounds, then repeated the two biofeedback stages when given explicit information on the biofeedback. The biofeedback conditions were respiration and skin-conductance (EDA) adaptations. Adaptation targets were four balanced player avatar attributes. We collected data with psycho¬physiological measures (electromyography, respiration, and EDA), a game experience questionnaire, and game-play measures. According to our experiment, implicit biofeedback does not produce significant effects in player experience in an FPS game. In the explicit biofeedback conditions, players were more immersed and positively affected, and they were able to manipulate the game play with the biosignal interface. We recommend exploring the possibilities of using explicit biofeedback interaction in commercial games.
2010	Effects of interactivity and 3D-motion on mental rotation brain activity in an immersive virtual environment	The combination of virtual reality (VR) and brain measurements is a promising development of HCI, but the maturation of this paradigm requires more knowledge about how brain activity is influenced by parameters of VR applications. To this end we investigate the influence of two prominent VR parameters, 3d-motion and interactivity, while brain activity is measured for a mental rotation task, using functional MRI (fMRI). A mental rotation network of brain areas is identified, matching previous results. The addition of interactivity increases the activation in core areas of this network, with more profound effects in frontal and preparatory motor areas. The increases from 3d-motion are restricted to primarily visual areas. We relate these effects to emerging theories of cognition and potential applications for brain-computer interfaces (BCIs). Our results demonstrate one way to provoke increased activity in task-relevant areas, making it easier to detect and use for adaptation and development of HCI.
2010	Scale detection for a priori gesture recognition	Gesture-based interfaces provide expert users with an efficient form of interaction but they require a learning effort for novice users. To address this problem, some on-line guiding techniques display all available gestures in response to partial input. However, partial input recognition algorithms are scale dependent while most gesture recognizers support scale independence (i.e., the same shape at different scales actually invokes the same command). We propose an algorithm for estimating the scale of any partial input in the context of a gesture recognition system and illustrate how it can be used to improve users' experience with gesture-based systems.
2010	Insight into goal-directed movement strategies	The current paper proposes a novel method of analyzing goal-directed movements by dividing them into distinct movement intervals. We demonstrate how the description of the first and second most prominent movement intervals in terms of duration and length can provide insight into the applied movement strategies under different conditions. This method, although demonstrated for goal-directed movements, has the potential to be generalized to other types of movements, such as steering movements.
2010	Usable gestures for mobile interfaces: evaluating social acceptability	Gesture-based mobile interfaces require users to change the way they use technology in public settings. Since mobile phones are part of our public appearance, designers must integrate gestures that users perceive as acceptable for pub-lic use. This topic has received little attention in the litera-ture so far. The studies described in this paper begin to look at the social acceptability of a set of gestures with re-spect to location and audience in order to investigate possi-ble ways of measuring social acceptability. The results of the initial survey showed that location and audience had a significant impact on a user's willingness to perform ges-tures. These results were further examined through a user study where participants were asked to perform gestures in different settings (including a busy street) over repeated trials. The results of this work provide gesture design rec-ommendations as well as social acceptability evaluation guidelines.
2010	iCanDraw: using sketch recognition and corrective feedback to assist a user in drawing human faces	When asked to draw, many people are hesitant because they consider themselves unable to draw well. This paper describes the first system for a computer to provide direction and feedback for assisting a user to draw a human face as accurately as possible from an image. Face recognition is first used to model the features of a human face in an image, which the user wishes to replicate. Novel sketch recognition algorithms were developed to use the information provided by the face recognition to evaluate the hand-drawn face. Two design iterations and user studies led to nine design principles for providing such instruction, presenting reference media, giving corrective feedback, and receiving actions from the user. The result is a proof-of-concept application that can guide a person through step-by-step instruction and generated feedback toward producing his/her own sketch of a human face in a reference image.
2010	Exploring the accessibility and appeal of surface computing for older adult health care support	This paper examines accessibility issues of surface computing with older adults and explores the appeal of surface computing for health care support. We present results from a study involving 20 older adults (age 60 to 88) performing gesture-based interactions on a multitouch surface. Older adults were able to successfully perform all actions on the surface computer, but some gestures that required two fingers (resize) and fine motor movement (rotate) were problematic. Ratings for ease of use and ease of performing each action as well as time required to figure out an action were similar to that of younger adults. Older adults reported that the surface computer was less intimidating, less frustrating, and less overwhelming than a traditional computer. The idea of using a surface computer for health care support was well-received by participants. We conclude with a discussion of design issues involving surface computing for older adults and use of this technology for health care.
2010	Patients, pacemakers, and implantable defibrillators: human values and security for wireless implantable medical devices	Implantable medical devices (IMDs) improve patients' quality of life and help sustain their lives. In this study, we explore patient views and values regarding their devices to inform the design of computer security for wireless IMDs. We interviewed 13 individuals with implanted cardiac devices. Key questions concerned the evaluation of 8 mockups of IMD security systems. Our results suggest that some systems that are technically viable are nonetheless undesirable to patients. Patients called out a number of values that affected their attitudes towards the systems, including perceived security, safety, freedom from unwanted cultural and historical associations, and self-image. In our analysis, we extend the Value Sensitive Design value dams and flows technique in order to suggest multiple, complementary systems; in our discussion, we highlight some of the usability, regulatory, and economic complexities that arise from offering multiple options. We conclude by offering design guidelines for future security systems for IMDs.
2010	One size does not fit all: applying the transtheoretical model to energy feedback technology design	Global warming, and the climate change it induces, is an urgent global issue. One remedy to this problem, and the focus of this paper, is to motivate sustainable energy usage behaviors by people. One approach is the development of technologies that provide real-time, continuous feedback of energy usage. However, there is one problem - most tech-nologies use a "one-size-fits-all" solution, providing the same feedback to differently motivated individuals at different stages of readiness, willingness and ableness to change. In this paper, we synthesize a wide range of motivational psychology literature to develop a motivational framework based on the Transtheoretical (aka Stages of Behavior Change) Model. For each stage, we state the mo-tivational goal(s), and recommendation(s) for how technol-ogies can reach these goals. Each goal and recommendation is supported by a rationale based on motivational literature. Each recommendation is supported by a simple textual example illustrating one way to apply the recommendation.
2010	Small business applications of sourcemap: a web tool for sustainable design and supply chain transparency	This paper introduces sustainable design applications for small businesses through the Life Cycle Assessment and supply chain publishing platform Sourcemap.org. This web-based tool was developed through a year-long participatory design process with five small businesses in Scotland and in New England. Sourcemap was used as a diagnostic tool for carbon accounting, design and supply chain management. It offers a number of ways to market sustainable practices through embedded and printed visualizations. Our experiences confirm the potential of web sustainability tools and social media to expand the discourse and to negotiate the diverse goals inherent in social and environmental sustainability.
2010	FeedWinnower: layering structures over collections of information streams	Information overload is a growing threat to the productivity of today's knowledge workers, who need to keep track of multiple streams of information from various sources. RSS feed readers are a popular choice for syndicating information streams, but current tools tend to contribute to the overload problem instead of solving it. We introduce FeedWinnower, an enhanced feed aggregator that helps readers to filter feed items by four facets (topic, people, source, and time), thus facilitating feed triage. The combination of the four facets provides a powerful way for users to slice and dice their personal feeds. In addition, we present a formative evaluation of the prototype conducted with 15 knowledge workers in two different organizations.
2010	Tools-at-hand and learning in multi-session, collaborative search	Improving search interfaces and algorithms are major foci of HCI and information retrieval (IR) research respectively. However, less attention has been given to understanding how users collect, manage, organize, and share the results they find from conducting searches on the Web and designing tools to support their needs. In this paper, we present results from a study in which we interviewed 30 people in three cohorts (academic researchers, corporate workers, and people looking for medical information) about their current practices conducting, managing, and sharing information from on-going, exploratory searches. We report results on users' current practices, tool use, areas of difficulties and associated coping strategies with emphasis on how information seekers use a variety of "tools-at-hand" beyond search engines and web browsers as they search, process, and share results, and on the learning processes that occur as they seek and use information over time.
2010	Share: a programming environment for loosely bound cooperation	We introduce a programming environment entitled Share that is designed to encourage loosely bound cooperation between individuals within communities of practice through the sharing of code. Loosely bound cooperation refers to the opportunity community members have to assist and share resources with one another while maintaining their autonomy and independent practice. We contrast this model with forms of collaboration that enable large numbers of distributed individuals to collaborate on large scale works where they are guided by a shared vision of what they are collectively trying to achieve. We hypothesize that providing fine-grained, publicly visible attribution of code sharing activity within a community can provide socially motivated encouragement for code sharing. We present an overview of the design of our tool and the objectives that guided its design and a discussion of a small-scale deployment of our prototype among members of a particular community of practice.
2010	Enhancing directed content sharing on the web	To find interesting, personally relevant web content, people rely on friends and colleagues to pass links along as they encounter them. In this paper, we study and augment link-sharing via e-mail, the most popular means of sharing web content today. Armed with survey data indicating that active sharers of novel web content are often those that actively seek it out, we developed FeedMe, a plug-in for Google Reader that makes directed sharing of content a more salient part of the user experience. FeedMe recommends friends who may be interested in seeing content that the user is viewing, provides information on what the recipient has seen and how many emails they have received recently, and gives recipients the opportunity to provide lightweight feedback when they appreciate shared content. FeedMe introduces a novel design space within mixed-initiative social recommenders: friends who know the user voluntarily vet the material on the user's behalf. We performed a two-week field experiment (N=60) and found that FeedMe made it easier and more enjoyable to share content that recipients appreciated and would not have found otherwise.
2010	Cultural difference in image tagging	Do people from different cultures tag digital images differently? The current study compared the content of tags for digital images created by two cultural groups: European Americans and Chinese. In line with previous findings on cultural differences in attentional patterns, we found similar cultural differences in the order of the image parts (e.g., foreground or background objects) that people tag. We found that for European Americans, the first tag was more likely assigned to the main objects than that by Chinese; but for Chinese, the first tag was more likely assigned to the overall description or relations between objects in the images. The findings had significant implications for designing cultural-sensitive tools to facilitate the tagging and search process of digital media, as well as for developing data-mining tools that identify user profiles based on their tagging patterns and cultural origins.
2010	Social tagging revamped: supporting the users' need of self-promotion through persuasive techniques	People share pictures online to increase their social presence. However, recent studies have shown that most of the content shared in social networks is not looked at by peers. Proper metadata can be generated and used to improve the retrieval of this content. In spite of this, we still lack solutions for collecting valid descriptors of content that can be used effectively in the context of social information navigation. In this paper, we propose a mechanism based on persuasive techniques to support peers in providing metadata for multimedia content that can be used for a person's self-promotion. Through an iterative design and experimentation process, we demonstrate how this methodology can be used effectively to increase one's social presence thus building more enjoyable, rich, and creative content that is shared in the social network. In addition, we highlight implications that inform the design of social games with a purpose.
2010	Some observations on the live collaborative tagging of audio conferences in the enterprise	This paper describes preliminary findings related to a system for "live" collaborative tagging of enterprise meetings taking place on an audio bridge between distributed participants. Participants can apply tags to different points of the interaction as it is ongoing and can see, in near real-time, the "flow" of tags as they are being contributed. Two novel types of tags are proposed: "deep tags" that apply to a portion of the interaction and "instant tags" that apply to an instant of the interaction. Our system is being used by enterprise users and we analyze a corpus of 737 live-tags collected from 16 conversations that took place over several months. We found that the live-tags for audio have slightly different characteristics from Web 2.0 tags: they are longer and confer affordances on the audio like description and summarization. Some observations on the "cognitive cost" of live-tagging are offered.
2010	Perceptions and practices of usability in the free/open source software (FoSS) community	This paper presents results from a study examining perceptions and practices of usability in the free/open source software (FOSS) community. 27 individuals associated with 11 different FOSS projects were interviewed to understand how they think about, act on, and are motivated to address usability issues. Our results indicate that FOSS project members possess rather sophisticated notions of software usability, which collectively mirror definitions commonly found in HCI textbooks. Our study also uncovered a wide range of practices that ultimately work to improve software usability. Importantly, these activities are typically based on close, direct interpersonal relationships between developers and their core users, a group of users who closely follow the project and provide high quality, respected feedback. These relationships, along with positive feedback from other users, generate social rewards that serve as the primary motivations for attending to usability issues on a day-to-day basis. These findings suggest a need to reconceptualize HCI methods to better fit this culture of practice and its corresponding value system.
2010	End-user mashup programming: through the design lens	Programming has recently become more common among ordinary end users of computer systems. We believe that these end-user programmers are not just coders but also designers, in that they interlace making design decisions with coding rather than treating them as two separate phases. To better understand and provide support for the programming and design needs of end users, we propose a design theory-based approach to look at end-user programming. Toward this end, we conducted a think-aloud study with ten end users creating a web mashup. By analyzing users' verbal and behavioral data using Schön's reflection-in-action design model and the notion of ideations from creativity literature, we discovered insights into end-user programmers' problem-solving attempts, successes, and obstacles, with accompanying implications for the design of end-user programming environments for mashups. The contribution of our work is three-fold: 1) the methodology of using a design lens to view programming, 2) evidence, through insights gained, of the usefulness of this approach, and 3) the implications themselves.
2010	What would other programmers do: suggesting solutions to error messages	Interpreting compiler errors and exception messages is challenging for novice programmers. Presenting examples of how other programmers have corrected similar errors may help novices understand and correct such errors. This paper introduces HelpMeOut , a social recommender system that aids the debugging of error messages by suggesting solutions that peers have applied in the past. HelpMeOut comprises IDE instrumentation to collect examples of code changes that fix errors; a central database that stores fix reports from many users; and a suggestion interface that, given an error, queries the database for a list of relevant fixes and presents these to the programmer. We report on implementations of this architecture for two programming languages. An evaluation with novice programmers found that the technique can suggest useful fixes for 47\% of errors after 39 person-hours of programming in an instrumented environment.
2010	Where are you pointing?: the accuracy of deictic pointing in CVEs	Deictic reference -- pointing at things during conversation -- is ubiquitous in human communication, and should also be an important tool in distributed collaborative virtual environments (CVEs). Pointing gestures can be complex and subtle, however, and pointing is much more difficult in the virtual world. In order to improve the richness of interaction in CVEs, it is important to provide better support for pointing and deictic reference, and a first step in this support is to determine how well people can interpret the direction that another person is pointing. To investigate this question, we carried out two studies. The first identified several ways that people point towards distant targets, and established that not all pointing requires high accuracy. This suggested that natural CVE pointing could potentially be successful; but no knowledge is available about whether even moderate accuracy is possible in CVEs. Therefore, our second study looked more closely at how accurately people can produce and interpret the direction of pointing gestures in CVEs. We found that although people are more accurate in the real world, the differences are smaller than expected; our results show that deixis can be successful in CVEs for many pointing situations, and provide a foundation for more comprehensive support of deictic pointing.
2010	Lie tracking: social presence, truth and deception in avatar-mediated telecommunication	The success of visual telecommunication systems depends on their ability to transmit and display users' natural nonverbal behavior. While video-mediated communication (VMC) is the most widely used form of interpersonal remote interaction, avatar-mediated communication (AMC) in shared virtual environments is increasingly common. This paper presents two experiments investigating eye tracking in AMC. The first experiment compares the degree of social presence experienced in AMC and VMC during truthful and deceptive discourse. Eye tracking data (gaze, blinking, and pupil size) demonstrates that oculesic behavior is similar in both mediation types, and uncovers systematic differences between truth telling and lying. Subjective measures show users' psychological arousal to be greater in VMC than AMC. The second experiment demonstrates that observers of AMC can more accurately detect truth and deception when viewing avatars with added oculesic behavior driven by eye tracking. We discuss implications for the design of future visual telecommunication media interfaces.
2010	Embodied social proxy: mediating interpersonal connection in hub-and-satellite teams	Current business conditions have given rise to distributed teams that are mostly collocated except for one remote member. These "hub-and-satellite" teams face the challenge of the satellite colleague being out-of-sight and out-of-mind. We developed a telepresence device, called an Embodied Social Proxy (ESP), which represents the satellite coworker 24x7. Beyond using ESPs in our own group, we deployed an ESP in four product teams within our company for six weeks. We studied how ESP was used through ethnographic observations, surveys, and usage log data. ESP not only increased the satellite worker's ability to fully participate in meetings, it also increased the hub's attention and affinity towards the satellite. The continuous physical presence of ESP in each team improved the interpersonal social connections between hub and satellite colleagues.
2010	MOSES: exploring new ground in media and post-conflict reconciliation	While the history of traditional media in post-conflict peace building efforts is rich and well studied, the potential for interactive new media technologies in this area has gone unexplored. In cooperation with the Truth and Reconciliation Commission of Liberia, we have constructed a novel interactive kiosk system, called MOSES, for use in that country's post-conflict reconciliation effort. The system allows the sharing of video messages between Liberians throughout the country, despite the presence of little or no communications infrastructure. In this paper, we describe the MOSES system, including several innovative design elements. We also present a novel design methodology we employed to manage the various distances between our design team and the intended user group in Liberia. Finally, we report on a qualitative study of the system with 27 participants from throughout Liberia. The study found that participants saw MOSES as giving them a voice and connecting them to other Liberians throughout the country; that the system was broadly usable by low-literate, novice users without human assistance; that the embodied conversational agent used in our design shows considerable promise; that users generally ascribed foreign involvement to the system; and that the system encouraged heavily group-oriented usage.
2010	Blogging in a region of conflict: supporting transition to recovery	The blogosphere is changing how people experience war and conflict. We conducted an analysis of 125 blogs written by Iraqi citizens experiencing extreme disruption in their country. We used Hoffman's [8] stages of recovery model to understand how blogs support people in a region where conflict is occurring. We found that blogs create a safe virtual environment where people could interact, free of the violence in the physical environment and of the strict social norms of their changing society in wartime. Second, blogs enable a large network of global support through their interactive and personal nature. Third, blogs enable people experiencing a conflict to engage in dialogue with people outside their borders to discuss their situation. We discuss how blogs enable people to collaboratively interpret conflict through communities of interest and discussion with those who comment. We discuss how technology can better support blog use in a global environment.
2010	Microblogging during two natural hazards events: what twitter may contribute to situational awareness	We analyze microblog posts generated during two recent, concurrent emergency events in North America via Twitter, a popular microblogging service. We focus on communications broadcast by people who were "on the ground" during the Oklahoma Grassfires of April 2009 and the Red River Floods that occurred in March and April 2009, and identify information that may contribute to enhancing situational awareness (SA). This work aims to inform next steps for extracting useful, relevant information during emergencies using information extraction (IE) techniques.
2010	The secure haptic keypad: a tactile password system	Authentication in public spaces poses significant security risks. Most significantly, passwords can be stolen, potentially leading to fraud. A common method to steal a PIN is through an observation attack, either using a camera or through direct observation (e.g. shoulder-surfing). This paper addresses this problem by presenting the design and implementation of a novel input keypad which uses tactile cues as means to compose a password. In this system, passwords are encoded as a sequence of randomized vibration patterns, making it visually impossible for an observer to detect which items are selected. An evaluation of this system shows it outperforms previous interfaces which have used tactile feedback to obfuscate passwords.
2010	Multi-touch authentication on tabletops	The introduction of tabletop interfaces has given rise to the need for the development of secure and usable authentication techniques that are appropriate for the co-located collaborative settings for which they have been designed. Most commonly, user authentication is based on something you know , but this is a particular problem for tabletop interfaces, as they are particularly vulnerable to shoulder surfing given their remit to foster co-located collaboration. In other words, tabletop users would typically authenticate in full view of a number of observers. In this paper, we introduce and evaluate a number of novel tabletop authentication schemes that exploit the features of multi-touch interaction in order to inhibit shoulder surfing. In our pilot work with users, and in our formal user-evaluation, one authentication scheme - Pressure-Grid - stood out, significantly enhancing shoulder surfing resistance when participants used it to enter both PINs and graphical passwords.
2010	ColorPIN: securing PIN entry through indirect input	Automated teller machine (ATM) frauds are increasing drastically these days. When analyzing the most common attacks and the reasons for successful frauds, it becomes apparent that the main problem lies in the PIN based authentication which in itself does not provide any security features (besides the use of asterisks). That is, security is solely based on a user's behavior. Indirect input is one way to solve this problem. This mostly comes at the costs of adding overhead to the input process. We present ColorPIN, an authentication mechanism that uses indirect input to provide security enhanced PIN entry. At the same time, ColorPIN remains a one-to-one relationship between the length of the PIN and the required number of clicks. A user study showed that ColorPIN is significantly more secure than standard PIN entry while enabling good authentication speed in comparison with related systems.
2010	Shoulder-surfing resistance with eye-gaze entry in cued-recall graphical passwords	We present Cued Gaze-Points (CGP) as a shoulder-surfing resistant cued-recall graphical password scheme where users gaze instead of mouse-click. This approach has several advantages over similar eye-gaze systems, including a larger password space and its cued-recall nature that can help users remember multiple distinct passwords. Our 45-participant lab study is the first evaluation of gaze-based password entry via user-selected points on images. CGP's usability is potentially acceptable, warranting further refinement and study.
2010	Visual vs. compact: a comparison of privacy policy interfaces	In this paper, we compare the impact of two different privacy policy representations -- AudienceView and Expandable Grids -- on users modifying privacy policies for a social network site. Despite the very different interfaces, there were very few differences in user performance. However, users had clear, and different, preferences and acknowledged the tradeoffs between the two representations. Our results imply that while either interface would be a usable option for policy settings, a combination may appeal to a wider audience and offer the best of both worlds.
2010	Pointassist for older adults: analyzing sub-movement characteristics to aid in pointing tasks	Perceptual, cognitive and motor deficits cause many older adults to have difficulty conducting pointing tasks on computers. Many strategies have been discussed in the HCI community to aid older adults and others in pointing tasks. We present a different approach in PointAssist, software that aids in pointing tasks by analyzing the characteristics of sub-movements, detecting when users have difficulty pointing, and triggering a precision mode that slows the speed of the cursor in those cases. PointAssist is designed to help maintain pointing skills, runs as a background process working with existing software, is not vulnerable to clusters of targets or targets in the way, and does not modify the visual appearance or the feel of user interfaces. There is evidence from a prior study that PointAssist helps young children conduct pointing tasks. In this paper, we present a study evaluating PointAssist with twenty older adults (ages 66-88). The study participants benefited from greater accuracy when using PointAssist, when compared to using the "enhance pointer precision" option in Windows XP. In addition, we provide evidence of correlations between neuropsychological measures, pointing performance, and PointAssist detecting pointing difficulty.
2010	Steadied-bubbles: combining techniques to address pen-based pointing errors for younger and older adults	Tablet PCs are gaining popularity but many older adults still struggle with pointing, particularly with two error types: missing , landing and lifting outside the target bounds; and slipping , landing on the target, but slipping off before lifting. To solve these problems, we examined the feasibility of extending and combining existing techniques designed for younger users and the mouse, focusing our investigation on the Bubble cursor and Steady Clicks techniques. Through a laboratory experiment with younger and older adults, we showed that both techniques can be adapted for use in a pen interface, and that combining the two techniques provides greater support than either technique on its own. Though our results were especially pertinent to the older group, both ages benefited from the designs. We also found that technique performance depended on task context. From these findings we established guidelines for technique selection.
2010	Learning to Text: An Interaction Analytic Study of How Seniors Learn to Enter Text on Mobile Phones	This paper is based on an interaction analysis of video recordings of seniors being instructed in the use of texting. Learning to text is a complex ordeal for the elderly, which not only involves grasping such complex phenomena as hierarchically organized menus and text prediction technology, but also more mundane and seemingly simple skills as pressing the keys. The latter is the primary focus of the analysis, as this is a common and taken for granted skill upon which many HCI systems rely. We show how the seniors struggle with learning to press in a sequence, embodying the timing and rhythm of key pressing, and orchestrating their vision and pressing. The study contributes to the general field of mobile phone design for the elderly, to our knowledge on how people appropriate and learn to use new technologies, as well as adds to models explaining novice users' mastering of text input.
2010	Touch-display keyboards: transforming keyboards into interactive surfaces	In spite of many advances in GUI workstations, the keyboard has remained limited to text entry and basic command invocation. In this work, we introduce the Touch-Display Keyboard (TDK), a novel keyboard that combines the physical-ergonomic qualities of the conventional keyboard with dynamic display and touch-sensing embedded in each key. The TDK effectively transforms the keyboard into an interactive surface that is seamlessly integrated with the interaction space of GUIs, extending graphical output, mouse interaction and three-state input to the keyboard. This gives rise to an entirely new design space of interaction across keyboard, mouse and screen, for which we provide a first systematic analysis in this paper. We illustrate the emerging design opportunities with a host of novel interaction concepts and techniques, and show how these contribute to expressiveness of GUIs, exploration and learning of keyboard interfaces, and interface customization across graphics display and physical keyboard.
2010	iCon: utilizing everyday objects as additional, auxiliary and instant tabletop controllers	This work describes a novel approach to utilizing everyday objects of users as additional, auxiliary, and instant tabletop controllers. Based on this approach, a prototype platform, called iCon, is developed to explore the possible design. Field studies and user studies reveal that utilizing everyday objects such as auxiliary input devices might be appropriate under a multi-task scenario. User studies further demonstrate that daily objects can generally be applied in low precision circumstances, low engagement with selected objects, and medium-to-high frequency of use. The proposed approach allows users to interact with computers while not altering their original work environments.
2010	Lumino: tangible blocks for tabletop computers based on glass fiber bundles	Tabletop computers based on diffuse illumination can track fiducial markers placed on the table's surface. In this paper, we demonstrate how to do the same with objects arranged in a three-dimensional structure without modifying the table. We present lumino, a system of building blocks. In addition to a marker, each block contains a glass fiber bundle. The bundle optically guides the light reflected off markers in the higher levels down to the table surface, where the table's built-in camera reads it. While guiding marker images down, the bundle optically scales and rearranges them. It thereby fits the images of an entire vertical arrangement of markers into the horizontal space usually occupied by a single 2D marker. We present six classes of blocks and matching marker designs, each of which is optimized for different requirements. We show three demo applications. One of them is a construction kit that logs and critiques constructions. The presented blocks are unpowered and maintenance-free, keeping larger numbers of blocks manageable.
2010	Opinion space: a scalable tool for browsing online comments	Internet users are increasingly inclined to contribute comments to online news articles, videos, product reviews, and blogs. The most common interface for comments is a list, sorted by time of entry or by binary ratings. It is widely recognized that such lists do not scale well and can lead to "cyberpolarization," which serves to reinforce extreme opinions. We present Opinion Space: a new online interface incorporating ideas from deliberative polling, dimensionality reduction, and collaborative filtering that allows participants to visualize and navigate through a diversity of comments. This self-organizing system automatically highlights the comments found most insightful by users from a range of perspectives. We report results of a controlled user study. When Opinion Space was compared with a chronological List interface, participants read a similar diversity of comments. However, they were significantly more engaged with the system, and they had significantly higher agreement with and respect for the comments they read.
2010	Short and tweet: experiments on recommending content from information streams	More and more web users keep up with newest information through information streams such as the popular micro-blogging website Twitter. In this paper we studied content recommendation on Twitter to better direct user attention. In a modular approach, we explored three separate dimensions in designing such a recommender: content sources, topic interest models for users, and social voting. We implemented 12 recommendation engines in the design space we formulated, and deployed them to a recommender service on the web to gather feedback from real Twitter users. The best performing algorithm improved the percentage of interesting content to 72\% from a baseline of 33\%. We conclude this work by discussing the implications of our recommender design and how our design can generalize to other information streams.
2010	Characterizing debate performance via aggregated twitter sentiment	Television broadcasters are beginning to combine social micro-blogging systems such as Twitter with television to create social video experiences around events. We looked at one such event, the first U.S. presidential debate in 2008, in conjunction with aggregated ratings of message sentiment from Twitter. We begin to develop an analytical methodology and visual representations that could help a journalist or public affairs person better understand the temporal dynamics of sentiment in reaction to the debate video. We demonstrate visuals and metrics that can be used to detect sentiment pulse, anomalies in that pulse, and indications of controversial topics that can be used to inform the design of visual analytic systems for social media events.
2010	Dandelion: supporting coordinated, collaborative authoring in Wikis	Dandelion is a tool that extends wikis to support coordinated, collaborative authoring using a tag-based approach. Specifically, users can insert tags in a wiki page to specify various co-authoring tasks. These tags can then be executed to help drive and manage the collaboration workflow, and provide content-centric collaboration awareness for all the co-authors. Four successful pilot deployments and positive user feedback show the practical value of Dandelion, especially its value in supporting a structured, collaborative authoring process often seen in business settings.
2010	Constructing identities through storytelling in diabetes management	The continuing epidemics of diabetes and obesity create much need for information technologies that can help individuals engage in proactive health management. Yet many of these technologies focus on such pragmatic issues as collecting and presenting health information and modifying individuals' behavior. At the same time, researchers in clinical community argue that individuals' perception of their identity has dramatic consequences for their health behaviors. In this paper we discuss results of a deployment study of a mobile health monitoring application. We show how individuals with considerable diabetes experience found a unique way to adopt this health-monitoring application to construct and negotiate their identities as persons with a chronic disease. We argue that viewing health management from identity construction perspective opens new opportunities for research and design in technologies for health.
2010	Self-monitoring, self-awareness, and self-determination in cardiac rehabilitation	The application of self-monitoring technologies to the problem of promoting health-related behavioural change has been an active area of research for many years. This paper reports on our investigations into health-related behavioural change within the context of a cardiac rehabilitation programme, and considers the role that self-monitoring currently plays and may play in the future. We carried out semi-structured interviews with nineteen cardiac rehabilitation participants. Our main findings relate to distinctions between implicit and conscious change, tensions between cardiac rehabilitation and everyday life, the importance of self-awareness and self-determination, and an overall reluctance towards unnecessary self-monitoring. In view of these findings, we then offer suggestions as to how self-monitoring technologies can be designed to suit this particular context of use.
2010	Negotiating boundaries: managing disease at home	To move treatment successfully from the hospital to that of technology assisted self-care at home, it is vital in the design of such technologies to understand the setting in which the health IT should be used. Based on qualitative studies we find that people engage in elaborate boundary work to maintain the order of the home when managing disease and adopting new healthcare technology. In our analysis we relate this boundary work to two continuums of visibility-invisibility and integration-segmentation in disease management. We explore five factors that affect the boundary work: objects, activities, places, character of disease, and collaboration. Furthermore, the processes are explored of how boundary objects move between social worlds pushing and shaping boundaries. From this we discuss design implications for future healthcare technologies for the home.
2010	Momentum : getting and staying on topic during a brainstorm	Despite the prevalent use of group brainstorming for problem solving and decision-making within organizations, brainstorming sessions often lack focus and fail to produce quality ideas. We describe Momentum , a tool that elicits topic-oriented responses prior to a group brainstorm. In an exploratory study, we found qualitative differences in task focus, quality and rate of ideation, and efficiency of storytelling between users and non-users of the tool.
2010	Layered elaboration: a new technique for co-design with children	As technology for children becomes more mobile, social, and distributed, our design methods and techniques must evolve to better explore these new directions. This paper reports on "Layered Elaboration," a co-design technique created to support these evolving needs. .Layered Elaboration allows design teams to generate ideas through an iterative process in which each version leaves prior ideas intact while extending concepts. Layered Elaboration is a useful technique as it enables co-design to take place asynchronously and does not require much space or many resources. Our intergenerational team, including adults and children ages 7 -- 11 years old, used the technique to design both a game about history and a prototype of an instructional game about energy conservation.
2010	Don't just stare at me!	Communication is more effective and persuasive when participants establish rapport. Tickle-Degnen and Rosenthal [57] argue rapport arises when participants exhibit mutual attentiveness, positivity and coordination. In this paper, we investigate how these factors relate to perceptions of rapport when users interact via avatars in virtual worlds. In this study, participants told a story to what they believed was the avatar of another participant. In fact, the avatar was a computer program that systematically manipulated levels of attentiveness, positivity and coordination. In contrast to Tickel-Degnen and Rosenthal's findings, high-levels of mutual attentiveness alone can dramatically lower perceptions of rapport in avatar communication. Indeed, an agent that attempted to maximize mutual attention performed as poorly as an agent that was designed to convey boredom. Adding positivity and coordination to mutual attentiveness, on the other hand, greatly improved rapport. This work unveils the dependencies between components of rapport and informs the design of agents and avatars in computer mediated communication.
2010	Video playdate: toward free play across distance	We present an empirical investigation of video-mediated free play between 13 pairs of friends (ages 7 and 8). The pairs spent 10 minutes playing with each of four different prototypes we developed to support free play over videoconferencing. We coded each interaction for the types of play and the amount of social play observed. The children in our study were largely successful in playing together across videoconferencing, though challenges in managing visibility, attention, and intersubjectivity made it more difficult than face-to-face play. We also found that our prototypes supported some types of play to varying degrees. Our contribution lies in identifying these design tradeoffs and providing directions for future design of video-mediated communication systems for children.
2010	Where should i turn: moving from individual to collaborative navigation strategies to inform the interaction design of future navigation systems	The design of in-vehicle navigation systems fails to take into account the social nature of driving and automobile navigation. In this paper, we consider navigation as a social activity among drivers and navigators to improve design of such systems. We explore the implications of moving from a map-centered, individually-focused design paradigm to one based upon collaborative human interaction during the navigation task. We conducted a qualitative interaction design study of navigation among three types of teams: parents and their teenage children, couples, and unacquainted individuals. We found that collaboration varied among these different teams, and was influenced by social role, as well as the task role of driver or navigator. We also found that patterns of prompts, maneuvers, and confirmations varied among the three teams. We identify overarching practices that differ greatly from the literature on individual navigation. From these discoveries, we present design implications that can be used to inform future navigation systems.
2010	Studying driver attention and behaviour for three configurations of GPS navigation in real traffic driving	Global Positioning System (GPS) navigation systems were amongst the top selling consumer technologies in 2008 and research has indicated that such technologies could affect driving behaviour. In this paper, we study how different output configurations (audio, visual and audio-visual) of a GPS system affect driving behaviour and performance. We conducted field experiments in real traffic with 30 subjects. Our results illustrated that visual output not only causes a substantial amount of eye glances, but also led to a decrease in driving performance. Adding audio output decreased the number of eye glances, but we found no significant effects on driving performance. Although the audio configuration implied much fewer eye glances and improved driving performance, several participants expressed preference for the audio/visual output.
2010	Cars, calls, and cognition: investigating driving and divided attention	Conversing on cell phones while driving an automobile is a common practice. We examine the interference of the cognitive load of conversational dialog with driving tasks, with the goal of identifying better and worse times for conversations during driving. We present results from a controlled study involving 18 users using a driving simulator. The driving complexity and conversation type were manipulated in the study, and performance was measured for factors related to both the primary driving task and secondary conversation task. Results showed significant interactions between the primary and secondary tasks, where certain combinations of complexity and conversations were found especially detrimental to driving. We present the studies and analyses and relate the findings to prior work on multiple resource models of cognition. We discuss how the results can frame thinking about policies and technologies aimed at enhancing driving safety.
2010	Homeless young people's experiences with information systems: life and work in a community technology center	This paper explores how homeless young people, aged 13-25, make use of information systems in daily life. Observed in a community technology center, four different examples of uses are described: i) Using digital tools to find employment, ii) Telling stories with representations of the built world, iii) Portraying life on the street with video, and iv) Constructing online identities. From these examples and a discussion of this community, a framework of ecological considerations is proposed. This framework distinguishes between elements of 'life' on the street (Self-Reliance, Vulnerability, and Basic Needs) and 'work' in the community technology center (Conformity, Youth-Adult Relationships, and Goals). Any information system for homeless young people must engage the tensions and opportunities that arise from these two different perspectives of homelessness.
2010	Feminist HCI: taking stock and outlining an agenda for design	Feminism is a natural ally to interaction design, due to its central commitments to issues such as agency, fulfillment, identity, equity, empowerment, and social justice. In this paper, I summarize the state of the art of feminism in HCI and propose ways to build on existing successes to more robustly integrate feminism into interaction design research and practice. I explore the productive role of feminism in analogous fields, such as industrial design, architecture, and game design. I introduce examples of feminist interaction design already in the field. Finally, I propose a set of femi-nist interaction design qualities intended to support design and evaluation processes directly as they unfold.
2010	Postcolonial computing: a lens on design and development	As our technologies travel to new cultural contexts and our designs and methods engage new constituencies, both our design and analytical practices face significant challenges. We offer postcolonial computing as an analytical orientation to better understand these challenges. This analytic orientation inspires four key shifts in our approach to HCI4D efforts: generative models of culture, development as a historical program, uneven economic relations, and cultural epistemologies. Then, through reconsideration of the practices of engagement, articulation and translation in other contexts, we offer designers and researchers ways of understanding use and design practice to respond to global connectivity and movement.
2010	Integrating Text with Video and 3D Graphics: The Effects of Text Drawing Styles on Text Readability	There have been many studies of computer based text reading. However, only a few have considered text integrated with video and 3D graphics. This paper presents an investigation into the effects of varying (a) text drawing style (plain, billboard, Anti-Interference, shadow), (b) image polarity (positive and negative), and (c) background style (video and 3D) on text readability. Reading speed and accuracy were measured and subjective views of participants recorded. Results showed that: (a) there was little difference in reading performance for the video and 3D backgrounds; (b) the negative presentation outperformed the positive presentation; (c) the billboard drawing styles supported the best performance; subjective comments showed a preference for the billboard style. We therefore suggest, for reading tasks, that designers of interfaces for games, video, and augmented reality provide billboard style to maximize readability for the widest range of applications.
2010	Apatite: a new interface for exploring APIs	We present Apatite, a new tool that aids users in learning and understanding a complex API by visualizing the common associations between its various components. Current object-oriented API documentation is usually navigated in a fixed tree structure, starting with a package and then filtering by a specific class. For large APIs, this scheme is overly restrictive, because it prevents users from locating a particular action without first knowing which class it belongs to. Apatite's design instead enables users to search across any level of an API's hierarchy. This is made possible by the introduction of a novel interaction technique that presents popular items from multiple categories simultaneously, determining their relevance by approximating the strength of their association using search engine data. The design of Apatite was refined through iterative usability testing, and it has been released publicly as a web application.
2010	Push-and-pull switching: window switching based on window overlapping	We propose Push-and-Pull Switching, a window switching technique using window overlapping to implicitly define groups. Push-and-Pull Switching enables switching between groups and restacking the focused window to any position to change its group membership. The technique was evaluated in an experiment which found that Push-and-Pull Switching improves switching performance by more than 50\% compared to other switching techniques in different scenarios. A longitudinal user study indicates that participants invoked this switching technique 15\% of the time on single monitor displays and that they found it easy to understand and use.
2010	Animated UI transitions and perception of time: a user study on animated effects on a mobile screen	The capability to present advanced graphics in the present mobile devices can be utilized to improve their usability and overall user experience. Mobile devices have limitations compared to PCs due to their inferior computing power and small screens, but a successful design of animated transitions can hide processing delays and make the user experience smoother. In this paper, we describe the design of animated transitions and present a user study on how they are perceived. The results show that in the transition between two images, bringing up the next image earlier dominates the perception of a fast transition over other variables examined in the study.
2010	Interactive optimization for steering machine classification	Interest has been growing within HCI on the use of machine learning and reasoning in applications to classify such hidden states as user intentions, based on observations. HCI researchers with these interests typically have little expertise in machine learning and often employ toolkits as relatively fixed "black boxes" for generating statistical classifiers. However, attempts to tailor the performance of classifiers to specific application requirements may require a more sophisticated understanding and custom-tailoring of methods. We present ManiMatrix, a system that provides controls and visualizations that enable system builders to refine the behavior of classification systems in an intuitive manner. With ManiMatrix, users directly refine parameters of a confusion matrix via an interactive cycle of re-classification and visualization. We present the core methods and evaluate the effectiveness of the approach in a user study. Results show that users are able to quickly and effectively modify decision boundaries of classifiers to tai-lor the behavior of classifiers to problems at hand.
2010	A longitudinal study of how highlighting web content change affects people's web interactions	The Web is constantly changing, but most tools used to access Web content deal only with what can be captured at a single instance in time. As a result, Web users may not have a good understanding of the changes that occur. In this paper we show that making Web content change explicitly visible allows people to interact with the Web in new ways. We present a longitudinal study in which 30 people used a Web browser plug-in that caches visited pages and highlights text changes to those pages when revisited. We used a survey to capture their understanding of Web page change and their own revisitation patterns at the beginning of use and after one month. For a majority of the participants, we also logged their Web page visits and associated content change. Exposing change is more valuable to our participants than initially expected, making them aware of how dynamic content they visit is and changing their interactions with it.
2010	Examining multiple potential models in end-user interactive concept learning	End-user interactive concept learning is a technique for interacting with large unstructured datasets, requiring insights from both human-computer interaction and machine learning. This note re-examines an assumption implicit in prior interactive machine learning research, that interaction should focus on the question "what class is this object?" . We broaden interaction to include examination of multiple potential models while training a machine learning system. We evaluate this approach and find that people naturally adopt revision in the interactive machine learning process and that this improves the quality of their resulting models for difficult concepts.
2010	Signed networks in social media	Relations between users on social media sites often reflect a mixture of positive (friendly) and negative (antagonistic) interactions. In contrast to the bulk of research on social networks that has focused almost exclusively on positive interpretations of links between people, we study how the interplay between positive and negative relationships affects the structure of on-line social networks. We connect our analyses to theories of signed networks from social psychology. We find that the classical theory of structural balance tends to capture certain common patterns of interaction, but that it is also at odds with some of the fundamental phenomena we observe --- particularly related to the evolving, directed nature of these on-line networks. We then develop an alternate theory of status that better explains the observed edge signs and provides insights into the underlying social mechanisms. Our work provides one of the first large-scale evaluations of theories of signed networks using on-line datasets, as well as providing a perspective for reasoning about social media sites.
2010	Why it's quick to be square: modelling new and existing hierarchical menu designs	We consider different hierarchical menu and toolbar-like interface designs from a theoretical perspective and show how a model based on visual search time, pointing time, decision time and expertise development can assist in understanding and predicting interaction performance. Three hierarchical menus designs are modelled -- a traditional pull-down menu, a pie menu and a novel Square Menu with its items arranged in a grid -- and the predictions are validated in an empirical study. The model correctly predicts the relative performance of the designs -- both the eventual dominance of Square Menus compared to traditional and pie designs and a performance crossover as users gain experience. Our work shows the value of modelling in HCI design, provides new insights about performance with different hierarchical menu designs, and demonstrates a new high-performance menu type.
2010	pCubee: a perspective-corrected handheld cubic display	In this paper, we describe the design of a personal cubic display that offers novel interaction techniques for static and dynamic 3D content. We extended one-screen Fish Tank VR by arranging five small LCD panels into a box shape that is light and compact enough to be handheld. The display uses head-coupled perspective rendering and a real-time physics simulation engine to establish an interaction metaphor of having real objects inside a physical box that a user can hold and manipulate. We evaluated our prototype as a visualization tool and as an input device by comparing it with a conventional LCD display and mouse for a 3D tree-tracing task. We found that bimanual interaction with pCubee and a mouse offered the best performance and was most preferred by users. pCubee has potential in 3D visualization and interactive applications such as games, storytelling and education, as well as viewing 3D maps, medical and architectural data.
2010	Bias towards regular configuration in 2D pointing	Extending Fitts' law to more than one dimension has been recognized as having important implications for HCI. In spite of the progress made over the years, however, it is still far from a resolved issue. Our work approaches this problem from the viewpoint of a configuration space, which has served as a useful conceptual framework for understanding human preference in perception. Notably, human are found to be biased towards regular configurations. In this work, we extended the configuration space framework to the domain of motor behavior, analyzed 2D pointing, and developed five models to account for the performance. An extensive experiment was conducted to measure the fit of the derived models and that of three previous models. Consistent with our hypothesis, the model reflecting a bias towards regular configuration was found to have the most satisfactory fit with the data. The paper concludes with discussions on improving understanding of Fitts' law and the implications for HCI.
2010	Digital drumming: a study of co-located, highly coordinated, dyadic collaboration	Collaborative drumming is a creative human activity that requires a high degree of coordination among the participants. In this study, inexperienced drummer and experienced drummer participants were paired with a computer or experienced human drummer counterpart and given the task of producing musical rhythms on the fly. We found differing patterns of music production across the computer and human conditions. Participants intentionally and unintentionally assumed leadership roles depending on the dyad dynamic. Also noted were differences in the needs of inexperienced and experienced participants for visual and verbal cues for coordination. In our study, participants did not treat computers as other humans, but seemed to engage a more complex evaluation of the situation. This study contributes to the growing body of knowledge on how people respond to and interact with technology to accomplish complex, collaborative tasks.
2010	G-nome surfer: a tabletop interface for collaborative exploration of genomic data	Molecular and computational biologists develop new insights by gathering heterogeneous data from genomic databases and leveraging bioinformatics tools. Through a qualitative study with 17 participants, we found that molecular and computational biologists experience difficulties interpreting, comparing, annotating, sharing, and relating this vast amount of biological information. We further observed that such interactions are critical for forming new scientific hypotheses. These observations motivated the creation of G-nome Surfer, a tabletop interface for collaborative exploration of genomic data that implements multi-touch and tangible interaction techniques. G-nome Surfer was developed in close collaboration with domain scientists and is aimed at lowering the threshold for using bioinformatics tools. A first-use study with 16 participants found that G-nome Surfer enables users to gain biological insights that are based on multiple forms of evidence with minimal overhead.
2010	America is like Metamucil: fostering critical and creative thinking about metaphor in political blogs	Blogs are becoming an increasingly important medium -- socially, academically, and politically. Much research has involved analyzing blogs, but less work has considered how such analytic techniques might be incorporated into tools for blog readers. A new tool, metaViz, analyzes political blogs for potential conceptual metaphors and presents them to blog readers. This paper presents a study exploring the types of critical and creative thinking fostered by metaViz as evidenced by user comments and discussion on the system. These results indicate the effectiveness of various system features at fostering critical thinking and creativity, specifically in terms of deep, structural reasoning about metaphors and creatively extending existing metaphors. Furthermore, the results carry broader implications beyond blogs and politics about exploring alternate configurations between computation and human thought.
2010	Understanding dispute resolution online: using text to reflect personal and substantive issues in conflict	Conflict is a natural part of human communication with implications for the work and well-being of a community. It can cause projects to stall or fail. Alternatively new insights can be produced that are valuable to the community, and membership can be strengthened. We describe how Wikipedia mediators create and maintain a 'safe space'. They help conflicting parties to express, recognize and respond positively to their personal and substantive differences. We show how the 'mutability' of wiki text can be used productively by mediators: to legitimize and restructure the personal and substantive issues under dispute; to actively and visibly differentiate personal from substantive elements in the dispute, and to maintain asynchronous engagement by adjusting expectations of timeliness. We argue that online conflicts could be effectively conciliated in other text-based web communities, provided power differences can be controlled, by policies and technical measures for maintaining special 'safe' conflict resolution spaces.
2010	Presenting diverse political opinions: how and how much	Is a polarized society inevitable, where people choose to be exposed to only political news and commentary that reinforces their existing viewpoints? We examine the relationship between the numbers of supporting and challenging items in a collection of political opinion items and readers' satisfaction, and then evaluate whether simple presentation techniques such as highlighting agreeable items or showing them first can increase satisfaction when fewer agreeable items are present. We find individual differences: some people are diversity-seeking while others are challenge-averse. For challenge-averse readers, highlighting appears to make satisfaction with sets of mostly agreeable items more extreme, but does not increase satisfaction overall, and sorting agreeable content first appears to decrease satisfaction rather than increasing it. These findings have important implications for builders of websites that aggregate content reflecting different positions.
2010	Propitious aggregation: reducing participant burden in ego-centric network data collection	One of the central challenges of ego-centric or personal social network research is minimizing the quantity of data that is requested from research participants while ensuring high data accuracy and validity. In general, collecting data about increasingly larger ego-centric networks places an increasing burden on respondents. The web-based Propitious Aggregation of Social Networks (PASN, http://pro.pitio.us) survey instrument reduces this burden by leveraging network data already available in the context of social network websites, and by providing an intuitive click-and-drag interface for survey responses. An experiment was conducted ( N = 85), and the PASN method was found to produce networks which were significantly larger and more diverse than those produced using standard survey methods, yet required significantly lower time investments from participants.
2010	Trying too hard: effects of mobile agents' (Inappropriate) social expressiveness on trust, affect and compliance	Mobile services can provide users with information relevant to their current circumstances. Distant services in turn can acquire local information from people in an area of interest. Socially expressive agent behaviour has been suggested as a way to build reciprocal relationships and to increase user response to such requests. This between-subject, Wizard-of-Oz experiment aimed to investigate the potential of such behaviours. 44 participants performed a search task in an urgent context while being interrupted by a mobile agent that both provided and requested information. The socially expressive behaviour shown in this study did not increase compliance to requests; it instead reduced trust in provided information and compliance to warnings. It also negatively impacted the affective experience of users scoring lower on empathy as a personality trait. Inappropriate social expressiveness can have serious consequences; we here elaborate on the reasons for our negative results.
2010	A simple index for multimodal flexibility	Most interactive tasks engage more than one of the user's exteroceptive senses and are therefore multimodal. In real world situations with multitasking and distractions, the key aspect of multimodality is not which modalities can be allocated to the interactive task but which are free to be allocated to something else. We present the multi¬modal flexibility index (MFI), calculated from changes in users' performance induced by blocking of sensory modalities. A high score indicates that the highest level of performance is achievable regardless of the modalities available and, conversely, a low score that performance will be severely hampered unless all modalities are allocated to the task. Various derivatives describe unimodal and bimodal effects. Results from a case study (mobile text entry) illustrate how an interface that is superior to others in absolute terms is the worst from the multimodal flexibility perspective. We discuss the suitability of MFI for evaluation of interactive prototypes.
2010	Social gravity: a virtual elastic tether for casual, privacy-preserving pedestrian rendezvous	We describe a virtual "tether" for mobile devices that allows groups to have quick, simple and privacy-preserving meetups. Our design provides cues which allow dynamic coordination of rendezvous without revealing users' positions. Using accelerometers and magnetometers, combined with GPS positioning and non-visual feedback, users can probe and sense a dynamic virtual object representing the nearest meeting point. The Social Gravity system makes social bonds tangible in a virtual world which is geographically grounded, using haptic feedback to help users rendezvous. We show dynamic navigation using this physical model-based system to be efficient and robust in significant field trials, even in the presence of low-quality positioning. The use of simulators to build models of mobile geolocated systems for pre-validation purposes is discussed, and results compared with those from our trials. Our results show interesting behaviours in the social coordination task, which lead to guidelines for geosocial interaction design. The Social Gravity system proved to be very successful in allowing groups to rendezvous efficiently and simply and can be implemented using only commercially available hardware.
2010	Temporal hybridity: footage with instant replay in real time	In this paper we explore the production of streaming media that involves live and recorded content. To examine this, we report on how the production practices and process are conducted through an empirical study of the production of live television, involving the use of live and non-live media under highly time critical conditions. In explaining how this process is managed both as an individual and collective activity, we develop the concept of temporal hybridity to explain the properties of these kinds of production system and show how temporally separated media are used, understood and coordinated. Our analysis is examined in the light of recent developments in computing technology and we present some design implications to support amateur video production.
2010	Experience, adjustment, and engagement: the role of video in law enforcement	Questions about the effectiveness of increasingly ubiquitous video technology in law enforcement have prompted an examination of the practices surrounding this technology. We present the results of a multi-site study aimed at understanding the use of video in several phases of law enforcement, from crime prevention and response to investigation and prosecution. Our findings show that while video has provided numerous benefits to law enforcement agencies, in many cases the technology either fails to support key facets of work or introduces new tasks that present an additional burden to workers. We discuss the need to incorporate human experience and tacit knowledge, operator engagement, and the greater ecosystem of work into video deployments.
2010	ToolClips: an investigation of contextual video assistance for functionality understanding	We investigate the use of on-line contextual video assistance to improve the learnability of software functionality. After discussing motivations and design goals for such forms of assistance, we present our new technique, ToolClips. ToolClips augment traditional tooltips to provide users with quick and contextual access to both textual and video assistance. In an initial study we found that users successfully integrated ToolClip usage into the flow of their primary tasks to overcome learnability difficulties. In a second study, we found that with ToolClips, users successfully completed 7 times as many unfamiliar tasks, in comparison to using a commercial professionally developed on-line help system. Users also retained the information obtained from ToolClips, performing tasks significantly faster one week later.
2010	Prefab: implementing advanced behaviors using pixel-based reverse engineering of interface structure	Current chasms between applications implemented with different user interface toolkits make it difficult to implement and explore potentially important interaction techniques in new and existing applications, limiting the progress and impact of human-computer interaction research. We examine an approach based in the single most common characteristic of all graphical user interface toolkits, that they ultimately paint pixels to a display. We present Prefab, a system for implementing advanced behaviors through the reverse engineering of the pixels in graphical interfaces. Informed by how user interface toolkits paint interfaces, Prefab features a separation of the modeling of widget layout from the recognition of widget appearance. We validate Prefab in implementations of three applications: target-aware pointing techniques, Phosphor transitions, and Side Views parameter spectrums. Working only from pixels, we demonstrate a single implementation of these enhancements in complex existing applications created in different user interface toolkits running on different windowing systems.
2010	GUI testing using computer vision	Testing a GUI's visual behavior typically requires human testers to interact with the GUI and to observe whether the expected results of interaction are presented. This paper presents a new approach to GUI testing using computer vision for testers to automate their tasks. Testers can write a visual test script that uses images to specify which GUI components to interact with and what visual feedback to be observed. Testers can also generate visual test scripts by demonstration. By recording both input events and screen images, it is possible to extract the images of components interacted with and the visual feedback seen by the demonstrator, and generate a visual test script automatically. We show that a variety of GUI behavior can be tested using this approach. Also, we show how this approach can facilitate good testing practices such as unit testing, regression testing, and test-driven development.
2010	Faster progress bars: manipulating perceived duration with visual augmentations	Human perception of time is fluid, and can be manipulated in purposeful and productive ways. In this note, we propose and evaluate variations on two visual designs for progress bars that alter users' perception of time passing, and "appear" faster when in fact they are not. As a baseline, we use standard, solid-color progress bars, prevalent in many user interfaces. In a series of direct comparison tests, we are able to rank how these augmentations compare to one another. We then show that these designs yield statistically significantly shorter perceived durations than progress bars seen in many modern interfaces, including Mac OSX. Progress bars with animated ribbing that move backwards in a decelerating manner proved to have the strongest effect. In a final experiment, we measured the effect of this particular progress bar design and showed that it reduces the perceived duration among our participants by 11\%.
2010	Evaluation of progressive image loading schemes	Although network bandwidth has increased dramatically, high-resolution images often take several seconds to load, and considerably longer on mobile devices over wireless connections. Progressive image loading techniques allow for some visual content to be displayed prior to the whole file being downloaded. In this note, we present an empirical evaluation of popular progressive image loading methods, and derive one novel technique from our findings. Results suggest a spiral variation of bilinear interlacing can yield an improvement in content recognition time.
2010	Friends only: examining a privacy-enhancing behavior in facebook	Privacy practices in social network sites often appear paradoxical, as content-sharing behavior stands in conflict with the need to reduce disclosure-related harms. In this study we explore privacy in social network sites as a contextual information practice, managed by a process of boundary regulation. Drawing on a sample survey of undergraduate Facebook users, we examine a particular privacy-enhancing practice: having a friends-only Facebook profile. Particularly, we look at the association between network composition, expectancy violations, interpersonal privacy practices and having a friends-only profile. We find that expectancy violations by weak ties and increased levels of interpersonal privacy management are positively associated with having a friends-only profile. We conclude with a discussion of how these findings may be integrated into the design of systems to facilitate interaction while enhancing individual privacy.
2010	Moving beyond untagging: photo privacy in a tagged world	Photo tagging is a popular feature of many social network sites that allows users to annotate uploaded images with those who are in them, explicitly linking the photo to each person's profile. In this paper, we examine privacy concerns and mechanisms surrounding these tagged images. Using a focus group, we explored the needs and concerns of users, resulting in a set of design considerations for tagged photo privacy. We then designed a privacy enhancing mechanism based on our findings, and validated it using a mixed methods approach. Our results identify the social tensions that tagging generates, and the needs of privacy tools to address the social implications of photo privacy management.
2010	Standardizing privacy notices: an online study of the nutrition label approach	Earlier work has shown that consumers cannot effectively find information in privacy policies and that they do not enjoy using them. In our previous research we developed a standardized table format for privacy policies. We compared this standardized format, and two short variants (one tabular, one text) with the current status quo: full text natural-language policies and layered policies. We conducted an online user study of 764 participants to test if these three more-intentionally designed, standardized privacy policy formats, assisted by consumer education, can benefit consumers. Our results show that standardized privacy policy presentations can have significant positive effects on accuracy and speed of information finding and on reader enjoyment of privacy policies.
2010	Family story play: reading with young children (and elmo) over a distance	We introduce Family Story Play, a system that supports grandparents to read books together with their grandchildren over the Internet. Family Story Play is designed to improve communication across generations and over a distance, and to support parents and grandparents in fostering the literacy development of young children. The interface encourages active child participation in the book reading experience by combining a paper book, a sensor-enhanced frame, video conferencing technology, and video content of a Sesame Street Muppet (Elmo). Results with users indicate that Family Story Play improves child engagement in long-distance communication and increases the quality of interaction between young children and distant grandparents. Additionally, Family Story Play encourages dialogic reading styles that are linked with literacy development. Ultimately, reading with Family Story Play becomes a creative shared activity that suggests a new kind of collaborative story telling.
2010	Designing with mobile digital storytelling in rural Africa	We reflect on activities to design a mobile application to enable rural people in South Africa's Eastern Cape to record and share their stories, which have implications for 'cross-cultural design,' and the wider use of stories in design. We based our initial concept for generating stories with audio and photos on cell-phones on a scenario informed by abstracting from digital storytelling projects globally and our personal experience. But insights from ethnography, and technology experiments involving storytelling, in a rural village led us to query our grounding assumptions and usability criteria. So, we implemented a method using cell-phones to localise storytelling, involve rural users and probe ways to incorporate visual and audio media. Products from this method helped us to generate design ideas for our current prototype which offers great flexibility. Thus we present a new way to depict stories digitally and a process for improving such software.
2010	Let's play chinese characters: mobile learning approaches via culturally inspired group games	In many developing countries such as India and China, low educational levels often hinder economic empowerment. In this paper, we argue that mobile learning games can play an important role in the Chinese literacy acquisition process. We report on the unique challenges in the learning Chinese language, especially its logographic writing system. Based on an analysis of 25 traditional Chinese games currently played by children in China, we present the design and implementation of two culturally inspired mobile group learning games, Multimedia Word and Drumming Strokes. These two mobile games are designed to match Chinese children's understanding of everyday games. An informal evaluation reveals that these two games have the potential to enhance the intuitiveness and engagement of traditional games, and children may improve their knowledge of Chinese characters through group learning activities such as controversy, judgments and self-correction during the game play.
2010	Expressive robots in education: varying the degree of social supportive behavior of a robotic tutor	Teaching is inherently a social interaction between teacher and student. Despite this knowledge, many educational tools, such as vocabulary training programs, still model the interaction in a tutoring scenario as unidirectional knowledge transfer rather than a social dialog. Therefore, ongoing research aims to develop virtual agents as more appropriate media in education. Virtual agents can induce the perception of a life-like social interaction partner that communicates through natural modalities such as speech, gestures and emotional expressions. This effect can be additionally enhanced with a physical robotic embodiment. This paper presents the development of social supportive behaviors for a robotic tutor to be used in a language learning application. The effect of these behaviors on the learning performance of students was evaluated. The results support that employing social supportive behavior increases learning efficiency of students.
2010	Exploring affective technologies for the classroom with the subtle stone	Constructive emotional experiences are strongly related to effective learning. Yet, it is challenging for teachers, researchers and students alike to understand the emotions experienced in the classroom setting. Advances in wireless and sensor technologies open up possibilities for better supporting emotions. However, little work has explored how affective technologies in the classroom might operate. This paper describes a study where 15 high school students used the Subtle Stone: a tangible technology designed to support students' active emotional communication in the classroom. We report on how the students used and experienced this technology, and the values they demonstrated through this use: flexibility, privacy, agency, voice and reflection. We conclude by examining future possibilities for affective technologies in the classroom.
2010	vSked: evaluation of a system to support classroom activities for children with autism	Visual schedules--the use of symbols to represent a series of activities or steps--have been successfully used by caregivers to help children with autism to understand, structure, and predict activities in their daily lives. Building from in-depth fieldwork and participatory design sessions, we developed vSked, an interactive and collaborative visual scheduling system designed for elementary school classrooms. We evaluated vSked in situ in one autism-specific classroom over three weeks. In this paper, we present the design principles, technical solution, and results from this successful deployment. Use of vSked resulted in reductions in staff effort required to use visual supports. vSked also resulted in improvements in the perceived quality and quantity of communication and social interactions in the classroom.
2010	Comparing user performance with single-finger, whole-hand, and hybrid pointing devices	Researchers have explored pointing devices operated by a single finger, but their advantage was not clear compared to conventional mice controlled by the whole hand. To incorporate the benefits of both, we prototyped hybrid pointing devices that combined both finger and hand movement to control the cursor, and experimentally compared their performance with single-finger and whole-hand devices. Results showed that such hybrid devices have the potential to improve pointing performance in terms of time, error, and bandwidth, especially for precise pointing.
2010	How users manipulate deformable displays as input devices	This study is aimed at understanding deformation-based user gestures by observing users interacting with artificial deformable displays with various levels of flexibility. We gained user-defined gestures that would help with the design and implementation of deformation-based interface, without considering current technical limitations. We found that when a display material gave more freedom from deformation, the level of consensus of gestures among the users as well as the intuitiveness and preferences were all enhanced. This study offers implications for deformation-based interaction which will be helpful for both designers and engineers who are trying to set the direction for future interface and technology development.
2010	Cord input: an intuitive, high-accuracy, multi-degree-of-freedom input method for mobile devices	A cord, although simple in form, has many interesting physical affordances that make it powerful as an input device. Not only can a length of cord be grasped in different locations, but also pulled, twisted and bent---four distinct and expressive dimensions that could potentially act in concert. Such an input mechanism could be readily integrated into headphones, backpacks, and clothing. Once grasped in the hand, a cord can be used in an eyes-free manner to control mobile devices, which often feature small screens and cramped buttons. In this note, we describe a proof-of-concept cord-based sensor, which senses three of the four input dimensions we propose. In addition to a discussion of potential uses, we also present results from our preliminary user study. The latter sought to compare the targeting performance and selection accuracy of different cord-based input modalities. We conclude with brief set of design recommendations drawn upon results from our study.
2010	Minput: enabling interaction on small mobile devices with high-precision, low-cost, multipoint optical tracking	We present Minput , a sensing and input method that enables intuitive and accurate interaction on very small devices -- ones too small for practical touch screen use and with limited space to accommodate physical buttons. We achieve this by incorporating two, inexpensive and high-precision optical sensors (like those found in optical mice) into the underside of the device. This allows the entire device to be used as an input mechanism, instead of the screen, avoiding occlusion by fingers. In addition to x/y translation, our system also captures twisting motion, enabling many interesting interaction opportunities typically found in larger and far more complex systems.
2010	How power users help and hinder open bug reporting	Many power users that contribute to open source projects have no intention of becoming regular contributors; they just want a bug fixed or a feature implemented. How often do these users participate in open source projects and what do they contribute? To investigate these questions, we analyzed the reports of Mozilla contributors who reported problems but were never assigned problems to fix. These analyses revealed that over 11 years and millions of reports, most of these 150,000 users reported non-issues that devolved into technical support, redundant reports with little new information, or narrow, expert feature requests. Reports that did lead to changes were reported by a comparably small group of experienced, frequent reporters, mostly before the release of Firefox 1. These results suggest that the primary value of open bug reporting is in recruiting talented reporters, and not in deriving value from the masses.
2010	Bringing the field into focus: user-centered design of a patient expertise locator	Managing personal aspects of health is challenging for many patients, particularly those facing a serious condition such as cancer. Finding experienced patients, who can share their knowledge from managing a similar health situation, is of tremendous value. Users of health-related social software form a large base of such knowledge, yet these tools often lack features needed to locate peers with expertise. Informed directly by our field work with breast cancer patients, we designed a patient expertise locator for users of online health communities. Using feedback from two focus groups with breast cancer survivors, we took our design through two iterations. Focus groups concluded that expertise locating features proved useful for extending social software. They guided design enhancements by suggesting granular user control through (1) multiple mechanisms to identify expertise, (2) detailed user profiles to select expertise, and (3) varied collaboration levels. Our user-centered approach links field work to design through close collaboration with patients. By illustrating trade-offs made when sharing sensitive health information, our findings inform the incorporation of expertise locating features into social software for patients.
2010	What do you know?: experts, novices and territoriality in collaborative systems	When experts participate in collaborative systems, tension may arise between them and novice contributors. In particular, when experts perceive novices as a bother or a threat, the experts may express territoriality: behaviors communicating ownership of a target of interest. In this paper, we describe the results of a user study of a mobile social tagging system deployed within a museum gallery to a group of novices and experts collaboratively tagging part of the collection. We observed that experts express greater feelings of ownership towards their contributions to the system and the museum in general. Experts were more likely than novices to participate at higher rates and to negatively evaluate contributions made by others. We suggest a number of design strategies to balance experts' expressions of territoriality so as to motivate their participation while discouraging exclusionary behaviors.
2010	An empirical task analysis of warehouse order picking using head-mounted displays	Evaluations of task guidance systems often focus on evaluations of new technologies rather than comparing the nuances of interaction across the various systems. One common domain for task guidance systems is warehouse order picking. We present a method involving an easily reproducible ecologically motivated order picking environment for quantitative user studies designed to reveal differences in interactions. Using this environment, we perform a 12 participant within-subjects experiment demonstrating the advantages of a head-mounted display based picking chart over a traditional text-based pick list, a paper-based graphical pick chart, and a mobile pick-by-voice system. The test environment proved sufficiently sensitive, showing statistically significant results along several metrics with the head-mounted display system performing the best. We also provide a detailed analysis of the strategies adopted by our participants.
2010	Where is my team: supporting situation awareness with tactile displays	A group of friends visiting a crowded and noisy music festival is an example of a situation where knowing the location of other people is important, but where external factors, such as darkness or noise, can limit the ability to keep track of the others. By combining theories about situation awareness and cognitive processing we inferred that communicating information via the sense of touch is a promising approach in such situations. We therefore investigated how to present the location of several people using a tactile torso display. In particular we focused on encoding spatial distances in the tactile signals. We experimentally compared encoding spatial distances in the rhythm, duration, and intensity of a tactile signal. Our findings show that all parameters are suited to encode distances. None of it was clearly outperformed. We then embedded our tactile location encoding into a fast-paced 3D multiplayer game. In this game, team play and the awareness of the team members' locations are crucial for the success in the game. The results provides evidence that the locations of the team members could be processed effectively despite the game's high cognitive demands. In addition, the team equipped with the tactile display showed a better team play and a higher situation awareness.
2010	Clutching at straws: using tangible interaction to provide non-visual access to graphs	We present a tangible user interface (TUI) called Tangible Graph Builder, that has been designed to allow visually impaired users to access graph and chart-based data. We describe the current paper-based materials used to allow independent graph construction and browsing, before discussing how researchers have applied virtual haptic and non-speech audio techniques to provide more flexible access. We discuss why, although these technologies overcome many of the problems of non-visual graph access, they also introduce new issues and why the application of TUIs is important. An evaluation of Tangible Graph Builder with 12 participants (8 sight deprived, 4 blind) revealed key design requirements for non-visual TUIs, including phicon design and handling marker detection failure. We finish by presenting future work and improvements to our system.
2010	Effects of automated transcription quality on non-native speakers' comprehension in real-time computer-mediated communication	Real-time transcription has been shown to be valuable in facilitating non-native speakers' comprehension in real-time communication. Automated speech recognition (ASR) technology is a critical ingredient for its practical deployment. This paper presents a series of studies investigating how the quality of transcripts generated by an ASR system impacts user comprehension and subjective evaluation. Experiments are first presented comparing performance across three different transcription conditions: no transcript, a perfect transcript, and a transcript with Word Error Rate (WER) =20\%. We found 20\% WER was the most likely critical point for transcripts to be just acceptable and useful. Then we further examined a lower WER of 10\% (a lower bound for today's state-of-the-art systems) employing the same experimental design. The results indicated that at 10\% WER comprehension performance was significantly improved compared to the no-transcript condition. Finally, implications for further system development and design are discussed.
2010	Understanding the impact of abstracted audio preview of SMS	Despite the availability of other mobile messaging applications, SMS has kept its position as a heavily used communication technology. However, there are many situations in which it is inconvenient or inappropriate to check a message's content immediately. In this paper, we introduce the concept of audio previews of SMS. Based on a real-time analysis of the content of a message, we provide auditory cues in addition to the notification tone upon receiving an SMS. We report on a field trial with 20 participants and show that the use of audio-enhanced SMS affects the reading and writing behavior of users. Our work is motivated by the results of an online survey among 347 SMS users of whose we analyzed 3400 text messages.
2010	What do people ask their social networks, and why?: a survey study of status message q&a behavior	People often turn to their friends, families, and colleagues when they have questions. The recent, rapid rise of online social networking tools has made doing this on a large scale easy and efficient. In this paper we explore the phenomenon of using social network status messages to ask questions. We conducted a survey of 624 people, asking them to share the questions they have asked and answered of their online social networks. We present detailed data on the frequency of this type of question asking, the types of questions asked, and respondents' motivations for asking their social networks rather than using more traditional search tools like Web search engines. We report on the perceived speed and quality of the answers received, as well as what motivates people to respond to questions seen in their friends' status messages. We then discuss the implications of our findings for the design of next-generation search tools.
2010	Affirming the self through online profiles: beneficial effects of social networking sites	Self-affirmation is the process of bringing to awareness important aspects of the self, such as values, goals, and treasured characteristics. When affirmed, individuals are more open-minded and less defensive. This study examines whether social networking tools, such as Facebook, have self-affirming value. Participants were asked to either spend time on their own Facebook profiles, or on a stranger's profile. Afterwards, they were given negative feedback on a task. Participants who spent time on their own profiles were more accepting of the feedback, and less likely to engage in ego-protective mechanisms, such as derogating the task or the evaluator. In fact, they behaved identically to participants who completed a classic self-affirmation manipulation. The theoretical contributions of this paper include (1) identifying intrapersonal effects of online self-presentation and (2) extending self-affirmation theory to include social media use.
2010	Improving social game engagement on facebook through enhanced socio-contextual information	In this paper we describe the results of a controlled study of a social game, Magpies , which was built on the Facebook Online Social Network (OSN) and enhanced with contextual social information in the form of a variety of social network indices. Through comparison with a concurrent control trial using an identical game without the enhanced social information, it was shown that the additional contextual data increased the frequency of social activity between players engaged in the game. Despite this increase in activity, there was little increase in growth of the player-base when compared to the control condition. These findings corroborate previous work that showed how socio-contextual enhancement can increase performance on task-driven games, whilst also suggesting that it can increase activity and engagement when provided as context for non task-driven game environments.
2010	The role of community and groupware in geocache creation and maintenance	Applications that provide location-based experiences are an increasingly viable design space given the proliferation of GPS-enabled mobile devices. However, these applications are in their infancy, and we do not yet know what design factors will contribute to their success. For this reason, we have studied the well-established location-based experience of geocaching. We report on the results of a survey of geocachers along with observations from our own in-depth geocaching activities. Our findings illustrate that geocaching permits users to create a range of experiences for others within a permeable yet restricted culture of norms. Once created, geocaches are maintained by the community of geocachers through a well-designed groupware system. Here maintenance acts can be performed "in the small," given their lightweight and well-defined nature, and become less about maintenance and more about personal participation. These findings provide insight into how community and groupware can be leveraged to support applications for location-based experiences.
2010	Doctors and psychosocial information: records and reuse in inpatient care	We conducted a field-based study at a large teaching hospital to examine doctors' use and documentation of patient care information, with a special focus on a patient's psychosocial information. We were particularly interested in the gaps between the medical work and any representations of the patient. The paper describes how doctors record this information for immediate and long-term use. We found that doctors documented a considerable amount of psychosocial information in their electronic health records (EHR) system. Yet, we also observed that such information was recorded selectively, and a medicalized view-point is a key contributing factor. Our study shows how missing or problematic representations of a patient affect work activities and patient care. We accordingly suggest that EHR systems could be made more usable and useful in the long run, by supporting both representations of medical processes and of patients.
2010	Supporting coordination in surgical suites: physical aspects of common information spaces	To accommodate frequent emergencies, interruptions, and delays, hospital staff continually make and coordinate changes to the surgery schedule. The technical and social aspects of coordination in surgical suites have been described by prior studies. This paper addresses an understudied aspect of coordination: the physical environment. Based on a field study of four surgical suites in two large academic centers, we show how the physical layout of hallways and rooms, and barriers and spaces around displays and key coordinators, support or fail to support the common information spaces used for coordination. We use the concept "information hotspots" to represent how physical places and their characteristics facilitate coordination. We developed design principles based on the concept of information hotspots that should guide architectural considerations for coordination in dynamic environments such as hospitals.
2010	Documenting transitional information in EMR	An observational study was conducted to examine EMR-based documentation in an Emergency Department (ED), with an emphasis on computerized documentation activities in the complex flow of clinical processes. This study revealed a gap between the formal EMR documentation and the actual clinical workflow, which leads ED staff to rely on intermediate - transitional artifacts to facilitate their work. The analysis of these transitional artifacts in four different clinical workflows shows that the EMR system's inability to document procedural information, capture key information, and present information according to the actual clinical workflow are accountable for leading to the use of transitional artifacts. The findings of this study call for designing EMR system not only for keeping patients' formal records, but also for documenting transitional information in the chart-writing process.
2010	Understanding the space for co-design in riders' interactions with a transit service	The recent advances in web 2.0 technologies and the rapid adoption of smart phones raises many opportunities for public services to improve their services by engaging their users (who are also owners of the service) in co-design: a dialog where users help design the services they use. To investigate this opportunity, we began a service design project investigating how to create repeated information exchanges between riders and a transit agency in order to create a virtual "place" from which the dialog on services could take place. Through interviews with riders, a workshop with a transit agency, and speed dating of design concepts, we have developed a design direction. Specifically, we propose a service that combines vehicle location and "fullness" ratings provided by riders with dynamic route change information from the transit agency as a foundation for a dialog around riders conveying input for continuous service improvement.
2010	OneBusAway: results from providing real-time arrival information for public transit	Public transit systems play an important role in combating traffic congestion, reducing carbon emissions, and promoting compact, sustainable urban communities. The usability of public transit can be significantly enhanced by providing good traveler information systems. We describe OneBusAway, a set of transit tools focused on providing real-time arrival information for Seattle-area bus riders. We then present results from a survey of OneBusAway users that show a set of important positive outcomes: strongly increased overall satisfaction with public transit, decreased waiting time, increased transit trips per week, increased feelings of safety, and even a health benefit in terms of increased distance walked when using transit. Finally, we discuss the design and policy implications of these results and plans for future research in this area.
2010	Biketastic: sensing and mapping for better biking	Bicycling is an affordable, environmentally friendly alternative transportation mode to motorized travel. A common task performed by bikers is to find good routes in an area, where the quality of a route is based on safety, efficiency, and enjoyment. Finding routes involves trial and error as well as exchanging information between members of a bike community. Biketastic is a platform that enriches this experimentation and route sharing process making it both easier and more effective. Using a mobile phone application and online map visualization, bikers are able to document and share routes, ride statistics, sensed information to infer route roughness and noisiness, and media that documents ride experience. Biketastic was designed to ensure the link between information gathering, visualization, and bicycling practices. In this paper, we present architecture and algorithms for route data inferences and visualization. We evaluate the system based on feedback from bicyclists provided during a two-week pilot.
2010	A death in the family: opportunities for designing technologies for the bereaved	Following the death of a loved one, bereaved family members use technology in several ways to respond to their loss. However, very little is known about how technology intersects with the lives of the bereaved. We present a survey and interview study which examines how the bereaved inherit personal digital devices, use technology to remember the deceased, and reflect on their own digital estates. The study provides one of the first characterizations of technology use by the bereaved, and presents a set of empirically-grounded design opportunities and challenges.
2010	Passing on & putting to rest: understanding bereavement in the context of interactive technologies	While it can be a delicate and emotionally-laden topic, new technological trends compel us to confront a range of problems and issues about death and bereavement. This area presents complex challenges and the associated literature is extensive. In this paper we offer a way of slicing through several perspectives in the social sciences to see clearly a set of salient issues related to bereavement. Following this, we present a theoretical lens to provide a way of conceptualizing how the HCI community could begin to approach such issues. We then report field evidence from 11 in-depth interviews conducted with bereaved participants and apply the proposed lens to unpack key emergent problems and tensions. We conclude with a discussion on how the HCI design space might be sensitized to better support the social processes that unfold when bereavement occurs.
2010	Fear and the city: role of mobile services in harnessing safety and security in urban use contexts	This paper describes investigation of a mobile communication system that helps alleviate fear experienced in the urban context. In order to obtain empirically grounded insights for the concept design, urban females in their twenties and thirties and living in Bangalore, New Delhi and San Francisco, were studied. More than 200 females filled in an online survey. Extensive qualitative data for 13 participants were collected through week long diaries, semi-structured interviews, and situated participative enactment of scenarios. Fear-related concerns were voiced both in India and the U.S., suggesting that reducing fear, particularly in a pedestrian context after the onset of darkness, could be a globally applicable need. User research findings into subjective experiences of fear, contexts in which they occur, and behavioral strategies were used to design a mobile service titled ComfortZones. This concept was developed to the level of a high fidelity prototype and tested in a field trial in India. The investigation highlights further opportunities for design, particularly the notion of emphasizing positive and socially successful qualities of cities to communities concerned with their safety and security.
2010	UpStream: motivating water conservation with low-cost water flow sensing and persuasive displays	Water is our most precious and most rapidly declining natural resource. We explore pervasive technology as an approach for promoting water conservation in public and private spaces. We hope to motivate immediate reduction in water use as well as higher-order behaviors (seeking new information, etc) through unobtrusive low-cost water flow sensing and several persuasive displays. Early prototypes were installed at public faucets and a private (shared) shower, logging water usage first without and then with ambient displays. This pilot study led to design iterations, culminating in long-term deployment of sensors in four private showers over the course of three weeks. Sensors first logged baseline water usage without visualization. Then, two display styles, ambient and numeric, were deployed in random order, each showing individual and average water consumption. Quantitative data along with participants' feedback contrast the effectiveness of numeric displays against abstract visualization in this very important domain of water conservation and public health.
2010	InAir: sharing indoor air quality measurements and visualizations	This paper describes inAir, a tool for sharing measurements and visualizations of indoor air quality within one's social network. Poor indoor air quality is difficult for humans to detect through sight and smell alone and can contribute to the development of chronic diseases. Through a four-week long study of fourteen households as six groups, we found that inAir (1) increased awareness of, and reflection on air quality, (2) promoted behavioral changes that resulted in improved indoor air quality, and (3) demonstrated the persuasive power of sharing for furthering improvements to indoor air quality in terms of fostering new social awareness and behavior changes as well as strengthening social bonds and prompting collaborative efforts across social networks to improve human health and well being.
2010	Exploring sustainable design with reusable paper	This paper explores the need for sustainable design with paper: how people really print and how we can take advantage of novel, reusable paper technology. We conducted two studies to investigate user's printing behavior. A key finding of the first study was that users often need an intermediate state between the electronic and physical forms of their documents. The second study examined users' predictions of which types of documents required this intermediate state. We formulate these findings into design guidelines that take into account: examination phase, transitions, cognitive and emotional reasons , and task- and event-relevant documents . Finally, we discuss how the different physical characteristics of reusable paper affect the user interface and could effectively support sustainable design.
2010	Finding the lost treasure: understanding reuse of used computing devices	In this paper, we report our findings on the adoption practices of used personal digital assistants (PDAs) to inform reuse of outdated computing products. Our interviews with 12 eBay users who bought used PDAs showed a variety of ways in which users indirectly supported sustainability. This allowed us to re-examine sustainability as something that is dynamically and arbitrarily shaped by the users and not just dependent on the sustainable feature of the product. We end with design implications for supporting users' shaping of sustainability.
2010	Physician-driven management of patient progress notes in an intensive care unit	We describe fieldwork in which we studied hospital ICU physicians and their strategies and documentation aids for composing patient progress notes. We then present a clinical documentation prototype, activeNotes, that supports the creation of these notes, using techniques designed based on our fieldwork. ActiveNotes integrates automated, context-sensitive patient data retrieval, and user control of automated data updates and alerts via tagging, into the documentation process. We performed a qualitative study of activeNotes with 15 physicians at the hospital to explore the utility of our information retrieval and tagging techniques. The physicians indicated their desire to use tags for a number of purposes, some of them extensions to what we intended, and others new to us and unexplored in other systems of which we are aware. We discuss the physicians' responses to our prototype and distill several of their proposed uses of tags: to assist in note content management, communication with other clinicians, and care delivery.
2010	Mobile-izing health workers in rural India	Researchers have long been interested in the potential of ICTs to enable positive change in developing regions communities. In these environments, ICT interventions often fail because political, social and cultural forces work against the changes ICTs entail. We argue that familiar uses of ICTs for information services in these contexts are less potent than their use for persuasion and motivation in order to facilitate change. We focus on India's rural maternal health system where health workers are employed in villages to persuade pregnant women to utilize health services. Health workers face challenges due to resistance to change in the village, and because of their limited education, training and status. These factors appear to reduce the motivation of health workers and impair their performance. For two months, we deployed short videos on mobile phones designed to persuade village women and motivate health workers. We also asked health workers to record their own videos. While our results are preliminary, they show evidence that the creation and use of videos did help (1) engage village women in dialogue, (2) show positive effects toward health worker motivation and learning, and (3) motivate key community influencers to participate in promoting the health workers.
2010	Who's scribing?: documenting patient encounter during trauma resuscitation	With healthcare moving towards electronic health records, it is important to understand existing work practices to design effective systems. We conducted an observational study in a Level I trauma center to examine the documentation process and the role of the nurse recorder in trauma resuscitation. We identified several difficulties with current recording practices, including the late arrival of the nurse recorder, parallel activities of the trauma team, and multitasking by the recorder. Our observations showed that the recorder's role extends beyond archival responsibilities. The recorder, with the help of a paper record, manages the resuscitation process, rather than passively documenting it. Our findings highlighted the complexity of the recorder's role and the need to consider documentation in the broader context of trauma teamwork. We proposed a set of design challenges that emphasize important aspects of trauma care to be considered when designing technologies to support the documentation process.
2010	Social network activity and social well-being	Previous research has shown a relationship between use of social networking sites and feelings of social capital. However, most studies have relied on self-reports by college students. The goals of the current study are to (1) validate the common self-report scale using empirical data from Facebook, (2) test whether previous findings generalize to older and international populations, and (3) delve into the specific activities linked to feelings of social capital and loneliness. In particular, we investigate the role of directed interaction between pairs---such as wall posts, comments, and "likes" --- and consumption of friends' content, including status updates, photos, and friends' conversations with other friends. We find that directed communication is associated with greater feelings of bonding social capital and lower loneliness, but has only a modest relationship with bridging social capital, which is primarily related to overall friend network size. Surprisingly, users who consume greater levels of content report reduced bridging and bonding social capital and increased loneliness. Implications for designs to support well-being are discussed.
2010	Predicting influence in an online community of creators	This paper introduces the concept of Online Communities of Creators (OCOCs), which are a subset of social network sites in which the core activity is sharing personal, original creations. Next it defines two distinct types of influence, Project Influence and Social Influence. Project Influence is a measure of the degree to which the community recognizes members' work. Social Influence is a measure of how much a member is a social bridge between otherwise unconnected members. These two types of influence are studied in an online programming community called the Scratch Online Community. Two multiple linear regressions determine the factors that predict each of the two types of influence. The factors predicting each were distinct, suggesting that these are two distinct constructs in this community.
2010	Lurking? cyclopaths?: a quantitative lifecycle analysis of user behavior in a geowiki	Online communities produce rich behavioral datasets, e.g., Usenet news conversations, Wikipedia edits, and Facebook friend networks. Analysis of such datasets yields important insights (like the "long tail" of user participation) and suggests novel design interventions (like targeting users with personalized opportunities and work requests). However, certain key user data typically are unavailable, specifically viewing, pre-registration, and non-logged-in activity. The absence of data makes some questions hard to answer; ac- cess to it can strengthen, extend, or cast doubt on previous results. We report on analysis of user behavior in Cyclopath, a geographic wiki and route-finder for bicyclists. With access to viewing and non-logged-in activity data, we were able to: (a) replicate and extend prior work on user lifecycles in Wikipedia, (b) bring to light some pre-registration activity, thus testing for the presence of "educational lurking," and (c) demonstrate the locality of geographic activity and how editing and viewing are geographically correlated.
2010	Motivations to participate in online communities	A consistent theoretical and practical challenge in the design of socio-technical systems is that of motivating users to participate in and contribute to them. This study examines the case of Everything2.com users from the theoretical perspectives of Uses and Gratifications and Organizational Commitment to compare individual versus organizational motivations in user participation. We find evidence that users may continue to participate in a site for different reasons than those that led them to the site. Feelings of belonging to a site are important for both anonymous and registered users across different types of uses. Long-term users felt more dissatisfied with the site than anonymous users. Social and cognitive factors seem to be more important than issues of usability in predicting contribution to the site.
2010	Motivating expressive writing with a text-to-sound application	Writing about emotional experiences has been shown to have long-term physical and mental health benefits, but it also creates short-term discomfort. We designed a system to motivate expressive writing by enhancing enjoyment and pleasure. Using automated language analysis, we designed a system that maps sound onto categories of language resulting in a musical interpretation of expressive writing texts. An experimental design compared the experience of 126 participants across musical and non-musical writing platforms Participants found the musical system to be more pleasurable.
2010	Artificial subtle expressions: intuitive notification methodology of artifacts	We describe artificial subtle expressions (ASEs) as intuitive notification methodology for artifacts' internal states for users. We prepared two types of audio ASEs; one was a flat artificial sound (flat ASE), and the other was a sound that decreased in pitch (decreasing ASE). These two ASEs were played after a robot made a suggestion to the users. Specifically, we expected that the decreasing ASE would inform users of the robot's lower level of confidence about the suggestions. We then conducted a simple experiment to observe whether the participants accepted or rejected the robot's suggestion in terms of the ASEs. The results showed that they accepted the robot's suggestion when the flat ASE was used, whereas they rejected it when the decreasing ASE was used. Therefore, we found that the ASEs succeeded in conveying the robot's internal state to the users accurately and intuitively.
2010	SoundNet: investigating a language composed of environmental sounds	Auditory displays have been used in both human-machine and computer interfaces. However, the use of non-speech audio in assistive communication for people with language disabilities, or in other applications that employ visual representations, is still under-investigated. In this paper, we introduce SoundNet, a linguistic database that associates natural environmental sounds with words and concepts. A sound labeling study was carried out to verify SoundNet associations and to investigate how well the sounds evoke concepts. A second study was conducted using the verified SoundNet data to explore the power of environmental sounds to convey concepts in sentence contexts, compared with conventional icons and animations. Our results show that sounds can effectively illustrate (especially concrete) concepts and can be applied to assistive interfaces.
2010	Detecting professional versus personal closeness using an enterprise social network site	In this work we analyze the behavior on a company-internal social network site to determine which interaction patterns signal closeness between colleagues. Regression analysis suggests that employee behavior on social network sites (SNSs) reveals information about both professional and personal closeness. While some factors are predictive of general closeness (e.g. content recommendations), other factors signal that employees feel personal closeness towards their colleagues, but not professional closeness (e.g. mutual profile commenting). This analysis contributes to our understanding of how SNS behavior reflects relationship multiplexity: the multiple facets of our relationships with SNS connections.
2010	Lessons learned from blog muse: audience-based inspiration for bloggers	Blogging in the enterprise is increasingly popular and recent research has shown that there are numerous benefits for both individuals and the organization, e.g. developing reputation or sharing knowledge. However, participation is very low, blogs are often abandoned and few users realize those benefits. We have designed and implemented a novel system -- called Blog Muse -- whose goal is to inspire potential blog writers by connecting them with their audience through a topic-suggestion system. We describe our system design and report results from a 4-week study with 1004 users who installed our tool. Our data indicate that topics requested by users are effective at inspiring bloggers to write and lead to more social interactions around the resulting entries.
2010	Mapping the landscape of sustainable HCI	With the recent growth in sustainable HCI, now is a good time to map out the approaches being taken and the intellectual commitments that underlie the area, to allow for community discussion about where the field should go. Here, we provide an empirical analysis of how sustainable HCI is defining itself as a research field. Based on a corpus of published works, we identify (1) established genres in the area, (2) key unrecognized intellectual differences, and (3) emerging issues, including urgent avenues for further exploration, opportunities for interdisciplinary engagement, and key topics for debate.
2010	Home, habits, and energy: examining domestic interactions and energy consumption	This paper presents findings from a qualitative study of people's everyday interactions with energy-consuming products and systems in the home. Initial results from a large online survey are also considered. This research focuses not only on "conservation behavior" but importantly investigates interactions with technology that may be characterized as "normal consumption" or "over-consumption." A novel vocabulary for analyzing and designing energy-conserving interactions is proposed based on our findings, including: cutting, trimming, switching, upgrading, and shifting. Using the proposed vocabulary, and informed by theoretical developments from various literatures, this paper demonstrates ways in which everyday interactions with technology in the home are performed without conscious consideration of energy consumption but rather are unconscious, habitual, and irrational. Implications for the design of energy-conserving interactions with technology and broader challenges for HCI research are proposed.
2010	Studying always-on electricity feedback in the home	The recent emphasis on sustainability has made consumers more aware of their responsibility for saving resources, in particular, electricity. Consumers can better understand how to save electricity by gaining awareness of their consumption beyond the typical monthly bill. We conducted a study to understand consumers' awareness of energy consumption in the home and to determine their requirements for an interactive, always-on interface for exploring data to gain awareness of home energy consumption. In this paper, we describe a three-stage approach to supporting electricity conservation routines: raise awareness, inform complex changes, and maintain sustainable routines. We then present the findings from our study to support design implications for energy consumption feedback interfaces.
2010	The design of eco-feedback technology	Eco-feedback technology provides feedback on individual or group behaviors with a goal of reducing environmental impact. The history of eco-feedback extends back more than 40 years to the origins of environmental psychology. Despite its stated purpose, few HCI eco-feedback studies have attempted to measure behavior change. This leads to two overarching questions: (1) what can HCI learn from environmental psychology and (2) what role should HCI have in designing and evaluating eco-feedback technology? To help answer these questions, this paper conducts a comparative survey of eco-feedback technology, including 89 papers from environmental psychology and 44 papers from the HCI and UbiComp literature. We also provide an overview of predominant models of proenvironmental behaviors and a summary of key motivation techniques to promote this behavior.
2010	Mobile taskflow in context: a screenshot study of smartphone usage	The impact of interruptions on workflow and productivity has been extensively studied in the PC domain, but while fragmented user attention is recognized as an inherent aspect of mobile phone usage, little formal evidence exists of its effect on mobile productivity. Using a survey and a screenshot-based diary study we investigated the types of barriers people face when performing tasks on their mobile phones, the ways they follow up with such suspended tasks, and how frustrating the experience of task disruption is for mobile users. From 386 situated samples provided by 12 iPhone and 12 Pocket PC users, we distill a classification of barriers to the completion of mobile tasks. Our data suggest that moving to a PC to complete a phone task is common, yet not inherently problematic, depending on the task. Finally, we relate our findings to prior design guidelines for desktop workflow, and discuss how the guidelines can be extended to mitigate disruptions to mobile taskflow.
2010	An adaptive speed-call list algorithm and its evaluation with ESM	We designed an algorithm to build a speed-call list adaptively based on mobile phone call logs. Call logs provide the time-dependent calling patterns of mobile phone users, and therefore a speed-call list based on them will be more successful in recommending a desired number than a speed-call list based on recent calls only. This paper presents the design process of our algorithm for an adaptive speed-call list, its verification result with recorded call logs, and in-situ evaluation results of the algorithm using an Experience Sampling Method (ESM) system.
2010	Evaluation of text entry methods for Korean mobile phones, a user study	This paper reports the results of a user study designed to evaluate text entry methods for mobile phones used in Korea. At present the keypad layout for Korean mobile phones has not been standardized and different manufacturers produce phones with different layouts. Included in the evaluation are three of the dominant text entry methods: Chon-ji-in, EZ-Hangul, and SKY. The metrics used in the analysis are key strokes per character, words per minute, and total error rate. The results suggest that SKY offers a good balance between speed, effort, and accuracy. The paper also introduces a phrase set that has high correlation with the Korean language and could be used in other experiments on Korean text entry methods.
2010	Pensieve: supporting everyday reminiscence	Reminiscing is a valuable activity that people of all ages spontaneously and informally partake in as part of their everyday lives. This paper discusses the design and use of Pensieve, a system that supports everyday reminiscence by emailing memory triggers to people that contain either social media content they previously created on third-party websites or text prompts about common life experiences. We discuss how the literature on reminiscence informed Pensieve's design, then analyze data from 91 users over five months. We find that people value spontaneous reminders to reminisce as well as the ability to write about their reminiscing. Shorter, more general triggers draw more responses, as do triggers containing people's own photos-although responses to photos tended to contain more metadata elements than storytelling elements. We compare these results to data from a second, Pensieve-like system developed for Facebook, and suggest a number of important aspects to consider for both designers and researchers around technology and reminiscence.
2010	Involving reflective users in design	We draw on the idea of the reflective practitioner to consider how end users can directly contribute to user experience design discussions in open source projects. People with expertise in their own use context but without programming or user experience analysis and design skills can provide reflections on personal experiences.
2010	Designing games for learning: insights from conversations with designers	This paper presents insights about design practices that can lead to effective and fun games for learning, gleaned from interviews with experienced game developers. We based our approach on Schön's notion of practitioners evolving shared 'appreciation systems' for discussing and critiquing work, and aimed to gather and share some of game designers' 'appreciation system' for games and learning. The resulting insights provide valuable pointers to other designers in the CHI community crafting game-like experiences.
2010	Now let me see where i was: understanding how lifelogs mediate memory	Lifelogging technologies can capture both mundane and important experiences in our daily lives, resulting in a rich record of the places we visit and the things we see. This study moves beyond technology demonstrations, in aiming to better understand how and why different types of Lifelogs aid memory. Previous work has demonstrated that Lifelogs can aid recall, but that they do many other things too. They can help us look back at the past in new ways, or to reconstruct what we did in our lives, even if we don't recall exact details. Here we extend the notion of Lifelogging to include locational information. We augment streams of Lifelog images with geographic data to examine how different types of data (visual or locational) might affect memory. Our results show that visual cues promote detailed memories (akin to recollection). In contrast locational information supports inferential processes -- allowing participants to reconstruct habits in their behaviour.
2010	The prayer companion: openness and specificity, materiality and spirituality	In this paper we describe the Prayer Companion, a device we developed as a resource for the spiritual activity of a group of cloistered nuns. The device displays a stream of information sourced from RSS news feeds and social networking sites to suggest possible topics for prayers. The nuns have engaged with the device enthusiastically over the first ten months of an ongoing deployment, and, notwithstanding some initial irritation with the balance of content, report that it plays a significant and continuing role in their prayer life. We discuss how we balanced specificity in the design with a degree of openness for interpretation to create a resource that the nuns could both understand and appropriate, describe the importance of materiality to the device's successful adoption, consider its implications as a design for older people, and reflect on the example it provides of how computation may serve spirituality.
2010	What's your idea?: a case study of a grassroots innovation pipeline within a large software company	Establishing a grassroots innovation pipeline has come to the fore as strategy for nurturing innovation within large organizations. A key element of such pipelines is the use of an idea management system that enables and encourages community ideation on defined business problems. The value of these systems can be highly sensitive to design choices, as different designs may influence participation. We report the results of a case study examining the use of one particular idea management system and pipeline. We analyzed the content, interaction, and participation from three creativity challenges organized via the pipeline and conducted interviews with users to uncover motivations for participating and perceptions of the outcomes. Additional interviews were conducted with senior managers to learn about the objectives, successes, and unique nature of the pipeline. From the results, we formulate recommendations for improving the design of idea management systems and execution of the pipelines within organizations.
2010	Asl-stem forum: enabling sign language to grow through online collaboration	American Sign Language (ASL) currently lacks agreed-upon signs for complex terms in scientific fields, causing deaf students to miss or misunderstand course material. Furthermore, the same term or concept may have multiple signs, resulting in inconsistent standards and strained collaboration. The ASL-STEM Forum is an online, collaborative, video forum for sharing ASL signs and discussing them. An initial user study of the Forum has shown its viability and revealed lessons in accommodating varying user types, from lurkers to advanced contributors, until critical mass is achieved.
2010	Curator: a game with a purpose for collection recommendation	Collection recommender systems suggest groups of items that work well as a whole. The interaction effects between items is an important consideration, but the vast space of possible collections makes it difficult to analyze. In this paper, we present a class of games with a purpose for building collections where users create collections and, using an output agreement model, they are awarded points based on the collections that match. The data from these games will help researchers develop guidelines for collection recommender systems among other applications. We conducted a pilot study of the game prototype which indicated that it was fun and challenging for users, and that the data obtained had the characteristics necessary to gain insights into the interaction effects among items. We present the game and these results followed by a discussion of the next steps necessary to bring games to bear on the problem of creating harmonious groups.
2010	Modeling dwell-based eye pointing target acquisition	We propose a quantitative model for dwell-based eye pointing tasks. Using the concepts of information theory to analogize eye pointing, we define an index of difficulty ( ID eye ) for the corresponding tasks in a similar manner to the definition that Fitts made for hand pointing. According to our validations in different situations, ID eye , which takes account of the distinct characteristics of rapid saccades and involuntary eye jitters, can accurately and meaningfully describe eye pointing tasks. To the best of our knowledge, this work is the first successful attempt to model eye gaze interactions.
2010	Gazemarks: gaze-based visual placeholders to ease attention switching	Many tasks require attention switching. For example, searching for information on one sheet of paper and then entering this information onto another one. With paper we see that people use fingers or objects as placeholders. Using these simple aids, the process of switching attention between displays can be simplified and speeded up. With large or multiple visual displays we have many tasks where both attention areas are on the screen and where using a finger as a placeholder is not suitable. One way users deal with this is to use the mouse and highlight their current focus. However, this also has its limitations -- in particular in environments where there is no pointing device. Our approach is to utilize the user's gaze position to provide a visual placeholder. The last area where a user fixated on the screen (before moving their attention away) is highlighted; we call this visual reminder a Gazemark. Gazemarks ease orientation and the resumption of the interrupted task when coming back to this display. In this paper we report on a study where the effectiveness of using Gazemarks was investigated, in particular we show how they can ease attention switching. Our results show faster completion times for a resumed simple visual search task when using this technique. The paper analyzes relevant parameters for the implementation of Gazemarks and discusses some further application areas for this approach.
2010	Knowing where and when to look in a time-critical multimodal dual task	Human-computer systems intended for time-critical multitasking need to be designed with an understanding of how humans can coordinate and interleave perceptual, memory, and motor processes. This paper presents human performance data for a highly-practiced time-critical dual task. In the first of the two interleaved tasks, participants tracked a target with a joystick. In the second, participants keyed-in responses to objects moving across a radar display. Task manipulations include the peripheral visibility of the secondary display (visible or not) and the presence or absence of auditory cues to assist with the radar task. Eye movement analyses reveal extensive coordination and overlapping of human information processes and the extent to which task manipulations helped or hindered dual task performance. For example, auditory cues helped only a little when the secondary display was peripherally visible, but they helped a lot when it was not peripherally visible.
2010	Towards customizable games for stroke rehabilitation	Stroke is the leading cause of long term disability among adults in industrialized nations. The partial paralysis that stroke patients often experience can make independent living difficult or impossible. Research suggests that many of these patients could recover by performing hundreds of daily repetitions of motions with their affected limbs. Yet, only 31\% of patients perform the exercises recommended by their therapists. Home-based stroke rehabilitation games may help motivate stroke patients to perform the necessary exercises to recover. In this paper, we describe a formative study in which we designed and user tested stroke rehabilitation games with both stroke patients and therapists. We describe the lessons we learned about what makes games useful from a therapeutic point of view.
2010	Designing patient-centric information displays for hospitals	Electronic medical records are increasingly comprehensive, and this vast repository of information has already contri-buted to medical efficiency and hospital procedure. However, this information is not typically accessible to patients, who are frequently under-informed and unclear about their own hospital courses. In this paper, we propose a design for in-room, patient-centric information displays, based on iterative design with physicians. We use this as the basis for a Wizard-of-Oz study in an emergency department, to assess patient and provider responses to in-room information displays. 18 patients were presented with real-time information displays based on their medical records. Semi-structured interviews with patients, family members, and hospital staff reveal that subjective response to in-room displays was overwhelmingly positive, and through these interviews we elicited guidelines regarding specific information types, privacy, use cases, and information presentation techniques. We describe these findings, and we discuss the feasibility of a fully-automatic implementation of our design.
2010	Supporting sandtray therapy on an interactive tabletop	We present the iterative design of a virtual sandtray application for a tabletop display. The purpose of our prototype is to support sandtray therapy, a form of art therapy typically used for younger clients. A significant aspect of this therapy is the insight gained by the therapist as they observe the client interact with the figurines they use to create a scene in the sandtray. In this manner, the therapist can gain increased understanding of the client's psyche. We worked with three sandtray therapists throughout the evolution of our prototype. We describe the details of the three phases of this design process: initial face-to-face meetings, iterative design and development via distance collaboration, and a final face-to-face feedback session. This process revealed that our prototype was sufficient for therapists to gain insight about a person's psyche through their interactions with the virtual sandtray.
2010	MAGIC: a motion gesture design tool	Devices capable of gestural interaction through motion sensing are increasingly becoming available to consumers; however, motion gesture control has yet to appear outside of game consoles. Interaction designers are frequently not expert in pattern recognition, which may be one reason for this lack of availability. Another issue is how to effectively test gestures to ensure that they are not unintentionally activated by a user's normal movements during everyday usage. We present MAGIC, a gesture design tool that addresses both of these issues, and detail the results of an evaluation.
2010	Protractor: a fast and accurate gesture recognizer	Protractor is a novel gesture recognizer that can be easily implemented and quickly customized for different users. Protractor uses a nearest neighbor approach, which recognizes an unknown gesture based on its similarity to each of the known gestures, e.g., training samples or examples given by a user. In particular, it employs a novel method to measure the similarity between gestures, by calculating a minimum angular distance between them with a closed-form solution. As a result, Protractor is more accurate, naturally covers more gesture variation, runs significantly faster and uses much less memory than its peers. This makes Protractor suitable for mobile computing, which is limited in processing power and memory. An evaluation on both a previously published gesture data set and a newly collected gesture data set indicates that Protractor outperforms its peers in many aspects.
2010	GesText: accelerometer-based gestural text-entry systems	Accelerometers are common on many devices, including those required for text-entry. We investigate how to enter text with devices that are solely enabled with accelerometers. The challenge of text-entry with such devices can be overcome by the careful investigation of the human limitations in gestural movements with accelerometers. Preliminary studies provide insight into two potential text-entry designs that purely use accelerometers for gesture recognition. In two experiments, we evaluate the effectiveness of each of the text-entry designs. The first experiment involves novice users over a 45 minute period while the second investigates the possible performance increases over a four day period. Our results reveal that a matrix-based text-entry system with a small set of simple gestures is the most efficient (5.4wpm) and subjectively preferred by participants.
2010	Predicting Chinese text entry speeds on mobile phones	Chinese text entry on mobile phones is critical considering the large number of Chinese speakers worldwide and as a key task in many core applications. But there is still a lack of both empirical data and predictive models that explore the pattern of user behavior in the process. We propose a model to predict user performance with two types of Chinese pinyin input methods on mobile phones. The model integrates a language model (digraph probability) with Fitts' law for key presses, a keystroke-level model for navigation, and a linear model for visual search in pinyin marks and Chinese characters. We tested the model by comparing its predictions with the empirical measures. The predictions are satisfactory and the percentage differences are all within 4\% of the empirical results, suggesting that the model can be used to evaluate user performance of Chinese pinyin text entry solutions on mobile phones.
2010	Chinese online communities: balancing managementcontrol and individual autonomy	Existing studies of online social communities mainly focus on communities in the United States. Since Chinese social beliefs and behaviors largely differ from that of Americans, we hypothesize that Chinese online communities also greatly differ from their U.S. counterparts. In particular, we believe that Chinese online communities must balance management control and individual autonomy to accommodate both Chinese tradition and the social nature of online societies. In this paper, we present three studies to test our hypothesis. First, we use a structured observation (Study I) to examine community governance practices of 32 Chinese and American social sites. Based on the identified community governance practices, we use a cross-cultural survey of 208 Chinese and Americans (Study II) to learn about their behavior and attitude toward these practices. Finally, we interview 38 Chinese users (Study III) to help us further understand how Chinese online communities balance the needs of management and users. Not only do the studies confirm our hypothesis, but they also help us abstract two key design implications of social software to meet the needs of Chinese.
2010	How socio-economic structure influences rural users' acceptance of mobile entertainment	Mobile entertainment services are rapidly and widely developing. However, in emerging markets like Chinese rural area, entertainment related services are still not fully accepted by mobile phone users. This primary research aimed to study Chinese rural people's acceptance for mobile entertainment, to provide comprehensive models, and to explain the problem from its socio-economic roots. Interview and survey data were collected. Using explorative factor analysis method, two mobile entertainment acceptance models were built: one for rural people in North China and the other in East China. The models show that "social influence" is the most influential factor for north rural users while users' "self efficacy" carries the largest weight in East China. Both factors are more important than "product and service quality". The socio-economic roots of the results were analyzed from the differences between the traditional interdependent society in North China and the more independent society in East China. It primarily reveals the possibility to predict users' technology acceptance with socio-economic variables. Implications for mobile entertainment design were discussed.
2010	Multi-touch techniques for exploring large-scale 3D astrophysical simulations	Enabling efficient exploration of large-scale virtual environments such as those simulating astrophysical environments is highly challenging. Astrophysical virtual worlds span exceptionally large spatial scales occupied mostly by empty space, and this makes it difficult for the user to comprehend the spatial context during exploratory navigation. Public exhibits, where novice users have little experience using complicated virtual navigation interfaces, pose additional challenges. To address these issues, we propose multi-touch techniques to deliver an effective interface to navigate the unique features of large-scale 3D environments such as astrophysical simulations. In this work, we carefully study conventional multi-touch methods and adapt them to the practical requirements of this application. A novel technique called the powers-of-ten ladder is introduced to support efficient movement across huge spatial scales using multi-touch interactions. We also investigate user experiences with various multi-touch finger gestures on our prototype digital planetarium.
2010	Graspables revisited: multi-touch vs. tangible input for tabletop displays in acquisition and manipulation tasks	We present an experimental comparison of multi-touch and tangible user interfaces for basic interface actions. Twelve participants completed manipulation and acquisition tasks on an interactive surface in each of three conditions: tangible user interface; multi-touch; and mouse and puck. We found that interface control objects in the tangible condition were easiest to acquire and, once acquired, were easier/more accurate to manipulate. Further qualitative analysis suggested that in the evaluated tasks tangibles offer greater adaptability of control and specifically highlighted a problem of exit error that can undermine fine-grained control in multi-touch interactions. We discuss the implications of these findings for interface design.
2010	The design and evaluation of multitouch marking menus	Despite the considerable quantity of research directed towards multitouch technologies, a set of standardized UI components have not been developed. Menu systems provide a particular challenge, as traditional GUI menus require a level of pointing precision inappropriate for direct finger input. Marking menus are a promising alternative, but have yet to be investigated or adapted for use within multitouch systems. In this paper, we first investigate the human capabilities for performing directional chording gestures, to assess the feasibility of multitouch marking menus. Based on the positive results collected from this study, and in particular, high angular accuracy, we discuss our new multitouch marking menu design, which can increase the number of items in a menu, and eliminate a level of depth. A second experiment showed that multitouch marking menus perform significantly faster than traditional hierarchal marking menus, reducing acquisition times in both novice and expert usage modalities.
2010	Multi-lifespan information system design: a research initiative for the hci community	This CHI Note proposes a new research initiative for the HCI community: multi-lifespan information system design. The central idea begins with the identification of categories of problems that are unlikely to be solved within a single human lifespan. Three such categories are proposed: limitations of the human psyche, limitations of the structure of society, and slower moving natural time-scales. We then examine possible opportunities and roles for information systems to help construct longer-term solutions to such problems and, in turn, identify key challenges for such systems. Finally, we conclude by discussing significant real world problems that would benefit from a multi-lifespan design approach and point to open questions. This CHI Note's key contribution entails the articulation of a promising new research initiative for the HCI community.
2010	Designing interactivity in media interfaces: a communications perspective	Interactivity has become ubiquitous in the digital media landscape. Numerous interactive tools are designed, tested, deployed and evaluated. Yet, we do not have generalizable knowledge about the larger concept of interactivity and its psychological impact on user experience. As a first step toward a theory of interface interactivity, this paper identifies three species of interactivity corresponding to three central elements of communication - source, medium, and message. Interactivity situated in any of these three loci of communication can provide cues and affordances that operate either individually or together to capture users' attention and determine the nature and depth of their processing of online content as well as contribute to their perceptions, attitudes and behavioral intentions. This paper discusses psychological mechanisms by which the three classes of interactivity tools affect users, with the specific purpose of drawing out design implications and outlining UI challenges for strategic development of interactive interfaces.
2010	Designing with interactive example galleries	Designers often use examples for inspiration; examples offer contextualized instances of how form and content integrate. Can interactive example galleries bring this practice to everyday users doing design work, and does working with examples help the designs they create? This paper explores whether people can realize significant value from explicit mechanisms for designing by example modification. We present the results of three studies, finding that independent raters prefer designs created with the aid of examples, that examples may benefit novices more than experienced designers, that users prefer adaptively selected examples to random ones, and that users make use of multiple examples when creating new designs. To enable these studies and demonstrate how software tools can facilitate designing with examples, we introduce interface techniques for browsing and borrowing from a corpus of examples, manifest in the Adaptive Ideas Web design tool. Adaptive Ideas leverages a faceted metadata interface for viewing and navigating example galleries.
2010	Worlds of information: designing for engagement at a public multi-touch display	In designing for engagement at a public multi-touch installation, we identified supporting multiple users and allowing for gradual discovery as challenges. In this paper, we present Worlds of Information , a multi-touch application featuring 3D Worlds , which provide access to different content. These 3D widgets gradually unfold and allow for temporal navigation of multimedia in parallel, while also providing a 2D plane where media can be shared. We report on a field trial at an exhibition using questionnaires and video ethnography. We studied engagement through questions adapted from Flow, Presence and Intrinsic Motivation questionnaires, which showed that users, overall, had a positive and social experience with the installation. The worlds effectively invited multiple users and provided for parallel interaction. While functionality was discovered gradually through social learning, the study demonstrates the challenges of designing multi-touch applications for walk-up-and-use displays.
2010	Designing urban media façades: cases and challenges	Media façades comprise a category of urban computing concerned with the integration of displays into the built environment, including buildings and street furniture. This paper identifies and discusses eight challenges faced when designing urban media façades. The challenges concern a broad range of issues: interfaces, physical integration, robustness, content, stakeholders, situation, social relations, and emerging use. The challenges reflect the fact that the urban setting as a domain for interaction design is characterized by a number of circumstances and socio-cultural practices that differ from those of other domains. In order to exemplify the challenges and discuss how they may be addressed, we draw on our experiences from five experimental design cases, ranging from a 180 m2 interactive building façade to displays integrated into bus shelters.
2010	Touch projector: mobile interaction through video	In 1992, Tani et al. proposed remotely operating machines in a factory by manipulating a live video image on a computer screen. In this paper we revisit this metaphor and investigate its suitability for mobile use. We present Touch Projector, a system that enables users to interact with remote screens through a live video image on their mobile device. The handheld device tracks itself with respect to the surrounding displays. Touch on the video image is "projected" onto the target display in view, as if it had occurred there. This literal adaptation of Tani's idea, however, fails because handheld video does not offer enough stability and control to enable precise manipulation. We address this with a series of improvements, including zooming and freezing the video image. In a user study, participants selected targets and dragged targets between displays using the literal and three improved versions. We found that participants achieved highest performance with automatic zooming and temporary image freezing.
2010	High accuracy position and orientation detection in two-dimensional communication network	In this paper we describe a method of high accuracy device position and orientation detection for HCI environments. Our position and orientation detection is an additional function to the Two-Dimensional Communication technology, which enables devices placed on a thin sheet to achieve two key functions for ubiquitous computing, to communicate one another and to receive electricity through the sheet wirelessly. This paper discusses the method developed to specify the positions and orientation of devices placed on the sheet. It evaluates the accuracy of obtained position and orientation through an experiment using a prototype of our positioning sensor.
2010	Rethinking RFID: awareness and control for interaction with RFID systems	People now routinely carry radio frequency identification (RFID) tags - in passports, driver's licenses, credit cards, and other identifying cards - from which nearby RFID readers can access privacy-sensitive information. The problem is that people are often unaware of security and privacy risks associated with RFID, likely because the technology remains largely invisible and uncontrollable for the individual. To mitigate this problem, we introduce a collection of novel yet simple and inexpensive tag designs. Our tags provide reader awareness, where people get visual, audible, or tactile feedback as tags come into the range of RFID readers. Our tags also provide information control, where people can allow or disallow access to the information stored on the tag by how they touch, orient, move, press or illuminate the tag.
2010	SensorTune: a mobile auditory interface for DIY wireless sensor networks	Wireless Sensor Networks (WSNs) allow the monitoring of activity or environmental conditions over a large area, from homes to industrial plants, from agriculture fields to forests and glaciers. They can support a variety of applications, from assisted living to natural disaster prevention. WSNs can, however, be challenging to setup and maintain, reducing the potential for real-world adoption. To address this limitation, this paper introduces SensorTune, a novel mobile interface to support non-expert users in iteratively setting up a WSN. SensorTune uses non-speech audio to present to its users information regarding the connectivity of the network they are setting up, allowing them to decide how to extend it. To simplify the interpretation of the data presented, the system adopts the metaphor of tuning a consumer analog radio, a very common and well known operation. A user study was conducted in which 20 subjects setup real multi-hop networks inside a large building using a limited number of wireless nodes. Subjects repeated the task with SensorTune and with a comparable mobile GUI interface. Experimental results show a statistically significant difference in the task completion time and a clear preference of users for the auditory interface.
2010	API usability peer reviews: a method for evaluating the usability of application programming interfaces	We describe a usability inspection method to evaluate Application Programming Interfaces (APIs). We found the method useful as it identified usability defects in Microsoft's .NET Framework, of which 59\% were new and 21\% were fixed. Based on a comparison of usability defects identified between API usability peer reviews and API usability tests, API usability tests were found to expose design issues related to actually using an API whereas API usability peer reviews were found to expose the design rationale of an API. We reflect on the efficiency and productivity of each method: each API usability test is equivalent to 16 API usability peer reviews with the former having a 2.5x productivity advantage. We discuss how API usability peer reviews can be used in conjunction with API usability tests to increase usability coverage on APIs.
2010	Understanding usability practices in complex domains	Although usability methods are widely used for evaluating conventional graphical user interfaces and websites, there is a growing concern that current approaches are inadequate for evaluating complex, domain-specific tools. We interviewed 21 experienced usability professionals, including in-house experts, external consultants, and managers working in a variety of complex domains, and uncovered the challenges commonly posed by domain complexity and how practitioners work around them. We found that despite the best efforts by usability professionals to get familiar with complex domains on their own, the lack of formal domain expertise can be a significant hurdle for carrying out effective usability evaluations. Partnerships with domain experts lead to effective results as long as domain experts are willing to be an integral part of the usability team. These findings suggest that for achieving usability in complex domains, some fundamental educational changes may be needed in the training of usability professionals.
2010	Average task times in usability tests: what to report?	The distribution of task time data in usability studies is positively skewed. Practitioners who are aware of this positive skew tend to report the sample median. Monte Carlo simulations using data from 61 large-sample usability tasks showed that the sample median is a biased estimate of the population median. Using the geometric mean to estimate the center of the population will, on average, have 13\% less error and 22\% less bias than the sample median. Other estimates of the population center (trimmed, harmonic and Winsorized means) had worse performance than the sample median.
2010	Designing a technological playground: a field study of the emergence of play in household messaging	We present findings from a field study of Wayve, a situated messaging device for the home that incorporates handwriting and photography. Wayve was used by 24 households (some of whom were existing social networks of family and friends) over a three-month period. We consider the various types of playfulness that emerged during the study, both through the sending of Wayve messages and through the local display of photos and notes. The findings are explored in the context of the literature on play, with the aim of identifying aspects of Wayve's design, as well as the context in which it was used, that engendered playfulness. We also highlight the role of play in social relationships, before concluding with design implications.
2010	The family window: the design and evaluation of a domestic media space	Families have a strong need to connect with their loved ones over distance. However, most technologies do not provide the same feelings of connectedness that one feels from seeing remote family members. Hence our goal was to understand if a video connection, in the form of a media space, could help families feel more connected and what design factors would be critical for its success. To answer this, we designed a video media space called the Family Window and deployed it within the homes of two families for eight months and four families for five weeks. Our results show that always-on video can lead to an increase in feelings of connectedness by providing availability awareness and opportunities for sharing everyday life. However usage and value of such media spaces hinges on close-knit relationships and control over one's autonomy.
2010	FM radio: family interplay with sonic mementos	Digital mementos are increasingly problematic, as people acquire large amounts of digital belongings that are hard to access and often forgotten. Based on fieldwork with 10 families, we designed a new type of embodied digital memento, the FM Radio. It allows families to access and play sonic mementos of their previous holidays. We describe our underlying design motivation where recordings are presented as a series of channels on an old fashioned radio. User feedback suggests that the device met our design goals: being playful and intriguing, easy to use and social. It facilitated family interaction, and allowed ready access to mementos, thus sharing many of the properties of physical mementos that we intended to trigger.
2010	Think-aloud protocols: a comparison of three think-aloud protocols for use in testing data-dissemination web sites for usability	We describe an empirical, between-subjects study on the use of think-aloud protocols in usability testing of a federal data-dissemination Web site. This double-blind study used three different types of think-aloud protocols: a traditional protocol, a speech-communication protocol, and a coaching protocol. A silent condition served as the control. Eighty participants were recruited and randomly pre-assigned to one of four conditions. Accuracy and efficiency measures were collected, and participants rated their subjective satisfaction with the site. Results show that accuracy is significantly higher in the coaching condition than in the other conditions. The traditional protocol and the speech-communication protocol are not statistically different from each other with regard to accuracy. Participants in the coaching condition are more satisfied with the Web site than participants in the traditional or speech-communication condition. In addition, there are no significant differences with respect to efficiency (time-on-task). This paper concludes with recommendations for usability practitioners.
2010	Powerful and consistent analysis of likert-type ratingscales	Likert-type scales are used extensively during usability evaluations, and more generally evaluations of interactive experiences, to obtain quantified data regarding attitudes, behaviors, and judgments of participants. Very often this data is analyzed using parametric statistics like the Student t -test or ANOVAs. These methods are chosen to ensure higher statistical power of the test (which is necessary in this field of research and practice where sample sizes are often small), or because of the lack of software to handle multi-factorial designs nonparametrically. With this paper we present to the HCI audience new developments from the field of medical statistics that enable analyzing multiple factor designs nonparametrically. We demonstrate the necessity of this approach by showing the errors in the parametric treatment of nonparametric data in experiments of the size typically reported in HCI research. We also provide a practical resource for researchers and practitioners who wish to use these new methods.
2010	Measuring the user experience on a large scale: user-centered metrics for web applications	More and more products and services are being deployed on the web, and this presents new challenges and opportunities for measurement of user experience on a large scale. There is a strong need for user-centered metrics for web applications, which can be used to measure progress towards key goals, and drive product decisions. In this note, we describe the HEART framework for user-centered metrics, as well as a process for mapping product goals to metrics. We include practical examples of how HEART metrics have helped product teams make decisions that are both data-driven and user-centered. The framework and process have generalized to enough of our company's own products that we are confident that teams in other organizations will be able to reuse or adapt them. We also hope to encourage more research into metrics based on large-scale behavioral data.
2010	Are your participants gaming the system?: screening mechanical turk workers	In this paper we discuss a screening process used in conjunction with a survey administered via Amazon.com's Mechanical Turk. We sought an easily implementable method to disqualify those people who participate but don't take the study tasks seriously. By using two previously pilot tested screening questions, we identified 764 of 1,962 people who did not answer conscientiously. Young men seem to be most likely to fail the qualification task. Those that are professionals, students, and non-workers seem to be more likely to take the task seriously than financial workers, hourly workers, and other workers. Men over 30 and women were more likely to answer seriously.
2010	Trained to accept?: a field experiment on consent dialogs	A typical consent dialog was shown in 2 x 2 x 3 experimental variations to 80,000 users of an online privacy tool. We find that polite requests and button texts pointing to a voluntary decision decrease the probability of consent---in contrast to findings in social psychology. Our data suggests that subtle positive effects of polite requests indeed exist, but stronger negative effects of heuristic processing dominate the aggregated results. Participants seem to be habituated to coercive interception dialogs---presumably due to ubiquitous EULAs---and blindly accept terms the more their presentation resembles a EULA. Response latency and consultation of online help were taken as indicators to distinguish more systematic from heuristic responses.
2010	Spyn: augmenting the creative and communicative potential of craft	We present data collected from a field study of 12 needle-crafters introduced to Spyn-mobile phone software that associates digital records (audio/visual media, text, and geographic data) with locations on fabric. We observed leisure needle-crafters use Spyn to create one or more handmade garments over two to four weeks and then give those garments to friends, partners, and family members. Using Spyn, creators left behind digital and physical traces that heightened recipients' appreciation for the gift and enabled a diverse set of meanings to emerge. Digital engagements with Spyn became a means for unraveling the value of the gift: recipients used digital information associated with the physical objects to interpret the story behind the objects and their creators. We discuss the nature of this relationship between digital and physical material and its implications for craft.
2010	Toque: designing a cooking-based programming language for and with children	An intergenerational design team of children (ages 7-11 years old) along with graduate students and faculty in computer science and information studies developed a programming language for children, Toque . Concrete real-world cooking scenarios were used as programming metaphors to support an accessible programming learning experience. The Wiimote and Nunchuk were used as physical programming input devices. The programs that were created were pictorial recipes which dynamically controlled animations of an on-screen chef preparing virtual dishes in a graphical kitchen environment. Through multiple design sessions, programming strategies were explored, cooking metaphors were developed and, prototypes of the Toque environment were iterated. Results of these design experiences have shown us the importance of pair-programming, programming by storytelling, parallel programming, function-argument relationships, and the role of tangibility in overcoming challenges with constraints imposed by the system design.
2010	Cooking with robots: designing a household system working in open environments	We propose a cooking system that operates in an open environment. The system cooks a meal by pouring various ingredients into a boiling pot on an induction heating cooker and adjusts the heating strength according to the user's instructions. We then describe how the system incorporates robotic- and human-specific elements in a shared workspace so as to achieve a cooperative rudimentary cooking capability. First, we use small mobile robots instead of built-in arms to save space, improve flexibility and increase safety. Second, we use detachable visual markers to allow the user to easily configure the real-world environment. Third, we provide a graphical user interface to display detailed cooking instructions to the user. We hope insights obtained in this experiment will be useful for the design of other household systems in the future.
2010	LensMouse: augmenting the mouse with an interactive touch display	We introduce LensMouse, a novel device that embeds a touch-screen display -- or tangible 'lens' -- onto a mouse. Users interact with the display of the mouse using direct touch, whilst also performing regular cursor-based mouse interactions. We demonstrate some of the unique capabili-ties of such a device, in particular for interacting with auxil-iary windows, such as toolbars, palettes, pop-ups and dia-log-boxes. By migrating these windows onto LensMouse, challenges such as screen real-estate use and window man-agement can be alleviated. In a controlled experiment, we evaluate the effectiveness of LensMouse in reducing cursor movements for interacting with auxiliary windows. We also consider the concerns involving the view separation that results from introducing such a display-based device. Our results reveal that overall users are more effective with LenseMouse than with auxiliary application windows that are managed either in single or dual-monitor setups. We conclude by presenting other application scenarios that LensMouse could support.
2010	Pacer: fine-grained interactive paper via camera-touch hybrid gestures on a cell phone	PACER is a gesture-based interactive paper system that supports fine-grained paper document content manipulation through the touch screen of a cameraphone. Using the phone's camera, PACER links a paper document to its digital version based on visual features. It adopts camera-based phone motion detection for embodied gestures (e.g. marquees, underlines and lassos), with which users can flexibly select and interact with document details (e.g. individual words, symbols and pixels). The touch input is incorporated to facilitate target selection at fine granularity, and to address some limitations of the embodied interaction, such as hand jitter and low input sampling rate. This hybrid interaction is coupled with other techniques such as semi-real time document tracking and loose physical-digital document registration, offering a gesture-based command system. We demonstrate the use of PACER in various scenarios including work-related reading, maps and music score playing. A preliminary user study on the design has produced encouraging user feedback, and suggested future research for better understanding of embodied vs. touch interaction and one vs. two handed interaction.
2010	MouseLight: bimanual interactions on digital paper using a pen and a spatially-aware mobile projector	MouseLight is a spatially-aware standalone mobile projector with the form factor of a mouse that can be used in combination with digital pens on paper. By interacting with the projector and the pen bimanually, users can visualize and modify the virtually augmented contents on top of the paper, and seamlessly transition between virtual and physical information. We present a high fidelity hardware prototype of the system and demonstrate a set of novel interactions specifically tailored to the unique properties of MouseLight. MouseLight differentiates itself from related systems such as PenLight in two aspects. First, MouseLight presents a rich set of bimanual interactions inspired by the ToolGlass interaction metaphor, but applied to physical paper. Secondly, our system explores novel displaced interactions , that take advantage of the independent input and output that is spatially aware of the underneath paper. These properties enable users to issue remote commands such as copy and paste or search. We also report on a preliminary evaluation of the system which produced encouraging observations and feedback.
2010	How routine learners can support family coordination	Researchers have detailed the importance of routines in how people live and work, while also cautioning system designers about the importance of people's idiosyncratic behavior patterns and the challenges they would present to learning systems. We wish to take up their challenge, and offer a vision of how simple sensing technology could capture and model idiosyncratic routines, enabling applications to solve many real world problems. To identify how a simple routine learner can demonstrate this in support of family coordination, we conducted six months of nightly interviews with six families, focusing on how they make and execute plans. Our data reveals that only about 40\% of events unfold in a routine manner. When deviations do occur, family members often need but do not have access to accurate information about their routines. With about 90\% of their content concerning deviations, not routines, families do not rely on calendars to support them during these moments. We discuss how coordination tools, like calendars and reminder systems, would improve coordination and reduce stress when augmented with routine information, and how commercial mobile phones can support the automatic creation of routine models.
2010	The design and evaluation of an end-user-deployable, whole house, contactless power consumption sensor	We present the design, development, and evaluation of an end-user installable, whole house power consumption sensing system capable of gathering accurate real-time power use that does not require installing a current transformer around the electrical feeds in a home. Rather, our sensor system offers contactless operation by simply placing it on the outside of the breaker panel in a home. Although there are a number of existing commercial systems for gathering energy use in a home, almost none can easily and safely be installed by a homeowner (especially for homes in the U.S.). Our approach leverages advances in magnetoresistive materials and circuit design to allow contactless operation by reliably sensing the magnetic field induced by the 60 Hz current and a closed loop circuit allows us to precisely infer the power consumption in real-time. The contribution of this work is an enabling technology for researchers in the fields of Ubiquitous Computing and Human-Computer Interaction wanting to conduct practical large-scale deployments of end-user-deployable energy monitoring applications. We discuss the technical details, the iterative design, and end-user evaluations of our sensing approach.
2010	InPhase: evaluation of a communication system focused on happy coincidences of daily behaviors	To supplement existing forms of communication such as telephone and e-mail, this research proposes a new method of communicating "awareness" between people who are separated by long distances. In this paper, we investigate cases where coincidences in daily activities lead to casual conversation and thus intimacy and togetherness. We propose a new method of communicating these "happy coincidences" between a pair of remotely located locations. By equipping furniture and appliances such as doors, sofas, refrigerators and televisions with sensors, we developed a system wherein these items are connected to remote equivalents and their near simultaneous use is communicated. We conducted a two month field test of the system in a laboratory setting and a three month field test in an actual home. The study showed that the participant felt the presence of other people and thought about, imagined or even confirmed the habits of others by intentionally triggering the coincidence notification.
2010	O job can you return my mojo: improving human engagement and enjoyment in routine activities	Unlike machines, we humans are prone to boredom when we perform routine activities for long periods of time. Workers' mental engagement in boring tasks diminishes, which eventually, compromises their performance. The result is a double-whammy because the workers do not get job satisfaction and their employers do not receive optimal return on investment. This paper proposes a novel way for improving workers' mental engagement and hence, enjoyment, in routine activities. Specifically, we propose to blend in routine tasks mild mental/physical challenges. To test our hypothesis, we chose to experiment on a monitoring task typical of security guard operations. We combined this routine task with an iPhone-based game to make it more enjoyable. The results from 10 participants show that their mental engagement and enjoyment were significantly higher during the combined task.
2010	Identifying drivers and hindrances of social user experience in web services	Social activity is becoming a central contributor to user experience (UX) in many modern Web services. The motivations, norms and rules of online communities have been widely researched, however, social activity and its UX in modern Web services is a less studied area. We conducted a four-week-long field study with three Web services -- Facebook, Nokia Sports Tracker and Dopplr -- which all support social activity. The aim of this study was to identify the central drivers and hindrances of social UX, user experience of online social activity. Our results show that the main drivers of social UX include self-expression, reciprocity, learning and curiosity , whereas unsuitability of content and functionality, incompleteness of user networks and lack of trust and privacy are often experienced as hindrances for social UX. Our findings also reveal the pragmatic and hedonic nature of the drivers and hindrances. The results can be used to inform design and evaluation of social UX in Web services.
2010	Code bubbles: a working set-based interface for code understanding and maintenance	Developers spend significant time reading and navigating code fragments spread across multiple locations. The file-based nature of contemporary IDEs makes it prohibitively difficult to create and maintain a simultaneous view of such fragments. We propose a novel user interface metaphor for code understanding based on collections of lightweight, editable fragments called bubbles, which form concurrently visible working sets. We present the results of a qualitative usability evaluation, and the results of a quantitative study which indicates Code Bubbles significantly improved code understanding time, while reducing navigation interactions over a widely-used IDE, for two controlled tasks.
2010	How to support designers in getting hold of the immaterial material of software	When designing novel GUI controls, interaction designers are challenged by the "immaterial" materiality of the digital domain; they lack tools that effectively support a reflecting conversation with the material of software as they attempt to conceive, refine, and communicate their ideas. To investigate this situation, we conducted two participatory design workshops. In the first workshop, focused on conceiving, we observed that designers want to invent controls by exploring gestures, context, and examples. In the second workshop, on refining and communicating, designers proposed tools that could refine movement, document context through usage scenarios, and support the use of examples. In this workshop they struggled to effectively communicate their ideas for developers because their ideas had not been fully explored. In reflecting on this struggle, we began to see an opportunity for the output of a design tool to be a boundary object that would allow for an ongoing conversation between the design and the material of software, in which the developer acts as a mediator for software.
2010	Enhancing web page readability for non-native readers	Readers face many obstacles on today's Web, including distracting content competing for the user's attention and other factors interfering with comfortable reading. On today's primarily English-language Web, non-native readers encounter even more problems, even if they have some fluency in English. In this paper, we focus on the presentation of content and propose a new transformation method, Jenga Format, to enhance web page readability. To evaluate the Jenga Format, we conducted a user study on 30 Asian users with moderate English fluency and the results indicated that the proposed transformation method improved reading comprehension without negatively affecting reading speed. We also describe Froggy, a Firefox extension which implements the Jenga format.
2010	Countertop responsive mirror: supporting physical retail shopping for sellers, buyers and companions	We examine opportunities for ubiquitous technologies in retail shopping, jewelry shopping in this case, to supplement the unique information needs inherent to physical trials of tactile products. We describe an iterative design approach to develop a mirror system that records and matches images across jewelry trials called the Countertop Responsive Mirror. The key technological distinction of our system from prior technologies is the use of "matched access," which automatically retrieves images that match a scene shown in separately accessed images. This not only helps shoppers compare jewelry but also promotes interactions among all parties during shopping. We report qualitative findings from multiple field trials of the system. This paper contributes to a body of research on the design and introduction of new technologies into retail shopping that provide value to all users without disruption to their normative practices and behaviors.
2010	Investigating the opportunity for a smart activity bag	As long as people have traveled, they have constructed bags to help them carry more items than their hands will hold. While quite effective at keeping things together, bags do a poor job of communicating when something is missing. We propose that there exists an opportunity for the HCI community to improve the quality of people's lives by creating bags that have knowledge of people's schedules and equipment needs, can sense their contents, and can communicate when something has been forgotten. To investigate this opportunity, we conducted a field study with six dual-income families. Through interviews and observations we investigated their experiences using bags to organize equipment needed for children's enrichment activities. Based on the findings we generated 100 concepts and conducted a needs validation session to better understand the best opportunity to improve people's lives with technical intervention. This paper reports on our field study and needs validation session, and shares insights on the opportunities and implications of a smart activity bag.
2010	A model of symbol size discrimination in scatterplots	Symbols are used in scatterplots to encode data in a way that is appropriate for perception through human visual channels. Symbol size is believed to be the second dominant channel after color. We study symbol size perception in scatterplots in the context of analytic tasks requiring size discrimination. More specifically, we performed an experiment to measure human performance in three visual analytic tasks. Circles are used as the representative symbol, with eight, linearly varying radii; 24 persons, divided across three groups, participated; and both objective and subjective measures were obtained. We propose a model to describe the results. The perception of size is assumed to be an early step in the complex cognitive process to mediate discrimination, and psychophysical laws are used to describe this perceptual mapping. Different mapping schemes are compared by regression on the experimental data. The results show that approximate homogeneity of size perception exists in our complex tasks and can be closely described by a power law transformation with an exponent of 0.4. This yields an optimal scale for symbol size discrimination.
2010	Individual models of color differentiation to improve interpretability of information visualization	Color is commonly used to represent categories and values in many computer applications, but differentiating these colors can be difficult in many situations (e.g., for users with color vision deficiency (CVD), or in bright light). Current solutions to this problem can adapt colors based on standard simulations of CVD, but these models cover only a fraction of the ways in which color perception can vary. To improve the specificity and accuracy of these approaches, we have developed the first ever individualized model of color differentiation (ICD). The model is based on a short calibration performed by a particular user for a particular display, and so automatically covers all aspects of the user's ability to see and differentiate colors in an environment. In this paper we introduce the new model and the manner in which differentiability limits are predicted. We gathered empirical data from 16 users to assess the model's accuracy and robustness. We found that the model is highly effective at capturing individual differentiation abilities, works for users with and without CVD, can be tuned to balance accuracy and color availability, and can serve as the basis for improved color adaptation schemes.
2010	Useful junk?: the effects of visual embellishment on comprehension and memorability of charts	Guidelines for designing information charts (such as bar charts) often state that the presentation should reduce or remove 'chart junk' - visual embellishments that are not essential to understanding the data. In contrast, some popular chart designers wrap the presented data in detailed and elaborate imagery, raising the questions of whether this imagery is really as detrimental to understanding as has been proposed, and whether the visual embellishment may have other benefits. To investigate these issues, we conducted an experiment that compared embellished charts with plain ones, and measured both interpretation accuracy and long-term recall. We found that people's accuracy in describing the embellished charts was no worse than for plain charts, and that their recall after a two-to-three-week gap was significantly better. Although we are cautious about recommending that all charts be produced in this style, our results question some of the premises of the minimalist approach to chart design.
2010	Intermediated technology use in developing communities	We describe a prevalent mode of information access in low-income communities of the developing world--intermediated interactions. They enable persons for whom technology is inaccessible due to non-literacy, lack of technology-operation skills, or financial constraints, to benefit from technologies through digitally skilled users--thus, expanding the reach of technologies. Reporting the results of our ethnography in two urban slums of Bangalore, India, we present three distinct intermediated interactions: inputting intent into the device in proximate enabling, interpretation of device output in proximate translation, and both input of intent and interpretation of output in surrogate usage. We present some requirements and challenges in interface design of these interactions and explain how they are different from direct interactions. We then explain the broader effects of these interactions on low-income communities, and present some implications for design.
2010	Deliberate interactions: characterizing technology use in Nairobi, Kenya	We present results from a qualitative study examining how professionals living and working in Nairobi, Kenya regularly use ICT in their everyday lives. There are two contributions of this work for the HCI community. First, we provide empirical evidence demonstrating constraints our participants encountered when using technology in an infrastructure-poor setting. These constraints are limited bandwidth, high costs, differing perceptions of responsiveness, and threats to physical and virtual security. Second, we use our findings to critically evaluate the "access, anytime and anywhere" construct shaping the design of future technologies. We present an alternative vision called deliberate interactions--a planned and purposeful interaction style that involves offline preparation and discuss ways ICT can support this online usage behavior.
2010	After access: challenges facing mobile-only internet users in the developing world	This study reports results of an ethnographic action research study, exploring mobile-centric internet use. Over the course of 13 weeks, eight women, each a member of a livelihoods collective in urban Cape Town, South Africa, received training to make use of the data (internet) features on the phones they already owned. None of the women had previous exposure to PCs or the internet. Activities focused on social networking, entertainment, information search, and, in particular, job searches. Results of the exercise reveal both the promise of, and barriers to, mobile internet use by a potentially large community of first-time, mobile-centric users. Discussion focuses on the importance of self-expression and identity management in the refinement of online and offline presences, and considers these forces relative to issues of gender and socioeconomic status.
2010	ViralVCD : tracing information-diffusion paths with low cost media in developing communities	We describe ViralVCD: a low cost method for tracing paths of information diffusion in developing communities using physical media. We instituted a participatory video framework for creation and dissemination of developmental videos in seven urban slums and peri-urban communities of Bangalore, India. By combining a call-in contest with Video CDs, we were able to measure developmental impact as well as elicit data on social networks and technology usage practices. In particular, our technique was able to extract data from multiple layers-social, technological, and developmental. ViralVCD allowed us to identify key actors and map information diffusion, as well as technology ownership and access. These findings have implications for HCI initiatives targeting low income locales and populations.
2010	Interactivity and non-interactivity on tabletops	In the growing field of tabletop computing research, there has been an understandable focus on interactive aspects of tabletop use, in terms of technology, design, and behavioural analysis. In this paper, I highlight the importance of considering also non-interactive aspects of tabletop computing and the mutually dependent relationship between interactive and non-interactive. We illustrate aspects of this relationship using findings from a deployment of an interactive tabletop in a public setting. The findings highlight how consequences of interaction can impact on non-interactive behaviours and intentions and how non-interactive actions can constrain interactive behaviours on the tabletop. In doing this we aim to raise more awareness of the relationship between interactivity and non-interactivity within tabletop computing research.
2010	Clutch-free panning and integrated pan-zoom control on touch-sensitive surfaces: the cyclostar approach	This paper introduces two novel navigation techniques, CycloPan, for clutch-free 2D panning and browsing, and CycloZoom+, for integrated 2D panning and zooming. These techniques instantiate a more generic concept which we call Cyclo* (CycloStar). The basic idea is that users can exert closed-loop control over several continuous variables by voluntarily modulating the parameters of a sustained oscillation. Touch-sensitive surfaces tend to offer impoverished input resources. Cyclo* techniques seem particularly promising on these surfaces because oscillations have multiple geometrical and kinematic parameters many of which may be used as controls. While CycloPan and CycloZoom+ are compatible with each other and with much of the state of the art, our experimental evaluations suggest that these two novel techniques outperform flicking and rubbing techniques.
2010	Touching the void: direct-touch interaction for intangible displays	In this paper, we explore the challenges in applying and investigate methodologies to improve direct-touch interaction on intangible displays. Direct-touch interaction simplifies object manipulation, because it combines the input and display into a single integrated interface. While traditional tangible display-based direct-touch technology is commonplace, similar direct-touch interaction within an intangible display paradigm presents many challenges. Given the lack of tactile feedback, direct-touch interaction on an intangible display may show poor performance even on the simplest of target acquisition tasks. In order to study this problem, we have created a prototype of an intangible display. In the initial study, we collected user discrepancy data corresponding to the interpretation of 3D location of targets shown on our intangible display. The result showed that participants performed poorly in determining the z-coordinate of the targets and were imprecise in their execution of screen touches within the system. Thirty percent of positioning operations showed errors larger than 30mm from the actual surface. This finding triggered our interest to design a second study, in which we quantified task time in the presence of visual and audio feedback. The pseudo-shadow visual feedback was shown to be helpful both in improving user performance and satisfaction.
2011	Classroom-based assistive technology: collective use of interactive visual schedules by students with autism	vSked is an interactive and collaborative assistive technology for students with autism, combining visual schedules, choice boards, and a token-based reward system into an integrated classroom system. In this paper, we present the results of a study of three deployments of vSked over the course of a year in two autism classrooms. The results of our study demonstrate that vSked can promote student independence, reduce the quantity of educator-initiated prompts, encourage consistency and predictability, reduce the time required to transition from one activity to another. The findings from this study reveal practices surrounding the use of assistive technologies in classrooms and highlight important considerations for both the design and the evaluation of assistive technologies in the future, especially those destined for classroom use.
2011	Privacy risks emerging from the adoption of innocuous wearable sensors in the mobile environment	Wearable sensors are revolutionizing healthcare and science by enabling capture of physiological, psychological, and behavioral measurements in natural environments. However, these seemingly innocuous measurements can be used to infer potentially private behaviors such as stress, conversation, smoking, drinking, illicit drug usage, and others. We conducted a study to assess how concerned people are about disclosure of a variety of behaviors and contexts that are embedded in wearable sensor data. Our results show participants are most concerned about disclosures of conversation episodes and stress - inferences that are not yet widely publicized. These concerns are mediated by temporal and physical context associated with the data and the participant's personal stake in the data. Our results provide key guidance on the extent to which people understand the potential for harm and data characteristics researchers should focus on to reduce the perceived harm from such datasets.
2011	Interaction design for cancer patients: do we need to take into account the effects of illness and medication?	In this paper we explore how having cancer and receiving therapy influences upon patients' ability to use an online healthcare system. The motivation is that no empirically based design guidelines are available concerning this user group. Ignoring possible effects of illness and therapy can result in systems with poor usability and user acceptance. A case-control usability test with 14 cancer patients and 14 matched controls revealed that the cancer patients experienced significantly more difficulties compared with the healthy controls using a web-based online healthcare system. We conclude that designers of online healthcare systems need to take into consideration the unique challenges of being ill and/or using medication.
2011	Simulating the feel of brain-computer interfaces for design, development and social interaction	We describe an approach to improving the design and development of Brain-Computer Interface (BCI) applications by simulating the error-prone characteristics and subjective feel of electroencephalogram (EEG), motor-imagery based BCIs. BCIs have the potential to enhance the quality of life of people who are severely disabled, but it is often time-consuming to test and develop the systems. Simulation of BCI characteristics allows developers to rapidly test design options, and gain both subjective and quantitative insight into expected behaviour without using an EEG cap. A further motivation for the use of simulation is that 'impairing' a person without motor disabilities in a game with a disabled BCI user can create a level playing field and help carers empathise with BCI users. We demonstrate a use of the simulator in controlling a game of Brain Pong.
2011	Characterizing patient-friendly micro-explanationsof medical events	Patients' basic understanding of clinical events has been shown to dramatically improve patient care. We propose that the automatic generation of very short micro-explanations , suitable for real-time delivery in clinical settings, can transform patient care by giving patients greater awareness of key events in their electronic medical record. We present results of a survey study indicating that it may be possible to automatically generate such explanations by extracting individual sentences from consumer-facing Web pages. We further inform future work by characterizing physician and non-physician responses to a variety of Web-extracted explanations of medical lab tests.
2011	Now, i have a body: uses and social norms for mobile remote presence in the workplace	As geographically distributed teams become increasingly common, there are more pressing demands for communication work practices and technologies that support distributed collaboration. One set of technologies that are emerging on the commercial market is mobile remote presence (MRP) systems, physically embodied videoconferencing systems that remote workers use to drive through a workplace, communicating with locals there. Our interviews, observations, and survey results from people, who had 2-18 months of MRP use, showed how remotely-controlled mobility enabled remote workers to live and work with local coworkers almost as if they were physically there. The MRP supported informal communications and connections between distributed coworkers. We also found that the mobile embodiment of the remote worker evoked orientations toward the MRP both as a person and as a machine, leading to formation of new usage norms among remote and local coworkers.
2011	Hands on hitchcock: embodied reference to a moving scene	In this paper we report on some experiments with a high fidelity media space, t-Room, an immersive system that presents full scale, real-time images of co-participants who are in similar spaces many miles apart. Although being designed to provide a coherent environment for interaction the system introduces a number of incongruities, both in time and space. Drawing on some quasi-naturalistic experiments, where the participants were required to analyse complex data, we consider how the participants manage these incongruities. We conclude by briefly discussing the resources people utilize to produce and recognize conduct in embodied spaces.
2011	Exploring camera viewpoint control models for a multi-tasking setting in teleoperation	Control of camera viewpoint plays a vital role in many teleoperation activities, as watching live video streams is still the fundamental way for operators to obtain situational awareness from remote environments. Motivated by a real-world industrial setting in mining teleoperation, we explore several possible solutions to resolve a common multi-tasking situation where an operator is required to control a robot and simultaneously perform remote camera operation. Conventional control interfaces are predominantly used in such teleoperation settings, but could overload an operator's hand-operation capability, and require frequent attention switches and thus could decrease productivity. We report on an empirical user study in a model multi-tasking teleoperation setting where the user has a main task which requires their attention. We compare three different camera viewpoint control models: (1) dual manual control, (2) natural interaction (combining eye gaze and head motion) and (3) autonomous tracking. The results indicate the advantages of using the natural interaction model, while the manual control model performed the worst.
2011	Zoom cameras and movable displays enhance social telepresence	This paper shows that the augmentation of a remote person's positional movement enhances social telepresence. There are three possible ways of representing a remote person's movement toward the user in visual communication: a) the remote person's movement toward the remote camera, b) the remote camera's zooming in to enlarge the remote person's picture, and c) a forward movement of the display that is displaying the remote person. We conducted an experiment to see the relationship among these three ways and the effects of a remote camera's zooming and a display's movement on social telepresence. In the experiment, we observed that the remote person's movement lowered the reality of conversations, and the remote camera's zooming lowered the visual quality. However, social telepresence was enhanced when both the person's movement and the camera's zooming occurred simultaneously. We also observed that a 6-centimeter movement of the display enhanced social telepresence, whether the remote person moved or not.
2011	Breath control of amusement rides	Emerging robotic technologies are enabling the control of individual seats on rollercoasters and other thrill rides. We explore the potential of breathing as an effective and engaging way of driving this. Observations and interviews from trials of an enhanced bucking bronco ride show that breath-control is fun, challenging and intelligible, and reveal riders-x tactics as they battled the machine. We conclude that breath control is feasible and appropriate for controlling rides, unpack its important characteristics, and consider how it might be built into future ride systems. We argue that the combination of voluntary and involuntary factors in breathing is especially appealing for controlling rides as it balances game-like elements of skill and learning against the thrill of surrendering control to the machine.
2011	Time characteristics of olfaction in a single breath	The transmission of olfactory information together with audiovisual information is now attracting much attention. However, the information is difficult to synchronize because of problems of scent lingering in the air and olfactory adaptation. We aimed at minimizing the amount of odorant presented to users in order to mitigate these problems, and developed an olfactory display that is able to present scents precisely. The display uses pulse ejection, whereby scents are emitted for only short periods of time. In this study, we aimed to mitigate the above-mentioned problems and to measure the time characteristics of olfaction in a single breath, which are difficult to measure by conventional methods. As a result, the most effective conditions for using a small amount of odorant in a single breath were revealed. These results are expected to ease the synchronization of olfactory and audiovisual information.
2011	Augmented reality flavors: gustatory display based on edible marker and cross-modal interaction	The main contribution of this paper is to realize computer generated augmented flavors and establish a method to integrate gustatory information into computer human interactions. There are several reasons for the scarcity of research on gustatory information. One reason is that taste sensations are affected by a number of factors, such as vision, olfaction and memories. This produces a complex cognition mechanism for a user's gustatory sensation, and makes it difficult to build up a gustatory display which produces a specific taste on demand. Our hypothesis is that the complexity of gustatory sensation can be applied to the realization of a "Pseudo-gustatory" display that presents the desired flavors by means of a cross-modal effect elicited by visual and olfactory augmented reality. We propose the Edible Marker system, which can detect the state [number/shape/6-degree-of-freedom (DOF) coordinate] of each piece of bitten or divided food in real time, and the "Pseudo-gustation" method to change the perceived taste of food by changing its appearance and scent. We construct "MetaCookie+" as an implementation and discuss its validity through an exploratory study.
2011	Biofeedback game design: using direct and indirect physiological control to enhance game interaction	Prior work on physiological game interaction has focused on dynamically adapting games using physiological sensors. In this paper, we propose a classification of direct and indirect physiological sensor input to augment traditional game control. To find out which sensors work best for which game mechanics, we conducted a mixed-methods study using different sensor mappings. Our results show participants have a preference for direct physiological control in games. This has two major design implications for physiologically controlled games: (1) Direct physiological sensors should be mapped intuitively to reflect an action in the virtual world; (2) Indirect physiological input is best used as a dramatic device in games to influence features altering the game world.
2011	Confessions from a grounded theory PhD: experiences and lessons learnt	Grounded Theory (GT) is used within HCI research, but nuances and more modern interpretations of the method are rarely discussed. This paper has two intentions: to offer guidance on practical issues when applying GT, and to clarify the space of methodological possibilities. We describe an extended GT study on understanding why practitioners choose particular usability evaluation methods. We describe five stages in this study to highlight our experiences and choices made. We draw out seven practical and methodological considerations in applying GT in a CHI context. This challenges the more traditional inductive and objective positions on GT use; it sensitizes novices of GT to these issues; and through the extended case study it provides substance for debate on issues that affect those that use qualitative methods more broadly.
2011	Reflexivity in digital anthropology	There are a variety of forms of ethnography inside and outside HCI each with valid complementary contributions. This paper looks at the practices of digital anthropology and how it contributes to reflexive design in HCI. The paper overviews key aspects its use in HCI, as well as in the anthropological approach. In doing so it relates these practices to participatory design and the socio-technical gap, and the ways ethnography can address them.
2011	Comparing activity theory with distributed cognition for video analysis: beyond kicking the tires	The field of HCI is growing, not only in the variety of application areas or the volume of research conducted, but also in the number of analytical approaches for use in the evaluation and design of interactive systems. However, despite the abundance of theoretical frameworks available, relatively little work has directly compared the application of these frameworks. This paper compares video analysis methods based on two analytic frameworks - activity theory (AT) and distributed cognition (DCog) - by performing an analysis of the same system from each of the two different theoretical perspectives. The results presented here provide a better understanding of how such theoretically informed methods in practice both resemble and differ from one another. Furthermore, this comparison enables specific insights about each of the theories themselves, as well as more general discussion about the role of theory in HCI.
2011	The aligned rank transform for nonparametric factorial analyses using only anova procedures	Nonparametric data from multi-factor experiments arise often in human-computer interaction (HCI). Examples may include error counts, Likert responses, and preference tallies. But because multiple factors are involved, common nonparametric tests ( e.g. , Friedman) are inadequate, as they are unable to examine interaction effects. While some statistical techniques exist to handle such data, these techniques are not widely available and are complex. To address these concerns, we present the Aligned Rank Transform (ART) for nonparametric factorial data analysis in HCI. The ART relies on a preprocessing step that "aligns" data before applying averaged ranks, after which point common ANOVA procedures can be used, making the ART accessible to anyone familiar with the F-test. Unlike most articles on the ART, which only address two factors, we generalize the ART to N factors. We also provide ARTool and ARTweb , desktop and Web-based programs for aligning and ranking data. Our re-examination of some published HCI results exhibits advantages of the ART.
2011	Human model evaluation in interactive supervised learning	Model evaluation plays a special role in interactive machine learning (IML) systems in which users rely on their assessment of a model's performance in order to determine how to improve it. A better understanding of what model criteria are important to users can therefore inform the design of user interfaces for model evaluation as well as the choice and design of learning algorithms. We present work studying the evaluation practices of end users interactively building supervised learning systems for real-world gesture analysis problems. We examine users' model evaluation criteria, which span conventionally relevant criteria such as accuracy and cost, as well as novel criteria such as unexpectedness. We observed that users employed evaluation techniques---including cross-validation and direct, real-time evaluation---not only to make relevant judgments of algorithms' performance and interactively improve the trained models, but also to learn to provide more effective training data. Furthermore, we observed that evaluation taught users about what types of models were easy or possible to build, and users sometimes used this information to modify the learning problem definition or their plans for using the trained models in practice. We discuss the implications of these findings with regard to the role of generalization accuracy in IML, the design of new algorithms and interfaces, and the scope of potential benefits of incorporating human interaction in the design of supervised learning systems.
2011	CueT: human-guided fast and accurate network alarm triage	Network alarm triage refers to grouping and prioritizing a stream of low-level device health information to help operators find and fix problems. Today, this process tends to be largely manual because existing tools cannot easily evolve with the network. We present CueT, a system that uses interactive machine learning to learn from the triaging decisions of operators. It then uses that learning in novel visualizations to help them quickly and accurately triage alarms. Unlike prior interactive machine learning systems, CueT handles a highly dynamic environment where the groups of interest are not known a-priori and evolve constantly. A user study with real operators and data from a large network shows that CueT significantly improves the speed and accuracy of alarm triage compared to the network's current practice.
2011	Apolo: making sense of large network data by combining rich user interaction and machine learning	Extracting useful knowledge from large network datasets has become a fundamental challenge in many domains, from scientific literature to social networks and the web. We introduce Apolo, a system that uses a mixed-initiative approach - combining visualization, rich user interaction and machine learning - to guide the user to incrementally and interactively explore large network data and make sense of it. Apolo engages the user in bottom-up sensemaking to gradually build up an understanding over time by starting small, rather than starting big and drilling down. Apolo also helps users find relevant information by specifying exemplars, and then using a machine learning method called Belief Propagation to infer which other nodes may be of interest. We evaluated Apolo with twelve participants in a between-subjects study, with the task being to find relevant new papers to update an existing survey paper. Using expert judges, participants using Apolo found significantly more relevant papers. Subjective feedback of Apolo was also very positive.
2011	Mid-air pan-and-zoom on wall-sized displays	Very-high-resolution wall-sized displays offer new opportunities for interacting with large data sets. While pointing on this type of display has been studied extensively, higher-level, more complex tasks such as pan-zoom navigation have received little attention. It thus remains unclear which techniques are best suited to perform multiscale navigation in these environments. Building upon empirical data gathered from studies of pan-and-zoom on desktop computers and studies of remote pointing, we identified three key factors for the design of mid-air pan-and-zoom techniques: uni- vs. bimanual interaction, linear vs. circular movements, and level of guidance to accomplish the gestures in mid-air. After an extensive phase of iterative design and pilot testing, we ran a controlled experiment aimed at better understanding the influence of these factors on task performance. Significant effects were obtained for all three factors: bimanual interaction, linear gestures and a high level of guidance resulted in significantly improved performance. Moreover, the interaction effects among some of the dimensions suggest possible combinations for more complex, real-world tasks.
2011	Gesture select:: acquiring remote targets on large displays without pointing	When working at a large wall display, even if partially utilized, many targets are likely to be distant from the user, requiring walking, which is slow, and interrupts workflow. We propose a novel technique for selecting remote targets called Gesture Select, in which users draw an initial mark, in a target's direction; rectilinear gestures represented as icons are dynamically overlaid on targets within a region of interest; the user then continues by drawing the continuation mark corresponding to the target, to select it. Extensions to this technique to support working with remote content for an extended period, and learning gesture shortcuts are presented. A formal experiment indicates Gesture Select significantly outperformed direct selection for mid/far targets. Further analysis suggests Gesture Select performance is principally affected by the extent to which users can read the gestures, influenced by distance and perspective warping, and the gesture complexity in the ROI. The results of a second 2-D experiment with labeled targets indicate Gesture Select significantly outperformed direct selection and an existing technique.
2011	User-defined motion gestures for mobile interaction	Modern smartphones contain sophisticated sensors to monitor three-dimensional movement of the device. These sensors permit devices to recognize motion gestures - deliberate movements of the device by end-users to invoke commands. However, little is known about best-practices in motion gesture design for the mobile computing paradigm. To address this issue, we present the results of a guessability study that elicits end-user motion gestures to invoke commands on a smartphone device. We demonstrate that consensus exists among our participants on parameters of movement and on mappings of motion gestures onto commands. We use this consensus to develop a taxonomy for motion gestures and to specify an end-user inspired motion gesture set. We highlight the implications of this work to the design of smartphone applications and hardware. Finally, we argue that our results influence best practices in design for all gestural interfaces.
2011	Gesture avatar: a technique for operating mobile user interfaces using gestures	Finger-based touch input has become a major interaction modality for mobile user interfaces. However, due to the low precision of finger input, small user interface components are often difficult to acquire and operate on a mobile device. It is even harder when the user is on the go and unable to pay close attention to the interface. In this paper, we present Gesture Avatar, a novel interaction technique that allows users to operate existing arbitrary user interfaces using gestures. It leverages the visibility of graphical user interfaces and the casual interaction of gestures. Gesture Avatar can be used to enhance a range of mobile interactions. A user study we conducted showed that compared to Shift (an alternative technique for target acquisition tasks), Gesture Avatar performed at a much lower error rate on various target sizes and significantly faster on small targets (1mm). It also showed that using Gesture Avatar while walking did not significantly impact its performance, which makes it suitable for mobile uses.
2011	Speak little and well: recommending conversations in online social streams	Conversation is a key element in online social streams such as Twitter and Facebook. However, finding interesting conversations to read is often a challenge, due to information overload and differing user preferences. In this work we explored five algorithms that recommend conversations to Twitter users, utilizing thread length, topic and tie-strength as factors. We compared the algorithms through an online user study and gathered feedback from real Twitter users. In particular, we investigated how users' purposes of using Twitter affect user preferences for different types of conversations and the performance of different algorithms. Compared to a random baseline, all algorithms recommended more interesting conversations. Further, tie-strength based algorithms performed significantly better for people who use Twitter for social purposes than for people who use Twitter for informational purpose only.
2011	Twitinfo: aggregating and visualizing microblogs for event exploration	Microblogs are a tremendous repository of user-generated content about world events. However, for people trying to understand events by querying services like Twitter, a chronological log of posts makes it very difficult to get a detailed understanding of an event. In this paper, we present TwitInfo, a system for visualizing and summarizing events on Twitter. TwitInfo allows users to browse a large collection of tweets using a timeline-based display that highlights peaks of high tweet activity. A novel streaming algorithm automatically discovers these peaks and labels them meaningfully using text from the tweets. Users can drill down to subevents, and explore further via geolocation, sentiment, and popular URLs. We contribute a recall-normalized aggregate sentiment visualization to produce more honest sentiment overviews. An evaluation of the system revealed that users were able to reconstruct meaningful summaries of events in a small amount of time. An interview with a Pulitzer Prize-winning journalist suggested that the system would be especially useful for understanding a long-running event and for identifying eyewitnesses. Quantitatively, our system can identify 80-100\% of manually labeled peaks, facilitating a relatively complete view of each event studied.
2011	Tweets from Justin Bieber's heart: the dynamics of the location field in user profiles	Little research exists on one of the most common, oldest, and most utilized forms of online social geographic information: the 'location' field found in most virtual community user profiles. We performed the first in-depth study of user behavior with regard to the location field in Twitter user profiles. We found that 34\% of users did not provide real location information, frequently incorporating fake locations or sarcastic comments that can fool traditional geographic information tools. When users did input their location, they almost never specified it at a scale any more detailed than their city. In order to determine whether or not natural user behaviors have a real effect on the 'locatability' of users, we performed a simple machine learning experiment to determine whether we can identify a user's location by only looking at what that user tweets. We found that a user's country and state can in fact be determined easily with decent accuracy, indicating that users implicitly reveal location information, with or without realizing it. Implications for location-based services and privacy are discussed.
2011	An open, social microcalender for the enterprise: timely?	We present the system design and rational for a novel social microcalendar called Timely. Our system has been inspired by previous research on calendaring and popular social network applications, in particular microblogging. Timely provides an open, social space for enterprise users to share their events, socialize, and discover what else is going on in their network and beyond. A detailed analysis of the events shared by users during the site's first 47 days reveals that users willingly share their time commitments despite an existing culture of restricted calendars.
2011	Pleasure is your birthright: digitally enabled designer sex toys as a case of third-wave HCI	In the past decade, HCI has become increasingly preoccupied with the deeply subjective qualities of interaction: experience, embodiment, pleasure, intimacy, and so on, an agenda sometimes grouped under the heading of "third-wave HCI"."Analytically understanding and designing for such qualities has been an ongoing challenge to the field, in part because its established theories and methodologies are comparatively weak at understanding and being responsive to human subjectivity. In this paper, we present a case study of a group of designers who have, in the past few years, revolutionized their domain - sex toys - by combining embodied pleasure, intimate experience, health and wellness, emerging technologies, high-quality design processes, and social activism. We consider the implications this case could have for researchers innovating on especially third-wave HCI design theories, methodologies, and processes.
2011	Designing a phone broadcasting system for urban sex workers in India	In this paper, we present the design, implementation, and deployment of a phone-based broadcasting system designed for reaching out to at-risk populations in urban India. We worked in collaboration with Pragati, a non-governmental organization dedicated to assisting Urban Sex Workers (USWs) in Bangalore, India, with the goal of improving Pragati's outreach to the women they serve. We conducted ethnographic action research to understand and address the needs of Pragati and the lifestyles of USWs. Responding to the unique design constraints of the USW community such as specific privacy and timing constraints, a desire to remain invisible, and the unusually high rate of mobile phone use, we designed a phone-based broadcasting system for Pragati. We then deployed the system on four different occasions and application areas. We present the results and key findings from our study, and conclude with a discussion on how designing for particularly difficult cases such as USWs can shed new light on the design of mobile applications for the developing world in general, such as challenging ubiquity and phone numbers as identity.
2011	Bodily orientations around mobiles: lessons learnt in vanuatu	Since we started carrying mobiles phones, they have altered the ways in which we orient our bodies in the world. Many of those changes are invisible to us - they have become habits, deeply engrained in our society. To make us more aware of our bodily ways of living with mobiles and open the design space for novel ways of designing mobiles and their interactions, we decided to study one of the last groups of users on earth who had not been exposed to mobiles: the people of Vanuatu. As they had so recently started using mobiles, their use was still in flux: the fragility of the mobile was unusual to them as was the need to move in order to find coverage. They were still getting used to carrying their mobiles and keeping them safe. Their encounters with mobile use exposed the need to consider somaesthetics practices when designing mobiles as they profoundly affect our bodily ways of being in the world.
2011	We want more: human-computer collaboration in mobile social video remixing of music concerts	Recording and publishing mobile video clips from music concerts is popular. There is a high potential to increase the concert's perceived value when producing video remixes from individual video clips and using them socially. A digital production of a video remix is an interactive process between human and computer. However, it is not clear what the collaboration implications between human and computer are. We present a case study where we compare the processes and products of manual and automatic mobile video remixing. We provide results from the first systematic real world study of the subject. We draw our observations from a user trial where fans recorded mobile video clips during a rock concert. The results reveal issues on heterogeneous interests of the stakeholders, unexpected uses of the raw material, the burden of editing, diverse quality requirements, motivations for remixing, the effect of understanding the logic of automation, and the collaborative use of manual and automatic remixing.
2011	Knowing funny: genre perception and categorization in social video sharing	Categorization of online videos is often treated as a tag suggestion task; tags can be generated by individuals or by machine classification. In this paper, we suggest categorization can be determined socially, based on people's interactions around media content without recourse to metadata that are intrinsic to the media object itself. This work bridges the gap between the human perception of genre and automatic categorization of genre in classifying online videos. We present findings from two internet surveys and from follow-up interviews where we address how people determine genre classification for videos and how social framing of video content can alter the perception and categorization of that content. From these findings, we train a Naive Bayes classifier to predict genre categories. The trained classifier achieved 82\% accuracy using only social action data, without the use of content or media-specific metadata. We conclude with implications on how we categorize and organize media online as well as what our findings mean for designing and building future tools and interaction experiences.
2011	Real-time nonverbal opinion sharing through mobile phones during sports events	Even with the rise of the World Wide Web, TV has remained the most pervasive entertainment medium and is nowadays often used together with other media, which allow for active participation. The idea of connecting non-collocated TV viewers via telecommunication technologies, referred to as Social TV, has recently received considerable attention. Such systems typically include set-top boxes for supporting collaboration. In this research we investigate if real-time opinion sharing about TV shows through a nonverbal (non-textual) iconic UI on mobile phones is reasonable. For this purpose we developed a mobile app, made it available to a large number of users through the Android Market, and conducted an uncontrolled user study in the wild during the soccer world cup 2010. The results of the study indicate that TV viewers who used the app had more fun and felt more connected to other viewers. We also show that by monitoring this channel it is possible to collect sentiments relevant to the broadcasted content in real-time. The collected data exemplify that the aggregated sentiments correspond to important moments, and hence can be used to generate a summary of the event.
2011	Are we in sync?: synchronization requirements for watching online video together.	Synchronization between locations is an important factor for enabling remote shared experiences. Still, experimental data on what is the acceptable synchronization level is scarce. This paper discusses the synchronization requirements for watching online videos together - a popular set of services that recreate the shared experience of watching TV together by offering tools to communicate while watching. It studies the noticeability and annoyance of synchronization differences of the video being watched, as well as the impact on users' feelings of togetherness, both for voice chat and text chat. Results of an experiment with 36 participants show that when using voice chat, users notice synchronization differences sooner, are more annoyed and feel more together than when using text chat. However, users with high text chat activity notice synchronization differences similar to participants using voice chat.
2011	Designing for peer involvement in weight management	The problems of obesity and overweight are commonly cited as the motivation behind recent efforts to develop technology that promotes physical activity. Prompted by the social nature of many of the emerging applications, this paper presents our investigation of the sociality of weight management as experienced by a broad demographic of individuals. Our findings highlight the broad scope of peer involvement, and provide insight into the context and mechanics of related interaction that may prove valuable in informing the next generation of peer-based weight management technology for use in everyday life.
2011	Mining behavioral economics to design persuasive technology for healthy choices	Influence through information and feedback has been one of the main approaches of persuasive technology. We propose another approach based on behavioral economics research on decision-making. This approach involves designing the presentation and timing of choices to encourage people to make self-beneficial decisions. We applied three behavioral economics persuasion techniques - the default option strategy, the planning strategy, and the asymmetric choice strategy - to promote healthy snacking in the workplace. We tested the strategies in three experimental case studies using a human snack deliverer, a robot, and a snack ordering website. The default and the planning strategies were effective, but they worked differently depending on whether the participants had healthy dietary lifestyles or not. We discuss designs for persuasive technologies that apply behavioral economics.
2011	Means based adaptive persuasive systems	Large differences in individual responses to persuasive strategies suggest the need for systems that rely on persuasion profiles: estimates of an individual user's susceptibility to different persuasive strategies. Establishing an empirical ground supporting decisions regarding user involvement can provide valuable guidelines for the design of such systems. We describe two studies examining the effects of choice, disclosure, and multiple strategy usage on user compliance to persuasive attempts. We show that involving users in the selection of a specific influence strategy can increase compliance, while disclosing the persuasive intent can reduce compliance. Furthermore, we demonstrate that it is not only feasible, but optimal to choose the single correct influence strategy for a given context; even more so than implementing multiple relevant and congruent influence attempts.
2011	Side effects and gateway tools: advocating a broader look at evaluating persuasive systems	This paper argues for evaluating the impact of persuasive systems on users beyond metrics that focus on system usage, based on an interview study of 16 Wii Fit users. While exploring their experiences and reasons for abandoning the system, two main themes emerged: the tension between Wii Fit as a fitness tool and a game, and ways participants reacted to the system's feedback about their weight and performance. Some participants used Wii Fit as a "gateway fitness" tool, moving beyond it to other fitness routines. Additionally, some users had significant emotional reactions to the Wii Fitts feedback. We argue that these 'side effects' are crucial considerations for the design and long-term evaluation of persuasive technologies.
2011	I will do it, but i don't like it: user reactions to preference-inconsistent recommendations	Recommender systems have their origin in e-commerce. In this domain the users are meant to like the recommended information. This preference-consistency is not adequate or even desirable for all domains where recommender systems are implemented. One key issue for opinion formation and informed decision making is to be aware of more than one's own perspective. However, information search is often biased, because confirming information is favored over opposing information. Therefore it would be useful to recommend information that is inconsistent to users' prior perspective to help overcome this bias. The present paper deals with an online experiment aimed at investigating the effects of preference-consistent compared to preference-inconsistent recommendations on information selection and evaluation. Results showed a significant reduction of confirmation bias in the condition with preference-inconsistent recommendations. However, participants prefer preference-consistent recommendations in terms of global, cognitive and affective evaluations. We discuss the impact of these findings for application.
2011	Embodiment in brain-computer interaction	With emerging opportunities for using Brain-Computer Interaction (BCI) in gaming applications, there is a need to understand the opportunities and constraints of this interaction paradigm. To complement existing laboratory-based studies, there is also a call for the study of BCI in real world contexts. In this paper we present such a real world study of a simple BCI game called MindFlex®, played as a social activity in the home. In particular, drawing on the philosophical traditions of embodied interaction, we highlight the importance of considering the body in BCI and not simply what is going on in the head. The study shows how people use bodily actions to facilitate control of brain activity but also to make their actions and intentions visible to, and interpretable by, others playing and watching the game. It is the public availability of these bodily actions during BCI that allows action to be socially organised, understood and coordinated with others and through which social relationships can be played out. We discuss the implications of this perspective and findings for BCI.
2011	Now where was I?: physiologically-triggered bookmarking	This work explores a novel interaction paradigm driven by implicit, low-attention user control, accomplished by monitoring a user's physiological state. We have designed and prototyped this interaction for a first use case of bookmarking an audio stream, to holistically explore the implicit interaction concept. Here, a user's galvanic skin conductance (GSR) is monitored for orienting responses (ORs) to external interruptions; our prototype automatically bookmarks the media such that the user can attend to the interruption, then resume listening from the point he/she is interrupted. To test this approach's viability, we addressed questions such as: does GSR exhibit a detectable response to interruptions, and how should the interaction utilize this information? In evaluating this system in a controlled environment, we found an OR detection accuracy of 84\%; users provided subjective feedback on its accuracy and utility.
2011	This is your brain on interfaces: enhancing usability testing with functional near-infrared spectroscopy	This project represents a first step towards bridging the gap between HCI and cognition research. Using functional near-infrared spectroscopy (fNIRS), we introduce tech-niques to non-invasively measure a range of cognitive workload states that have implications to HCI research, most directly usability testing. We present a set of usability experiments that illustrates how fNIRS brain measurement provides information about the cognitive demands placed on computer users by different interface designs.
2011	Sensing cognitive multitasking for a brain-based adaptive user interface	Multitasking has become an integral part of work environments, even though people are not well-equipped cognitively to handle numerous concurrent tasks effectively. Systems that support such multitasking may produce better performance and less frustration. However, without understanding the user's internal processes, it is difficult to determine optimal strategies for adapting interfaces, since all multitasking activity is not identical. We describe two experiments leading toward a system that detects cognitive multitasking processes and uses this information as input to an adaptive interface. Using functional near-infrared spectroscopy sensors, we differentiate four cognitive multitasking processes. These states cannot readily be distinguished using behavioral measures such as response time, accuracy, keystrokes or screen contents. We then present our human-robot system as a proof-of-concept that uses real-time cognitive state information as input and adapts in response. This prototype system serves as a platform to study interfaces that enable better task switching, interruption management, and multitasking.
2011	RemoteTouch: touch-screen-like interaction in the tv viewing environment	We explored the possibility of touch-screen-like interaction with a remote control in the TV-viewing environment. A shadow representing the user's thumb touches the screen, presses a button, flicks a cover-flow list, and draws a simple stroke, while the thumb stays and moves on and above the touchpad. In order to implement the concept we developed an optical touchpad for tracking the thumb hovering over its surface, and designed a TV application to demonstrate possible new interaction styles. Throughout two iterations of prototyping, we corrected some of our false expectations, and also verified its potential as a viable option for a TV remote control. This paper presents technical issues and requirements for the hover-tracking touchpad and a complete report of our user studies to explore touch-screen-like interaction for the TV.
2011	Experimental analysis of touch-screen gesture designs in mobile environments	Direct-touch interaction on mobile phones revolves around screens that compete for visual attention with users' real-world tasks and activities. This paper investigates the impact of these situational impairments on touch-screen interaction. We probe several design factors for touch-screen gestures, under various levels of environmental demands on attention, in comparison to the status-quo approach of soft buttons. We find that in the presence of environmental distractions, gestures can offer significant performance gains and reduced attentional load, while performing as well as soft buttons when the user's attention is focused on the phone. In fact, the speed and accuracy of bezel gestures did not appear to be significantly affected by environment, and some gestures could be articulated eyes-free, with one hand. Bezel-initiated gestures offered the fastest performance, and mark-based gestures were the most accurate. Bezel-initiated marks therefore may offer a promising approach for mobile touch-screen interaction that is less demanding of the user's attention.
2011	Usable gestures for blind people: understanding preference and performance	Despite growing awareness of the accessibility issues surrounding touch screen use by blind people, designers still face challenges when creating accessible touch screen interfaces. One major stumbling block is a lack of understanding about how blind people actually use touch screens. We conducted two user studies that compared how blind people and sighted people use touch screen gestures. First, we conducted a gesture elicitation study in which 10 blind and 10 sighted people invented gestures to perform common computing tasks on a tablet PC. We found that blind people have different gesture preferences than sighted people, including preferences for edge-based gestures and gestures that involve tapping virtual keys on a keyboard. Second, we conducted a performance study in which the same participants performed a set of reference gestures. We found significant differences in the speed, size, and shape of gestures performed by blind people versus those performed by sighted people. Our results suggest new design guidelines for accessible touch screen interfaces.
2011	Fit4life: the design of a persuasive technology promoting healthy behavior and ideal weight	This is a critical design paper offering a possible scenario of use intended to provoke reflection about values and politics of design in persuasive computing. We describe the design of a system - Fit4Life - that encourages individuals to address the larger goal of reducing obesity in society by promoting individual healthy behaviors. Using the Persuasive Systems Design Model [26], this paper outlines the Fit4Life persuasion context, the technology, its use of persuasive messages, and an experimental design to test the system's efficacy. We also contribute a novel discussion of the ethical and sociocultural considerations involved in our design, an issue that has remained largely unaddressed in the existing persuasive technologies literature [29].
2011	Many bills: engaging citizens through visualizations of congressional legislation	US federal legislation is a common subject of discussion and advocacy on the web, inspired by the open government movement. While the contents of these bills are freely available for download, understanding them is a significant challenge to experts and average citizens alike due to their length, complex language, and obscure topics. To make these important documents more accessible to the general public, we present Many Bills (http://manybills.us): a web-based set of visualization tools that reveals the underlying semantics of a bill. Using machine learning techniques, we classify each bill's sections based on existing document-level categories. We then visualize the resulting topic substructure of these bills. These visualizations provide an overview-and-detail view of bills, enabling users to read individual sections of a bill and compare topic patterns across multiple bills. Through an overview of the site's user activity and interviews with active users, this paper highlights how Many Bills makes the tasks of reading bills, identifying outlier sections in bills, and understanding congressperson's legislative activity more manageable.
2011	HCI for peace: a call for constructive action	Peace is an important value for the human-computer interaction research community, yet it has not resulted in the development of a research sub-community or even a research agenda. In this paper we seek to address this void by first motivating the need for computing research on promoting peace and preventing war. We then review evidence on the factors that affect the likelihood that armed conflict will occur, as well as the aspects involved when individuals make moral decisions on whether or not to support a war. Based on this review, we propose a research agenda, citing research examples from the human-computer interaction literature and discussing new ideas.
2011	Evaluating a pattern-based visual support approach for humanitarian landmine clearance	Unexploded landmines have severe post-conflict humanitarian repercussions: landmines cost lives, limbs and land. For deminers engaged in humanitarian landmine clearance, metal detectors remain the primary detection tool as more sophisticated technologies fail to get adopted due to restrictive cost, low reliability, and limited robustness. Metal detectors are, however, of limited effectiveness, as modern landmines contain only minimal amounts of metal, making them difficult to distinguish from the ubiquitous but harmless metallic clutter littering post-combat areas. We seek to improve the safety and efficiency of the demining process by developing support tools that will enable deminers to make better decisions using feedback from existing metal detectors. To this end, in this paper we propose and evaluate a novel, pattern-based visual support approach inspired by the documented strategies employed by expert deminers. In our laboratory study, participants provided with a prototype of our support tool were 80\% less likely to mistake a mine for harmless clutter. A follow-up study demonstrates the potential of our pattern-based approach to enable peer decision-making support during landmine clearance. Lastly, we identify several design opportunities for further improving deminers' decision making capabilities.
2011	Hang on a sec!: effects of proactive mediation of phone conversations while driving	Conversing on cell phones while driving is a risky, yet commonplace activity. State legislatures in the U.S. have enacted rules that limit hand-held phone conversations while driving but that allow for hands-free conversations. However, studies have demonstrated that the cognitive load of conversation is a significant source of distraction that increases the likelihood of accidents. We explore in a controlled study with a driving simulator the effectiveness of proactive alerting and mediation of communications during phone conversations while driving. We study the use of auditory messages indicating upcoming critical road conditions and placing calls on hold. We found that such actions reduce driving errors and that alerts sharing details about situations were more effective than general alerts. Drivers found such a system valuable in most situations for maintaining driving safety. These results provide evidence that context-sensitive mediation systems could play a valuable role in focusing drivers' attention on the road during phone conversations.
2011	Fast or safe?: how performance objectives determine modality output choices while interacting on the move	In-car devices that use audio output have been shown to be less distracting than traditional graphical user interfaces, but can be cumbersome and slow to use. In this paper, we report an experiment that demonstrates how these performance characteristics impact whether people will elect to use an audio interface in a multitasking situation. While steering a simulated vehicle, participants had to locate a source of information in a short passage of text. The text was presented either on a visual interface, or using a text-to-speech audio interface. The relative importance of each task was varied. A no-choice/choice paradigm was used in which participants first gained experience with each of the two interfaces, before being given a choice on which interface to use on later trials. The characteristics of the interaction with the interfaces, as measured in the no-choice phase, and the relative importance of each task, had an impact on which output modality was chosen in the choice phase. Participants that prioritized the secondary task tended to select the (faster yet more distracting) visual interface over the audio interface, and as a result had poorer lane keeping performance. This work demonstrates how a user's task objective will influence modality choices with multimodal devices in multitask environments.
2011	Gestural interaction on the steering wheel: reducing the visual demand	Cars offer an increasing number of infotainment systems as well as comfort functions that can be controlled by the driver. In our research, we investigate new interaction techniques that aim to make it easier to interact with these systems while driving. We suggest utilizing the steering wheel as an additional interaction surface. In this paper, we present two user studies conducted with a working prototype of a multi-touch steering wheel. In the first, we developed a user-defined steering wheel gesture set, and in the second, we applied the identified gestures and compared their application to conventional user interaction with infotainment systems in terms of driver distraction. The main outcome was that driver's visual demand is reduced significantly by using gestural interaction on the multi-touch steering wheel.
2011	Usability of car dashboard displays for elder drivers	The elder population is rising worldwide; in the US, no longer being able to drive is a significant marker of loss of independence. One of the approaches to helping elders drive more safely is to investigate the use of automotive user interface technology, and specifically, to explore the instrument panel (IP) display design to help attract and manage attention and make information easier to interpret. In this paper, we explore the premise that dashboard displays can be better designed to support elder drivers, their information needs, and their cognitive capabilities. We conducted a study to understand which display design features are critically linked to issues of divided attention and driving performance. We found that contrast of size and reduced clutter are instrumental in enhancing driving performance, particularly for the elder population. Surprisingly, our results showed that color elements have a negative effect on driving performance for elders, while color elements and fills slightly improve performance. We conclude with design implications generated from this work.
2011	Synchronous interaction among hundreds: an evaluation of a conference in an avatar-based virtual environment	This paper presents the first in-depth evaluation of a large multi-format virtual conference. The conference took place in an avatar-based 3D virtual world with spatialized audio, and had keynote, poster and social sessions. We studied it by drawing on logs, a survey and interviews with 30 participants. We develop a model - Coalescence, Focused Interaction, Remixing (CoFIRe) -- of large synchronous interactions, and use it to discuss how the technology supported, or failed to support, the interactions that are the raison d'etre of conferences. We conclude by discussing the prospects for such large virtual gatherings.
2011	What did i miss?: in-meeting review using multimodal accelerated instant replay (air) conferencing	People sometimes miss small parts of meetings and need to quickly catch up without disrupting the rest of the meeting. We developed an Accelerated Instant Replay (AIR) Conferencing system for videoconferencing that enables users to catch up on missed content while the meeting is ongoing. AIR can replay parts of the conference using four different modalities: audio, video, conversation transcript, and shared workspace. We performed two studies to evaluate the system. The first study explored the benefit of AIR catch-up during a live meeting. The results showed that when the full videoconference was reviewed (i.e., all four modalities) at an accelerated rate, users were able to correctly recall a similar amount of information as when listening live. To better understand the benefit of full review, a follow-up study more closely examined the benefits of each of the individual modalities. The results show that users (a) preferred using audio along with any other modality to using audio alone, (b) were most confident and performed best when audio was reviewed with all other modalities, (c) compared to audio-only, had better recall of facts and explanations when reviewing audio together with the shared workspace and transcript modalities, respectively, and (d) performed similarly with audio-only and audio with video review.
2011	MOGCLASS: evaluation of a collaborative system of mobile devices for classroom music education of young children	Composition, listening, and performance are essential activities in classroom music education, yet conventional music classes impose unnecessary limitations on students' ability to develop these skills. Based on in-depth fieldwork and a user-centered design approach, we created MOGCLASS, a multimodal collaborative music environment that enhances students' musical experience and improves teachers' management of the classroom. We conducted a two-round system evaluation to improve the prototype and evaluate the system: Improvements were made based on the results from an iterative design evaluation, in which a trial system was implemented. The system then underwent a second round of evaluation through a three-week between-subject controlled experiment in a local primary school. Results showed that MOGCLASS is effective in motivating students to learn music, improving the way they collaborate with other students as well as helping teachers manage the classroom.
2011	Buzzing to play: lessons learned from an in the wild study of real-time vibrotactile feedback	Vibrotactile feedback offers much potential for facilitating and accelerating how people learn sensory-motor skills that typically take hundreds of hours to learn, such as learning to play a musical instrument, skiing or swimming. However, there is little evidence of this benefit materializing outside of research lab settings. We describe the findings of an in-the-wild study that explored how to integrate vibrotactile feedback into a real-world teaching setting. The focus of the study was on exploring how children of different ages, learning to play the violin, can use real-time vibrotactile feedback. Many of the findings were unexpected, showing how students and their teachers appropriated the technology in creative ways. We present some 'lessons learned' that are also applicable to other training settings, emphasizing the need to understand how vibrotactile feedback can switch between being foregrounded and backgrounded depending on the demands of the task, the teacher's role in making it work and when feedback is most relevant and useful. Finally, we discuss how vibrotactile feedback can provide a new language for talking about the skill being learned that may also play an instrumental role in enhancing learning.
2011	PossessedHand: techniques for controlling human hands using electrical muscles stimuli	If a device can control human hands, the device can be useful for HCI and tangible application's output. To aid the controlling of finger movement, we present PossessedHand, a device with a forearm belt that can inform when and which fingers should be moved. PossessedHand controls the user's fingers by applying electrical stimulus to the muscles around the forearm. Each muscle is stimulated via 28 electrode pads. Muscles at different depths in the forearm can be selected for simulation by varying the stimulation level. PossessedHand can automatically calibrate the system for individuals. The automatic calibration system estimates relations between each electrode pad, stimulation level and muscle movement. Experiments show that PossessedHand can control the motion of 16 joints in the hand. Further, we also discuss an application based on this device to aid in playing a musical instrument.
2011	Design interventions for open-air museums: applying and extending the principles of 'assembly'	This paper presents an empirical approach to designing and deploying technologies to support visitor activities in exhibition spaces. Specifically, we focus on the concept of "assembly" and how it was extended and applied to develop an interactive installation for an open-air museum. We argue that this approach to designing for a meaningful visitor experience is particularly suited to open-air visit scenarios; we describe how we have extended the approach and applied it, detailing the resulting multi-device installation that was deployed on site, and presenting some reflections on the usefulness of the assembly concept.
2011	MoBoogie: creative expression through whole body musical interaction	In this paper we describe MoBoogie, an application that allows users to manipulate and arrange music through movement. MoBoogie is designed to foster experiences in creative expression for children and potentially adults. The application responds to users' movements by changing variables in a continuous stream of music loops. Results from this study suggest that the creative expressions arose in the joint space of movement and music, and did not primarily have to be in one form or the other. This allowed users with limited experience in dance and music making to be creative in such forms of expression.
2011	Life modes in social media	Current social media products such as Facebook and Twitter have not sufficiently addressed how to help users organize people and content streams across different areas of their lives. We conducted a qualitative design research study to explore how we might best leverage natural models of social organization to improve experiences of social media. We found that participants organize their social worlds based on life 'modes', i.e., family, work and social. They strategically use communication technologies to manage intimacy levels within these modes, and levels of permeability through the boundaries between these modes. Mobile communication in particular enabled participants to aggregate and share content dynamically across life modes. While exploring problems with managing their social media streams, people showed a strong need for focused sharing - the ability to share content only with appropriate audiences within certain areas of life.
2011	Social capital on facebook: differentiating uses and users	Though social network site use is often treated as a monolithic activity, in which all time is equally social and its impact the same for all users, we examine how Facebook affects social capital depending upon: (1) types of site activities, contrasting one-on-one communication, broadcasts to wider audiences, and passive consumption of social news, and (2) individual differences among users, including social communication skill and self-esteem. Longitudinal surveys matched to server logs from 415 Facebook users reveal that receiving messages from friends is associated with increases in bridging social capital, but that other uses are not. However, using the site to passively consume news assists those with lower social fluency draw value from their connections. The results inform site designers seeking to increase social connectedness and the value of those connections.
2011	Farmer's tale: a facebook game to promote volunteerism	Volunteering is an important activity that brings great benefits to societies. However, encouraging volunteerism is difficult due to the altruistic nature of volunteer activities and the high resource demand in carrying them out. We have created a Facebook game called "Farmer's Tale" to attract and make it easier for people to volunteer. We evaluated people's acceptance to this novel idea and the results revealed great potential in such type of games.
2011	Identifying social capital in the facebook interface	A number of studies have identified a robust relationship between the use of social network sites, particularly Facebook, and positive outcomes such as social capital. Social network site use is often measured as a function of use frequency, network size, and a range of subjective opinions about the value of the site. This research extends this understanding by exploring the relationship between the use of particular elements of the site and social capital. Our goal in this research is to identify where, in the interface, perceived social capital is most effectively produced and transmitted. We find that, as hypothesized, public, person-to-person communication is positively associated with perceived social capital. Through the use of a structural equation model, we are able to provide in-depth exploration of the relationship between the interface elements and the outcome, perceived social capital.
2011	Competing online viewpoints and models of chronic illness	People with chronic health problems use online resources to understand and manage their condition, but many such resources can present competing and confusing viewpoints. We surveyed and interviewed with people experiencing prolonged symptoms after a Lyme disease diagnosis. We explore how competing viewpoints in online content affect participants' understanding of their disease. Our results illustrate how chronically ill people search for information and support, and work to help others over time. Participant identity and beliefs about their illness evolved, and this led many to take on new roles, creating content and advising others who were sick. What we learned about online content creation suggests a need for designs that support this journey and engage with complex issues surrounding online health resources.
2011	Using interface cues in online health community boards to change impressions and encourage user contribution	Online health message boards have become popular, as users not only gain information from other users but also share their own experiences. However, as with most venues of user-generated content, there is need to constantly make quality evaluations as one sifts through enormous amounts of content. Can interface cues, conveying (1) pedigree of users posting content and (2) popularity of the posted content, help new users efficiently make credibility assessments? Furthermore, can the assignment of these same cues to their own posts serve to motivate content generation on their part? These questions were investigated in a 2-session between-subjects experiment (N = 99) with a prototype of a message-board that experimentally varied interface cues, and found that popularity indicators are more influential than pedigree indicators for both evaluation of existing content and contribution of new content. Findings also suggest theoretical mechanisms - involving such concepts as perceived authority, bandwagon effects, sense of agency and sense of community - by which cues affect user experience, providing rich implications for designing and deploying interface cues.
2011	ACES: promoting empathy towards aphasia through language distortion emulation software	Individuals with aphasia, an acquired communication disorder, constantly struggle against a world that does not understand them. This lack of empathy and understanding negatively impacts their quality of life. While aphasic individuals may appear to have lost cognitive functioning, their impairment relates to receptive and expressive language, not to thinking processes. We introduce a novel system and model, Aphasia Characteristics Emulation Software (ACES), enabling users (e.g., caregivers, speech therapists and family) to experience, firsthand, the communication-distorting effects of aphasia. By allowing neurologically typical individuals to "walk in another's shoes," we aim to increase patience, awareness and understanding. ACES was grounded in the communication science and psychological literature, and informed by an initial pilot study. Results from an evaluation of 64 participants indicate that ACES provides a rich experience that increases understanding and empathy for aphasia.
2011	Cueing for drooling in Parkinson's disease	We present the development of a socially acceptable cueing device for drooling in Parkinson's disease (PD). Sialorrhea, or drooling, is a significant problem associated with PD and has a strong negative emotional impact on those who experience it. Previous studies have shown the potential for managing drooling by using a cueing device. However, the devices used in these studies were deemed unacceptable by their users due to factors such as hearing impairment and social embarrassment. We conducted exploratory scoping work and high fidelity iterative prototyping with people with PD to get their input on the design of a cueing aid and this has given us an insight into challenges that confront users with PD and limit device usability and acceptability. The key finding from working with people with PD was the need for the device to be socially acceptable.
2011	Evaluating swabbing: a touchscreen input method for elderly users with tremor	Elderly users suffering from hand tremor have difficulties interacting with touchscreens because of finger oscillation. It has been previously observed that sliding one's finger across the screen may help reduce this oscillation. In this work, we empirically confirm this advantage by (1) measuring finger oscillation during different actions and (2) comparing error rate and user satisfaction between traditional tapping and swabbing in which the user slides his finger towards a target on a screen edge to select it. We found that oscillation is generally reduced during sliding. Also, compared to tapping, swabbing resulted in improved error rates and user satisfaction. We believe that swabbing will make touchscreens more accessible to senior users with tremor.
2011	Direct manipulation through surrogate objects	Direct manipulation has had major influence on interface design since it was proposed by Shneiderman in 1982. Although directness generally benefits users, direct manipulation also has weaknesses. In some cases, such as when a user needs to manipulate small, attribute-rich objects or multiple objects simultaneously, indirect manipulation may be more efficient at the cost of directness or intuitiveness of the interaction. Several techniques have been developed over the years to address these issues, but these are all isolated and limited efforts with no coherent underlying principle. We propose the notion of Surrogate Interaction that ties together a large subset of these techniques through the use of a surrogate object that allow users to interact with the surrogate instead of the domain object. We believe that formalizing this family of interaction techniques will provide an additional and powerful interface design alternative for interaction designers, as well as uncover opportunities for future research.
2011	An actuated physical puppet as an input device for controlling a digital manikin	We present an actuated handheld puppet system for controlling the posture of a virtual character. Physical puppet devices have been used in the past to intuitively control character posture. In our research, an actuator is added to each joint of such an input device to provide physical feedback to the user. This enhancement offers many benefits. First, the user can upload pre-defined postures to the device to save time. Second, the system is capable of dynamically adjusting joint stiffness to counteract gravity, while allowing control to be maintained with relatively little force. Third, the system supports natural human body behaviors, such as whole-body reaching and joint coupling. This paper describes the user interface and implementation of the proposed technique and reports the results of expert evaluation. We also conducted two user studies to evaluate the effectiveness of our method.
2011	Roboshop: multi-layered sketching interface for robot housework assignment and management	As various home robots come into homes, the need for efficient robot task management tools is arising. Current tools are designed for controlling individual robots independently, so they are not ideally suitable for assigning coordinated action among multiple robots. To address this problem, we developed a management tool for home robots with a graphical editing interface. The user assigns instructions by selecting a tool from a toolbox and sketching on a bird's-eye view of the environment. Layering supports the management of multiple tasks in the same room. Layered graphical representation gives a quick overview of and access to rich information tied to the physical environment. This paper describes the prototype system and reports on our evaluation of the system.
2011	Examining the impact of collaborative tagging on sensemaking in nutrition management	Collaborative tagging mechanisms are integral to social computing applications in a variety of domains. Their expected benefits include simplified retrieval of digital content, as well as enhanced ability of a community to makes sense of the shared content. We examine the impact of collaborative tagging in context of nutrition management. In a controlled experiment we asked individuals to assess the nutritional value of meals based on photographic images and observed the impact of different types of tags and tagging mechanisms on individuals nutritional sensemaking. The results of the study show that tags enhance individuals' ability to remember the viewed meals. However, we found that some types of tags can be detrimental to sensemaking, rather than supporting it. These findings stress the importance of tagging vocabularies and suggest a need for expert moderation of community sensemaking.
2011	Using tags to encourage reflection and annotation on data during nomadic inquiry	Nomadic inquiry may benefit from tagging when used for educational purposes to support reflection and annotation during data collection. To that end we created Zydeco, a mobile system to scaffold learners through the science inquiry process in and out of the classroom, and tested it in a museum with 42 middle school students. Students report that tags encouraged reflection and annotation during data collection, suggesting that tagging can be used to support nomadic inquiry. From this work we present some emerging design recommendations for constructing similar systems.
2011	User perceptions of the role and value of tags	This study investigates user ideas about the role and value of tags in social media. An analysis of 45 interviews with heavy Web users reveals that user perceptions of tags differ from common assumptions held by researchers and designers of social tagging systems. Among beliefs held by participants were that tags were query suggestions or links to other pages, sites, or advertisements - although most identified tags as categories or keywords - and that tags were generated automatically by the computer system. Several participants believed that tags were intended for not only other users but also systems such as search engines. Our findings indicate that Web users, including those who are taggers themselves, experience a high level of uncertainty and confusion about the nature, purpose and value of tags.
2011	Towards a feminist HCI methodology: social science, feminism, and HCI	With substantial efforts in ubiquitous computing, ICT4D, and sustainable interaction design, among others, HCI is increasingly engaging with matters of social change that go beyond the immediate qualities of interaction. In doing so, HCI takes on scientific and moral concerns. This paper explores the potential for feminist social science to contribute to and potentially benefit from HCI's rising interest in social change. It describes how feminist contributions to debates in the philosophy of science have helped clarify relationships among objectivity, values, data collection and interpretation, and social consequences. Feminists have proposed and implemented strategies to pursue scientific and moral agendas together and with equal rigor. In this paper, we assess the epistemologies, methodologies, and methods of feminist social science relative to prior and ongoing research efforts in HCI. We conclude by proposing an outline of a feminist HCI methodology.
2011	Out there	"Out there" is increasingly becoming a topic of concern in HCI. Thanks to various clarion calls, researchers in the field are turning their attention to technology-mediated activities that are shaped less by Euro-American sensibilities and defined more by how they are culturally and geographically distinct. Fieldwork and ethnography researchers, for instance, are beginning to investigate ICT use at religious and spiritual sites, by the socially excluded and disenfranchised, and by people in developing regions. In this paper, I concentrate on the latter focus on development to reflect on HCI's disciplinary turn "out there". Specifically, I take the following three themes as common rhetorical devices in such work: (i) the network, (ii) difference and (iii) complexity. Through examples, I discuss how each of these themes has been mobilised. I then use materials from anthropology, science and technology studies, and to a lesser extent geography and postcolonial studies to complicate and in some cases question the interpretative frames that are being applied. Thus, my hope is that this paper is seen as a thought piece that deepens our thinking around HCI's efforts to look "out there" by paying critical attention to what is going on "in here".
2011	How HCI talks about sexuality: discursive strategies, blind spots, and opportunities for future research	The topic of sexuality has been increasingly researched inside the field of HCI. At the same time, and for many reasons, research gaps remain. In this paper, we present a critical analysis of 70 works on this topic spanning the past two decades to understand how we as an academic field talk about sexuality. We use Foucauldian discourse analysis to identify and analyze the various rules of knowledge production on this topic inside our field. By doing so, we expose not only existing gaps in current research literature, but we also gain an understanding of why some of them exist. We suggest some opportunities to make the field more amenable to this kind of research and point out future research directions on sexuality inside the field of HCI.
2011	In the shadow of misperception: assistive technology use and social interactions	Few research studies focus on how the use of assistive technologies is affected by social interaction among people. We present an interview study of 20 individuals to determine how assistive technology use is affected by social and professional contexts and interactions. We found that specific assistive devices sometimes marked their users as having disabilities; that functional access took priority over feeling self-conscious when using assistive technologies; and that two misperceptions pervaded assistive technology use: (1) that assistive devices could functionally eliminate a disability, and (2) that people with disabilities would be helpless without their devices. Our findings provide further evidence that accessibility should be built into mainstream technologies. When this is not feasible, assistive devices should incorporate cutting edge technologies and strive to be designed for social acceptability, a new design approach we propose here.
2011	Identifying emotional states using keystroke dynamics	The ability to recognize emotions is an important part of building intelligent computers. Emotionally-aware systems would have a rich context from which to make appropriate decisions about how to interact with the user or adapt their system response. There are two main problems with current system approaches for identifying emotions that limit their applicability: they can be invasive and can require costly equipment. Our solution is to determine user emotion by analyzing the rhythm of their typing patterns on a standard keyboard. We conducted a field study where we collected participants' keystrokes and their emotional states via self-reports. From this data, we extracted keystroke features, and created classifiers for 15 emotional states. Our top results include 2-level classifiers for confidence, hesitance, nervousness, relaxation, sadness, and tiredness with accuracies ranging from 77 to 88\%. In addition, we show promise for anger and excitement, with accuracies of 84\%.
2011	PAM: a photographic affect meter for frequent, in situ measurement of affect	The assessment of emotion, or affect, is critical for anyone trying to understand human behavior. But there is a problem: affect as a state is frequently changing and difficult to recall and express, yet in research, we typically only assess it via a single questionnaire at the end of a study. This work presents PAM, the Photographic Affect Meter, a novel tool for measuring affect in which users select from a wide variety of photos the one which best suits their current mood. Our findings indicate that PAM-which takes seconds to complete and is designed to run on modern mobile phones and mobile computing devices-demonstrates strong construct validity across two studies and is very well suited for frequent sampling in context. This work provides a tool to researchers in need of frequent assessment of affect and guidance to others interested in developing similar measurement tools.
2011	Affective computational priming and creativity	While studies have shown that affect influences creativity, few investigate how affect influences creative performance with creativity support tools. Drawing from methods commonly used in psychology research, we present affective computational priming, a new method for manipulating affect using digitally embedded stimuli. We present two studies that explore computational techniques for inducing positive, neutral, and negative affect and examine their impact on idea generation with creativity support tools. Our results suggest that positive affective computational priming positively influences the quality of ideas generated. We discuss opportunities for future HCI research and offer practical applications of affective computational priming.
2011	Upset now?: emotion contagion in distributed groups	The importance of emotion to group outcomes in FtF highlights the need to understand emotion contagion in distributed groups. The present study examines the transfer of negative emotion in online groups. Negative emotion was induced in one of three group members completing a task in CMC. The data suggest that emotion contagion took place at the group level, with partners experiencing more negative emotion, more disagreement, higher verbosity, and use of more complex language in induced groups compared to control groups. Induced groups also performed better on the group task, raising questions about the effects of negative emotion contagion in online groups.
2011	Emotion regulation for frustrating driving contexts	Driving is a challenging task because of the physical, attentional, and emotional demands. When drivers become frustrated by events their negative emotional state can escalate dangerously. This study examines behavioral and attitudinal effects of cognitively reframing frustrating events. Participants (N = 36) were asked to navigate a challenging driving course that included frustrating events such as long lights and being cut-off. Drivers were randomly assigned to three conditions. After encountering a frustrating event, drivers in a reappraisal-down condition heard voice prompts that reappraised the event in an effort to deflate negative reactions. Drivers in the second group, reappraisal-up, heard voice prompts that brought attention to the negative actions of vehicles and pedestrians. Drivers in a silent condition drove without hearing any voice prompts. Participants in the reappraisal-down condition had better driving behavior and reported less negative emotions than participants in the other conditions.
2011	Introverted elves & conscientious gnomes: the expression of personality in world of warcraft	Personality inference can be used for dynamic personalization of content or system customization. In this study, we examined whether and how personality is expressed in Virtual Worlds (VWs). Survey data from 1,040 World of Warcraft players containing demographic and personality variables was paired with their VW behavioral metrics over a four-month period. Many behavioral cues in VWs were found to be related to personality. For example, Extraverts prefer group activities over solo activities. We also found that these behavioral indicators can be used to infer a player's personality.
2011	Starcraft from the stands: understanding the game spectator	Video games are primarily designed for the players. However, video game spectating is also a popular activity, boosted by the rise of online video sites and major gaming tournaments. In this paper, we focus on the spectator, who is emerging as an important stakeholder in video games. Our study focuses on Starcraft, a popular real-time strategy game with millions of spectators and high level tournament play. We have collected over a hundred stories of the Starcraft spectator from online sources, aiming for as diverse a group as possible. We make three contributions using this data: i) we find nine personas in the data that tell us who the spectators are and why they spectate; ii) we strive to understand how different stakeholders, like commentators, players, crowds, and game designers, affect the spectator experience; and iii) we infer from the spectators' expressions what makes the game entertaining to watch, forming a theory of distinct types of information asymmetry that create suspense for the spectator. One design implication derived from these findings is that, rather than presenting as much information to the spectator as possible, it is more important for the stakeholders to be able to decide how and when they uncover that information.
2011	Do men heal more when in drag?: conflicting identity cues between user and avatar	Studies in the Proteus Effect have shown that users conform to stereotypes associated with their avatar's appearance. In this study, we used longitudinal behavioral data from 1,040 users in a virtual world to examine the behavioral outcome of conflicting gender cues between user and avatar. We found that virtual gender had a significant effect on in-game behaviors for both healing and player-vs-player activity.
2011	Is the media equation a flash in the pan?: the durability and longevity of social responses to computers	Research on social responses to computers often assesses only first-impression reactions during a single experimental session, providing limited knowledge about the lasting effect of the results. In this work, we assess the lasting strength of social desirability bias effects on an interface designed to track exercise, manipulated to have high or low personalization (text vs. anthropomorphic conversational character). After 40 days of daily interactions by 25 participants, we found that self-reported exercise was more accurate when reported to the character vs. text. We also find that, for both conditions, participants' decision to initiate a session is greater when they have done more exercise. Moreover, we show that this effect significantly increases over time for participants in the character condition, and decreases for participants in the text condition. This study demonstrates that Media Equation effects can grow stronger or weaker over time, depending upon the presentation of the interface.
2011	What drives customization?: control or identity?	Customization - an attribute that lets users take control and make changes to the presentation and functionality of the interface - is becoming a hallmark of today's interactive media devices. What do users experience when they change interface aspects like fonts and colors, skins on mobile phones, speed dial numbers, privacy settings on social networks and different command menus in software? Do they feel in control? Do they see the customized interface as a reflection of who they are? More importantly, is the feeling of being in control a major driver of usage, or does sense of identity - a personal connection with the interface - prove more vital? This paper discusses the psychology of customization, reports an empirical user study designed to explore the relationship between customization, sense of control, and sense of identity, and outlines implications for design of customizable interfaces based on the findings.
2011	Your noise is my command: sensing gestures using the body as an antenna	Touch sensing and computer vision have made human-computer interaction possible in environments where keyboards, mice, or other handheld implements are not available or desirable. However, the high cost of instrumenting environments limits the ubiquity of these technologies, particularly in home scenarios where cost constraints dominate installation decisions. Fortunately, home environments frequently offer a signal that is unique to locations and objects within the home: electromagnetic noise. In this work, we use the body as a receiving antenna and leverage this noise for gestural interaction. We demonstrate that it is possible to robustly recognize touched locations on an uninstrumented home wall using no specialized sensors. We conduct a series of experiments to explore the capabilities that this new sensing modality may offer. Specifically, we show robust classification of gestures such as the position of discrete touches around light switches, the particular light switch being touched, which appliances are touched, differentiation between hands, as well as continuous proximity of hand to the switch, among others. We close by discussing opportunities, limitations, and future work.
2011	Sensor synaesthesia: touch in motion, and motion in touch	We explore techniques for hand-held devices that leverage the multimodal combination of touch and motion. Hybrid touch + motion gestures exhibit interaction properties that combine the strengths of multi-touch with those of motion-sensing. This affords touch-enhanced motion gestures, such as one-handed zooming by holding one's thumb on the screen while tilting a device. We also consider the reverse perspective, that of motion-enhanced touch, which uses motion sensors to probe what happens underneath the surface of touch. Touching the screen induces secondary accelerations and angular velocities in the sensors. For example, our prototype uses motion sensors to distinguish gently swiping a finger on the screen from 'Sdrags with a hard onset' - to enable more expressive touch interactions.
2011	Data miming: inferring spatial object descriptions from human gesture	Speakers often use hand gestures when talking about or describing physical objects. Such gesture is particularly useful when the speaker is conveying distinctions of shape that are difficult to describe verbally. We present data miming---an approach to making sense of gestures as they are used to describe concrete physical objects. We first observe participants as they use gestures to describe real-world objects to another person. From these observations, we derive the data miming approach, which is based on a voxel representation of the space traced by the speaker's hands over the duration of the gesture. In a final proof-of-concept study, we demonstrate a prototype implementation of matching the input voxel representation to select among a database of known physical objects.
2011	Understanding naturalness and intuitiveness in gesture production: insights for touchless gestural interfaces	This paper explores how interaction with systems using touchless gestures can be made intuitive and natural. Analysis of 912 video clips of gesture production from a user study of 16 subjects communicating transitive actions (manipulation of objects with or without external tools) indicated that 1) dynamic pantomimic gestures where imagined tool/object is explicitly held are performed more intuitively and easily than gestures where a body part is used to represent the tool/object or compared to static hand poses and 2) gesturing while communicating the transitive action as how the user habitually performs the action (pantomimic action) is perceived to be easier and more natural than gesturing while communicating it as an instruction. These findings provide guidelines for the characteristics of gestures and user mental models one must consciously be concerned with when designing and implementing gesture vocabularies of touchless interaction.
2011	The impact on musculoskeletal system during multitouch tablet interactions	HCI researchers and technologists have heralded multitouch interaction as the technology to drive computing systems into the future. However, as we move towards a world where interaction is based on human body movements that are not well documented or studied, we face a serious and a grave risk of creating technology and systems that may lead to musculoskeletal disorders (MSD's). Designers need to be empowered with objective data on the impact of multitouch interactions on the musculoskeletal system to make informed choices in interaction design. In this paper we present an experiment that documents kinematic (movement) and kinetic measures (EMG) when interacting with a multitouch tablet. Results show that multitouch interaction can induce significant stress that may lead to MSDs and care must be taken when designing multitouch interaction.
2011	TorusDesktop: pointing via the backdoor is sometimes shorter	When pointing to a target on a computer desktop, we may think we are taking the shortest possible path. But new shortcuts become possible if we allow the mouse cursor to jump from one edge of the screen to the opposite one, i.e., if we turn the desktop into a torus. We discuss the design of TORUSDESKTOP, a pointing technique that allows to wrap the cursor around screen edges to open this pointing backdoor. A dead zone and an off-screen cursor feedback make the technique more usable and more compatible with everyday desktop usage. We report on three controlled experiments conducted to refine the design of the technique and evaluate its performance. The results suggest clear benefits of using the backdoor when target distance is more than 80\% the screen size in our experimental conditions.
2011	Comet and target ghost: techniques for selecting moving targets	Numerous applications such as simulations, air traffic control systems, and video surveillance systems are inherently composed of spatial objects that move in a scene. In many instances, users can benefit from tools that allow them to select these targets in real-time, without having to pause the dynamic display. However, selecting moving objects is considerably more difficult and error prone than selecting stationary targets. In this paper, we evaluate the effectiveness of several techniques that assist in selecting moving targets. We present Comet, a technique that enhances targets based on their speed and direction. We also introduce Target Ghost, which allows users to select a static proxy of the target, while leaving the motion uninterrupted. We found a speed benefit for the Comet in a 1D selection task in comparison to other cursor and target enhancements. For 2D selection, Comet outperformed Bubble cursor but only when Target Ghost was not available. We conclude with guidelines for design.
2011	Acquiring and pointing: an empirical study of pen-tilt-based interaction	Research literature has shown that pen tilt is a promising input modality in pen-based interaction. However, the human capability to control pen tilt has not been fully evaluated. This paper systematically investigates the human ability to perform discrete target selection tasks by varying the stylus' tilt angle through two controlled experiments: pen tilt target acquiring (Experiment 1) and tilt pointing (Experiment 2). Results revealed a decreasing power relationship between angular width and selection time in Experiment 1. The results of Experiment 2 confirmed that pen tilt pointing can be modeled by Fitts' law. Based on our quantitative analysis, we discuss the human ability to control pen tilt and the implications of pen tilt use. We also propose a taxonomy of pen tilt based interaction techniques and showcase a series of possible pen tilt technique designs.
2011	On the costs of multiple trajectory pointing methods	Several enhanced pointing techniques aim to reduce the Fitts' law targeting distance by providing multiple target trajectories in the hope that a shorter path is available. However, these techniques introduce a search or decision component to pointing users must examine the alternatives available and decide upon the trajectory to use. We analyse these difficulties, present a methodology for examining them as well as other behaviour issues, and report empirical results of performance with pointer wrapping and Ninja cursors. Results show that offering multiple trajectories incurs a significant search or decision cost, and that users are therefore poor at capitalising on the theoretical benefits of reduced target distance.
2011	Cursor relocation techniques to help older adults find 'lost' cursors	Older adult computer users often lose track of the mouse cursor and so resort to methods such as mouse shaking or searching the screen to find the cursor again. Hence, this paper describes how a standard optical mouse was modified to include a touch sensor, activated by releasing and touching the mouse, which automatically centers the mouse cursor to the screen, potentially making it easier to find a 'lost' cursor. Six older adult computer users and six younger computer users were asked to compare the touch sensitive mouse with cursor centering with two alternative techniques for locating the mouse cursor: manually shaking the mouse and using the Windows sonar facility. The time taken to click on a target following a distractor task was recorded, and results show that centering the mouse was the fastest to use, with a 35\% improvement over shaking the mouse. Five out of six older participants ranked the touch sensitive mouse with cursor centering as the easiest to use.
2011	Enhancing interactional synchrony with an ambient display	Nonverbal communication is an essential part of face-to-face social interaction, conveying information about emotion and interpersonal relationships. The rigorous sensing capabilities of pervasive technologies and the subtle nature of ambient technologies make them ideal to support the production of nonverbal communication in social interactions. In this paper we present a study using an ambient technology that supports nonverbal communication, and specifically nonverbal behaviours associated with rapport. We show that an ambient display can influence a participant's nonverbal behaviour, and that participants are not aware of this change in their behaviour. We discuss these findings in terms of the design and ethical issues that it raises, and define an agenda for future work.
2011	Issues in evaluating ambient displays in the wild: two case studies	In this paper we discus the complex task of evaluating ambient displays, concentrating on issues within in-situ deployments. We start by describing how these technologies have been evaluated in lab settings, where the focus has been primarily on issues of usability, and argue strongly for the necessity of in-situ evaluation. We then present two case studies involving in-situ evaluations, and from these derive issues that hindered the researchers from being able to delve more deeply into the overall impact of their implementations. We conclude with our own suggestions on possible alternatives to explore for evaluating ambient displays, which are based on the issues derived from our case studies.
2011	Does MoodyBoard make internet use more secure?: evaluating an ambient security visualization tool	Internet users are targets for ever-advancing phishing- and other attacks. The risks are, for example, to disclose credit card information or passwords to unauthorized instances. One approach to help users with insecure situations is provided by MoodyBoard, which uses ambient information to highlight potential risks. In this paper, we present findings from an evaluation of this system. Two user studies were conducted in order to find out whether an ambient security tool can protect users during sensitive tasks. We designed a pilot study to find out whether users understand the warnings and a security study to see if it helps to protect users from phishing attacks. Results show that MoodyBoard users behaved significantly more secure.
2011	Peripheral computing during presentations: perspectives on costs and preferences	Despite the common use of mobile computing devices to communicate and access information, the effects of peripheral computing tasks on people's attention is not well understood. Studies that have identified consequences of multitasking in diverse domains have largely focused on influences on productivity. We have yet to understand perceptions and preferences regarding the use of computing devices for potentially extraneous tasks in settings such as presentations at seminars and colloquia. We explore costs and attitudes about the use of computing devices by people attending presentations. We find that audience members who use devices believe that they are missing content being presented and are concerned about social costs. Other attendees report being less offended by multitasking around them than the device users may realize.
2011	An exploratory study of input modalities for mobile devices used with museum exhibits	New mobile device features and the growing proportion of visitors carrying mobiles allow the range of museum exhibit design possibilities to be expanded. In particular, we see opportunities for using mobiles to help exhibits scale up to support variable-sized groups of visitors, and to support collaborative visitor-visitor interactions. Because exhibit use is generally one-time-only, any interfaces created for these purposes must be easily learnable, or visitors may not use the exhibit at all. To guide the design of learnable mobile interfaces, we chose to employ the Consistency design principle. Consistency was originally applied to desktop UIs, so we extended the definition to cover three new categories of consistency relevant to ubiquitous computing: Within-Device Consistency , Across-Device Consistency and Within-Context Consistency . We experimentally contrasted designs created from these categories. The results show small differences in learnability, but illustrate that even for one-off situations learnability may not be as important as usability.
2011	I lie to myself that i have freedom in my own schedule: productivity tools and experiences of busyness	This paper examines the relationship between experiences of busyness in everyday life and the use of productivity tools, including planners, calendars and to-do lists. Field study findings demonstrate that American individuals across a demographic range have internalized a cultural emphasis of busyness as a moral value to construct positive identities as busy individuals. At the same time, they struggle with a sense of conflict around busyness, reflected in real-life experiences of clashing priorities, fantasies of downtime, and struggles with anxiety, guilt, and loss of control. Our findings also point to the ways digital and non-digital productivity tools are embedded in experiences and coping practices around busyness. Grounded in our observations we propose design principles for productivity tools that support users' identities as busy people but also address some of the perils of the American busyness ethic.
2011	Homebrew databases: complexities of everyday information management in nonprofit organizations	Many people manage a complex assortment of digital information in their lives. Volunteer coordinators at nonprofit organizations are no exception; they collectively manage information about millions of volunteers every year. Yet current information management systems are insufficient for their needs. In this paper, we present results of a qualitative study of the information management practices of volunteer coordinators. We identify the resource constraints and the diverse and fluid information needs, stakeholders, and work contexts that motivate their information management strategies. We characterize the assemblages of information systems that volunteer coordinators have created to satisfice their needs as 'homebrew databases.' Finally, we identify additional information management challenges that result from the use of these 'homebrew databases,' highlighting deficiencies in the appropriateness and usability of databases and information management systems, more generally.
2011	How a freeform spatial interface supports simple problem solving tasks	We developed DataBoard, a freeform spatial interface, to support users in simple problem solving tasks. To develop a deeper understanding of the role of space and the tradeoffs between freeform and structured interaction styles in problem solving tasks, we conducted a controlled user study comparing the DataBoard with a spreadsheet and analyzed video data in detail. Beyond improvements in task performance and memory recall, our observations reveal that freeform interfaces can support users in a variety of ways: representing problems flexibly, developing strategies, executing strategies incrementally, tracking problem state easily, reducing mental computation, and verifying solutions perceptually. The spreadsheet also had advantages, and we discuss the tradeoffs.
2011	Utilizing multimedia capabilities of mobile phones to support teaching in schools in rural panama	Providing good education is one of the major challenges for humanity. In many developing regions in the world improving educational standards is seen as a central building block for improving socio-economic situation of society. Based on our research in Panama we report on how mobile phones can be used as educational tools. In contrast to personal computers mobile phones are widely available and in Panama over 80\% of the children have access to phones. We report on four different studies building on one another. We conducted surveys, focus groups, and group interviews with several hundred teachers and pupils to assess opportunities, needs, and threads for using phones in teaching and learning. Based on the feedback received we created a set of use cases and finally evaluated these in a field study in a rural multigrade school in Panama. Our findings suggest that current phones with multimedia capabilities provide a valuable resource for teaching and learning across many subjects. In particular recording of audio and video, programs for drawing, and taking photos were used in very creative and constructive ways beyond the use cases envisioned by us and initial skepticism of parents turned into support.
2011	Infrastructures for low-cost laptop use in Mexican schools	In recent years, a number of low-cost laptops have been created for children's education, most notably the XO, developed by One Laptop per Child to embody principles of constructionist learning, and the ClassmatePC, designed by Intel to fit within and improve traditional education. We report on a series of field studies in Mexican elementary schools that deployed the XO or ClassmatePC. Although both devices are promoted as valuable for improving education in developing countries, our studies suggest that creating the social and technical infrastructures needed to sustain school laptop use is far more complex than what technology designers assume.
2011	Utilizing DVD players as low-cost offline internet browsers	In the developing world, computers and Internet access remain rare. However, there are other devices that can be used to deliver information, including TVs and DVD players. In this paper, we work to bridge this gap by delivering offline Internet content on DVD, for interactive playback on ordinary DVD players. Using the remote control, users can accomplish all of the major functions available in a Web browser, including navigation, hyperlinks, and search. As our driving application, we map the entirety of schools-wikipedia.org - encompassing 5,500 articles and 259,000 screens - to a double-layer DVD. We evaluate our system via a study of 20 low-income users in Bangalore, India. Using our DVD as reference, participants are able to answer factual questions with over 90\% success. While most participants prefer to use a computer if one is available, for resource-poor environments the DVD platform could represent a viable and low-cost alternative.
2011	Importance-driven compositing window management	In this paper we present importance-driven compositing window management, which considers windows not only as basic rectangular shapes but also integrates the importance of the windows' content using a bottom-up visual attention model. Based on this information, importance-driven compositing optimizes the spatial window layout for maximum visibility and interactivity of occluded content in combination with see-through windows. We employ this technique for emerging window manager functions to minimize information overlap caused by popping up windows or floating toolbars and to improve the access to occluded window content. An initial user study indicates that our technique provides a more effective and satisfactory access to occluded information than the well-adopted Alt+Tab window switching technique and see-through windows without optimized spatial layout.
2011	Content and hierarchy in pixel-based methods for reverse engineering interface structure	The rigidity and fragmentation of GUI toolkits are fundamentally limiting the progress and impact of interaction research. Pixel-based methods offer unique potential for addressing these challenges independent of the implementation of any particular interface or toolkit. This work builds upon Prefab, which enables the modification of existing interfaces. We present new methods for hierarchical models of complex widgets, real-time interpretation of interface content, and real-time interpretation of content and hierarchy throughout an entire interface. We validate our new methods through implementations of four applications: stencil-based tutorials, ephemeral adaptation, interface translation, and end-user interface customization. We demonstrate these enhancements in complex existing applications created from different user interface toolkits running on different operating systems.
2011	Client TouchPoint modeling: understanding client interactions in the context of service delivery	Service delivery organizations oftentimes overlook opportunities to cultivate client relationships due to a lack of awareness of the totality of touchpoints, or interactions, that occur between service delivery personnel and client personnel over time. To enable service delivery organizations to strategically manage their client relationships, we introduce the first phase of the Client TouchPoint Modeling (CTM) process in which service delivery teams create a touchpoint map of their collective interactions across a client account. Participatory design sessions with service delivery personnel informed the design of a CTM TouchPoint Map prototype. Through these sessions, we also discovered a more collaborative approach to CTM, one in which service delivery team members work together to co-construct a unified account map in a way that promotes team transparency and sensemaking of the service experience.
2011	Using predictive human performance models to inspire and support UI design recommendations	Predictive human performance modeling has traditionally been used to make quantitative comparisons between alternative designs (e.g., task execution time for skilled users) instead of identifying UI problems or making design recommendations. This note investigates how reliably novice modelers can extract design recommendations from their models. Many HCI evaluation methods have been plagued by the "evaluator effect" [3], i.e., different people using the same method find different UI problems. Our data and analyses show that predictive human performance modeling is no exception. Novice modelers using CogTool [5] display a 34\% Any-Two Agreement in their design recommendations, a result in the upper quartile of evaluator effect studies. However, because these recommendations are grounded in models, they may have more reliable impact on measurable performance than recommendations arising from less formal methods.
2011	Matters of life and death: locating the end of life in lifespan-oriented hci research	Examining developmental periods of the human lifespan has been a useful tradition for focusing HCI research (e.g., technologies for children or the elderly). In this paper, we identify the end of life as another period of the human lifespan that merits consideration by technology designers and researchers. This paper maps out current and future research in HCI at the end of life by first describing how this area raises questions concerning materiality and artifacts, social identities, temporality and methodologies. Having provided a description of the richness of this area, we then frame it against HCI traditions and practices in an orientation we term the lifespan-oriented approach . This paper maps early efforts in end of life research, structures and suggests areas for continued work, and situates the end of life among existing areas of HCI research.
2011	I said your name in an empty room: grieving and continuing bonds on facebook	In response to the death of a close friend or relative, bereaved individuals can use technology as part of the grieving process. We present a study that analyzes the messages of the friends and family of the deceased to their Facebook profile before and after their passing. Our analysis reveals that mourners use profiles as a way to maintain a continuing bond with the deceased, as well as a way to accomplish specific front stage bereavement communication, such as sharing memories, expressing sorrow and providing social support. These observations may improve the design of social networking technologies so that they remain useful, sensitive tools for the bereaved.
2011	Dealing with death in design: developing systems for the bereaved	Increasingly, systems are being developed and used in ways that involve end of life issues such as death, dying, and bereavement. Yet design considerations and guidelines for technologists working in this sensitive area are not well-established. We therefore report on exploratory fieldwork consisting of focus groups, observations, and consultation with bereavement experts aimed at understanding how technology might be designed to support bereaved parents. From this fieldwork, we derive a set of considerations useful for researchers and designers developing systems that deal specifically with bereavement, and with the end of life more broadly. These considerations focus on interpersonal communication, new ways of being in the world , and materiality . We conclude with a distillation of these considerations into practical design guidelines for working in this area.
2011	Touch input on curved surfaces	Advances in sensing technology are currently bringing touch input to non-planar surfaces, ranging from spherical touch screens to prototypes the size and shape of a ping-pong ball. To help interface designers create usable interfaces on such devices, we determine how touch surface curvature affects targeting. We present a user study in which participants acquired targets on surfaces of different curvature and at locations of different slope. We find that surface convexity increases pointing accuracy, and in particular reduces the offset between the input point perceived by users and the input point sensed by the device. Concave surfaces, in contrast, are subject to larger error offsets. This is likely caused by how concave surfaces hug the user's finger, thus resulting in a larger contact area. The effect of slope on targeting, in contrast, is unexpected at first sight. Some targets located downhill from the user's perspective are subject to error offsets in the opposite direction from all others. This appears to be caused by participants acquiring these targets using a different finger posture that lets them monitor the position of their fingers more effectively.
2011	Audience behavior around large interactive cylindrical screens	Non-planar screens, such as columns, have been a popular means for displaying information for a long time. In con-trast to traditional displays their digital counterparts are mainly flat and rectangular due to current technological constraints. However, we envision bendable displays to be available in the future, which will allow for creating new forms of displays with new properties. In this paper we ex-plore cylindrical displays as a possible form of such novel public displays. We present a prototype and report on a user study, comparing the influence of the display shape on user behavior and user experience between flat and cylindrical displays. The results indicate that people move more in the vicinity of cylindrical displays and that there is no longer a default position when it comes to interaction. As a result, such displays are especially suitable to keep people in motion and to support gesture-like interaction.
2011	Motionbeam: a metaphor for character interaction with handheld projectors	We present the MotionBeam metaphor for character interaction with handheld projectors. Our work draws from the tradition of pre-cinema handheld projectors that use direct physical manipulation to control projected imagery. With our prototype system, users interact and control projected characters by moving and gesturing with the handheld projector itself. This creates a unified interaction style where input and output are tied together within a single device. We introduce a set of interaction principles and present prototype applications that provide clear examples of the MotionBeam metaphor in use. Finally we describe observations and insights from a preliminary user study with our system.
2011	3d projection on physical objects: design insights from five real life cases	3D projection on physical objects is a particular kind of Augmented Reality that augments a physical object by projecting digital content directly onto it, rather than by using a mediating device, such as a mobile phone or a head-mounted display. In this paper, we present five cases in which we have developed installations that employ 3D projection on physical objects. The installations have been developed in collaboration with external partners and have been put into use in real-life settings such as museums, exhibitions and interaction design laboratories. On the basis of these cases, we present and discuss three central design insights concerning new potentials for well-known 3D effects, dynamics between digital world and physical world, and relations between object, content and context.
2011	The new good: exploring the potential of philosophy of technology to contribute to human-computer interaction	As a result of the increased interest in issues such as engagement, affection, and meaning, contemporary human-computer interaction (HCI) has increasingly come to examine the nature of interactions between artifacts, humans, and environments through concepts such as user experience and meaning. In the transition from usability metrics to user experience, what appears lacking is a more explicit characterization of what it is HCI now strives for as a discipline--i.e. what constitutes a 'good' user experience? Through a detailed look at two contemporary philosophies of technology--Albert Borgmann's notion of the device paradigm and Don Ihde's non-neutrality of technology-mediated experience--this paper seeks to explore the potential of the philosophy of technology to contribute new insights and provide well-grounded conceptual tools for coming to terms with what may become HCI's 'new good'.
2011	Understanding interaction design practices	There is an undesirable gap between HCI research aimed at influencing interaction design practice and the practitioners in question. To close this gap, we advocate a theoretical and methodological focus on the day-to-day, lived experience of designers. To date, this type of theory-generative, experientially oriented research has focused on the users of technologies, not the designers. In contrast, we propose that HCI researchers turn their attention to producing theories of interaction design practice that resonate with practitioners themselves. In part one of this paper, we describe the mismatch between HCI research and interaction design practices. Then we present vignettes from an observational study of commercial design practice to illustrate the issues at hand. In part two, we discuss methodological and theoretical changes in research practice that might support the goal of integrating HCI research with interaction design practices. We then discuss current research methods and theories to identify changes that might enlarge our view on practice. In part three, we elaborate on our theoretically minded agenda and a kind of ideal-type theory.
2011	Voluntweeters: self-organizing by digital volunteers in times of crisis	This empirical study of "digital volunteers" in the aftermath of the January 12, 2010 Haiti earthquake describes their behaviors and mechanisms of self-organizing in the information space of a microblogging environment, where collaborators were newly found and distributed across continents. The paper explores the motivations, resources, activities and products of digital volunteers. It describes how seemingly small features of the technical environment offered structure for self-organizing, while considering how the social-technical milieu enabled individual capacities and collective action. Using social theory about self-organizing, the research offers insight about features of coordination within a setting of massive interaction.
2011	Social media ownership: using twitter as a window onto current attitudes and beliefs	Social media, by its very nature, introduces questions about ownership. Ownership comes into play most crucially when we investigate how social media is saved or archived; how it is reused; and whether it can be removed or deleted. We investigate these social media ownership issues using a Mechanical Turk survey of Twitter users; the survey uses open-ended questions and statements of belief about realistic Twitter-based scenarios to give us a window onto current attitudes and beliefs. Our findings reveal that respondents take a liberal attitude toward saving and storing the tweets that they encounter. More caution is exercised with republishing the material, and still more with sharing the material among friends and associates. Respondents approach removal of this type of lightweight social media most cautiously. The material's provenance and the respondents' relationship to the material (whether they are the author or subject) has considerable bearing on what they feel they can do with it.
2011	Fragile online relationship: a first look at unfollow dynamics in twitter	We analyze the dynamics of the behavior known as 'unfollow' in Twitter. We collected daily snapshots of the online relationships of 1.2 million Korean-speaking users for 51 days as well as all of their tweets. We found that Twitter users frequently unfollow. We then discover the major factors, including the reciprocity of the relationships, the duration of a relationship, the followees' informativeness, and the overlap of the relationships, which affect the decision to unfollow. We conduct interview with 22 Korean respondents to supplement the quantitative results. They unfollowed those who left many tweets within a short time, created tweets about uninteresting topics, or tweeted about the mundane details of their lives. To the best of our knowledge, this work is the first systematic study of the unfollow behavior in Twitter.
2011	The impact of network structure on breaking ties in online social networks: unfollowing on twitter	We investigate the breaking of ties between individuals in the online social network of Twitter, a hugely popular social media service. Building on sociology concepts such as strength of ties, embeddedness, and status, we explore how network structure alone influences tie breaks - the common phenomena of an individual ceasing to "follow" another in Twitter's directed social network. We examine these relationships using a dataset of 245,586 Twitter "follow" edges, and the persistence of these edges after nine months. We show that structural properties of individuals and dyads at Time 1 have a significant effect on the existence of edges at Time 2, and connect these findings to the social theories that motivated the study.
2011	Computing political preference among twitter followers	There is great interest in understanding media bias and political information seeking preferences. As many media outlets create online personas, we seek to automatically estimate the political preferences of their audience, rather than of the outlet itself. In this paper, we present a novel method for computing preference among an organization's Twitter followers. We present an application of this technique to estimate political preference of the audiences of U.S. media outlets. We also discuss how these results may be used and extended.
2011	Online contribution practices in countries that engage in internet blocking and censorship	In this article we describe people's online contribution practices in contexts in which the government actively blocks access to or censors the Internet. We argue that people experience blocking as confusing, as a motivation for self-censorship online, as a cause of impoverishment of available content and as a real threat of personal persecution. Challenging ideas of blocking as a monolithic, abstract policy, we discuss five strategies with which Internet users navigate blocking: self-censorship, cultivating technical savvy, reliance on social ties to relay blocked content, use of already blocked sites for content production as a form of protection and practiced transparency. We also discuss strategies that forum owners and blogging platform providers employ to deal with and to avoid blocking. We conclude by advocating for more research that acknowledges the complexity of the contexts in which all Internet users contribute to the Internet and social media.
2011	Real-time collaborative editing behavior in USA and Japanese distributed teams	While there are tools that allow distributed teams to collaboratively edit in real time, little work examines this practice among real teams doing real work. Even less is known about how teams from different countries make use of real-time collaborative editing tools. The current work highlights results from a qualitative user study of real-world Japanese and U.S. distributed work teams who used LiveDeck, a real-time slide editing and whiteboarding tool. Through the implementation of various novel features used as probes, differences in behavior and attitudes between team members were uncovered. Differences in the use of slide navigation options, anonymity features, and pop-up 'emotes' representing nonverbal gestures are discussed.
2011	Cultural differences on visual self-presentation through social networking site profile images	A profile image is one of the most important personal attributes on social networking sites (SNSs). The current study examines whether self-presentation on SNSs is related to national culture and how forms of self-presentation differ between American and Chinese users. We accomplish this by analyzing profile images on two social networking sites, Facebook in the US and Renren in China. Our findings indicate that self-presentation is sensitive to national culture: Chinese users are more likely to customize their profile images than Americans. Our study suggests that there is a need to design social networking website features that better support profile construction for international users.
2011	MonoTrans2: a new human computation system to support monolingual translation	In this paper, we present MonoTrans2, a new user interface to support monolingual translation; that is, translation by people who speak only the source or target language, but not both. Compared to previous systems, MonoTrans2 supports multiple edits in parallel, and shorter tasks with less translation context. In an experiment translating children's books, we show that MonoTrans2 is able to substantially close the gap between machine translation and human bilingual translations. The percentage of sentences rated 5 out of 5 for fluency and adequacy by both bilingual evaluators in our study increased from 10\% for Google Translate output to 68\% for MonoTrans2.
2011	Culture or fluency?: unpacking interactions between culture and communication medium	In this paper we describe two studies intended to replicate earlier work comparing American and Chinese communication in a negotiation task using several different media. In the earlier studies, the participants all spoke in English, raising the question of whether differences in fluency rather than differences in cultural background explained the results. We replicated the earlier studies using materials translated into Chinese, a native Chinese-speaking experimenter, and native Chinese participants. Counts of Chinese characters in each media show nearly the identical pattern found in the earlier studies, suggesting that cultural differences in communication styles, rather than fluency, account for the earlier findings. We describe implications of this work for tools to support intercultural communication.
2011	Skim reading by satisficing: evidence from eye tracking	Readers on the Web often skim through text to cope with the volume of available information. In a previous study, Duggan and Payne [11] tracked readers' eye movements as they skimmed through expository text under time pressure. This article presents novel analyses of these eye-movement data. Results indicated that readers were able to explicitly direct attention to the most important information in the text and that this improved performance on a subsequent test of memory for the meaning of text. We suggest readers achieve this by satisficing reading through text until the rate of information gain drops below threshold and then skipping to the next section of text. Further analyses of gaze patterns for paragraphs and pages supported this explanation. Combining satisficing with some form of scanning or sampling behaviour could explain patterns of reading found on the Web. A greater understanding of the way that text is read on the Web would assist many producers of online content.
2011	Older web users' eye movements: experience counts	Eye-tracking is a valuable tool for usability research. Studies into the effect of age on eye-movement behavior tend to indicate a propensity for slower viewing and longer times spent examining information. This pattern is usually attributed to the general physiological and cognitive slow-down associated with normal aging. In this paper, however, across three different tasks based on computer and internet use (free-viewing, visual search, and browser interaction), we show that among older adults (n=18, age range: 70-93) computer experience appears to be a highly important factor in eye-movement behavior. We argue that as a consequence of the experimental environment used in modern eye-tracking studies, characteristics such as familiarity and experience with computers should be taken into account before conclusions are drawn about the raw effects of age.
2011	Retrospective think-aloud method: using eye movements as an extra cue for participants' verbalizations	The retrospective think-aloud method, in which participants work in silence and verbalize their thoughts afterwards while watching a recording of their performance, is often used for the evaluation of websites. However, participants may not always be able to recall what they thought, when they only see few visual cues that help them remembering their task execution process. In our study we complemented the recording of the performance with a gaze trail of the participant" eye movements, in order to elicit more verbalizations. A comparison was made between the traditional retrospective think-aloud protocols and the variant with eye movements. Contrary to our expectations, no differences were found between the two conditions on numbers of problems, the ways these problems were detected, and types of problems. Two possible explanations for this result are that eye movements might be rather confronting and distracting for participants, and the rather generic way of probing we used. The added value might be stronger when specific questions are asked, based on the observed eye movements. Implications for usability practitioners are discussed in the conclusions of this paper.
2011	Triggered think-aloud protocol: using eye tracking to improve usability test moderation	Usability practitioners often rely on research participants' verbal reports to better understand the user experience. These reports can be collected either during or after task execution, with each approach entailing unique benefits and limitations. This note presents a framework for using eye tracking data to "trigger" when and how moderators probe participants for verbal comments during task execution to supplement or elaborate participant-initiated comments. A preliminary case study suggests that this approach affords a level of efficiency and effectiveness difficult to achieve with retrospective verbalization or without the use of eye tracking. The hope is that practitioners will be encouraged to use and refine this method for the benefit of the field.
2011	Learning patterns of pick-ups and drop-offs to support busy family coordination	Part of being a parent is taking responsibility for arranging and supplying transportation of children between various events. Dual-income parents frequently develop routines to help manage transportation with a minimal amount of attention. On days when families deviate from their routines, effective logistics can often depend on knowledge of the routine location, availability and intentions of other family members. Since most families rarely document their routine activities, making that needed information unavailable, coordination breakdowns are much more likely to occur. To address this problem we demonstrate the feasibility of learning family routines using mobile phone GPS. We describe how we (1) detect pick-ups and drop-offs; (2) predict which parent will perform a future pick-up or drop-off; and (3) infer if a child will be left at an activity. We discuss how these routine models give digital calendars, reminder and location systems new capabilities to help prevent breakdowns, and improve family life.
2011	Mediated parent-child contact in work-separated families	Parents and children in families living with regular separation due to work develop strategies to manage being apart. We interviewed 14 pairs of parents and children (ages 7 -- 13) from work-separated families to understand their experiences and the strategies that they use to keep their family together. Parents focus on combining scheduled synchronous and spontaneous asynchronous communication to maintain a constant presence in the life of the child. Children, on the other hand, focus on other sources of support, on other activities, and on the eventual reunion. Both the remote parent and the child rely heavily on a collocated adult to maintain aware-ness and contact. We compare work-separated families with other types of separation and highlight opportunities for new designs.
2011	Hello, is grandma there? let's read! StoryVisit: family video chat and connected e-books	StoryVisit allows children and long-distance adults to experience a sense of togetherness by reading children's story books together over a distance. StoryVisit combines video conferencing and connected books: remote grown-up and child readers can see and hear each other, and can also see and control the same e-book. We report on research with 61 families - over 200 users including parents, children and long-distance readers - who used StoryVisit in their homes with a long-distance reader for at least one reading session. In addition, we report qualitative findings regarding nineteen of the families who participated in telephone interviews and four families who were monitored and interviewed by researchers at home. Results show that connected e-book video chat sessions last about five times as long as the typical video chats reported in previous research on families with young children. Moreover, the addition of an animated character increased session lengths by another 50\%. StoryVisit usage peaked for families with three year olds, showing that sustained distance interactions with very young children are possible if communication technologies incorporate joint activities that engage children and adults.
2011	Family portals: connecting families through a multifamily media space	Video conferencing allows distance-separated family members to interact somewhat akin to being together at the same place and time. Yet most video conferencing systems are designed for phone-like calls between only two locations. Using such systems for long interactions or social gatherings with multiple families is cumbersome, if not impossible. For this reason, we wanted to explore how families would make use of a video system that permitted sharing everyday life over extended periods of time between multiple locations. We designed a media space called Family Portals that provides shared video between three locations and deployed it within the homes of six families. Results show that the media space increased feelings of connectedness and the focus on a triad, in contrast to a dyad, caused new styles of interaction to emerge. Despite this, families experienced new privacy challenges and non-adoption by some family members, not previously seen in dyadic family media spaces.
2011	The information flaneur: a fresh look at information seeking	We introduce the information flaneur as a new human-centred view on information seeking that is grounded in interdisciplinary research. We use the metaphor of the urban flaneur making sense of a city as an inspiring lens that brings together diverse perspectives. These perspectives shift information seeking towards a more optimistic outlook: the information flaneur represents curious, creative, and critical information seeking. The resulting information-seeking model conceptualizes the interrelated nature between information activities and experiences as a continuum between horizontal exploration and vertical immersion. Motivated by enabling technological trends and inspired by the information flaneur, we present explorability as a new guiding principle for design and raise research challenges regarding the representation of information abstractions and details.
2011	No clicks, no problem: using cursor movements to understand and improve search	Understanding how people interact with search engines is important in improving search quality. Web search engines typically analyze queries and clicked results, but these actions provide limited signals regarding search interaction. Laboratory studies often use richer methods such as gaze tracking, but this is impractical at Web scale. In this paper, we examine mouse cursor behavior on search engine results pages (SERPs), including not only clicks but also cursor movements and hovers over different page regions. We: (i) report an eye-tracking study showing that cursor position is closely related to eye gaze, especially on SERPs; (ii) present a scalable approach to capture cursor movements, and an analysis of search result examination behavior evident in these large-scale cursor data; and (iii) describe two applications (estimating search result relevance and distinguishing good from bad abandonment) that demonstrate the value of capturing cursor data. Our findings help us better understand how searchers use cursors on SERPs and can help design more effective search systems. Our scalable cursor tracking method may also be useful in non-search settings.
2011	Enhancing credibility judgment of web search results	In this paper, we propose a system for helping users to judge the credibility of Web search results and to search for credible Web pages. Conventional Web search engines present only titles, snippets, and URLs for users, which give few clues to judge the credibility of Web search results. Moreover, ranking algorithms of the conventional Web search engines are often based on relevance and popularity of Web pages. Towards credibility-oriented Web search, our proposed system provides users with the following three functions: (1) calculation and visualization of several scores of Web search results on the main credibility aspects, (2) prediction of user's credibility judgment model through user's credibility feedback for Web search results, and (3) re-ranking of Web search results based on user's predicted credibility model. Experimental results suggest that our system enables users - in particular, users with knowledge about search topics - to find credible Web pages from a list of Web search results more efficiently than conventional Web search interfaces.
2011	Augmenting web pages and search results to support credibility assessment	The presence (and, sometimes, prominence) of incorrect and misleading content on the Web can have serious consequences for people who increasingly rely on the internet as their information source for topics such as health, politics, and financial advice. In this paper, we identify and collect several page features (such as popularity among specialized user groups) that are currently difficult or impossible for end users to assess, yet provide valuable signals regarding credibility. We then present visualizations designed to augment search results and Web pages with the most promising of these features. Our lab evaluation finds that our augmented search results are particularly effective at increasing the accuracy of users'" credibility assessments, highlighting the potential of data aggregation and simple interventions to help people make more informed decisions as they search for information online.
2011	Using fast interaction to create intense experiences	Several emerging strands of HCI involve connecting physical exercise activity with digital interactive systems to create intense combined experiences, for example pervasive games, GPS based exercise games and 'exertion interfaces'. Many of these systems are mobile, used outside in public, whilst moving quickly through the environment. In this paper, we argue that the combination of moving fast and interacting with a digital system allows us to create a powerfully intense experience for participants, and that key to this is careful attention to the way in which movement is combined with digital content. We study an interactive art experience in which a person runs whilst listening to poetry. Based on this study and other HCI research, we present a framework for mixing physical and interactive content, based on 3 dimensions, which describe ways that a movement activity may itself create intense experiences, followed by a set of tactics for combining intense movement and interactive content.
2011	A VJ centered exploration of expressive interaction	This paper identifies key themes of expressive interaction for VJs. VJs are visual artists who use digital media to express themselves to an audience during a live audio-visual performance. Those designing for the expressive use of technology can gain insight from an articulation of expressive interaction from the perspective of VJ practice. This is developed using a novel qualitative methodology designed to be sensitive to the subtle and tacit nature of expression. We detail our methodology, present the results of its application to a group of VJs and conclude with a discussion of the implications our findings may have for those wishing to design for VJs, or those in related domains that involve expressive interaction with technology.
2011	Placing a value on aesthetics in online casual games	Game designers frequently invest in aesthetic improvements such as music, sound effects, and animations. However, their exact value for attracting and retaining players remains unclear. Seeking to estimate this value in two popular Flash games, we conducted a series of large-scale A/B tests in which we selectively removed aesthetic improvements and examined the effect of each component on play time, progress, and return rate. We found that music and sound effects had little or no effect on player retention in either game, while animations caused users to play more. We also found, counterintuitively, that optional rewards caused players to play less in both games. In one game, this gameplay modification affected play time three times as much as the largest aesthetic variation. Our methodology provides a way to determine where resources may be best spent during the game design and development process.
2011	Kinetic tiles	We propose and demonstrate Kinetic Tiles, modular construction units for kinetic animations. Three different design methods are explored and evaluated for kinetic animation with the Kinetic Tiles using preset movements, design via animation toolkit, and design via direct input. It is expected that the Kinetic Tiles, as a new design and architecture material, will assist designers to introduce kinetic expressions to the surfaces of everyday objects and spaces.
2011	SandCanvas: a multi-touch art medium inspired by sand animation	Sand animation is a performance art technique in which an artist tells stories by creating animated images with sand. Inspired by this medium, we have developed a new multi-touch digital artistic medium named SandCanvas that simplifies the creation of sand animations. SandCanvas also goes beyond traditional sand animation with tools for mixing sand animation with video and replicating recorded free-form hand gestures. In this paper, we analyze common sand animation hand gestures, present SandCanvas 's intuitive UI, and describe implementation challenges we encountered. We also present an evaluation with professional and novice artists that shows the importance and unique affordances of this new medium.
2011	Evaluating effects of structural holds on pointing and dragging performance with flexible displays	In this paper, we present a study of the effects of structural holds and rigidity of a flexible display on touch pointing and dragging performance. We discuss an observational study in which we collected common holds used when pointing on a mockup paper display. We also measured the force patterns each hold generated within the display surface. We analyzed this data to produce 3 force zones in the display for each of the four most frequently observed holds: the grip zone, rigid zone, and the flexible zone. We report on an empirical evaluation in which we compared the efficiency of pointing and dragging operations between holds, and between structural zones within holds, using a real flexible Lumalive display. Results suggest that structural force distributions in a flexible display affect the Index of Performance of both pointing and dragging tasks, irrespective of hold, with rigid parts of the display yielding a 12\% average performance gain over flexible areas.
2011	PaperPhone: understanding the use of bend gestures in mobile devices with flexible electronic paper displays	Flexible displays potentially allow for interaction styles that resemble those used in paper documents. Bending the display, e.g., to page forward, shows particular promise as an interaction technique. In this paper, we present an evaluation of the effectiveness of various bend gestures in executing a set of tasks with a flexible display. We discuss a study in which users designed bend gestures for common computing actions deployed on a smartphone-inspired flexible E Ink prototype called PaperPhone. We collected a total of 87 bend gesture pairs from ten participants and their appropriateness over twenty actions in five applications. We identified six most frequently used bend gesture pairs out of 24 unique pairs. Results show users preferred bend gestures and bend gesture pairs that were conceptually simpler, e.g., along one axis, and less physically demanding. There was a strong agreement among participants to use the same three pairs in applications: (1) side of display, up/down (2) top corner, up/down (3) bottom corner, up/down. For actions with a strong directional cue, we found strong consensus on the polarity of the bend gestures (e.g., navigating left is performed with an upwards bend gesture, navigating right, downwards). This implies that bend gestures that take directional cues into account are likely more natural to users.
2011	Pinstripe: eyes-free continuous input on interactive clothing	We present Pinstripe, a textile user interface element for eyes-free, continuous value input on smart garments that uses pinching and rolling a piece of cloth between your fingers. The input granularity can be controlled in a natural way by varying the amount of cloth pinched. Pinstripe input elements physically consist of fields of parallel conductive lines sewn onto the fabric. This way, they can be invisible, and can be included across large areas of a garment. Pinstripe also addresses several problems previously identified in the placement and operation of textile UI elements on smart clothing. Two user studies evaluate ideal placement and orientation of Pinstripe elements on the users' garments as well as acceptance and perceived ease of use of this novel textile input technique.
2011	Grips and gestures on a multi-touch pen	This paper explores the interaction possibilities enabled when the barrel of a digital pen is augmented with a multi-touch sensor. We present a novel multi-touch pen (MTPen) prototype and discuss its alternate uses beyond those of a standard stylus, such as allowing new touch gestures to be performed using the index finger or thumb and detecting how users grip the device as a mechanism for mode switching. We also discuss the hardware and software implementation challenges in realizing our prototype, and showcase how one can combine different grips (tripod, relaxed tripod, sketch, wrap) and gestures (swipe and double tap) to enable new interaction techniques with the MTPen in a prototype drawing application. One specific aim is the elimination of some of the comfort problems associated with existing auxiliary controls on digital pens. Mechanical controls such as barrel buttons and barrel scroll wheels work best in only a few specific hand grips and pen rotations. Comparatively, our gestures can be successfully and comfortably performed regardless of the rotation of the pen or how the user grips it, offering greater flexibility in use. We describe a formal evaluation comparing MTPen gestures against the use of a barrel button for mode switching. This study shows that both swipe and double tap gestures are comparable in performance to commonly employed barrel buttons without its disadvantages.
2011	WYSIWYF: exploring and annotating volume data with a tangible handheld device	Visual exploration of volume data often requires the user to manipulate the orientation and position of a slicing plane in order to observe, annotate or measure its internal structures. Such operations, with its many degrees of freedom in 3D space, map poorly into interaction modalities afforded by mouse-keyboard interfaces or flat multi-touch displays alone. We addressed this problem using a what-you-see-is-what-you-feel (WYSIWYF) approach, which integrates the natural user interface of a multi-touch wall display with the untethered physical dexterity provided by a handheld device with multi-touch and 3D-tilt sensing capabilities. A slicing plane can be directly and intuitively manipulated at any desired position within the displayed volume data using a commonly available mobile device such as the iPod touch. 2D image slices can be transferred wirelessly to this small touch screen device, where a novel fast fat finger annotation technique (F 3 AT) is proposed to perform accurate and speedy contour drawings. Our user studies support the efficacy of our proposed visual exploration and annotation interaction designs.
2011	Eden: a professional multitouch tool for constructing virtual organic environments	Set construction is the process of selecting and positioning virtual geometric objects to create a virtual environment used in a computer-animated film. Set construction artists often have a clear mental image of the set composition, but find it tedious to build their intended sets with current mouse and keyboard interfaces. We investigate whether multitouch input can ease the process of set construction. Working with a professional set construction artist at Pixar Animation Studios, we designed and developed Eden, a fully functional multitouch set construction application. In this paper, we describe our design process and how we balanced the advantages and disadvantages of multitouch input to develop usable gestures for set construction. Based on our design process and the user experiences of two set construction artists, we present a general set of lessons we learned regarding the design of a multitouch interface.
2011	2d touching of 3d stereoscopic objects	Recent developments in the area of touch and display technologies have suggested to combine multi-touch systems and stereoscopic visualization. Stereoscopic perception requires each eye to see a slightly different perspective of the same scene, which results in two distinct projections on the display. Thus, if the user wants to select a 3D stereoscopic object in such a setup, the question arises where she would touch the 2D surface to indicate the selection. A user may apply different strategies, for instance touching the midpoint between the two projections, or touching one of them. In this paper we analyze the relation between the 3D positions of stereoscopically rendered objects and the on-surface touch points , where users touch the surface. We performed an experiment in which we determined the positions of the users' touches for objects, which were displayed with positive, negative or zero parallaxes. We found that users tend to touch between the projections for the two eyes with an offset towards the projection for the dominant eye. Our results give implications for the development of future touch-enabled interfaces, which support 3D stereoscopic visualization.
2011	TZee: exploiting the lighting properties of multi-touch tabletops for tangible 3d interactions	Manipulating 3D objects on a tabletop is inherently problematic. Tabletops lack a third degree of freedom and thus require novel solutions to support even the simplest 3D manipulations. Our solution is TZee - a passive tangible widget that enables natural interactions with 3D objects by exploiting the lighting properties of diffuse illumination (DI) multi-touch tabletops. TZee is assembled from stacked layers of acrylic glass to extend the tabletop's infrared light slightly above the surface without supplemental power. With TZee, users can intuitively scale, translate and rotate objects in all three dimensions, and also perform more sophisticated gestures, like "slicing" a volumetric object, that have not been possible with existing tabletop interaction schemes. TZee is built with affordable and accessible materials, and one tabletop surface can easily support multiple TZees. Moreover, since TZee is transparent, there are numerous possibilities to augment interactions with feedback, helpful hints, or other visual enhancements. We discuss several important design considerations and demonstrate the value of TZee with several applications.
2011	Guess who?: enriching the social graph through a crowdsourcing game	Despite the tremendous popularity of social network sites both on the web and within enterprises, the relationship information they contain may be often incomplete or outdated. We suggest a novel crowdsourcing approach that uses a game to help enrich and expand the social network topology. The game prompts players to provide the names of people who have a relationship with individuals they know. The game was deployed for a one-month period within a large global organization. We provide an analysis of the data collected through this deployment, in comparison with the data from the organization's social network site. Our results indicate that the game rapidly collects large volumes of valid information that can be used to enrich and reinforce an existing social network site's data. We point out other aspects and benefits of using a crowdsourcing game to harvest social network information.
2011	PhotoCity: training experts at large-scale image acquisition through a competitive game	Large-scale, ground-level urban imagery has recently developed as an important element of online mapping tools such as Google's Street View. Such imagery is extremely valuable in a number of potential applications, ranging from augmented reality to 3D modeling, and from urban planning to monitoring city infrastructure. While such imagery is already available from many sources, including Street View and tourist photos on photo-sharing sites, these collections have drawbacks related to high cost, incompleteness, and accuracy. A potential solution is to leverage the community of photographers around the world to collaboratively acquire large-scale image collections. This work explores this approach through PhotoCity, an online game that trains its players to become "experts" at taking photos at targeted locations and in great density, for the purposes of creating 3D building models. To evaluate our approach, we ran a competition between two universities that resulted in the submission of over 100,000 photos, many of which were highly relevant for the 3D modeling task at hand. Although the number of players was small, we found that this was compensated for by incentives that drove players to become experts at photo collection, often capturing thousands of useful photos each.
2011	Cooks or cobblers?: crowd creativity through combination	A sketch combination system is introduced and tested: a crowd of 1047 participated in an iterative process of design, evaluation and combination. Specifically, participants in a crowdsourcing marketplace sketched chairs for children. One crowd created a first generation of chairs, and then successive crowds created new generations by combining the chairs made by previous crowds. Other participants evaluated the chairs. The crowd judged the chairs from the third generation more creative than those from the first generation. An analysis of the design evolution shows that participants inherited and modified presented features, and also added new features. These findings suggest that crowd based design processes may be effective, and point the way toward computer-human interactions that might further encourage crowd creativity.
2011	Human computation: a survey and taxonomy of a growing field	The rapid growth of human computation within research and industry has produced many novel ideas aimed at organizing web users to do great things. However, the growth is not adequately supported by a framework with which to understand each new system in the context of the old. We classify human computation systems to help identify parallels between different systems and reveal "holes" in the existing work as opportunities for new research. Since human computation is often confused with "crowdsourcing" and other terms, we explore the position of human computation with respect to these related topics.
2011	The times they are a-changin': mobile payments in india	We report on an ethnographic study of payment and banking practices in India. Currently a mobile payment mechanism is being developed in India and we were interested to see how it would fit with various current payment systems for various types of users. Therefore we studied a variety of current payment situations and gained an understanding of the banking and payment practices and needs of a diverse community. Our aim was to inform the development of interface elements, applications and services that would support the needs we uncovered. We describe our findings and the design ideas they provoked.
2011	Folk music goes digital in India	Folk music forms in India are rich and diverse, varying from region to region across the Indian landscape. The recent explosion of new media technologies (e.g. DVDs, CDs, mobile phones) in both rural and urban India is changing how oral folk music is being performed, produced, distributed, and shared. To further understand this impact, we conducted an extended field study across four field sites in India that are rich in folk music tradition and activity. Through a process of interviews, participant observation, focus group discussion, and content analysis with a varied group of stakeholders - including folk musicians, listeners, retailers, and radio show producers - we found that 1) there are a diverse set of motivations for performing and listening to folk music, 2) new media technologies are helping folk musicians become more popular, while reducing some streams of revenue, particularly for businesses engaged only in music production and distribution, and 3) as expected, piracy is widely tolerated by musicians, both out of apathy, and an interest in reaching new audiences with their message, while increasing their own fame and associated patronage. Based on these findings, we propose some implications for the design of an appropriate folk music sharing and distribution service that addresses these various motivations of the musicians and listeners.
2011	Designing for emerging rural users: experiences from China	As part of IBM's Smarter Planet initiative, we studied information-sharing practices in rural Northern China to understand if and how ICT can help rural residents improve their lives. Interviews and participant observation in two villages showed a profusion of ICT devices, as well as an abundance of face-to-face information exchanges, but a shortage of localized and easily accessible information, and a deep dependence of many rural residents on 'information brokers' such as agricultural extension workers and shop owners. Can ICT support existing practices of information sharing among rural residents, when these practices are largely based on face-to-face encounters and passive reception of information? We argue that in such an environment, ICT should build on existing social habits even if less than ideal, rather than trying to transform them, and we outline a possible way to do so.
2011	Adapting usability testing for oral, rural users	Traditional usability methods are of limited use when evaluating systems designed for distant, diverse populations. In this paper, we describe a study conducted in two Ghanaian villages that evaluated an audio computer designed for people living in oral cultures. Informed by ICTD and orality-grounded HCID, we modified existing usability testing practices and we reflect on the utility of these adaptations. We found that conducting a culturally appropriate study often meant forgoing more traditional approaches in favor of flexible, opportunistic methods. We acknowledge the challenges of adapting traditional usability methods for oral, rural users. However, we found that by implementing strategic modifications led by local staff, our study produced valuable, actionable results.
2011	Evaluating video visualizations of human behavior	Previously, we presented Viz-A-Vis , a VI suali Z ation of A ctivity through computer VIS ion [17]. Viz-A-Vis visualizes behavior as aggregate motion over observation space. In this paper, we present two complementary user studies of Viz-A-Vis measuring its performance and discovery affordances. First, we present a controlled user study aimed at comparatively measuring behavioral analysis preference and performance for observation and search tasks. Second, we describe a study with architects measuring discovery affordances and potential impacts on their work practices. We conclude: 1) Viz-A-Vis significantly reduced search time; and 2) it increased the number and quality of insightful discoveries.
2011	Sizing up visualizations: effects of display size in focus+context, overview+detail, and zooming interfaces	Whereas the literature is clear on the benefits of large displays and visualizations, little is known about their combination, that is, how display size affect the usability of visualizations. We describe a controlled experiment where 19 participants used focus+context, overview+detail, and zooming techniques with varying display sizes (13.8, 1.5, and 0.17 megapixels). Participants navigated geographical maps to find specific locations, compare items, and follow routes. Results show that for multi-scale navigation, classic interactive visualization techniques did not benefit from being scaled to a large display: In contrast to the literature we find similar performance on medium and large displays. Across display sizes, overview+detail works the best, in particular for comparing items. Focus+context is relatively more difficult to use at a small display size. We explain these findings and discuss the design of interactive visualization techniques for large displays.
2011	The impact of social information on visual judgments	Social visualization systems have emerged to support collective intelligence-driven analysis of a growing influx of open data. As with many other online systems, social signals (e.g., forums, polls) are commonly integrated to drive use. Unfortunately, the same social features that can provide rapid, high-accuracy analysis are coupled with the pitfalls of any social system. Through an experiment involving over 300 subjects, we address how social information signals (social proof) affect quantitative judgments in the context of graphical perception. We identify how unbiased social signals lead to fewer errors over non-social settings and conversely, how biased signals lead to more errors. We further reflect on how systematic bias nullifies certain collective intelligence benefits, and we provide evidence of the formation of information cascades. We describe how these findings can be applied to collaborative visualization systems to produce more accurate individual interpretations in social contexts.
2011	Directing attention and influencing memory with visual saliency modulation	In augmented reality, it is often necessary to draw the user's attention to particular objects in the real world without distracting her from her task. We explore the effectiveness of directing a user's attention by imperceptibly modifying existing features of a video. We present three user studies of the effects of applying a saliency modulation technique to video; evaluating modulation awareness, attention, and memory. Our results validate the saliency modulation technique as an alternative means to convey information to the user, suggesting attention shifts and influencing recall of selected regions without perceptible changes to visual input.
2011	Freed: a system for creating multiple views of a digital collection during the design process	In this paper Freed is presented, a system that enables design students to spatially organize their digital collection, define relations between collection content and reflect on it. The system features a force-based layout that allows to explore spatial organizations, and hence to gain new insights. Its main advantage over existing software, is that it empowers the students to create different views of their digital collection. A view is a spatial organization of a selection of the collection content and its relations. It can e.g. be used for a specific design activity or project phase, for organizing work around a specific topic, or for explaining the perspective of a given student or stakeholder. Feedback of design students working with Freed during their design projects, and results from a workshop as measured by a questionnaire, show positive prospects for adoption of the system during the design process.
2011	Teenagers and their virtual possessions: design opportunities and issues	Over the past several years, people have increasingly acquired virtual possessions . We consider these things to include artifacts that are increasingly becoming immaterial (e.g. books, photos, music, movies) and things that have never traditionally had a lasting material form (e.g. SMS archives, social networking profiles, personal behavior logs). To date, little research exists about how people value and form attachments to virtual possessions. To investigate, we conducted a study with 21 teenagers exploring the perceived value of their virtual possessions, and the comparative similarities and differences with their material things. Findings are interpreted to detail design and research opportunities and issues in this emerging space.
2011	Life editing: third-party perspectives on lifelog content	Lifelog collections digitally capture and preserve personal experiences and can be mined to reveal insights and understandings of individual significance. These rich data sources also offer opportunities for learning and discovery by motivated third parties. We employ a custom-designed storytelling application in constructing meaningful lifelog summaries from third-party perspectives. This storytelling initiative was implemented as a core component in a university media-editing course. We present promising results from a preliminary study conducted to evaluate the utility and potential of our approach in creatively interpreting a unique experiential dataset.
2011	Metrics for the evaluation of news site content layout in large-screen contexts	Despite the fact that screen sizes and average screen resolutions have dramatically increased over the past few years, little attention has been paid to the design of web sites for large, high-resolution displays that are now becoming increasingly used both in enterprise and consumer spaces. We present a study of how the visual area of the browser window is currently utilised by news web sites at different widescreen resolutions. The analysis includes measurements of space taken up by the article content, embedded ads and the remaining components as they appear in the viewport of the web browser. The results show that the spatial distribution of page elements does not scale well with larger viewing sizes, which leads to an increasing amount of unused screen real estate and unnecessary scrolling. We derive a number of device-sensitive metrics to measure the quality of web page layout in different viewing contexts, which can guide the design of flexible layout templates that scale effectively on large screens.
2011	YouPivot: improving recall with contextual search	According to cognitive science literature, human memory is predicated on contextual cues (e.g., room, music) in the environment. During recall tasks, we associate information/activities/objects with contextual cues. However, computer systems do not leverage our natural process of using contextual cues to facilitate recall. We present a new interaction technique, Pivoting, that allows users to search for contextually related activities and find a target piece of information (often not semantically related). A sample motivation for contextual search would be, 'what was that website I was looking at when Yesterday by The Beatles was last playing?' Our interaction technique is grounded in the cognitive science literature, and is demonstrated in our system YouPivot. In addition, we present a new personal annotation method, called TimeMarks, to further support contextual recall and the pivoting process. In a pilot study, participants were quicker to identify websites, and preferred using YouPivot, compared to current tools. YouPivot demonstrates how principles of human memory can be applied to enhance the search of digital information.
2011	An examination of two delivery modes for interactive search system experiments: remote and laboratory	We compare two delivery modes for interactive search system (ISS) experiments: remote and laboratory. Our study was completed by two groups of subjects from the same population. The first group completed the study remotely and the second group completed the study in the laboratory. We compare differences in participants, participation behaviors, search behaviors and evaluation behaviors. Overall, for most measures no significant differences were found, but there were some notable differences. Greater variance was observed in time taken and number of documents opened and saved by remote subjects. Lab subjects provided more favorable responses to exit questionnaire items and reported significantly higher satisfaction. Lab subjects also provided significantly longer responses to open questions, while remote subjects provided more null responses. These results suggest that many behaviors do not change significantly according to study mode and that results from remote ISS experiments are similar to those from laboratory experiments.
2011	Review spotlight: a user interface for summarizing user-generated reviews using adjective-noun word pairs	Many people read online reviews written by other users to learn more about a product or venue. However, the overwhelming amount of user-generated reviews and variance in length, detail and quality across the reviews make it difficult to glean useful information. In this paper, we present the iterative design of our system, called Review Spotlight. It provides a brief overview of reviews using adjective-noun word pairs, and allows the user to quickly explore the reviews in greater detail. Through a laboratory user study which required participants to perform decision making tasks, we showed that participants could form detailed impressions about restaurants and decide between two options significantly faster with Review Spotlight than with traditional review webpages.
2011	Making spaces: how design workbooks work	In this paper, I discuss design workbooks , collections of design proposals and related materials, both as a method for design and as a design methodology. In considering them as a method, I describe a number of examples of design workbooks we have developed in our studio and describe some of the practical techniques we have used in developing them. More fundamentally, I discuss design workbooks as embodiments of a methodological approach which recognises that ideas may emerge slowly over time, that important issues and perspectives may emerge from multiple concrete ideas, potentially generated by multiple members of a team, rather than being theory-driven, and that maintaining the provisionality and vagueness of early proposals can be useful in supporting a quasi-participatory design approach that allows participants to interpret, react to and elaborate upon the ideas they present.
2011	Inspirational bits: towards a shared understanding of the digital material	In any design process, a medium's properties need to be considered. This is nothing new in design. Still we find that in HCI and interactive systems design the properties of a technology are often glossed over. That is, technologies are black-boxed without much thought given to how their distinctive properties open up design possibilities. In this paper we describe what we call inspirational bits as a way to become more familiar with the design material in HCI, the digital material. We describe inspirational bits as quick and dirty but fully working systems in both hardware and software built with the aim of exposing one or several of the dynamic properties of a digital material. We also show how they provide a means of sharing design knowledge across the members of a multi-disciplined design team.
2011	Don't drop it!: pick it up and storyboard	Storyboards offer designers a way to illustrate a narrative. Their creation can be enabled by tools supporting sketching or widget collections. As designers often incorporate previous ideas, we contribute the notion of blending the reappropriation of artifacts and their design tradeoffs with storyboarding. We present PIC-UP, a storyboarding tool supporting reappropriation, and report on two studies--a long-term investigation with novices and interviews with experts. We discuss how it may support design thinking, tailor to different expertise levels, facilitate reappropriation during storyboarding, and assist with communication.
2011	Rock & rails: extending multi-touch interactions with shape gestures to enable precise spatial manipulations	Direct touch manipulations enable the user to interact with the on-screen content in a direct and easy manner closely mimicking the spatial manipulations in the physical world. However, they also suffer from well-known issues of precision, occlusion and an inability to isolate different degrees of freedom in spatial manipulations. We present a set of interactions, called Rock & Rails, that augment existing direct touch manipulations with shape-based gestures, thus providing on-demand gain control, occlusion avoidance, and separation of constraints in 2D manipulation tasks. Using shape gestures in combination with direct-manipulations allows us to do this without ambiguity in detection and without resorting to manipulation handles, which break the direct manipulation paradigm. Our set of interactions were evaluated by 8 expert graphic designers and were found to be easy to learn and master, as well as effective in accomplishing a precise graphical layout task.
2011	Multi-touch document folding: gesture models, fold directions and symmetries	For document visualization, folding techniques provide a focus-plus-context approach with fairly high legibility on flat sections. To enable richer interaction, we explore the design space of multi-touch document folding. We discuss several design considerations for simple modeless gesturing and compatibility with standard Drag and Pinch gestures. We categorize gesture models along the characteristics of Symmetric/Asymmetric and Serial/Parallel, which yields three gesture models. We built a prototype document workspace application that integrates folding and standard gestures, and a system for testing the gesture models. A user study was conducted to compare the three models and to analyze the factors of fold direction, target symmetry, and target tolerance in user performance when folding a document to a specific shape. Our results indicate that all three factors were significant for task times, and parallelism was greater for symmetric targets.
2011	FingerGlass: efficient multiscale interaction on multitouch screens	Many tasks in graphical user interfaces require users to interact with elements at various levels of precision. We present FingerGlass, a bimanual technique designed to improve the precision of graphical tasks on multitouch screens. It enables users to quickly navigate to different locations and across multiple scales of a scene using a single hand. The other hand can simultaneously interact with objects in the scene. Unlike traditional pan-zoom interfaces, FingerGlass retains contextual information during the interaction. We evaluated our technique in the context of precise object selection and translation and found that FingerGlass significantly outperforms three state-of-the-art baseline techniques in both objective and subjective measurements: users acquired and translated targets more than 50\% faster than with the second-best technique in our experiment.
2011	An interactive multi-touch sketching interface for diffusion curves	Diffusion curves are effective 2D vector-graphics primitives, for creating smoothly-shaded drawings with rich colors and unique styles. Conventional drawing systems for diffusion curves often require users to successively layout curve geometry and then specify colors, which is rather tedious for complex drawings. This paper proposes a novel multi-touch sketching interface for efficient design of 2D vector graphics with diffusion curves. In sharp contrast to previous interfaces, we develop a family of multi-touch gestures, allowing users to simultaneously sketch multiple diffusion curves and also to interactively edit and tune curve geometry and colors. Our experiments show that this not only brings novel painting experience to users but also provides a practical and effective tool for vector graphics design, useful for styles like silk painting, Disney cartoon, art poster, and photo-realistic effects. Lastly, we conduct a user study to explore the interface's intuitive and efficient drawing capability with both professional 2D artists and novice users.
2011	Grids & guides: multi-touch layout and alignment tools	Precise alignment of graphical objects and the creation of accurate layouts are crucial activities in many applications, such as graphics design tools, presentation software or graph editors. Surface computing is very promising for these application domains but not fully explored yet. In this paper we contribute two tools which support layout tasks on interactive displays: interactive grids and multi-touch alignment guides. Both tools allow the precise positioning of graphical objects in a flexible and fluent way by multi-touch input. Direct bimanual interaction and physical metaphors are applied to arrange objects along straight lines and curves. A formative user evaluation showed promising results with regard to a productive and easy use of the tools.
2011	Fitt's law as an explicit time/error trade-off	The widely-held view that Fitts' law expresses a speed/accuracy trade-off is presumably correct, but it is vague. We outline a simple resource-allocation theory of Fitts' law in which movement time and error trade for each other. The theory accounts quite accurately for the data of Fitts' (1954) seminal study, as well as some fresh data of our own. In both data sets we found the time/error trade-off to obey a power law. Our data, which we could analyze more thoroughly than Fitts', are consistent with a square-root function with a single adjustable constant. We suggest that the resource-allocation framework should help combine information and energy considerations to allow a more complete account of Fitts' law.
2011	Benchmarking pointing techniques with distractors: adding a density factor to Fitts' pointing paradigm	Fitts' pointing paradigm is widely used to conduct controlled experiments and to evaluate new interaction techniques enhancing target acquisition. Many of them change the behavior of the cursor according to various inputs, most notably the positions of potential targets. We propose to extend Fitts' paradigm in order to challenge those techniques with distractors (i.e., potential targets which are not the goal of the user) in a controlled manner. To reduce variability, we add a single new factor to the paradigm, the distractor density. We specify a distractors distribution, fully determined by this factor together with those of Fitts' task, aimed at reducing bias toward a specific technique. We also propose a preliminary extension of Fitts' law to take account of the sensitivity to the density of distractors as well as of the task difficulty. In an experiment, we compare five existing pointing techniques, and show that this extended protocol enables contrasted comparisons between them.
2011	Surfpad: riding towards targets on a squeeze film effect	We present Surfpad, a pointing facilitation technique that does not decrease target distance or increase target width in either control or display space. This new technique operates instead in the tactile domain by taking advantage of the ability to alter a touchpad's coefficient of friction by means of a squeeze film effect. We report on three experiments comparing Surfpad to the Semantic Pointing technique and constant control-display gain with and without distractor targets. Our results clearly show the limits of traditional target-aware control-display gain adaptation in the latter case, and the benefits of our tactile approach in both cases. Surfpad leads to a performance improvement close to 9\% compared to unassisted pointing at small targets with no distractor. It is also robust to high distractor densities, keeping an average performance improvement of nearly 10\% while Semantic Pointing can degrade up to 100\%. Our results also suggest the performance improvement is caused by tactile information feedback rather than mechanical causes, and that the feedback is more effective when friction is increased on targets using a simple step function.
2011	Understanding touch	Current touch devices, such as capacitive touchscreens are based on the implicit assumption that users acquire targets with the center of the contact area between finger and device. Findings from our previous work indicate, however, that such devices are subject to systematic error offsets. This suggests that the underlying assumption is most likely wrong. In this paper, we therefore revisit this assumption. In a series of three user studies, we find evidence that the features that users align with the target are visual features. These features are located on the top of the user's fingers, not at the bottom, as assumed by traditional devices. We present the projected center model, under which error offsets drop to 1.6mm, compared to 4mm for the traditional model. This suggests that the new model is indeed a good approximation of how users conceptualize touch input. The primary contribution of this paper is to help understand touch-one of the key input technologies in human-computer interaction. At the same time, our findings inform the design of future touch input technology. They explain the inaccuracy of traditional touch devices as a -Sparallax- artifact between user control based on the top of the finger and sensing based on the bottom side of the finger. We conclude that certain camera-based sensing technologies can inherently be more accurate than contact area-based sensing.
2011	Magic desk: bringing multi-touch surfaces into desktop work	Despite the prominence of multi-touch technologies, there has been little work investigating its integration into the desktop environment. Bringing multi-touch into desktop computing would give users an additional input channel to leverage, enriching the current interaction paradigm dominated by a mouse and keyboard. We provide two main contributions in this domain. First, we describe the results from a study we performed, which systematically evaluates the various potential regions within the traditional desktop configuration that could become multi-touch enabled. The study sheds light on good or bad regions for multi-touch, and also the type of input most appropriate for each of these regions. Second, guided by the results from our study, we explore the design space of multi-touch-integrated desktop experiences. A set of new interaction techniques are coherently integrated into a desktop prototype, called Magic Desk, demonstrating potential uses for multi-touch enabled desktop configurations.
2011	Benefits of matching domain structure for planning software: the right stuff	We investigated the role of domain structure, in designing for software usefulness and usability. We ran through the whole application development cycle, in miniature, from needs analysis through design, implementation, and evaluation, for planning needs of one NASA Mission Control group. Based on our needs analysis, we developed prototype software that matched domain structure better than did the legacy system. We compared our new prototype to the legacy application in a laboratory, high-fidelity analog of the natural planning work. We found large performance differences favoring the prototype, which better captured domain structure. Our research illustrates the importance of needs analysis (particularly Domain Structure Analysis), and the viability of the design process that we are exploring.
2011	Developmentally situated design (DSD): making theoretical knowledge accessible to designers of children's technology	There is a wealth of theoretical knowledge about the developmental abilities and skills of children. However, this knowledge is not readily accessible to designers of interactive products. In this paper, we present the requirements, design and evaluation of developmentally situated design (DSD) cards. DSD cards are a design tool that makes age specific information about children's developing cognitive, physical, social, and emotional abilities readily accessible for designers. Initial requirements were elicited through interviews with design practitioners and students. The cards were evaluated through a design-in-use study in which design students used the cards to address three different design problems. Our analysis of observational notes and post-design interviews revealed how the cards' characteristics enabled different kinds of uses including framing, orienting, inspiring, informing, integrating and constraining. We conclude with a discussion of possible refinements and an analysis of the strengths and weaknesses of our approach.
2011	A spreadsheet-based user interface for managing plural relationships in structured data	A key feature of relational database applications is managing \emph{plural} relationships---one-to-many and many-to-many---between entities. However, since it is often infeasible to adopt or develop a new database application for any given schema at hand, information workers instead turn to spreadsheets, which lend themselves poorly to schemas requiring multiple related entity sets. In this paper, we propose to reduce the cost-usability gap between spreadsheets and tailor-made relational database applications by extending the spreadsheet paradigm to let the user establish relationships between rows in related worksheets as well as view and navigate the hierarchical cell structure that arises as a result. We present Related Worksheets, a spreadsheet-like prototype application, and evaluate it with a screencast-based user study on 36 Mechanical Turk workers. First-time users of our software were able to solve lookup-type query tasks with the same or higher accuracy as subjects using Microsoft Excel, in one case 40\% faster on average.
2011	Variation in importance of time-on-task with familiarity with mobile phone models	We studied the extent to which time-on-task is correlated with perception of usability for people who are familiar with a phone model and for those who are not. Our controlled experiment, conducted in Japan, correlated subjective usability assessments with time-on-task for expert and novice users on three different mobile phone models. We found that the correlation between perceived usability and time-on-task is stronger when participants are more familiar with the phone model. While not significant when initially inspecting a new phone model, a negative correlation between time-on-task and perceived usability becomes significant with as little as an hour's time doing tasks on the unfamiliar phone. This suggests that designing the UI to make time-on-task as short as possible may not have much effect on the purchase decision, but as experience increases, it may increase the loyalty of existing users.
2011	Some like it hot: thermal feedback for mobile devices	Thermal stimulation is a rich, emotive and salient feedback channel that is well suited to HCI, but one that is yet to be fully investigated. Thermal feedback may be suited to environments that are too loud for audio or too bumpy for vibrotactile feedback. This paper presents two studies into how well users could detect hot and cold stimuli presented to the fingertips, the palm, the dorsal surface of the forearm and the dorsal surface of the upper arm. Evaluations were carried out in static and mobile settings. Results showed that the palm is most sensitive, cold is more perceivable and comfortable than warm and that stronger and faster-changing stimuli are more detectable but less comfortable. Guidelines for the design of thermal feedback are outlined, with attention paid to perceptual and hedonic factors.
2011	HeatWave: thermal imaging for surface user interaction	We present HeatWave, a system that uses digital thermal imaging cameras to detect, track, and support user interaction on arbitrary surfaces. Thermal sensing has had limited examination in the HCI research community and is generally under-explored outside of law enforcement and energy auditing applications. We examine the role of thermal imaging as a new sensing solution for enhancing user surface interaction. In particular, we demonstrate how thermal imaging in combination with existing computer vision techniques can make segmentation and detection of routine interaction techniques possible in real-time, and can be used to complement or simplify algorithms for traditional RGB and depth cameras. Example interactions include (1) distinguishing hovering above a surface from touch events, (2) shape-based gestures similar to ink strokes, (3) pressure based gestures, and (4) multi-finger gestures. We close by discussing the practicality of thermal sensing for naturalistic user interaction and opportunities for future work.
2011	AnglePose: robust, precise capacitive touch tracking via 3d orientation estimation	We present a finger-tracking system for touch-based interaction which can track 3D finger angle in addition to position, using low-resolution conventional capacitive sensors, therefore compensating for the inaccuracy due to pose variation in conventional touch systems. Probabilistic inference about the pose of the finger is carried out in real-time using a particle filter; this results in an efficient and robust pose estimator which also gives appropriate uncertainty estimates. We show empirically that tracking the full pose of the finger results in greater accuracy in pointing tasks with small targets than competitive techniques. Our model can detect and cope with different finger sizes and the use of either fingers or thumbs, bringing a significant potential for improvement in one-handed interaction with touch devices. In addition to the gain in accuracy we also give examples of how this technique could open up the space of novel interactions.
2011	TouchCuts and TouchZoom: enhanced target selection for touch displays using finger proximity sensing	Although touch-screen laptops are increasing in popularity, users still do not comfortably rely on touch in these environments, as current software interfaces were not designed for being used by the finger. In this paper, we first demonstrate the benefits of using touch as a complementary input modality along with the keyboard and mouse or touchpad in a laptop setting. To alleviate the frustration users experience with touch, we then design two techniques, TouchCuts , a single target expansion technique, and ,i>TouchZoom,/i>, a multiple target expansion technique. Both techniques facilitate the selection of small icons, by detecting the finger proximity above the display surface, and expanding the target as the finger approaches. In a controlled evaluation, we show that our techniques improve performance in comparison to both the computer mouse and a baseline touch-based target acquisition technique. We conclude by discussing other application scenarios that our techniques support.
2011	Of passwords and people: measuring the effect of password-composition policies	Text-based passwords are the most common mechanism for authenticating humans to computer systems. To prevent users from picking passwords that are too easy for an adversary to guess, system administrators adopt password-composition policies (e.g., requiring passwords to contain symbols and numbers). Unfortunately, little is known about the relationship between password-composition policies and the strength of the resulting passwords, or about the behavior of users (e.g., writing down passwords) in response to different policies. We present a large-scale study that investigates password strength, user behavior, and user sentiment across four password-composition policies. We characterize the predictability of passwords by calculating their entropy, and find that a number of commonly held beliefs about password composition and strength are inaccurate. We correlate our results with user behavior and sentiment to produce several recommendations for password-composition policies that result in strong passwords without unduly burdening users.
2011	MARASIM: a novel jigsaw based authentication scheme using tagging	In this paper we propose and evaluate Marasim , a novel Jigsaw based graphical authentication mechanism using tagging. Marasim is aimed at achieving the security of random images with the memorability of personal images. Our scheme relies on the human ability to remember a personal image and later recognize the alternate visual representations (images) of the concepts occurred in the image. These concepts are retrieved from the tags assigned to the image. We illustrate how a Jigsaw based approach helps to create a portfolio of system-chosen random images to be used for authentication. The paper describes the complete design of Marasim along with the empirical studies of Marasim that provide evidences of increased memorability. Results show that 93\% of all participants succeeded in the authentication tests using Marasim after three months while 71\% succeeded in authentication tests using Marasim after nine months. Our findings indicate that Marasim has potential applications, especially where text input is hard (e.g., PDAs or ATMs), or in situations where passwords are infrequently used (e.g., web site passwords).
2011	Exploring implicit memory for painless password recovery	Knowledge-based authentication systems generally rely upon users' explicit recollection of passwords, facts, or personal preferences. These systems impose a cognitive burden that often results in forgotten secrets or secrets with poor entropy. We propose an authentication system that instead draws on implicit memory - that is, the unconscious encoding and usage of information. In such a system, a user is initially presented with images of common objects in a casual familiarization task. When the user later authenticates, she is asked to perform a task involving a set of degraded images, some of which are based upon the images in the familiarization task. The prior exposure to those images influences the user's responses in the task, thereby eliciting authentication information. We ran a user study to investigate the plausibility of our system design. Our results suggest that implicit memory has potential as a basis for low-cognitive-overhead, high-stability, knowledge-based authentication.
2011	Self-reported password sharing strategies	This paper contributes to the growing body of literature on privacy and security by looking at self-reported password sharing practices. 62 men and 60 women recruited through a combination of snowball sampling and small ads answered a series of open-ended questions about their password sharing strategies. One third of respondants shared their personal email password, and a quarter shared their Facebook password, both primarily with partners and close friends. Approximately 20\% of people who had work email passwords reported sharing them with colleagues. These results support understanding password sharing not as a deviant practice to be stamped out, but rather a nuanced practice engaged in with thought and care.
2011	On the necessity of user-friendly CAPTCHA	A "Completely Automated Public Turing test to tell Computers and Humans Apart" (CAPTCHA) is a mechanism widely used nowadays for protection of web applications, interfaces, and services from malicious users. A questionnaire-based survey combined with a real usage scenario of a native-language CAPTCHA mechanism was conducted in order to investigate several aspects that affect end-user perceptions related to the quality of CAPTCHA. A total of 210 participants of age between 19 and 64 participated during May and July 2010. The survey results validate the common belief that CAPTCHAs are still difficult for humans to solve. They also provide insights that can be applied to improve users' experience on interacting with CAPTCHA systems.
2011	A diary study of password usage in daily life	While past work has examined password usage on a specific computer, web site, or organization, there is little work examining overall password usage in daily life. Through a diary study, we examine all usage of passwords, and offer some new findings based on quantitative analyses regarding how often people log in, where they log in, and how frequently people use foreign computers. Our analysis also confirms or updates existing statistics about password usage patterns. We also discuss some implications for design as well as security education.
2011	Understanding people and animals: the use of a positioning system in ordinary human-canine interaction	Animals are increasingly integrated in interactive contexts depending on digital technologies. The current and future use of such technologies is a relevant topic for HCI research. However, the field is struggling with the inherent problem of 'nteraction' in understanding interaction with animals. We argue for a way forward based on an ethnomethodological perspective on anthropomorphism, with a focus on manifest interaction. Drawing upon a field study of hunters' use of a GPS dog tracking-device, we discuss how interaction between dogs and humans is affected when new technology is introduced. The GPS data is situated and interpreted by the dog handler, and supports the hunter's work of dealing with the dogs' intentions. This opens up for new forms of interactions with the dog. When studying and designing for interaction between humans and animals we should move beyond merely looking at dyadic relationships, and also consider the social organization of the interaction.
2011	Communication technology for human-dog interaction: exploration of dog owners' experiences and expectations	Whereas communication technology to connect people has long been an integral part of our everyday lives, it has only recently expanded to offer applications for dogs and dog-owners. In this paper, we present two explorative studies to understand the experiences and expectations of dog owners for communication technology to support their interaction with dogs. These studies look at two different user groups, hunters and pet owners, charting the lessons learnt from the current technology and exploring the aspects that should be taken into account when designing future applications and services. Our findings reveal that usability problems are still the dominant issue with current applications. We also suggest key design implications which can be utilized in the development of future human-dog interaction systems.
2011	Designing sports: a framework for exertion games	Exertion games require investing physical effort. The fact that such games can support physical health is tempered by our limited understanding of how to design for engaging exertion experiences. This paper introduces the Exertion Framework as a way to think and talk about Exertion Games, both for their formative design and summative analysis. Our Exertion Framework is based on the ways in which we can conceive of the body investing in game-directed exertion, supported by four perspectives on the body (the Responding Body, Moving Body, Sensing Body and Relating Body) and three perspectives on gaming (rules, play and context). The paper illustrates how this framework was derived from prior systems and theory, and presents a case study of how it has been used to inspire novel exertion interactions.
2011	Cat cat revolution: an interspecies gaming experience	Despite owners' desires to include pets in their everyday activities, pets have yet to be included in the digital gaming experience. The Cat Cat Revolution (CCR) is a digital game of cat and mouse that allows cats to participate in play through a species-appropriate interface. The game applies Human-Computer Interaction (HCI) principles to pets and casts pets as participants in the gaming experience. During the pilot study, pet owners characterized CCR as a mutually positive experience, describing the game as a fun way to play. CCR explores the effects of including pets in the digital gaming experience.
2011	Antiquarian answers: book restoration as a resource for design	As technologies age, they experience wear and degradation, sometimes resulting in loss of functionality. In response, parts are replaced and software is updated. Yet restoration - the process of returning something to a previous condition, often regardless of its instrumental value -"is a relatively rare practice with computational technologies. The aim of this paper is to enrich HCI design practices by considering the material qualities of restoration. We consider what makes a technology worth restoring and what constitutes the process of restoration by examining data collected from a three-month apprenticeship-based qualitative study of bookbinding. Building on relevant literatures, we offer antiquarian books -"long-established information technologies - as a lens onto the ways values are enacted through material engagements. We conclude with a discussion of restoration's role in HCI.
2011	Which version is this?: improving the desktop experience within a copy-aware computing ecosystem	Computers today make it easy for people to scatter copies and versions of digital items across their file systems, but do little to help people manage the resulting mess. In this paper, we introduce the concept of a copy-aware computing ecosystem, inspired by a vision of computing when systems track and surface copy relationships between files. Based on two deployments of a copy-aware software prototype and in-depth interviews with individuals in collaborative relationships, we present our findings on the origins of copies and the barriers to eliminating them, but offer a promising solution based on the set of files that together represent a user's conceptual view of a document - the versionset. We show that the versionset is viable to infer, and we draw upon user activity logs and feedback on personalized views of versionsets to distill guidelines for the factors that define a versionset. We conclude by enumerating the many PIM user experiences that could be transformed as a result.
2011	Enticing consumers via incomplete product experience: an investigation of online product interactivity designs	This paper reports on two studies that investigate the design of online product interactivity. The first study compares three different presentation formats: a video presentation and two Virtual Product Experience (VPE) presentations, namely, triggered interaction and full interaction. The findings suggest that triggered interaction VPE is more effective in enticing users to attend to and further explore the featured products than both the non-interactive video presentation and the full interaction VPE. The second study builds upon the first and focuses on two specific VPE design factors. In particular, it investigates interaction constraint (high versus low constraint) in addition to the activation mode of interaction (process-based interaction versus event-based interaction). The results reveal interesting interaction patterns between the two design factors, i.e., providing less constrained interaction performs better when process-based interaction design is adopted, but performs worse when event-based interaction is employed.
2011	Old wine in new bottles or novel challenges: a critical analysis of empirical studies of user experience	This paper reviews how empirical research on User Experience (UX) is conducted. It integrates products, dimensions of experience, and methodologies across a systematically selected sample of 51 publications from 2005-2009, reporting a total of 66 empirical studies. Results show a shift in the products and use contexts that are studied, from work towards leisure, from controlled tasks towards open use situations, and from desktop computing towards consumer products and art. Context of use and anticipated use, often named key factors of UX, are rarely researched. Emotions, enjoyment and aesthetics are the most frequently assessed dimensions. The methodologies used are mostly qualitative, and known from traditional usability studies, though constructive methods with unclear validity are being developed and used. Many studies use self-developed questionnaires without providing items or statistical validations. We discuss underexplored research questions and potential improvements of UX research.
2011	Perceptual analysis of talking avatar head movements: a quantitative perspective	Lifelike interface agents (e.g. talking avatars) have been increasingly used in human-computer interaction applications. In this work, we quantitatively analyze how human perception is affected by audio-head motion characteristics of talking avatars. Specifically, we quantify the correlation between perceptual user ratings (obtained via user study) and joint audio-head motion features as well as head motion patterns in the frequency-domain. Our quantitative analysis results clearly show that the correlation coefficient between the pitch of speech signals (but not the RMS energy of speech signals) and head motions is approximately linearly proportional to the perceptual user rating, and a larger proportion of high frequency signals in talking avatar head movements tends to degrade the user perception in terms of naturalness.
2011	Diminishing returns?: revisiting perception of computing performance	The computing performance literature offers guidelines and frameworks, but data on the limits of user appreciation for performance are scarce. This paper presents a study of user satisfaction with different levels of computing performance. Thirty-five participants performed common computing tasks such as creating email and Web surfing. They rated computing performance for specific task elements - such as application launching and menu responsiveness - that occurred during those tasks. They repeated the tasks under varying levels of computer performance. Results include user ratings as a function of computing performance for each of the task elements. The results have implications for system designers who create products that must meet user expectations for performance.
2011	ShadowPuppets: supporting collocated interaction with mobile projector phones using hand shadows	Pico projectors attached to mobile phones allow users to view phone content using a large display. However, to provide input to projector phones, users have to look at the device, diverting their attention from the projected image. Additionally, other collocated users have no way of interacting with the device. We present ShadowPuppets, a system that supports collocated interaction with mobile projector phones. ShadowPuppets allows users to cast hand shadows as input to mobile projector phones. Most people understand how to cast hand shadows, which provide an easy input modality. Additionally, they implicitly support collocated usage, as nearby users can cast shadows as input and one user can see and understand another user's hand shadows. We describe the results of three user studies. The first study examines what hand shadows users expect will cause various effects. The second study looks at how users perceive hand shadows, examining what effects they think various hand shadows will cause. Finally, we present qualitative results from a study with our functional prototype and discuss design implications for systems using shadows as input. Our findings suggest that shadow input can provide a natural and intuitive way of interacting with projected interfaces and can support collocated collaboration.
2011	DoubleFlip: a motion gesture delimiter for mobile interaction	To make motion gestures more widely adopted on mobile devices it is important that devices be able to distinguish between motion intended for mobile interaction and every-day motion. In this paper, we present DoubleFlip, a unique motion gesture designed as an input delimiter for mobile motion-based interaction. The DoubleFlip gesture is distinct from regular motion of a mobile device. Based on a collection of 2,100 hours of motion data captured from 99 users, we found that our DoubleFlip recognizer is extremely resistant to false positive conditions, while still achieving a high recognition rate. Since DoubleFlip is easy to perform and unlikely to be accidentally invoked, it provides an always-active input event for mobile interaction.
2011	Multi-user interaction on media facades through live video on mobile devices	The increasing number of media facades in urban spaces offers great potential for new forms of interaction especially for collaborative multi-user scenarios. In this paper, we present a way to directly interact with them through live video on mobile devices. We extend the Touch Projector interface to accommodate multiple users by showing individual content on the mobile display that would otherwise clutter the facade's canvas or distract other users. To demonstrate our concept, we built two collaborative multi-user applications: (1) painting on the facade and (2) solving a 15-puzzle. We gathered informal feedback during the ARS Electronica Festival in Linz, Austria and found that our interaction technique is (1) considered easy-to-learn, but (2) may leave users unaware of the actions of others.
2011	Interaction with magic lenses: real-world validation of a Fitts' Law model	Rohs and Oulasvirta (2008) proposed a two-component Fitts' law model for target acquisition with magic lenses in mobile augmented reality (AR) with 1) a physical pointing phase, in which the target can be directly observed on the background surface, and 2) a virtual pointing phase, in which the target can only be observed through the device display. The model provides a good fit (R 2 =0.88) with laboratory data, but it is not known if it generalizes to real-world AR tasks. In the present outdoor study, subjects (N=12) did building-selection tasks in an urban area. The differences in task characteristics to the laboratory study are drastic: targets are three-dimensional and they vary in shape, size, z-distance, and visual context. Nevertheless, the model yielded an R 2 of 0.80, and when using effective target width an R 2 of 0.88 was achieved.
2011	Xpaaand: interaction techniques for rollable displays	We present a device concept and a prototype of a future mobile device. By featuring a rollable display, its display size and its form factor can be dynamically changed. Moreover, we investigate how physical resizing of the display can be used as an input technique for interacting with digital contents and present a set of novel interaction techniques. Evaluation results show that physical resizing of the display can improve the way we interact with digital contents on mobile devices.
2011	TapBack: towards richer mobile interfaces in impoverished contexts	Much of the mobile work by HCI researchers explores a future world populated by high-end devices and relatively affluent users. This paper turns to consider the hundreds of millions of people for whom such sophistication will not be realised for many years to come. In developing world contexts, people will continue to rely on voice-primary interactions due to both literacy and economic reasons. Here, we motivate research into how to accommodate advanced mobile interface techniques while overcoming the handset, data-connection and user limitations. As a first step we introduce TapBack: back-of-device taps to control a dialled-up, telephone-network-based voice service. We show how these audio gestures might be recognised over a standard telephone connection, via users' existing low-end devices. Further, in a longitudinal deployment, the techniques were made available on a live voice service used by rural Indian farmers. Data from the study illustrates the desire by users to adopt the approach and its potential extensions.
2011	ClearPlate for capturing printed information: a scanner and viewfinder in one optical unit	As it is becoming more common for various handheld devices to be equipped with a camera, applications that use image recognition are increasing. Therefore, improving the usability of these devices by enhancing their image capture characteristics is becoming more important. We present ClearPlate - a new optical unit for image capture. It has a physically transparent viewfinder through which the user can observe the target directly without offset; the framed image is captured by the built-in camera. We also present a user study that evaluates ClearPlate performance in the 2D barcode acquisition task. Results show that ClearPlate significantly outperforms the camera-phone-based approach with regard to 2D barcode acquisition.
2011	Dips and ceilings: understanding and supporting transitions to expertise in user interfaces	Interface guidelines encourage designers to include shortcut mechanisms that enable high levels of expert performance, but prior research has demonstrated that few users switch to using them. To help understand how interfaces can better support a transition to expert performance we develop a framework of the interface and human factors influencing expertise development. We then present a system called Blur that addresses three main problems in promoting the transition: prompting an initial switch to expert techniques, minimising the performance dip arising from the switch, and enabling a high performance ceiling. Blur observes the user's interaction with unaltered desktop applications and uses calm notification to support learning and promote awareness of an alternative hot command interface. An empirical study validates Blur's design, showing that users make an early and sustained switch to hot commands, and that doing so improves their performance and satisfaction.
2011	Ambient help	In this paper we present Ambient Help, a system that supports opportunistic learning by providing automatic, context-sensitive learning resources while a user works. Multiple videos and textual help resources are presented ambiently on a secondary display. We define and examine a collection of design consideration for this type of interface. After describing our implementation details, we report on an experiment which shows that Ambient Help supports finding more helpful information, while not having a negative impact on the user's productivity, as compared to a traditional help condition.
2011	Parameter selection in keyboard-based dialog boxes	Recent keyboard-based alternatives to WIMP interfaces do not have good support for commands that require multiple parameters. We remedy this by extending a previous design and mimicking dialog boxes to provide good visual feedback while still keeping the advantages of keyboard input. A laboratory study showed the new technique to be competitive with dialog boxes on speed and error rate, but strongly preferred over dialog boxes by experienced command line users. This is a marked improvement over the previous design, which was also preferred by the target user group but did not compete with dialog boxes in terms of performance.
2011	Categorization costs for hierarchical keyboard commands	Previous research comparing methods of issuing commands found that selecting a toolbar item is faster than selecting an item from two menus with either a mouse or keyboard shortcut. Over the course of 90 trials, however, the keyboard method showed the most improvement, nearing the toolbar response time. The study presented in this paper compared the response time of the keyboard method across 240 trials when items were drawn from a single versus two menus. Throughout the trials, the 1-menu condition produced selection times that were on average 600 ms to 800 ms faster than the 2-menu condition suggesting users in the 2-menu condition were not able to bypass the menu decision by chunking the 3-key sequence into one cognitive unit. Models are presented to describe performance at various stages of learning. Practical implications are that hierarchical, category-based keyboard commands do not provide a clear advantage to toolbar-based selection and that theory-based evaluation methods may need to reflect this result.
2011	Sasayaki: augmented voice web browsing experience	Auditory user interfaces have great Web-access potential for billions of people with visual impairments, with limited literacy, who are driving, or who are otherwise unable to use a visual interface. However a sequential speech-based representation can only convey a limited amount of information. In addition, typical auditory user interfaces lose the visual cues such as text styles and page structures, and lack effective feedback about the current focus. To address these limitations, we created Sasayaki (from whisper in Japanese), which augments the primary voice output with a secondary whisper of contextually relevant information, automatically or in response to user requests. It also offers new ways to jump to semantically meaningful locations. A prototype was implemented as a plug-in for an auditory Web browser. Our experimental results show that the Sasayaki can reduce the task completion times for finding elements in webpages and increase satisfaction and confidence.
2011	On the audio representation of radial direction	We present and evaluate an approach towards eyes-free auditory display of spatial information that considers radial direction as a fundamental type of value primitive. There are many benefits to being able to sonify radial directions, such as indicating the heading towards a point of interest in a direct and dynamic manner, rendering a path or shape outline by sonifying a continual sequence of tangent directions as the path is traced, and providing direct feedback of the direction of motion of the user in a physical space or a pointer in a virtual space. We propose a concrete mapping of vowel-like sounds to radial directions as one potential method to enable sonification of such information. We conducted a longitudinal study with five sighted and two blind participants to evaluate the learnability and effectiveness of this method. Results suggest that our directional sound mapping can be learned within a few hours and be used to aurally perceive spatial information such as shape outlines and path contours.
2011	Multidimensional gesture sensing at the piano keyboard	In this paper we present a new keyboard interface for computer music applications. Where traditional keyboard controllers report the velocity of each key-press, our interface senses up to five separate dimensions: velocity, percussiveness, rigidity, weight, and depth. These dimensions, which we identified based on the pedagogical piano literature and pilot studies with professional pianists, together present a rich picture of physical gestures at the keyboard, including information on the performer's motion before, during, and after a note is played. User studies confirm that the sensed dimensions are intuitive and controllable and that mappings between gesture and sound produce novel, playable musical instruments, even for users without prior keyboard experience. The multidimensional sensing capability demonstrated in this paper is also potentially applicable to button interfaces outside the musical domain.
2011	Spatialized sound enhances biomechanically-induced self-motion illusion (vection)	The use of vection, the illusion of self-movement, has recently been explored as a novel way to immerse observers in mediated environments through illusory yet compelling self-motion without physically moving. This provides advantages over existing systems that employ costly, cumbersome, and potentially hazardous motion platforms, which are often surprisingly inadequate to provide life-like motion experiences. This study investigates whether spatialized sound rotating around the stationary, blindfolded listener can facilitate biomechanical vection, the illusion of self-rotation induced by stepping along a rotating floor plate. For the first time, integrating simple auditory and biomechanical cues for turning in place evoked convincing circular vection. In an auditory baseline condition, participants experienced only spatialized auditory cues. In a purely biomechanical condition, seated participants stepped along sideways on a rotating plate while listening to mono masking sounds. Scores of the bi-modal condition (binaural+biomechanical cues) exceeded the sum of both single cue conditions, which may imply super-additive or synergistic effects.
2011	Name that tune: musicons as reminders in the home	In this paper we argue that Musicons, short samples from pieces of music are a useful way to present private but memorable reminder messages. We investigated accuracy, memorability and response times for short, medium, and long Musicons. User performance on the Musicons was also compared to short spoken reminders. The study consisted of two sessions a week apart. Quantitative measures were augmented with qualitative questions about associations and memories. Overall, participants achieved a high level of accuracy (89\%) on the Musicons. Recognition was stable at 90\% or better across sessions for users who were able to construct meaningful links between Musicons and the associated tasks. Optimal response times were achieved for medium-length 0.5 sec. Musicons. We conclude that Musicons are a viable option for alarms and notifications that combine the high learnability of Auditory Icons with the more private nature of Earcons.
2011	Prototyping dynamics: sharing multiple designs improves exploration, group rapport, and results	Prototypes ground group communication and facilitate decision making. However, overly investing in a single design idea can lead to fixation and impede the collaborative process. Does sharing multiple designs improve collaboration? In a study, participants created advertisements individually and then met with a partner. In the Share Multiple condition, participants designed and shared three ads. In the Share Best condition, participants designed three ads and selected one to share. In the Share One condition, participants designed and shared one ad. Sharing multiple designs improved outcome, exploration, sharing, and group rapport. These participants integrated more of their partner's ideas into their own subsequent designs, explored a more divergent set of ideas, and provided more productive critiques of their partner's designs. Furthermore, their ads were rated more highly and garnered a higher click-through rate when hosted online.
2011	Enhancing genomic learning through tabletop interaction	We present G-nome Surfer 2.0, a tabletop interface for fostering inquiry-based learning of genomics. We conducted an experimental study with 48 participants that compared students' learning of genomic concepts using existing bioinformatics tools and using two alternative implementations of G-nome Surfer: a collaborative multi-mouse GUI and a tabletop interface. Our findings indicate that G-nome Surfer improves students' performance, reduces workload, and increases enjoyment. The comparison of tabletop and multi-mouse implementations further shows that the tabletop condition results in four educational benefits: 1) increasing physical participation, 2) encouraging reflection, 3) fostering effective collaboration, and 4) facilitating more intuitive interaction.
2011	Supporting fluid tabletop collaboration across distances	In this study, we examine how remote collaborators' upper body view affects collaboration when people engage in multiparty fluid tabletop activities across distances. We experimentally investigated the effects of upper body view on four-person group tabletop collaboration, two-by-two at identical locations: shared tabletop vs. shared tabletop plus upper body view. Although previous research has often failed to illustrate the advantages of showing remote participants' upper body view, our study showed that task performance was significantly higher in conditions with upper body view. Furthermore, participants with upper body view tended to take a step away from their remote partners to effectively glance at them while taking a comparable perspective of the tabletop objects. Detailed analysis of the video recordings revealed that upper body view was effective for fluid tabletop collaboration because it helped achieve joint perspective and helped estimate the timing and rough location of subsequent tabletop activity.
2011	Effects of community size and contact rate in synchronous social q&a	Social question-and-answer (Q&A) involves the location of answers to questions through communication with people. Social Q&A systems, such as mailing lists and Web forums are popular, but their asynchronous nature can lead to high answer latency. Synchronous Q&A systems facilitate real-time dialog, usually via instant messaging, but face challenges with interruption costs and the availability of knowledgeable answerers at question time. We ran a longitudinal study of a synchronous social Q&A system to investigate the effects of the rate with which potential answerers were contacted (trading off time-to-answer against interruption cost) and community size (varying total number of members). We found important differences in subjective and objective measures of system performance with these variations. Our findings help us understand the costs and benefits of varying contact rate and community size in synchronous social Q&A, and inform system design for social Q&A.
2011	Redesign as an act of violence: disrupted interaction patterns and the fragmenting of a social Q&A community	The worst-case scenario for the redesign of an established online community is a subsequent mass migration of its core members to other sites. Using data from transaction logs, content analysis and participant observation, this paper presents a descriptive analysis of the fragmentation of a social question answering (Q&A) community in the immediate aftermath of a fundamental redesign, where site-based communication mechanisms no longer functioned. The ways in which the community and its diaspora reacted, reconnected and resettled on other sites provides empirical data to support recent research on the life cycle of online communities. The results suggest that many of the same processes that help social Q&A sites generate content and motivate participation can work to dismantle an established community if communications between members are even temporarily disrupted. Modeling a redesign as an attack on a community can help future designers anticipate alternative paths of communication and information flows.
2011	Design lessons from the fastest q&a site in the west	This paper analyzes a Question & Answer site for programmers, Stack Overflow, that dramatically improves on the utility and performance of Q&A systems for technical domains. Over 92\% of Stack Overflow questions about expert topics are answered - in a median time of 11 minutes. Using a mixed methods approach that combines statistical data analysis with user interviews, we seek to understand this success. We argue that it is not primarily due to an a priori superior technical design, but also to the high visibility and daily involvement of the design team within the community they serve. This model of continued community leadership presents challenges to both CSCW systems research as well as to attempts to apply the Stack Overflow model to other specialized knowledge domains.
2011	Towards a design model for women's empowerment in the developing world	Pulitzer Prize-winning journalist Nicholas Kristof argues that in this century the paramount moral challenge will be the struggle for gender equality around the world. In this paper, we present a design model for empowering low-income women in the developing world, in ways that cut across individual application areas. Specifically, this model characterizes a possible trajectory for NGOs and women to engage with each other and among themselves potentially augmented by technology to help women escape from poverty. The fieldwork components in this study took place over 15 weeks in three phases, with a total of 47 NGO staff members and 35 socio-economically challenged women in rural and urban India. Interviews and co-design sessions with seven proof-of-concept prototypes showed that women appeared to belong to five distinct stages of growth in striving towards independence. We report the technology design lessons from our co-design sessions to illustrate how user readiness, relationship building at the community and family levels, and integration with state, national and international level programs, should be taken into account in the broader context of intervention design.
2011	Reuse in the wild: an empirical and ethnographic study of organizational content reuse	We present a large-scale study of content reuse networks in a large and highly hierarchical organization. In our study, we combine analysis of a collection of presentations produced by employees with interviews conducted throughout the organization and a survey to study presentation content reuse. Study results show a variety of information needs and behaviors related to content reuse as well as a need for a personalized and socially-integrated networking tool for enabling easy access to previously generated presentation material. In this paper we describe our findings and outline a set of requirements for an effective content reuse facility.
2011	Do you know dis?: a user study of a knowledge discovery tool for organizations	Organisations today have no reliable way of ensuring that all employees are aware of information that may be relevant to their work. In this paper we report on a 2-year project in which we have iteratively designed, developed and tested a knowledge discovery system (KnowDis) for organizations. Early stages of our study revealed that, employees do not know what is available on the corporate intranet, or files and messages they have stored. KnowDis proactively fetches relevant information and displays it in an unobtrusive form; this increases employee awareness without disrupting their tasks. We discuss and characterize knowledge workers' email usage behavior. Our main study with 28 users of KnowDis-enhanced email showed it can improve the user experience and performance on information retrieval tasks for knowledge workers.
2011	What's in a move?: normal disruption and a design challenge	The CHI community has led efforts to support teamwork, but has neglected team disruption, as may occur if team members relocate to another institution. We studied moves in 548 interdisciplinary research projects with 2691 researchers (PIs). Moves, and thus disruptions, were not rare, especially in large distributed projects. Overall, one-third of all projects experienced at least one member relocating but most moves reflected churn across high-ranking institutions. When collaborators moved, the project was disrupted. Our data suggest that moves exemplify normal disruptions. A design challenge is to help projects adapt to disruption.
2011	Finders/keepers: a longitudinal study of people managing information scraps in a micro-note tool	Mainstream PIM tools capture only a portion of the information that people need to manage. Many information scraps seem to exist that don't make their way into these tools, instead being relegated to sticky notes, text files, and other makeshift storage, or simply being lost. In an effort to understand the role of these information scraps, the underlying needs they reflect, and the way PIM tools must be modified to support those needs, we created List-it, a micronote tool for quick and simple capture of information scraps. In this article, we analyze the notes and interaction logs of 420 volunteer users of List-it over a two-year period of study (August 2008-August 2010). We contextualize our analysis with results of two surveys and an e-mail interview we conducted in October 2009. We find that people are drawn to List-it by the ease and speed of note capture and by the ability to record scraps with arbitrary content that blends or completely escapes the types and roles imposed by our rigid PIM tools. Notes are taken to serve a variety of needs -- reminding, reference, journaling/activity logging, brainstorming, and to indefinitely archive information of sentimental or personal value. Finally, while people differ considerably in the ways they keep information, our findings suggest such differences can be described as a combination of four distinct strategies, enriching the Filer/Piler distinction identified for classic document management.
2011	The imposition and superimposition of digital reading technology: the academic potential of e-readers	While rapid growth in e-reader use is receiving much attention in industry and academia, the use of e-readers for academic reading remains understudied. This qualitative study investigates how graduate students accomplish their academic reading and integrate an e-reader into their reading practices. Our work represents the first long-term study of e-reading on a production device (the Amazon Kindle DX). In this paper we contribute new knowledge to the discussion of the academic potential of e-readers by analyzing the meta-level relationship between reading tasks and associated reading techniques, students' compensation for the limitations of e-readers, and the hindrance of the human ability to construct cognitive maps of texts when using e-readers.
2011	Active reading and its discontents: the situations, problems and ideas of readers	The increasing popularity of personal reading devices raises the question of how best to support so-called active reading, which involves acts like annotation, note taking, etc. Prior research addressed this question by observing the active reading process, and identifying disparities between computers and paper as a reading medium. We extend this research by 1) investigating the problems that readers experience in their real world tasks, 2) inquiring about their requirements for an ideal reading technology, and 3) updating earlier studies of naturalistic reading behavior, which are several years old now. We present here the results of our investigation, which included a diary study, interviews, and participatory design workshops.
2011	Exploratory evaluations of a computer game supporting cognitive behavioural therapy for adolescents	The need to provide effective mental health treatments for adolescents has been described as a global public health challenge [27]. In this paper we discuss the exploratory evaluations of the first adolescent intervention to fully integrate a computer game implementing Cognitive Behavioural Therapy. Three distinct studies are presented: a detailed evaluation in which therapists independent of the design team used the game with 6 adolescents experiencing clinical anxiety disorders; a study in which a member of the design team used the game with 15 adolescents; and finally a study assessing the acceptability of the game and intervention with 216 practicing therapists. Findings are presented within the context of a framework for the design and evaluation of complex health interventions. The paper provides an in-depth insight into the use of therapeutic games to support adolescent interventions and provides stronger evidence than previously available for both their effectiveness and acceptability to stakeholders.
2011	In the mood: engaging teenagers in psychotherapy using mobile phones	Mental illness is a significant and growing problem throughout the world. Many mental health problems have their root in childhood, and early intervention is recommended. Engaging young people in psychotherapeutic activities is challenging, and treatment adherence is often poor. This paper presents a series of studies carried out as part of the development of a mobile and online symptom tracking tool for adolescents with mental health problems. Teenagers use the system to record symptoms on their mobile phones and can view this information in a clinical setting with a therapist. We focus on a clinical pilot of the system with ten users in public mental health clinics. As well as indicating that the mobile diary tool can increase client adherence to therapeutic activities, the study yields insight into the factors influencing the success of the design and informs the design of other systems to be used as adjuncts to therapy.
2011	Breaking boundaries: strategies for mentoring through textile computing workshops	With over 13.3 million children living below poverty line in the United States, there is a pressing need for engaging HCI research with children at the socio-economic margins. Drawing from design studio culture and art therapy literature, we explore wearable computing as a creative and tangible medium (similar to markers, paints, clays, etc .) for motivating 'at-risk' children in hands-on making and expressive instantiation of ideas. Working with a local outreach organization for 'at-risk' middle school girls, we conducted five weekly workshops during which participants ideated, designed and implemented personal wearable computing projects. These sessions inspired participants (age 10-12) who tend to be uninterested and uncooperative in educational activities to complete interactive projects and engage with workshop volunteers as mentors and peers. We present the challenges, merits and outcomes of our approach, proposing wearable computing as a healing outlet and a mentoring strategy for at-risk children.
2011	African American men constructing computing identity	Many young African American males have a passion for video games, but they don't often translate that passion into learning about computing. Part of the problem is that they do not identify with computing as a social norm within their peer group. This disidentification with computing can negatively impact academic performance and limit opportunities for upward mobility. We developed a job training program called Glitch Game Testers in which young African American men are trained to 'Sbreak open the black box' of their game consoles to learn about computing. Perceptions of peers' technical competency were measured before and after the summer 2010 program. Results showed that participants were more likely to view their peers as technical resources and their overall access to technical resources increased. Broader implications for motivating technology adoption in HCI are discussed.
2011	Brick by brick: iterating interventions to bridge the achievement gap with virtual peers	We lay out one strand of a continuing investigation into the development of a virtual peer to help children learn to use "school English" and "school-ratified science talk". In this paper we describe a detailed analysis of a corpus of child-child language use, and report our findings on the ways children shift dialects and ways of discussing science depending on the social context and task. We discuss the implications of these results for the redesign of a virtual peer that can evoke language behaviors associated with student achievement. Furthermore, our results allow us to describe the ways in which this virtual agent can tailor its level of interaction based on a child's current aptitude in this area.
2011	Tangible bots: interaction with active tangibles in tabletop interfaces	We present interaction techniques for tangible tabletop interfaces that use active, motorized tangibles, what we call Tangible Bots. Tangible Bots can reflect changes in the digital model and assist users by haptic feedback, by correcting errors, by multi-touch control, and by allowing efficient interaction with multiple tangibles. A first study shows that Tangible Bots are usable for fine-grained manipulation (e.g., rotating tangibles to a particular orientation); for coarse movements, Tangible Bots become useful only when several tangibles are controlled simultaneously. Participants prefer Tangible Bots and find them less taxing than passive, non-motorized tangibles. A second study focuses on usefulness by studying how electronic musicians use Tangible Bots to create music with a tangible tabletop application. We conclude by discussing the further potential of active tangibles, and their relative benefits over passive tangibles and multi-touch.
2011	Geckos: combining magnets and pressure images to enable new tangible-object design and interaction	In this paper we present Geckos, a new type of tangible objects which are tracked using a Force-Sensitive Resistance sensor. Geckos are based on low-cost permanent magnets and can also be used on non-horizontal surfaces. Unique pressure footprints are used to identify each tangible Gecko. Two types of tangible object designs are presented: Using a single magnet in combination with felt pads provides new pressure-based interaction modalities. Using multiple separate magnets it is possible to change the marker footprint dynamically and create new haptic experiences. The tangible object design and interaction are illustrated with example applications. We also give details on the feasibility and benefits of our tracking approach and show compatibility with other tracking technologies.
2011	TUIC: enabling tangible interaction on capacitive multi-touch displays	We present TUIC , a technology that enables tangible interaction on capacitive multi-touch devices, such as iPad, iPhone, and 3M's multi-touch displays, without requiring any hardware modifications. TUIC simulates finger touches on capacitive displays using passive materials and active modulation circuits embedded inside tangible objects, and can be used with multi-touch gestures simultaneously. TUIC consists of three approaches to sense and track objects: spatial , frequency , and hybrid (spatial plus frequency) . The spatial approach, also known as 2D markers, uses geometric, multi-point touch patterns to encode object IDs. Spatial tags are straightforward to construct and are easily tracked when moved, but require sufficient spacing between the multiple touch points. The frequency approach uses modulation circuits to generate high-frequency touches to encode object IDs in the time domain. It requires fewer touch points and allows smaller tags to be built. The hybrid approach combines both spatial and frequency tags to construct small tags that can be reliably tracked when moved and rotated. We show three applications demonstrating the above approaches on iPads and 3M's multi-touch displays.
2011	tBox: a 3d transformation widget designed for touch-screens	3D transformation widgets are commonly used in many 3D applications operated from mice and keyboards. These user interfaces allow independent control of translations, rotations, and scaling for manipulation of 3D objects. In this paper, we study how these widgets can be adapted to the tactile paradigm. We have explored an approach where users apply rotations by means of physically plausible gestures, and we have extended successful 2D tactile principles to the context of 3D interaction. These investigations led to the design of a new 3D transformation widget, tBox, that can been operated easily and efficiently from gestures on touch-screens.
2011	Rendering physical effects in tabletop controls	We introduce dynamic physical properties as an additional degree of freedom for passive tabletop controls. Using electromagnetic actuation, we manipulate attributes of tangibles on the fly, such as perceived weight, spring resistance, friction, and latching. We describe our actuation concepts, prototypes, and measurements showing that magnetic fields can change physical effects in a linear way. Controlled experiments reveal that participants can tactually distinguish four rendered resistance levels of a button prototype and easily detect dynamic detents in a continuous slider. Finally, we describe how adjustable physical properties in tangibles can enhance tabletop interaction.
2011	Materializing the query with facet-streams: a hybrid surface for collaborative search on tabletops	We introduce "Facet-Streams", a hybrid interactive surface for co-located collaborative product search on a tabletop. Facet-Streams combines techniques of information visualization with tangible and multi-touch interaction to materialize collaborative search on a tabletop. It harnesses the expressive power of facets and Boolean logic without exposing users to complex formal notations. Two user studies reveal how Facet-Streams unifies visual and tangible expressivity with simplicity in interaction, supports different strategies and collaboration styles, and turns product search into a fun and social experience.
2011	Gestures in the wild: studying multi-touch gesture sequences on interactive tabletop exhibits	In this paper we describe our findings from a field study that was conducted at the Vancouver Aquarium to investigate how visitors interact with a large interactive table exhibit using multi-touch gestures. Our findings show that the choice and use of multi-touch gestures are influenced not only by general preferences for certain gestures but also by the interaction context and social context they occur in. We found that gestures are not executed in isolation but linked into sequences where previous gestures influence the formation of subsequent gestures. Furthermore, gestures were used beyond the manipulation of media items to support social encounters around the tabletop exhibit. Our findings indicate the importance of versatile many-to-one mappings between gestures and their actions that, other than one-to-one mappings, can support fluid transitions between gestures as part of sequences and facilitate social information exploration.
2011	Rethinking 'multi-user': an in-the-wild study of how groups approach a walk-up-and-use tabletop interface	Multi-touch tabletops have been much heralded as an innovative technology that can facilitate new ways of group working. However, there is little evidence of these materialising outside of research lab settings. We present the findings of a 5-week in-the-wild study examining how a shared planning application - designed to run on a walk-up-and-use tabletop - was used when placed in a tourist information centre. We describe how groups approached, congregated and interacted with it and the social interactions that took place - noting how they were quite different from research findings describing the ways groups work around a tabletop in lab settings. We discuss the implications of such situated group work for designing collaborative tabletop applications for use in public settings.
2011	The effects of interaction techniques on talk patterns in collaborative peer learning around interactive tables	This paper presents the findings of a user study investigating conversational patterns across three conditions of table-based interaction (direct touch interactive table, pantograph interactive table and non-digital table) for different types of educational activities. Findings demonstrate that communication style is significantly affected by interaction techniques. The direct touch technique stimulated conversations based around the topic and pedagogical method. The pantograph technique promoted playfulness and had a higher number of directive utterances between participants, with fewer task-based, group-oriented utterances. The non-digital table promoted reflective forms of task-orientated utterance, encouraged group communication and fostered more equitable participation between members. The findings provide insights into the design of interactive tables to support particular forms of social interaction.
2011	Opportunities for computing technologies to support healthy sleep behaviors	Getting the right amount of quality sleep is a key aspect of good health, along with a healthy diet and regular exercise. Human-computer interaction (HCI) researchers have recently designed systems to support diet and exercise, but sleep has been relatively under-studied in the HCI community. We conducted a literature review and formative study aimed at uncovering opportunities for computing to support the important area of promoting healthy sleep. We present results from interviews with sleep experts, as well as a survey ( N = 230) and interviews with potential users ( N = 16) to indicate what people would find practical and useful for sleep. Based on these results, we identify a number of design considerations, challenges, and opportunities for using computing to support healthy sleep behaviors, as well as a design framework for mapping the design space of technologies for sleep.
2011	How to evaluate technologies for health behavior change in HCI research	New technologies for encouraging physical activity, healthy diet, and other types of health behavior change now frequently appear in the HCI literature. Yet, how such technologies should be evaluated within the context of HCI research remains unclear. In this paper, we argue that the obvious answer to this question - that evaluations should assess whether a technology brought about the intended change in behavior - is too limited. We propose that demonstrating behavior change is often infeasible as well as unnecessary for a meaningful contribution to HCI research, especially when in the early stages of design or when evaluating novel technologies. As an alternative, we suggest that HCI contributions should focus on efficacy evaluations that are tailored to the specific behavior-change intervention strategies (e.g., self-monitoring, conditioning) embodied in the system and studies that help gain a deep understanding of people's experiences with the technology.
2011	Motivating mobility: designing for lived motivation in stroke rehabilitation	How to motivate and support behaviour change through design is becoming of increasing interest to the CHI community. In this paper, we present our experiences of building systems that motivate people to engage in upper limb rehabilitation exercise after stroke. We report on participatory design work with four stroke survivors to develop a holistic understanding of their motivation and rehabilitation needs, and to construct and deploy engaging interactive systems that satisfy these. We reflect on the limits of motivational theories in trying to design for the lived experience of motivation and highlight lessons learnt around: helping people articulate what motivates them; balancing work, duty, fun; supporting motivation over time; and understanding the wider social context. From these we identify design guidelines that can inform a toolkit approach to support both scalability and personalisability.
2011	Group pulmonary rehabilitation delivered to the home via the internet: feasibility and patient perception	Chronic Obstructive Pulmonary Disease (COPD) is a common and debilitating lung condition. Pulmonary rehabilitation is effective in treating COPD. Rehabilitation, combining physical exercise with education, is usually undertaken in hospital or clinic-based groups led by a clinician. The support of the group is important. However, distance of travel, and mobility and transport problems can mean that patients are unable to participate. This paper describes a feasibility study to deliver a program to a group of patients in their own homes, improving accessibility. A novel videoconferencing system was installed in four patient's homes, connected to their TV and the Internet. A physiotherapist delivered a pulmonary rehabilitation program, involving twice-weekly exercise sessions for eight weeks. All were visible and audible to maintain the group-based approach of the conventional program. The technology performed well, satisfaction was high, and clinical improvements occurred in all patients, comparable to a conventional program. Larger studies are warranted.
2011	Modern software product support processes and the usage of multimedia formats	Despite being an important channel for end-user assistance, few studies have directly investigated the interactions that occur in modern-day practice of software product support. We present results from a multi-dimensional analysis of product support activities at a leading design software company. We carried out a quantitative analysis of existing support requests, a survey with product support specialists, and follow-up interviews to understand the current practices in product support. In particular, we investigated the utility of different multimedia formats that modern web-based support systems enable. Our results showed that despite the value that these formats bring to support tasks, support specialists still face bottlenecks in remotely resolving software problems. We conclude by highlighting several opportunities in HCI for improving diagnosis and resolution of software issues over the web.
2011	Ease of juggling: studying the effects of manual multitasking	Everyday activities often involve using an interactive device while one is handling various other physical objects (wallets, bags, doors, pens, mugs, etc.). This paper presents the Manual Multitasking Test , a test with 12 conditions emulating manual demands of everyday multitasking situations. It allows experimenters to expose the effects of design on "manual flexibility": users' ability to reconfigure the sensorimotor control of arms, hands, and fingers in order to regain the high performance levels they experience when using the device on its own. The test was deployed for pointing devices on laptops and Qwerty keyboards of mobile devices. In these studies, we identified facilitative design features whose absence explains, for example, why the mouse and stylus function poorly in multi-object performance. The issue deserves more attention, because interfaces that are nominally similar (e.g., "one-handed input") can vary dramatically in terms of "ease of juggling".
2011	Designing of multimodal feedback for enhanced multitasking performance	In this paper, we explore the possibility of applying multimodal feedback to improve multitasking performance. For this purpose, we have devised a general multitasking test application, called the MSP-Blocks, which includes many basic elements of multitasking and can be used to carry out a variety of multimodal multitasking experiments. An experiment was run to study the effects of two factors (the number of jobs and types of multimodal feedback) to user task performance, specifically, interaction effort, concurrency, fairness and output quality. The results indicated that multimodal feedback did influence multitasking performance, and moreover, non-redundant multimodal feedback was more effective than no multimodality or redundant multimodality for tasks with reasonable difficulty, e.g. when the number of jobs was more than four.
2011	The effects of time constraints on user behavior for deferrable interruptions	Previous studies of multitasking have highlighted the importance of cognitive load in interruptibility by showing that forced interruptions are least disruptive when cognitive load is low, and also that users prefer to address interruptions at low-load points when given a choice. We present an empirical study that uses a ringing-phone scenario to examine how users manage deferrable interruptions in the presence of varying time constraints. We found that while cognitive load did influence multitasking as expected, the time constraints placed on the user also had a significant impact. In particular, we observed three distinct strategies for addressing interruption: the expected strategy of switching at low-load points, but also two other strategies of continuing on after a low-load point or giving up at a high-load point. The presence of the latter two strategies strongly suggests that users can adapt their multitasking behavior with respect to the time constraints of the interrupting task.
2011	Why do i keep interrupting myself?: environment, habit and self-interruption	Self-interruptions account for a significant portion of task switching in information-centric work contexts. However, most of the research to date has focused on understanding, analyzing and designing for external interruptions. The causes of self-interruptions are not well understood. In this paper we present an analysis of 889 hours of observed task switching behavior from 36 individuals across three high-technology information work organizations. Our analysis suggests that self-interruption is a function of organizational environment and individual differences, but also external interruptions experienced. We find that people in open office environments interrupt themselves at a higher rate. We also find that people are significantly more likely to interrupt themselves to return to solitary work associated with central working spheres, suggesting that self-interruption occurs largely as a function of prospective memory events. The research presented contributes substantially to our understanding of attention and multitasking in context.
2011	CommentSpace: structured support for collaborative visual analysis	Collaborative visual analysis tools can enhance sensemaking by facilitating social interpretation and parallelization of effort. These systems enable distributed exploration and evidence gathering, allowing many users to pool their effort as they discuss and analyze the data. We explore how adding lightweight tag and link structure to comments can aid this analysis process. We present CommentSpace, a collaborative system in which analysts comment on visualizations and websites and then use tags and links to organize findings and identify others'" contributions. In a pair of studies comparing CommentSpace to a system without support for tags and links, we find that a small, fixed vocabulary of tags (question, hypothesis, to-do) and links (evidence-for, evidence-against) helps analysts more consistently and accurately classify evidence and establish common ground. We also find that managing and incentivizing participation is important for analysts to progress from exploratory analysis to deeper analytical tasks. Finally, we demonstrate that tags and links can help teams complete evidence gathering and synthesis tasks and that organizing comments using tags and links improves analytic results.
2011	Supporting collaborative help for individualized use	In this paper, we seek to advance the research around utilizing collaborative help for supporting individualized use of technologies. We do this by shedding light on the ways that users of MythTV, a highly flexible open-source software system for home entertainment enthusiasts, collaboratively help one another in maintaining their individualized MythTV systems. By analyzing the MythTV user community's mailing list archive, documentation, and wiki, coupled with user interviews we discuss how the community utilizes configuration artifacts as proxies to easily mobilize and exchange knowledge. While exchanging concrete artifacts such as scripts and configuration files was seen to sometimes increase the efficiency of knowledge transfer, it also presented several challenges. Negotiating the transparency of configuration artifacts, navigating the customization and appropriation gulfs, and aligning usage trajectories all emerged as problematic areas. We discuss design implications that address these challenges. Our findings provide a crucial understanding for how to support users in their individualized use of systems.
2011	The scale and evolution of coordination needs in large-scale distributed projects: implications for the future generation of collaborative tools	The past decade has witnessed the development of a new class of coordination tools that focus on automatically providing individuals a rich context for facilitating the coordination of their work. Despite their valuable contributions, current coordination tools have mostly been designed without taking into account scalability aspects beyond the small-group level. The increasing pervasiveness of large-scale projects suggests that those mechanisms need to scale dramatically to adequately support such work settings. In this paper, we used data from five distinct large-scale projects from three different companies to study the scale, range, and volatility of the coordination requirements that emerged over time within those projects. Our results showed that coordination requirements tend to be quite volatile, vary significantly in their magnitude across project members and a significant proportion of the coordination requirements cut across organizational and geographical boundaries. Furthermore, new coordination requirements represent, on average, a third of the coordination requirements faced by a project member on a monthly basis. The implications of these results for the design of collaborative tools are discussed.
2011	Topika: integrating collaborative sharing with email	New enterprise tools (wikis, team spaces, social tags) offer potential benefits for enterprise collaboration, providing shared resources to organize work. However, a vast amount of collaboration still takes place by email. But email is problematic for collaboration because information may be distributed across multiple messages in an overloaded inbox. Email also increases workload as each individual has to manage their own versions of collaborative materials. We present a novel system, Topika that integrates email with collaboration tools. It allows users to continue to use email while also enjoying the benefits of these dedicated tools. When a user composes an email Topika analyzes the message and suggests relevant shared spaces (e.g., wiki pages) within the user's collaboration tools. This allows her to post the email to those spaces. An evaluation of Topika's suggestion algorithm shows that it performs well at accurately suggesting shared spaces.
2011	Raconteur: integrating authored and real-time social media	Social media enables people to share personal experiences, often through real-time media such as chat. People also record their life experiences in media collections, with photos and video. However, today's social media force a choice between real-time communication, and authoring a coherent story illustrated with digital media. There is simply not enough time in real-time communication to select and compose coherent multimedia stories. We present Raconteur , which introduces a new style of social media combining aspects of the real-time and authored styles of communication. It is structured around a text chat, augmented by an agent that continuously interprets the chat text to suggest appropriate media elements to illustrate the story. A small experiment shows that storytellers find Raconteur's suggestions helpful in presenting their experiences, and audiences find the interaction engaging.
2011	MicroMandarin: mobile language learning in context	Learning a new language is hard, but learning to use it confidently in conversations with native speakers is even harder. From our field research with language learners, with support from Cognitive Psychology and Second Language Acquisition, we argue for the value of contextual microlearning in the many breaks spread across different places and throughout the day. We present a mobile application that supports such microlearning by leveraging the location-based service Foursquare to automatically provide contextually relevant content in the world's major cities. In an evaluation of Mandarin Chinese learning, a four-week, 23-user study spanning Beijing and Shanghai compared this contextual system to a system based on word frequency. Study sessions with the contextual version lasted half as long but occurred in twice as many places as sessions with the frequency version, suggesting a complementary relationship between the two approaches.
2011	Augmenting the web for second language vocabulary learning	The busyness of everyday life means that those with casual interest in additional learning opportunities are often unable to schedule regular time and effort for studying. In this paper, we explore how to augment information technologies that people use on a daily basis to create micro-learning opportunities. In particular, we examine how a person's existing Web browsing experience-with first language Web pages-can be augmented to teach them second language vocabulary. We present a prototype, ALOE, which runs inside the Firefox Web browser and dynamically augments Web pages by replacing a selected set of English words with their foreign translations. The foreign translations are embedded in the rich context of a Web page's existing English text to promote incidental learning and guessing from context of the translated words. Through a two month user evaluation of ALOE, we found that most participants were able to learn an average of 50 new French vocabulary words.
2011	Document area identification for extending books without markers	We present a method of document area identification that utilizes consecutive characters in the non-reading direction as search keys. We use this method to develop a prototype system called Kappan . It enables service providers and users to create hyperlinks in books without markers. Existing techniques generally require markers to be printed on the page if a hyperlink is to be created. We consider that utilizing the concept of the search index makes markers unnecessary. Kappan associates indexed text areas in a large number of books with supporting digital contents. The indexed text areas, freely defined by service providers or users, are identified by subjecting images of small areas of the printed page to OCR (Optical Character Recognition) and extracting from the text so recognized highly specific and efficient search keys. Traditional text indexing methods must extract long character sequences from the partial image in order to identify the area exactly given the sheer number of book pages. However, considering that the average OCR error rate is more than 20 percent if the partial image is captured by a camera-equipped cellular phone, it is highly probable that many characters would be misrecognized and area identification would thus fail. In contrast, our indexing method can extract area-specific clues using fewer characters that can identify the area exactly even when the partial image is small and the extracted text contains misrecognized characters. An experiment proves that our method can identify the exact area from more than one million areas with the high accuracy rates of 99 percent and 96 percent for OCR error rates of 0 percent and 22 percent, respectively.
2011	The reading desk: applying physical interactions to digital documents	Reading is increasingly being performed interactively on-screen; for instance, new novels are now routinely released in electronic format for viewing on PCs and mobile devices. Unfortunately, on-screen reading loses many of the natural features of conventional physical media, such as the ability to annotate, slip in bookmarks, turn page corners, and so on. How best should these features be represented electronically? Can computerized representations give benefits that excel the conventional benefits of paper? We describe the design and implementation of a novel reading system that mimics key properties of paper and surpasses them by incorporating digital techniques. A comparative user study evaluating the system confirmed the effectiveness of the features and the value of the system as a whole.
2011	ReadN'Karaoke: visualizing prosody in children's books for expressive oral reading	We present a method for displaying prosody, the melody of speech, to aid beginning readers with fluent oral reading. We build on proven auditory techniques by manipulating and augmenting text in children's stories. The acoustic properties of a fluent recording are used to construct visualizations of pitch, loudness and length variations in read samples aligned with text. Our initial approach was to directly manipulate text, which was tested on ten children who showed significant increases in pitch modulation with manipulated text but reported difficulty with word recognition. This motivated designing the augmented text renderings, which display prosodic cues layered with text. Manipulated and augmented texts were compared with two beginning readers. Children showed similar prosodic gains with both versions and reported greater satisfaction with augmented pitch cues. Visual prosodic cues show promise for improving reading fluency in early readers and may have applications for disability education and second language learning.
2011	Situating the concern for information privacy through an empirical study of responses to video recording	In this paper, we present the results of an empirical study of perceptions towards pervasive video recording. We describe a commonly used model for understanding information privacy, the Concern for Information Privacy (CFIP) model, and present the ways that this model and its associated questionnaire can shed light on information privacy concerns about pervasive and ubiquitous computing technologies. Specifically, the CFIP model encourages analysis of data across four facets of experience: the collection of personal data, the risk of improper access, the potential for unauthorized secondary use, and the challenge of preventing or correcting errors in the data. We further identify areas not well handled by this model of information privacy and suggest avenues for future work, including research on how and when to notify people about recording technologies, awareness of data provenance and leakage, and understanding of and access to the data assemblage being created about individuals.
2011	We're in it together: interpersonal management of disclosure in social network services	The workload needed for managing privacy and publicness in current social network services (SNSs) is placed on individuals, yet people have few means to control what others disclose about them. This paper considers SNS-users' concerns in relation to online disclosure and the ways in which they cope with these both individually and collaboratively. While previous work has focused mainly on individual coping strategies, our findings from a qualitative study with 27 participants suggest that collaborative strategies in boundary regulation are of additional importance. We present a framework of strategies for boundary regulation that informs both theoretical work and design practice related to management of disclosure in SNSs. The framework considers disclosure as an interpersonal process of boundary regulation, in which people are dependent on what others choose to disclose about them. The paper concludes by proposing design solutions supportive of collaborative and preventive strategies in boundary regulation that facilitate the management of disclosure online.
2011	Privacy dictionary: a linguistic taxonomy of privacy for content analysis	Privacy is frequently a key concern relating to technology and central to HCI research, yet it is notoriously difficult to study in a naturalistic way. In this paper we describe and evaluate a dictionary of privacy designed for content analysis, derived using prototype theory and informed by traditional theoretical approaches to privacy. We evaluate our dictionary categories alongside privacy-related categories from an existing content analysis tool, LIWC, using verbal discussions of privacy issues from a variety of technology and non-technology contexts. We find that our privacy dictionary is better able to distinguish between privacy and non-privacy language, and is less context-dependent than LIWC. However, the more general LIWC categories are able to describe a greater amount of variation in our data. We discuss possible improvements to the privacy dictionary and note future work.
2011	Social and technical challenges in parenting teens' social media use	With millions of teenagers on the Internet, millions of parents are trying to understand what their teens are doing and why. Understanding how technology use impacts teens' learning, growth, and social development is critical for their health and wellbeing and for the welfare of the family. Yet, balancing parent authority with teen privacy and autonomy is difficult. We conducted an interview study with 16 parents to examine challenges in "technoparenting" - parenting teens' technology use. Parents said they wanted more transparency in their teens' use of cell phones and the Internet and they struggled with their own unfamiliarity with technology. Technoparenting is a distributed problem and, surprisingly, parents wanted support and collaboration from the broader community. We conclude with design implications for a socially translucent "digital window".
2011	Enhancing independence and safety for blind and deaf-blind public transit riders	Blind and deaf-blind people often rely on public transit for everyday mobility, but using transit can be challenging for them. We conducted semi-structured interviews with 13 blind and deaf-blind people to understand how they use public transit and what human values were important to them in this domain. Two key values were identified: independence and safety . We developed GoBraille , two related Braille-based applications that provide information about buses and bus stops while supporting the key values. GoBraille is built on MoBraille , a novel framework that enables a Braille display to benefit from many features in a smartphone without knowledge of proprietary, device-specific protocols. Finally, we conducted user studies with blind people to demonstrate that GoBraille enables people to travel more independently and safely. We also conducted co-design with a deaf-blind person, finding that a minimalist interface, with short input and output messages, was most effective for this population.
2011	A haptic wristwatch for eyes-free interactions	We present a haptic wristwatch prototype that makes it possible to acquire information from a companion mobile device through simple eyes-free gestures. The wristwatch we have built uses a custom-made piezoelectric actuator combined with sensors to create a natural, inconspicuous, gesture-based interface. Feedback is returned to the user in the form of haptic stimuli that are delivered to the wrist. We evaluated the capabilities and limitations of our prototype through two user experiments. One experiment verified that the apparatus could be used as a tactile notification mechanism. The other experiment assessed the feasibility of using a cover-and-hold gesture on the wristwatch to obtain numerical data tactually. Results from the numerosity experiment and feedback from participants prompted us to redesign the cover-and-hold gesture to provide users with additional control over the interaction. We qualitatively evaluated the redesigned interaction by handing the prototype to users so that they could use it in a realistic work environment. Taken together, results from the experiments and the validation process indicate that a wrist accessory can be effectively used to perform discreet, closed-loop, eyes-free interactions with a mobile device.
2011	Detecting vibrations across the body in mobile contexts	In this paper we explore the potential and limitations of vibrotactile displays in practical wearable applications, by comparing users' detection rate and response time to stimuli applied across the body in varied conditions. We examined which body locations are more sensitive to vibrations and more affected by movement; whether visual workload, expectation of location, or gender impact performance; and if users have subjective preferences to any of these conditions. In two experiments we compared these factors using five vibration intensities on up to 13 body locations. Our contributions are comparisons of tactile detection performance under conditions typifying mobile use, an experiment design that supports further investigation in vibrotactile communication, and guidelines for optimal display location given intended use.
2011	Tactile feedback can assist vision during mobile interactions	We evaluated the use of rich tactile feedback in the task of scrolling through a long list of items. We used a hand-held device having a tactile transducer that could provide sensations with temporal and spatial content. These capabilities were put to use in an interaction metaphor where input and tactile feedback were tightly coupled. We measured time- to-target and error rates, but also measured the time spent by participants to look at the screen. We found a 28\% decrease of reliance on vision when tactile feedback was enabled.
2011	The effects of task dimensionality, endpoint deviation, throughput calculation, and experiment design on pointing measures and models	Fitts' law (1954) characterizes pointing speed-accuracy performance as throughput, whose invariance to target distances (A) and sizes (W) is known. However, it is unknown whether throughput and Fitts' law models in general are invariant to task dimensionality (1-D vs. 2-D), whether univariate (SDx) or bivariate (SDx,y) endpoint deviation is used, whether throughput is calculated using the mean-of-means approach or the slope-inverse approach, or whether Guiard's (2009) Form - Scale experiment design is used instead of fully crossed A-W factors. We empirically investigate the confluence of these issues, finding that Fitts' law is largely invariant across 1-D and 2-D, provided that univariate endpoint deviation (SDx) is used in both, but that for 2-D pointing data, bivariate endpoint deviation (SDx,y) results in better Fitts' law models. Also, the mean-of-means throughput calculation exhibits lower variance across subjects and dimensionalities than the slope-inverse calculation. In light of these and other findings, we offer recommendations for pointing evaluations, especially in 2-D. We also offer an evaluation tool called Fitts Study to facilitate comparisons.
2011	The effects of intended use on target acquisition	Fitts's Law has been used extensively in HCI to describe 2D targeting; however, the controlled tasks generally used neglect aspects of real-world pointing, including how the intended use of a target affects its acquisition. We studied aiming to a target in four tasks requiring varying precision after acquisition. Our results present the first evidence that the intended use of a target affects its acquisition in terms of movement time and motion kinematics for computer aiming. Important for researchers who model 2D targeting, our results also have particular impact for HCI research that uses motion kinematics.
2011	Modeling and predicting pointing errors in two dimensions	Recently, Wobbrock et al. (2008) derived a predictive model of pointing accuracy to complement Fitts' law's predictive model of pointing speed. However, their model was based on one-dimensional (1-D) horizontal movement, while applications of such a model require two dimensions (2-D). In this paper, the pointing error model is investigated for 2-D pointing in a study of 21 participants performing a time-matching task on the ISO 9241-9 ring-of-circles layout. Results show that the pointing error model holds well in 2-D. If univariate endpoint deviation (SDx) is used, regressing on N=72 observed vs. predicted error rate points yields R2=.953. If bivariate endpoint deviation (SDx,y) is used, regression yields R2=.936. For both univariate and bivariate models, the magnitudes of observed and predicted error rates are comparable.
2011	Into the wild: challenges and opportunities for field trial methods	Field trials of experimental systems in the wild have developed into a standard method within HCI - testing new systems with groups of users in relatively unconstrained settings outside of the laboratory. In this paper we discuss methodological challenges in running user trials. Using a trial of trials we examined the practices of investigators and participants - documenting demand characteristics, where users adjust their behaviour to fit the expectations of those running the trial, the interdependence of how trials are run and the result they produce, and how trial results can be dependent on the insights of a subset of trial participants. We develop three strategies that researchers can use to leverage these challenges to run better trials.
2011	When a little knowledge isn't a dangerous thing	In this paper we compare two departments of a public administration body carrying out similar work. In one department two sections, telephony and processing, are collocated whereas in the other they are not. We demonstrate the costs of distribution, in particular how the strictly enforced division of labour and limited visibility onto the workflow of the other section causes problems when dealing with normal, natural exceptions. The setting is one of seemingly routine bureaucratic work rather than high-skilled cooperative work, thus the impact of distribution might be considered rather surprising. We argue that a key requirement for any solution is to enable practitioners on the 'shop floor' the freedom to find elegant solutions to problems.
2011	Field trial of Tiramisu: crowd-sourcing bus arrival times to spur co-design	Crowd-sourcing social computing systems represent a new material for HCI designers. However, these systems are difficult to work with and to prototype, because they require a critical mass of participants to investigate social behavior. Service design is an emerging research area that focuses on how customers co-produce the services that they use, and thus it appears to be a great domain to apply this new material. To investigate this relationship, we developed Tiramisu, a transit information system where commuters share GPS traces and submit problem reports. Tiramisu processes incoming traces and generates real-time arrival time predictions for buses. We conducted a field trial with 28 participants. In this paper we report on the results and reflect on the use of field trials to evaluate crowd-sourcing prototypes and on how crowd sourcing can generate co-production between citizens and public services.
2011	Publics in practice: ubiquitous computing at a shelter for homeless mothers	Today, commodity technologies like mobile phones - once symbols of status and wealth - have become deeply woven into social and economic participation in Western society. Despite the pervasiveness of these technologies, there remain groups who may not have extensive access to them but who are nonetheless deeply affected by their presence in everyday life. In light of this, we designed, built, and deployed a ubiquitous computing system for one such overlooked group: the staff and residents at a shelter for homeless mothers. Our system connects mobile phones, a shared display, and a Web application to help staff and residents stay connected. We report on the adoption and use of this system over the course of a 30 week deployment, discussing the substantial impact our system had on shelter life and the broader implications for such socio-technical systems that sit at the juncture of social action and organizational coordination.
2011	Homeless young people and living with personal digital artifacts	This paper reports on an investigation of how homeless young people hold themselves in relation to personal digital artifacts. Twelve participants, aged 19-29, took part in semi-structured interviews. Participants answered questions about the acquisition and disposition of personal artifacts, digital and non-digital, including mobile phones, music players, and wallets. The analysis of the interview transcripts reveals that young people often part with their digital artifacts in order to meet immediate needs, including the need to create and reciprocate goodwill. This contingent holding of personal artifacts illuminates both the ordinary and extraordinary circumstances of homelessness. The paper concludes with a discussion of constraints and implications for the design of information systems for improving the welfare of homeless young people.
2011	Improving the safety of homeless young people with mobile phones: values, form and function	By their pervasiveness and by being worn on our bodies, mobile phones seem to have become intrinsic to safety. To examine this proposition, 43 participants, from four stakeholder groups (homeless young people, service providers, police officers, and community members), were asked to consider how homeless young people could use mobile phones to keep safe. Participants were asked to express their knowledge for place-based safety and to envision how mobile phones might be used to improve safety. Detailed analysis of the resulting data, which included value sketches, written value scenarios, and semi-structured discussion, led to specific design opportunities, related to values (e.g., supporting trust and desire to help others), function (e.g., documenting harms for future purposes), and form (e.g., leveraging social expectations for how mobile phones can be used to influence behavior). Together, these findings bound a design space for how mobile phones can be used to manage unsafe situations.
2011	Playable data: characterizing the design space of game-y infographics	This work explores the intersection between infographics and games by examining how to embed meaningful visual analytic interactions into game mechanics that in turn impact user behavior around a data-driven graphic. In contrast to other methods of narrative visualization, games provide an alternate method for structuring a story, not bound by a linear arrangement but still providing structure via rules, goals, and mechanics of play. We designed two different versions of a game-y infographic, Salubrious Nation, and compared them to a non-game-y version in an online experiment. We assessed the relative merits of the game-y approach of presentation in terms of exploration of the visualization, insights and learning, and enjoyment of the experience. Based on our results, we discuss some of the benefits and drawbacks of our designs. More generally, we identify challenges and opportunities for further exploration of this new design space.
2011	Cardiogram: visual analytics for automotive engineers	We present Cardiogram, a visual analytics system that supports automotive engineers in debugging masses of traces each consisting of millions of recorded messages from in-car communication networks. With their increasing complexity, ensuring these safety-critical networks to be error-free has become a major task and challenge for automotive engineers. To overcome shortcomings of current analysis tools, Cardiogram combines visualization techniques with a data preprocessing approach to automatically reduce complexity based on engineers' domain knowledge. In this paper, we provide the findings from an exploratory, three-year field study within a large automotive company, studying current practices of engineers, the challenges they meet and the characteristics for integrating novel visual analytics tools into their work practices. We then introduce Cardiogram, discuss how our field analysis influenced our design decisions, and present a qualitative, long-term, in-depth evaluation. Results of this study showed that our participants successfully used Cardiogram to increase the amount of analyzable information, to externalize domain knowledge, and to provide new insights into trace data. Our design approach finally led to the adoption of Cardiogram into engineers' daily practices.
2011	KronoMiner: using multi-foci navigation for the visual exploration of time-series data	The need for pattern discovery in long time-series data led researchers to develop interactive visualization tools and analytical algorithms for gaining insight into the data. Most of the literature on time-series data visualization either focus on a small number of tasks or a specific domain. We propose KronoMiner, a tool that embeds new interaction and visualization techniques as well as analytical capabilities for the visual exploration of time-series data. The interface's design has been iteratively refined based on feedback from expert users. Qualitative evaluation with an expert user not involved in the design process indicates that our prototype is promising for further research.
2011	LifeFlow: visualizing an overview of event sequences	Event sequence analysis is an important task in many domains: medical researchers may study the patterns of transfers within the hospital for quality control; transportation experts may study accident response logs to identify best practices. In many cases they deal with thousands of records. While previous research has focused on searching and browsing, overview tasks are often overlooked. We introduce a novel interactive visual overview of event sequences called \emph{LifeFlow}. LifeFlow is scalable, can summarize all possible sequences, and represents the temporal spacing of the events within sequences. Two case studies with healthcare and transportation domain experts are presented to illustrate the usefulness of LifeFlow. A user study with ten participants confirmed that after 15 minutes of training novice users were able to rapidly answer questions about the prevalence and temporal characteristics of sequences, find anomalies, and gain significant insight from the data.
2011	The photostroller: supporting diverse care home residents in engaging with the world	The Photostroller is a device designed for use by residents of a care home for older people. It shows a continuous slideshow of photographs retrieved from the Flickr™ image website using a set of six predefined categories modified by a tuneable degree of 'semantic drift'. In this paper, we describe the design process that led to the Photostroller, and summarise observations made during a deployment in the care home that has lasted over two months at the time of writing. We suggest that the Photostroller balances constraint with openness, and control with drift, to provide an effective resource for the ludic engagement of a diverse group of older people with each other and the world outside their home.
2011	Automics: souvenir generating photoware for theme parks	Automics is a photo-souvenir service which utilises mobile devices to support the capture, sharing and annotation of digital images amongst groups of visitors to theme parks. The prototype service mixes individual and group photo-capture with existing in-park, on-ride photo services, to allow users to create printed photo-stories. Herein we discuss initial fieldwork in theme parks that grounded the design of Automics, our development of the service prototype, and its real-world evaluation with theme park visitors. We relate our findings on user experience of the service to a literature on mobile photoware, finding implications for the design of souvenir services.
2011	Contextual dynamics of group-based sharing decisions	In this paper we investigate how decisions made while using a granular access control mechanism for sharing photographs are influenced by contextual factors and properties relating to the identities of contacts. We develop analytical models using logistic regression to understand relationships between variables that affect sharing decisions. We also investigate how predefined, static groups for privacy control cope with the challenge of sharing large amounts of content associated with numerous different contexts, and test whether they need to be adjusted to suit particular contexts.
2011	Pass-them-around: collaborative use of mobile phones for photo sharing	In this paper we explore shared collocated interactions with mobile phones. We introduce a phone-based application that allows a small group of collocated people to share photos using the metaphor of passing paper photos around. The prototype encourages people to share their devices and use them interchangeably while discussing photos face-to-face. The prototype supports ad-hoc photo sharing in different contexts by taking into account the spatial arrangement of users around a table, measured with sensors embedded in their mobile phones. Our evaluations show that people are willing to share and connect their mobile phones to engage in collaborative interactions. Participants were able to easily share their collections of photos using our proposed interaction techniques.
2011	ClassSearch: facilitating the development of web search skills through social learning	We explore the use of social learning - improving knowledge skills by observing peer behavior - in the domain of Web search skill acquisition, focusing specifically on co-located classroom scenarios. Through a series of interviews, pilot studies, and classroom deployments, we conclude that a peripheral display of Web search activity within a classroom facilitates both social learning and teacher-led discourse. We present the ClassSearch system for shared awareness of Web search activity, which embodies principles gleaned from our iterative design process, and show results from a ClassSearch deployment in twelve middle-school classroom sessions. Finally, we highlight design suggestions and opportunities for future work while taxonomizing the space of co-located search pedagogies.
2011	Role of available and provided resources in sensemaking	Making sense of a topic often involves appropriating information and organizing themes from various existing resources. We studied how sensemakers appropriated from available online resources as well as artifacts provided by another person directly. We found that both available and provided resources affect sensemaking activities. Sensemakers added more structure in their work when online resources were easily available, but added less structure and information when they were provided relevant sensemaking artifacts from another person. We also studied how early and mature artifacts provided by another person were appropriated differently and found that mature artifacts were rated better and used more but resulted in lesser structure and information being added by the recipient. These findings have implications for the support of sensemaking activities using resources available online as well as artifacts provided by others including co-workers and friends.
2011	Characterizing the usability of interactive applications through query log analysis	People routinely rely on Internet search engines to support their use of interactive systems: they issue queries to learn how to accomplish tasks, troubleshoot problems, and otherwise educate themselves on products. Given this common behavior, we argue that search query logs can usefully augment traditional usability methods by revealing the primary tasks and needs of a product's user population. We term this use of search query logs CUTS - characterizing usability through search. In this paper, we introduce CUTS and describe an automated process for harvesting, ordering, labeling, filtering, and grouping search queries related to a given product. Importantly, this data set can be assembled in minutes, is timely, has a high degree of ecological validity, and is arguably less prone to self-selection bias than data gathered via traditional usability methods. We demonstrate the utility of this approach by applying it to a number of popular software and hardware systems.
2011	Determining relevancy: how software developers determine relevant information in feeds	Finding relevant information within the vast amount of information exchanged via feeds is difficult. Previous research into this problem has largely focused on recommending relevant information based on topicality. By not considering individual and situational factors these approaches fall short. Through a formative, interview-based study, we explored how five software developers determined relevancy of items in two kinds of project news feeds. We identified four factors that the developers used to help determine relevancy and found that placement of items in source code and team contexts can ease the determination of relevancy.
2011	Measuring web page revisitation in tabbed browsing	Browsing the web has been shown to be a highly recurrent activity. Aimed to optimize the browsing experience, extensive previous research has been carried out on users' revisitation behavior. However, the conventional definition for revisitation, which only considers page loading activities by monitoring http requests initiated by the browser, largely underestimates users' intended revisitation activities with tabbed browsers . Thus, we introduce a goal-oriented definition and a refined revisitation measurement based on page viewings in tabbed browsers. An empirical analysis of statistics taken from a client-side log study showed that although the overall revisitation rate remained relatively constant, tabbed browsing has introduced new behaviors warrant future investigations.
2011	Evaluating longitudinal projects combining technology with temporal arts	The integration of interactive technology with temporal art such as dance is an exciting, emerging area. The design space for such collaborations is immense, with variations in sensors, visualizations, and how these interact with dancers and choreography. This paper presents the evaluation methodology and results of Dance.Draw, a longitudinal project spanning two years and three productions, which aimed to develop a deep, interdisciplinary understanding of this space. Given that this is pioneering work, there is little guidance on how to evaluate such collaborations. We describe the significant confounds in doing evaluation in this area, and we present our evolving mixed-methods approach, which includes two unique methods to address the multiple stakeholders in a holistic manner: dancer focus groups and repeated presentations. Our approach has generated insights, such as differing perspectives of audience members and the responses of dancers to technological variables. We conclude by discussing the challenges and successes of our evaluation approach.
2011	Love, hate, arousal and engagement: exploring audience responses to performing arts	Understanding audience responses to art and performance is a challenge. New sensors are promising for measurement of implicit and explicit audience engagement. However, the meaning of biometric data, and its relationship to engagement, is unclear. We conceptually explore the audience engagement domain to uncover opportunities and challenges in the assessment and interpretation of audience engagement data. We developed a display that linked performance videos with audience biometric data and presented it to 7 performing arts experts, to explore the measurement, interpretation and application of biometric data. Experts were intrigued by the response data and reflective in interpreting it. We deepened our inquiry with an empirical study with 49 participants who watched a video of a dance performance. We related temporal galvanic skin response (GSR) data to two self-report scales, which provided insights on interpreting this measure. Our findings, which include strong correlations, support the interpretation of GSR as a valid representation of audience engagement.
2011	Designing from within: humanaquarium	We present an experience-based approach to designing a collaborative interactive performance, humanaquarium. Our research explores public interaction with digital technology through the practice-based inquiry of an inter-disciplinary team of interaction designers and musicians. We present a method of designing experience from within, literally situating ourselves within the performance/use space and assuming the roles both of performers and of designers as we develop and refine the humanaquarium project over the course of a year's worth of public performances.
2011	The polymath project: lessons from a successful online collaboration in mathematics	Although science is becoming increasingly collaborative, there are remarkably few success stories of online collaborations between professional scientists that actually result in real discoveries. A notable exception is the Polymath Project, a group of mathematicians who collaborate online to solve open mathematics problems. We provide an in-depth descriptive history of Polymath, using data analysis and visualization to elucidate the principles that led to its success, and the difficulties that must be addressed before the project can be scaled up. We find that although a small percentage of users created most of the content, almost all users nevertheless contributed some content that was highly influential to the task at hand. We also find that leadership played an important role in the success of the project. Based on our analysis, we present a set of design suggestions for how future collaborative mathematics sites can encourage and foster newcomer participation.
2011	Collaborative creativity: a complex systems model with distributed affect	The study of creativity has received significant attention over the past century, with a recent increase in interest in collaborative, distributed creativity. We posit that creativity in distributed groups is fostered by software interfaces that specifically enable socio-emotional or affective communication. However, previous work on creativity and affect has primarily focused on the individual, while group creativity research has concentrated more on cognition rather than affect. In this paper we propose a new model for creativity in distributed groups, based on the theory of groups as complex systems, that includes affect as well as cognition and that explicitly calls out the interface between individuals as a key parameter of the model. We describe the model, the four stages of collaborative creativity and the causal dynamics in each stage, and demonstrate how affect and interface can facilitate the generation, selection, and amplification of ideas in the various stages of collaborative creativity. We then validate our model with data from three field sites. The data was collected from longitudinal studies of two distributed groups involved in producing creative products--astrophysicists studying supernovae and the expansion rate of the universe and children creating multimedia programming projects online-"-and interviews with staff in a multinational engineering company.
2011	Predicting the perceived quality of online mathematics contributions from users' reputations	There are two perspectives on the role of reputation in collaborative online projects such as Wikipedia or Yahoo! Answers. One, user reputation should be minimized in order to increase the number of contributions from a wide user base. Two, user reputation should be used as a heuristic to identify and promote high quality contributions. The current study examined how offline and online reputations of contributors affect perceived quality in MathOverflow, an online community with 3470 active users. On MathOverflow, users post high-level mathematics questions and answers. Community members also rate the quality of the questions and answers. This study is unique in being able to measure offline reputation of users. Both offline and online reputations were consistently and independently related to the perceived quality of authors' submissions, and there was only a moderate correlation between established offline and newly developed online reputation.
2011	Why is my internet slow?: making network speeds visible	With widespread broadband adoption, more households report experiencing sub-optimal speeds. Not only are slow speeds frustrating, they may indicate consumers are not receiving the services they are paying for from their internet service providers. Yet, determining the speed and source of slow-downs is difficult because few tools exist for broadband management. We report on results of a field trial with 10 households using a visual network probe designed to address these problems. We describe the results of the study and provide design implications for future tools. More importantly, we argue that tools like this can educate and empower consumers by making broadband speeds and sources of slow-downs more visible.
2011	GridOrbit: an infrastructure awareness system for increasing contribution in volunteer computing	The success of a volunteer computing infrastructure depends on the contributions of its users. An example of such an infrastructure is the Mini-Grid, a local peer-to-peer system used for computational analysis of DNA. The speed of analysis increases as more users join the Mini-Grid. However, the invisible nature of such an infrastructure hinders adoption, as it is difficult for users to participate in an infrastructure they are not aware of. This paper introduces GridOrbit, a system designed to increase user awareness, fostering contributions to this infrastructure. We designed GridOrbit using a participatory design process with biologists, and subsequently deployed it for use in a biology laboratory. Our results indicate that the number of contributors to the Mini-Grid increased with the use of awareness technologies. In addition, our analysis presents their motives and behaviors. Finally, a characterization of user interaction with GridOrbit emerged, which enabled us to understand how awareness systems can be better designed. We see GridOrbit as an example of a broader class of technologies designed to create "Infrastructure Awareness" as a means to increase the contributions to technological infrastructures.
2011	How users associate wireless devices	In a wireless world, users can establish connections between devices spontaneously, and unhampered by cables. However, in the absence of cables, what is the natural interaction to connect one device with another? A wide range of device association techniques have been demonstrated, but it has remained an open question what actions users would spontaneously choose for device association. We contribute a study eliciting device association actions from non-technical users without premeditation. Over 700 user-defined actions were collected for 37 different device combinations. We present a classification of user-defined actions, and observations of the users' rationale. Our findings indicate that there is no single most spontaneous action; instead five prominent categories of user-defined actions were found.
2011	ShadowStory: creative and collaborative digital storytelling inspired by cultural heritage	With the fast economic growth and urbanization of many developing countries come concerns that their children now have fewer opportunities to express creativity and develop collaboration skills, or to experience their local cultural heritage. We propose to address these concerns by creating technologies inspired by traditional arts, and allowing children to create and collaborate through playing with them. ShadowStory is our first attempt in this direction, a digital storytelling system inspired by traditional Chinese shadow puppetry. We present the design and implementation of ShadowStory and a 7-day field trial in a primary school. Findings illustrated that ShadowStory promoted creativity, collaboration, and intimacy with traditional culture among children, as well as interleaved children's digital and physical playing experience.
2011	Designing for perceptual crossing to improve user involvement	In this paper we describe our research on how to design for perceptive activity in artifacts in order for perceptual crossing between subject and artifact to happen. We base our research on the phenomenology of perception [19] and on ecological psychology [10]. Perceptual crossing is believed to be essential to share perception and thereby to feel involved in the situation [5,15]. We propose a theoretical model in which perceptive connections between user, artifact and event are presented. We designed an artifact to function as physical hypotheses [9] and show the design relevance of the model. In an experiment we investigate how the user's feeling of involvement is influenced in relation to differentiations of the proposed theoretical model. The results of our experiment show that indeed perceptual crossing between user and artifact influences the user's feeling of involvement with the artifact in their common space. We conclude with describing several design notions important for designing for perceptive activity in artifacts.
2011	Limits of rereadability in procedural interactive stories	The paper investigates the limits of what authors can vary procedurally to encourage and reward rereadability in procedural hypertext fiction. Exploring these issues raises a methodological challenge: how do we study re-reading in the context of stories that change? We have developed an adapted form of the Piagetan clinical interview to do this. Using this approach, we have determined that readers, surprisingly, do not want to experience endless variation when rereading interactive stories. Instead, they are looking for some form of closure, either in terms of "understanding the story", reaching the "best ending" for the characters in the story, or finding the "most interesting" version of the story. This has implications for the design/authoring of interactive stories and interactive art and entertainment.
2011	Rigid structures, independent units, monitoring: organizing patterns in frontline firefighting	Providing firefighters working on the frontline of interventions with ubiquitous computing support remains an open challenge. Designing meaningful solutions for this complex work environment requires reflective thought and conceptual understanding of its social configuration. This paper presents organizing patterns of firefighting frontline practice as a means to inform ubiquitous computing design processes. The patterns originate from a qualitative analysis of an extensive range of user studies conducted with French and German firefighters. As the patterns show, firefighting on the frontline is based on a rigid structure that gains its flexibility through independent units whose safety is ensured by a number of monitoring activities. We conclude that the interaction between the presented patterns forms a balanced whole and needs to be recognized by ubiquitous computing design.
2011	Zero-fidelity simulation of fire emergency response: improving team coordination learning	Fire emergency responders rely on team coordination to survive and succeed in high-stress environments, but traditional education does not directly teach these essential skills. Prior simulations seek the highest possible fidelity, employing resources to capture concrete characteristics of operating environments. We take a different tack, hypothesizing that a zero -fidelity approach, focusing on human-centered aspects of work practice, will improve team coordination learning. Such an approach promotes simulation focus by developing an alternative environment that stimulates participants to engage in distributed cognition . The costs of simulation development are reduced. To supplement preparation for burn training exercises, 28 fire emergency response students played the Teaching Team Coordination game (T 2 eC), a zero-fidelity simulation of the distributed cognition of fire emergency response work practice. To test our hypothesis, we develop quantitative evaluation methods for impact on team coordination learning through measures of communication efficiency and cooperative activity. Results show that participants improve cooperation, become more efficient communicators, differentiate team roles through communication, and leverage multiple communication modalities. Given the context of the study amidst the educational process, qualitative data from the students and their expert instructor supports the ecological validity of the contribution of the T 2 eC zero-fidelity simulation to fire emergency response education.
2011	Kairoscope: managing time perception and scheduling through social event coordination	If everyone says time is relative, why is it still so rigidly defined? There have been many attempts to address the issue of coordinating schedules, but each of these attempts runs into an issue of rigidity: in order to negotiate an event, a specific time must be designated in advance. This model is inherently poor at accommodating life's unpredictability. Kairoscope looks at time from a human perspective, focusing on time as made up of a series of events, rather than simply a series of events in time. By removing our reliance on a fixed time system, events are coordinated socially and on the fly, without worrying about precision. This paper explores the creation of Kairoscope, rooted in ideas of time perception and aiming to reduce time-related stress, optimize time usage, and increase social interaction. The result is a socially-coordinated, constantly adapting, and highly malleable guide through time.
2011	Practical, appropriate, empirically-validated guidelines for designing educational games	There has recently been a great deal of interest in the potential of computer games to function as innovative educational tools. However, there is very little evidence of games fulfilling that potential. Indeed, the process of merging the disparate goals of education and games design appears problematic, and there are currently no practical guidelines for how to do so in a coherent manner. In this paper, we describe the successful, empirically validated teaching methods developed by behavioural psychologists and point out how they are uniquely suited to take advantage of the benefits that games offer to education. We conclude by proposing some practical steps for designing educational games, based on the techniques of Applied Behaviour Analysis. It is intended that this paper can both focus educational games designers on the features of games that are genuinely useful for education, and also introduce a successful form of teaching that this audience may not yet be familiar with.
2011	The mathematical imagery trainer: from embodied interaction to conceptual learning	We introduce an embodied-interaction instructional design, the Mathematical Imagery Trainer (MIT), for helping young students develop grounded understanding of proportional equivalence (e.g., 2/3 = 4/6). Taking advantage of the low-cost availability of hand-motion tracking provided by the Nintendo Wii remote, the MIT applies cognitive-science findings that mathematical concepts are grounded in mental simulation of dynamic imagery, which is acquired through perceiving, planning, and performing actions with the body. We describe our rationale for and implementation of the MIT through a design-based research approach and report on clinical interviews with twenty-two 4th-6th grade students who engaged in problem-solving tasks with the MIT.
2011	Kineticons: using iconographic motion in graphical user interface design	Icons in graphical user interfaces convey information in a mostly universal fashion that allows users to immediately interact with new applications, systems and devices. In this paper, we define Kineticons - an iconographic scheme based on motion. By motion, we mean geometric manipulations applied to a graphical element over time (e.g., scale, rotation, deformation). In contrast to static graphical icons and icons with animated graphics, kineticons do not alter the visual content or "pixel-space" of an element. Although kineticons are not new - indeed, they are seen in several popular systems - we formalize their scope and utility. One powerful quality is their ability to be applied to GUI elements of varying size and shape from a something as small as a close button, to something as large as dialog box or even the entire desktop. This allows a suite of system-wide kinetic behaviors to be reused for a variety of uses. Part of our contribution is an initial kineticon vocabulary, which we evaluated in a 200 participant study. We conclude with discussion of our results and design recommendations.
2011	Temporal distortion for animated transitions	Animated transitions are popular in many visual applications but they can be difficult to follow, especially when many objects move at the same time. One informal design guideline for creating effective animated transitions has long been the use of slow-in/slow-out pacing, but no empirical data exist to support this practice. We remedy this by studying object tracking performance under different conditions of temporal distortion, i.e., constant speed transitions, slow-in/slow-out, fast-in/fast-out, and an adaptive technique that slows down the visually complex parts of the animation. Slow-in/slow-out outperformed other techniques, but we saw technique differences depending on the type of visual transition.
2011	Tactile brush: drawing on skin with a tactile grid display	Tactile Brush is an algorithm that produces smooth, two-dimensional tactile moving strokes with varying frequency, intensity, velocity and direction of motion. The design of the algorithm is derived from the results of psychophysical investigations of two tactile illusions -- apparent tactile mo-tion and phantom sensations. Combined together they allow for the design of high-density two-dimensional tactile displays using sparse vibrotactile arrays. In a series of experiments and evaluations we demonstrate that Tactile Brush is robust and can reliably generate a wide variety of moving tactile sensations for a broad range of applications.
2011	A comparative study of tactile representation techniques for landmarks on a wearable device	Wearable tactile navigation displays may provide an alternative or complement to mobile visual navigation displays. Landmark information may provide a useful complement to directional information for navigation, however, there has been no reported use of landmark information in tactile navigation displays. We report a study that compared two tactile display techniques for landmark representation using one or two actuators respectively. The single-actuator technique generated different vibration patterns on a single actuator to represent different landmarks. The dual-actuator technique generated a single vibration pattern using two simultaneous actuators and different pairs of actuators around the body represented different landmarks. We compared the two techniques on four measures: distinguishability, learnability, short term memorability and user preference. Results showed that users performed equally well when either technique was used to represent landmarks alone. However, when landmark representations were presented together with directional signals, performance with the single-actuator technique was significantly reduced while performance with the dual-actuator technique remained unchanged.
2011	Handscope: enabling blind people to experience statistical graphics on websites through haptics	Statistical graphics on the web such as a tag cloud visually represent statistical data which are generated by website users. While sighted people can scan the latest information through the dynamic changes of statistical graphics, blind people, who cannot perceive them, lose opportunities to keep up to date in this quickly-changing society. In order to enable blind people to experience socially-generated statistical graphics, we propose a new assistive device, namely, Handscope, which translates statistical graphics on websites into simple height changes of its haptic pole. We conducted a two-phase user study with blind people in order to test its usability and explore its effects on the quality of blind users' web experiences. The results show the meaningful contribution of Handscope in extending the area of blind people's web experiences.
2011	Nenya: subtle and eyes-free mobile input with a magnetically-tracked finger ring	We present Nenya, a new input device in the shape of a finger ring. Nenya provides an input mechanism that is always available, fast to access, and allows analog input, while remaining socially acceptable by being embodied in commonly worn items. Users make selections by twisting the ring and "click" by sliding it along the finger. The ring - the size of a regular wedding band - is magnetic, and is tracked by a wrist-worn sensor. Nenya's tiny size, eyes-free usability, and physical form indistinguishable from a regular ring make its use subtle and socially acceptable. We present two user studies (one- and two-handed) in which we studied sighted and eyes-free use, finding that even with no visual feedback users were able to select from eight targets.
2011	The haptic laser: multi-sensation tactile feedback for at-a-distance physical space perception and interaction	We present the Haptic Laser, a system for providing a range of tactile sensations to represent a physical environment at-a-distance. The Haptic Laser is a handheld device that simulates interaction with physical surfaces as a user targets objects of interest (e.g., a light switch, TV, etc). Using simple computer vision techniques for scene analysis and laser range finding for calculating distance, the Haptic Laser extracts information about the physical environment and conveys it haptically through a collection of hardware actuators. Pointing the Haptic Laser around a room, for example, presents the user with information about the presence of objects, transitions, and edges through touch rather than, or in addition to, vision. The Haptic Laser extends current work on haptic touch screens and pens, and is designed to allow for haptic feedback from a distance using multiple feedback channels.
2011	Interactive generator: a self-powered haptic feedback device	We present Interactive Generator (InGen), a self-powered wireless rotary input device capable of generating haptic or force feedback without the need for any external power source. Our approach uses a modified servomotor to perform three functions: (1) generating power for wireless communication and embedded electronics, (2) sensing the direction and speed of rotation, and (3) providing force feedback during rotation. While InGen is rotating, the device is capable of providing the sensation of detents or bumps, changes in stiffness, and abrupt stops using only power that is harvested during interaction. We describe the device in detail, demonstrate an initial 'TV remote control' application, and end with a discussion of our experiences developing the prototype and application. To the best of our knowledge, InGen is the first self-powered device, which also provides haptic feedback during operation. More broadly, this work demonstrates a new class of input sys-tems that uses human-generated power to provide feedback to the user and wirelessly communicate sensed information.
2011	Security through a different kind of obscurity: evaluating distortion in graphical authentication schemes	While a large body of research on image-based authentication has focused on memorability, comparatively less attention has been paid to the new security challenges these schemes may introduce. Because images can convey more information than text, image-based authentication may be more vulnerable to educated guess attacks than passwords. In this paper, we evaluate the resilience of a recognition-based graphical authentication scheme using distorted images against two types of educated guess attacks through two user studies. The first study, consisting of 30 participants, investigates whether distortion prevents educated guess attacks primarily based on information about individual users. The second study, using Amazon Mechanical Turk, investigates whether distortion mitigates the risk of educated guess attacks based on collective information about users. Our results show that authentication images without distortion are vulnerable to educated guess attacks, especially when information about the target is known, and that distortion makes authentication images more resilient against educated guess attacks.
2011	More than skin deep: measuring effects of the underlying model on access-control system usability	In access-control systems, policy rules conflict when they prescribe different decisions (allow or deny) for the same access. We present the results of a user study that demonstrates the significant impact of conflict-resolution method on policy-authoring usability. In our study of 54 participants, varying the conflict-resolution method yielded statistically significant differences in accuracy in five of the six tasks we tested, including differences in accuracy rates of up to 78\%. Our results suggest that a conflict-resolution method favoring rules of smaller scope over rules of larger scope is more usable than the Microsoft Windows operating system's method of favoring deny rules over allow rules. Perhaps more importantly, our results demonstrate that even seemingly small changes to a system's semantics can fundamentally affect the system's usability in ways that are beyond the power of user interfaces to correct.
2011	Does domain highlighting help people identify phishing sites?	Phishers are fraudsters that mimic legitimate websites to steal user's credenfitial information and exploit that information for identity theft and other criminal activities. Various anti-phishing techniques attempt to mitigate such attacks. Domain highlighting is one such approach recently incorporated by several popular web browsers. The idea is simple: the domain name of an address is highlighted in the address bar, so that users can inspect it to determine a web site's legitimacy. Our research asks a basic question: how well does domain highlighting work? To answer this, we showed 22 participants 16 web pages typical of those targeted for phishing attacks, where participants had to determine the page's legitimacy. In the first round, they judged the page's legitimacy by whatever means they chose. In the second round, they were directed specifically to look at the address bar. We found that participants fell into 3 types in terms of how they determined the legitimacy of a web page; while domain highlighting was somewhat effective for one user type, it was much less effective for others. We conclude that domain highlighting, while providing some benefit, cannot be relied upon as the sole method to prevent phishing attacks.
2011	Exploring reactive access control	As users store and share more digital content at home, access control becomes increasingly important. One promising approach for helping non-expert users create accurate access policies is reactive policy creation, in which users can update their policy dynamically in response to access requests that would not otherwise succeed. An earlier study suggested reactive policy creation might be a good fit for file access control at home. To test this, we conducted an experience-sampling study in which participants used a simulated reactive access-control system for a week. Our results bolster the case for reactive policy creation as one mode by which home users specify access-control policy. We found both quantitative and qualitative evidence of dynamic, situational policies that are hard to implement using traditional models but that reactive policy creation can facilitate. While we found some clear disadvantages to the reactive model, they do not seem insurmountable.
2011	Reflecting on pills and phone use: supporting awareness of functional abilities for older adults	Older adults often struggle with maintaining self-aware of their ability to carry out everyday activities important for independence. Unobtrusive sensors embedded in the home can monitor how older adults interact with objects around the home and can provide objective accounts of behaviors to support self-awareness. In this paper, we describe the design and four month deployment of a prototype sensing system that tracks medication taking and phone use in the homes of two older adults. We describe two case studies on 1) how they engaged with the data by looking for and explaining their own anomalous behaviors and 2) how they used the sensor data to reflect on their actions and their own self-awareness of their abilities to remain independent. Finally, we propose recommendations for the design of home sensing systems that support awareness of functional abilities for older adults using reflection.
2011	User-centred multimodal reminders for assistive living	While there has been a lot of research on the usability of reminders and alarms in the work context, the home has been somewhat neglected despite the importance of reminder systems for telecare and assistive living systems. We conducted a comprehensive mixed-methods study into the requirements for useable and acceptable reminders in the home. The study consisted of a questionnaire (N=379), 6 focus groups, and 7 home tour interviews. Our results highlight the need for highly flexible and contextualized multimodal and multi-device reminder solutions that build on existing successful strategies for remembering in and around the home. We suggest that developers of home care reminder systems should design for diversity, context, priorities, autonomy, shared spaces, and optimal care.
2011	Home automation in the wild: challenges and opportunities	Visions of smart homes have long caught the attention of researchers and considerable effort has been put toward enabling home automation. However, these technologies have not been widely adopted despite being available for over three decades. To gain insight into this state of affairs, we conducted semi-structured home visits to 14 households with home automation. The long term experience, both positive and negative, of the households we interviewed illustrates four barriers that need to be addressed before home automation becomes amenable to broader adoption. These barriers are high cost of ownership, inflexibility, poor manageability, and difficulty achieving security. Our findings also provide several directions for further research, which include eliminating the need for structural changes for installing home automation, providing users with simple security primitives that they can confidently configure, and enabling composition of home devices.
2011	Creek watch: pairing usefulness and usability for successful citizen science	Citizen science projects can collect a wealth of scientific data, but that data is only helpful if it is actually used. While previous citizen science research has mostly focused on designing effective capture interfaces and incentive mechanisms, in this paper we explore the application of HCI methods to ensure that the data itself is useful. To provide a focus for this exploration we designed and implemented Creek Watch, an iPhone application and website that allow volunteers to report information about waterways in order to aid water management programs. Working with state and local officials and private groups involved in water monitoring, we conducted a series of contextual inquiries to uncover what data they wanted, what data they could immediately use, and how to most effectively deliver that data to them. We iteratively developed the Creek Watch application and website based on our findings and conducted evaluations of it with both contributors and consumers of water data, including scientists at the city water resources department. Our study reveals that the data collected is indeed useful for their existing practices and is already in use in water and trash management programs. Our results suggest the application of HCI methods to design the data for the end users is just as important as their use in designing the user interface.
2011	Designing eco-feedback systems for everyday life	Eco-feedback systems currently frame householders as micro-resource managers, who weigh up the costs and benefits of their consumption, and make autonomous, rational and efficient decisions. Reporting on findings from a qualitative study of three Australian energy and water eco-feedback programs utilising an in-home display (IHD) system, this paper challenges this view. The research finds that householders consume energy and water to carry out everyday practices, such as showering, laundering and cooling, which are mediated by social, cultural, technical and institutional dynamics. The paper proposes an alternative design paradigm for eco-feedback systems premised on the realities of everyday life and identifies several design directions that emerge from this new starting point.
2011	BeeParking: feedback interfaces for collective behavior change	Recent years have seen a growing interest for the study of feedback interfaces to support behavior change in different research areas, from personal healthcare and wellbeing, to energy saving and proenvironmental sustainability. While HCI design has been primarily inspired by behavior change models that best fit individual change, less attention has been deserved to test their validity in the context of collective behavior change, where interdependencies between people's choices and behaviors matter, as in the shared use of limited resources or public goods. We discuss some relevant directions to fill this gap, based on the iterative design of BeeParking, a feedback display aimed to induce more cooperative use of a parking facility within a work environment.
2011	GreenHat: exploring the natural environment through experts' perspectives	We present GreenHat, an interactive mobile learning application that helps students learn about biodiversity and sustainability issues in their surroundings from experts' points of view, before participating in unfamiliar debates about their familiar surroundings. Using the interactive location-sensitive map and video on a smart phone, GreenHat simulates how experts go about making observations in the field and encourages students to actively observe their environment. We present our design process, our initial prototype, report the results from our preliminary evaluation, and discuss ongoing work.
2011	Telling calls: facilitating mobile phone conversation grounding and management	Current cell phone designs are limited by the information a caller can provide to the receiver at the time of a call. As a result callers are handicapped in effectively negotiating interaction commitment from the receiver, and perhaps more importantly, receivers are unable to make informed call handling decisions. To examine the nature of this information gap we 1) developed Telling Calls , a mobile phone application which allows users to provide and receive information such as what the call is about and the circumstances of the caller under which it is being made, and 2) conducted a qualitative field study (36 users) and a quantitative field study (30 users) of Telling Calls use. Together these studies provide insights on how additional caller generated information shared at the time of call handling effectively improves the process of negotiating interaction commitment, and establishing common ground.
2011	Deep shot: a framework for migrating tasks across devices using mobile phone cameras	A user task often spans multiple heterogeneous devices, e.g., working on a PC in the office and continuing the work on a laptop or a mobile phone while commuting on a shuttle. However, there is a lack of support for users to easily migrate their tasks across devices. To address this problem, we created Deep Shot, a framework for capturing the user's work state that is needed for a task (e.g., the specific part of a webpage being viewed) and resuming it on a different device. In particular, Deep Shot supports two novel and intuitive interaction techniques, deep shooting and deep posting, for pulling and pushing work states, respectively, using a mobile phone camera. In addition, Deep Shot provides a concise API for developers to leverage its services and make their application states migratable. We demonstrated that Deep Shot can be used to support a range of everyday tasks migrating across devices. An evaluation consisting of a series of experiments showed that our framework and techniques are feasible.
2011	Eyes-free multitasking: the effect of cognitive load on mobile spatial audio interfaces	As mobile devices increase in functionality, users perform more tasks when on the move. Spatial audio interfaces offer a solution for eyes-free interaction. However, such interfaces face a number of challenges when supporting multiple and simultaneous tasks, namely: 1) interference amongst multiple audio streams, and 2) the constraints of cognitive load. We present a comparative study of spatial audio techniques evaluated in a divided- and selective-attention task. A podcast was used for high cognitive load (divided-attention) and classical music for low cognitive load (selective-attention), while interacting with an audio menu. Results showed that spatial audio techniques were preferred when cognitive load was kept low, while a baseline technique using an interruptible single audio stream was significantly less preferred. Conversely, when cognitive load was increased the preferences reversed. Thus, given an appropriate task structure, spatial techniques offer a means of designing effective audio interfaces to support eyes-free mobile multitasking.
2011	Feedlack detects missing feedback in web applications	While usability methods such as user studies and inspections can reveal a wide range of problems, they do so for only a subset of an application's features and states. We present FeedLack, a tool that explores the full range of web applications' behaviors for one class of usability problems, namely that of missing feedback. It does this by enumerating control flow paths originating from user input, identifying paths that lack output-affecting code. FeedLack was applied to 330 applications; of the 129 that contained input handlers and did not contain syntax errors, 115 were successfully analyzed, resulting in 647 warnings. Of these 36\% were missing crucial feedback; 34\% were executable and missing feedback, but followed conventions that made feedback inessential; 18\% were scenarios that did produce feedback; 12\% could not be executed. We end with a discussion of the viability of FeedLack as a usability testing tool.
2011	Entity-linking interfaces in user-contributed content: preference and performance	The ability to embed links to other resources in user generated content can help authors create more useful and usable content. A variety of interfaces have emerged for entity-linking at popular online sites; such interfaces vary in the way that entity linking is initiated (in-band or out-of-band with respect to the message creation), the timing of entity resolution (interrupting or deferred), and the method of resolving the entity (auto-completion or search). Four interfaces mimicking popular entity linking websites were developed and tested. Results showed that out-of-band initiation (e.g., a link button) was faster to learn, but that in-band initiation performance improved with familiarity. Deferred search was disliked and led to worse performance. And auto-completion was generally preferred to search interfaces.
2011	Bricolage: example-based retargeting for web design	The Web provides a corpus of design examples unparalleled in human history. However, leveraging existing designs to produce new pages is often difficult. This paper introduces the Bricolage algorithm for transferring design and content between Web pages. Bricolage employs a novel, structured-prediction technique that learns to create coherent mappings between pages by training on human-generated exemplars. The produced mappings are then used to automatically transfer the content from one page into the style and layout of another. We show that Bricolage can learn to accurately reproduce human page mappings, and that it provides a general, efficient, and automatic technique for retargeting content between a variety of real Web pages.
2011	HyperSource: bridging the gap between source and code-related web sites	Programmers frequently use the Web while writing code: they search for libraries, code examples, tutorials, and documentation. This link between code and visited Web pages remains implicit today. Connecting source code and browsing histories might help programmers maintain con-text, reduce the cost of Web page re-retrieval, and enhance understanding when code is shared. This note introduces HyperSource, an IDE augmentation that associates browsing histories with source code edits. HyperSource comprises a browser extension that logs visited pages; an IDE that tracks user activity and maps pages to code edits; a source document model that tracks visited pages at a character level; and a user interface that enables interaction with these histories. We discuss relevance heuristics and privacy issues inherent in this approach. Informal log analyses and user feedback suggest that our annotation model is promising for code editing and might also apply to other document authoring tasks after refinement.
2011	Item sampling for information architecture	When creating a taxonomy for information architecture, practitioners or design participants typically work with a sample of content items to form categories that allow users to successfully navigate to desired information, commands, or items. In order to examine how sample selection affects the coverage of the desired taxonomy, computer simulations were conducted that models the process of sample selection. The simulations reveal how the number of categories, the distribution of items in the taxonomy and the method of selection affect the coverage of a sample at various sizes.
2011	When designing usability questionnaires, does it hurt to be positive?	When designing questionnaires there is a tradition of including items with both positive and negative wording to minimize acquiescence and extreme response biases. Two disadvantages of this approach are respondents accidentally agreeing with negative items (mistakes) and researchers forgetting to reverse the scales (miscoding). The original System Usability Scale (SUS) and an all positively worded version were administered in two experiments (n=161 and n=213) across eleven websites. There was no evidence for differences in the response biases between the different versions. A review of 27 SUS datasets found 3 (11\%) were miscoded by researchers and 21 out of 158 questionnaires (13\%) contained mistakes from users. We found no evidence that the purported advantages of including negative and positive items in usability questionnaires outweigh the disadvantages of mistakes and miscoding. It is recommended that researchers using the standard SUS verify the proper coding of scores and include procedural steps to ensure error-free completion of the SUS by users. Researchers can use the all positive version with confidence because respondents are less likely to make mistakes when responding, researchers are less likely to make errors in coding, and the scores will be similar to the standard SUS.
2011	Synchronous remote usability testing: a new approach facilitated by virtual worlds	This study proposes a new methodology for conducting synchronous remote usability studies using a three-dimensional virtual usability testing laboratory built using the Open Wonderland toolkit. This virtual laboratory method is then compared with two other commonly used synchronous usability test methods: the traditional lab approach and WebEx, a web-based conferencing and screen sharing approach. A study was conducted with 48 participants in total, 36 test participants and 12 test facilitators. The test participants completed 5 tasks on a simulated e-commerce website. The three methodologies were compared with respect to the following dependent variables: the time taken to complete the tasks; the usability defects identified; the severity of these usability defects; and the subjective ratings from NASA-TLX, presence and post-test subjective questionnaires. The three methodologies agreed closely in terms of the total number defects identified, number of high severity defects identified and the time taken to complete the tasks. However, there was a significant difference in the workload experienced by the test participants and facilitators, with the traditional lab condition imposing the least and the virtual lab and the WebEx conditions imposing similar levels. It was also found that the test participants experienced greater involvement and a more immersive experience in the virtual world condition than the WebEx condition. These ratings were not significantly different from those in the traditional lab condition. The results of this study suggest that participants were productive and enjoyed the virtual lab condition, indicating the potential of a virtual world based approach as an alternative to the conventional approaches for synchronous usability testing.
2011	Representing users in accessibility research	The need to study representative users is widely accepted within the human-computer interaction (HCI) community. While exceptions exist, and alternative populations are sometimes studied, virtually any introduction to the process of designing user interfaces will discuss the importance of understanding the intended users as well as the significant impact individual differences can have on how effectively individuals can use various technologies. HCI researchers are expected to provide relevant demographics regarding study participants as well as information about experience using similar technologies. Yet, in the field of accessibility we continue to see studies that do not appropriately include representative users. Highlighting ways to remedy this multifaceted problem, we argue that expectations regarding how accessibility research is conducted and reported must be raised if this field is to have the desired impact with regard to inclusive design, the information technologies studied, and the lives of the individuals being studied.
2011	Democratising technology: making transformation using designing, performance and props	This study of personal transformation is offered as HCI increasingly seeks to change behavior with persuasive products. Performance-derived improvisation methods were used to inspire a sense of agency with ICT in people marginalized from digital design. A case study of an older person's experience shows the techniques supporting her to reconceive her response to technology. In particular, we analyze how using a "prop" as a design artifact allows her to imagine new possibilities and take a more assertive role.
2011	Post-deployment usability: a survey of current practices	Despite the growing research on usability in the pre-development phase, we know little about post-deployment usability activities. To characterize these activities, we surveyed 333 full-time usability professionals and consultants working in large and small corporations from a wide range of industries. Our results show that, as a whole, usability professionals are currently not playing a substantial role in the post-deployment phase compared to other phases of user-centered design, but when they do, practitioners find their interactions quite valuable. We highlight opportunities in HCI research and practice to bridge this gap by working more closely with software support and maintenance teams. We also raise the need to understand what might be called 'usability maintenance,' that is, the process and procedures, by which usability is maintained after deployment.
2011	Collaboration personas: a new approach to designing workplace collaboration tools	The success of social computing has generated a host of workplace collaboration tools. However, adoption of these tools by entire groups is a major problem. One reason for the adoption problem is a lack of methods for considering collaborative groups in technology design. Even when designing collaboration tools, designers often employ methods that focus on individuals. This leads to tools that are not well targeted at the groups who will use them. To solve this problem, we propose the notion of collaboration personas, which are empirically derived descriptions of hypothetical groups, including details that inform the design of collaboration tools. Collaboration personas differ from individual personas in having (1) multiple, inter-related individuals playing specific roles; (2) a focus on collective goals and elaboration of individual goals that affect the collective goal; and (3) new attributes that characterize collaborative aspects of the group's work. We contrast collaboration personas with other design approaches and provide examples of how they can be used to design new collaborative tools that better meet the needs of typical groups.
2011	From garments to gardens: negotiating material relationships online and 'by hand'	From home improvement to scrapbooking, leisure activities performed "by hand" increasingly involve digital tools. In turn, software and devices to support handwork are proliferating. We use data from an observational field study of gardening and knitting to examine relationships to information technology. Handwork experiences of patience, effort, sensation, and cleverness can shift with the introduction of new tools. Our participants' attachment to these experiences made them sensitive to the potential consequences of introducing new tools. Digital tools were sometimes rejected and other times woven into handwork activities. In response, we propose three metaphors for handwork practice - extending, interjecting, and segmenting - as a resource for moving beyond the binary opposition of digital and physical practices.
2011	Persona cases: a technique for grounding personas	Personas are a popular technique in User-Centered Design, however their validity can be called into question. While the techniques used to developed personas and their integration with other design activities provide some measure of validity, a persona's legitimacy can be threatened by challenging its characteristics. This note presents Persona Cases: personas whose characteristics are both grounded in, and traceable to their originating source of empirical data. This approach builds on the premise that sense-making in qualitative data analysis is an argumentative activity, and aligns concepts associated with a Grounded Theory analysis with recent work on arguing the characteristics of personas. We illustrate this approach using a case study in the Critical Infrastructure Protection domain.
2011	When the implication is not to design (technology)	As HCI is applied in increasingly diverse contexts, it is important to consider situations in which computational or information technologies may be less appropriate. This paper presents a series of questions that can help researchers, designers, and practitioners articulate a technology's appropriateness or inappropriateness. Use of these questions is demonstrated via examples from the literature. The paper concludes with specific arguments for improving the conduct of HCI. This paper provides a means for understanding and articulating the limits of HCI technologies, an important but heretofore under-explored contribution to the field.
2011	Utility of human-computer interactions: toward a science of preference measurement	The success of a computer system depends upon a user choosing it, but the field of Human-Computer Interaction has little ability to predict this user choice. We present a new method that measures user choice, and quantifies it as a measure of utility. Our method has two core features. First, it introduces an economic definition of utility, one that we can operationalize through economic experiments. Second, we employ a novel method of crowdsourcing that enables the collection of thousands of economic judgments from real users.
2011	Informing decisions: how people use online rating information to make choices	In this paper we investigate how people use online rating information to inform decision making. We examine whether a theory of searching for information to discriminate between alternative choices can explain behavior, and we contrast it to the normative theory. Partly in accord with the theory, findings from a controlled experiment suggest that in an environment dominated by positive reviews, such as the World-Wide Web, people gather more information for the best alternative under consideration, and they take more time to inspect reviews of lower rating. We discuss the theoretical and experimental implications, and propose a bounded optimal account of the way in which people acquire information in service of decision making.
2011	Oops, I did it again: mitigating repeated access control errors on facebook	We performed a study of Facebook users to examine how they coped with limitations of the Facebook privacy settings interface. Students graduating and joining the workforce create significant problems for all but the most basic privacy settings on social networking websites. We therefore created realistic scenarios exploiting work/play boundaries that required users to specify access control policies that were impossible due to various limitations. We examined whether users were aware of these problems without being prompted, and once given feedback, what their coping strategies were. Overall, we found that simply alerting participants to potential errors was ineffective, but when choices were also presented, participants introduced significantly fewer errors. Based on our findings, we designed a privacy settings interface based on Venn diagrams, which we validated with a usability study. We conclude that this interface may be more effective than the current privacy settings interface.
2011	Integrating user feedback with heuristic security and privacy management systems	Tools aimed at helping users safely navigate the web and safeguard themselves against potential online predators have become reasonably common. Currently there are two families of tools; heuristics analysis tools that test websites directly using automated scripts and programs, and community based tools where users rate websites and write reviews for the benefit of others. In this paper we examine the relative strengths and weaknesses of each technique, whether these techniques are compatible, and how community feedback can be combined with heuristic-based evaluations. In order to do this we conduct a large-scale comparison of the ratings of heuristic and community based tools, and explore novel methods for abstracting key information from user comments, which could be used to add context and nuance to heuristic based ratings. We find that heuristic and community based ratings are highly complementary, and can be combined to potentially guide users to make more informed decisions.
2011	Pairing devices for social interactions: a comparative usability evaluation	When users wish to establish wireless radio communication between/among their devices, the channel has to be bootstrapped first. The process of setting up a secure communication channel between two previously unassociated devices is referred to as "Secure Device Pairing". The focus of prior research on this topic has mostly been limited to "personal pairing" scenarios, whereby a single user controls both the devices. In this paper, we instead consider "social pairing" scenarios, whereby two different users establish pairing between their respective devices. We present a comprehensive study to identify methods suitable for social pairing, and comparatively evaluate the usability and security of these methods. Our results identify methods best-suited for users, in terms of efficiency, error-tolerance and of course, usability. Our work provides insights on the applicability and usability of methods for emerging social pairing scenarios, a topic largely ignored so far.
2011	Experiencing security in interaction design	Security is experienced differently in different contexts. This paper argues that in everyday situations, users base their security decisions on a mix of prior experiences. When approaching security and interaction design from an experience approach, tools that help bring out such relevant experiences for design are needed. This paper reports on how Prompted exploration workshops and Acting out security were developed to target such experiences when iteratively designing a mobile digital signature solution in a participatory design process. We discuss how these tools helped the design process and illustrate how the tangibility of such tools matters. We further demonstrate how the approach grants access to non-trivial insights into people's security experience. We point out how the specific context is essential for exploring the space between experience and expectations, and we illustrate how people activate their collections of security experiences rather than deploying one security strategy in all situations.
2011	Building sensitising terms to understand free-play in open-ended interactive art environments	In this paper we introduce and discuss the nature of free-play in the context of three open-ended interactive art installation works. We observe the interaction work of situated free-play of the participants in these environments and, building on precedent work, devise a set of sensitising terms derived both from the literature and from what we observe from participants interacting there. These sensitising terms act as guides and are designed to be used by those who experience, evaluate or report on open-ended interactive art. That is, we propose these terms as a common-ground language to be used by participants communicating while in the art work to describe their experience, by researchers in the various stages of research process (observation, coding activity, analysis, reporting, and publication), and by inter-disciplinary researchers working across the fields of HCI and art. This work builds a foundation for understanding the relationship between free-play, open-ended environments, and interactive installations and contributes sensitising terms useful for the HCI community for discussion and analysis of open-ended interactive art works.
2011	Evaluating the benefits of 3d stereo in modern video games	We present a study that investigates user performance benefits of 3D stereo in modern video games. Based on an analysis of several video games that are best suited for use with commercial 3D stereo drivers and vision systems, we chose five modern titles focusing on racing, first and third person shooter, and sports game genres. For each game, quantitative and qualitative measures were taken to determine if users performed better and learned faster in the experimental group (3D stereo display) than in the control group (2D display). A game experience pre-questionnaire was used to classify participants into beginner, intermediate, and advanced gameplay categories to ensure prior game experience did not bias the experiment. Our results indicate that although participants preferred playing in 3D stereo for the games we tested, it does not provide any significant advantage in overall user performance. In addition, users' learning rates were comparable in the 3D stereo display and 2D display cases.
2011	Target assistance for subtly balancing competitive play	In games where skills such as targeting are critical to winning, it is difficult for players with different skill levels to have a competitive and engaging experience. Although several mechanisms for accommodating different skill levels have been proposed, traditional approaches can be too obvious and can change the nature of the game. For games involving aiming, we propose the use of target assistance techniques (such as area cursors, target gravity, and sticky targets) to accommodate skill imbalances. We compared three techniques in a study, and found that area cursors and target gravity significantly reduced score differential in a shooting-gallery game. Further, less skilled players reported having more fun when the techniques helped them be more competitive, and even after they learned assistance was given, felt that this form of balancing was good for group gameplay. Our results show that target assistance techniques can make target-based games more competitive for shared play.
2011	Data cracker: developing a visual game analytic tool for analyzing online gameplay	Game analytics is a domain that focuses on the systems and methods used to analyze game-related data. In this paper we present how a visual game analytic tool can be developed to analyze player gameplay behavior. Our tool, Data Cracker, was built for monitoring gameplay in Dead Space 2, the latest game in the Dead Space franchise. We use Data Cracker as a case study to inform a larger discussion of designing a visual game analytic tool while working with a game team. Our design approach focuses on increasing the data literacy of a game team. This means getting an entire team interested and involved with game analytics. We found that building our tool during the early game development cycle, creating multiple early visual prototypes and branding the tool to the Dead Space team caused more team members to become interested in our tool. Increasing interest in analytics is also a means, we argue, for changing the common occurrence within the game industry to disband teams after a game is released. Instead, we promote the creation of "live" teams which stay attached to a game long after it is release in order to continue the analysis process. Additionally, we discuss the barriers one might face when developing game analytic tools, such as prejudice against analytics or the technical issues involved when collecting large data sets. All of these examples are presented as insights we gained while coupling analytic tool design to game development.
2011	Ceci n'est pas une pipe bombe: authoring urban landscapes with air quality sensors	Our work explores the convergence between participatory sensing, political activism and public expressions. Unlike prior research, which focuses on personal sensing, we present low-cost, networked air quality sensors, designed to be repositioned across public landscapes by communities of citizen stakeholders. Our GPS-enabled sensors report dust, exhaust, or VOC's (volatile organic compounds), along with temperature, humidity and light levels to a website that visualizes this data in real time. The sensors can be attached to a variety of surfaces serving as research probes to demarcate ('tag') public spaces with environmental concerns. We deploy our fully functional system with four urban communities - parents, bicyclists, homeless and activists, positioning our system as a tool for studying and supporting community togetherness and public activism. Our findings highlight community sharing of the physical sensors and dialogues surrounding the collected data.
2011	Second-hand interactions: investigating reacquisition and dispossession practices around domestic objects	We present a qualitative study of reacquisition-the acquisition of previously possessed goods-involving in-depth interviews with 18 reacquirers within or nearby Pittsburgh, PA, USA. Based on critiques of sustainable consumption and our findings, we reframe technology consumption as acquisition, possession, dispossession and reacquisition. We present four reacquisition orientations describing our participants' motivations and practices: casual, necessary, critical, and experiential. We then present a range of findings including issues with work, time and effort involved in reacquisition, and values and practices of care and patience associated with invested reacquirers. We conclude with implications for designing technologies to support current reacquisition practices, as well as broader opportunities for HCI and interaction design to incorporate non-mainstream reacquisition practices and values into more mainstream technologies.
2011	Practices in the creative reuse of e-waste	E-waste is a generic term embracing various forms of electric and electronic equipment that is loosely discarded, surplus, obsolete, or broken [27]. When e-waste is improperly discarded as trash, there are predictable negative impacts on the environment and human health. Existing e-waste solutions range from designing for reuse to fabricating with eco-friendly decomposable materials to more radical critiques of current practices surrounding capitalism and consumerism. Complementary to theses efforts, this paper presents an accessible reuse framework that encourages creativity while maintaining personal ownership of e-waste. Through a series of online surveys of existing personal e-waste stockpiling behaviors combined with observational studies of existing reuse practices, we developed a design reuse vocabulary: materials, shapes, and operations to enable wide ranging and creative reuse of obsolete electronics by everyday people. We operationalized this vocabulary and evaluated its legibility and usefulness. As a result, we derived a novel reuse composition framework: reuse as-is, remake, and remanufacture designed to be accessible and to have broader impact in encouraging creative reuse across a wide range of e-waste types beyond those specifically used in our study. We believe these frameworks will be a catalyst for the creative reuse of e-waste.
2011	A phenomenology of human-electricity relations	This paper investigates the philosophical question of how we can experience energy with the aim of informing the design of future ways of experiencing energy by means of technology. Four human-technology relations formulated by philosopher of technology Don Ihde are presented. Each is then developed in the context of electrical interactive technologies. In conclusion these human-electricity and human-technology relations are employed in order to interpret current work related to energy and sustainability within HCI and point to future work in these areas.
2011	I'm the mayor of my house: examining why people use foursquare - a social-driven location sharing application	There have been many location sharing systems developed over the past two decades, and only recently have they started to be adopted by consumers. In this paper, we present the results of three studies focusing on the foursquare check-in system. We conducted interviews and two surveys to understand, both qualitatively and quantitatively, how and why people use location sharing applications, as well as how they manage their privacy. We also document surprising uses of foursquare, and discuss implications for design of mobile social services.
2011	In the best families: tracking and relationships	A growing body of research has been exploring the use of control mechanisms to address the privacy concerns raised by location-tracking technology. We report on a qualitative study of two family groups who used a custom-built tracking application for an extended period of time. Akin to sociological breaching experiments, the study focuses on the interferences between location tracking and relationship management. We analyze the tensions that can arise between affordances of the technology and uses that the contracts between family members legitimize. We describe how, by fostering misperceptions and 'nudging' behaviors, location-tracking technology can generate anxieties and conflicts even in close relationships. We discuss their vulnerability to the overreaching effects of tracking, against which the use of mechanisms such as location-sharing preferences and feedback may not be socially viable.
2011	Opportunities exist: continuous discovery of places to perform activities	A rich cognitive map of a space can enhance the individual's experience within the space. However, cognitive maps develop gradually through repeated experience; and because of this, on-demand mobile search services ( e.g. , Google Maps, Yelp) are often used to compensate for missing knowledge. In this work, we developed and evaluated a context-aware place discovery application called Opportunities Exist to assist in the acquisition of spatial knowledge and meaning. The application differs from traditional search in that places are discovered using an activity ( e.g. , drink coffee, sit in the sun) and the discovery process runs continuously, maintaining a history of places the user can perform her activities as she goes about her day. We conducted a 4-week deployment in two North American cities. The results show that users were able to discover new places to perform their activities in familiar spaces and learned to associate new activities with familiar places. In addition, participants leveraged the application to perform activities opportunistically, and used continuous place discovery as an opportunistic reminder of routines they wanted to break out of or resume.
2011	Location visualization in social media applications	Location sharing applications are becoming increasingly popular in social media and for use on mobile devices, yet little research has focused on their user interface design. In this paper we describe our method of charting and creating comparable designs, and present a survey-based study of 106 social media users on their preferences regarding location indicators. Our paper contributes in proposing a methodology for visual element evaluation purposes, and reveals results, e.g., that users preferred simple indicators such as points or pins for their own location, and friend location indicators to include the corresponding name.
2011	When are users comfortable sharing locations with advertisers?	As smartphones and other mobile computing devices have increased in ubiquity, advertisers have begun to realize a more effective way of targeting users and a promising area for revenue growth: location-based advertising. This trend brings to bear new questions about whether or not users will adopt products involving this potentially invasive form of advertising and what sorts of protections they should be given. Our real-world user study of 27 participants echoes earlier findings that users have significant privacy concerns regarding sharing their locations with advertisers. However, we examine these concerns in more detail and find that they are complex (e.g., relating not only to the quantity of ads, but the locations and times at which they are received). With advanced privacy settings, users stated they would feel more comfortable and share more information than with a simple opt-in/opt-out mechanism.
2011	Typing on flat glass: examining ten-finger expert typing patterns on touch surfaces	Touch screen surfaces large enough for ten-finger input have become increasingly popular, yet typing on touch screens pales in comparison to physical keyboards. We examine typing patterns that emerge when expert users of physical keyboards touch-type on a flat surface. Our aim is to inform future designs of touch screen keyboards, with the ultimate goal of supporting touch-typing with limited tactile feedback. To study the issues inherent to flat-glass typing, we asked 20 expert typists to enter text under three conditions: (1) with no visual keyboard and no feedback on input errors, then (2) with and (3) without a visual keyboard, but with some feedback. We analyzed touch contact points and hand contours, looking at attributes such as natural finger positioning, the spread of hits among individual keys, and the pattern of non-finger touches. We also show that expert typists exhibit spatially consistent key press distributions within an individual, which provides evidence that eyes-free touch-typing may be possible on touch surfaces and points to the role of personalization in such a solution. We conclude with implications for design.
2011	CHANTI: predictive text entry using non-verbal vocal input	This paper introduces a text entry application for users with physical disabilities who cannot utilize a manual keyboard. The system allows the user to enter text hands-free, with the help of "Non-verbal Vocal Input" (e.g., humming or whistling). To keep the number of input sounds small, an ambiguous keyboard is used. As the user makes a sequence of sounds, each representing a subset of the alphabet, the program searches for matches in a dictionary. As a model for the system, the scanning-based application QANTI was redesigned and adapted to accept the alternative input signals. The usability of the software was investigated in an international longitudinal study done at locations in the Czech Republic, Germany, and the United States. Eight test users were recruited from the target community. The users differed in the level of speech impairment. Three users did not complete the study due to the severity of their impairment. By the end of the experiment, the users were able to enter text at rates between 10 and 15 characters per minute.
2011	AirStroke: bringing unistroke text entry to freehand gesture interfaces	In this paper, we explore the opportunity of bringing unistroke text entry to freehand gesture interfaces. Using existing text entry methods directly in such interfaces is impractical because of the differences between freehand gestures and traditional forms of input. To address this problem, we consider the design constraints of text entry methods using freehand gestures, and present AirStroke, a new technique based on a reengineering of the well-known unistroke technique Graffiti. Using Graffiti's alphabet, AirStroke takes advantage of the richer input capabilities of two-handed freehand gestures by providing combined mode selection and character entry with one hand, as well as word completion with the other hand. A longitudinal study suggests that AirStroke has competitive speed and accuracy to unistroke methods based on stylus input.
2011	Sampling representative phrase sets for text entry experiments: a procedure and public resource	Text entry experiments evaluating the effectiveness of various input techniques often employ a procedure whereby users are prompted with natural language phrases which they are instructed to enter as stimuli. For experimental validity, it is desirable to control the stimuli and present text that is representative of a target task, domain or language. MacKenzie and Soukoreff (2001) manually selected a set of 500 phrases for text entry experiments. To demonstrate representativeness, they correlated the distribution of single letters in their phrase set to a relatively small (by current standards) corpus of English prior to 1966, which may not reflect the style of text input today. In this paper, we ground the notion of representativeness in terms of information theory and propose a procedure for sampling representative phrases from any large corpus so that researchers can curate their own stimuli. We then describe the characteristics of phrase sets we generated using the procedure for email and social media (Facebook and Twitter). The phrase sets and code for the procedure are publicly available for download.
2011	Enhancing physicality in touch interaction with programmable friction	Touch interactions have refreshed some of the 'glowing enthusiasm' of thirty years ago for direct manipulation interfaces. However, today's touch technologies, whose interactions are supported by graphics, sounds or crude clicks, have a tactile sameness and gaps in usability. We use a Large Area Tactile Pattern Display (LATPaD) to examine design possibilities and outcomes when touch interactions are enhanced with variable surface friction. In a series of four studies, we first confirm that variable friction gives significant performance advantages in low-level targeting activities. We then explore the design space of variable friction interface controls and assess user reactions. Most importantly, we demonstrate that variable friction can have a positive impact on the enjoyment, engagement and sense of realism experienced by users of touch interfaces.
2011	Designing tactile feedback for piezo buttons	The present aim was to study the preference of tactile feedback stimulations given by non-physical (i.e., solid) piezo-actuated buttons. Participants ( n =16) ranked 16 different tactile feedback stimuli varied by 4 output delays and 4 vibration durations. The results showed that the mean ranks of the stimuli differed significantly from each other. The timing parameters of delay and duration interacted with each other, for example, so that preference of certain vibration duration fluctuated in response to different output delays. Using a very short time window (i.e., 10-453 ms) combining both delay and duration parameters of the feedback could result either in favorable or significantly less favorable subjective experience. The results suggest that a preferred perception of tactile feedback from non-physical buttons requires careful design and controlling of the timing parameters.
2011	LiquidText: a flexible, multitouch environment to support active reading	Active reading, involving acts such as highlighting, writing notes, etc., is an important part of knowledge workers' activities. Most computer-based active reading support seeks to replicate the affordances of paper, but paper has limitations, being in many ways inflexible. In this paper we introduce LiquidText, a computer-based active reading system that takes a fundamentally different approach, offering a flexible, fluid document representation built on multitouch input, with a range of interaction techniques designed to facilitate the activities of active reading. We report here on our design for LiquidText, its interactions and gesture vocabulary, and our design process, including formative user evaluations which helped shape the final system.
2011	Dimensions of collaboration on a tabletop interface for children with autism spectrum disorder	In this paper we describe a co-located suite of games on a tabletop device to support social competence training for children with Autism Spectrum Disorder. This suite has been designed to use patterns of collaboration to support therapists in their use of Cognitive-Behavioral Therapy (CBT). In this paper, we discuss the observations collected during a field study where two therapists used the system for social competence training sessions with 8 children. We conclude with lessons learned from meshing software enhanced collaboration within the CBT model.
2011	MemTable: an integrated system for capture and recall of shared histories in group workspaces	This paper presents the design, implementation, and evaluation of an interactive tabletop system that supports co-located meeting capture and asynchronous search and review of past meetings. The goal of the project is to evaluate the design of a conference table that augments the everyday work patterns of small collaborative groups by incorporating an integrated annotation system. We present a holistic design that values hardware ergonomics, supports heterogeneous input modalities, generates a memory of all user interactions, and provides access to historical data on and off the table. We present a user evaluation that assesses the usefulness of the input modalities and software features, and validates the effectiveness of the MemTable system as a tool for assisting memory recall.
2011	Distinguishing multiple smart-phone interactions on a multi-touch wall display using tilt correlation	While very large collaborative surfaces are already being widely employed to facilitate concurrent interactions with multiple users, they involve no personalization in the touch interactions. Augmenting them to identify the touch interactions with multiple smart-phones can enable interesting co-located communal applications with context-based personalized interactions and information exchange amongst users' portable devices and the shared wall display. This paper proposes a novel matching technique, called tilt correlation, which employs the built-in tilt sensor to identify smart-phones that make concurrent two-point contacts on a common multi-touch wall display. Experimental investigations suggest that the resultant error rate is relatively low; in addition, we also propose a quantitative measure, called the Bourne Identity Index to allow application designers to determine the reliability of each device identification.
2011	Through the troll forest: exploring tabletop interaction design for children with special cognitive needs	We describe the interaction design process of conceiving, designing, implementing, and testing Trollskogen, a purpose-built tabletop multitouch system featuring a range of small software applications, termed 'micro applications'. Each micro application is devised as a tool intended to improve or allow for exercise of social communication skills. Throughout the project, we have worked closely with a group of six children diagnosed with Autism Spectrum Disorder (ASD) or Down's syndrome, all in the age range of 5-8. The system has been designed together with the users, their teachers, and various experts as a complement to the current curricula. In this paper, the three main phases of our design process are described and we conclude the paper by reporting on and discussing some preliminary findings and observations from a small user study.
2011	Exploring the potential for touchless interaction in image-guided interventional radiology	The growth of image-guided procedures in surgical settings has led to an increased need to interact with digital images under sterile conditions. Traditional touch-based interaction techniques present challenges for managing asepsis in these environments leading to suggestions that new touchless interaction techniques may provide a compelling set of alternatives. In this paper we explore the potential for touchless interaction in image-guided Interventional Radiology (IR) through an ethnographic study. The findings highlight how the distribution of labour and spatial practices of this work are organised with respect to concerns about asepsis and radiation exposure, the physical and cognitive demands of artefact manipulation, patient management, and the construction of "professional vision". We discuss the implications of these key features of the work for touchless interaction technologies within IR and suggest that such issues will be of central importance in considering new input techniques in other medical settings.
2011	AnatOnMe: facilitating doctor-patient communication using a projection-based handheld device	In this paper, we explore the use of a projection-based handheld device to facilitate in-clinic doctor-patient communication. We present the user-centered design process used to understand the workflow of medical professionals and to identify challenges they currently face in communicating information to patients. Based on the lessons learned, we developed AnatOnMe, a prototype projection-based hand-held system for enhancing information exchange in the current practice of one medical sub-specialty, physical therapy. We then present the results of a controlled experiment to understand the desirability and learning tradeoffs of using AnatOnMe to teach medical concepts on three potential projection surfaces - wall, model, and patient body. Finally, we present results of two expert reviews of the system.
2011	Unpacking exam-room computing: negotiating computer-use in patient-physician interactions	The presence of computers - especially desktops - takes significant time and attention away from patients during medical visits. As a result, patients may feel disengaged and disregarded. In this study, we examined the impact of using "Computer-on-Wheels" (COWs) in exam-rooms. We found physicians constantly reorienting and resituating exam-room computers to different positions during the three stages of a medical visit: communication-intensive phase, lecturing phase and ordering phase. We refer to this behavior as micro-negotiation of computer-use. Analysis of its usage patterns, as well as physician and patient perceptions, show that micro-negotiations facilitate eye contact expression and encourage patient participation in medical visits. In addition, we identify two tensions and two unintended benefits resulting from micro-negotiations. These findings lead us to consider new modes of negotiation in the exam-room that could alleviate the tensions identified while enabling physicians to continue enjoying micro-negotiation benefits in their work practice.
2011	CPOE workarounds, boundary objects, and assemblages	We conducted an ethnographically based study at a large teaching hospital to examine clinician workarounds engendered by the adoption of a Computerized Prescribe Order Entry (CPOE) system. Specifically, we investigated how adoption of computerized systems may alter medical practice, order management in particular, as manifested through the working-around behavior developed by doctors and nurses to accommodate the changes in their day-to-day work environment. In this paper, we focus on clinicians' workarounds, including those workarounds that gradually disappeared and those that have become routinized. Further, we extend the CSCW concept of boundary object (to "assemblage") in order to understand the workarounds created with CPOE system use and the changing nature of clinical practices that are increasingly computerized.
2011	Wrangler: interactive visual specification of data transformation scripts	Though data analysis tools continue to improve, analysts still expend an inordinate amount of time and effort manipulating data and assessing data quality issues. Such "data wrangling" regularly involves reformatting data values or layout, correcting erroneous or missing values, and integrating multiple data sources. These transforms are often difficult to specify and difficult to reuse across analysis tasks, teams, and tools. In response, we introduce Wrangler , an interactive system for creating data transformations. Wrangler combines direct manipulation of visualized data with automatic inference of relevant transforms, enabling analysts to iteratively explore the space of applicable operations and preview their effects. Wrangler leverages semantic data types (e.g., geographic locations, dates, classification codes) to aid validation and type conversion. Interactive histories support review, refinement, and annotation of transformation scripts. User study results show that Wrangler significantly reduces specification time and promotes the use of robust, auditable transforms instead of manual editing.
2011	The concept maps method as a tool to evaluate the usability of APIs	Application programming interfaces (APIs) are the interfaces to existing code structures, such as widgets, frameworks, or toolkits. Therefore, they very much do have an impact on the quality of the resulting system. So, ensuring that developers can make the most out of them is an important challenge. However standard usability evaluation methods as known from HCI have limitations in grasping the interaction between developer and API as most IDEs (essentially the GUI) capture only part of it. In this paper we present the Concept Map method to study the usability of an API over time. This allows us to elicit the mental model of a programmer when using an API and thereby identify usability issues and learning barriers and their development over time.
2011	Shared substance: developing flexible multi-surface applications	This paper presents a novel middleware for developing flexible interactive multi-surface applications. Using a scenario-based approach, we identify the requirements for this type of applications. We then introduce Substance , a data-oriented framework that decouples functionality from data, and Shared Substance , a middleware implemented in Substance that provides powerful sharing abstractions. We describe our implementation of two applications with Shared Substance and discuss the insights gained from these experiments. Our finding is that the combination of a data-oriented programming model with middleware support for sharing data and functionality provides a flexible, robust solution with low viscosity at both design-time and run-time.
2011	OldGen: mobile phone personalization for older adults	Mobile devices are currently difficult to customize for the usability needs of elderly users. The elderly are instead referred to specially designed "senior phones" or software add-ons. These tend to compromise in functionality as they attempt to solve many disabilities in a single solution. We present OldGen, a prototype framework where a novel concept enables accessibility features on generic mobile devices, by decoupling the software user interface from the phone's physical form factor. This opens up for better customization of the user interface, its functionality and behavior, and makes it possible to adapt it to the specific needs of each individual. OldGen makes the user interface portable, such that it could be moved between different phone hardware, regardless of model and brand. Preliminary observations and evaluations with elderly users indicate that this concept could address individual user interface related accessibility issues on general-purpose devices.
2011	Dinah: an interface to assist non-programmers with selecting program code causing graphical output	The web holds an abundance of source code examples with the potential to become learning resources for any end-user. However, for some end-users these examples may be unusable. An example is unusable if a user cannot select the code in the example that corresponds to their interests. Research suggests that non-programmers struggle to correctly select the code responsible for interesting output functionality. In this paper we present Dinah: an interface to support non-programmers with selecting code causing graphical output. Dinah assists non-programmers by providing concurrency support and in-context affordances for statement replay and temporally based navigation.
2011	Normative influences on thoughtful online participation	We describe two experiments on whether individual thoughtful effort during online commenting is shaped by situational norms derived from the behavior of social others and the design of the environment, respectively. By measuring the length of participants' comments on a news website, the time taken to write them, and the number of issue-relevant thoughts they contain, we demonstrate that participants conform to high vs. low norms of thoughtfulness manifested through either the apparent behavior of other users or through visual, textual and interactional design features conceptually associated with thoughtfulness. Theoretical and applied insights for designing online participatory environments are discussed.
2011	My kind of people?: perceptions about wikipedia contributors and their motivations	Perceptions of information products such as Wikipedia can depend on assumptions and stereotypes about the people who create them. As new Wikipedians consider contributing they are likely to apply such assumptions and ask themselves: "Are Wikipedia contributors my kind of people? Is this a group I'd like to belong to?" In this qualitative study I address the potential challenge of these questions by exploring readers and infrequent editors' perceptions of Wikipedia contributors and their motivations. Through analysis of twenty semi-structured interviews, I find evidence of strong negative perceptions as well as positive ones which nonetheless prevent users from identifying with active Wikipedia contributors. I argue that these perceptions present a barrier to the progression of participation over time. I conclude by discussing the practical challenges of my findings for Wikipedia and other online collaborative systems.
2011	Computers can't give credit: how automatic attribution falls short in an online remixing community	In this paper, we explore the role that attribution plays in shaping user reactions to content reuse, or remixing, in a large user-generated content community. We present two studies using data from the Scratch online community - a social media platform where hundreds of thousands of young people share and remix animations and video games. First, we present a quantitative analysis that examines the effects of a technological design intervention introducing automated attribution of remixes on users' reactions to being remixed. We compare this analysis to a parallel examination of "manual" credit-giving. Second, we present a qualitative analysis of twelve in-depth, semi-structured, interviews with Scratch participants on the subject of remixing and attribution. Results from both studies suggest that automatic attribution done by technological systems (i.e., the listing of names of contributors) plays a role that is distinct from, and less valuable than, credit which may superficially involve identical information but takes on new meaning when it is given by a human remixer. We discuss the implications of these findings for the designers of online communities and social media platforms.
2011	Identifying shared leadership in Wikipedia	In this paper, we introduce a method to measure shared leadership in Wikipedia as a step in developing a new model of online leadership. We show that editors with varying degrees of engagement and from peripheral as well as central roles all act like leaders, but that core and peripheral editors show different profiles of leadership behavior. Specifically, we developed machine learning models to automatically identify four types of leadership behaviors from 4 million messages sent between Wikipedia editors. We found strong evidence of shared leadership in Wikipedia, with editors in peripheral roles producing a large proportion of leadership behaviors.
2011	Donate for credibility: how contribution incentives can improve credibility	This study explores whether certain contribution incentives for online user-generated content can undermine or enhance contributor's credibility. In an online experiment, we found that contributors who are rewarded with donations made in their names are perceived to be more credible than contributors who are financially compensated through revenue-sharing or contribute voluntarily. In addition, disclosing the chosen charity for donation can also impact credibility. Content viewer's self-identification with charity and the congruency between charity and content topic are both factors that may enhance credibility. Our findings lead to practical implications on when and how to use contribution incentives to enhance credibility.
2011	Should I open this email?: inbox-level cues, curiosity and attention to email	The quantity of email people receive each day can be overwhelming. Previous research suggests that when handling email, individuals prioritize certain messages for attention over others. Since people generally make this decision about which message to read before opening the email, the question largely unanswered in the email literature is: what surface features of an email draw attention to it? In this research, we examined how top-level cues about an email's content influence attention to email. We describe results from a think-aloud study examining people's stated rationale for prioritizing certain emails over others. Based on these results and theory on curiosity, we conducted an experiment examining how message importance, subject line specificity, workload and personal utility influence attention to email. Results suggest that uncertainty about message content at the inbox level increases the likelihood of attention to a message. The influence of uncertainty diminishes, however, in the face of enhanced task and personal utility cues and increased demand, suggesting that curiosity operates in an intrinsic way in the email context. Our results have implications for intelligent email system design, email client interfaces, and reducing email strain.
2011	Am I wasting my time organizing email?: a study of email refinding	We all spend time every day looking for information in our email, yet we know little about this refinding process. Some users expend considerable preparatory effort creating complex folder structures to promote effective refinding. However modern email clients provide alternative opportunistic methods for access, such as search and threading, that promise to reduce the need to manually prepare. To compare these different refinding strategies, we instrumented a modern email client that supports search, folders, tagging and threading. We carried out a field study of 345 long-term users who conducted over 85,000 refinding actions. Our data support opportunistic access. People who create complex folders indeed rely on these for retrieval, but these preparatory behaviors are inefficient and do not improve retrieval success. In contrast, both search and threading promote more effective finding. We present design implications: current search-based clients ignore scrolling, the most prevalent refinding behavior, and threading approaches need to be extended.
2011	Using email to facilitate wiki-based coordinated, collaborative authoring	Dandelion is a wiki-based tool that supports coordinated, collaborative authoring. In this paper, we present an ex-tended version of Dandelion, which provides an email inter-face for users to accomplish their tasks by email in a coordinated, collaborative authoring process. Specifically, Dandelion employs a semi-structured, template-based approach that allows users to use templates to specify their requests in email. These emailed requests can be interpreted by Dandelion and are then used to automatically drive the collaboration flow. As part of its actions, Dandelion automatically creates a wiki page and dynamically updates it to record co-authoring tasks and collate co-authored content. As a result, users can use their familiar tool (email) to accomplish their tasks in a co-authoring process, while leveraging a wiki for additional benefits (e.g., obtaining collaboration awareness and formatting the text). Our preliminary study with two groups of users shows the usefulness of both Dandelion email and wiki features and their impact on collaboration effectiveness.
2011	F for fake: four studies on how we fall for phish	This paper reports findings from a multi-method set of four studies that investigate why we continue to fall for phish. Current security advice suggests poor spelling and grammar in emails can be signs of phish. But a content analysis of a phishing archive indicates that many such emails contain no obvious spelling or grammar mistakes and often use convincing logos and letterheads. An online survey of 224 people finds that although phish are detected approximately 80\% of the time, those with logos are significantly harder to detect. A qualitative interview study was undertaken to better understand the strategies used to identify phish. Blind users were selected because it was thought they may be more vulnerable to phishing attacks, however they demonstrated robust strategies for identifying phish based on careful reading of emails. Finally an analysis was undertaken of phish as a literary form. This identifies the main literary device employed as pastiche and draws on critical theory to consider why security based pastiche may be currently very persuasive.
2012	Health promotion as activism: building community capacity to effect social change	As HCI researchers have designed tools to promote wellness, disease has often been approached as a general problem. In contrast, public health research argues for an activist approach focused on how certain groups disproportionately experience disease and eliminating these disparities. Taking this activist stance, we examine how technology can reduce health inequalities by disrupting power relationships and helping communities pursue social change. We discuss our tool, Community Mosaic (CM), which allows individuals to share their healthy eating ideas with one another as a means of advocating behavior change. Our results characterize how CM helped facilitate activism (i.e., collective efforts to counter local challenges to healthy living) and shift users' attitudes regarding their role as advocates for health. We contribute to the field of HCI by using our findings to present a set of recommendations for future research focused on designing and evaluating health promotion tools using an activist lens.
2012	Laying the table for HCI: uncovering ecologies of domestic food consumption	Food contributes fundamentally to our well-being: physically, mentally, and socially. Unsurprisingly then, the importance of food to our lives has long been recognized in the social sciences, and more recently, in Human-Computer Interaction. Yet, despite ongoing trends towards the digital augmentation of domestic environments, little consideration has been given to the impact of the material aspects of food consumption in the home. This paper takes an ecological approach to uncovering the role spaces, tabletops, and artefacts play in the social organization of domestic eating practices. Based on our findings of interviews with seven households in England, we discuss implications for those seeking to digitally augment domestic dining.
2012	Understanding user experience in stereoscopic 3D games	Recent advances in digital game technology are making stereoscopic games more popular. Stereoscopic 3D graphics promise a better gaming experience but this potential has not yet been proven empirically. In this paper, we present a comprehensive study that evaluates player experience of three stereoscopic games in comparison with their monoscopic counterparts. We examined 60 participants, each playing one of the three games, using three self-reporting questionnaires and one psychophysiological instrument. Our main results are (1) stereoscopy in games increased experienced immersion, spatial presence, and simulator sickness; (2) the effects strongly differed across the three games and for both genders, indicating more affect on male users and with games involving depth animations; (3) results related to attention and cognitive involvement indicate more direct and less thoughtful interactions with stereoscopic games, pointing towards a more natural experience through stereoscopy.
2012	panavi: recipe medium with a sensors-embedded pan for domestic users to master professional culinary arts	"panavi," a recipe medium, supports cooking experience for domestic users to master professional culinary arts in their kitchens by managing temperature and pan movement properly. Utilizing a sensors-embedded frying pan--providing projected images, LED indications, and vibration--wirelessly connected with a computer system that shows text messages with sounds, the panavi system analyzes sensors' data, recognizes users' conditions, and provides the users with situated instructions. Describing our vision, design process, implementation, and user study that outlines experience of challenging professional cooking, this paper introduces a design framework model of this recipe medium for domestic usage. Throughout revealing the design process--from ideation to the finished research artifact as a whole cooking support system--this research suggests how to design interactive systems responding to human situated actions, for use as daily commodities enriching domestic user experience.
2012	Tales from the front lines of a large-scale serious game project	Serious games have received much positive attention; correspondingly, many researchers have taken up the challenge of establishing how to best design them. However, the current literature often focuses on best practice design strategies and frameworks. Fine-grained details, contextual descriptions, and organisational factors that are invaluable in helping us to learn from and reflect on project experiences are often overlooked. In this paper, we present five distinct and sometimes competing perspectives that are critical in understanding factors that influence serious game projects: project organisation, technology, domain knowledge, user research , and game design . We explain these perspectives by providing insights from the design and development process of an EU-funded serious game about conflict resolution developed by an interdisciplinary consortium of researchers and industry-based developers. We also point out a set of underlying forces that become evident from viewing the process from different perspectives, to underscore that problems exist in serious game projects and that we should open the conversation about them.
2012	Augmented perception of satiety: controlling food consumption by changing apparent size of food with augmented reality	The main contribution of this paper is to realize a method for modifying perception of satiety and controlling nutritional intake by changing the apparent size of food with augmented reality. As a possible method for decreasing rates of obesity, we focused on controlling food intake implicitly without any effort. We hypothesized that ambiguous perception of satiety can be applied to control our food intake. Recent psychological studies have revealed that the amount of food consumed is influenced by both its actual volume and external factors during eating. Based on this knowledge, we sought to control perception of satiety gained from the same amount of food by changing its apparent size. We also proposed a method for food-volume augmentation using real-time shape deformation. Our results suggest that this augmentation can control the perception of satiety and food intake.
2012	The impact of tutorials on games of varying complexity	One of the key challenges of video game design is teaching new players how to play. Although game developers frequently use tutorials to teach game mechanics, little is known about how tutorials affect game learnability and player engagement. Seeking to estimate this value, we implemented eight tutorial designs in three video games of varying complexity and evaluated their effects on player engagement and retention. The results of our multivariate study of over 45,000 players show that the usefulness of tutorials depends greatly on game complexity. Although tutorials increased play time by as much as 29% in the most complex game, they did not significantly improve player engagement in the two simpler games. Our results suggest that investment in tutorials may not be justified for games with mechanics that can be discovered through experimentation.
2012	From participatory to contributory simulations: changing the game in the classroom	There is much potential for supporting collaborative learning with interactive computer simulations in formal education and professional training. A number have been developed for single user and remote interaction. In contrast, our research is concerned with how such learning activities can be designed to fit into co-located large group settings, such as whole classrooms. This paper reports on the iterative design process and two in-the-wild evaluations of the 4Decades game, which was developed for a whole classroom of students to engage with a climate simulation. The system allows students to play and change the rules of the simulation, thereby enabling them to be actively engaged at different levels. The notion of Contributory Simulations is proposed as an instructional model that empowers groups to make informed, critical changes to the underlying scientific model. We discuss how large-group collaboration was supported through constraining an ecology of shared devices and public displays.
2012	Not doing but thinking: the role of challenge in the gaming experience	Previous research into the experience of videogames has shown the importance of the role of challenge in producing a good experience. However, defining exactly which challenges are important and which aspects of gaming experience are affected is largely under-explored. In this paper, we investigate if altering the level of challenge in a videogame influences people's experience of immersion. Our first study demonstrates that simply increasing the physical demands of the game by requiring gamers to interact more with the game does not result in increased immersion. In a further two studies, we use time pressure to make games more physically and cognitively challenging. We find that the addition of time pressure increases immersion as predicted. We argue that the level of challenge experienced is an interaction between the level of expertise of the gamer and the cognitive challenge encompassed within the game.
2012	Beyond energy monitors: interaction, energy, and emerging energy systems	Motivated by a recent surge of research related to energy and sustainability, this paper presents a review of energy-related work within HCI as well as from literature outside of HCI. Our review of energy-related HCI research identifies a central cluster of work focused on electricity consumption feedback (ECF). Our review of literature outside of HCI highlights a number of emerging energy systems trends of strong relevance to HCI and interaction design, including smart grid, demand response, and distributed generation technologies. We conclude by outlining a range of opportunities for HCI to engage with the experiential, behavioral, social, and cultural aspects of these emerging systems, including highlighting new areas for ECF research that move beyond our field's current focus on energy feedback displays to increase awareness and motivate individual conservation behavior.
2012	Collapse informatics: augmenting the sustainability & ICT4D discourse in HCI	Research in many fields argues that contemporary global industrial civilization will not persist indefinitely in its current form, and may, like many past human societies, eventually collapse. Arguments in environmental studies, anthropology, and other fields indicate that this transformation could begin within the next half-century. While imminent collapse is far from certain, it is prudent to consider now how to develop sociotechnical systems for use in these scenarios. We introduce the notion of collapse informatics---the study, design, and development of sociotechnical systems in the abundant present for use in a future of scarcity---as a complement to ICT4D and mitigation-oriented sustainable HCI. We draw on a variety of literatures to offer a set of relevant concepts and articulate the relationships among them to orient and evaluate collapse informatics work. Observing that collapse informatics poses a unique class of cross-cultural design problems, we sketch the design space of collapse informatics and provide a variety of example projects. We explore points of connection and distinction between collapse informatics and sustainable HCI, ICT4D, and crisis informatics. Finally, we discuss next steps and comment on the potential value of collapse informatics work even in the event that collapse never occurs.
2012	The dubuque water portal: evaluation of the uptake, use and impact of residential water consumption feedback	The Dubuque Water Portal is a system aimed at supporting voluntary reductions of water consumption that is intended to be deployed city-wide. It provides each household with fine-grained, near real time feedback on their water consumption, as well as using techniques like social comparison, weekly games, and news and chat to encourage water conservation. This study used logs, a survey and interviews to evaluate a 15-week pilot with 303 households. It describes the Portal's design, and discusses its adoption, use and impacts. The system resulted in a 6.6% decrease in water consumption, and the paper employs qualitative methods to look at the ways in which the Portal was (or wasn't) effective in supporting its users and enabling them to reduce their consumption. The paper concludes with a discussion of design implications for residential feedback systems, and possible engagement models.
2012	CamBlend: an object focused collaboration tool	CamBlend is a new focus-in-context panoramic video collaboration system designed to facilitate the interaction with and around objects in a lightweight, flexible package. As well as the ability to view very high resolution local and remote video that covers a full 180#176; field of view, the system contains a number of tools which facilitate bi-directional pointing between two remote spaces. In the first quasi-naturalistic exploratory study on a focus-in-context video system, we show a number of unique object referencing behaviours, including un-intentional or 'implicit' pointing and a number of scenarios where this was advantageous. Additionally the study highlighted some of the problems inherent in aligning between screen-based and real-world perspectives.
2012	Video summagator: an interface for video summarization and navigation	This paper presents Video Summagator (VS) , a volume-based interface for video summarization and navigation. VS models a video as a space-time cube and visualizes the video cube using real-time volume rendering techniques. VS empowers a user to interactively manipulate the video cube. We show that VS can quickly summarize both the static and dynamic video content by visualizing the space-time information in 3D. We demonstrate that VS enables a user to quickly look into the video cube, understand the content, and navigate to the content of interest.
2012	Swift: reducing the effects of latency in online video scrubbing	We first conduct a study using abstracted video content to measure the effects of latency on video scrubbing performance and find that even very small amounts of latency can significantly degrade navigation performance. Based on these results, we present Swift , a technique that supports real-time scrubbing of online videos by overlaying a small, low resolution copy of the video during video scrubbing, and snapping back to the high resolution video when the scrubbing is completed or paused. A second study compares the Swift technique to traditional online video players on a collection of realistic live motion videos and content-specific search tasks which finds the Swift technique reducing completion times by as much as 72% even with a relatively low latency of 500ms. Lastly, we demonstrate that the Swift technique can be easily implemented using modern HTML5 web standards.
2012	Video as memorabilia: user needs for collaborative automatic mobile video production	Digital memorabilia, such as video remixes, can increase the value of attending music events. Remixes can be made using video clips recorded by attendees during the event; however, producing them is a laborious task. In this paper we study the prospects of an automatic video remixing and present the results of a study on users' perceptions and attitudes towards collaborative automatic mobile video production. The three findings are as follows: People assess automatic video remix memorabilia as fairly equal to amateur-made manual ones, even if the manually-created video remixes are better in overall quality; as a remixing actor, a computer can be perceived to be more trustworthy than a human remixer; and, the quality of the video remix and the publication forum of the remix outcome plays a significant role when people are deciding whether or not they need public acknowledgement for their contribution. We conclude by discussing the design implications for collaborative automatic mobile video production.
2012	Embedded interaction in a water fountain for motivating behavior change in public space	This paper presents an interactive installation for a public space aimed at motivating new behaviors by augmenting the space with subtle and playful audiovisual interaction aesthetically integrated in a shared environment. Designed to complement an existing water fountain with projected light and sound, the embedded installation encouraged people to take a drink, increasing the proportion of people who used the water fountain by 42% to 57% approximately for nine months. Sensors evaluated the impact of multiple interaction modalities on actual water usage. We found that subtle interaction can improve the experience of a space, in particular for those that use it frequently, and lead to sustained behavior change, especially when its modalities are responsive to the level of activity in the space.
2012	DragLocks: handling temporal ambiguities in direct manipulation video navigation	Direct manipulation video navigation (DMVN) systems allow to navigate inside video scenes by spatially manipulating objects in the video. Problems arise when dealing with temporal ambiguities where a time span is projected onto a single point in image space, e.g., when objects stop moving. Existing DMVN systems deal with these cases by either disabling navigation on the paused object or by allowing jumps in the timeline. Both of these workarounds are undesirable as they introduce inconsistency or provoke loss of context. We analyze current practices regarding temporal ambiguities and introduce two new methods to visualize and navigate object pauses. User tests show that the new approaches are better suited for navigation in scenes containing temporal ambiguities and are rated higher in terms of user satisfaction.
2012	ShoeSense: a new perspective on gestural interaction and wearable applications	When the user is engaged with a real-world task it can be inappropriate or difficult to use a smartphone. To address this concern, we developed ShoeSense, a wearable system consisting in part of a shoe-mounted depth sensor pointing upward at the wearer. ShoeSense recognizes relaxed and discreet as well as large and demonstrative hand gestures. In particular, we designed three gesture sets (Triangle, Radial, and Finger-Count) for this setup, which can be performed without visual attention. The advantages of ShoeSense are illustrated in five scenarios: (1) quickly performing frequent operations without reaching for the phone, (2) discreetly performing operations without disturbing others, (3) enhancing operations on mobile devices, (4) supporting accessibility, and (5) artistic performances. We present a proof-of-concept, wearable implementation based on a depth camera and report on a lab study comparing social acceptability, physical and mental demand, and user preference. A second study demonstrates a 94-99% recognition rate of our recognizers.
2012	Using rhythmic patterns as an input method	While interaction techniques that use the temporal dimension have been used for a long time, such as multiple clicks or spring-loaded widgets, more advanced uses of rhythmic patterns have received little attention in HCI. Using such temporal structures to convey information can be particularly useful in situations where the visual channel is overloaded or even not available. In this paper we introduce Rhythmic Interaction as the use of rhythms for input. We report the results of two experiments that show that (i) rhythmic patterns can be efficiently reproduced by novice users and recognized by computer algorithms, and (ii) rhythmic patterns can be memorized as efficiently as traditional shortcuts when associating them with visual commands. Overall, these results demonstrate the potential of Rhythmic Interaction and open the way to a richer repertoire of interaction techniques.
2012	Engaging older people using participatory design	The use of digital technologies is increasingly proposed in health and social care to address the aging population phenomenon but, in practice, the designers of these technologies are ill equipped to design for older people. We suggest participatory design as an approach to improving the quality of design for older people but, based on previous work and our own experiences, identify four central issues that participatory design approaches need to address. We describe an approach to early engagement in design with older people that address each of these issues and some of our experiences applying the approach in a variety of different design projects. We conclude by discussing some of the issues that have been highlighted when attempting apply this approach in different design contexts and the issues that have been raised when working with partners who are less committed to the idea of engaging with older adults in participatory design.
2012	How do designers and user experience professionals actually perceive and use personas?	Personas are a critical method for orienting design and development teams to user experience. Prior work has noted challenges in justifying them to developers . In contrast, it has been assumed that designers and user experience professionals - whose goal is to focus designs on targeted users - will readily exploit personas. This paper examines that assumption. We present the first study of how experienced user-centered design (UCD) practitioners with prior experience deploying personas, use and perceive personas in industrial software design. We identify limits to the persona approach in the context studied. Practitioners used personas almost exclusively for communication, but not for design. Participants identified four problems with personas, finding them abstract, impersonal, misleading and distracting. Our findings argue for a new approach to persona deployment and construction. Personas cannot replace immersion in actual user data. And rather than focusing on creating engaging personas, it is critical to avoid persona attributes that mislead or distract.
2012	Bootstrapper: recognizing tabletop users by their shoes	In order to enable personalized functionality, such as to log tabletop activity by user, tabletop systems need to recognize users. DiamondTouch does so reliably, but requires users to stay in assigned seats and cannot recognize users across sessions. We propose a different approach based on distinguishing users' shoes . While users are interacting with the table, our system Bootstrapper observes their shoes using one or more depth cameras mounted to the edge of the table. It then identifies users by matching camera images with a database of known shoe images. When multiple users interact, Bootstrapper associates touches with shoes based on hand orientation. The approach can be implemented using consumer depth cameras because (1) shoes offer large distinct features such as color, (2) shoes naturally align themselves with the ground, giving the system a well-defined perspective and thus reduced ambiguity. We report two simple studies in which Bootstrapper recognized participants from a database of 18 users with 95.8% accuracy.
2012	Putting your best foot forward: investigating real-world mappings for foot-based gestures	Foot-based gestures have recently received attention as an alternative interaction mechanism in situations where the hands are pre-occupied or unavailable. This paper investigates suitable real-world mappings of foot gestures to invoke commands and interact with virtual workspaces. Our first study identified user preferences for mapping common mobile-device commands to gestures. We distinguish these gestures in terms of discrete and continuous command input. While discrete foot-based input has relatively few parameters to control, continuous input requires careful design considerations on how the user's input can be mapped to a control parameter (e.g. the volume knob of the media player). We investigate this issue further through three user-studies. Our results show that rate-based techniques are significantly faster, more accurate and result if far fewer target crossings compared to displacement-based interaction. We discuss these findings and identify design recommendations.
2012	Cheque mates: participatory design of digital payments with eighty somethings	This paper describes a project exploring the design of digital payment services in collaboration with 16 people aged over 80. Many older people find cheques valuable as a means of payment but the UK Payments Council recently proposed their abolition. We describe two designs that simultaneously aimed to preserve and augment the paper cheque as a means of making electronic payments. These were devised during participatory design workshops through critical dialogues with our eighty something participants. Workshop discussions resulted in the creation of a real world cheque system where we issued pre-paid cheques without the involvement of banks. This work informed the development of a digital cheque book based on Anoto digital pen technology. The work illustrates the value of participatory design with 'extraordinary' users, such as the eighty somethings, in HCI.
2012	Personas and decision making in the design process: an ethnographic case study	Personas have become a well-lauded method to aid designers in keeping the needs of the intended user population at the forefront of the design process. However, few studies have ethnographically observed design teams that use personas, and fewer studies have looked specifically at how designers linguistically invoke personas in their decision-making sessions. This discourse analysis of the decision-making sessions of designers at a top tier design firm reveals that although the designers dedicate much time researching, developing, and refining personas, personas themselves make relatively few appearances in the designers' language during decision-making sessions. This study shows that, for persuasive ends, these designers, who are advocates of personas, routinely use other less precise and more designer-centric linguistic mechanisms in lieu of personas. Despite the scarcity of personas in the decision-making sessions, this ethnographic case study also explores the value of personas for this team even when the personas are not explicitly linguistically invoked.
2012	PULSE: the design and evaluation of an auditory display to provide a social vibe	We present PULSE, a mobile application designed to allow users to gain a 'vibe', an intrinsic understanding of the people, places and activities around their current location, derived from messages on the Twitter social networking site. We compared two auditory presentations of the vibe. One presented message metadata implicitly through modification of spoken message attributes. The other presented the same metadata, but through additional auditory cues. We compared both techniques in a lab and real world study. Additional auditory cues were found to allow for smaller changes in metadata to be more accurately detected, but were least preferred when PULSE was used in context. Results also showed that PULSE enhanced and shaped user understanding, with audio presentation allowing a closer coupling of digital data to the physical world.
2012	I can't get no sleep: discussing #insomnia on twitter	Emerging research has shown that social media services are being used as tools to disclose a range of personal health information. To explore the role of social media in the discussion of mental health issues, and with particular reference to insomnia and sleep disorders, a corpus of 18,901 messages - or Tweets - posted to the microblogging social media service Twitter were analysed using a mixed methods approach. We present a content analysis which revealed that Tweets that contained the word "insomnia" contained significantly more negative health information than a random sample, strongly suggesting that individuals were making disclosures about their sleep disorder. A subsequent thematic analysis then revealed two themes: coping with insomnia, and describing the experience of insomnia. We discuss these themes as well as the implications of our research for those in the interaction design community interested in integrating online social media systems in health interventions.
2012	Virtual projection: exploring optical projection as a metaphor for multi-device interaction	Handheld optical projectors provide a simple way to overcome the limited screen real-estate on mobile devices. We present virtual projection (VP), an interaction metaphor inspired by how we intuitively control the position, size, and orientation of a handheld optical projector's image. VP is based on tracking a handheld device without an optical projector and allows selecting a target display on which to position, scale, and orient an item in a single gesture. By relaxing the optical projection metaphor, we can deviate from modeling perspective projection, for example, to constrain scale or orientation, create multiple copies, or offset the image. VP also supports dynamic filtering based on the projection frustum, creating overview and detail applications, and selecting portions of a larger display for zooming and panning. We show exemplary use cases implemented using our optical feature-tracking framework and present the results of a user study demonstrating the effectiveness of VP in complex interactions with large displays.
2012	GraphTrail: analyzing large multivariate, heterogeneous networks while supporting exploration history	Exploring large network datasets, such as scientific collaboration networks, is challenging because they often contain a large number of nodes and edges in several types and with multiple attributes. Analyses of such networks are often long and complex, and may require several sessions by multiple users. Therefore, it is often difficult for users to recall their own exploration history or share it with others. We introduce GraphTrail, an interactive visualization for analyzing networks through exploration of node and edge aggregates that captures users' interactions and integrates this history directly in the exploration workspace. To facilitate large network analysis, GraphTrail integrates aggregation with familiar charts, drag-and-drop interaction on a canvas, and a novel pivoting mechanism for transitioning between aggregates. Through a three-month field study with a team of archeologists and a qualitative lab study with ten users, we demonstrate the effectiveness of our design and the benefits of integrated exploration history, including analysis comprehension, insight discovery, and exploration recall.
2012	Unlocking the expressivity of point lights	Small point lights (e.g., LEDs) are used as indicators in a wide variety of devices today, from digital watches and toasters, to washing machines and desktop computers. Although exceedingly simple in their output - varying light intensity over time - their design space can be rich. Unfortunately, a survey of contemporary uses revealed that the vocabulary of lighting expression in popular use today is small, fairly unimaginative, and generally ambiguous in meaning. In this paper, we work through a structured design process that points the way towards a much richer set of expressive forms and more effective communication for this very simple medium. In this process, we make use of five different data gathering and evaluation components to leverage the knowledge, opinions and expertise of people outside our team. Our work starts by considering what information is typically conveyed in this medium. We go on to consider potential expressive forms -- how information might be conveyed. We iteratively refine and expand these sets, concluding with ideas gathered from a panel of designers. Our final step was to make use of thousands of human judgments, gathered in a crowd-sourced fashion (265 participants), to measure the suitability of different expressive forms for conveying different information content. This results in a set of recommended light behaviors that mobile devices, such as smartphones, could readily employ.
2012	Vignette: interactive texture design and manipulation with freeform gestures for pen-and-ink illustration	Vignette is an interactive system that facilitates texture creation in pen-and-ink illustrations. Unlike existing systems, Vignette preserves illustrators' workflow and style: users draw a fraction of a texture and use gestures to automatically fill regions with the texture. We currently support both 1D and 2D synthesis with stitching. Our system also has interactive refinement and editing capabilities to provide a higher level texture control, which helps artists achieve their desired vision. A user study with professional artists shows that Vignette makes the process of illustration more enjoyable and that first time users can create rich textures from scratch within minutes.
2012	Trust me, i'm partially right: incremental visualization lets analysts explore large datasets faster	Queries over large scale (petabyte) data bases often mean waiting overnight for a result to come back. Scale costs time. Such time also means that potential avenues of exploration are ignored because the costs are perceived to be too high to run or even propose them. With sampleAction we have explored whether interaction techniques to present query results running over only incremental samples can be presented as sufficiently trustworthy for analysts both to make closer to real time decisions about their queries and to be more exploratory in their questions of the data. Our work with three teams of analysts suggests that we can indeed accelerate and open up the query process with such incremental visualizations.
2012	Instructing people for training gestural interactive systems	Entertainment and gaming systems such as the Wii and XBox Kinect have brought touchless, body-movement based interfaces to the masses. Systems like these enable the estimation of movements of various body parts from raw inertial motion or depth sensor data. However, the interface developer is still left with the challenging task of creating a system that recognizes these movements as embodying meaning. The machine learning approach for tackling this problem requires the collection of data sets that contain the relevant body movements and their associated semantic labels. These data sets directly impact the accuracy and performance of the gesture recognition system and should ideally contain all natural variations of the movements associated with a gesture. This paper addresses the problem of collecting such gesture datasets. In particular, we investigate the question of what is the most appropriate semiotic modality of instructions for conveying to human subjects the movements the system developer needs them to perform. The results of our qualitative and quantitative analysis indicate that the choice of modality has a significant impact on the performance of the learnt gesture recognition system; particularly in terms of correctness and coverage.
2012	Rewarding the original: explorations in joint user-sensor motion spaces	This paper presents a systematic and general technique for establishing a set of motions suitable for use with sensor systems, by drawing performable and measurable motions directly from users. It uses reinforcement which rewards originality to induce users to explore the space of motions they can perform. A decomposition of movements into motion primitives is constructed, among which a meaningful originality metric can be defined. Because the originality measure is defined in terms of the sensed input, the resulting space contains only movements which can both be performed and sensed. We show how this can be used to evaluate the relative performance of different joint user-sensor systems, providing objective analyses of gesture lexicons with regard to the technical limitations of sensors and humans. In particular, we show how the space of motions varies across the arm for a body-mounted inertial sensor.
2012	Creating and using interactive narratives: reading and writing branching comics	In this paper we describe the design and development of a multi-touch surface and software that challenges current approaches to the production and consumption of comics. Authorship of the comics involves drawing the 'top level' of the story directly onto paper and projecting lower-level narrative elements, such as objects, characters, dialogue, descriptions and/or events onto the paper via a multi-touch interface. In terms of the impact this has upon the experience of reading and writing, the implementation of paper is intended to facilitate the creation of high-level overviews of stories, while the touch surface allows users to generate branches through the addition of artifacts in accordance with certain theories about interactive narratives. This provides the opportunity to participate in the reading and authoring of both traditional, paper-based texts and interactive, digital scenarios. Prototype comics are used to demonstrate this approach to reading and writing top-level and low-level narratives.
2012	TimeBlocks: mom, can I have another block of time	Time is a difficult concept for parents to communicate with young children. We developed TimeBlocks, a novel tangible, playful object to facilitate communication about concepts of time with young children. TimeBlocks consists of a set of cubic blocks that function as a physical progress bar. Parents and children can physically manipulate the blocks to represent the concept of time. We evaluated TimeBlocks through a field study in which six families tried TimeBlocks for four days at their homes. The results indicate that TimeBlocks played a useful role in facilitating the often challenging task of time-related communication between parents and children. We also report on a range of observed insightful novel uses of TimeBlocks in our study.
2012	Uncomfortable interactions	We argue for deliberately and systematically creating uncomfortable interactions as part of powerful cultural experiences. We identify the potential benefits of uncomfortable interactions under the general headings of entertainment, enlightenment and sociality. We then review artworks and performances that have employed discomfort, including two complementary examples from the worlds of entertainment and performance. From this, we articulate a suite of tactics for designing four primary forms of discomfort referred to as visceral, cultural, control and intimate. We discuss how moments of discomfort need to be embedded into an overall experience which requires a further consideration of the dramatic acts of exposition, rising action, climax, falling action, and dénouement. Finally, we discuss an ethical framework for uncomfortable interactions which leads us to revisit key issues of consent, withdrawal, privacy and risk.
2012	Dwell-and-spring: undo for direct manipulation	In graphical user interfaces, direct manipulation consists in incremental actions that should be reversible. Typical examples include manipulating geometrical shapes in a vector graphics editor, navigating a document using a scrollbar, or moving and resizing windows on the desktop. As in many such cases, there will not be any mechanism to undo them, requiring users to manually revert to the previous state using a similar sequence of direct manipulation actions. The associated motor and cognitive costs can be high. We argue that proper and consistent mechanisms to support undo in this context are lacking, and present Dwell-and-Spring, an interaction technique that uses the metaphor of springs to enable users to undo direct manipulations. A spring widget pops up whenever the user dwells during a press-drag-release interaction, giving her the opportunity to either cancel the current manipulation or undo the last one. The technique is generic and can easily be implemented on top of existing applications to complement the traditional undo command. Empirical evaluation shows that users quickly adopt it as soon as they discover it.
2012	I did that!: measuring users' experience of agency in their own actions	Cognitive neuroscience defines the sense of agency as the experience of controlling one's own actions and, through this control, affecting the external world. We believe that the sense of personal agency is a key factor in how people experience interactions with technology. This paper draws on theoretical perspectives in cognitive neuroscience and describes two implicit methods through which personal agency can be empirically investigated. We report two experiments applying these methods to HCI problems. One shows that a new input modality - skin-based interaction - can substantially increase users' sense of agency. The second demonstrates that variations in the parameters of assistance techniques such as predictive mouse acceleration can have a significant impact on users' sense of agency. The methods presented provide designers with new ways of evaluating and refining empowering interaction techniques and interfaces, in which users experience an instinctive sense of control and ownership over their actions.
2012	The labor practices of service mediation: a study of the work practices of food assistance outreach	In this paper, we present the results of a study of the work practices of food assistance outreach workers. We introduce the construct of service mediation, which includes the technical, social, and knowledge labor practices involved in enabling access to and use of an e-government service. We explore the service mediation activities of outreach, technological assistance, providing knowledge, and ongoing engagement. These activities bring to light how successful service relationships involve fostering a process, bridging relationships, and providing broader scaffolding. The results of our research highlight the role service mediation plays in the use of services and service technologies in information-rich organizations. This research extends previous conceptualizations of mediation by documenting how mediators support broader service processes for their clients, transform potential beneficiaries into clients, and engage in long term assistance. Therefore, this work moves beyond prior conceptualizations of mediation that concentrate solely on enabling access and use of specific technologies.
2012	Socially computed scripts to support social problem solving skills	The social world that most of us navigate effortlessly can prove to be a perplexing and disconcerting place for individuals with autism. Interactive tools to teach social skills that are personalized to the individual's needs show promise, but it is challenging to author them. We describe the design, development, and preliminary evaluation of an approach to using human computation that enables the creation of models of complex and interesting social scenarios, possible obstacles that may arise in those scenarios, and potential solutions to those obstacles. Our preliminary evaluation of the models confirms that these models have the potential to help an author create a social skills instructional module.
2012	Appreciating plei-plei around mobiles: playfulness in Rah island	We set out to explore and understand the ways in which mobiles made their way into an environment--Rah Island in Vanuatu--for the first time. We were struck by their playful use, especially given the very limited infrastructure and inexpensive devices that were available. Based on our findings, we discuss tensions between playfulness and utility, in particular relating to socio-economic benefits, and conclude that playfulness in these settings needs to be taken as seriously as in any other setting. Additionally, we formulated three challenges when designing for play in similar settings: (1) engage intimately with the materials of inexpensive ICT; (2) revisit design recommendations for playfulness to ensure that they can travel/translate into other cultures; and (3) alleviate existing tensions.
2012	Bridging between organizations and the public: volunteer coordinators' uneasy relationship with social computing	We present the results of a qualitative study of the use of social computing technologies by volunteer coordinators at nonprofit organizations. The work of volunteer coordinators is bridge-building work - bringing together numerous public constituencies as well as constituencies within their organizations. One might expect this class of work to be well supported by social software, some of which has been found to enable bridging social capital. However, we find that, in many ways, this class of technology fails to adequately support volunteer coordinators' bridge-building work. We discuss a number of strategies for bridge-building via social computing technologies, numerous challenges faced by volunteer coordinators in their use of these technologies, and opportunities for designing social software to better support bridge-building between organizations and the public.
2012	TEROOS: a wearable avatar to enhance joint activities	This paper proposes a wearable avatar named TEROOS, which is mounted on a person's shoulder. TEROOS allows the users who wear it and control it to share a vision remotely. Moreover, the avatar has an anthropomorphic face that enables the user who controls it to communicate with people co-located with the user who wears it. We have a field test by using TEROOS and observed that the wearable avatar innovatively assisted the users to communicate during their joint activities such as route navigating and buying goods at a shop. The user controlling TEROOS could give the user wearing it appropriate route instructions on the basis of the situation around TEROOS. In addition, both users could easily identify objects that they discussed. Moreover, shop staff members communicated with the user controlling TEROOS and behaved as they normally would when the user asked questions about the goods.
2012	Comparing collaboration and individual personas for the design and evaluation of collaboration software	Collaboration personas are a tool that can be used to design for groups. Prior work posits that collaboration personas can improve tool adoption by helping designers create collaboration tools that are better targeted to the goals, needs, and interactions between members of collaborative groups. We present a comparative study of design and user experience practitioners who used both collaboration personas and individual personas. Participants conducted a cognitive walkthrough and provided redesign suggestions for a collaboration tool. Our results show that the focus of the cognitive walkthrough and redesign task differed, with collaboration personas showing more group focus. Collaboration personas led to a more complete discussion, as indicated by a greater amount of time spent on the task compared to individual personas. Despite prior experience and training with individual personas, collaboration personas were preferred and better supported the task, since they focused on groups of people and their interactions.
2012	HoloDesk: direct 3d interactions with a situated see-through display	HoloDesk is an interactive system combining an optical see through display and Kinect camera to create the illusion that users are directly interacting with 3D graphics. A virtual image of a 3D scene is rendered through a half silvered mirror and spatially aligned with the real-world for the viewer. Users easily reach into an interaction volume displaying the virtual image. This allows the user to literally get their hands into the virtual display and to directly interact with an spatially aligned 3D virtual world, without the need for any specialized head-worn hardware or input device. We introduce a new technique for interpreting raw Kinect data to approximate and track rigid (e.g., books, cups) and non-rigid (e.g., hands, paper) physical objects and support a variety of physics-inspired interactions between virtual and real. In particular the algorithm models natural human grasping of virtual objects with more fidelity than previously demonstrated. A qualitative study highlights rich emergent 3D interactions, using hands and real-world objects. The implementation of HoloDesk is described in full, and example application scenarios explored. Finally, HoloDesk is quantitatively evaluated in a 3D target acquisition task, comparing the system with indirect and glasses-based variants.
2012	DisplayStacks: interaction techniques for stacks of flexible thin-film displays	Stacking physical documents is one of the main forms of spatio-temporal organization of information. We present DisplayStacks, a system that enables physical stacking of digital documents via piles of flexible E Ink displays. With a conductive dot pattern sensor attached to the flexible display, we dynamically track the position and orientation of these displays in relation to one another. We introduce mechanisms for interacting with these physical stacks for access and manipulation of information using asymmetric bi-manual interactions, such as providing contextual overviews. Initial user experiences indicate a preference for linear overlaps as a stacking configuration.
2012	Watts in it for me?: design implications for implementing effective energy interventions in organisations	The design of technological interventions to motivate behaviour-based reductions in end-user energy consumption has recently been identified as a priority for the HCI community. Previous interventions have produced promising results, but have typically focused on domestic energy consumption. By contrast, this paper focuses on the workplace context, which presents very different opportunities and challenges. For instance, financial consequences, which have proved successful as motivations in the domestic environment, are not present in the workplace in the context of employees. We describe the outcome of a sequence of workshops that focussed on understanding employee perceptions of energy use in the workplace, with the locus of activity on energy intervention design. Using a grounded theory analysis, we produced a framework of key themes detailing user perceptions and energy intervention design considerations. Our findings provide a framework of considerations for the design of successful workplace energy interventions.
2012	ClayVision: the (elastic) image of the city	In this paper we describe ClayVision, a new quasi-immersive urban navigation system that rethinks the design conventions of existing Augmented Reality (AR) applications, by aggressively incorporating knowledge from non-Computer Science fields - namely Information Design and Urban Planning. Instead of the prevailing approach of pasting "information bubbles" onto the existing urban scenery, ClayVision communicates through real-time 3D transformations of city elements. In other words, the system dynamically probes and reassembles the city into a better-designed copy of the original, that is both easier to navigate and tailored to suit the user's needs and preferences. We provide extensive discussions that cover the technical details of the system, the types of city-morphing operations that can be effectively applied, and what people's experiences will be in the newly "elastic" city.
2012	The design and evaluation of prototype eco-feedback displays for fixture-level water usage data	Few means currently exist for home occupants to learn about their water consumption: e.g. , where water use occurs, whether such use is excessive and what steps can be taken to conserve. Emerging water sensing systems, however, can provide detailed usage data at the level of individual water fixtures ( i.e., disaggregated usage data). In this paper, we perform formative evaluations of two sets of novel eco-feedback displays that take advantage of this disaggregated data. The first display set isolates and examines specific elements of an eco-feedback design space such as data and time granularity . Displays in the second set act as design probes to elicit reactions about competition, privacy, and integration into domestic space. The displays were evaluated via an online survey of 651 North American respondents and in-home, semi-structured interviews with 10 families (20 adults). Our findings are relevant not only to the design of future water eco-feedback systems but also for other types of consumption ( e.g. , electricity and gas).
2012	Video kids: augmenting close friendships with asynchronous video conversations in videopal	Consumer-based synchronous video communication is on the rise and is viewed as a valuable medium to support long distance relationships. We were interested in the potential of asynchronous video to augment children's close friendships and what types of activities they would engage in using video. We explored both of these concepts through a 9-week field study with a group of six 9-10 year old girls. We see children as potential media trendsetters when it comes to video communication given their comfort with video and desire for rich social interactions. The results from this study were striking. Despite having frequent face-to-face interactions, the girls used our asynchronous video communication tool extensively to augment their existing relationships. Not only were they able to have rich conversations using asynchronous video, they also demonstrated a strong desire to share more than just a "talking head". The results from this work point to the need for video mediated communication to move beyond conversations, to the sharing of rich experiences.
2012	KidCAD: digitally remixing toys through tangible tools	Children have great facility in the physical world, and can skillfully model in clay and draw expressive illustrations. Traditional digital modeling tools have focused on mouse, keyboard and stylus input. These tools may be complicated and difficult for young users to easily and quickly create exciting designs. We seek to bring physical interaction to digital modeling, to allow users to use existing physical objects as tangible building blocks for new designs. We introduce KidCAD a digital clay interface for children to remix toys. KidCAD allows children to imprint 2.5D shapes from physical objects into their digital models by deforming a malleable gel input device, deForm. Users can mashup existing objects, edit and sculpt or draw new designs on a 2.5D canvas using physical objects, hands and tools as well as 2D touch gestures. We report on a preliminary user study with 13 children, ages 7 to 10, which provides feedback for our design and helps guide future work in tangible modeling for children.
2012	Interpreting input from children: a designerly approach	Involving children in the design process of interactive technology can greatly enhance its likelihood of successful adoption. However, children's input and ideas require careful interpretation to reach viable designs and technical specifications, which poses a significant challenge to an adult design research team. In this paper we discuss our approach to managing the complexity of combining concepts and ideas that were generated through participatory design work with the practical, technical, ethical and theoretical constraints of developing a technologically enhanced learning environment for children with and without Autism Spectrum Conditions. We found that the nature of this design problem did not lend itself to be rationally reduced to produce a single solution, but required an understanding of interpretive and speculative approaches for us to be able to cope with the complexity of requirements. We describe a workshop in which members of the design team used such approaches to develop a design brief that is faithful to the children's input. By making this process transparent, we aim to contribute to the methodology of using such designerly approaches in combination with participatory and human-centred methods to develop interactive technology.
2012	Interchangeability of computer and paper based questionnaires in gathering computer experience data from young children	The study compares self-reported computer experience (CE) obtained from children in computer-assisted and paper-and-pencil self-administered questionnaires. Twenty primary school children aged between 8 and 9 years completed a set of CE questions in both forms of administration in a Latin-square order. Findings show that young children can use both methods, and that they are able to answer a computer-based questionnaire just as consistently as a paper-based questionnaire.
2012	Diversity among enterprise online communities: collaborating, teaming, and innovating through social media	There is a growing body of research into the adoption and use of social software in enterprises. However, less is known about how groups, such as communities, use and appropriate these technologies, and the implications for community structures. In a study of 188 very active online enterprise communities, we found systematic differences in size, demographics and participation, aligned with differences in community types. Different types of communities differed in their appropriation of social software tools to create and use shared resources, and build relationships. We propose implications for design of community support features, services for potential community members, and organizations looking to derive value from online groups.
2012	Supporting the social context of technology appropriation: on a synthesis of sharing tools and tool knowledge	There is an increasing spread of flexible software applications that can be modified by adding components (sometimes called plug-ins or add-ons). A popular example in the software development domain is Eclipse, a flexible development environment that can be extended with literally thousands of different plug-ins. However, searching, installing and configuring new plug-ins requires complex overhead work that is only weakly addressed by existing support mechanisms. Recent research has highlighted the related practices of learning about new plug-ins and tailoring software tools as being highly cooperative, situated, socially embedded, and often connected to particular work situations. Based on an empirical study in small software enterprises, we develop an understanding of appropriation as a social and collaborative activity. We then suggest design principles for appropriation support that are grounded in the practices we have found in the field, and present a prototypical implementation of the concept that extends existing mechanisms of sharing tools and tool-knowledge.
2012	Regional undo/redo techniques for large interactive surfaces	When multiple users are simultaneously sharing a workspace, it is not always clear what should happen when a user invokes an undo action. In this paper we explore different user interfaces for undo/redo for co-located collaborative workspaces, such as large interactive whiteboards. A preliminary study revealed that users expect neither a global nor personal undo, but rather a regional undo. We propose and evaluate three automatic regional undo/redo techniques (clustering, workspace, field of view) designed for a large interactive whiteboard. The results of the evaluation showed that an undo technique based on users' field of view was most preferred, while the content-based clustering technique produced most errors. We conclude with potential improvements to the developed techniques, and propose a set of design recommendations for implementing regional undo/redo on large interactive surfaces.
2012	Tangible remote controllers for wall-size displays	We explore the use of customizable tangible remote controllers for interacting with wall-size displays. Such controllers are especially suited to visual exploration tasks where users need to move to see details of complex visualizations. In addition, we conducted a controlled user study suggesting that tangibles make it easier for users to focus on the visual display while they interact. We explain how to build such controllers using off-the-shelf touch tablets and describe a sample application that supports multiple dynamic queries.
2012	Homeless young people on social network sites	This paper reports on the use of social network sites (MySpace and Facebook) by homeless young people, an extraordinary user population, made so in part by its vulnerability. Twenty-three participants of diverse ethnicities, 11 women and 12 men (mean age, 21.7 years), were interviewed in same-sex discussion groups of four participants each. The interviews consisted of questions about the uses, benefits, and harms of social network sites and how people present themselves online. Qualitative analysis of the discussion group transcripts shows how young people explore their identities, cultivate and exploit social ties, experience interpersonal tensions, manage incompatible audiences, and respond to shifting affiliations and transitions. From this analysis, implications for social intervention and technical design are presented, focused on maintaining ties with pro-social family and friends and with maintaining separation between communication spheres of incompatible audiences. This work contributes to the growing literature on vital, deeply human experiences that have become associated with social network sites.
2012	Gesture coder: a tool for programming multi-touch gestures by demonstration	Multi-touch gestures have become popular on a wide range of touchscreen devices, but the programming of these gestures remains an art. It is time-consuming and error-prone for a developer to handle the complicated touch state transitions that result from multiple fingers and their simultaneous movements. In this paper, we present Gesture Coder, which by learning from a few examples given by the developer automatically generates code that recognizes multi-touch gestures, tracks their state changes and invokes corresponding application actions. Developers can easily test the generated code in Gesture Coder, refine it by adding more examples, and once they are satisfied with its performance integrate the code into their applications. We evaluated our learning algorithm exhaustively with various conditions over a large set of noisy data. Our results show that it is sufficient for rapid prototyping and can be improved with higher quality and more training data. We also evaluated Gesture Coder's usability through a within-subject study in which we asked participants to implement a set of multi-touch interactions with and without Gesture Coder. The results show overwhelmingly that Gesture Coder significantly lowers the threshold of programming multi-touch gestures.
2012	ReticularSpaces: activity-based computing support for physically distributed and collaborative smart spaces	Smart spaces research focuses on technology for multiple displays and devices for collocated participants. In most approaches, however, users have to cope with heterogeneous interfaces and information organization, as well as a lack of support for collaboration with mobile and remote users outside the smart space. In this paper, we present ReticularSpaces; a multi-display smart space system built on the principles of activity-based computing. The focus of ReticularSpaces is to support: (i) unified interaction with applications and documents through ReticularUI, a novel distributed user interfaces design; (ii) management of the complexity of tasks between users and displays; (iii) mobile users in a local, remote or 'nomadic' settings; and (iv) collaboration among local and remote users. We describe the motivation, design, and architecture of ReticularSpaces, and report from a preliminary feasibility study. The study shows that participants found ReticularSpaces useful and effective, but at the same time reveals new areas for research on smart environments.
2012	Experimental investigation of human adaptation to change in agent's strategy through a competitive two-player game	We conducted an experimental investigation on human adaptation to change in an agent's strategy through a competitive two-player game. Modeling the process of human adaptation to agents is important for designing intelligent interface agents and adaptive user interfaces that learn a user's preferences and behavior strategy. However, few studies on human adaptation to such an agent have been done. We propose a human adaptation model for a two-player game. We prepared an on-line experimental system in which a participant and an agent play a repeated penny-matching game with a bonus round. We then conducted experiments in which different opponent agents (human or robot) change their strategy during the game. The experimental results indicated that, as expected, there is an adaptation phase when a human is confronted with a change in the opponent agent's strategy, and adaptation is faster when a human is competing with robot than with another human.
2012	Through the azerothian looking glass: mapping in-game preferences to real world demographics	Examining how in-game behavior preferences map onto real world demographics provides important empirically-derived insights into how to match game-based mechanisms to target demographic segments. Using behavioral and demographic data from 1,037 World of Warcraft players, we use multiple regressions to provide this mapping. Given current interest in "gamifying" applications, we believe these findings are relevant for both gaming and non-gaming research.
2012	Understanding mobile Q&A usage: an exploratory study	Recently questioning and answering (Q&A) communities that facilitate knowledge sharing among people have been introduced to the mobile environments such as Naver Mobile Q&A and ChaCha. These mobile Q&A services are very different from traditional Q&A sites in that questions/answers are short in length and are exchanged via mobile devices (e.g., SMS or mobile Internet). While traditional Q&A sites have been well investigated, so far little is known about the mobile Q&A usage. To understand mobile Q&A usage, we analyzed 2.4 million question/answer pairs spanning a 14 month period from Naver Mobile Q&A and performed a complementary survey study of 555 active mobile Q&A users. We find that mobile Q&A is deeply wired into users' everyday life activities - its usage is largely dependent on users' spatial, temporal, and social contexts; the key factors of mobile Q&A usage are accessibility/convenience of mobile Q&A, promptness of receiving answers, and users' satisficing behavior of information seeking (i.e., minimizing efforts and settling with good enough information). We also observe that users tend to seek more factual information attributed to everyday life activities than they do on traditional Q&A sites and that they exhibit unique interaction patterns such as repeating and refining questions as coping strategies in seeking information needs. Our main findings reported in the paper have significant implications on the design of mobile Q&A systems.
2012	Perceptions of facebook's value as an information source	Facebook has become an increasingly important tool for people engaging in a range of communication behaviors, including requesting help from their social network to address information needs. Through a study of 614 staff members at a large university, we show how social capital, network characteristics, and use of Facebook are related to how useful individuals find Facebook to be for informational purposes and their propensity to seek different types of information on the site. We find that bridging social capital and engagement with one's network through directed communication behaviors are important predictors of these dimensions of information seeking; furthermore, a number of demographic and usage behavior differences exist between those who choose to engage in information-seeking behaviors on Facebook and those who do not. Finally, when predicting information-seeking behaviors, we identify a significant interaction between users' perceptions of Facebook as appropriate for purposes beyond the purely social and their engagement with their network.
2012	WebCrystal: understanding and reusing examples in web authoring	Examples have been widely used in the area of web design to help web authors create web pages. However, without actually understanding how an example is constructed, people often have trouble extracting the elements they want and incorporating them into their own design. This paper introduces WebCrystal, a web development tool that helps users understand how a web page is built. WebCrystal contributes novel interaction techniques that let the user quickly access HTML and CSS information by selecting questions regarding how a selected element is designed. It provides answers using a textual description and a customized code snippet that can be copied-and-pasted to recreate the desired properties. WebCrystal also supports combining the styles and structures from multiple elements into the generated code snippet, and provides visualizations on the web page itself to explain layout relationships. Our user study shows that WebCrystal helped both novice and experienced developers complete more tasks successfully using significantly less time.
2012	Examining technology that supports community policing	This paper investigates how citizens use technology to support community policing efforts. To explore the types of conversations that are shared on the community web forum, we conducted a qualitative study. We analyzed 865 forum posts from a community crime web forum from April 2004 to June 2011. We found that residents use the forum to: 1) build relationships by strengthening social ties, 2) discuss ways to take collective action, 3) share information and advice, and 4) regulate the social norms of the neighborhood and the web forum. Results suggest that technologies intended for crime prevention should be designed to support communication and problem-solving discussions amongst residents, as opposed to simply providing information to citizens.
2012	Yours is better!: participant response bias in HCI	Although HCI researchers and practitioners frequently work with groups of people that differ significantly from themselves, little attention has been paid to the effects these differences have on the evaluation of HCI systems. Via 450 interviews in Bangalore, India, we measure participant response bias due to interviewer demand characteristics and the role of social and demographic factors in influencing that bias. We find that respondents are about 2.5x more likely to prefer a technological artifact they believe to be developed by the interviewer, even when the alternative is identical. When the interviewer is a foreign researcher requiring a translator, the bias towards the interviewer's artifact increases to 5x. In fact, the interviewer's artifact is preferred even when it is degraded to be obviously inferior to the alternative. We conclude that participant response bias should receive more attention within the CHI community, especially when designing for underprivileged populations.
2012	A comparative evaluation of finger and pen stroke gestures	This paper reports an empirical investigation in which participants produced a set of stroke gestures with varying degrees of complexity and in different target sizes using both the finger and the pen. The recorded gestures were then analyzed according to multiple measures characterizing many aspects of stroke gestures. Our findings were as follows: (1) Finger drawn gestures were quite different to pen drawn gestures in basic measures including size ratio and average speed. Finger drawn gestures tended to be larger and faster than pen drawn gestures. They also differed in shape geometry as measured by, for example, aperture of closed gestures, corner shape distance and intersecting points deviation; (2) Pen drawn gestures and finger drawn gestures were similar in several measures including articulation time, indicative angle difference, axial symmetry and proportional shape distance; (3) There were interaction effects between gesture implement (finger vs. pen) and target gesture size and gesture complexity. Our findings show that half of the features we tested were performed well enough by the finger. This finding suggests that "finger friendly" systems should exploit these features when designing finger interfaces and avoid using the other features in which the finger does not perform as well as the pen.
2012	Going beyond the surface: studying multi-layer interaction above the tabletop	Lightweight spatially aware displays (Tangible Magic Lenses) are an effective approach for exploring complex information spaces within a tabletop environment. One way of using the 3D space above a horizontal surface is to divide it into discrete parallel layers stacked upon each other. Horizontal and vertical lens movements are essential tasks for the style of multi-layer interaction associated with it. We conducted a comprehensive user study with 18 participants investigating fundamental issues such as optimal number of layers and their thickness, movement and holding accuracies, and physical boundaries of the interaction volume. Findings include a rather limited overall interaction height (44 cm), a different minimal layer thickness for vertical and horizontal search tasks (1 cm/4 cm), a reasonable maximum number of layers depending on the primary task, and a convenience zone in the middle for horizontal search. Derived from that, design guidelines are also presented.
2012	Evaluating the implicit acquisition of second language vocabulary using a live wallpaper	An essential aspect of learning a second language is the acquisition of vocabulary. However, acquiring vocabulary is often a protracted process that requires repeated and spaced exposure; which can be difficult to accommodate given the busyness of daily living. In this paper, we explore if a learner can implicitly acquire second language vocabulary through her explicit interactions with her mobile phone (e.g., navigating multiple home screens) using an interface we developed called Vocabulary Wallpaper. In addition, we examine if the type of vocabulary this technique exposes to the learner, whether it is contextually relevant or contextually-independent will influence the learner's rate of vocabulary acquisition. The results of our study show participants were able to use Vocabulary Wallpaper to increase the number of second language vocabulary that they can recognize and recall and their rate of vocabulary acquisition was significantly greater when presented with a contextually relevant vocabulary than a contextually-independent vocabulary.
2012	Collaboration in cognitive tutor use in latin America: field study and design recommendations	Technology has the promise to transform educational prac-tices worldwide. In particular, cognitive tutoring systems are an example of educational technology that has been ex-tremely effective at improving mathematics learning over traditional classroom instruction. However, studies on the effectiveness of tutor software have been conducted mainly in the United States, Canada, and Western Europe, and little is known about how these systems might be used in other contexts with differing classroom practices and values. To understand this question, we studied the usage of mathematics tutoring software for middle school at sites in three Latin American countries: Brazil, Mexico, and Costa Rica. While cognitive tutors were designed for individual use, we found that students in these classrooms worked collaboratively, engaging in interdependently paced work and conducting work away from their own computer. In this paper we present design recommendations for how cognitive tutors might be incorporated into different classroom practices, and better adapted for student needs in these environments.
2012	Best intentions: health monitoring technology and children	In this paper we describe findings from two studies aimed at understanding how health monitoring technology affects the parent-child relationship, examining emotional response and barriers to using this type of technology. We present suggestions for the design of health monitoring technology intended to enhance self-care in children without creating parent-child conflict. Our recommendations integrate the study findings, developmental stage specific concerns, and prior HCI research aimed at children's health.
2012	Using mobile phones to present medical information to hospital patients	The awareness that hospital patients have of the people and events surrounding their care has a dramatic impact on satisfaction and clinical outcomes. However, patients are often under-informed about even basic aspects of their care. In this work, we hypothesize that mobile devices - which are increasingly available to patients - can be used as real-time information conduits to improve patient awareness and consequently improve patient care. To better understand the unique affordances that mobile devices offer in the hospital setting, we provided twenty-five patients with mobile phones that presented a dynamic, interactive report on their progress, care plan, and care team throughout their emergency department stay. Through interviews with these patients, their visitors, and hospital staff, we explore the benefits and challenges of using the mobile phone as an information display, finding overall that this is a promising approach to improving patient awareness. Furthermore, we demonstrate that only a small number of technology challenges remain before such a system could be deployed without researcher intervention.
2012	Listening factors: a large-scale principal components analysis of long-term music listening histories	There are about as many strategies for listening to music as there are music enthusiasts. This makes learning about overarching patterns and similarities difficult. In this paper, we present an empirical analysis of long-term music listening histories from the last.fm web service. It gives insight into the most distinguishing factors in music listening behavior. Our sample contains 310 histories with up to six years duration and 48 associated variables describing various user and music characteristics. Using a principal components analysis, we aggregated these variables into 13 components and found several correlations between them. The analysis especially showed the impact of seasons and a listener's interest in novelty on music choice. Using this information, a sample of a user's listening history or even just demographical data could be used to create personalized interfaces and novel recommendation strategies. We close with derived design considerations for future music interfaces.
2012	Fly: studying recall, macrostructure understanding, and user experience of canvas presentations	Most presentation software uses the slide deck metaphor to create visual presentation support. Recently, canvas presentation tools such as Fly or Prezi have begun to use a zoomable free-form canvas to arrange information instead. While their effect on authoring presentations has been evaluated previously, we studied how they impact the audience. In a quantitative study, we compared audience retention and macrostructure understanding of slide deck vs. canvas presentations. We found both approaches to be equally capable of communicating information to the audience. Canvas presentations, however, were rated by participants to better aid them in staying oriented during a talk. This makes canvas presentation tools a promising slideware alternative.
2012	Balancing exertion experiences	Exercising with others, such as jogging in pairs, can be socially engaging. However, if exercise partners have different fitness levels then the activity can be too strenuous for one and not challenging enough for the other, compromising engagement and health benefits. Our system, Jogging over a Distance, uses heart rate data and spatialized sound to create an equitable, balanced experience between joggers of different fitness levels who are geographically distributed. We extend this prior work by analyzing the experience of 32 joggers to detail how specific design features facilitated, and hindered, an engaging and balanced exertion experience. With this knowledge, we derive four dimensions that describe a design space for balancing exertion experiences: Measurement, Adjustment, Presentation and Control. We also present six design tactics for creating balanced exertion experiences described by these dimensions. By aiding designers in supporting participants of different physical abilities, we hope to increase participation and engagement with physical activity and facilitate the many benefits it brings about.
2012	The acute cognitive benefits of casual exergame play	Acute cognitive benefits, such as temporary improvements in concentration, can result from as few as ten minutes of exercise; however, most people do not take exercise breaks throughout the day. To motivate people to receive the cognitive benefits of exercising in short bursts multiple times per day, we designed an engaging casual exergame. To determine whether there are cognitive benefits after playing our game, we conducted two studies to compare playing ten minutes of our casual exergame to a sedentary version of the game or exercise on a treadmill. We found acute cognitive benefits of the casual exergame over the sedentary version (but not treadmill exercise), demonstrated by significantly improved performance on two cognitive tests that require focus and concentration. Significant improvements were also found in participants' affective states after playing the casual exergame. Finally, our casual exergame produces similar exertion levels to treadmill exercise, but is perceived as more fun.
2012	Full-body motion-based game interaction for older adults	Older adults in nursing homes often lead sedentary lifestyles, which reduces their life expectancy. Full-body motion-control games provide an opportunity for these adults to remain active and engaged; these games are not designed with age-related impairments in mind, which prevents the games from being leveraged to increase the activity levels of older adults. In this paper, we present two studies aimed at developing game design guidelines for full-body motion controls for older adults experiencing age-related changes and impairments. Our studies also demonstrate how full-body motion-control games can accommodate a variety of user abilities, have a positive effect on mood and, by extension, the emotional well-being of older adults. Based on our studies, we present seven guidelines for the design of full-body interaction in games. The guidelines are designed to foster safe physical activity among older adults, thereby increasing their quality of life.
2012	Informal information gathering techniques for active reading	GatherReader is a prototype e-reader with both pen and multi-touch input that illustrates several interesting design trade-offs to fluidly interleave content consumption behaviors (reading and flipping through pages) with information gathering and informal organization activities geared to active reading tasks. These choices include (1) relaxed precision for casual specification of scope; (2) multiple object collection via a visual clipboard; (3) flexible workflow via deferred action; and (4) complementary use of pen+touch. Our design affords active reading by limiting the transaction costs for secondary subtasks, while keeping users in the flow of the primary task of reading itself.
2012	mClerk: enabling mobile crowdsourcing in developing regions	Global crowdsourcing platforms could offer new employment opportunities to low-income workers in developing countries. However, the impact to date has been limited because poor communities usually lack access to computers and the Internet. This paper presents mClerk, a new platform for mobile crowdsourcing in developing regions. mClerk sends and receives tasks via SMS, making it accessible to anyone with a low-end mobile phone. However, mClerk is not limited to text: it leverages a little-known protocol to send small images via ordinary SMS, enabling novel distribution of graphical tasks. Via a 5-week deployment in semi-urban India, we demonstrate that mClerk is effective for digitizing local-language documents. Usage of mClerk spread virally from 10 users to 239 users, who digitized over 25,000 words during the study. We discuss the social ecosystem surrounding this usage, and evaluate the potential of mobile crowdsourcing to both deliver and derive value from users in developing regions.
2012	DiskPlay: in-track navigation on turntables	Although digital media playback and storage have several advantages, many DJs still prefer using vinyl records on turntables due to their direct manipulation and haptic qualities. The physical structure of a traditional vinyl record provides important cues for in-track navigation, such as track length or location of loud and soft passages. Digital vinyl systems use a timecode record to combine the advantages of digital playback with the handling DJs are used to. These records contain a special audio signal that is processed by a computer and mapped to information such as playback speed, direction, and absolute position in a track. However, due to their generic nature, timecode records cannot provide visual information to navigate inside individual tracks. Using top-projection, DiskPlay augments a white timecode record with individual visual cues of the medium, such as cue points or track start and end. In our observational study with four professional DJs, participants valued the co-location of visual feedback with the control vinyl on the turntable.
2012	Claim mobile: when to fail a technology	This paper looks back at the deployment of Claim Mobile, a smartphone-based data collection application developed for a non-governmental organization (NGO) in Southwest Uganda. This NGO subsidizes health facilities by paying for medical services on the basis of claims submitted after the patient consultation, targeting treatment of 99,000 clients between 2006-2011. I successfully tested Claim Mobile in Summer 2008, processing 35 claims over two weeks, and then discontinued it six months later, when it became apparent that integration and scale-up of the technology would be problematic for the NGO. In addition, many issues we hoped to address through technology had been addressed through program management changes instead. I find that a) the context motivating the technology changed over time, b) simpler solutions can be as effective as new technologies, and c) prioritizing the needs of the NGO required abandoning the deployment of Claim Mobile. Thus this paper presents the value of learning from failure in the process of designing for users in developing regions.
2012	Interactive paper substrates to support musical creation	We present paper substrates, interactive paper components that support the creation and manipulation of complex musical data. Substrates take different forms, from whole pages to movable strips, and contain or control typed data representations. We conducted participatory design sessions with five professional musicians with extensive experience with music creation tools. All generated innovative uses of paper substrates, manipulating their data, linking multiple representation layers and creating modular, reusable paper elements. The substrates reflect the structure of their computer-based data, but in a much more flexible and adaptable form. We use their prototypes to provide concrete examples of substrates, identify their roles, properties and functions. Finally, we explore their physical and interaction design with an interactive prototype.
2012	Successful classroom deployment of a social document annotation system	NB is an in-place collaborative document annotation website targeting students reading lecture notes and draft textbooks. Serving as a discussion forum in the document margins, NB lets users ask and answer questions about their reading material as they are reading . NB users can read and annotate documents using their web browsers, without any special plug-ins. We describe the NB system and its evaluation in real class environment, where students used it to submit their reading assignments, ask questions and get or provide feedback. We show that this tool can be and has been successfully incorporated into a number of different classes at different institutions. To understand how and why, we focus on a particularly successful class deployment where the instructor adapted his teaching style to take students' comment into account. We analyze the annotation practices that were observed - including the way geographic locality was exploited in ways unavailable in traditional forums - and discuss general design implications for online annotation tools in academia.
2012	Brainput: enhancing interactive systems with streaming fnirs brain input	This paper describes the Brainput system, which learns to identify brain activity patterns occurring during multitasking. It provides a continuous, supplemental input stream to an interactive human-robot system, which uses this information to modify its behavior to better support multitasking. This paper demonstrates that we can use non-invasive methods to detect signals coming from the brain that users naturally and effortlessly generate while using a computer system. If used with care, this additional information can lead to systems that respond appropriately to changes in the user's state. Our experimental study shows that Brainput significantly improves several performance metrics, as well as the subjective NASA-Task Load Index scores in a dual-task human-robot activity.
2012	The effect of task assignments and instruction types on remote asynchronous usability testing	Remote asynchronous usability testing involves users directly in reporting usability problems. Most studies of this approach employ predefined tasks to ensure that users experience specific aspects of the system, whereas other studies use no task assignments. Yet the effect of using predefined tasks is still to be uncovered. There is also limited research on instructions for users in identifying usability problems. This paper reports from a comparative study of the effect of task assignments and instruction types on the problems identified in remote asynchronous usability testing of a website for information retrieval, involving 53 prospective users. The results show that users solving predefined tasks identified significantly more usability problems with a significantly higher level of agreement than those working on their own authentic tasks. Moreover, users that were instructed by means of examples of usability problems identified significantly more usability problems than those who received a conceptual definition of usability problems.
2012	Analysis in practical usability evaluation: a survey study	Analysis is a key part of conducting usability evaluations, yet rarely systematically studied. Thus, we lack direction on how to do research on supporting practitioners' analysis and lose an opportunity for practitioners to learn from each other. We have surveyed 155 usability practitioners on the analysis in their latest usability evaluation. Analysis is typically flexible and light-weight. At the same time, practitioners see a need to strengthen reliability in evaluation. Redesign is closely integrated with analysis; more than half of the respondents provide visual redesign suggestions in their evaluation deliverables. Analysis support from academic research, including tools, forms and structured formats, does not seem to have direct impact on analysis practice. We provide six recommendations for future research to better support analysis.
2012	What do users really care about?: a comparison of usability problems found by users and experts on highly interactive websites	Expert evaluation methods, such as heuristic evaluation, are still popular in spite of numerous criticisms of their effectiveness. This paper investigates the usability problems found in the evaluation of six highly interactive websites by 30 users in a task-based evaluation and 14 experts using three different expert evaluation methods. A grounded theory approach was taken to categorize 935 usability problems from the evaluation. Four major categories emerged: Physical presentation, Content, Information Architecture and Interactivity. Each major category had between 5 and 16 sub-categories. The categories and sub-categories were then analysed for whether they were found by users only, experts only or both users and experts. This allowed us to develop an evidence-based set of 21 heuristics to assist in the development and evaluation of interactive websites.
2012	ZeroTouch: an optical multi-touch and free-air interaction architecture	ZeroTouch (ZT) is a unique optical sensing technique and architecture that allows precision sensing of hands, fingers, and other objects within a constrained 2-dimensional plane. ZeroTouch provides tracking at 80 Hz, and up to 30 concurrent touch points. Integration with LCDs is trivial. While designed for multi-touch sensing, ZT enables other new modalities, such as pen+touch and free-air interaction. In this paper, we contextualize ZT innovations with a review of other flat-panel sensing technologies. We present the modular sensing architecture behind ZT, and examine early diverse uses of ZT sensing.
2012	Evaluating the collaborative critique method	We introduce a new usability walkthrough method called Collaborative Critique (CC), which is inspired by the human-computer collaboration paradigm of system-user interaction. This method applies a "collaboration lens" to assessing the system's behavior and its impact on the user's efforts in the context of the task being performed. We present findings from a laboratory evaluation of the CC method with usability practitioners, in which the results of the CC walkthrough were compared to a benchmark set of problems collected via user testing with two experimental Enterprise Resource Planning (ERP) system tasks. The development of this new usability evaluation method was driven by the need for an approach that assesses the adequacy of the system's support for reducing the user's cognitive and physical effort in the context of the interaction.
2012	Ultra-tangibles: creating movable tangible objects on interactive tables	Tangible objects placed on interactive surfaces allow users to employ a physical object to manipulate digital content. However, creating the reverse effect - having digital content manipulate a tangible object placed on the surface - is a more challenging task. We present a new approach to this problem, using ultrasound-based air pressure waves to move multiple tangible objects, independently, around an interactive surface. We describe the technical background, design, implementation, and test cases for such a system. We conclude by discussing practical uses of our system, Ultra-Tangibles, in the creation of new tangible user interfaces.
2012	Enabling concurrent dual views on common LCD screens	Researchers have explored a variety of technologies that enable a single display to simultaneously present different content when viewed from different angles or by different people. These displays provide new functionalities such as personalized views for multiple users, privacy protection, and stereoscopic 3D displays. However, current multi-view displays rely on special hardware, thus significantly limiting their availability to consumers and adoption in everyday scenarios. In this paper, we present a pure software solution (i.e. with no hardware modification) that allows us to present two independent views concurrently on the most widely used and affordable type of LCD screen, namely Twisted Nematic (TN). We achieve this by exploiting a technical limitation of the technology which causes these LCDs to show varying brightness and color depending on the viewing angle. We describe our technical solution as well as demonstrate example applications in everyday scenarios.
2012	CapStones and ZebraWidgets: sensing stacks of building blocks, dials and sliders on capacitive touch screens	Recent research proposes augmenting capacitive touch pads with tangible objects, enabling a new generation of mobile applications enhanced with tangible objects, such as game pieces and tangible controllers. In this paper, we extend the concept to capacitive tangibles consisting of multiple parts, such as stackable gaming pieces and tangible widgets with moving parts. We achieve this using a system of wires and connectors inside each block that causes the capacitance of the bottom-most block to reflect the entire assembly. We demonstrate three types of tangibles, called CapStones , Zebra Dials and Zebra Sliders that work with current consumer hardware and investigate what designs may become possible as touchscreen hardware evolves.
2012	MOSOCO: a mobile assistive tool to support children with autism practicing social skills in real-life situations	MOSOCO is a mobile assistive application that uses augmented reality and the visual supports of a validated curriculum, the Social Compass, to help children with autism practice social skills in real-life situations. In this paper, we present the results of a seven-week deployment study of MOSOCO in a public school in Southern California with both students with autism and neurotypical students. The results of our study demonstrate that MOSOCO facilitates practicing and learning social skills, increases both quantity and quality of social interactions, reduces social and behavioral missteps, and enables the integration of children with autism in social groups of neurotypical children. The findings from this study reveal emergent practices of the uses of mobile assistive technologies in real-life situations.
2012	Supporting face-to-face communication between clinicians and children with chronic headaches through a zoomable multi-touch app	Chronic headaches are one of the top five health problems for young children in the United States, negatively affecting their quality of life and learning opportunities. A clear understanding of children's headache characteristics is crucial for delivering appropriate treatment. However, current data collection methods were designed for adults often resulting in insufficient information. In this paper we present a novel method to help children communicate with health care providers and researchers about their headaches. It augments an existing child-centric method called Draw-and-Tell Conversation, which has already been shown to provide more actionable information from children than standard data collection methods. It does so by enabling children to draw their symptoms on a zoomable drawing application, giving them the ability to provide more details and context than on paper. We present a study conducted with nineteen children aged 7 to 12 suggesting that children provided more information about their headaches when using the zoomable drawing application than when drawing on paper. This study provides a rare example of a mobile device used to enhance face-to-face interactions and contributes evidence of a specific benefit of zoomable user interfaces.
2012	ICT-development in residential care settings: sensitizing design to the life circumstances of the residents of a care home	In this paper we wish to contribute to the recent ICT-design for and reflection of the application field of residential care homes. In doing so, the contribution of the paper is twofold: we wish to highlight some aspects of the every-day life of institutionalized elderly people - trust, sociality, and memory - which not only provoke reflection on design ideas but also on the socio-technical nexus in which design for the elderly has to take place. This domain, we suggest, is one where the 'parachuting in' of technology is unlikely to prove successful, for reasons we examine below. Further, we suggest that design for and with the elderly carries with it some specific problems. We illustrate our methodological reflections by means of an ongoing empirical research project which aims at the development of a large-screen display for a residential care home.
2012	Design of an exergaming station for children with cerebral palsy	We report on the design of a novel station supporting the play of exercise video games (exergames) by children with cerebral palsy (CP). The station combines a physical platform allowing children with CP to provide pedaling input into a game, a standard Xbox 360 controller, and algorithms for interpreting the cycling input to improve smoothness and accuracy of gameplay. The station was designed through an iterative and incremental participatory design process involving medical professionals, game designers, computer scientists, kinesiologists, physical therapists, and eight children with CP. It has been tested through observation of its use, through gathering opinions from the children, and through small experimental studies. With our initial design, only three of eight children were capable of playing a cycling-based game; with the final design, seven of eight could cycle effectively, and six reached energy expenditure levels recommended by the American College of Sports Medicine while pedaling unassisted.
2012	Enabling self, intimacy and a sense of home in dementia: an enquiry into design in a hospital setting	Design and digital technologies to support a sense of self and human relationships for people living with dementia are both urgently needed. We present an enquiry into design for dementia facilitated by a public art commission for an adult mental health unit in a hospital in the UK. The interactive art piece was informed by the notion of personhood in dementia that foregrounds the person's social being and interpersonal relationships as sites where self is maintained and constructed. How clients, clients' family members and staff used the piece is reported and insights related to the notions of home, intimacy, possessions and self are presented. The art piece served as window on both dementia and the institution leading to a number of insights and implications for design.
2012	Investigating interruptions in the context of computerised cognitive testing for older adults	Interruptions in the home pose a threat to the validity of self-administered computerised cognitive testing. We report the findings of a laboratory experiment investigating the effects of increased interruption workload demand on older adults' computerised cognitive test performance. Related work has reported interruptions having a range of inhibitory and facilitatory effects on primary task performance. Cognitive ageing literature suggests that increased interruption workload demand should have greater detrimental effects on older adults' performance, when compared to younger adults. With 36 participants from 3 age groups (20-54, 55-69, 70+), we found divergent effects of increased interruption demand on two primary tasks. Results suggest that older and younger adults experience interruptions differently, but at no age is test performance compromised by demanding interruptions. This finding is reassuring with respect to the success of a self-administered computerised cognitive assessment test, and is likely to be useful for other applications used by older adults.
2012	Developing IDEAS: supporting children with autism within a participatory design team	IDEAS (Interface Design Experience for the Autistic Spectrum) is a method for involving children with Autism Spectrum Disorders (ASD) in the technology design process. This paper extends the IDEAS method to enable use with a design team, providing specific added support for communication and collaboration difficulties that may arise. A study to trial this extended method was conducted with two design teams, each involving three children with ASD, in a series of six, weekly design sessions focused on designing a math game. The findings from this study reveal that the children were able to successfully participate in the sessions and collaborate with other children. The findings also highlight the positive experience that involvement in such a process can offer this population.
2012	Observational and experimental investigation of typing behaviour using virtual keyboards for mobile devices	With the rise of current smartphones, virtual keyboards for touchscreens became the dominant mobile text entry technique. We developed a typing game that records how users touch on the standard Android keyboard to investigate users' typing behaviour. 47,770,625 keystrokes from 72,945 installations have been collected by publishing the game. By visualizing the touch distribution we identified a systematic skew and derived a function that compensates this skew by shifting touch events. By updating the game we conduct an experiment that investigates the effect of shifting touch events, changing the keys' labels, and visualizing the touched position. Results based on 6,603,659 keystrokes and 13,013 installations show that visualizing the touched positions using a simple dot decreases the error rate of the Android keyboard by 18.3% but also decreases the speed by 5.2% with no positive effect on learnability. The Android keyboard outperforms the control condition but the constructed shift function further improves the performance by 2.2% and decreases the error rate by 9.1%. We argue that the shift function can improve existing keyboards at no costs.
2012	The impact of three interfaces for 360-degree video on spatial cognition	In this paper, we describe an experiment designed to evaluate the effectiveness of three interfaces for surveillance or remote control using live 360-degree video feeds from a person or vehicle in the field. Video feeds are simulated using a game engine. While locating targets within a 3D terrain using a 2D 360-degree interface, participants indicated perceived egocentric directions to targets and later placed targets on an overhead view of the terrain. Interfaces were compared based on target finding and map placement performance. Results suggest 1) non-seamless interfaces with visual boundaries facilitate spatial understanding, 2) correct perception of self-to-object relationships is not correlated with understanding object-to-object relationships within the environment, and 3) increased video game experience corresponds with better spatial understanding of an environment observed in 360-degrees. This work can assist researchers of panoramic video systems in evaluating the optimal interface for observation and teleoperation of remote systems.
2012	Phylo-Genie: engaging students in collaborative 'tree-thinking' through tabletop techniques	Phylogenetic trees are representations of evolutionary relationships amongst species. Interviews of instructors and students have revealed that novice biologists have difficulty understanding phylogenetics. Moreover, misinterpretations of phylogenetics are common among college-level students. In this paper we present Phylo-Genie, a tabletop interface for fostering collaborative learning of phylogenetics. We conducted an experimental study with 56 participants, comparing students' conceptual learning and engagement using Phylo-Genie as: 1) a multi-touch tabletop interface and 2) a pen and paper activity. Our findings show that the tabletop implementation fosters collaborative learning by engaging users in the activity. We also shed light on the way in which our design principles facilitated engagement and collaborative learning in a tabletop environment.
2012	The impact of communication structure on new product development outcomes	New product development teams face important challenges to their performance due to the novelty of the work and the need to rapidly develop shared knowledge and goals. However, little is known about the relationship between the structural properties of communication and performance in these teams. This study examined the effect of communication structure, specifically hierarchical and small-world structures on the delivery performance and quality outcomes of a large-scale new product development project. Our longitudinal analyses revealed that structuring communication patterns in a hierarchical manner significantly improves delivery performance. However, hierarchical communication has a detrimental effect on quality while small-world communication structures improved the quality outcomes of development teams. We discuss the implications of these results for collaborative tools that support communication tradeoffs
2012	The eLabBench in the wild: supporting exploration in a molecular biology lab	In this paper we present a field trial of the eLabBench, a digital tabletop-based laboratory bench designed to support the exploratory practices of molecular biologists in the laboratory. The eLabBench supports the organization of personal information, capture of experimental work for later access, and the use of a variety of computational resources directly at the lab bench. We deployed the eLabBench in a biology laboratory for 16 weeks, and invited seven molecular biologists to run experiments on it. We report on how they used the bench and how it fitted within their larger experimental process. The main impact of the eLabBench lies in the changes it sparked off in preparing, running, and documenting lab experiments. By supporting computation at the bench and management of physical objects in the office, the eLabBench blurred the separation between office and laboratory work. Based on our observations, we discuss how interactive systems for laboratories such as the eLabBench can support a more exploratory or design-oriented way of 'doing' science.
2012	Income, race, and class: exploring socioeconomic differences in family technology use	Minorities are the fastest growing demographic in the U.S. and the poverty level in the U.S. is the highest it has been in 50 years. We interviewed middle to upper class, suburban, white American parents and low-income, urban, African-American parents to understand how each group incorporates technology into their lives. Participants had teens in their homes and devices like computers and cell phones played a powerful and preeminent role in family life. Our results show that socioeconomic differences both reflect and reinforce technology use at home. Specifically, low socioeconomic status families share devices more often and low socioeconomic status teens have more responsibility and independence in their technology use. We argue that that as low socioeconomic status families become the majority demographic, the CHI community needs to better understand how to design for these groups.
2012	How students find, evaluate and utilize peer-collected annotated multimedia data in science inquiry with zydeco	Scientific inquiry can be more authentic and meaningful to students when using personal and peer-collected data. The challenges of organizing and evaluating a potentially large amount of data can be overcome through the use of annotations (title, tags, and audio notes). We created Zydeco, a multi-component system that students use to collect annotated multimedia data from a museum (using a smartphone app), and then create a scientific explanation with their personal and peers' data (using a tablet app). We ran a classroom study with 54 students (ages 11-13) investigating how students searched for, evaluated, and used annotated data to construct a scientific explanation. We found that tags supported data interpretation, while title searching and panning through the unfiltered data set supported finding and using data.
2012	Cross-cutting faultlines of location and shared identity in the intergroup cooperation of partially distributed groups	This paper reports the results of a study comparing the relative influence of location and shared identity in partially distributed work. Using an experimental task called Shape Factory, groups of eight participants were configured such that in the baseline 'strangers' condition only the location-based faultline was present while in the experimental 'intergroup' condition, participants from two different shared identity groups engaged in distributed collaboration, creating an additional, cross-cutting faultline. The results showed that participants in the intergroup condition, with both location-based and shared identity faultlines, performed at a higher level than participants in the strangers condition, with only the location-based faultline. In the intergroup condition, the performance effects of location and shared identity were roughly equal and did not affect each other differentially in combination.
2012	One of the gang: supporting in-group behavior for embodied mediated communication	As an emerging technology that enables geographically distributed work teams, mobile remote presence (MRP) systems present new opportunities for supporting effective team building and collaboration. MRP systems are physically embodied mobile videoconferencing systems that remote co-workers control. These systems allow remote users, pilots , to actively initiate conversations and to navigate throughout the local environment. To investigate ways of encouraging team-like behavior among local and remote co-workers, we conducted a 2 (visual framing: decoration vs. no decoration) x 2 (verbal framing: interdependent vs. independent performance scoring) between-participants study ( n =40). We hypothesized that verbally framing the situation as interdependent and visually framing the MRP system to create a sense of self-extension would enhance group cohesion between the local and the pilot. We found that the interdependent framing was successful in producing more in-group oriented behaviors and, contrary to our predictions, visual framing of the MRP system weakened team cohesion.
2012	Evaluation of human tangential force input performance	While interacting with mobile devices, users may press against touch screens and also exert tangential force to the display in a sliding manner. We seek to guide UI design based on the tangential force applied by a user to the surface of a hand-held device. A prototype of an interface using tangential force input was implemented utilizing a force sensitive layer and an elastic layer and used for the user experiment. We investigated user controllability to reach and maintain target force levels and considered the effects of hand pose and direction of force input. Our results imply no significant difference in performance when applying force holding the device in one hand and in two hands. We also observed that users have more physical and perceived loads when applying tangential force in the left-right direction compared to the up-down direction. Based on the experimental results, we discuss considerations for user interface applications of tangential-force-based interface.
2012	Time travel proxy: using lightweight video recordings to create asynchronous, interactive meetings	Time Travel Proxy (TTP) enables participating in meetings that you cannot attend in real time, either because of time conflicts or global time zone differences. TTP uses lightweight video recordings to pre-record your contributions to a meeting, which are played on a tablet that serves as a proxy for you during the meeting. Reactions and responses in the meeting are also captured in video to give you feedback of what happened at the meeting. A working prototype of TTP was deployed and studied within four developer teams in their daily stand-up meetings. The study found that the affordances of video helped integrate the time traveler into the social context of the meeting, although the current prototype was better at enabling the time traveler to contribute to the meeting than it was in conveying the meeting experience back to the time traveler.
2012	ShutEye: encouraging awareness of healthy sleep recommendations with a mobile, peripheral display	Sleep is a basic physiological process essential for good health. However, 40 million people in the U.S. are diagnosed with sleep disorders, with many more undiagnosed. To help address this problem, we developed an application, ShutEye, which provides a peripheral display on the wall-paper of the user's mobile phone to promote awareness about recommended activities that promote good sleep quality. Based on preferences about the user's desired bed-time and activities' for example - consuming caffeine or performing vigorous exercise - ShutEye displays guidance about when engaging in those activities is likely to affect sleep without requiring any explicit interaction from the user. In this paper, we describe ShutEye and results from a four-week field study with 12 participants. Results indicate that a simple, recommendation-based peripheral display can be a very low-effort but still effective method for improving awareness of healthy sleep habits. We also provide recommendations about designing peripheral displays and extend insights for designing health-based mobile applications.
2012	Reactive information foraging: an empirical investigation of theory-based recommender systems for programmers	Information Foraging Theory (IFT) has established itself as an important theory to explain how people seek information, but most work has focused more on the theory itself than on how best to apply it. In this paper, we investigate how to apply a reactive variant of IFT (Reactive IFT) to design IFT-based tools, with a special focus on such tools for ill-structured problems. Toward this end, we designed and implemented a variety of recommender algorithms to empirically investigate how to help people with the ill-structured problem of finding where to look for information while debugging source code. We varied the algorithms based on scent type supported (words alone vs. words + code structure), and based on use of foraging momentum to estimate rapidity of foragers' goal changes. Our empirical results showed that (1) using both words and code structure significantly improved the ability of the algorithms to recommend where software developers should look for information; (2) participants used recommendations to discover new places in the code and also as shortcuts to navigate to known places; and (3) low-momentum recommendations were significantly more useful than high-momentum recommendations, suggesting rapid and numerous goal changes in this type of setting. Overall, our contributions include two new recommendation algorithms, empirical evidence about when and why participants found IFT-based recommendations useful, and implications for the design of tools based on Reactive IFT.
2012	Engagement with online mental health interventions: an exploratory clinical study of a treatment for depression	Online mental health interventions can benefit people experiencing a range of psychological difficulties, but attrition is a major problem in real-world deployments. We discuss strategies to reduce attrition, and present SilverCloud, a platform designed to provide more engaging online experiences. The paper presents the results of a practice-based clinical study in which 45 clients and 6 therapists used an online Cognitive Behavioural Therapy programme for depression. Pre and post-treatment assessments, using the Beck Depression Inventory, indicate a statistically significant improvement in depressive symptoms, with a large effect size, for the moderate-to-severe clinical sub-sample receiving standalone online treatment (n=18). This group was the primary target for the intervention. A high level of engagement was also observed compared to a prior online intervention used within the same service. We discuss strategies for design in this area and consider how the quantitative and qualitative results contribute towards our understanding of engagement.
2012	Viewpoint: empowering communities with situated voting devices	Viewpoint is a public voting device developed to allow residents in a disadvantaged community to make their voices heard through a simple, lightweight interaction. This was intended to open a new channel of communication within the community and increase community members' perception of their own efficacy. Local elected officials and community groups were able to post questions on devices located in public spaces, where residents could vote for one of two responses. Question authors were subsequently required to post a response indicating any actions to be taken. Following a two-month trial, we present our experiences and contribute guidelines for the design of public democracy tools and dimensions impacting their effectiveness, including credibility, efficacy and format.
2012	Profanity use in online communities	As user-generated Web content increases, the amount of inappropriate and/or objectionable content also grows. Several scholarly communities are addressing how to detect and manage such content: research in computer vision focuses on detection of inappropriate images, natural language processing technology has advanced to recognize insults. However, profanity detection systems remain flawed. Current list-based profanity detection systems have two limitations. First, they are easy to circumvent and easily become stale - that is, they cannot adapt to misspellings, abbreviations, and the fast pace of profane slang evolution. Secondly, they offer a one-size fits all solution; they typically do not accommodate domain, community and context specific needs. However, social settings have their own normative behaviors - what is deemed acceptable in one community may not be in another. In this paper, through analysis of comments from a social news site, we provide evidence that current systems are performing poorly and evaluate the cases on which they fail. We then address community differences regarding creation/tolerance of profanity and suggest a shift to more contextually nuanced profanity detection systems.
2012	Consensus building in open source user interface design discussions	We report results of a study which examines consensus building in user interface design discussions in open source software communities. Our methodology consisted of conducting interviews with designers and developers from the Drupal and Ubuntu communities (N=17) and analyzing a large corpus of interaction data collected from Drupal. The interviews captured user perspectives on the challenges of reaching consensus, techniques employed for building consensus, and the consequences of not reaching consensus. We analyzed the interaction data to determine how different elements of the content, process, and user relationships in the design discussions affect consensus. Our main result shows that design discussions engaging participants with more experience and prior interaction history are more likely to reach consensus. Based on all of our results, we formulated design implications for promoting consensus in distributed discussions of user interface design issues.
2012	Introducing the ambivalent socialiser	Social interaction can be a powerful strategy for persuasive technology interventions, yet many users are reluctant to engage with others online because they fear pressure, failure and shame. We introduce the 'ambivalent socialiser', a person who is simultaneously keen but also reluctant to engage with others via social media. Our contribution is to identify four approaches to introducing sociality to ambivalent socialisers: structured socialising, incidental socialising, eavesdropping and trace sensing. We discuss the rationale for these approaches and show how they address recent critiques of persuasive technology. Furthermore, we provide actionable insights for designers of persuasive technology by showing how these approaches can be implemented in a social media application.
2012	The case of the missed icon: change blindness on mobile devices	Insights into human visual attention have benefited many areas of computing, but perhaps most significantly visualisation and UI design [3]. With the proliferation of mobile devices capable of supporting significantly complex applications on small screens, demands on mobile UI design and the user's visual system are becoming greater. In this paper, we report results from an empirical study of human visual attention, specifically the Change Blindness phenomenon, on handheld mobile devices and its impact on mobile UI design. It is arguable that due to the small size of the screen - unlike a typical computer monitor - a greater visual coverage of the mobile device is possible, and that these phenomena may occur less frequently during the use of the device, or even that they may not occur at all. Our study shows otherwise. We tested for Change Blindness (CB) and Inattentional Blindness (IB) in a single-modal, mobile context and attempted to establish factors in the application interface design that induce and/or reduce their occurrences. The results show that both CB and IB can and do occur while using mobile devices. The results also suggest that the number of separate attendable items on-screen is directly proportional to rates of CB. Newly inserted objects were correctly identified more often than changes applied to existing on-screen objects. These results suggest that it is important for mobile UI designers to take these aspects of visual attention into account when designing mobile applications that attempt to deliver information through visual changes or notifications.
2012	Representing too small to see as too small to see with temporal representation	Teaching and learning the vast range of the sizes of the objects that are too small to see with human eyes (called imperceptible objects) has been a challenging issue in education. Because representation is the only medium that learners can use to make sense of imperceptible phenomena, learners encounter challenges when trying to understand the range of imperceptible sizes. However, the conventional visual representations that are incorporated in many learning technologies tend to direct learners to overestimate the sizes of imperceptible objects. To address this issue, we designed a multimodal representation called ""temporal-aural-visual representation" (or TAVR) to provide students with an alternative way of perceiving and conceptualizing imperceptible sizes. In prior studies it was noticed that learners constructed more refined mental models of the vast range of imperceptible sizes through the TAVR-enhanced learning activity. In this paper, we introduce a recent study that explored how to best augment the temporal experience of the range of imperceptible sizes with supporting modalities.
2012	Twitter and the development of an audience: those who stay on topic thrive!	Although economists have long recognized the importance of a critical mass in growing a community, we know little about how it is achieved. This paper examines how initial topical focus influences communities' ability to attract a critical mass. When starting an online community, organizers need to define its initial scope. Topically narrow communities will probably attract a homogeneous group of interested in its content and compatible with each other. However, they are likely to attract fewer members than a diverse one because they offer only a subset of the topics. This paper reports an empirical analysis of longitudinal data collected from Twitter, where each new Twitter poster is considered the seed of a potential social collection. Users who focus the topics of their early tweets more narrowly ultimately attract more followers with more ties among them. Our results shed light on the development of online social networking structures.
2012	Taming wild behavior: the input observer for text entry and mouse pointing measures from everyday computer use	We present the Input Observer , a tool that can run quietly in the background of users' computers and measure their text entry and mouse pointing performance from everyday use. In lab studies, participants are presented with prescribed tasks, enabling easy identification of speeds and errors. In everyday use, no such prescriptions exist. We devised novel algorithms to segment text entry and mouse pointing input streams into "trials". We are the first to measure errors for unprescribed text entry and mouse pointing. To measure errors, we utilize web search engines, adaptive offline dictionaries, an Automation API, and crowdsourcing. Capturing errors allows us to employ Crossman's (1957) speed-accuracy normalization when calculating Fitts' law throughputs. To validate the Input Observer, we compared its measures from 12 participants over a week of computer use to the same participants' results from a lab study. Overall, in the lab and field, average text entry speeds were 74.47 WPM and 80.59 WPM, respectively. Average uncorrected error rates were near zero, at 0.12% and 0.28%. For mouse pointing, average movement times were 971 ms and 870 ms. Average pointing error rates were 4.42% and 4.66%. Average throughputs were 3.48 bits/s and 3.45 bits/s. Device makers, researchers, and assistive technology specialists may benefit from measures of everyday use.
2012	Rock-paper-fibers: bringing physical affordance to mobile touch devices	We explore how to bring physical affordance to mobile touch devices. We present Rock-Paper-Fibers , a device that is functionally equivalent to a touchpad, yet that users can reshape so as to best match the interaction at hand. For efficiency, users interact bimanually: one hand reshapes the device and the other hand operates the resulting widget. We present a prototype that achieves deformability using a bundle of optical fibers, demonstrate an audio player and a simple video game each featuring multiple widgets. We demonstrate how to support applications that require responsiveness by adding mechanical wedges and clamps .
2012	IllumiShare: sharing any surface	Task and reference spaces are important communication channels for remote collaboration. However, all existing systems for sharing these spaces have an inherent weakness: they cannot share arbitrary physical and digital objects on arbitrary surfaces. We present IllumiShare, a new cost-effective, light-weight device that solves this issue. It both shares physical and digital objects on arbitrary surfaces and provides rich referential awareness. To evaluate IllumiShare, we studied pairs of children playing remotely. They used IllumiShare to share the task-reference space and Skype Video to share the person space. The study results show that IllumiShare shared the play space in a natural and seamless way. We also found that children preferred having both spaces compared to having only one. Moreover, we found that removing the task-reference space caused stronger negative disruptions to the play task and engagement level than removing the person space. Similarly, we found that adding the task-reference space resulted in stronger positive disruptions.
2012	Augmenting the scope of interactions with implicit and explicit graphical structures	When using interactive graphical tools, users often have to manage a structure, i.e. the arrangement of and relations between the parts or elements of the content. However, interaction with structures may be complex and not well integrated with interaction with the content. Based on contextual inquiries and past work, we have identified a number of requirements for the interaction with graphical structures. We have designed and explored two interactive tools that rely on implicit and explicit structures: ManySpector, an inspector for multiple objects that help visualize and interact with used values; and links that users can draw between object properties to provide a dependency. The interactions with the tools augment the scope of interactions to multiple objects. A study showed that users understood the interactions and could use them to perform complex graphical tasks.
2012	Toward a theory of interaction in mobile paper-digital ensembles	Although smartphones and tablets become increasingly popular, pen and paper continues to play an important role in mobile practices, such as note taking or creative discussions. Applications designed to combine the benefits of both worlds in a mobile paper-digital ensemble require a theoretical understanding of interaction, to inform the design of adequate interaction techniques. To fill this void, we propose a theory based on the results of a stimulus driven exploratory study.
2012	Shake'n'sense: reducing interference for overlapping structured light depth cameras	We present a novel yet simple technique that mitigates the interference caused when multiple structured light depth cameras point at the same part of a scene. The technique is particularly useful for Kinect, where the structured light source is not modulated. Our technique requires only mechanical augmentation of the Kinect, without any need to modify the internal electronics, firmware or associated host software. It is therefore simple to replicate. We show qualitative and quantitative results highlighting the improvements made to interfering Kinect depth signals. The camera frame rate is not compromised, which is a problem in approaches that modulate the structured light source. Our technique is non-destructive and does not impact depth values or geometry. We discuss uses for our technique, in particular within instrumented rooms that require simultaneous use of multiple overlapping fixed Kinect cameras to support whole room interactions.
2012	Humantenna: using the body as an antenna for real-time whole-body interaction	Computer vision and inertial measurement have made it possible for people to interact with computers using whole-body gestures. Although there has been rapid growth in the uses and applications of these systems, their ubiquity has been limited by the high cost of heavily instrumenting either the environment or the user. In this paper, we use the human body as an antenna for sensing whole-body gestures. Such an approach requires no instrumentation to the environment, and only minimal instrumentation to the user, and thus enables truly mobile applications. We show robust gesture recognition with an average accuracy of 93% across 12 whole-body gestures, and promising results for robust location classification within a building. In addition, we demonstrate a real-time interactive system which allows a user to interact with a computer using whole-body gestures
2012	Your phone or mine?: fusing body, touch and device sensing for multi-user device-display interaction	Determining who is interacting with a multi-user interactive touch display is challenging. We describe a technique for associating multi-touch interactions to individual users and their accelerometer-equipped mobile devices. Real-time device accelerometer data and depth camera-based body tracking are compared to associate each phone with a particular user, while body tracking and touch contacts positions are compared to associate a touch contact with a specific user. It is then possible to associate touch contacts with devices, allowing for more seamless device-display multi-user interactions. We detail the technique and present a user study to validate and demonstrate a content exchange application using this approach.
2012	SoundWave: using the doppler effect to sense gestures	Gesture is becoming an increasingly popular means of interacting with computers. However, it is still relatively costly to deploy robust gesture recognition sensors in existing mobile platforms. We present SoundWave , a technique that leverages the speaker and microphone already embedded in most commodity devices to sense in-air gestures around the device. To do this, we generate an inaudible tone, which gets frequency-shifted when it reflects off moving objects like the hand. We measure this shift with the microphone to infer various gestures. In this note, we describe the phenomena and detection algorithm, demonstrate a variety of gestures, and present an informal evaluation on the robustness of this approach across different devices and people.
2012	BiTouch and BiPad: designing bimanual interaction for hand-held tablets	Despite the demonstrated benefits of bimanual interaction, most tablets use just one hand for interaction, to free the other for support. In a preliminary study, we identified five holds that permit simultaneous support and interaction, and noted that users frequently change position to combat fatigue. We then designed the BiTouch design space, which introduces a support function in the kinematic chain model for interacting with hand-held tablets, and developed BiPad, a toolkit for creating bimanual tablet interaction with the thumb or the fingers of the supporting hand. We ran a controlled experiment to explore how tablet orientation and hand position affect three novel techniques: bimanual taps, gestures and chords. Bimanual taps outperformed our one-handed control condition in both landscape and portrait orientations; bimanual chords and gestures in portrait mode only; and thumbs outperformed fingers, but were more tiring and less stable. Together, BiTouch and BiPad offer new opportunities for designing bimanual interaction on hand-held tablets.
2012	We've bin watching you: designing for reflection and social persuasion to promote sustainable lifestyles	BinCam is a social persuasive system to motivate reflection and behavioral change in the food waste and recycling habits of young adults. The system replaces an existing kitchen refuse bin and automatically logs disposed of items through digital images captured by a smart phone installed on the underside of the bin lid. Captured images are uploaded to a BinCam application on Facebook where they can be explored by all users of the BinCam system. Engagement with BinCam is designed to fit into the existing structure of users' everyday life, with the intention that reflection on waste and recycling becomes a playful and shared group activity. Results of a user study reveal an increase in both users' awareness of, and reflection about, their waste management and their motivation to improve their waste-related skills. With BinCam, we also explore informational and normative social influences as a source of change (e.g., socially evoked feelings of 'guilt' for non-recycling or food disposal), which has to date been underexplored in persuasive HCI. Design implications for reflection and social persuasion are proposed.
2012	Hand occlusion on a multi-touch tabletop	We examine the shape of hand and forearm occlusion on a multi-touch table for different touch contact types and tasks. Individuals have characteristic occlusion shapes, but with commonalities across tasks, postures, and handedness. Based on this, we create templates for designers to justify occlusion-related decisions and we propose geometric models capturing the shape of occlusion. A model using diffused illumination captures performed well when augmented with a forearm rectangle, as did a modified circle and rectangle model with ellipse "fingers" suitable when only X-Y contact positions are available. Finally, we describe the corpus of detailed multi-touch input data we generated which is available to the community.
2012	Voice typing: a new speech interaction model for dictation on touchscreen devices	Dictation using speech recognition could potentially serve as an efficient input method for touchscreen devices. However, dictation systems today follow a mentally disruptive speech interaction model: users must first formulate utterances and then produce them, as they would with a voice recorder. Because utterances do not get transcribed until users have finished speaking, the entire output appears and users must break their train of thought to verify and correct it. In this paper, we introduce Voice Typing, a new speech interaction model where users' utterances are transcribed as they produce them to enable real-time error identification. For fast correction, users leverage a marking menu using touch gestures. Voice Typing aspires to create an experience akin to having a secretary type for you, while you monitor and correct the text. In a user study where participants composed emails using both Voice Typing and traditional dictation, they not only reported lower cognitive demand for Voice Typing but also exhibited 29% relative reduction of user corrections. Overall, they also preferred Voice Typing.
2012	The SoundsRight CAPTCHA: an improved approach to audio human interaction proofs for blind users	In this paper we describe the development of a new audio CAPTCHA called the SoundsRight CAPTCHA, and the evaluation of the CAPTCHA with 20 blind users. Blind users cannot use visual CAPTCHAs, and it has been documented in the research literature that the existing audio CAPTCHAs have task success rates below 50% for blind users. The SoundsRight audio CAPTCHA presents a real-time audio-based challenge in which the user is asked to identify a specific sound (for example the sound of a bell or a piano) each time it occurs in a series of 10 sounds that are played through the computer's audio system. Evaluation results from three rounds of usability testing document that the task success rate was higher than 90% for blind users. Discussion, limitations, and suggestions for future research are also presented.
2012	See me, see you: a lightweight method for discriminating user touches on tabletop displays	Tabletop systems provide a versatile space for collaboration, yet, in many cases, are limited by the inability to differentiate the interactions of simultaneous users. We present See Me, See You, a lightweight approach for discriminating user touches on a vision-based tabletop. We contribute a valuable characterization of finger orientation distributions of tabletop users. We exploit this biometric trait with a machine learning approach to allow the system to predict the correct position of users as they touch the surface. We achieve accuracies as high as 98% in simple situations and above 92% in more challenging conditions, such as two-handed tasks. We show high acceptance from users, who can self-correct prediction errors without significant costs. See Me, See You is a viable solution for providing simple yet effective support for multi-user application features on tabletops.
2012	Legible, are you sure?: an experimentation-based typographical design in safety-critical context	Designing Safety-critical interfaces entails proving the safety and operational usability of each component. Largely taken for granted in everyday interface design, the typographical component, through its legibility and aesthetics, weighs heavily on the ubiquitous reading task at the heart of most visualizations and interactions. In this paper, we present a research project whose goal is the creation of a new typeface to display textual information on future aircraft interfaces. After an initial task analysis leading to the definition of specific needs, requirements and design principles, the design constantly evolves from an iterative cycle of design and experimentation. We present three experiments (laboratory and cockpit) used mainly to validate initial choices and fine-tune font properties. Results confirm the importance of rigorously testing the typographical component as a part of text output evaluation in interactive systems.
2012	Using mobile phones to support sustainability: a field study of residential electricity consumption	Recent focus on sustainability has made consumers more aware of our joint responsibility for conserving energy resources such as electricity. However, reducing electricity use can be difficult with only a meter and a monthly or annual electricity bill. With the emergence of new power meters units, information on electricity consumption is now available digitally and wirelessly. This enables the design and deployment of a new class of persuasive systems giving consumers insight into their use of energy resources and means for reducing it. In this paper, we explore the design and use of one such system, Power Advisor, promoting electricity conservation through tailored information on a mobile phone or tablet. The use of the system in 10 households was studied over 7 weeks. Findings provide insight into peoples awareness of electricity consumption in their home and how this may be influenced through design.
2012	SSMRecolor: improving recoloring tools with situation-specific models of color differentiation	Color is commonly used to convey information in digital environments, but colors can be difficult to distinguish for many users -- either because of a congenital color vision deficiency (CVD), or because of situation-induced CVDs such as wearing colored glasses or working in sunlight. Tools intended to improve color differentiability (recoloring tools) exist, but these all use abstract models of only a few types of congenital CVD; if the user's color problems have a different cause, existing recolorers can perform poorly. We have developed a recoloring tool (SSMRecolor) based on the idea of situation-specific modeling -- in which we build a performance-based model of a particular user in their specific environment, and use that model to drive the recoloring process. SSMRecolor covers a much wider range of CVDs, including acquired and situational deficiencies. We evaluated SSMRecolor and two existing tools in a controlled study of people's color-matching performance in several environmental conditions. The study included participants with and without congenital CVD. Our results show both accuracy and response time in color-matching tasks were significantly better with SSMRecolor. This work demonstrates the value of a situation-specific approach to recoloring, and shows that this technique can substantially improve the usability of color displays for users of all types.
2012	WalkType: using accelerometer data to accomodate situational impairments in mobile touch screen text entry	The lack of tactile feedback on touch screens makes typing difficult, a challenge exacerbated when situational impairments like walking vibration and divided attention arise in mobile settings. We introduce WalkType , an adaptive text entry system that leverages the mobile device's built-in tri-axis accelerometer to compensate for extraneous movement while walking. WalkType's classification model uses the displacement and acceleration of the device, and inference about the user's footsteps. Additionally, WalkType models finger-touch location and finger distance traveled on the screen, features that increase overall accuracy regardless of movement. The final model was built on typing data collected from 16 participants. In a study comparing WalkType to a control condition, WalkType reduced uncorrected errors by 45.2% and increased typing speed by 12.9% for walking participants.
2012	Triggering triggers and burying barriers to customizing software	General-purpose software applications are usually not tailored for a specific user with specific tasks, strategies or preferences. In order to achieve optimal performance with such applications, users typically need to transition to an alternative efficient behavior. Often, features of such alternative behaviors are not initially accessible and first need to be customized. However, few research works formally study and empirically measure what drives a user to customize. In this paper, we describe the challenges involved in empirically studying customization behaviors, and propose a methodology for formally measuring the impact of potential customization factors. We then demonstrate this methodology by studying the impact of different customization factors on customization behaviors. Our results show that increasing exposure and awareness of customization features, and adding social influence can significantly affect the user's customization behavior.
2012	Designing social translucence over social networks	Social translucence is a landmark theory in social computing. Modeled on physical life, it guides designers toward elegant social technologies. However, we argue that it breaks down over modern social network sites because social networks resist its physical metaphors. In this paper, we build theory relating social translucence to social network structure. To explore this idea, we built a tool called Link Different. Link Different addresses a structural awareness problem by letting users know how many of their Twitter followers already a saw link via someone else they follow. During two months on the web, nearly 150K people used the site a total of 1.3M times. Its widespread, viral use suggests that people want social translucence, but network structure gets in the way. We conclude the paper by illustrating new design problems that lie at the intersection of social translucence and other unexplored network structures.
2012	Codelets: linking interactive documentation and example code in the editor	Programmers frequently use instructive code examples found on the Web to overcome cognitive barriers while programming. These examples couple the concrete functionality of code with rich contextual information about how the code works. However, using these examples necessitates understanding, configuring, and integrating the code, all of which typically take place after the example enters the user's code and has been removed from its original instructive context. In short, a user's interaction with an example continues well after the code is pasted . This paper investigates whether treating examples as "first-class" objects in the code editor - rather than simply as strings of text - will allow programmers to use examples more effectively. We explore this through the creation and evaluation of Codelets . A Codelet is presented inline with the user's code, and consists of a block of example code and an interactive helper widget that assists the user in understanding and integrating the example. The Codelet persists throughout the example's lifecycle, remaining accessible even after configuration and integration is done. A comparative laboratory study with 20 participants found that programmers were able to complete tasks involving examples an average of 43% faster when using Codelets than when using a standard Web browser.
2012	Multidimensional pareto optimization of touchscreen keyboards for speed, familiarity and improved spell checking	This paper presents a new optimization technique for keyboard layouts based on Pareto front optimization. We used this multifactorial technique to create two new touchscreen phone keyboard layouts based on three design metrics: minimizing finger travel distance in order to maximize text entry speed, a new metric to maximize the quality of spell correction by reducing tap ambiguity, and maximizing familiarity through a similarity function with the standard Qwerty layout. The paper describes the optimization process and resulting layouts for a standard trapezoid shaped keyboard and a more rectangular layout. Fitts' law modelling shows a predicted 11% improvement in entry speed without taking into account the significantly improved error correction potential and the subsequent effect on speed. In initial user tests typing speed dropped from approx. 21 wpm with Qwerty to 13 wpm (64%) on first use of our layout but recovered to 18 wpm (85%) within four short trial sessions, and was still improving. NASA TLX forms showed no significant difference on load between Qwerty and our new layout use in the fourth session. Together we believe this shows the new layouts are faster and can be quickly adopted by users.
2012	Evaluating interactive support for secure programming	Implementing secure code is an important and oft-overlooked non-functional requirement. Secure programming errors are a subset of program errors that result in many common privacy and security breaches in commercial software. We are seeking to provide interactive support for secure programming in the development environment. In this paper, we have evaluated our prototype tool, ASIDE, which provides real-time warnings and code generation to reduce secure programming errors introduced by programmers. We evaluate the potential use and effectiveness of ASIDE on both novice and professional developers in two comparison user studies. Our results demonstrate that the interactive support can help address this important non-functional requirement, and suggest guidelines for such tools to support programmers.
2012	Brainstorming for Japan: rapid distributed global collaboration for disaster response	Tragic events struck northern Japan in March-April 2011. This note presents a case study of rapid distributed brainstorming for disaster response, involving 275 contributors from 23 countries within a three-day period, conducted among the staff in a multinational company. Factors that appear to have contributed to the success of this brainstorming include: Social media that could be easily appropriated; and employee familiarity with large-scale brainstorming. The formation of this "flash-community" joins other CHI reports to point toward a new genre of rapid large-scale responses to disasters through social media.
2012	Touch typing using thumbs: understanding the effect of mobility and hand posture	Mobile touch devices have become increasingly popular, yet typing on virtual keyboards whilst walking is still an overwhelming task. In this paper we analyze; firstly, the negative effect of walking on text-input performance, particularly the users' main difficulties and error patterns. We focused our research on thumb typing, since this is a commonly used technique to interact with touch interfaces. Secondly, we analyze how these effects can be compensated by two-hand interaction and increasing target size. We asked 22 participants to input text under three mobility conditions (seated, slow walking, and normal walking) and three hand conditions (one-hand/portrait, two-hand/portrait, and two-hand/landscape). Results show that independently of hand condition, mobility significantly decreased input quality, leading to specific error patterns. Moreover, it was shown that target size can compensate the negative effect of walking, while two-hand interaction does not provide additional stability or input accuracy. We finish with implications for future designs.
2012	Beyond QWERTY: augmenting touch screen keyboards with multi-touch gestures for non-alphanumeric input	Although many techniques have been proposed to improve text input on touch screens, the vast majority of this research ignores non-alphanumeric input ( i.e. , punctuation, symbols, and modifiers). To support this input, widely adopted commercial touch-screen interfaces require mode switches to alternate keyboard layouts for most punctuation and symbols. Our approach is to augment existing ten-finger QWERTY keyboards with multi-touch gestural input that can exist as a complement to the moded-keyboard approach. To inform our design, we conducted a study to elicit user-defined gestures from 20 participants. The final gesture set includes both multi-touch and single-touch gestures for commonly used non-alphanumeric text input. We implemented and conducted a preliminary evaluation of a touch-screen keyboard augmented with this technique. Findings show that using gestures for non-alphanumeric input is no slower than using keys, and that users strongly prefer gestures to a moded-keyboard interface.
2012	A general-purpose target-aware pointing enhancement using pixel-level analysis of graphical interfaces	We present a general-purpose implementation of a target aware pointing technique, functional across an entire desktop and independent of application implementations. Specifically, we implement Grossman and Balakrishnan's Bubble Cursor, the fastest general pointing facilitation technique in the literature. Our implementation obtains the necessary knowledge of interface targets using a combination of pixel-level analysis and social annotation. We discuss the most novel aspects of our implementation, including methods for interactive creation and correction of pixel-level prototypes of interface elements and methods for interactive annotation of how the cursor should select identified elements. We also report on limitations of the Bubble Cursor unearthed by examining our implementation in the complexity of real-world interfaces. We therefore contribute important progress toward real-world deployment of an important family of techniques and shed light on the gap between understanding techniques in controlled settings versus behavior with real-world interfaces.
2012	Using shear as a supplemental two-dimensional input channel for rich touchscreen interaction	Touch input is constrained, typically only providing finger X/Y coordinates. To access and switch between different functions, valuable screen real estate must be allocated to buttons and menus, or users must perform special actions, such as touch-and-hold, double tap, or multi-finger chords. Even still, this only adds a few bits of additional information, leaving touch interaction unwieldy for many tasks. In this work, we suggest using a largely unutilized touch input dimension: shear (force tangential to a screen's surface). Similar to pressure, shear can be used in concert with conventional finger positional input. However, unlike pressure, shear provides a rich, analog 2D input space, which has many powerful uses. We put forward five classes of advanced interaction that considerably expands the envelope of interaction possible on touchscreens.
2012	PocketNavigator: studying tactile navigation systems in-situ	In this paper, we report about a large-scale in-situ study of tactile feedback for pedestrian navigation systems. Recent advances in smartphone technology have enabled a number of interaction techniques for smartphone that use tactile feedback to deliver navigation information. The aim is to enable eyes-free usage and avoid distracting the user from the environment. Field studies where participants had to fulfill given navigation tasks, have found these techniques to be efficient and beneficial in terms of distraction. But it is not yet clear whether these findings will replicate in in-situ usage. We, therefore, developed a Google Maps-like navigation application that incorporates interaction techniques proposed in previous work. The application was published for free on the Android Market and so people were able to use it as a navigation system in their everyday life. The data collected through anonymous monitoring suggests that tactile feedback is successfully adopted in one third of all trips and has positive effects on the user's level of distraction.
2012	Funneling and saltation effects for tactile interaction with virtual objects	Funneling and saltation are two major illusory feedback techniques for vibration-based tactile feedback. They are often put into practice e.g. to reduce the number of vibrators to be worn on the body and thereby build a less cumbersome feedback device. Recently, these techniques have been found to be applicable to eliciting "out of the body" experiences as well (e.g. through user-held external objects). This paper examines the possibility of applying this phenomenon to interacting with virtual objects. Two usability experiments were run to test the effects of funneling and saltation respectively for perceiving tactile sensation from a virtual object in an augmented reality setting. Experimental results have shown solid evidences for phantom sensations from virtual objects with funneling, but mixed results for saltation.
2012	Extending Fitts' law to account for the effects of movement direction on 2d pointing	Fitts' law is the most widely applied model in the field of HCI. However, this model and its existing extensions are still limited for 2D pointing task especially when the effects of movement direction ( Θ ) remain in the task. In this paper, we employ the concept of projection to account for the effects of target width ( W ) and height ( H ) on movement time so that we seamlessly integrate the four factors, i.e. Θ , amplitude ( A ), W and H , into the new extension of Fitts' law, which can uncover not only the periodicity of the asymmetrical impacts of W and H with the variation of Θ but also their interrelation. Carrying out two experiments, we verify that the vertical projection of W and the horizontal projection of H in the line of movement direction can be viewed as the determinants of movement time. Finally, we offer recommendations for 2D pointing experiments and discuss the implications for interface designs.
2012	Accurate measurements of pointing performance from in situ observations	We present a method for obtaining lab-quality measurements of pointing performance from unobtrusive observations of natural in situ interactions. Specifically, we have developed a set of user-independent classifiers for discriminating between deliberate, targeted mouse pointer movements and those movements that were affected by any extraneous factors. To develop and validate these classifiers, we developed logging software to unobtrusively record pointer trajectories as participants naturally interacted with their computers over the course of several weeks. Each participant also performed a set of pointing tasks in a formal study set-up. For each movement, we computed a set of measures capturing nuances of the trajectory and the speed, acceleration, and jerk profiles. Treating the observations from the formal study as positive examples of deliberate, targeted movements and the in situ observations as unlabeled data with an unknown mix of deliberate and distracted interactions, we used a recent advance in machine learning to develop the classifiers. Our results show that, on four distinct metrics, the data collected in-situ and filtered with our classifiers closely matches the results obtained from the formal experiment.
2012	GyroTab: a handheld device that provides reactive torque feedback	Haptic devices that provide robust and realistic force feedback are generally grounded to counterweight the applied force, prohibiting their use in mobile devices. Many ungrounded force-feedback devices rely on the gyro effect to produce torques on the human body, but their active control systems render them extremely bulky for implementation in small mobile devices. We present GyroTab, a relatively flat handheld system that utilizes the gyro effect to provide torque feedback. GyroTab relies on the user to produce an input torque and provides feedback by opposing that torque, making its feedback reactive to the user's motion. We describe the implementation of GyroTab, discuss the kinds of feedback it generates, and explore some of the psychophysical results we obtained from a study with the device.
2012	Assisting hand skill transfer of tracheal intubation using outer-covering haptic display	Various systems for hand tool skill training have been developed in the domain of haptic displays. These systems typically present force to a learner's palm by directly actuating the tool. However, this approach is sometimes ineffective because learners have difficulty sensing the haptic feedback from the tool when they are holding it tightly. Thus, we propose a different approach (OCHD) that effectively guides the learner's hand by presenting force to the back of his/her hand as if an instructor is holding it. A preliminary experiment showed that OCHD effectively guides users with less actuator drive force than cases where the tool is directly actuated.
2012	An investigation of Fitts' law in a multiple-display environment	We describe the design and analysis of a Fitts' law experiment, conducted in a multiple-display environment (MDE), in which the physical gap between displays and the proximity of targets to the gap systematically varied. Participants achieved decreasing throughput values (a combined measure of movement time and accuracy in a target acquisition task) under increasing gap sizes. Participants likewise performed relatively poorly in tasks involving monitor crossing over all gap conditions, especially so when motion either originates or terminates very close to the gap. Both results could be considered surprising since in either case, the amount of mouse movement needed to successfully execute the task does not change based on physical gap size or a target's proximity to the edge. Fitts' law may underestimate the difficulty of movement tasks in MDEs.
2012	Participation and publics: supporting community engagement	CHI researchers are beginning a shift from studying technology use in uncommon or exotic communities to designing and deploying technology interventions into those same settings. This paper picks up on these recent developments and further examines the impact and implication of using a bespoke technology platform within the context of providing shelter and basic social services to homeless mothers and their children. I build on findings from a previous system deployment by describing targeted changes made to the technology, the design impetus for making those changes, and the resulting impact those changes had on the relationship between shelter staff, residents, and the information they shared via the system. By way of the findings reported here, I continue to develop the framing of Deweyan publics as a way to scaffold an environmental approach to technology design in contexts with multiple and diverse stakeholders.
2012	The bohemian bookshelf: supporting serendipitous book discoveries through information visualization	Serendipity, a trigger of exciting yet unexpected discoveries, is an important but comparatively neglected factor in information seeking, research, and ideation. We suggest that serendipity can be facilitated through visualization. To explore this, we introduce the Bohemian Bookshelf, which aims to support serendipitous discoveries in the context of digital book collections. The Bohemian Bookshelf consists of five interlinked visualizations each offering a unique overview of the collection. It aims at encouraging serendipity by (1) offering multiple visual access points to the collection, (2) highlighting adjacencies between books, (3) providing flexible visual pathways for exploring the collection, (4) enticing curiosity through abstract, metaphorical, and visually distinct representations of books, and (5) enabling a playful approach to information exploration. A deployment at a library revealed that visitors embraced this approach of utilizing visualization to support open-ended explorations and serendipitous discoveries. This encourages future explorations into promoting serendipity through information visualization.
2012	Envisioning ubiquitous computing	Visions of the future are a common feature of discourse within ubiquitous computing and, more broadly, HCI. 'Envisioning', a characteristic future-oriented technique for design thinking, often features as significant part of our research processes in the field. This paper compares, contrasts and critiques the varied ways in which envisionings have been used within ubiquitous computing and traces their relationships to other, different envisionings, such as those of virtual reality. In unpacking envisioning, it argues primarily that envisioning should be foregrounded as a significant concern and interest within HCI. Foregrounding envisioning's frequent mix of fiction, forecasting and extrapolation, the paper recommends changes in the way we read, interpret and use envisionings through taking into account issues such as context and intended audience.
2012	Is this what you meant?: promoting listening on the web with reflect	A lack of support for active listening undermines discussion and deliberation on the web. We contribute a design frame identifying potential improvements to web discussion were listening more explicitly encouraged in interfaces. We explore these concepts through a novel interface, Reflect, that creates a space next to every comment where others can summarize the points they hear the commenter making. Deployments on Slashdot, Wikimedia's Strategic Planning Initiative, and a local civic effort suggest that interfaces for listening may have traction for general use on the web.
2012	LemonAid: selection-based crowdsourced contextual help for web applications	Web-based technical support such as discussion forums and social networking sites have been successful at ensuring that most technical support questions eventually receive helpful answers. Unfortunately, finding these answers is still quite difficult, since users' textual queries are often incomplete, imprecise, or use different vocabularies to describe the same problem. We present LemonAid, a new approach to help that allows users to find help by instead selecting a label, widget, link, image or other user interface (UI) element that they believe is relevant to their problem. LemonAid uses this selection to retrieve previously asked questions and their corresponding answers. The key insight that makes LemonAid work is that users tend to make similar selections in the interface for similar help needs and different selections for different help needs. Our initial evaluation shows that across a corpus of dozens of tasks and thousands of requests, LemonAid retrieved a result for 90% of help requests based on UI selections and, of those, over half had relevant matches in the top 2 results.
2012	CommunitySourcing: engaging local crowds to perform expert work via physical kiosks	Online labor markets, such as Amazon's Mechanical Turk, have been used to crowdsource simple, short tasks like image labeling and transcription. However, expert knowledge is often lacking in such markets, making it impossible to complete certain classes of tasks. In this work we introduce an alternative mechanism for crowdsourcing tasks that require specialized knowledge or skill: communitysourcing --- the use of physical kiosks to elicit work from specific populations. We investigate the potential of communitysourcing by designing, implementing and evaluating Umati: the communitysourcing vending machine. Umati allows users to earn credits by performing tasks using a touchscreen attached to the machine. Physical rewards (in this case, snacks) are dispensed through traditional vending mechanics. We evaluated whether communitysourcing can accomplish expert work by using Umati to grade Computer Science exams. We placed Umati in a university Computer Science building, targeting students with grading tasks for snacks. Over one week, 328 unique users (302 of whom were students) completed 7771 tasks (7240 by students). 80% of users had never participated in a crowdsourcing market before. We found that Umati was able to grade exams with 2% higher accuracy (at the same price) or at 33% lower cost (at equivalent accuracy) than traditional single-expert grading. Mechanical Turk workers had no success grading the same exams. These results indicate that communitysourcing can successfully elicit high-quality expert work from specific communities.
2012	Revisiting the jacquard loom: threads of history and current patterns in HCI	In the recent developments of human computer interaction, one central challenge has been to find and to explore alternatives to the legacy of the desktop computer paradigm for interaction design. To investigate this issue further we have conducted an analysis on a fascinating piece of machinery often referred to as one of the predecessors of the modern day computer, the Jacquard loom. In analysing the Jacquard loom we look at qualities in design and interaction from some different perspectives: how historical tools, crafts, and practices can inform interaction design, the role of physicality, materiality, and full-body interaction in order to rethink some current conceptions of interaction and design of computational devices.
2012	Act natural: instructions, compliance and accountability in ambulatory experiences	This paper uses a detailed ethnographic study of an ambulatory experience, where participants were invited to explore the perspective of two notorious terrorists, in order to discuss the nature of instruction-giving and, most particularly, the methodical ways in which such instructions are complied with. Four distinct layers of compliance are identified, as are three different kinds of accountability, all of which stand potentially at odds with one another. The paper examines the tensions created by this, tensions that are further aggravated by instructions usually being delivered down a thin channel, with considerable surrounding contextual complexity and little opportunity for repair, and uncovers some core challenges for future design in relation to providing instructions for, and orchestrating a range of possible activities.
2012	Supporting improvisation work in inter-organizational crisis management	Improvisation is necessary when planned decision-making as the main managerial activity does not fit the conditions the practice provides. In these cases, information technology should not just automate planned and structured decisions, but support improvisational practice. In this contribution we present an empirical study about the improvisation work in scenarios of medium to large power outages in Germany. Our focus is on inter-organizational cooperation practices, thus we examined the cooperation of fire departments, police, public administration, electricity infrastructure operators and citizens. Our empirical material allows to describe reasons and conditions for improvisation. Our resulting recommendations address the support of aggregation and visualization of information, a necessary individualization of information compositions, options for collaborative situation assessment, requirements for informal and formal communication, and accessibility of information resources.
2012	#EpicPlay: crowd-sourcing sports video highlights	During a live sports event, many sports fans use social media as a part of their viewing experience, reporting on their thoughts on the event as it unfolds. In this work, we use this information stream to semantically annotate live broadcast sports games, using these annotations to select video highlights from the game. We demonstrate that this approach can be used to select highlights specific for fans of each team, and that these clips reflect the emotions of a fan during a game. Further, we describe how these clips differ from those seen on nightly sportscasts.
2012	Of BATs and APEs: an interactive tabletop game for natural history museums	In this paper we describe visitor interaction with an interactive tabletop exhibit on evolution that we designed for use in natural history museums. We video recorded 30 families using the exhibit at the Harvard Museum of Natural History. We also observed an additional 50 social groups interacting with the exhibit without video recording. The goal of this research is to explore ways to develop "successful" interactive tabletop exhibits for museums. To determine criteria for success in this context, we borrow the concept of Active Prolonged Engagement (APE) from the science museum literature. Research on APE sets a high standard for visitor engagement and learning, and it offers a number of useful concepts and measures for research on interactive surfaces in the wild. In this paper we adapt and expand on these measures and apply them to our tabletop exhibit. Our results show that visitor groups collaborated effectively and engaged in focused, on-topic discussion for prolonged periods of time. To understand these results, we analyze visitor conversation at the exhibit. Our analysis suggests that social practices of game play contributed substantially to visitor collaboration and engagement with the exhibit.
2012	Adaptation as design: learning from an EMR deployment study	We conducted an observational study in an Emergency Department (ED) to examine the adaptation process after deploying an Electronic Medical Records (EMR) system. We investigated how EMR was adapted to the complex clinical work environment and how doctors and nurses engaged in the adaptation process. In this paper, we present three cases in which ED clinicians designed workarounds in order to adapt to the new work practice. Our findings reveal a rich picture of ED clinicians' active reinterpretation and modification of their work practice through their engagement with the system-in-use and its organizational and physical context. These findings call for the adaptation period in designing a socio-technical system in healthcare settings to be critically considered as an active end-user design process, a negotiating process, and a re-routinized process.
2012	Activity-based interaction: designing with child life specialists in a children's hospital	Child Life Specialists (CLS's) are medical professionals who use activities to educate, comfort, entertain and distract children in hospitals. Adapting to a shifting cast of children, context and mediating activities requires CLS's to be experts at a kind of articulation work. This expertise means CLS's are well equipped to help technologists introduce child-facing interventions to the hospital. We conducted participatory design activities with 9 CLS's to develop two mobile systems to explore how CLS-child interactions are shaped by activities. We observed 18 child-CLS pairs using these systems in a hospital setting. By analyzing these encounters, we describe a continuum for classifying activities as either Co-Present or Collaborative. We then introduce a framework, Activity-Based Interaction, to describe structural components of activities that impact their position on this continuum. These concepts suggest new approaches to designing mediating technologies for adults and children.
2012	The design space of opinion measurement interfaces: exploring recall support for rating and ranking	Rating interfaces are widely used on the Internet to elicit people's opinions. Little is known, however, about the effectiveness of these interfaces and their design space is relatively unexplored. We provide a taxonomy for the design space by identifying two axes: Measurement Scale for absolute rating vs. relative ranking, and Recall Support for the amount of information provided about previously recorded opinions. We present an exploration of the design space through iterative prototyping of three alternative interfaces and their evaluation. Among many findings, the study showed that users do take advantage of recall support in interfaces, preferring those that provide it. Moreover, we found that designing ranking systems is challenging; there may be a mismatch between a ranking interface that forces people to specify a total ordering for a set of items, and their mental model that some items are not directly comparable to each other.
2012	Assessing the vulnerability of magnetic gestural authentication to video-based shoulder surfing attacks	Secure user authentication on mobile phones is crucial, as they store highly sensitive information. Common approaches to authenticate a user on a mobile phone are based either on entering a PIN, a password, or drawing a pattern. However, these authentication methods are vulnerable to the shoulder surfing attack. The risk of this attack has increased since means for recording high-resolution videos are cheaply and widely accessible. If the attacker can videotape the authentication process, PINs, passwords, and patterns do not even provide the most basic level of security. In this project, we assessed the vulnerability of a magnetic gestural authentication method to the video-based shoulder surfing attack. We chose a scenario that is favourable to the attack-er. In a real world environment, we videotaped the interactions of four users performing magnetic signatures on a phone, in the presence of HD cameras from four different angles. We then recruited 22 participants and asked them to watch the videos and try to forge the signatures. The results revealed that with a certain threshold, i.e, th=1.67, none of the forging attacks was successful, whereas at this level all eligible login attempts were successfully recognized. The qualitative feedback also indicated that users found the magnetic gestural signature authentication method to be more secure than PIN-based and 2D signature methods.
2012	Playable character: extending digital games into the real world	This paper describes a series of research probe games developed to investigate how real-world activity could be incorporated into digital game systems. These culminated in the design of our final game, Forest, which was conceived for the San Francisco non-profit Friends of the Urban Forest (FUF), who have been planting and caring for the city's street trees for 30 years. By incorporating real-world actions and behaviors into digital games, we can create experiences that both enhance our understanding of the world around us and provide incentive structures towards our personal, community, or societal goals.
2012	Reducing compensatory motions in video games for stroke rehabilitation	Stroke is the leading cause of long-term disability among adults in industrialized nations; approximately 80% of people who survive a stroke experience motor disabilities. Recovery requires hundreds of daily repetitions of therapeutic exercises, often without therapist supervision. When performing therapy alone, people with limited motion often compensate for the lack of motion in one joint by moving another one. This compensation can impede the recovery progress and create new health problems. In this work we contribute (1) a methodology to reliably sense compensatory torso motion in the context of shoulder exercises done by persons with stroke and (2) the design and experimental evaluation of operant-conditioning-based strategies for games that aim to reduce compensatory torso motion. Our results show that these strategies significantly reduce compensatory motions compared to alternatives.
2012	Game design for promoting counterfactual thinking	We describe the first iteration of an Alternate Reality Game (ARG) designed to lead players into a newly enfranchised relationship with history and engage them in scientific thinking and information literacy practices. We found that the points at which the game's mythology blurred the lines between fact and fiction prompted middle school students to move beyond rote memorization of content. Instead, they began to question, analyze, and make hypotheses about the data presented. However, striking a meaningful balance between "true" history and imagined events poses new design challenges. We present a formative typology of counterfactual design patterns that can help designers, educators, and players locate interesting fault lines in reality that facilitate the expansion of ARG mythologies.
2012	Discovery-based games for learning software	We propose using discovery-based learning games to teach people how to use complex software. Specifically, we developed Jigsaw, a learning game that asks players to solve virtual jigsaw puzzles using tools in Adobe Photoshop. We conducted an eleven-person lab study of the prototype, and found the game to be an effective learning medium that can complement demonstration-based tutorials. Not only did the participants learn about new tools and techniques while actively solving the puzzles in Jigsaw, but they also recalled techniques that they had learned previously but had forgotten.
2012	Corporate career presences on social network sites: an analysis of hedonic and utilitarian value	Due to the shortage of skilled workforce and the increasing usage of social network sites, companies increasingly apply social network sites to attract potential applicants. This paper explores how corporate career presences on network sites should be realized in order to attract potential applicants. Therefore, we tested the impact of seven individual characteristics (namely Appointments, Daily Working Routine, Jobs, Corporate News, Entertainment, Media Format, and Features) of these corporate career presences that we extracted by a comprehensive pre-study on users' perceived hedonic and utilitarian value of these presences on social network sites. Based on an online survey with 470 participants, the results reveal a highly significant impact of five characteristics that corporate career presences provide both a hedonic as well as a utilitarian value to the user.
2012	Talking about implications for design in pattern language	In this paper we present our approach to capture and share knowledge from field studies using pattern language and thereby inform the design of ubiquitous computing. In our case, we studied frontline firefighting by observing the existing practice, by developing empathy through participation and by introducing new technology as triggering artifacts. Applying grounded theory, we distilled our findings into pattern language describing core aspects of this practice and their interaction. In a workshop, we introduced the pattern language to developers who had no previous knowledge of this practice and, in follow-up interviews, confronted them with new technology proposals for firefighters. Our study shows that pattern language, while not to be confused with an immutable description of the status quo or a direct path from contextual analysis to design, supports a reflective discussion of novel technology and the fit with and potential impact on existing practice.
2012	Designing a debugging interaction language for cognitive modelers: an initial case study in natural programming plus	In this paper, we investigate how a debugging environment should support a population doing work at the core of HCI research: cognitive modelers. In conducting this investigation, we extended the Natural Programming methodology (a user-centered design method for HCI researchers of programming environments), to add an explicit method for mapping the outcomes of NP's empirical investigations to a language design. This provided us with a concrete way to make the design leap from empirical assessment of users' needs to a language. The contributions of our work are therefore: (1) empirical evidence about the content and sequence of cognitive modelers' information needs when debugging, (2) a new, empirically derived, design specification for a debugging interaction language for cognitive modelers, and (3) an initial case study of our "Natural Programming Plus" methodology.
2012	Understanding agency in interaction design materials	We draw on the concept of agency in order to understand the process of how design materials 'talk back' to designers. In so doing, we illustrate the various levels at which agency can emerge in the context of intensive short-time prototyping sessions. In HCI, it is often assumed that the designer is the agent that acts intentionally in the design process. Contrary to this, recent notions of agency provide a way of analysing the performative role of design materials as intra-actions between components within a given phenomenon, rather than as meanings merely ascribed by actions of designers. The notion of agency puts focus on the emerging properties of materials and how they actively contribute to the way that design activity unfolds. The analyses showed how interaction design is to a large extent driven by emergent characteristics of available materials. The results have implications for understanding material interactions and materiality in interaction design.
2012	CogTool-Explorer: a model of goal-directed user exploration that considers information layout	CogTool-Explorer 1.2 (CTE1.2) predicts novice exploration behavior and how it varies with different user-interface (UI) layouts. CTE1.2 improves upon previous models of information foraging by adding a model of hierarchical visual search to guide foraging behavior. Built within CogTool so it is easy to represent UI layouts, run the model, and present results, CTE1.2's vision is to assess many design ideas at the storyboard stage before implementation and without the cost of running human participants. This paper evaluates CTE1.2 predictions against observed human behavior on 108 tasks (36 tasks on 3 distinct website layouts). CTE1.2's predictions accounted for 63-82% of the variance in the percentage of participants succeeding on each task, the number of clicks to success, and the percentage of participants succeeding without error. We demonstrate how these predictions can be used to identify areas of the UI in need of redesign.
2012	Finding and assessing social media information sources in the context of journalism	Social media is already a fixture for reporting for many journalists, especially around breaking news events where non-professionals may already be on the scene to share an eyewitness report, photo, or video of the event. At the same time, the huge amount of content posted in conjunction with such events serves as a challenge to finding interesting and trustworthy sources in the din of the stream. In this paper we develop and investigate new methods for filtering and assessing the verity of sources found through social media by journalists. We take a human centered design approach to developing a system, SRSR ("Seriously Rapid Source Review"), informed by journalistic practices and knowledge of information production in events. We then used the system, together with a realistic reporting scenario, to evaluate the filtering and visual cue features that we developed. Our evaluation offers insights into social media information sourcing practices and challenges, and highlights the role technology can play in the solution.
2012	Easing the generation of predictive human performance models from legacy systems	With the rise of tools for predictive human performance modeling in HCI comes a need to model legacy applications. Models of legacy systems are used to compare products to competitors, or new proposed design ideas to the existing version of an application. We present CogTool-Helper, an exemplar of a tool that results from joining this HCI need to research in automatic GUI testing from the Software Engineering testing community. CogTool-Helper uses automatic UI-model extraction and test case generation to automatically create CogTool storyboards and models and infer methods to accomplish tasks beyond what the UI designer has specified. A design walkthrough with experienced CogTool users reveal that CogTool-Helper resonates with a "pain point" of real-world modeling and provide suggestions for future work.
2012	Modeling task performance for a crowd of users from interaction histories	We present TOME, a novel framework that helps developers quantitatively evaluate user interfaces and design iterations by using histories from crowds of end users. TOME collects user-interaction histories via an interface instrumentation library as end users complete tasks; these histories are compiled using the Keystroke-Level Model (KLM) into task completion-time predictions using CogTool. With many histories, TOME can model prevailing strategies for tasks without needing an HCI specialist to describe users' interaction steps. An unimplemented design change can be evaluated by perturbing a TOME task model in CogTool to reflect the change, giving a new performance prediction. We found that predictions for quick (5-60s) query tasks in an instrumented brain-map interface averaged within 10% of measured expert times. Finally, we modified a TOME model to predict closely the speed-up yielded by a proposed interaction before implementing it.
2012	Understanding experts' and novices' expertise judgment of twitter users	Judging topical expertise of micro-blogger is one of the key challenges for information seekers when deciding which information sources to follow. However, it is unclear how useful different types of information are for people to make expertise judgments and to what extent their background knowledge influences their judgments. This study explored differences between experts and novices in inferring expertise of Twitter users. In three conditions, participants rated the level of expertise of users after seeing (1) only the tweets, (2) only the contextual information including short biographical and user list information, and (3) both tweets and contextual information. Results indicated that, in general, contextual information provides more useful information for making expertise judgment of Twitter users than tweets. While the addition of tweets seems to make little difference, or even add nuances to novices' expertise judgment, experts' judgments were improved when both content and contextual information were presented.
2012	Characterizing web use on smartphones	The current paper establishes empirical patterns associated with mobile internet use on smartphones and explores user differences in these behaviors. We apply a naturalistic and longitudinal logs-based approach to collect real usage data from 24 iPhone users in the wild. These data are used to describe smartphone usage and analyze revisitation patterns of web browsers, native applications, and physical locations where phones are used. Among our findings are that web page revisitation through browsers occurred very infrequently (approximately 25% of URLs are revisited by each user), bookmarks were used sparingly, physical traversing patterns mirrored virtual (internet) traversing patterns and users systematically differed in their web use. We characterize these differences and suggest ways to support users with enhanced design of smartphone technologies and content.
2012	Narratives of satisfying and unsatisfying experiences of current mobile augmented reality applications	Over the last few years, mobile applications demonstrating Augmented Reality (AR) - such as Layar, Junaio and Google Goggles - have been introduced to consumers. We conducted an online survey to explore the user experience (UX) of early stage mobile AR applications available in the market in spring 2011, covering both location-based AR browsers and image recognition AR applications for object-based interaction. We identify various types of experiences such applications have evoked by qualitatively analyzing 84 users' narratives of their most satisfying and unsatisfying experiences. The results highlight, for example, experiences of awareness of surroundings, empowerment, positive surprise, amazement and fascination from the novelty value, as well as some examples of immersion and social connectivity. The analysis indicates that the applications have not yet reached their potential in evoking a multifaceted user experience that is characteristic especially to AR. This work helps in understanding the experiential design potential in mobile AR and points out UX issues to further focus on in design.
2012	A longitudinal study of facebook, linkedin, & twitter use	We conducted four annual comprehensive surveys of social networking at Microsoft between 2008 and 2011. We are interested in how employees use these tools and whether they consider then useful for organizational communication and information-gathering. Our study is longitudinal and based on random sampling. Between 2008 and 2011, social networking went from being a niche activity to being very widely and heavily used. Growth in use and acceptance was not uniform, with differences based on gender, age and level (individual contributor vs. manager). Behaviors and concerns changed, with some showing signs of leveling off.
2012	Protecting artificial team-mates: more seems like less	Previous research on conversational, competitive, and cooperative systems suggests that people respond differently to humans and AI agents in terms of perception and evaluation of observed team-mate behavior. However, there has not been research examining the relationship between participants' protective behavior toward human/AI team-mates and their beliefs about their behavior. A study was conducted in which 32 participants played two sessions of a cooperative game, once with a "presumed" human and once with an AI team-mate; players could "draw fire" from a common enemy by "yelling" at it. Overwhelmingly, players claimed they "drew fire" on behalf of the presumed human more than for the AI team-mate; logged data indicates the opposite. The main contribution of this paper is to provide evidence of the mismatch in player beliefs about their actions and actual behavior with humans or agents and provides possible explanations for the differences.
2012	'Timid encounters': a case study in the use of proximity-based mobile technologies	We report a comparative ethnographic study of a proximity-based mobile 'video game' (Dragon Quest 9) in Japan: the Nintendo DS game terminals may 'recognize' one another and allow players to exchange game resources when they are close to one another. Because different communication infrastructures are available, situations of encounter are shown to be potentially seamful and to support multi-layered participation frames. Our observations show a variety of encounter formats, among whom 'timid' encounters are the most characteristic of the kind of sociality which may develop in urban public places turned into proximity-sensitive 'hybrid ecologies' The normative order which governs such encounters is marked by a tension between the minimality expected of encounters with strangers in urban spaces, and the concern for identification and focused interaction that derives from being engaged in proximal digital communication. These empirical observations and framework of analysis offer insights for the design and the understanding of proximity-based mobile technologies.
2012	Online gaming motivations scale: development and validation	Understanding gaming motivations is important given the growing trend of incorporating game-based mechanisms in non-gaming applications. In this paper, we describe the development and validation of an online gaming motivations scale based on a 3-factor model. Data from 2,071 US participants and 645 Hong Kong and Taiwan participants is used to provide a cross-cultural validation of the developed scale. Analysis of actual in-game behavioral metrics is also provided to demonstrate predictive validity of the scale.
2012	Breaking news on twitter	After the news of Osama Bin Laden's death leaked through Twitter, many people wondered if Twitter would fundamentally change the way we produce, spread, and consume news. In this paper we provide an in-depth analysis of how the news broke and spread on Twitter. We confirm the claim that Twitter broke the news first, and find evidence that Twitter had convinced a large number of its audience before mainstream media confirmed the news. We also discover that attention on Twitter was highly concentrated on a small number of "opinion leaders" and identify three groups of opinion leaders who played key roles in spreading the news: individuals affiliated with media played a large part in breaking the news, mass media brought the news to a wider audience and provided eager Twitter users with content on external sites, and celebrities helped to spread the news and stimulate conversation. Our findings suggest Twitter has great potential as a news medium.
2012	The twitter mute button: a web filtering challenge	The microblogging service Twitter has become an important, and sometimes primary, source of information for many users. As a forum for sharing news and discussing events, it can provide instant access to the latest updates, but this is not always welcome. In the case of television shows or live sporting events, for example, tweets about them may reveal spoilers to users in different time zones or who are delaying their viewing until later. More broadly, because Twitter is a broadcast medium, users may often want to temporarily or permanently hide content about a very specific given topic. In this paper, we describe the unique challenges to HCI, social computing, and computational linguistics posed by the task of building an interface that blocks all tweets about a specific event or topic. We illustrate some of the challenges through a pilot experiment run for three major television events: the 2009 NFC Championship football game, the 2010 mid-season finale of the show Glee, and the 2010 season premiere of the show 24. While simple techniques achieve very high recall (>98%), spoilers still make it through the filter and precision is extremely poor. We conclude with a description of challenges to the community in implementing this new and increasingly important feature.
2012	Exploring user motivations for eyes-free interaction on mobile devices	While there is increasing interest in creating eyes-free interaction technologies, a solid analysis of why users need or desire eyes-free interaction has yet to be presented. To gain a better understanding of such user motivations, we conducted an exploratory study with four focus groups, and suggest a classification of motivations for eyes-free interaction under four categories ( environmental, social, device features, and personal ). Exploring and analyzing these categories, we present early insights pointing to design implications for future eyes-free interactions.
2012	Look & touch: gaze-supported target acquisition	While eye tracking has a high potential for fast selection tasks, it is often regarded as error-prone and unnatural, especially for gaze-only interaction. To improve on that, we propose gaze-supported interaction as a more natural and effective way combining a user's gaze with touch input from a handheld device. In particular, we contribute a set of novel and practical gaze-supported selection techniques for distant displays. Designed according to the principle gaze suggests, touch confirms they include an enhanced gaze-directed cursor, local zoom lenses and more elaborated techniques utilizing manual fine positioning of the cursor via touch. In a comprehensive user study with 24 participants, we investigated the potential of these techniques for different target sizes and distances. All novel techniques outperformed a simple gaze-directed cursor and showed individual advantages. In particular those techniques using touch for fine cursor adjustments (MAGIC touch) and for cycling through a list of possible close-to-gaze targets (MAGIC tab) demonstrated a high overall performance and usability.
2012	Mouse tracking: measuring and predicting users' experience of web-based content	Previous studies have used mouse tracking as a tool to measure usability of webpages, user attention and search relevance. In this paper, we go beyond measurement of user behavior to prediction of the resulting user experience from mouse patterns alone. Specifically, we identify mouse markers that can predict user frustration and reading struggles at reasonably high accuracy. We believe that mouse-based prediction of user experience is an important advance, and could potentially offer a scalable way to infer user experience on the web. In addition, we demonstrate that mouse tracking could be used for applications such as evaluating content layout and content noticeability; we apply this in particular to advertisements. More generally, it could be used to infer user attention in complex webpages containing images, text and varied content, including how attention patterns vary with page layout and user distraction.
2012	Gaze-augmented think-aloud as an aid to learning	The use of recorded eye movements, or scanpaths, has been demonstrated as an effective visualization for feed-forward visual search training, instruction, and stimulated retrospective think-aloud usability testing. In this paper we show that creation of a scripted or recorded video of an expert's think-aloud session augmented by an animation of their scanpaths can result in an effective aid for learners of visual search. Because the creation of such a video is relatively easy, the benefits-to-cost ratio may potentially be substantial, especially in settings where learned visual scanning strategies are indicators of expertise. We suggest that two such examples are examinations of Chest X-Rays and histological slides. Results are presented where straightforward construction of an instruction video provides measurable benefit to novice as well as experienced learners in the latter context.
2012	Increasing the security of gaze-based cued-recall graphical passwords using saliency masks	With computers being used ever more ubiquitously in situations where privacy is important, secure user authentication is a central requirement. Gaze-based graphical passwords are a particularly promising means for shoulder-surfing-resistant authentication, but selecting secure passwords remains challenging. In this paper, we present a novel gaze-based authentication scheme that makes use of cued-recall graphical passwords on a single image. In order to increase password security, our approach uses a computational model of visual attention to mask those areas of the image that are most likely to attract visual attention. We create a realistic threat model for attacks that may occur in public settings, such as filming the user's interaction while drawing money from an ATM. Based on a 12-participant user study, we show that our approach is significantly more secure than a standard image-based authentication and gaze-based 4-digit PIN entry.
2012	You're capped: understanding the effects of bandwidth caps on broadband use in the home	Bandwidth caps, a limit on the amount of data users can upload and download in a month, are common globally for both home and mobile Internet access. With caps, each bit of data consumed comes at a cost against a monthly quota or a running tab. Yet, relatively little work has considered the implications of this usage-based pricing model on the user experience. In this paper, we present results from a qualitative study of households living with bandwidth caps. Our findings suggest home users grapple with three uncertainties regarding their bandwidth usage: invisible balances, mysterious processes , and multiple users . We discuss how these uncertainties impact their usage and describe the potential for better tools to help monitor and manage data caps. We conclude that as a community we need to cater for users under Internet cost constraints.
2012	An exploratory study of eye typing fundamentals: dwell time, text entry rate, errors, and workload	Although eye typing (typing on an on-screen keyboard via one's eyes as they are tracked by an eye tracker) has been studied for more than three decades now, we still know relatively little about it from the users' point of view. Standard metrics such as words per minute and keystrokes per character yield information only about the effectiveness of the technology and the interaction techniques developed for eye typing. We conducted an extensive study with almost five hours of eye typing per participant and report on extended qualitative and quantitative analysis of the relationship of dwell time, text entry rate, errors made, and workload experienced by the participants. The analysis method is comprehensive and stresses the need to consider different metrics in unison. The results highlight the importance of catering for individual differences and lead to suggestions for improvements in the interface.
2012	Age differences in exploratory learning from a health information website	An empirical study was conducted to investigate how older and younger users learned by performing exploratory search of health information using an interface that recommended relevant links based on browsing histories. While older and younger users gained both factual and structural knowledge about the health topics, significant age differences were observed. Our results showed that processing of recommended and regular Web links imposed distinct demands on cognitive abilities, which at least partially explained the observed age differences in the search process. The use of recommended links was positively associated with general knowledge, while the use of regular Web links was positively associated with processing capacity. Results also showed that the recommended links benefited both younger and older adults by broadening the exploration of information, which led to better learning. Implications on designs of health information interfaces that facilitate exploratory search and learning for different age groups were discussed.
2012	How do we find personal files?: the effect of OS, presentation & depth on file navigation	Folder navigation is the main way that computer users retrieve their personal files. However we know surprisingly little about navigation, particularly about how it is affected by the operating system used, the interface presentation and the folder structure. To investigate this, we asked 289 participants to retrieve 1,109 of their own active files. We analyzed the 4,948 resulting retrieval steps, i.e. moves through the hierarchical folder tree. Results show: (a) significant differences in overall retrieval time between PC and Mac that arise from different organizational strategies rather than interface design; (b) the default Windows presentation is suboptimal - if changed, retrieval time could be reduced substantially and (c) contrary to our expectations, folder depth did not affect step duration. We discuss possible reasons for these results and suggest directions for future research.
2012	Evaluating the benefits of real-time feedback in mobile augmented reality with hand-held devices	Augmented Reality (AR) has been proved useful to guide operational tasks in professional domains by reducing the shift of attention between instructions and physical objects. Modern smartphones make it possible to use such techniques in everyday tasks, but raise new challenges for the usability of AR in this context: small screen, occlusion, operation "through a lens". We address these problems by adding real-time feedback to the AR overlay. We conducted a controlled experiment comparing AR with and without feedback, and with standard textual and graphical instructions. Results show significant benefits for mobile AR with feedback and reveals some problems with the other techniques.
2012	Steampunk as design fiction	In this paper we look at the Steampunk movement and consider is relevance as a design strategy for HCI and interaction design. Based on a study of online practices of Steampunk, we consider how, as a design fiction, Steampunk provides an explicit model for how to physically realize an ideological and imagined world through design practice. We contend that the practices of DIY and appropriation that are evident in Steampunk design provide a useful set of design strategies and implications for HCI.
2012	Implicit imitation in social tagging: familiarity and semantic reconstruction	Social Tagging is a recent widespread phenomenon on the Web where people assign labels (tags) to Web resources. It has been hypothesized to support collaborative sensemaking. In this paper, we examine some of the cognitive mechanisms assumed to underlie sensemaking, namely social imitation. In line with the semantic imitation model of Fu et al., we assume that implicit processing can be understood as a semantic reconstruction of gist. Our model contrasts this process with a recall of tags from an explicit verbatim memory trace. We tested this model in an experimental study in which after the search task students had to generate tags themselves. We exposed their answers to a multinomial model derived from Fuzzy Trace Theory to obtain independent parameter estimates for the processes of explicit recall, semantic gist reconstruction and familiarity-based recall. A model that assumes all processes are at play explains the data well. Similar to results of our previous study, we find an influence of search intentions on the two processes. Our results have implications for interface and interaction design of social tagging systems, as well as for tag recommendation in these environments.
2012	Augmenting spatial skills with mobile devices	Mobile devices are increasingly providing novel ways for users to engage with the spaces around them. However, there are few systematic studies of enhancing spatial ability with mobile devices, and applications such as turn-by-turn navigation systems have even been associated with a decline in spatial skills. In this paper we present a study based on the 1971 Shepard-Metzler mental rotation test but performed on a mobile-phone handset and a tablet PC. Our study extends the original experiment with the incorporation of touch and tilt interaction techniques, in order to determine if these affect the use and acquisition of spatial skills. Results suggest that the task is performed faster, and with no significant difference in accuracy, when participants rely on mental abilities rather than interaction techniques to perform 3D rotations. We also find significant differences between tablet and phone handset platforms under interactive conditions. We conclude that applications on mobile devices could be designed to enhance rather than erode spatial skills, by supporting the use of imagination to align real and virtual content.
2012	The normal natural troubles of driving with GPS	In-car GPS based satellite navigation systems are now a common part of driving, providing turn-by-turn navigation instructions on smartphones, portable units or in-car dashboard navigation systems. This paper uses interactional analysis of video data from fifteen naturalistically recorded journeys with GPS to understand the navigational practices deployed by drivers and passengers. The paper documents five types of 'trouble' where GPS systems cause issues and confusion for drivers around: destinations, routes, maps & sensors, timing and relevance and legality. The paper argues that to design GPS systems better we need to move beyond the notion of a docile driver who follows GPS command blindly, to a better understanding of how drivers, passengers and GPS systems work together. We develop this in discussing how technology might better support 'instructed action'.
2012	Annotating BI visualization dashboards: needs & challenges	Annotations have been identified as an important aid in analysis record-keeping and recently data discovery. In this paper we discuss the use of annotations on visualization dashboards, with a special focus on business intelligence (BI) analysis. In-depth interviews with experts lead to new annotation needs for multi-chart visualization systems, on which we based the design of a dashboard prototype that supports data and context aware annotations. We focus particularly on novel annotation aspects, such as multi-target annotations, annotation transparency across charts and data dimension levels, as well as annotation properties such as lifetime and validity. Moreover, our prototype is built on a data layer shared among different data-sources and BI applications, allowing cross application annotations. We discuss challenges in supporting context aware annotations in dashboards and other visualizations, such as dealing with changing annotated data, and provide design solutions. Finally we report reactions and recommendations from a different set of expert users.
2012	Understanding the verbal language and structure of end-user descriptions of data visualizations	Tools exist for people to create visualizations with their data; however, they are often designed for programmers or they restrict less technical people to pre-defined templates. This can make creating novel, custom visualizations difficult for the average person. For example, existing tools typically do not support syntax or interaction techniques that are natural to end users. To explore how to support a more natural production of data visualizations by end users, we conducted an exploratory study to illuminate the structure and content of the language employed by end users when describing data visualizations. We present our findings from the study and discuss their design implications for future visualization languages and toolkits.
2012	Drawing the city: differing perceptions of the urban environment	In building location-based services, it is important to present information in ways that fit with how individuals view and navigate the city. We conducted an adaptation of the 1970s Mental Maps study by Stanley Milgram in order to better understand differences in people's views of the city based on their backgrounds and technology use. We correlated data from a demographic questionnaire with the map data from our participants to perform a first-of-its-kind statistical analysis on differences in hand-drawn city maps. We describe our study, findings, and design implications for location-based services.
2012	Characterizing local interests and local knowledge	When searching for destinations and activities, the interests and knowledge of locals and non-locals may vary. In this paper, we compare and contrast the search-related interests of these two groups, and when they share a common interest (in our case, for restaurants), we analyze the quality of the venues they intend to visit. We find differences in interests depending on local knowledge, and that locals generally select higher-quality venues than non-locals. These findings have implications for search and recommendation systems that can personalize results based on local knowledge and leverage that knowledge to benefit non-locals.
2012	Analysis within and between graphs: observed user strategies in immunobiology visualization	We present an analysis of two user strategies in interactive data analysis, based on an observational study of four researchers in the immunology domain. Screen captures, video records, interviews, and verbal protocols are used to analyze common procedures in this type of visual data analysis, as well as how these procedures differ among these users. Our findings present a case where skilled users can approach a similar problem with diverging analysis strategies. In the group we observed, strategies fell within two broad categories: within-graph analysis, in which a user generates a few graph layouts and interacts heavily within them, and between-graph analysis, in which a user generates a series of graphs and switches between them in sequence. Differences in strategies lead to distinct interaction patterns, and are likely to be best supported by different interface designs. We characterize these observed strategies and discuss their implications for scientific visualization design and evaluation.
2012	Choosing to interleave: human error and information access cost	People are prone to making more errors when multitasking. Thus in safety-critical environments, it is often considered safer to perform tasks sequentially. Here we explore how the cost of accessing information affects the way people choose to interleave. An empirical study based on a medical scenario was conducted. Participants had to program infusion pump devices using information from a prescription form. The physical and mental effort involved in accessing information was manipulated. This was achieved by varying the physical distance between the prescription form and the devices. We demonstrate that by increasing information access cost, individuals are less likely to omit a required task step. This is because they adopt a more memory-intensive strategy, which encourages interleaving at natural boundaries, i.e., after completing the programming of one of the pumps. Interleaving during programming can result in task steps being forgotten.
2012	I'd never get out of this !?$%# office: redesigning time management for the enterprise	In this paper, we propose to improve time management in the enterprise by providing users interactive visualizations of how they are spending their time. Through an interview study (n=21) in a multi-national corporation, we were able to determine the data available for visualizations and the value of a number of general visualizations of employees' calendar data. We develop implications for design in improving personal time management.
2012	Building the trail best traveled: effects of domain knowledge on web search trailblazing	Web users can help guide others through complex tasks in unfamiliar domains by creating ordered sequences of queries and Web pages, an activity we call trailblazing . The trails generated from this process can be surfaced by search engines to help users engaged in these tasks. However, if search engines are going to have people generate trails they need to understand whether there is value in using domain experts for trailblazing (or whether novices are sufficient). In this paper, we describe the findings of a user study of trailblazing in the medical domain, comparing domain novices and experts. We observed differences in how people in each of the groups blazed trails and the value of the trails they generated; experts were more efficient and generated better-quality trails. Although there has been significant research on contrasting novice and expert search behaviors, to our knowledge there is no work (at least in the search domain) on establishing whether artifacts created by domain experts (trails in our case) are more valuable than those created by novices. The answer to this question is important for system designers who want to learn whether investing in domain expertise is worthwhile.
2012	Do you see that I see?: effects of perceived visibility on awareness checking behavior	Informal interactions are a key element of group work, and many theoretical frameworks and systems have been developed to understand and support these conversations in distributed workgroups. In particular, systems used in several recent experiments provided information about others' current activities so that their availability for conversation could be assessed, and interruptions could be timed strategically. One issue with these experimental systems, though, is that many do not notify the observed party that these observations are taking place. There is reason to believe that such notification could be valuable to users, and that it could alter observers' behavior. Moreover, factors such as the perceived urgency of the interruption could affect willingness to violate social norms in gathering information. We report on an experiment assessing the impact of perceived visibility and task urgency on awareness checking behavior. Results suggest that people check more often when they believe their partners do not know they are checking, and more often when the task is time-constrained than when it is not.
2012	The search dashboard: how reflection and comparison impact search behavior	Most searchers do not know how to use Web search engines as effectively as possible. This is due, in part, to search engines not providing feedback about how search behavior can be improved. Because feedback is an essential part of learning, we created the Search Dashboard, which provides an interface for reflection on personal search behavior. The Dashboard aggregates and presents an individual's search history and provides comparisons with that of archetypal expert profiles. Via a five-week study of 90 Search Dash-board users, we find that users are able to change aspects of their behavior to be more in line with that of the presented expert searchers. We also find that reflection can be beneficial, even without comparison, by changing participants' views about their own search skills, what is possible with search, and what aspects of their behavior may influence search success. Our findings demonstrate a new way for search engines to help users modify their search behavior for positive outcomes.
2012	Becoming-sound: affect and assemblage in improvisational digital music making	The concepts of affect and assemblage proposed by thinkers such as Gilles Deleuze and Brian Massumi can help us to understand the interaction between users and artefacts in interactive systems, particularly in the context of computer-supported improvisation and creativity. In this paper I provide an introduction to affect and assemblage theory for HCI practitioners. I then use a case study of Viscotheque, an iOS-based interface for group musical collaboration, to demonstrate the application of affective analysis in making sense of improvisational group music making.
2012	Digging in the crates: an ethnographic study of DJS' work	An ethnographic study uncovers the work of nightclub DJs, which extends far beyond the act of mixing tracks to also encompass collecting music, preparing for performances, and promotion and networking. We reveal how DJs value vinyl and digital formats in different ways, acquire music through 'crate digging', prepare physical and digital crates of music before gigs, and how these underpin improvised selections during their performances. We document how DJs interact with promoters, venues, dancers and other DJs, revealing an etiquette that governs how they select and share music, and manage an ongoing tension between revealing and hiding metadata so as to maintain a competitive edge. We raise implications for technologies to support DJs, while also shedding light on previous studies of music consumption and sharing in other settings.
2012	Best faces forward: a large-scale study of people search in the enterprise	This paper presents Faces , an application built to enable effective people search in the enterprise. We take advantage of the popularity Faces has gained within a globally distributed enterprise to provide an extensive analysis of how and why people search is used within the organization. Our study is primarily based on an analysis of the Faces query log over a period of more than four months, with over a million queries and tens of thousands of users. The analysis results are presented across four dimensions: queries, users, clicks, and actions, and lay the foundation for further advancement and research on the topic.
2012	Clipoid: an augmentable short-distance wireless toolkit for 'accidentally smart home' environments	Unlike lab environments, the existing environment is not built for smart applications, but rather should be "upgraded" to support new technologies. The result of this process is called the "accidentally smart home". We developed Clipoid, an augmentable wireless technology toolkit for supporting the development of an "accidentally smart home" environment. We observed the real user context (static, moving) with Clipoid. We present a guideline for developing an augmentation toolkit, and identify human needs of close proximity physical interaction and multiple users-public platforms.
2012	Making gestural input from arm-worn inertial sensors more practical	Gestural input can greatly improve computing experiences away from the desktop, and has the potential to provide always-available access to computing. Specifically, accelerometers and gyroscopes worn on the arm (e.g., in a wristwatch) can sense arm gestures, enabling natural input in untethered scenarios. Two core components of any gesture recognition system are detecting when a gesture is occurring and classifying which gesture a person has performed. In previous work, accurate detection has required significant computation, and high-accuracy classification has come at the cost of training the system on a per-user basis. In this note, we present a gesture detection method whose computational complexity does not depend on the duration of the gesture, and describe a novel method for recognizing gestures with only a single example from a new user.
2012	User learning and performance with bezel menus	Touchscreen phones tend to require constant visual attention, thus not allowing eyes-free interaction. For users with visual impairment, or when occupied with another task that requires a user's visual attention, these phones can be difficult to use. Recently, marks initiating from the bezel , the physical touch-insensitive frame surrounding a touchscreen display, have been proposed as a method for eyes-free interaction. Due to the physical form factor of the mobile device, it is possible to access different parts of the bezel eyes-free. In this paper, we first studied the performance of different bezel menu layouts. Based on the results, we designed a bezel-based text entry application to gain insights into how bezel menus perform in a real-world application. From a longitudinal study, we found that the participants achieved 9.2 words per minute in situations requiring minimal visual attention to the screen. After only one hour of practice, the participants transitioned from novice to expert users. This shows that bezel menus can be adopted for realistic applications.
2012	Phone as a pixel: enabling ad-hoc, large-scale displays using mobile devices	We present Phone as a Pixel : a scalable, synchronization-free, platform-independent system for creating large, ad-hoc displays from a collection of smaller devices. In contrast to most tiled-display systems, the only requirement for participation is for devices to have an internet connection and a web browser. Thus, most smartphones, tablets, laptops and similar devices can be used. Phone as a Pixel uses a color-transition encoding scheme to identify and locate displays. This approach has several advantages: devices can be arbitrarily arranged (i.e., not in a grid) and infrastructure consists of a single conventional camera. Further, additional devices can join at any time without re-calibration. These are desirable properties to enable collective displays in contexts like sporting events, concerts and political rallies. In this paper we describe our system, show results from proof-of-concept setups, and quantify the performance of our approach on hundreds of displays.
2012	To switch or not to switch: understanding social influence in online choices	We designed and ran an experiment to measure social influence in online recommender systems, specifically how often people's choices are changed by others' recommendations when facing different levels of confirmation and conformity pressures. In our experiment participants were first asked to provide their preferences between pairs of items. They were then asked to make second choices about the same pairs with knowledge of others' preferences. Our results show that others people's opinions significantly sway people's own choices. The influence is stronger when people are required to make their second decision sometime later (22.4%) than immediately (14.1%). Moreover, people seem to be most likely to reverse their choices when facing a moderate, as opposed to large, number of opposing opinions. Finally, the time people spend making the first decision significantly predicts whether they will reverse their decisions later on, while demographics such as age and gender do not. These results have implications for consumer behavior research as well as online marketing strategies.
2012	iRotate: automatic screen rotation based on face orientation	We present iRotate, an approach to automatically rotate screens on mobile devices to match users' face orientation. Current approaches to automatic screen rotation are based on gravity and device orientation. Our survey of 513 users shows that 42% currently experience auto-rotation that leads to incorrect viewing orientation several times a week or more, and 24% find the problem to be very serious to extremely serious. iRotate augments gravity-based approach, and uses front cameras on mobile devices to detect users' faces and rotates screens accordingly. It requires no explicit user input and supports different user postures and device orientations. We have implemented a iRotate that works in real-time on iPhone and iPad, and we assess the accuracy and limitations of iRotate through a 20- participant feasibility study.
2012	Looking at you: fused gyro and face tracking for viewing large imagery on mobile devices	We present a touch-free interface for viewing large imagery on mobile devices. In particular, we focus on viewing paradigms for 360 degree panoramas, parallax image sequences, and long multi-perspective panoramas. We describe a sensor fusion methodology that combines face tracking using a front-facing camera with gyroscope data to produce a robust signal that defines the viewer's 3D position relative to the display. The gyroscopic data provides both low-latency feedback and allows extrapolation of the face position beyond the the field-of-view of the front-facing camera. We also demonstrate a hybrid position and rate control that uses the viewer's 3D position to drive exploration of very large image spaces. We report on the efficacy of the hybrid control vs. position only control through a user study.
2012	Asking the right person: supporting expertise selection in the enterprise	Expertise selection is the process of choosing an expert from a list of recommended people. This is an important and nuanced step in expertise location that has not received a great deal of attention. Through a lab-based, controlled investigation with 35 enterprise workers, we found that presenting additional information about each recommended person in a search result list led the participants to make quicker and better-informed selections. These results focus attention on a currently understudied aspect of expertise location--expertise selection--that could greatly improve the usefulness of supporting systems. We also asked participants to rate the type of information that might be most useful for expertise selection on a paper prototype containing 36 types of potentially helpful information. We identified sixteen types of this information that may be most useful for various expertise selection tasks.
2012	Determining the orientation of proximate mobile devices using their back facing camera	Proximate mobile devices that are aware of their orientation relative to one another can support novel and natural forms of interaction. In this paper, we present a method to determine the relative orientation of proximate mobile devices using only the backside camera. We implemented this method as a service called Orienteer, which provides mobile device with the orientation of other proximate mobile devices. We demonstrate that orientation information can be used to enable novel and natural interactions by developing two applications that allow the user to push content in the direction of another device to share it and point the device toward another to filter content based on the device's owner. An informal evaluation revealed that interactions built upon orientation information can be natural and compelling to users, but developers and designers need to carefully consider how orientation should be applied effectively.
2012	AccessRank: predicting what users will do next	We introduce AccessRank, an algorithm that predicts revisitations and reuse in many contexts, such as file accesses, website visits, window switches, and command lines. AccessRank uses many sources of input to generate its predictions, including recency, frequency, temporal clustering, and time of day. Simulations based on log records of real user interaction across a diverse range of applications show that AccessRank more accurately predicts upcoming accesses than other algorithms. The prediction lists generated by AccessRank are also shown to be more stable than other algorithms that have good predictive capability, which can be important for usability when items are presented in lists as users can rely on their spatial memory for target location. Finally, we present examples of how real world applications might use AccessRank.
2012	Effects of behavior monitoring and perceived system benefit in online recommender systems	Behavior monitoring is an important part of many recommender systems; however, its effects on users' perceptions of such systems are not well understood. We describe a 2x2 factorial experiment that manipulates a simulated recommender system's monitoring of user behavior ( monitoring : present vs. absent) and whom the system is perceived to benefit ( benefit : corporate vs. consumer). We find that attitudes toward being monitored are moderated by perceptions about system intentions. We propose an explanatory mechanism and highlight the value of understanding the subjective experience of interacting with recommender systems.
2012	TeleHuman: effects of 3d perspective on gaze and pose estimation with a life-size cylindrical telepresence pod	In this paper, we present TeleHuman, a cylindrical 3D display portal for life-size human telepresence. The TeleHuman 3D videoconferencing system supports 360 degree motion parallax as the viewer moves around the cylinder and optionally, stereoscopic 3D display of the remote person. We evaluated the effect of perspective cues on the conveyance of nonverbal cues in two experiments using a one-way telecommunication version of the system. The first experiment focused on how well the system preserves gaze and hand pointing cues. The second experiment evaluated how well the system conveys 3D body postural information. We compared 3 perspective conditions: a conventional 2D view, a 2D view with 360 degree motion parallax, and a stereoscopic view with 360 degree motion parallax. Results suggest the combined presence of motion parallax and stereoscopic cues significantly improved the accuracy with which participants were able to assess gaze and hand pointing cues, and to instruct others on 3D body poses. The inclusion of motion parallax and stereoscopic cues also led to significant increases in the sense of social presence and telepresence reported by participants.
2012	SphereAvatar: a situated display to represent a remote collaborator	An emerging form of telecollaboration utilizes situated or mobile displays at a physical destination to virtually represent remote visitors. An example is a personal telepresence robot, which acts as a physical proxy for a remote visitor, and uses cameras and microphones to capture its surroundings, which are transmitted back to the visitor. We propose the use of spherical displays to represent telepresent visitors at a destination. We suggest that the use of such 360 degree displays in a telepresence system has two key advantages: it is possible to understand the identity of the visitor from any viewpoint; and with suitable graphical representation, it is possible to tell where the visitor is looking from any viewpoint. In this paper, we investigate how to optimally represent a visitor as an avatar on a spherical display by evaluating how varying representations are able to accurately convey head gaze.
2012	On the use of virtual environments for the evaluation of location-based applications	User experience (UX) research on pervasive technologies faces considerable challenges regarding today's mobile context-sensitive applications: evaluative field studies lack control, whereas lab studies miss the interaction with a dynamic context. This dilemma has inspired researchers to use virtual environments (VEs) to acquire control while offering the user a rich contextual experience. Although promising, these studies are mainly concerned with usability and the technical realization of their setup. Furthermore, previous setups leave room for improvement regarding the user's immersive experience. This paper contributes to this line of research by presenting a UX case study on mobile advertising with a novel CAVE-smartphone interface. We conducted two experiments in which we evaluated the intrusiveness of a mobile location-based advertising app in a virtual supermarket. The results confirm our hypothesis that context-congruent ads lessen the experienced intrusiveness thereby demonstrating that our setup is capable of generating preliminary meaningful results with regards to UX. Furthermore, we share insights in conducting these studies.
2012	MUSTARD: a multi user see through AR display	We present MUSTARD, a multi-user dynamic random hole see-through display, capable of delivering viewer dependent information for objects behind a glass cabinet. Multiple viewers are allowed to observe both the physical object(s) being augmented and their location dependent annotations at the same time. The system consists of two liquid-crystal (LC) panels within which physical objects can be placed. The back LC panel serves as a dynamic mask while the front panel serves as the data. We first describe the principle of MUSTARD and then examine various functions that can be used to minimize crosstalk between multiple viewer positions. We compare different conflict management strategies using PSNR and the quality mean opinion score of HDR-VDP2. Finally, through a user-study we show that users can clearly identify images and objects even when the images are shown with strong conflicting regions; demonstrating that our system works even in the most extreme of circumstances.
2012	1 € filter: a simple speed-based low-pass filter for noisy input in interactive systems	The 1 € filter ("one Euro filter") is a simple algorithm to filter noisy signals for high precision and responsiveness. It uses a first order low-pass filter with an adaptive cutoff frequency: at low speeds, a low cutoff stabilizes the signal by reducing jitter, but as speed increases, the cutoff is increased to reduce lag. The algorithm is easy to implement, uses very few resources, and with two easily understood parameters, it is easy to tune. In a comparison with other filters, the 1 € filter has less lag using a reference amount of jitter reduction.
2012	Your opinion counts!: leveraging social comments for analyzing aesthetic perception of photographs.	This paper presents a novel method for estimating the main factors that influence aesthetic perception of photographs. This goal is achieved by automatically leveraging comments written by professional and knowledgeable photographers in specialized community websites. The statistical analysis of the resulting data shows the importance of multiple visual attributes in aesthetic perception, and their interaction effects with different photography categories. This technique can be applied in personalization and ranking of search results, and has the potential to reveal relevant factors in other domains.
2012	Trajectory-aware mobile search	Most location-aware mobile applications only make use of the user's current location, but there is an opportunity for them to infer the user's future locations. We present Trajectory-Aware Search (TAS), a mobile local search application that predicts the user's destination in real-time based on location data from the current trip and shows search results near the predicted location. TAS demonstrates the feasibility of destination prediction in an interactive mobile application. Our user study of TAS shows using predicted destinations to help select search results positively augments the local search experience.
2012	360° panoramic overviews for location-based services	We investigate 360° panoramas as overviews to support users in the task of locating objects in the surrounding environment. Panoramas are typically visualized as rectangular photographs, but this does not provide clear cues for physical directions in the environment. In this paper, we conduct a series of studies with three different shapes: Frontal, Top-Down and Bird's Eye ; the last two shapes are chosen because they provide a clearer representation of the spatial mapping between panorama and environment. Our results show that good readability of the panorama is most important and that a clear representation of the spatial mapping plays a secondary role. This paper is the first to provide understanding on how users exploit 360° panoramic over-views to locate objects in the surrounding environment and how different design factors can affect user performance.
2012	Beyond stereo: an exploration of unconventional binocular presentation for novel visual experience	Human stereo vision processes the two different images seen by the two eyes to generate depth sensation. While current stereoscopic display technologies look at how to faithfully simulate the stereo viewing experience, we took a look out of this scope, to explore how we may present binocular image pairs that differ in other ways to create novel visual experience. This paper presents several interesting techniques we explored, and discusses their potential applications according to an informal user study.
2012	Proton: multitouch gestures as regular expressions	Current multitouch frameworks require application developers to write recognition code for custom gestures; this code is split across multiple event-handling callbacks. As the number of custom gestures grows it becomes increasingly difficult to 1) know if new gestures will conflict with existing gestures, and 2) know how to extend existing code to reliably recognize the complete gesture set. Proton is a novel framework that addresses both of these problems. Using Proton, the application developer declaratively specifies each gesture as a regular expression over a stream of touch events. Proton statically analyzes the set of gestures to report conflicts, and it automatically creates gesture recognizers for the entire set. To simplify the creation of complex multitouch gestures, Proton introduces gesture tablature, a graphical notation that concisely describes the sequencing of multiple interleaved touch actions over time. Proton contributes a graphical editor for authoring tablatures and automatically compiles tablatures into regular expressions. We present the architecture and implementation of Proton, along with three proof-of-concept applications. These applications demonstrate the expressiveness of the framework and show how Proton simplifies gesture definition and conflict resolution.
2012	Social desirability bias and self-reports of motivation: a study of amazon mechanical turk in the US and India	In this study we extend research on online collaboration by examining motivation to do work on the crowdsoucing service Amazon Mechanical Turk (MTurk). We address a challenge to many existing studies of motivation in online contexts: they are based on survey self-reports, which are susceptible to effects such as social desirability bias. In addition we investigate a second challenge to the extant research on motivation in the context of MTurk: a failure to examine potential differences between MTurk workers (Turkers) from different parts of the world, especially those from the US and India, MTurk's two largest worker groups. Using a survey technique called the list experiment, we observe distinct profiles of motivation and patterns of social desirability effects among Turkers in the US and India. Among US Turkers, we find that social desirability encourages over-reporting of each of four motivating factors we examined. The over-reporting was particularly large in the case of money as a motivator. In contrast, among Turkers in India we find a more complex pattern of social desirability effects, with workers under-reporting "killing time" and "fun" as motivations, and drastically over-reporting "sense of purpose." We conclude by discussing these results and proposing implications for future research and design.
2012	Habit as an explanation of participation in an online peer-production community	User activities in peer-production communities have mainly been examined under the assumption that individuals are rational individuals who are always cognizant of what they are doing and why. We argue that not all use is the same; while some behaviors are governed by conscious motivations, others may be a habitual response that is developed out of routine. We take a more granular approach to explaining what people are doing in online communities and how motivations and habits explain their use of specific features. In the context of the peer-production community Everything2 we employ both server log data and self-report, finding that habit is a non-conscious-driven behavior that is more associated with less cognitively-demanding tasks than content production.
2012	Evaluating compliance-without-pressure techniques for increasing participation in online communities	Social psychology offers several theories of potential use for designing techniques to increase user contributions to online communities. Some of these techniques follow the "compliance without pressure" approach, where users are led to comply with a request without being subjected to any obvious external pressure. We evaluated two such techniques -- foot-in-the-door and low-ball -- in the context of Cyclopath, a geographic wiki. We found that while both techniques succeeded, low-ball elicited more work than foot-in-the-door. We discuss design and research implications of applying these (and other such techniques) in online communities.
2012	An evaluation of how small user interface changes can improve scientists' analytic strategies	Subtle changes in analysis system interfaces can be used purposely to alter users' analytic behaviors. In a controlled study subjects completed three analyses at one-week intervals using an analysis support system. Control subjects used one interface in all sessions. Test subjects used modified versions in the last two sessions: a first set of changes aimed at increasing subjects' use of the system and their consideration of alternative hypotheses; a second set of changes aimed at increasing the amount of evidence collected. Results show that in the second session test subjects used the interface 39% more and switched between hypotheses 19% more than in the first session. They then collected 26% more evidence in the third than in the second session. These increases differ significantly ( p
2012	Identifying usability issues via algorithmic detection of excessive visual search	Automated detection of excessive visual search (ES) experienced by a user during software use presents the potential for substantial improvement in the efficiency of supervised usability analysis. This paper presents an objective evaluation of several methods for the automated segmentation and classification of ES intervals from an eye movement recording, a technique that can be utilized to aid in the identification of usability problems during software usability testing. Techniques considered for automated segmentation of the eye movement recording into unique intervals include mouse/keyboard events and eye movement scanpaths. ES is identified by a number of eye movement metrics, including: fixation count, saccade amplitude, convex hull area, scanpath inflections, scanpath length, and scanpath duration. The ES intervals identified by each algorithm are compared to those produced by manual classification to verify the accuracy, precision, and performance of each algorithm. The results indicate that automated classification can be successfully employed to substantially reduce the amount of recorded data reviewed by HCI experts during usability testing, with relatively little loss in accuracy.
2012	Bootstrapping personal gesture shortcuts with the wisdom of the crowd and handwriting recognition	Personal user-defined gesture shortcuts have shown great potential for accessing the ever-growing amount of data and computing power on touchscreen mobile devices. However, their lack of scalability is a major challenge for their wide adoption. In this paper, we present Gesture Marks, a novel approach to touch-gesture interaction that allows a user to access applications and websites using gestures without having to define them first. It offers two distinctive solutions to address the problem of scalability. First, it leverages the "wisdom of the crowd", a continually evolving library of gesture shortcuts that are collected from the user population, to infer the meaning of gestures that a user never defined himself. Second, it combines an extensible template-based gesture recognizer with a specialized handwriting recognizer to even better address handwriting-based gestures, which are a common form of gesture shortcut. These approaches effectively bootstrap a user's personal gesture library, alleviating the need to define most gestures manually. Our work was motivated and validated via a series of user studies, and the findings from these studies add to the body of knowledge on gesture-based interaction.
2012	A quantitative explanation of governance in an online peer-production community	In this paper, we examine how user ratings of content produced for an online community are taken into account by administrators when they decide whether to delete content. Incorporating about 10 years of server data from the online peer-production community Everything2, we looked at how specific features of voting predicted deletion of posts. We found that not all types of voting are the same: negative voting of users was the strongest factor explaining deletion of a Write-up. Receiving a positive vote from a member with higher status decreases the chances of deletion, while receiving a positive vote from a user with neutral status has a very little effect on the deletion of content.
2012	Deploying monotrans widgets in the wild	In this paper, we report our experience deploying the MonoTrans Widgets system in a public setting. Our work follows a line of crowd-sourced monolingual translation systems, and it is the first attempt to deploy such a system "in the wild". The results are promising, but we also found out that simultaneously drawing from multiple crowds with different expertise and sizes poses unique problems in the design of such crowd-sourcing systems.
2012	Touché: enhancing touch interaction on humans, screens, liquids, and everyday objects	Touché proposes a novel Swept Frequency Capacitive Sensing technique that can not only detect a touch event, but also recognize complex configurations of the human hands and body. Such contextual information significantly enhances touch interaction in a broad range of applications, from conventional touchscreens to unique contexts and materials. For example, in our explorations we add touch and gesture sensitivity to the human body and liquids. We demonstrate the rich capabilities of Touché with five example setups from different application domains and conduct experimental studies that show gesture classification accuracies of 99% are achievable with our technology.
2012	Implanted user interfaces	We investigate implanted user interfaces that small devices provide when implanted underneath human skin. Such devices always stay with the user, making their implanted user interfaces available at all times . We discuss four core challenges of implanted user interfaces: how to sense input through the skin, how to produce output, how to communicate amongst one another and with external infrastructure, and how to remain powered. We investigate these four challenges in a technical evaluation where we surgically implant study devices into a specimen arm. We find that traditional interfaces do work through skin. We then demonstrate how to deploy a prototype device on participants, using artificial skin to simulate implantation. We close with a discussion of medical considerations of implanted user interfaces, risks and limitations, and project into the future.
2012	From death to final disposition: roles of technology in the post-mortem interval	In this paper, we describe collaborative processes and stakeholders involved in the period from when a person dies until they are laid to rest: the funeral, final disposition of the body, and (in some circumstances) victim identification. The rich mixture of technologies currently deployed during this brief period are categorized and critically analyzed. We then reflect on the implications of our findings, both for the design of technology that takes the end of life into account, and for the wider HCI community.
2012	Detecting error-related negativity for interaction design	This paper examines the ability to detect a characteristic brain potential called the Error-Related Negativity (ERN) using off-the-shelf headsets and explores its applicability to HCI. ERN is triggered when a user either makes a mistake or the application behaves differently from their expectation. We first show that ERN can be seen on signals captured by EEG headsets like Emotiv™ when doing a typical multiple choice reaction time (RT) task -- Flanker task. We then present a single-trial online ERN algorithm that works by pre-computing the coefficient matrix of a logistic regression classifier using some data from a multiple choice reaction time task and uses it to classify incoming signals of that task on a single trial of data. We apply it to an interactive selection task that involved users selecting an object under time pressure. Furthermore the study was conducted in a typical office environment with ambient noise. Our results show that online single trial ERN detection is possible using off-the-shelf headsets during tasks that are typical of interactive applications. We then design a Superflick experiment with an integrated module mimicking an ERN detector to evaluate the accuracy of detecting ERN in the context of assisting users in interactive tasks. Based on these results we discuss and present several HCI scenarios for use of ERN.
2012	Empathy, participatory design and people with dementia	We describe the development, application and evaluation of a design method tailored for working with people with mild to moderate dementia. Our experiences with the approach highlighted areas where designers and participants held radically different views. The tenet of our approach was that to overcome these differences we needed to create an empathic relationship between participants and designers. To achieve this we modified participatory design techniques to foster respectful engagement with participants in the development of a digital aid to facilitate "safe walking". The process begins with broad qualitative scoping and design work then moves to developing personally tailored, individual designs to further exploration of the experiential elements of the domain while reducing the need for the participants to engage in abstract thought. Reflection highlights a number of important areas that demand consideration when undertaking research in this area and, more generally, when performing design work with people with dementia.
2012	On saliency, affect and focused attention	We study how the visual catchiness (saliency) of relevant information impacts user engagement metrics such as focused attention and emotion (affect). Participants completed tasks in one of two conditions, where the task-relevant information either appeared salient or non-salient. Our analysis provides insights into relationships between saliency, focused attention, and affect. Participants reported more distraction in the non-salient condition, and non-salient information was slower to find than salient. Lack-of-saliency led to a negative impact on affect, while saliency maintained positive affect, suggesting its helpfulness. Participants reported that it was easier to focus in the salient condition, although there was no significant improvement in the focused attention scale rating. Finally, this study suggests user interest in the topic is a good predictor of focused attention, which in turn is a good predictor of positive affect. These results suggest that enhancing saliency of user-interested topics seems a good strategy for boosting user engagement.
2012	Semantic interaction for visual text analytics	Visual analytics emphasizes sensemaking of large, complex datasets through interactively exploring visualizations generated by statistical models. For example, dimensionality reduction methods use various similarity metrics to visualize textual document collections in a spatial metaphor, where similarities between documents are approximately represented through their relative spatial distances to each other in a 2D layout. This metaphor is designed to mimic analysts' mental models of the document collection and support their analytic processes, such as clustering similar documents together. However, in current methods, users must interact with such visualizations using controls external to the visual metaphor, such as sliders, menus, or text fields, to directly control underlying model parameters that they do not understand and that do not relate to their analytic process occurring within the visual metaphor. In this paper, we present the opportunity for a new design space for visual analytic interaction, called semantic interaction , which seeks to enable analysts to spatially interact with such models directly within the visual metaphor using interactions that derive from their analytic process, such as searching, highlighting, annotating, and repositioning documents. Further, we demonstrate how semantic interactions can be implemented using machine learning techniques in a visual analytic tool, called ForceSPIRE , for interactive analysis of textual data within a spatial visualization. Analysts can express their expert domain knowledge about the documents by simply moving them, which guides the underlying model to improve the overall layout, taking the user's feedback into account.
2012	EEG analysis of implicit human visual perception	Image Based Rendering (IBR) allows interactive scene exploration from images alone. However, despite considerable development in the area, one of the main obstacles to better quality and more realistic visualizations is the occurrence of visually disagreeable artifacts. In this paper we present a methodology to map out the perception of IBR-typical artifacts. This work presents an alternative to traditional image and video quality evaluation methods by using an EEG device to determine the implicit visual processes in the human brain. Our work demonstrates the distinct differences in the perception of different types of visual artifacts and the implications of these differences.
2012	Development and evaluation of interactive system for synchronizing electric taste and visual content	Electric taste is a characteristic taste produced when the tongue is electrically stimulated. We have proposed apparatuses to add electric taste to food and drink. An interactive system could be developed to synchronize video contents using the reversibility and instantaneity of electric taste. However, to do so, the presentation time must be determined based on the different latency for the perception of each sense. We measured the latencies for electric taste and visual stimuli as a basic evaluation for a content presentation system in which electric taste and visual content are synchronized.
2012	Next steps for value sensitive design	Questions of human values often arise in HCI research and practice. Such questions can be difficult to address well, and a principled approach can clarify issues of both theory and practice. One such approach is Value Sensitive Design (VSD), an established theory and method for addressing issues of values in a systematic and principled fashion in the design of information technology. In this essay, we suggest however that the theory and at times the presentation of VSD overclaims in a number of key respects, with the result of inhibiting its more widespread adoption and appropriation. We address these issues by suggesting four topics for next steps in the evolution of VSD: (1) tempering VSD's position on universal values; (2) contextualizing existing and future lists of values that are presented as heuristics for consideration; (3) strengthening the voice of the participants in publications describing VSD investigations; and (4) making clearer the voice of the researchers. We propose new or altered approaches for VSD that address these issues of theory, voice, and reportage.
2012	Interactive visualization for low literacy users: from lessons learnt to design	This paper aims to address the problems low literacy (LL) users face when searching for information online. The first part of this paper summarizes the problems that LL user's face, and establishes a set of design principles for interfaces suitable for LL users. This is followed by a description of how these design principles are mapped to a novel interface for interactive data retrieval. The interface was realized into a working system and evaluated against a traditional web interface for both high literacy (HL) and LL users. The suitability of the designs was analyzed using performance data, subjective feedback and an observational analysis. The findings from the study suggest that LL users perform better and prefer the proposed designs over a traditional web interface.
2012	Questionable concepts: critique as resource for designing with eighty somethings	This paper reports findings from a series of participatory design workshops with ten people over eighty years old. The focus of the workshops was new banking technologies for the older old. Participants were asked to discuss their current experiences of banking and given packs of concept cards which contained design sketches and brief outlines of concepts for new financial services. The designs on the cards were deliberately provocative and aimed to encourage criticism and debate. Participants wrote and drew on the cards and the workshops were recorded and transcribed. The participants were extremely critical of current banking practices and most of the new concepts we presented to them. Their questions and comments led to a number of insights and further iterations. The paper argues that critique is an essential resource for design, both in terms of identifying problems and iterating ideas.
2012	Improving literacy in developing countries using speech recognition-supported games on mobile devices	Learning to read in a second language is challenging, but highly rewarding. For low-income children in developing countries, this task can be significantly more challenging because of lack of access to high-quality schooling, but can potentially improve economic prospects at the same time. A synthesis of research findings suggests that practicing recalling and vocalizing words for expressing an intended meaning could improve word reading skills - including reading in a second language - more than silent recognition of what the given words mean. Unfortunately, many language learning software do not support this instructional approach, owing to the technical challenges of incorporating speech recognition support to check that the learner is vocalizing the correct word. In this paper, we present results from a usability test and two subsequent experiments that explore the use of two speech recognition-enabled mobile games to help rural children in India read words with understanding. Through a working speech recognition prototype, we discuss two major contributions of this work: first, we give empirical evidence that shows the extent to which productive training (i.e. vocalizing words) is superior to receptive vocabulary training, and discuss the use of scaffolding hints to ""unpack"" factors in the learner's linguistic knowledge that may impact reading. Second, we discuss what our results suggest for future research in HCI.
2012	A spatiotemporal visualization approach for the analysis of gameplay data	Contemporary video games are highly complex systems with many interacting variables. To make sure that a game provides a satisfying experience, a meaningful analysis of gameplay data is crucial, particularly because the quality of a game directly relates to the experience a user gains from playing it. Automatic instrumentation techniques are increasingly used to record data during playtests. However, the evaluation of the data requires strong analytical skills and experience. The visualization of such gameplay data is essentially an information visualization problem, where a large number of variables have to be displayed in a comprehensible way in order to be able to make global judgments. This paper presents a visualization tool to assist the analytical process. It visualizes the game space as a set of nodes which players visit over the course of a game and is also suitable to observe time-dependent information, such as player distribution. Our tool is not tailored to a specific type of genre. To show the flexibility of our approach we use two different kinds of games as case studies.
2012	Senior designers: empowering seniors to design enjoyable falls rehabilitation tools	Studies have shown that functional strength and balance exercises can reduce the risk of falling in older people if they are done on a regular basis. However, the repetitive nature of these exercises; as well as the use of instructional booklets and videos for rehabilitation may discourage seniors to exercise in the home, thereby rendering such an intervention ineffective. Our work proposed that the use of multimodal games -- co-designed with seniors -- could be a way of making falls rehabilitation more enjoyable; thereby improving adherence to home exercise programmes. In this paper, we first explain the process by which we identified barriers to the users' effective interaction with current home rehabilitation tools. We then go on to describe how we actively involved seniors in the initial design, and improvement of useful, enjoyable games for falls rehabilitation. Our findings suggest that seniors are an integral part of the design process and should be directly involved from the concept stages of the design of tools for their rehabilitation.
2012	Being in the thick of in-the-wild studies: the challenges and insights of researcher participation	We describe the insights and challenges offered by researcher participation in in-the-wild studies through the comparison of two prototype evaluations with varying levels of researcher participation. By reflecting on these studies we expose different facets of the researcher's role when interacting with participants in in-the-wild studies. We also demonstrate the value of researcher participation in contributing to the way a researcher understands participant responses: aiding rapport, promoting empathy and stimulating the researcher to reflect on their own assumptions.
2012	Rethinking statistical analysis methods for CHI	CHI researchers typically use a significance testing approach to statistical analysis when testing hypotheses during usability evaluations. However, the appropriateness of this approach is under increasing criticism, with statisticians, economists, and psychologists arguing against the use of routine interpretation of results using "canned" p values. Three problems with current practice - the fallacy of the transposed conditional, a neglect of power, and the reluctance to interpret the size of effects - can lead us to build weak theories based on vaguely specified hypothesis, resulting in empirical studies which produce results that are of limited practical or scientific use. Using publicly available data presented at CHI 2010 [19] as an example we address each of the three concerns and promote consideration of the magnitude and actual importance of effects , as opposed to statistical significance, as the new criteria for evaluating CHI research.
2012	The envisioning cards: a toolkit for catalyzing humanistic and technical imaginations	We introduce the Envisioning Cards - a versatile toolkit for attending to human values during design processes - and discuss their early use. Drawing on almost twenty years of work in value sensitive design, the Envisioning Cards are built upon a set of four envisioning criteria: stakeholders, time, values, and pervasiveness. Each card contains on one side a title and an evocative image related to the card theme; on the flip side, the card shows the envisioning criterion, elaborates on the theme, and provides a focused design activity. Reports from the field demonstrate use in a range of research and design activities including ideation, co-design, heuristic critique, and more.
2012	Interpretation and trust: designing model-driven visualizations for text analysis	Statistical topic models can help analysts discover patterns in large text corpora by identifying recurring sets of words and enabling exploration by topical concepts. However, understanding and validating the output of these models can itself be a challenging analysis task. In this paper, we offer two design considerations - interpretation and trust - for designing visualizations based on data-driven models. Interpretation refers to the facility with which an analyst makes inferences about the data through the lens of a model abstraction. Trust refers to the actual and perceived accuracy of an analyst's inferences. These considerations derive from our experiences developing the Stanford Dissertation Browser, a tool for exploring over 9,000 Ph.D. theses by topical similarity, and a subsequent review of existing literature. We contribute a novel similarity measure for text collections based on a notion of "word-borrowing" that arose from an iterative design process. Based on our experiences and a literature review, we distill a set of design recommendations and describe how they promote interpretable and trustworthy visual analysis tools.
2012	SpaceSense: representing geographical information to visually impaired people using spatial tactile feedback	Learning an environment can be challenging for people with visual impairments. Braille maps allow their users to understand the spatial relationship between a set of places. However, physical Braille maps are often costly, may not always cover an area of interest with sufficient detail, and might not present up-to-date information. We built a handheld system for representing geographical information called SpaceSense, which includes custom spatial tactile feedback hardware-multiple vibration motors attached to different locations on a mobile touch-screen device. It offers high-level information about the distance and direction towards a destination and bookmarked places through vibrotactile feedback to help the user maintain the spatial relationships between these points. SpaceSense also adapts a summarization technique for online user reviews of public and commercial venues. Our user study shows that participants could build and maintain the spatial relationships between places on a map more accurately with SpaceSense compared to a system without spatial tactile feedback. They pointed specifically to having spatial tactile feedback as the contributing factor in successfully building and maintaining their mental map.
2012	Guidelines are only half of the story: accessibility problems encountered by blind users on the web	This paper describes an empirical study of the problems encountered by 32 blind users on the Web. Task-based user evaluations were undertaken on 16 websites, yielding 1383 instances of user problems. The results showed that only 50.4% of the problems encountered by users were covered by Success Criteria in the Web Content Accessibility Guidelines 2.0 (WCAG 2.0). For user problems that were covered by WCAG 2.0, 16.7% of websites implemented techniques recommended in WCAG 2.0 but the techniques did not solve the problems. These results show that few developers are implementing the current version of WCAG, and even when the guidelines are implemented on websites there is little indication that people with disabilities will encounter fewer problems. The paper closes by discussing the implications of this study for future research and practice. In particular, it discusses the need to move away from a problem-based approach towards a design principle approach for web accessibility.
2012	The user as a sensor: navigating users with visual impairments in indoor spaces using tactile landmarks	Indoor navigation systems for users who are visually impaired typically rely upon expensive physical augmentation of the environment or expensive sensing equipment; consequently few systems have been implemented. We present an indoor navigation system called Navatar that allows for localization and navigation by exploiting the physical characteristics of indoor environments, taking advantage of the unique sensing abilities of users with visual impairments, and minimalistic sensing achievable with low cost accelerometers available in smartphones. Particle filters are used to estimate the user's location based on the accelerometer data as well as the user confirming the presence of anticipated tactile landmarks along the provided path. Navatar has a high possibility of large-scale deployment, as it only requires an annotated virtual representation of an indoor environment. A user study with six blind users determines the accuracy of the approach, collects qualitative experiences and identifies areas for improvement.
2012	Interactivity as self-expression: a field experiment with customization and blogging	A paradigmatic quality of interactive interfaces is that they allow users to express themselves, thereby converting message receivers into communication sources. We define this quality as Source Interactivity [26, 29], and test its effects on user experience with a field experiment (N=141) of a portal site featuring cosmetic customization, functional customization and blogging (active versus filter). In demonstrating the psychological influence of source-based interactivity on such outcomes as user engagement, sense of agency, sense of community, intrinsic motivation and attitudes toward the interface, we discuss how designers can use them for creating interactive tools for self-expression.
2012	JigsawMap: connecting the past to the future by mapping historical textual cadasters	In this paper, we present an interactive visualization tool, JigsawMap, for visualizing and mapping historical textual cadasters. A cadaster is an official register that records land properties (e.g., location, ownership, value and size) for land valuation and taxation. Such mapping of old and new cadasters can help historians understand the social/economic background of changes in land uses or ownership. With JigsawMap, historians can continue mapping older or newer cadasters. In this way, JigsawMap can connect the past land survey results to today and to the future. We conducted usability studies and long term case studies to evaluate JigsawMap, and received positive responses. As well as summarizing the evaluation results, we also present design guidelines for participatory design projects with historians.
2012	CrossingGuard: exploring information content in navigation aids for visually impaired pedestrians	Visually impaired pedestrians experience unique challenges when navigating an urban environment because many cues about orientation and traffic patterns are difficult to ascertain without the use of vision. Technological aids such as customized GPS navigation tools offer the chance to augment visually impaired pedestrians' sensory information with a richer depiction of an environment, but care must be taken to balance the need for more information with other demands on the senses. In this paper, we focus on the information needs of visually impaired pedestrians at intersections, which present a specific cause of stress when navigating in unfamiliar locations. We present a navigation application prototype called CrossingGuard that provides rich information to a user such as details about intersection geometry that are not available to visually impaired pedestrians today. A user study comparing content-rich information to a baseline condition shows that content-rich information raises the level of comfort that visually impaired pedestrians feel at unfamiliar intersections. In addition, we discuss the categories of information that are most useful. Finally, we introduce a micro-task approach to gather intersection data via Street View annotations that achieves 85.5% accuracy over the 9 categories of information used by CrossingGuard.
2012	V-model: a new innovative model to chronologically visualize narrative clinical texts	Visualizing narrative medical events into a timeline can have positive effects on clinical environments. However, the characteristics of natural language and medical environments make this representation more difficult. This paper explains the obstacles and suggests a solution called the V-Model. The V-Model is a new innovative time model that was developed to represent chronological narrative events in a medical domain. Forty medical students participated in evaluating this model. The experimental results show the new model successfully solved the modeling requirements and had better usability compared to conventional timeline models. All the participants assessed the new timeline as very useful in effectively understanding a patient's history.
2012	The implications of offering more disclosure choices for social location sharing	We compared two privacy configuration styles for specifying rules for social sharing one's past locations. Our findings suggest that location-sharing applications (LSAs) which support varying levels of location granularities are associated with sharing rules that are less convoluted, are less likely to be negatively phrased, and can lead to more open sharing; users are also more comfortable with these rules. These findings can help inform LSA privacy designs.
2012	Sustainably unpersuaded: how persuasion narrows our vision of sustainability	In this paper we provide a critical analysis of persuasive sustainability research from 2009-2011. Drawing on critical sociological theory of modernism, we argue that persuasion is based on a limited framing of sustainability, human behavior, and their interrelationship. This makes supporting sustainability easier, but leads to characteristic patterns of breakdown. We then detail problems that emerge from this narrowing of vision, such as how the framing of sustainability as the optimization of a simple metrics places technologies incorrectly as objective arbiters over complex issues of sustainability. We conclude by suggesting alternative approaches to move beyond these problems.
2012	Undesigning technology: considering the negation of design by design	Motivated by substantive concerns with the limitations and negative effects of technology, this paper inquires into the negation of technology as an explicit and intentional aspect of design research within HCI. Building on theory from areas including philosophy and design theory, this paper articulates a theoretical framework for conceptualizing the intentional negation of technology (i.e., the undesign of technology), ranging from the inhibition of particular uses of technology to the total erasure or foreclosure of technology. The framework is then expanded upon to articulate additional areas of undesigning, including self-inhibition, exclusion, removal, replacement, restoration, and safeguarding. In conclusion a scheme is offered for addressing questions concerning the disciplinary scope of undesign in the context of HCI, along with suggestions for ways that undesigning may be more strongly incorporated within HCI research.
2012	Touch me once and i know it's you!: implicit authentication based on touch screen patterns	Password patterns, as used on current Android phones, and other shape-based authentication schemes are highly usable and memorable. In terms of security, they are rather weak since the shapes are easy to steal and reproduce. In this work, we introduce an implicit authentication approach that enhances password patterns with an additional security layer, transparent to the user. In short, users are not only authenticated by the shape they input but also by the way they perform the input. We conducted two consecutive studies, a lab and a long-term study, using Android applications to collect and log data from user input on a touch screen of standard commercial smartphones. Analyses using dynamic time warping (DTW) provided first proof that it is actually possible to distinguish different users and use this information to increase security of the input while keeping the convenience for the user high.
2012	Interaction proxemics and image use in neurosurgery	Within medical settings there is a growing interest in exploring touchless interaction technologies. The primary motivation here is to avoid contact during interaction with data so as to maintain asepsis. However, there is another important property of touchless interaction that has significant implications for their use within such settings -- namely that interaction behaviour is spatially distal from the device being interacted with. To further understand these implications we present fieldwork observations of work practice in neurosurgery theatres. Drawing on the notion of interaction proxemics and the theory of F-formations, our analysis articulates the spatial organization of collaborative work practices and interaction in these settings. From this understanding of spatial practices, we discuss opportunities and difficulties relating to the design of touchless interaction technologies for in surgical settings.
2012	What should we expect from research through design?	In this essay, I explore several facets of research through design in order to contribute to discussions about how the approach should develop. The essay has three parts. In the first, I review two influential theories from the Philosophy of Science to help reflect on the nature of design theory, concluding that research through design is likely to produce theories that are provisional, contingent, and aspirational. In the second part, I discuss three possible interpretations for the diversity of approaches to research through design, and suggest that this variation need not be seen as a sign of inadequate standards or a lack of cumulative progress in the field, but may be natural for a generative endeavour. In the final section, I suggest that, rather than aiming to develop increasingly comprehensive theories of design, practice based research might better view theory as annotation of realised design examples, and particularly portfolios of related pieces. Overall, I suggest that the design research community should be wary of impulses towards convergence and standardisation, and instead take pride in its aptitude for exploring and speculating, particularising and diversifying, and - especially - its ability to manifest the results in the form of new, conceptually rich artefacts.
2012	Biometric-rich gestures: a novel approach to authentication on multi-touch devices	In this paper, we present a novel multi-touch gesture-based authentication technique. We take advantage of the multi-touch surface to combine biometric techniques with gestural input. We defined a comprehensive set of five-finger touch gestures, based upon classifying movement characteristics of the center of the palm and fingertips, and tested them in a user study combining biometric data collection with usability questions. Using pattern recognition techniques, we built a classifier to recognize unique biometric gesture characteristics of an individual. We achieved a 90% accuracy rate with single gestures, and saw significant improvement when multiple gestures were performed in sequence. We found user ratings of a gestures desirable characteristics (ease, pleasure, excitement) correlated with a gestures actual biometric recognition rate - that is to say, user ratings aligned well with gestural security, in contrast to typical text-based passwords. Based on these results, we conclude that multi-touch gestures show great promise as an authentication mechanism.
2012	Affordances in HCI: toward a mediated action perspective	Interpretations of the concept of "affordances" in HCI are becoming increasingly diverse, extending well beyond the original Gibsonian meaning. We discuss some of the key analyses of affordances in HCI research and make three related claims. First, we argue that many current interpretations of the concept are essentially incompatible with Gibson. Second, we hold that the Gibsonian concept of affordances, conceptualized as interaction between animals and their environments, provides some important insights, but is, in the end, of limited relevance to HCI research. Third, we call for adopting a mediated action perspective on affordances as an alternative to Gibson's ecological psychology. We outline a view of technology affordances as possibilities for human action mediated by cultural means conceived as a relational property of a three-way interaction between the person, mediational means, and environment. We conclude with a discussion of prospects for future conceptual and empirical explorations of the meditational perspective in HCI research.
2012	Supporting visual assessment of food and nutrient intake in a clinical care setting	Monitoring nutritional intake is an important aspect of the care of older people, particularly for those at risk of malnutrition. Current practice for monitoring food intake relies on hand written food charts that have several inadequacies. We describe the design and validation of a tool for computer-assisted visual assessment of patient food and nutrient intake. To estimate food consumption, the application compares the pixels the user rubbed out against predefined graphical masks. Weight of food consumed is calculated as a percentage of pixels rubbed out against pixels in the mask. Results suggest that the application may be a useful tool for the conservative assessment of nutritional intake in hospitals.
2012	Tackling dilemmas in supporting 'the whole person' in online patient communities	Online health communities that engage the patient as a whole person attend to personal and medical needs in a holistic manner. Whether current communities structure interaction between health professionals and patients to address the whole person is an open question. To gain insights into this question, we examined a sample of online patient communities to understand health professionals' involvement in bringing in medical advice into peer-patient conversations. We found the communities fall short in supporting the whole person, because (1) patient expertise and clinical expertise generated by health professionals are shared separately, and (2) patients' quantified data are separate from narrative experiences. Such separation in the design of these systems can lead to limitations in addressing patients' interwoven medical and personal concerns. We discuss dilemmas and design implications for supporting the whole person in online patient communities.
2012	The mismeasurement of privacy: using contextual integrity to reconsider privacy in HCI	Privacy is a widely studied concept in relation to social computing and sensor-based technologies; scores of research papers have investigated people's "privacy preferences" and apparent reluctance to share personal data. In this paper we explore how Ubicomp and HCI studies have approached the notion of privacy, often as a quantifiable concept. Leaning on several theoretical frameworks, but in particular Nissenbaum's notion of contextual integrity, we question the viability of obtaining universal answers in terms of people's "general" privacy practices and apply elements of Nissenbaum's theory to our own data in order to illustrate its relevance. We then suggest restructuring inquiries into information sharing in studies of state-of-the-art technologies and analyze contextually grounded issues using a different, more specific vocabulary. Finally, we provide the first building blocks to such vocabulary.
2012	Tag, you can see it!: using tags for access control in photo sharing	Users often have rich and complex photo-sharing preferences, but properly configuring access control can be difficult and time-consuming. In an 18-participant laboratory study, we explore whether the keywords and captions with which users tag their photos can be used to help users more intuitively create and maintain access-control policies. We find that (a) tags created for organizational purposes can be repurposed to create efficient and reasonably accurate access-control rules; (b) users tagging with access control in mind develop coherent strategies that lead to significantly more accurate rules than those associated with organizational tags alone; and (c) participants can understand and actively engage with the concept of tag-based access control.
2012	Investigating the presence, form and behavior of virtual possessions in the context of a teen bedroom	Over the past several years, people have acquired more and more virtual possessions. While virtual possessions have become ubiquitous, little work exists to inform designers on how these growing collections should be displayed and how they should behave. We generated four design concepts that changed the form and behavior of these digital things, making them more present within a teen bedroom. We then conducted speed dating sessions to investigate how these new forms and behaviors influence perceptions of value. Sessions revealed how new technologies might better support self-exploration and reflection, as well as how they could complicate identity construction processes. Findings are interpreted to detail opportunities and tensions that can guide future research and practice in this emerging space.
2012	Chained displays: configurations of public displays can be used to influence actor-, audience-, and passer-by behavior	Most interactive public displays currently rely on flat screens. This form factor impacts how users (1) notice the public display (2) develop motivation and (3) (socially) interact with the public display. In this paper, we present Chained Displays , a combination of several screens to create different form factors for interactive public displays. We also present a design space based on two complementary concepts, Focus and Nimbus , to describe and compare chained display configurations. Finally, we performed a field study comparing three chained displays: Flat, Concave , and Hexagonal . Results show that Flat triggers the strongest honeypot effect, Hexagonal causes low social learning, and Concave triggers the smallest amount of simultaneously interacting users among other findings.
2012	Urban HCI: spatial aspects in the design of shared encounters for media facades	Designing interactive applications for Media Facades is a challenging task. Architectural sized largescale screens can result in unbalanced installations, and meaningful interaction is easily overshadowed by the drastic size of the display. In this paper we reflect on urban technology interventions by analyzing their spatial configuration in relation to the structuring of interaction. We outline basic categories and offer a new terminology to describe these interactive situations designed for the built environment.
2012	Technology heirlooms?: considerations for passing down and inheriting digital materials	Material artifacts are passed down as a way of sustaining relationships and family history. However, new issues are emerging as families are increasingly left with the digital remains of their loved ones. We designed three devices to investigate how digital materials might be passed down, lived with and inherited in the future. We conducted in-home interviews with 8 families using the devices to provoke discussion about how technology might support (or complicate) their existing practices. Sessions revealed families desired to treat their archives in ways not fully supported by technology as well as potential tensions that could emerge. Findings are interpreted to detail design considerations for future work in this emerging space.
2012	Digitality and materiality of new media: online TV watching in china	This paper examines issues of digitality and materiality of new media, grounded in a study of online TV watching in China. Particularly, by looking at how people make choices and decisions regarding TV watching in everyday life, we highlight material and digital properties of new media TV, and how they support and condition actions and interactions around them. The study illustrates that materiality and digitality are complementary, instead of one substituting the other, and are highly intertwined in the hybrid media environment around which meaningful experiences are conditioned and produced. It also suggests that an analytic distinction between materiality and digitality is fruitful in unpacking the complex relations between media technologies and social experiences.
2012	Writing the experience of information retrieval: digital collection design as a form of dialogue	In the context of digital libraries and other online resource collections, the substance of interaction is generated to a large degree through the selection, description, organization, and arrangement of the aggregated items. Within information studies, researchers [such as 32, 6] have shown how individual events of selection and description inevitably form judgments about the collected materials. This paper describes a process in which designers purposefully use the elements of selection, description, organization, and arrangement to "write" a resource collection as a form of rhetorical expression. The design process was implemented in two classroom settings. In the more successful second implementation, the role of the audience in structuring a rhetorical interaction was emphasized, and collection design was conceptualized as designing a dialogue between author and audience. The formalized critique of existing collection designs was a key element in enabling this dialogic orientation.
2012	Curation, provocation, and digital identity: risks and motivations for sharing provocative images online	Among the billions of photos that have been contributed to online photo-sharing sites, there are many that are provocative, controversial, and deeply personal. Previous research has examined motivations for sharing images online and has identified several key motivations for doing so: expression, curation of identity, maintaining social connections, and recording experiences. However, few studies have focused on the perceived risks of posting photos online and even fewer have examined the risks associated with provocative, controversial, or deeply personal images. In our work, we used photo-elicitation interviews to explore the motivations for posting these types of images and the perceived risks of doing so. In this paper, we describe our findings from those interviews.
2012	Social annotations in web search	We ask how to best present social annotations on search results, and attempt to find an answer through mixed-method eye-tracking and interview experiments. Current practice is anchored on the assumption that faces and names draw attention; the same presentation format is used independently of the social connection strength and the search query topic. The key findings of our experiments indicate room for improvement. First, only certain social contacts are useful sources of information, depending on the search topic. Second, faces lose their well-documented power to draw attention when rendered small as part of a social search result annotation. Third, and perhaps most surprisingly, social annotations go largely unnoticed by users in general due to selective, structured visual parsing behaviors specific to search result pages. We conclude by recommending improvements to the design and content of social annotations to make them more noticeable and useful.
2012	Omnipedia: bridging the wikipedia language gap	We present Omnipedia, a system that allows Wikipedia readers to gain insight from up to 25 language editions of Wikipedia simultaneously. Omnipedia highlights the similarities and differences that exist among Wikipedia language editions, and makes salient information that is unique to each language as well as that which is shared more widely. We detail solutions to numerous front-end and algorithmic challenges inherent to providing users with a multilingual Wikipedia experience. These include visualizing content in a language-neutral way and aligning data in the face of diverse information organization strategies. We present a study of Omnipedia that characterizes how people interact with information using a multilingual lens. We found that users actively sought information exclusive to unfamiliar language editions and strategically compared how language editions defined concepts. Finally, we briefly discuss how Omnipedia generalizes to other domains facing language barriers.
2012	Comparing averages in time series data	Visualizations often seek to aid viewers in assessing the big picture in the data, that is, to make judgments about aggregate properties of the data. In this paper, we present an empirical study of a representative aggregate judgment task: finding regions of maximum average in a series. We show how a theory of perceptual averaging suggests a visual design other than the typically-used line graph. We describe an experiment that assesses participants' ability to estimate averages and make judgments based on these averages. The experiment confirms that this color encoding significantly outperforms the standard practice. The experiment also provides evidence for a perceptual averaging theory.
2012	Color naming models for color selection, image editing and palette design	Our ability to reliably name colors provides a link between visual perception and symbolic cognition. In this paper, we investigate how a statistical model of color naming can enable user interfaces to meaningfully mimic this link and support novel interactions. We present a method for constructing a probabilistic model of color naming from a large, unconstrained set of human color name judgments. We describe how the model can be used to map between colors and names and define metrics for color saliency (how reliably a color is named) and color name distance (the similarity between colors based on naming patterns). We then present a series of applications that demonstrate how color naming models can enhance graphical interfaces: a color dictionary & thesaurus, name-based pixel selection methods for image editing, and evaluation aids for color palette design.
2012	WebTicket: account management using printable tokens	Passwords are the most common authentication scheme today. However, it is difficult for people to memorize strong passwords, such as random sequences of characters. Additionally, passwords do not provide protection against phishing attacks. This paper introduces WebTicket, a low cost, easy-to-use and reliable web account management system that uses "tickets", which are tokens that contain a two-dimensional barcode that can be printed or stored on smartphones. Users can log into accounts by presenting the barcodes to webcams connected to computers. Through two lab studies and one field study consisting of 59 participants in total, we found that WebTicket can provide reliable authentication and phishing resilience.
2012	Delta: a tool for representing and comparing workflows	Tutorials and sample workflows for complicated, feature-rich software packages are widely available online. As a result users must differentiate between workflows to choose the most suitable one for their task. We present Delta , an interactive workflow visualization and comparison tool that helps users identify the tradeoffs between workflows. We conducted an initial study to identify the set of attributes users attend to when comparing workflows, finding that they consider result quality, their knowledge of commands, and the efficiency of the workflow. We then designed Delta to surface these attributes at three granularities: a high-level, clustered view; an intermediate-level list view that contains workflow summaries; and a low-level detail view that allows users to compare two individual workflows. Finally, we conducted an evaluation of Delta on a small corpus of 30 workflows and found that the intermediate list view provided the best information density. We conclude with thoughts on how such a workflow comparison system could be scaled up to larger corpora in the future.
2012	The untapped promise of digital mind maps	Digital mind mapping tools present a fertile area for research on human-computer interaction. We evaluated numerous existing mind mapping software applications, performed ethnographic research with a variety of users, and developed a framework of principles to inform the design of future tools for collaborative knowledge management. Our findings suggest an opportunity to advance digital mind mapping beyond the existing state-of-the-art, particularly in the areas of improving workflow, facilitating collaboration, and supporting information storage and retrieval. We conclude with suggestions for how to improve digital mind mapping systems, specifically with regard to real-time collaborative thinking.
2012	Talking in circles: selective sharing in google+	Online social networks have become indispensable tools for information sharing, but existing 'all-or-nothing' models for sharing have made it difficult for users to target information to specific parts of their networks. In this paper, we study Google+, which enables users to selectively share content with specific 'Circles' of people. Through a combination of log analysis with surveys and interviews, we investigate how active users organize and select audiences for shared content. We find that these users frequently engaged in selective sharing, creating circles to manage content across particular life facets, ties of varying strength, and interest-based groups. Motivations to share spanned personal and informational reasons, and users frequently weighed ''limiting' factors (e.g. privacy, relevance, and social norms) against the desire to reach a large audience. Our work identifies implications for the design of selective sharing mechanisms in social networks.
2012	QuickDraw: improving drawing experience for geometric diagrams	We present QuickDraw, a prototype sketch-based drawing tool, that facilitates drawing of precise geometry diagrams that are often drawn by students and academics in several scientific disciplines. Quickdraw can recognize sketched diagrams containing components such as line segments and circles, infer geometric constraints relating recognized components, and use this information to beautify the sketched diagram. Beautification is based on a novel algorithm that iteratively computes various sub-components of the components using an extensible set of deductive rules. We conducted a user study comparing QuickDraw with four state-of-the-art diagramming tools: Microsoft PowerPoint, Cabri II Plus, Geometry Expressions and Geometer's SketchPad. Our study demonstrates a strong interest among participants for the use of sketch-based software for drawing geometric diagrams. We also found that QuickDraw enables users to draw precise diagrams faster than the majority of existing tools in some cases, while having them make fewer corrections.
2012	Pay attention!: designing adaptive agents that monitor and improve user engagement	Embodied agents hold great promise as educational assistants, exercise coaches, and team members in collaborative work. These roles require agents to closely monitor the behavioral, emotional, and mental states of their users and provide appropriate, effective responses. Educational agents, for example, will have to monitor student attention and seek to improve it when student engagement decreases. In this paper, we draw on techniques from brain-computer interfaces (BCI) and knowledge from educational psychology to design adaptive agents that monitor student attention in real time using measurements from electroencephalography (EEG) and recapture diminishing attention levels using verbal and nonverbal cues. An experimental evaluation of our approach showed that an adaptive robotic agent employing behavioral techniques to regain attention during drops in engagement improved student recall abilities 43% over the baseline regardless of student gender and significantly improved female motivation and rapport. Our findings offer guidelines for developing effective adaptive agents, particularly for educational settings.
2012	Regroup: interactive machine learning for on-demand group creation in social networks	We present ReGroup, a novel end-user interactive machine learning system for helping people create custom, on demand groups in online social networks. As a person adds members to a group, ReGroup iteratively learns a probabilistic model of group membership specific to that group. ReGroup then uses its currently learned model to suggest additional members and group characteristics for filtering. Our evaluation shows that ReGroup is effective for helping people create large and varied groups, whereas traditional methods (searching by name or selecting from an alphabetical list) are better suited for small groups whose members can be easily recalled by name. By facilitating on demand group creation, ReGroup can enable in-context sharing and potentially encourage better online privacy practices. In addition, applying interactive machine learning to social network group creation introduces several challenges for designing effective end-user interaction with machine learning. We identify these challenges and discuss how we address them in ReGroup.
2012	Tell me more?: the effects of mental model soundness on personalizing an intelligent agent	What does a user need to know to productively work with an intelligent agent? Intelligent agents and recommender systems are gaining widespread use, potentially creating a need for end users to understand how these systems operate in order to fix their agent's personalized behavior. This paper explores the effects of mental model soundness on such personalization by providing structural knowledge of a music recommender system in an empirical study. Our findings show that participants were able to quickly build sound mental models of the recommender system's reasoning, and that participants who most improved their mental models during the study were significantly more likely to make the recommender operate to their satisfaction. These results suggest that by helping end users understand a system's reasoning, intelligent agents may elicit more and better feedback, thus more closely aligning their output with each user's intentions.
2012	Oh dear stacy!: social interaction, elaboration, and learning with teachable agents	Understanding how children perceive and interact with teachable agents (systems where children learn through teaching a synthetic character embedded in an intelligent tutoring system) can provide insight into the effects of so-cial interaction on learning with intelligent tutoring systems. We describe results from a think-aloud study where children were instructed to narrate their experience teaching Stacy, an agent who can learn to solve linear equations with the student's help. We found treating her as a partner, primarily through aligning oneself with Stacy using pronouns like you or we rather than she or it significantly correlates with student learning, as do playful face-threatening comments such as teasing, while elaborate explanations of Stacy's behavior in the third-person and formal tutoring statements reduce learning gains. Additionally, we found that the agent's mistakes were a significant predictor for students shifting away from alignment with the agent.
2012	Monsieur, azonnal kövessen engem bitte!: an automatically generated interlanguage tailored to speakers of minority but culturally influenced languages	Automatic localization of cultural resources and UIs is crucial for the survival of minority languages, for which there are insufficient parallel corpora (or no corpus at all) to build machine translation systems. This paper proposes a new way to compensate for such resource-scarce languages, based on the fact that most languages share a common vocabulary. Concretely, our approach leverages a family of languages closely related to the speaker's native language to construct translations in a coherent mix of these languages. Experimental results indicate that these translations can be easily understood, being also a useful aid for users who are not proficient in foreign languages. Therefore this work significantly contributes to HCI in two ways: it establishes a language that can improve how applications communicate to their users, and it reports insights on the user acceptance towards the method.
2012	Then click ok!: extracting references to interface elements in online documentation	This paper presents a recognizer for identifying references to user interface components in online documentation. The recognizer first extracts phrases matching a list of known components, then employs a classifier to reject coincidental matches. We describe why this seemingly straightforward problem is challenging, then show how informal conventions in documentation writing can be leveraged to perform classification. Using the features identified in this paper, our approach achieves an average F1 score of 0.81, and can correctly distinguish between actual command references and coincidental matches in 93.7% of test cases.
2012	Impression formation in corporate people tagging	This research explores the relationship between self-presentation and perception by others as manifested explicitly through the use of tags in a people tagging system. The study provides insights relevant for the organizational context since it is based on a system implemented within IBM. We developed a detailed codebook and used it to categorize 9,506 tags assigned to a sample of taggers. Our analysis examines the use of self tags versus social tags (assigned by others) across different categories and sub-categories. While overlap exists, self tags tend to be more factual describing technology expertise, social tags augment the individual tags by adding a personal dimension.
2012	A pace not dictated by electrons: an empirical study of work without email	We report on an empirical study where we cut off email usage for five workdays for 13 information workers in an organization. We employed both quantitative measures such as computer log data and ethnographic methods to compare a baseline condition (normal email usage) with our experimental manipulation (email cutoff). Our results show that without email, people multitasked less and had a longer task focus, as measured by a lower frequency of shifting between windows and a longer duration of time spent working in each computer window. Further, we directly measured stress using wearable heart rate monitors and found that stress, as measured by heart rate variability, was lower without email. Interview data were consistent with our quantitative measures, as participants reported being able to focus more on their tasks. We discuss the implications for managing email better in organizations.
2012	<insert image>: Helping in the legal use of open images	Media creation applications cater poorly to one very common usage: Situations in which the users need media that they do not own and for which they are unwilling to pay. Finding and using externally produced media is currently a cumbersome process. Often, users locate the content using a search engine, copy it into their work, cross their fingers, and hope they do not infringe on any copyrights. While the authors have shared hundreds of millions of images with permissive licenses, the license terms are too complicated for other users to follow. In our studies, we found that even the well-intentioned users still fail to respect copyrights in simple image reuse situations. We therefore introduce an Open Media Retrieval (OMR) model to remedy this problem and supplement it with prototypes that access various legal image sources directly within the creative work flow and provide automatic credits to the original authors.
2012	Too close for comfort: a study of the effectiveness and acceptability of rich-media personalized advertising	Online display advertising is predicted to make $29.53 billion this year. Advertisers believe targeted and personalized ads to be more effective, but many users are concerned about their privacy. We conducted a study where 30 participants completed a simulated holiday booking task; each page showing ads with different degrees of personalization. Participants fixated twice as long when ads contained their photo. Participants reported being more likely to notice ads with their photo, holiday destination, and name, but also increasing levels of discomfort with increasing personalization. We conclude that greater personalization in ad content may achieve higher levels of attention, but that the most personalized ads are also the least acceptable. The noticeability benefit in using someone's photo to make them look at an ad may be offset by the privacy cost. As more personal data becomes available to advertisers, it becomes important that these trade-offs are considered.
2012	The way i talk to you: sentiment expression in an organizational context	Sentiment is a rich and important dimension of social interaction. However, its presence in computer-mediated communication in corporate settings is not well understood. This paper provides a preliminary study of people's expression of sentiment in email conversations in an organizational context. The study reveals that sentiment levels evolve over time during the process of newcomers' socialization, that sentiment varies according to tie-strength with the recipient, and that sentiment patterns can be indicative of one's position in the corporate social network as well as job performance. These findings shed light on the complex and dynamic nature of sentiment patterns, and would inspire further explorations and applications of sentiment analysis in organizations.
2012	Why Johnny can't opt out: a usability evaluation of tools to limit online behavioral advertising	We present results of a 45-participant laboratory study investigating the usability of nine tools to limit online behavioral advertising (OBA). We interviewed participants about OBA and recorded their behavior and attitudes as they configured and used a privacy tool, such as a browser plugin that blocks requests to specific URLs, a tool that sets browser cookies indicating a user's preference to opt out of OBA, or the privacy settings built into a web browser. We found serious usability flaws in all tools we tested. Participants found many tools difficult to configure, and tools' default settings were often minimally protective. Ineffective communication, confusing interfaces, and a lack of feedback led many participants to conclude that a tool was blocking OBA when they had not properly configured it to do so. Without being familiar with many advertising companies and tracking technologies, it was difficult for participants to use the tools effectively.
2012	Fighting for my space: coping mechanisms for sns boundary regulation	Sharing information online via social network sites (SNSs) is at an all-time high, yet research shows that users often exhibit a marked dissatisfaction in using such sites. A compelling explanation for this dichotomy is that users are struggling against their SNS environment in an effort to achieve their preferred levels of privacy for regulating social interactions. Our research investigates users' SNS boundary regulation behavior. This paper presents results from a qualitative interview-based study to identify "coping mechanisms" that users devise outside explicit boundary-regulation interface features in order to manage interpersonal boundaries. Our categorization of such mechanisms provides insight into interaction design issues and opportunities for new SNS features.
2012	You've got video: increasing clickthrough when sharing enterprise video with email	In this Note we summarize our research on increasing the information scent of video recordings that are shared via email in a corporate setting. We compare two types of email messages for sharing recordings: the first containing basic information (e.g. title, speaker, abstract) with a link to the video; the second with the same information plus a set of video thumbnails (hyperlinked to the segments they represent), which are automatically created by video summarization technology. We report on the results of two user studies. The first one compares the quality of the set of thumbnails selected by the technology to sets selected by 31 humans. The second study examines the clickthrough rates for both email formats (with and without hyperlinked thumbnails) as well as gathering subjective feedback via survey. Results indicate that the email messages with the thumbnails drove significantly higher clickthrough rates than the messages without, even though people clicked on the main video link more frequently than the thumbnails. Survey responses show that users found the email with the thumbnail set significantly more appealing and novel.
2012	TeleAdvisor: a versatile augmented reality tool for remote assistance	TeleAdvisor is a novel solution designed to support remote assistance tasks in many real-world scenarios. It consists of a video camera and a small projector mounted at the end of a tele-operated robotic arm. This enables a remote helper to view and interact with the workers' workspace, while controlling the point of view. It also provides the worker with a hands-free transportable device to be placed anywhere in his or her environment. Active tracking of the projection space is used in order to reliably correlate between the camera's view and the projector space.
2012	Learning how to feel again: towards affective workplace presence and communication technologies	Affect influences workplace collaboration and thereby impacts a workplace's productivity. Participants in face-to-face interactions have many cues to each other's affect, but work is increasingly carried out via computer-mediated channels that lack many of these cues. Current presence systems enable users to estimate the availability of other users, but not their affective states or communication preferences. This work demonstrates the feasibility of estimating affective state and communication preferences from a stream of presence states that are already being shared in a deployed presence system.
2012	Group hedonic balance and pair programming performance: affective interaction dynamics as indicators of performance	Inspired by research on the role of affect in marital interactions, the authors examined whether affective interaction dynamics occurring within a 5-minute slice can predict pair programming performance. In a laboratory experiment with professional programmers, Group Hedonic Balance, a measure of the balance between positive and negative expressed affect, accounted for up to 35% of the variance in not only subjective but also objective pair programming performance. Implications include a new set of methods to study pair programming interactions and recommendations to improve pair programming performance.
2012	Communication and commitment in an online game team	Theories about commitment in online settings and empirical evidence from offline environments suggest that greater communication in online groups should lead members to become more committed and participate longer. However, experimental evidence is sparse, in part because of difficulties inducing communication online. Moreover, previous work has not identified the route by which communication leads to increased commitment. In this paper, we investigated whether task versus social communication modeled by a leader versus a peer influenced the amount that group members talked and their willingness to continue participating in the group. We conducted an experiment within ad hoc groups in the online game World of Warcraft. Results suggest that communication early in a group's history causes members to talk more later on and that the early communication increases their commitment through its influence on group atmosphere rather than through increased member participation. Social communication by a peer is especially valuable in increasing commitment.
2012	Understanding heart rate sharing: towards unpacking physiosocial space	Advances in biosensing make it possible to include heart rate monitoring in applications and several studies have suggested that heart rate communication has potential for improving social connectedness. However, it is not known how people understand heart rate feedback, or what issues need to be taken into account when designing technologies including heart rate feedback. To explore this, we created a heart rate communication probe that was used in two qualitative in-lab studies and a two-week field trial in participants' homes. Results show that heart rate feedback is a strong connectedness cue that affects the interaction in various ways, depending on a number of interrelated factors. In particular, we found two distinct categories of effects: heart rate as information and heart rate as connection. We propose two mechanisms that could explain these observations and draw out the implications they have for future use of heartbeat communication to support social connectedness or other aspects of social interaction.
2012	Twiage: a game for finding good advice on twitter	Millions of recommendations, opinions and experiences are shared across popular microblogging platforms and services each day. Yet much of this content becomes quickly lost in the stream shortly after being posted. This paper looks at the feasibility of identifying useful content in microblog streams so that it might be archived to facilitate wider access and reference. Towards this goal, we present an experiment with a game-with-a-purpose called Twiage that we designed to determine how well the deluge of content in "raw" microblog streams could be turned into filtered and ranked collections using ratings from players. Experiments with Twiage validate the feasibility of applying human-computation to this problem, finding strong agreement about what constitutes the "most useful" content in our test dataset. Second, we compare the effectiveness of various methods of eliciting such ratings, finding that a "choose-best" interface and Elo rating ranking scheme yield the greatest agreement in the fewest rounds. External validation of resulting top-rated twitter content with a domain expert found that while the top Twiage-ranked "tweets" were among the best of the set, there was a tendency for players to also select what we term "weak spam" - e.g., promotional content disguised as articles or reviews, indicating a need for more stringent content filtering.
2012	AffectAura: an intelligent system for emotional memory	We present AffectAura, an emotional prosthetic that allows users to reflect on their emotional states over long periods of time. We designed a multimodal sensor set-up for continuous logging of audio, visual, physiological and contextual data, a classification scheme for predicting user affective state and an interface for user reflection. The system continuously predicts a user's valence, arousal and engage-ment, and correlates this with information on events, communications and data interactions. We evaluate the interface through a user study consisting of six users and over 240 hours of data, and demonstrate the utility of such a reflection tool. We show that users could reason forward and backward in time about their emotional experiences using the interface, and found this useful.
2012	Problems of data mobility and reuse in the provision of computer-based training for screening mammography	This paper explores some of the problems encountered in using a data archive to build tools for training radiologists to interpret breast screening images. We detail our experiences of taking images and case notes created as part of the work of breast cancer screening and using them as resources for training. Four instances of the use of the archive in training are described in detail and the problems they reveal are discussed. We formulate some general lessons for the mobility and re-use of rich ensembles of data and artefacts drawn from complex professional settings. We argue for a richer representation of the context from which the data was taken than can be achieved through making selected relations explicit in metadata. We also conclude that facilities for correcting and elaborating data should be available at the point of use, and not separated out as distinct activities.
2012	Findings of e-ESAS: a mobile based symptom monitoring system for breast cancer patients in rural Bangladesh	Breast cancer (BC) patients need traditional treatment as well as long term monitoring through an adaptive feedback-oriented treatment mechanism. Here, we present the findings of our 31-week long field study and deployment of e-ESAS - the first mobile-based remote symptom monitoring system (RSMS) developed for rural BC patients where patients are the prime users rather than just the source of data collection at some point of time. We have also shown how ' motivation ' and ' automation ' have been integrated in e-ESAS and creating a unique motivation-persuasion-motivation cycle where the motivated patients become proactive change agents by persuading others. Though in its early deployment stages (2 months), e-ESAS demonstrates the potential to positively impact the cancer care by (1) helping the doctors with graphical charts of long symptom history (automation), (2) facilitating timely interventions through alert generation (automation) and (3) improving three way communications (doctor-patient-attendant) for a better decision making process (motivation) and thereby improving the quality of life of BC patients.
2012	Athletes and street acrobats: designing for play as a community value in parkour	Participatory design methods face challenges when designing for a widespread youth community. In such projects, it is not enough to design in collaboration with a few selected individuals; one must also strive to understand the community at a deeper level and incorporate its values and practices into the design solution. We report on our process of designing with, and for, an identified youth group: the Parkour and Freerunning community. We show how the successful design relied not only on employing methods of participatory observation and participatory design, but also on acquiring an understanding of the practice as a "fun community", valuing play over achievement and competition.
2012	Polyzoom: multiscale and multifocus exploration in 2d visual spaces	The most common techniques for navigating in multiscale visual spaces are pan, zoom, and bird's eye views. However, these techniques are often tedious and cumbersome to use, especially when objects of interest are located far apart. We present the PolyZoom technique where users progressively build hierarchies of focus regions, stacked on each other such that each subsequent level shows a higher magnification. Correlation graphics show the relation between parent and child viewports in the hierarchy. To validate the new technique, we compare it to standard navigation techniques in two user studies, one on multiscale visual search and the other on multifocus interaction. Results show that PolyZoom performs better than current standard techniques.
2012	Aural browsing on-the-go: listening-based back navigation in large web architectures	Mobile web navigation requires highly-focused visual attention, which poses problems when it is inconvenient or distracting to continuously look at the screen (e.g., while walking). Aural interfaces support more eyes-free experiences, as users can primarily listen to the content and occasionally look at the device. Yet, designing aural information architectures remains a challenge. Specifically, back navigation is inefficient in the aural setting, as it forces users to listen to each previous page to retrieve the desired content. This paper introduces topic - and list-based back : two navigation strategies to enhance aural browsing. Both are manifest in Green-Savers Mobile (GSM), an aural mobile site. A study (N=29) compared both solutions to traditional back mechanisms. Our findings indicate that topic- and list-based back enable faster access to previous pages, improve the navigation experience and reduce perceived cognitive load. The proposed designs apply to a wide range of content-intensive, ubiquitous web systems.
2012	Strategies for crowdsourcing social data analysis	Web-based social data analysis tools that rely on public discussion to produce hypotheses or explanations of the patterns and trends in data, rarely yield high-quality results in practice. Crowdsourcing offers an alternative approach in which an analyst pays workers to generate such explanations. Yet, asking workers with varying skills, backgrounds and motivations to simply "Explain why a chart is interesting" can result in irrelevant, unclear or speculative explanations of variable quality. To address these problems, we contribute seven strategies for improving the quality and diversity of worker-generated explanations. Our experiments show that using (S1) feature-oriented prompts , providing (S2) good examples , and including (S3) reference gathering, (S4) chart reading , and (S5) annotation subtasks increases the quality of responses by 28% for US workers and 196% for non-US workers. Feature-oriented prompts improve explanation quality by 69% to 236% depending on the prompt. We also show that (S6) pre-annotating charts can focus workers' attention on relevant details, and demonstrate that (S7) generating explanations iteratively increases explanation diversity without increasing worker attrition. We used our techniques to generate 910 explanations for 16 datasets, and found that 63% were of high quality. These results demonstrate that paid crowd workers can reliably generate diverse, high-quality explanations that support the analysis of specific datasets.
2012	Improving command selection with CommandMaps	Designers of GUI applications typically arrange commands in hierarchical structures, such as menus, due to screen space limitations. However, hierarchical organisations are known to slow down expert users. This paper proposes the use of spatial memory in combination with hierarchy flattening as a means of improving GUI performance. We demonstrate these concepts through the design of a command selection interface, called CommandMaps, and analyse its theoretical performance characteristics. We then describe two studies evaluating CommandMaps against menus and Microsoft's Ribbon interface for both novice and experienced users. Results show that for novice users, there is no significant performance difference between CommandMaps and traditional interfaces -- but for experienced users, CommandMaps are significantly faster than both menus and the Ribbon.
2012	Distributed sensemaking: improving sensemaking by leveraging the efforts of previous users	We examine the possibility of distributed sensemaking: improving a user's sensemaking by leveraging previous users' work without those users directly collaborating or even knowing one another. We asked users to engage in sensemaking by organizing and annotating web search results into "knowledge maps," either with or without previous users' maps to work from. We also recorded gaze patterns as users examined others' knowledge maps. Our findings show the conditions under which distributed sensemaking can improve sensemaking quality; that a user's sensemaking process is readily apparent to a subsequent user via a knowledge map; and that the organization of content was more useful to subsequent users than the content itself, especially when those users had differing goals. We discuss the role distributed sensemaking can play in schema induction by helping users make a mental model of an information space and make recommendations for new tool and system development.
2012	Looking glass: a field study on noticing interactivity of a shop window	In this paper we present our findings from a lab and a field study investigating how passers-by notice the interactivity of public displays. We designed an interactive installation that uses visual feedback to the incidental movements of passers-by to communicate its interactivity. The lab study reveals: (1) Mirrored user silhouettes and images are more effective than avatar-like representations. (2) It takes time to notice the interactivity (approx. 1.2s). In the field study, three displays were installed during three weeks in shop windows, and data about 502 interaction sessions were collected. Our observations show: (1) Significantly more passers-by interact when immediately showing the mirrored user image (+90%) or silhouette (+47%) compared to a traditional attract sequence with call-to-action. (2) Passers-by often notice interactivity late and have to walk back to interact (the landing effect ). (3) If somebody is already interacting, others begin interaction behind the ones already interacting, forming multiple rows (the honeypot effect ). Our findings can be used to design public display applications and shop windows that more effectively communicate interactivity to passers-by.
2012	Human computation tasks with global constraints	An important class of tasks that are underexplored in current human computation systems are complex tasks with global constraints. One example of such a task is itinerary planning, where solutions consist of a sequence of activities that meet requirements specified by the requester. In this paper, we focus on the crowdsourcing of such plans as a case study of constraint-based human computation tasks and introduce a collaborative planning system called Mobi that illustrates a novel crowdware paradigm. Mobi presents a single interface that enables crowd participants to view the current solution context and make appropriate contributions based on current needs. We conduct experiments that explain how Mobi enables a crowd to effectively and collaboratively resolve global constraints, and discuss how the design principles behind Mobi can more generally facilitate a crowd to tackle problems involving global constraints.
2012	Direct answers for search queries in the long tail	Web search engines now offer more than ranked results. Queries on topics like weather, definitions, and movies may return inline results called answers that can resolve a searcher's information need without any additional interaction. Despite the usefulness of answers, they are limited to popular needs because each answer type is manually authored. To extend the reach of answers to thousands of new information needs, we introduce Tail Answers: a large collection of direct answers that are unpopular individually, but together address a large proportion of search traffic. These answers cover long-tail needs such as the average body temperature for a dog, substitutes for molasses, and the keyboard shortcut for a right-click. We introduce a combination of search log mining and paid crowdsourcing techniques to create Tail Answers. A user study with 361 participants suggests that Tail Answers significantly improved users' subjective ratings of search quality and their ability to solve needs without clicking through to a result. Our findings suggest that search engines can be extended to directly respond to a large new class of queries.
2012	Improving scrolling devices with document length dependent gain	We describe a method for applying gain to events reported by scrolling input devices such as scroll wheels. By treating document length as an input to our gain functions, the method allows rapid document traversal regardless of document length; it also allows slow and precise scroll control at shorter distances. An initial experiment characterises four diverse scrolling input devices -- a standard 'notched' scroll wheel, a high performance 'inertial' wheel, an isometric scrolling joystick, and a trackpad -- and the results are used to calibrate several gain function parameters. A second experiment validates the method, showing that it allows faster scrolling in long and short documents than current scrolling-device gain methods, and that subjective preferences favour it.
2012	Personalized input: improving ten-finger touchscreen typing through automatic adaptation	Although typing on touchscreens is slower than typing on physical keyboards, touchscreens offer a critical potential advantage: they are software-based, and, as such, the keyboard layout and classification models used to interpret key presses can dynamically adapt to suit each user's typing pattern. To explore this potential, we introduce and evaluate two novel personalized keyboard interfaces, both of which adapt their underlying key-press classification models. The first keyboard also visually adapts the location of keys while the second one always maintains a visually stable rectangular layout. A three-session user evaluation showed that the keyboard with the stable rectangular layout significantly improved typing speed compared to a control condition with no personalization. Although no similar benefit was found for the keyboard that also offered visual adaptation, overall subjective response to both new touchscreen keyboards was positive. As personalized keyboards are still an emerging area of research, we also outline a design space that includes dimensions of adaptation and key-press classification features.
2012	A-coord input: coordinating auxiliary input streams for augmenting contextual pen-based interactions	The human hand can naturally coordinate multiple finger joints, and simultaneously tilt, press and roll a pen to write or draw. For this reason, digital pens are now embedded with auxiliary input sensors to capture these actions. Prior research on auxiliary input channels has mainly investigated them in isolation of one another. In this work, we explore the coordinated use of two auxiliary channels, a class of interaction techniques we refer to as a-coord input . Through two separate experiments, we explore the design space of a-coord input . In the first study we identify if users can successfully coordinate two auxiliary channels. We found a strong degree of coordination between channels. In a second experiment, we evaluate the effectiveness of a-coord input in a task with multiple steps, such as multi-parameter selection and manipulation. We find that a-coord input facilitates coordination even with a complex, aforethought sequential task. Overall our results indicate that users can control at least two auxiliary input channels in conjunction which can facilitate a number of common tasks can on the pen.
2012	Understanding negotiation in airtime sharing in low-income microenterprises	Shared access to airtime is a prominent mode of connectivity access in the developing world. We seek to understand airtime sharing among low-income microenterprises in India (small, low-capital businesses, such as flower sellers and milkmen), that constitute 90% of the total enterprises in India. We introduce social negotiation as the foundation of airtime sharing. We highlight negotiation mechanisms in the microenterprise, showing how shared resources are used towards personal interests amidst tensions and value conflicts, by adapting, modifying, subverting, and repurposing airtime. We then explore the design space of airtime and bandwidth sharing in low-income communities, including designing for negotiation and improving readability of airtime.
2012	It's complicated: how romantic partners use facebook	Romantic partners face issues of relational development including managing information privacy, tension between individual and relational needs, and accountability to existing friends. Prior work suggests that affordances of social media might highlight and shape these tensions; to explore this, we asked 20 people to reflect daily for two weeks on feelings and decisions around their own and others' Facebook use related to their relationships. Most generally, we find that tensions arise when romantic partners must manage multiple relationships simultaneously because Facebook audiences are so present and so varied. People also engage in subtle negotiation around and appropriation of Facebook's features to accomplish both personal and relational goals. By capturing both why people make these decisions and how Facebook's affordances support them, we expect our findings to generalize to many other social media tools and to inform theorizing about how these tools affect relational development.
2012	Bimanual marking menu for near surface interactions	We describe a mouseless, near-surface version of the Bimanual Marking Menu system. To activate the menu system, users create a pinch gesture with either their index or middle finger to initiate a left click or right click. Then they mark in the 3D space near the interactive area. We demonstrate how the system can be implemented using a commodity range camera such as the Microsoft Kinect, and report on several designs of the 3D marking system. Like the multi-touch marking menu, our system offers a large number of accessible commands. Since it does not rely on contact points to operate, our system leaves the non-dominant hand available for other multi-touch interactions.
2012	Lost in translation: understanding the possession of digital things in the cloud	People are amassing larger and more diverse collections of digital things. The emergence of Cloud computing has enabled people to move their personal files to online places, and create new digital things through online services. However, little is known about how this shift might shape people's orientations toward their digital things. To investigate, we conducted in depth interviews with 13 people comparing and contrasting how they think about their possessions, moving from physical ones, to locally kept digital materials, to the online world. Findings are interpreted to detail design and research opportunities in this emerging space.
2012	Natural use profiles for the pen: an empirical exploration of pressure, tilt, and azimuth	Inherent pen input modalities such as tip pressure, tilt and azimuth (PTA) have been extensively used as additional input channels in pen-based interactions. We conducted a study to investigate the natural use profiles of PTA, which describes the features of PTA in the course of normal pen use such as writing and drawing. First, the study reveals the ranges of PTA in normal pen use, which can distinguish pen events accidently occurring in normal drawing and writing from those used for mode switch. The natural use profiles also show that azimuth is least likely to cause false pen mode switching while tip pressure is most likely to cause false pen mode switching. Second, the study reveals correlations among various modalities, indicating that pressure plus azimuth is superior to other pairs for dual-modality control.
2012	The spread of emotion via facebook	In this paper we study large-scale emotional contagion through an examination of Facebook status updates. After a user makes a status update with emotional content, their friends are significantly more likely to make a valence-consistent post. This effect is significant even three days later, and even after controlling for prior emotion expressions by both users and their friends. This indicates not only that emotional contagion is possible via text-only communication and that emotions flow through social networks, but also that emotion spreads via indirect communications media.
2012	How do couples use CheekTouch over phone calls?	In this paper we introduce CheekTouch, an affective audio-tactile communication technique that transmits multi-finger touch gestures applied on a sender's mobile phone to a receiver's cheek in real time during a call. We made a pair of CheekTouch prototypes each with a multi-touch screen and vibrotactile display to enable bidirectional touch delivery. We observed four romantic couples in their twenties using our prototype system in a lab setting over five consecutive days, and analyzed how CheekTouch affected their non-verbal and emotional communication. The results of the user study showed that CheekTouch could effectively support audio-tactile communication in various ways - persuading, conveying status, delivering information, emphasizing emotion/words, calling for attention, and being playful.
2012	MirageTable: freehand interaction on a projected augmented reality tabletop	Instrumented with a single depth camera, a stereoscopic projector, and a curved screen, MirageTable is an interactive system designed to merge real and virtual worlds into a single spatially registered experience on top of a table. Our depth camera tracks the user's eyes and performs a real-time capture of both the shape and the appearance of any object placed in front of the camera (including user's body and hands). This real-time capture enables perspective stereoscopic 3D visualizations to a single user that account for deformations caused by physical objects on the table. In addition, the user can interact with virtual objects through physically-realistic freehand actions without any gloves, trackers, or instruments. We illustrate these unique capabilities through three application examples: virtual 3D model creation, interactive gaming with real and virtual objects, and a 3D teleconferencing experience that not only presents a 3D view of a remote person, but also a seamless 3D shared task space. We also evaluated the user's perception of projected 3D objects in our system, which confirmed that the users can correctly perceive such objects even when they are projected over different background colors and geometries (e.g., gaps, drops).
2012	LightGuide: projected visualizations for hand movement guidance	LightGuide is a system that explores a new approach to gesture guidance where we project guidance hints directly on a user's body. These projected hints guide the user in completing the desired motion with their body part which is particularly useful for performing movements that require accuracy and proper technique, such as during exercise or physical therapy. Our proof-of-concept implementation consists of a single low-cost depth camera and projector and we present four novel interaction techniques that are focused on guiding a user's hand in mid-air. Our visualizations are designed to incorporate both feedback and feedforward cues to help guide users through a range of movements. We quantify the performance of LightGuide in a user study comparing each of our on-body visualizations to hand animation videos on a computer display in both time and accuracy. Exceeding our expectations, participants performed movements with an average error of 21.6mm, nearly 85% more accurately than when guided by video.
2012	Keep in touch: channel, expectation and experience	This paper investigates whether and how digitally mediated social touch (remote touch) may influence the sense of connectedness toward a speaker and the emotional experience of what is being communicated. We employ an 'augmented' storytelling methodology where we manipulate the modality of an 'emotive' channel that accompanies the speech, and the contextual expectation of the listener. Comparing a remote upper-arm touch against a similarly timed flashing light, we explore the importance of the touch modality in affect conveyance. Our second manipulation involves two cover stories where the listener is told that the touch or flashing light is triggered either by the storyteller expressively squeezing a touch input device while speaking, or by measured 'high points' in the mental state of the storyteller. Our results show that the story accompanied by communicative touch resulted in a significant increase in the sense of connectedness with the storyteller over the speech-only condition, and a trend toward greater affective conveyance.
2012	TAP & PLAY: an end-user toolkit for authoring interactive pen and paper language activities	Hybrid paper-digital interfaces are a promising approach for supporting language activities. The familiarity of pen and paper makes it a particularly attractive media for many user groups, including young children. Digital pens enhance interaction with traditional paper content by playing and recording audio and recognizing handwriting and gestures. Currently, generating custom interactive paper documents involves some programming, limiting its use by many user groups (e.g., educators and families) who might especially benefit from application of hybrid paper-digital interfaces in their practices. To address this need, we developed an end-user Toolkit for Authoring Pen and Paper Language Activities (TAP & PLAY). This paper describes the iterative development of the toolkit, its accessibility for novice non-technical users, and use in three different contexts for early language learning. We demonstrate and document the system's usability, generality, and utility for people who want to create and tailor their own custom interactive paper-based language activities.
2012	At home with surface computing?	This paper describes a field study of an interactive surface deployed in three family homes. The tabletop technology provides a central place where digital content, such as photos, can be easily archived, managed and viewed. The tabletop affords multi-touch input, allowing digital content to be sorted, triaged and interacted with using one or two-handed interactions. A physics-based simulation adds dynamics to digital content, providing users with rich ways of interacting that borrows from the real-world. The field study is one of the first of a surface computer within a domestic environment. Our goal is to uncover people's inter-actions, appropriations, perceptions and experiences with such technologies, exploring the potential barriers to use. Given these devices provide such a revolutionary shift in interaction, will people be able to engage with them in everyday life in the ways we intend? In answering this question, we hope to deepen our understanding of the design of such systems for home and consumer domains.
2012	StoryCrate: tabletop storyboarding for live film production	Creating film content for broadcast is a high pressure and complex activity involving multiple experts and highly specialized equipment. Production teams are under continuous pressure to produce ever more creative and groundbreaking content while reducing the budgets and human resources required. While technologies are being developed for digitizing and streamlining sections of the production workflow, a gap remains between creative decisions made on location, and those made during digital editing and post-production. We describe a prototype tangible, tabletop interface to be deployed on a film shoot, which uses a storyboard as a shared data representation to drive team creativity. We define creativity in terms of team production, discuss our implementation and describe a deployment in which the prototype was used by a professional production team during a film shoot. Finally we describe a number of interesting interactions that were observed and consider the implications of our design decisions on the creative process of film making and the benefits of tangible, tabletop collaborative interactive displays in live film production.
2012	Understanding flicking on curved surfaces	Flicking is a common interaction technique to move objects across large interactive surfaces, but little is known about its suitability for use on non-planar, curved surfaces. Flicking consists of two stages: First, visually determining the direction in which to flick the object, then planning and executing the corresponding gesture. Errors in both stages could influence flicking accuracy. We investigated flicking interactions on curved interactive surface to evaluate which type of error influences accuracy. Therefore, we carried out three user studies to analyze how each stage of flicking on a curved surface is influenced. Our main findings are: 1) Flicking gestures are more accurate if horizontal and vertical surface are joined by a continuous curve than if they are separated by an edge or gap. 2) Flicking gestures on curved surfaces are mostly influenced by the motor execution stage of the gesture rather than the visual perception stage. 3) Flicking accuracy decreases as the starting point of the gesture is moved closer to the curve. 4) We conclude with a first mathematical model to estimate the error users will make when flicking across a curve.
2012	How screen transitions influence touch and pointer interaction across angled display arrangements	Digital office environments often integrate multiple displays in a variety of arrangements. We investigated the combination of a horizontal and a directly connected vertical display, which together form a digital workspace. In particular, we were interested in the effect of the physical transition (bezel, edge or curve) on dragging. In a study participants performed dragging tasks across both display planes with direct touch as well as a pointing device. Contrary to our expectations, we found no significant effect on task completion time. Only regarding accuracy the curved transition performed better than edge and bezel. Interestingly, the subjective judgment did generally not match the objective results. These findings suggest that we need to rethink our understanding of display continuities in terms of usability as well as user satisfaction.
2012	How small can you go?: analyzing the effect of visual angle in pointing tasks	People are increasingly using wireless mice from across rooms as they use computers as entertainment centers. As a consequence, they often have to point at targets occupying small visual angles. In this note we present the results of a study on pointing performance for targets occupying small visual angles. Our results suggest there is a steep degradation of pointing performance in both accuracy and speed for targets occupying a visual angle below 3 minutes of arc.
2012	Shape-changing interfaces: a review of the design space and open research questions	Shape change is increasingly used in physical user interfaces, both as input and output. Yet, the progress made and the key research questions for shape-changing interfaces are rarely analyzed systematically. We review a sample of existing work on shape-changing interfaces to address these shortcomings. We identify eight types of shape that are transformed in various ways to serve both functional and hedonic design purposes. Interaction with shape-changing interfaces is simple and rarely merges input and output. Three questions are discussed based on the review: (a) which design purposes may shape-changing interfaces be used for, (b) which parts of the design space are not well understood, and (c) why studying user experience with shape-changing interfaces is important.
2012	Designing effective gaze mechanisms for virtual agents	Virtual agents hold great promise in human-computer interaction with their ability to afford embodied interaction using nonverbal human communicative cues. Gaze cues are particularly important to achieve significant high-level outcomes such as improved learning and feelings of rapport. Our goal is to explore how agents might achieve such outcomes through seemingly subtle changes in gaze behavior and what design variables for gaze might lead to such positive outcomes. Drawing on research in human physiology, we developed a model of gaze behavior to capture these key design variables. In a user study, we investigated how manipulations in these variables might improve affiliation with the agent and learning. The results showed that an agent using affiliative gaze elicited more positive feelings of connection, while an agent using referential gaze improved participants' learning. Our model and findings offer guidelines for the design of effective gaze behaviors for virtual agents.
2012	Ripple effects of an embedded social agent: a field study of a social robot in the workplace	Prior research has investigated the effect of interactive social agents presented on computer screens or embodied in robots. Much of this research has been pursued in labs and brief field studies. Comparatively little is known about social agents embedded in the workplace, where employees have repeated interactions with the agent, alone and with others. We designed a social robot snack delivery service for a workplace, and evaluated the service over four months allowing each employee to use it for two months. We report on how employees responded to the robot and the service over repeated encounters. Employees attached different social roles to the robot beyond a delivery person as they incorporated the robot's visit into their workplace routines. Beyond one-on-one interaction, the robot created a ripple effect in the workplace, triggering new behaviors among employees, including politeness, protection of the robot, mimicry, social comparison, and even jealousy. We discuss the implications of these ripple effects for designing services incorporating social agents.
2012	PINOKY: a ring that animates your plush toys	PINOKY is a wireless ring-like device that can be externally attached to any plush toy as an accessory that animates the toy by moving its limbs. A user is thus able to instantly convert any plush toy into a soft robot. The user can control the toy remotely or input the movement desired by moving the plush toy and having the data recorded and played back. Unlike other methods for animating plush toys, PINOKY is non-intrusive, so alterations to the toy are not required. In a user study, 1) the roles of plush toys in the participants' daily lives were examined, 2) how participants played with plush toys without PINOKY was observed, 3) how they played with plush toys with PINOKY was observed, and their reactions to the device were surveyed. On the basis of the results, potential applications were conceptualized to illustrate the utility of PINOKY.
2012	Baby it's cold outside: the influence of ambient temperature and humidity on thermal feedback	Thermal feedback is a new area of research in HCI and, as such, there has been very little investigation of the impact of environmental factors on its use for interaction. To address this shortcoming we conducted an experiment to investigate how ambient temperature and humidity could affect the usability of thermal feedback. If environmental conditions affect perception significantly, then it may not be suitable for mobile interactions. Evaluations were conducted outdoors in varying environmental conditions over a period of 5 months. Results showed that the ambient temperature has a significant impact on people's ability to detect stimuli and also their perception of these stimuli. Humidity has a negligible effect for most humidity values. Despite this, previous thermal feedback design recommendations still hold in varying temperatures and humidities showing that thermal feedback is a useful tool for mobile interaction.
2012	Intimacy in long-distance relationships over video chat	Many couples live a portion of their lives in a long-distance relationship (LDR). This includes a large number of dating college students as well as couples who are geographically-separated because of situational demands such as work. We conducted interviews with individuals in LDRs to understand how they make use of video chat systems to maintain their relationships. In particular, we have investigated how couples use video to "hang out" together and engage in activities over extended periods of time. Our results show that regardless of the relationship situation, video chat affords a unique opportunity for couples to share presence over distance, which in turn provides intimacy. While beneficial, couples still face challenges in using video chat, including contextual (e.g., location of partners, time zones), technical (e.g., mobility, audio/video quality, networking), and personal (e.g., a lack of physicality needed by most for intimate sexual acts) challenges.
2012	MimicTile: a variable stiffness deformable user interface for mobile devices	MimicTile is a novel variable stiffness deformable user interface for mobile devices that implements two key features. The first feature is an input interface that accepts a variety of deformation-based gestures, providing a user with several ways of interacting with a small mobile device. The other feature is the ability to provide information to the user through haptic feedback by varying the stiffness of the interface. The features are suitable for enhancing mobile applications. They were implemented using only shape memory alloy (SMA) wires as the actuator. SMA wire is extremely flexible, making it ideal for deformable user interfaces. In MimicTile, SMA wires act as both actuators and external input sensors. The actuator function works by altering stiffness based on user input. This study also discusses ideas for further development of deformable user interfaces.
2012	A transformational product to improve self-control strength: the chocolate machine	Lack of self-control is at the heart of many undesirable behaviors, such as overeating, overspending, and even overworking. While the field of Persuasive Technologies searches for ways to change attitudes and behaviors, it often neglects the science of self-control. We present the Chocolate Machine , an exploratory interactive product to train self-control strength based upon Ego Depletion theory. A field study showed the machine to increase perceived self-control over time, while providing a sustained positive experience. This makes the machine transformational , aiming at facilitating behaviors people find worthwhile, but hard to implement.
2012	Animating paper using shape memory alloys	Our aim is to make shape memory alloys (SMAs) accessible and visible as creative crafting materials by combining them with paper. In this paper, we begin by presenting mechanisms for actuating paper with SMAs along with a set of design guidelines for achieving dramatic movement. We then describe how we tested the usability and educational potential of one of these mechanisms in a workshop where participants, age 9 to 15, made actuated electronic origami cranes. We found that participants were able to successfully build constructions integrating SMAs and paper, that they enjoyed doing so, and were able to learn skills like circuitry design and soldering over the course of the workshop.
2012	User see, user point: gaze and cursor alignment in web search	Past studies of user behavior in Web search have correlated eye-gaze and mouse cursor positions, and other lines of research have found cursor interactions to be useful in determining user intent and relevant parts of Web pages. However, cursor interactions are not all the same; different types of cursor behavior patterns exist, such as reading, hesitating, scrolling and clicking, each of which has a different meaning. We conduct a search study with 36 subjects and 32 search tasks to determine when gaze and cursor are aligned, and thus when the cursor position is a good proxy for gaze position. We study the effect of time, behavior patterns, user, and search task on the gaze-cursor alignment, findings which lead us to question the maxim that "gaze is well approximated by cursor." These lessons inform an experiment in which we predict the gaze position with better accuracy than simply using the cursor position, improving the state-of-the-art technique for approximating visual attention with the cursor. Our new technique can help make better use of large-scale cursor data in identifying how users examine Web search pages.
2012	A hybrid mass participation approach to mobile software trials	User trials of mobile applications have followed a steady march out of the lab, and progressively further ''into the wild', recently involving ''app store'-style releases of software to the general public. Yet from our experiences on these mass participation systems and a survey of the literature, we identify a number of reported difficulties. We propose a hybrid methodology that aims to address these, by combining a global software release with a concurrent local trial. A phone-based game, created to explore the uptake and use of ad hoc peer-to-peer networking, was evaluated using this new hybrid trial method, combining a small-scale local trial (11 users) with a ''mass participation' trial (over 10,000 users). Our hybrid method offers many benefits, allowing locally observed findings to be verified, patterns in globally collected data to be explained and addresses ethical issues raised by the mass participation approach. We note trends in the local trial that did not appear in the larger scale deployment, and which would therefore have led to misleading results were the application trialed using ''traditional' methods alone. Based on this study and previous experience, we provide a set of guidelines to researchers working in this area.
2012	A handle bar metaphor for virtual object manipulation with mid-air interaction	Commercial 3D scene acquisition systems such as the Microsoft Kinect sensor can reduce the cost barrier of realizing mid-air interaction. However, since it can only sense hand position but not hand orientation robustly, current mid-air interaction methods for 3D virtual object manipulation often require contextual and mode switching to perform translation, rotation, and scaling, thus preventing natural continuous gestural interactions. A novel handle bar metaphor is proposed as an effective visual control metaphor between the user's hand gestures and the corresponding virtual object manipulation operations. It mimics a familiar situation of handling objects that are skewered with a bimanual handle bar. The use of relative 3D motion of the two hands to design the mid-air interaction allows us to provide precise controllability despite the Kinect sensor's low image resolution. A comprehensive repertoire of 3D manipulation operations is proposed to manipulate single objects, perform fast constrained rotation, and pack/align multiple objects along a line. Three user studies were devised to demonstrate the efficacy and intuitiveness of the proposed interaction techniques on different virtual manipulation scenarios.
2012	Digital pen and paper practices in observational research	Researchers from many disciplines are taking advantage of increasingly inexpensive digital video to capture extensive records of human activity in real-world settings. The ability to record and share such data has created a critical moment in the practice and scope of behavioral research. While recent work is beginning to develop techniques for visualizing and interacting with integrated multimodal information collected during field research, navigating and analyzing these large datasets remains challenging and tools are especially needed to support the early stages of data exploration. In this paper we describe digital pen and paper practices in observational research and their integration with ChronoViz, a tool for annotating, visualizing, and analyzing multimodal data. The goal is to better support researchers both in the field, while collecting data, and later in the lab, during analysis. We document the co-evolution of notetaking practices and system features as 28 participants used the tool during an 18-month deployment.
2013	Health vlogger-viewer interaction in chronic illness management	Health video blogs (vlogs) allow individuals with chronic illnesses to share their stories, experiences, and knowledge with the general public. Furthermore, health vlogs help in creating a connection between the vlogger and the viewers. In this work, we present a qualitative study examining the various methods that health vloggers use to establish a connection with their viewers. We found that vloggers used genres to express specific messages to their viewers while using the uniqueness of video to establish a deeper connection with their viewers. Health vloggers also explicitly sought interaction with their viewers. Based on these results, we present design implications to help facilitate and build sustainable communities for vloggers.
2013	The many faces of facebook: experiencing social media as performance, exhibition, and personal archive	The growing use of social media means that an increasing amount of people's lives are visible online. We draw from Goffman's theatrical metaphor and Hogan's exhibition approach to explore how people manage their personal collection of social media data over time. We conducted a qualitative study of 13 participants to reveal their day-to-day decision-making about producing and curating digital traces on Facebook. Their goals and strategies showed that people experience the Facebook platform as consisting of three different functional regions: a performance region for managing recent data and impression management, an exhibition region for longer term presentation of self-image, and a personal region for archiving meaningful facets of life. Further, users' need for presenting and archiving data in these three regions is mediated by temporality. These findings trigger a discussion of how to design social media that support these dynamic and sometimes conflicting needs.
2013	Augmented endurance: controlling fatigue while handling objects by affecting weight perception using augmented reality	The main contribution of this paper is to develop a method for alleviating fatigue during handling medium-weight objects and augmenting our endurance by affecting our weight perception with augmented reality technology. To assist people to lift medium-weight objects without a complex structure or various costs, we focus on the phenomenon that our weight perception during handling objects is affected by visual properties. Our hypothesis is that this illusionary effect in weight perception can be applied to reduce fatigue while handling medium-weight objects without mechatronics-based physical assistance. In this paper, we propose an augmented reality system that changes the brightness value of an object in order to reduce fatigue while handling the object. We conducted two fundamental experiments to investigate the effectiveness of the proposed system. Our results suggested that the system eliminates the need to use excess energy for handling objects and reduces fatigue during the handling task.
2013	Older adults as digital content producers	Older adults are normally characterized as consumers, rather than producers, of digital content. Current research concerning the design of technologies for older adults typically focuses on providing access to digital resources. Access is important, but is often insufficient, especially when establishing new social relationships. This paper investigates the nature and role of digital content that has been created by older adults, for the purpose of forging new relationships. We present a unique field study in which seven older adults (aged 71-92 years), who did not know each other, used a prototype iPad application ( Enmesh ) to create and share photographs and messages. The findings demonstrate that older adults, even those in the \'1c"oldest old\'1d" age group, embraced opportunities to express themselves creatively through digital content production. We show that self-expression and social engagement with peers can be realized when socio-technical systems are suitably designed to allow older adults to create and share their own digital content.
2013	Quantifying the invisible audience in social networks	When you share content in an online social network, who is listening? Users have scarce information about who actually sees their content, making their audience seem invisible and difficult to estimate. However, understanding this invisible audience can impact both science and design, since perceived audiences influence content production and self-presentation online. In this paper, we combine survey and large-scale log data to examine how well users' perceptions of their audience match their actual audience on Facebook. We find that social media users consistently underestimate their audience size for their posts, guessing that their audience is just 27% of its true size. Qualitative coding of survey responses reveals folk theories that attempt to reverse-engineer audience size using feedback and friend count, though none of these approaches are particularly accurate. We analyze audience logs for 222,000 Facebook users' posts over the course of one month and find that publicly visible signals --- friend count, likes, and comments --- vary widely and do not strongly indicate the audience of a single post. Despite the variation, users typically reach 61% of their friends each month. Together, our results begin to reveal the invisible undercurrents of audience attention and behavior in online social networks.
2013	Favors from facebook friends: unpacking dimensions of social capital	Past research has demonstrated a link between perceptions of social capital and use of the popular social network site, Facebook. Williams' Internet Social Capital Scales, based on Putnam's formulation, tap into sub-dimensions of social capital that have not been broadly used yet may enlighten our understanding of the different ways in which connecting with others online can facilitate access to resources embedded within our social relationships. In this study, we segment Williams' Internet Social Capital Scales into various sub-dimensions using factor analysis and explicate the distinct facets of social capital through a lab experiment in which Facebook users (N=98) request a small favor from their Facebook network. We find that some sub-dimensions play a significant role in getting favors from Facebook friends while bonding and bridging social capital do not significantly predict responses to favor requests.
2013	Using contextual integrity to examine interpersonal information boundary on social network sites	Although privacy problems in Social Network Sites (SNS) have become more salient than ever in recent years, interpersonal privacy issues in SNS remain understudied. This study aims to generate insights in understanding users' interpersonal privacy concerns by expounding interpersonal privacy boundaries in SNS. Through a case analysis of Friendship Pages on Facebook, this paper identifies users' interpersonal privacy concerns that are rooted from informational norms outlined in the theory of contextual integrity, as well as the tensions that occur within and cross these informational norms. This paper concludes with a discussion of design implications and future research.
2013	Gender, topic, and audience response: an analysis of user-generated content on facebook	Although both men and women communicate frequently on Facebook, we know little about what they talk about, whether their topics differ and how their network responds. Using Latent Dirichlet Allocation (LDA), we identify topics from more than half a million Facebook status updates and determine which topics are more likely to receive feedback, such as likes and comments. Women tend to share more personal topics (e.g., family matters), while men discuss more public ones (e.g., politics and sports). Generally, women receive more feedback than men, but "male" topics (those more often posted by men) receive more feedback, especially when posted by women.
2013	Accessible online content creation by end users	Like most online content, user-generated content (UGC) poses accessibility barriers to users with disabilities. However, the accessibility difficulties pervasive in UGC warrant discussion and analysis distinct from other kinds of online content. Content authors, community culture, and the authoring tool itself all affect UGC accessibility. The choices, resources available, and strategies in use to ensure accessibility are different than for other types of online content. We contribute case studies of two UGC communities with accessible content: Wikipedia, where authors focus on access to visual materials and navigation, and an online health support forum where users moderate the cognitive accessibility of posts. Our data demonstrate real world moderation strategies and illuminate factors affecting success, such as community culture. We conclude with recommended strategies for creating a culture of accessibility around UGC.
2013	Why interactive learning environments can have it all: resolving design conflicts between competing goals	Designing interactive learning environments (ILEs; e.g., intelligent tutoring systems, educational games, etc.) is a challenging interdisciplinary process that needs to satisfy multiple stakeholders. ILEs need to function in real educational settings (e.g., schools) in which a number of goals interact. Several instructional design methodologies exist to help developers address these goals. However, they often lead to conflicting recommendations. Due to the lack of an established methodology to resolve such conflicts, developers of ILEs have to rely on ad-hoc solutions. We present a principled methodology to resolve such conflicts. We build on a well-established design process for creating Cognitive Tutors, a highly effective type of ILE. We extend this process by integrating methods from multiple disciplines to resolve design conflicts. We illustrate our methodology's effectiveness by describing the iterative development of the Fractions Tutor, which has proven to be effective in classroom studies with 3,000 4th-6th graders.
2013	see me, feel me, touch me, hear me: trajectories and interpretation in a sculpture garden	We apply the HCI concept of trajectories to the design of a sculpture trail. We crafted a trajectory through each sculpture, combining textual and audio instructions to drive directed viewing, movement and touching while listening to accompanying music. We designed key transitions along the way to oscillate between moments of social interaction and isolated personal engagement, and to deliver official interpretation only after visitors had been given the opportunity to make their own. We describe how visitors generally followed our trajectory, engaging with sculptures and making interpretations that sometimes challenged the received interpretation. We relate our findings to discussions of sense-making and design for multiple interpretations, concluding that curators and designers may benefit from considering \'18trajectories of interpretation'.
2013	A conversation between trees: what data feels like in the forest	A study of an interactive artwork shows how artists engaged the public with scientific climate change data. The artwork visualised live environmental data collected from remote trees, alongside both historical and forecast global CO 2 data. Visitors also took part in a mobile sensing experience in a nearby forest. Our study draws on the perspectives of the artists, visitors and a climate scientist to reveal how the work was designed and experienced. We show that the artists adopted a distinct approach that fostered an emotional engagement with data rather than an informative or persuasive one. We chart the performative strategies they used to achieve this including sensory engagement with data, a temporal structure that balanced liveness with slowness, and the juxtaposition of different treatments of the data to enable interpretation and dialogue.
2013	From competition to metacognition: designing diverse, sustainable educational games	We investigate the unique educational benefits of 1-on-1 competitive games, arguing that such games can be just as easy to design as single-player educational games, while yielding a more diverse and sustainable learning experience. We present a study of chess and StarCraft II in order to inform the design of similar educational games and their communities. We discuss a competitive game we designed to teach Java programming. We evaluate the game by discussing its user study. Our main contributions are 1) an argument that the use of 1-on-1 competition can solve two existing problems inherent to single-player games, 2) an analysis of the features that make competitive games effective learning environments, and 3) an early but encouraging description of the emergent learning environment one can expect from designing an educational game with these features.
2013	In search of learning: facilitating data analysis in educational games	The field of Educational Games has seen many calls for added rigor. One avenue for improving the rigor of the field is developing more generalizable methods for measuring student learning within games. Throughout the process of development, what is relevant to measure and assess may change as a game evolves into a finished product. The field needs an approach for game developers and researchers to be able to prototype and experiment with different measures that can stand up to rigorous scrutiny, as well as provide insight into possible new directions for development. We demonstrate a toolkit and analysis tools that capture and analyze students' performance within open educational games. The system records relevant events during play, which can be used for analysis of player learning by designers. The tools support replaying student sessions within the original game's environment, which allows researchers and developers to explore possible explanations for student behavior. Using this system, we were able to facilitate a number of analyses of student learning in an open educational game developed by a team of our collaborators as well as gain greater insight into student learning with the game and where to focus as we iterate.
2013	Pointing at 3d target projections with one-eyed and stereo cursors	We present a study of cursors for selecting 2D-projected 3D targets. We compared a stereo- and mono-rendered (one-eyed) cursor using two mouse-based and two remote pointing techniques in a 3D Fitts' law pointing experiment. The first experiment used targets at fixed depths. Results indicate that one-eyed cursors only improve screen-plane pointing techniques, and that constant target depth does not influence pointing throughput. A second experiment included pointing between targets at varying depths and used only "screen-plane" pointing techniques. Our results suggest that in the absence of stereo cue conflicts, screen-space projections of Fitts' law parameters (target size and distance) yield constant throughput despite target depth differences and produce better models of performance.
2013	Unlimited editions: three approaches to the dissemination and display of digital art	The paper reflects on three approaches to the dissemination and display of digital art. \'1c"s[edition]\'1d" is a novel, web-based service that offers limited editions of "\'1cdigital prints"\'1d. Analysis of user comments suggests that the metaphor of a \'1c"limited digital edition"\'1d raises issues and to some extent is resisted. The second approach is the Flickr Brushes Gallery, where digital painters post images and comment on one another's work. Analysis of comment boards indicates that the shared art and comments are a form of gift exchange. Finally, the paper discusses a field study in which artists exhibited their work as it develops over time in digital frames and also in an immersive digital projection room. Analysis of field notes and interviews indicate that the digital frame approach was unsuccessful because of aesthetic and environmental concerns. The immersive projection suggested that more experiential approaches may be more interesting. It is argued that there is an inherent resistance in digital media to previous models of art commoditization. None of the approaches discussed here resolve the dilemma but rather indicate the scope and complexity of the issues.
2013	Electric materialities and interactive technology	This paper offers new theoretical and design insights into nteractive technology. By initially considering electric technology broadly, our work informs how HCI approaches a range of specific interactive or digital things and materials. Theoretically, we contribute a rigorous analysis of electric technology using the experiential lens of phenomenology. A major result is to characterize electric technology by three forms of materiality: the electric object, its electric materiality, and electric power. In terms of design, we present and analyze novel interactive form prototypes. Our theoretical contributions offer new insight into design artifacts, just as our novel design artifacts help reveal new theoretical insight.
2013	Optimizing challenge in an educational game using large-scale design experiments	Online games can serve as research instruments to explore the effects of game design elements on motivation and learning. In our research, we manipulated the design of an online math game to investigate the effect of challenge on player motivation and learning. To test the \'1cInverted-U Hypothesis\'1d, which predicts that maximum game engagement will occur with moderate challenge, we produced two large-scale (10K and 70K subjects), multi-factor (2x3 and 2x9x8x4x25) online experiments. We found that, in almost all cases, subjects were more engaged and played longer when the game was easier, which seems to contradict the generality of the Inverted-U Hypothesis. Troublingly, we also found that the most engaging design conditions produced the slowest rates of learning. Based on our findings, we describe several design implications that may increase challenge-seeking in games, such as providing feedforward about the anticipated degree of challenge.
2013	Flexpad: highly flexible bending interactions for projected handheld displays	Flexpad is an interactive system that combines a depth camera and a projector to transform sheets of plain paper or foam into flexible, highly deformable, and spatially aware handheld displays. We present a novel approach for tracking deformed surfaces from depth images in real time. It captures deformations in high detail, is very robust to occlusions created by the user's hands and fingers, and does not require any kind of markers or visible texture. As a result, the display is considerably more deformable than in previous work on flexible handheld displays, enabling novel applications that leverage the high expressiveness of detailed deformation. We illustrate these unique capabilities through three application examples: curved cross-cuts in volumetric images, deforming virtual paper characters, and slicing through time in videos. Results from two user studies show that our system is capable of detecting complex deformations and that users are able to perform them quickly and precisely.
2013	A pilot study of using crowds in the classroom	Industry relies on higher education to prepare students for careers in innovation. Fulfilling this obligation is especially difficult in classroom settings, which often lack authentic interaction with the outside world. Online crowdsourcing has the potential to change this. Our research explores if and how online crowds can support student learning in the classroom. We explore how scalable, diverse, immediate (and often ambiguous and conflicting) input from online crowds affects student learning and motivation for project-based innovation work. In a pilot study with three classrooms, we explore interactions with the crowd at four key stages of the innovation process: needfinding, ideating, testing, and pitching. Students reported that online crowds helped them quickly and inexpensively identify needs and uncover issues with early-stage prototypes, although they favored face-to-face interactions for more contextual feed-back. We share early evidence and discuss implications for creating a socio-technical infrastructure to more effectively use crowdsourcing in education.
2013	Creating and analyzing stereoscopic 3D graphical user interfaces in digital games	Creating graphical user interfaces (GUI) for stereoscopic 3D (S3D) games is a difficult choice between visual comfort and effect. We present a S3D Game GUI Design Space and a list of S3D-specific attributes that emphasizes integrating visually comfortable interfaces into the game world, story and S3D view. To showcase our approach, we created two GUI concepts and evaluated them with 32 users. Our results show quality improvements for a combination of bottom position and visual attachment for a menu. In a referencing interface, placing the reference near to the target depth significantly improved perceived quality, game integration, and increased presence. These results confirm the need to create S3D GUIs with perceptual constraints in mind, demonstrating the potential to extend the user experience. Additionally, our design space offers a formal and flexible way to create new effects in S3D GUIs.
2013	A multi-site field study of crowdsourced contextual help: usage and perspectives of end users and software teams	We present a multi-site field study to evaluate LemonAid, a crowdsourced contextual help approach that allows users to retrieve relevant questions and answers by making selections within the interface. We deployed LemonAid on 4 different web sites used by thousands of users and collected data over several weeks, gathering over 1,200 usage logs, 168 exit surveys, and 36 one-on-one interviews. Our results indicate that over 70% of users found LemonAid to be helpful, intuitive, and desirable for reuse. Software teams found LemonAid easy to integrate with their sites and found the analytics data aggregated by LemonAid a novel way of learning about users' popular questions. Our work provides the first holistic picture of the adoption and use of a crowdsourced contextual help system and offers several insights into the social and organizational dimensions of implementing such help systems for real-world applications.
2013	BeThere: 3D mobile collaboration with spatial input	We present BeThere , a proof-of-concept system designed to explore 3D input for mobile collaborative interactions. With BeThere , we explore 3D gestures and spatial input which allow remote users to perform a variety of virtual interactions in a local user's physical environment. Our system is completely self-contained and uses depth sensors to track the location of a user's fingers as well as to capture the 3D shape of objects in front of the sensor. We illustrate the unique capabilities of our system through a series of interactions that allow users to control and manipulate 3D virtual content. We also provide qualitative feedback from a preliminary user study which confirmed that users can complete a shared collaborative task using our system.
2013	Crowdsourcing performance evaluations of user interfaces	Online labor markets, such as Amazon's Mechanical Turk (MTurk), provide an attractive platform for conducting human subjects experiments because the relative ease of recruitment, low cost, and a diverse pool of potential participants enable larger-scale experimentation and faster experimental revision cycle compared to lab-based settings. However, because the experimenter gives up the direct control over the participants' environments and behavior, concerns about the quality of the data collected in online settings are pervasive. In this paper, we investigate the feasibility of conducting online performance evaluations of user interfaces with anonymous, unsupervised, paid participants recruited via MTurk. We implemented three performance experiments to re-evaluate three previously well-studied user interface designs. We conducted each experiment both in lab and online with participants recruited via MTurk. The analysis of our results did not yield any evidence of significant or substantial differences in the data collected in the two settings: All statistically significant differences detected in lab were also present on MTurk and the effect sizes were similar. In addition, there were no significant differences between the two settings in the raw task completion times, error rates, consistency, or the rates of utilization of the novel interaction mechanisms introduced in the experiments. These results suggest that MTurk may be a productive setting for conducting performance evaluations of user interfaces providing a complementary approach to existing methodologies.
2013	Form digitization in BPO: from outsourcing to crowdsourcing?	This paper describes an ethnographic study of an outsourced business process - the digitization of healthcare forms. The aim of the study was to understand how the work is currently organized, with an eye to uncovering the research challenges which need to be addressed if that work is to be crowdsourced. The findings are organised under four emergent themes: Workplace Ecology, Data Entry Skills and Knowledge, Achieving Targets and Collaborative Working. For each theme a description of how the work is undertaken in the outsourcer's Indian office locations is given, followed by the implications for crowdsourcing that work. This research is a first step in understanding how crowdsourcing might be applied to BPO activities. The paper examines features specific to form digitization - extreme distribution and form decomposition - and lightly touches on the crowdsourcing of BPO work more generally.
2013	3D object position using automatic viewpoint transitions	This paper presents IUCA (Interaction Using Camera Animations), a new interaction technique for 3D objects manipulation. IUCA allows efficient interaction in a full-resolution perspective view by integrating transients animated transitions to orthographic views into the manipulation task. This provides an interaction in context, with precise object positioning and alignment. An evaluation of the technique shows that, compared to the classical configurations, IUCA allows to reduce pointing time by 14% on average. Testing with professional 3D designers and novice users indicate that IUCA is easy to use and to learn; and that users feel comfortable with it.
2013	SpaceTop: integrating 2D and spatial 3D interactions in a see-through desktop environment	SpaceTop is a concept that fuses spatial 2D and 3D interactions in a single workspace. It extends the traditional desktop interface with interaction technology and visualization techniques that enable seamless transitions between 2D and 3D manipulations. SpaceTop allows users to type, click, draw in 2D, and directly manipulate interface elements that float in the 3D space above the keyboard. It makes it possible to easily switch from one modality to another, or to simultaneously use two modalities with different hands. We introduce hardware and software configurations for co-locating these various interaction modalities in a unified workspace using depth cameras and a transparent display. We describe new interaction and visualization techniques that allow users to interact with 2D elements floating in 3D space. We present the results from a preliminary user study that indicates the benefit of such hybrid workspaces.
2013	Still looking: investigating seamless gaze-supported selection, positioning, and manipulation of distant targets	We investigate how to seamlessly bridge the gap between users and distant displays for basic interaction tasks, such as object selection and manipulation. For this, we take advantage of very fast and implicit, yet imprecise gaze- and head-directed input in combination with ubiquitous smartphones for additional manual touch control. We have carefully elaborated two novel and consistent sets of gaze-supported interaction techniques based on touch-enhanced gaze pointers and local magnification lenses. These conflict-free sets allow for fluently selecting and positioning distant targets. Both sets were evaluated in a user study with 16 participants. Overall, users were fastest with a touch-enhanced gaze pointer for selecting and positioning an object after some training. While the positive user feedback for both sets suggests that our proposed gaze- and head-directed interaction techniques are suitable for a convenient and fluent selection and manipulation of distant targets, further improvements are necessary for more precise cursor control.
2013	EventHurdle: supporting designers' exploratory interaction prototyping with gesture-based sensors	Prototyping of gestural interactions in the early phase of design is one of the most challenging tasks for designers without advanced programming skills. Relating users' input from gesture-based sensor values requires a great deal of effort on the designer's part and disturbs their reflective and creative thinking. To deal with this problem, we present EventHurdle, a visual gesture-authoring tool to support designers' explorative prototyping. It supports remote gestures from a camera, handheld gestures with physical sensors, and touch gestures by utilizing touch screens. EventHurdle allows designers to visually define and modify gestures through interaction workspace and graphical markup language with hurdles. Because the created gestures can be integrated into a prototype as programming code and automatically recognized, designers do not need to pay attention in sensor-related implementation. Two user studies and a recognition test are reported to discuss the acceptance and implications of explorative prototyping tools for designers.
2013	Individual user characteristics and information visualization: connecting the dots through eye tracking	There is increasing evidence that users' characteristics such as cognitive abilities and personality have an impact on the effectiveness of information visualization techniques. This paper investigates the relationship between such characteristics and fine-grained user attention patterns. In particular, we present results from an eye tracking user study involving bar graphs and radar graphs, showing that a user's cognitive abilities such as perceptual speed and verbal working memory have a significant impact on gaze behavior, both in general and in relation to task difficulty and visualization type. These results are discussed in view of our long-term goal of designing information visualisation systems that can dynamically adapt to individual user characteristics.
2013	Small, medium, or large?: estimating the user-perceived scale of stroke gestures	We show that large consensus exists among users in the way they articulate stroke gestures at various scales (i.e., small, medium , and large ), and formulate a simple rule that estimates the user-intended scale of input gestures with 87% accuracy. Our estimator can enhance current gestural interfaces by leveraging scale as a natural parameter for gesture input, reflective of user perception (i.e., no training required). Gesture scale can simplify gesture set design, improve gesture-to-function mappings, and reduce the need for users to learn and for recognizers to discriminate unnecessary symbols.
2013	A preliminary investigation of human adaptations for various virtual eyes in video see-through HMDS	A video see-through head mounted display (HMD) has a different viewing point than does the real eye, resulting in visual displacement (VD). VD deteriorates visuomotor performance due to sensory conflict. Previous work has investigated this deterioration and human adaptation by comparing fixed VD and real eye conditions. In this study we go a step further to investigate whether any differences in visuomotor and adaptation trends exist across 16 distinct VD conditions. The performance tasks studied were of two types: foot placement and finger touch. In contrast to our initial prediction, the results showed equal task performance levels and adaptation within about 5 minutes regardless of VD conditions. We found that human adaptation covered a variety of VDs --- up to 55 mm in the X, Y direction; up to 125mm in the Z direction; and up to 140mm of interocular distance (IOD). In addition, we found that partial adaptation gave participants the interesting experience of a sense of body structure distortion for a few minutes.
2013	Gesture studio: authoring multi-touch interactions through demonstration and declaration	The prevalence of multi-touch devices opens the space for rich interactions. However, the complexity for creating multi-touch interactions hinders this potential. In this paper, we present Gesture Studio, a tool for creating multi-touch interaction behaviors by combining the strength of two distinct but complementary approaches: programming by demonstration and declaration. We employ an intuitive video-authoring metaphor for developers to demonstrate touch gestures, compose complicated behaviors, test these behaviors in the tool and export them as source code that can be integrated into the developers' project.
2013	A multi-touch interface for fast architectural sketching and massing	Architectural sketching and massing are used by designers to analyze and explore the design space of buildings. This paper describes a novel multi-touch interface for fast architectural sketching and massing of tall buildings. It incorporates a family of multi-touch gestures, enabling one to quickly sketch the 2D contour of a base floor plan and extrude it to model a building with multi-floor structures. Further, it provides a set of gestures to users: select and edit a range of floors; scale contours of a building; copy, paste, and rotate a building, i.e., create a twisted structure; edit profile curves of a building's profile; and collapse and remove a selected range of floors. The multi-touch system also allows users to apply textures or geometric facades to the building, and to compare different designs side-by-side. To guide the design process, we describe interactions with a domain expert, a practicing architect. The final interface is evaluated by architects and students in an architecture Dept., which demonstrates that the system allows rapid conceptual design and massing of novel multi-story building structures.
2013	EyeContext: recognition of high-level contextual cues from human visual behaviour	In this work we present EyeContext , a system to infer high-level contextual cues from human visual behaviour. We conducted a user study to record eye movements of four participants over a full day of their daily life, totalling 42.5 hours of eye movement data. Participants were asked to self-annotate four non-mutually exclusive cues: social (interacting with somebody vs. no interaction), cognitive (concentrated work vs. leisure), physical (physically active vs. not active), and spatial (inside vs. outside a building). We evaluate a proof-of-concept EyeContext system that combines encoding of eye movements into strings and a spectrum string kernel support vector machine (SVM) classifier. Our results demonstrate the large information content available in long-term human visual behaviour and opens up new venues for research on eye-based behavioural monitoring and life logging.
2013	Indirect shear force estimation for multi-point shear force operations	The possibility of using shear forces is being explored recently as a method to enrich touch screen interaction. However, most of the related studies are restricted to the case of single-point shear forces, possibly owing to the difficulty of independently sensing shear forces at multiple touch points. In this paper, we propose indirect methods to estimate shear forces using the movement of contact areas. These methods enable multi-point shear force estimation, where the estimation is done for each finger independently. We show the feasibility of these methods through an informal user study with a demo application utilizing these methods.
2013	Exploring personality-targeted UI design in online social participation systems	We present a theoretical foundation and empirical findings demonstrating the effectiveness of personality-targeted design. Much like a medical treatment applied to a person based on his specific genetic profile, we argue that theory-driven, personality-targeted UI design can be more effective than design applied to the entire population. The empirical exploration focused on two settings, two populations and two personality traits: Study 1 shows that users' extraversion level moderates the relationship between the UI cue of audience size and users' contribution. Study 2 demonstrates that the effectiveness of social anchors in encouraging online contributions depends on users' level of emotional stability. Taken together, the findings demonstrate the potential and robustness of the interactionist approach to UI design. The findings contribute to the HCI community, and in particular to designers of social systems, by providing guidelines to targeted design that can increase online participation.
2013	LEMtool: measuring emotions in visual interfaces	In this paper the development process and validation of the LEMtool (Layered Emotion Measurement tool) are described. The LEMtool consists of eight images that display a cartoon figure expressing four positive and four negative emotions using facial expressions and body postures. The instrument can be used during interaction with a visual interface, such as a website, and allows participants to select elements of the interface that elicit a certain emotion. The images of the cartoon figure were submitted to a validation study, in which participants rated the recognizability of the images as specific emotions. All images were found to be recognizable above chance level. In another study, the LEMtool was used to assess visual appeal judgements of a number of web pages. The LEMtool ratings were supported by visual appeal ratings of web pages both for very brief (50 milliseconds) and for long (free-viewing) stimulus exposures. Furthermore, the instrument provided insight into the elements of the web pages that elicited the emotional responses.
2013	Using crowdsourcing to support pro-environmental community activism	Community activist groups typically rely on core groups of highly motivated members. In this paper we consider how crowdsourcing strategies can be used to supplement the activities of pro-environmental community activists, thus increasing the scalability of their campaigns. We focus on mobile data collection applications and strategies that can be used to engage casual participants in pro-environmental data collection. We report the results of a study that used both quantitative and qualitative methods to investigate the impact of different motivational factors and strategies, including both intrinsic and extrinsic motivators. The study compared and provides empirical evidence for the effectiveness of two extrinsic motivation strategies, pointification - a subset of gamification - and financial incentives. Prior environmental interest is also assessed as an intrinsic motivation factor. In contrast to previous HCI research on pro-environmental technology, much of which has focused on individual behavior change, this paper offers new insights and recommendations on the design of systems that target groups and communities.
2013	Digital motherhood: how does technology help new mothers?	New mothers can experience social exclusion, particularly during the early weeks when infants are solely dependent on their mothers. We used ethnographic methods to investigate whether technology plays a role in supporting new mothers. Our research identified two core themes: (1) the need to improve confidence as a mother; and (2) the need to be more than \'18just' a mother. We reflect on these findings both in terms of those interested in designing applications and services for motherhood and also the wider CHI community.
2013	Age-related performance issues for PIN and face-based authentication systems	Graphical authentication systems typically claim to be more usable than PIN or password-based systems, but these claims often follow limited, single-stage paradigm testing on a young, student population. We present a more demanding test paradigm in which multiple codes are learned and tested over a three-week period. We use this paradigm with two user populations, comparing the performance of younger and older adults. We first establish baseline performance in a study in which populations of younger and older adults learn PIN codes and we follow this with a second study in which younger and older adults use two face-based graphical authentication systems employing young faces vs. old faces as code components. As expected, older adults show relatively poor performance when compared to younger adults, irrespective of the authentication material, but this age-related deficit can be markedly reduced by the introduction of age-appropriate faces. We conclude firstly that this paradigm provides a good basis for the future evaluation of memory-based authentication systems and secondly that age-appropriate face-based authentication is viable in the security marketplace.
2013	The presentation of health-related search results and its impact on negative emotional outcomes	Searching for health information online has become increasingly common, yet few studies have examined potential negative emotional effects of online health information search. We present results from an experiment manipulating the presentation of search results for common symptoms, which shows that the frequency and placement of serious illness mentions within results can influence perceptions of symptom severity and susceptibility of having the serious illness, respectively. The increase in severity and susceptibility can then lead to higher levels of negative emotional outcomes experienced--including feeling overwhelmed and frightened. Interestingly, health literacy can help reduce perceived symptom severity, and high online health experience actually increases the likelihood that individuals use a frequency-based heuristic. Technological implications and directions for future research are discussed.
2013	Designing and theorizing co-located interactions	This paper gives an interwoven account of the theoretical and practical work we undertook in pursuit of designing co-located interactions. We show how we sensitized ourselves to theory from diverse intellectual disciplines, to develop an analytical lens to better think about co-located interactions. By critiquing current systems and their conceptual foundations, and further interrelating theories particularly in regard to performative aspects of identity and communication, we develop a more nuanced way of thinking about co-located interactions. Drawing on our sensitivities, we show how we generated and are exploring, through the process of design, a set of co-located interactions that are situated within our social ecologies, and contend that our upfront theoretical work enabled us to identify and explore this space in the first place. This highlights the importance of problem framing, especially for projects adopting design methodologies.
2013	Access lens: a gesture-based screen reader for real-world documents	Gesture-based touch screen user interfaces, when designed to be accessible to blind users, can be an effective mode of interaction for those users. However, current accessible touch screen interaction techniques suffer from one serious limitation: they are only usable on devices that have been explicitly designed to support them. Access Lens is a new interaction method that uses computer vision-based gesture tracking to enable blind people to use accessible gestures on paper documents and other physical objects, such as product packages, device screens, and home appliances. This paper describes the development of Access Lens hardware and software, the iterative design of Access Lens in collaboration with blind computer users, and opportunities for future development.
2013	Age-related differences in performance with touchscreens compared to traditional mouse input	Despite the apparent popularity of touchscreens for older adults, little is known about the psychomotor performance of these devices. We compared performance between older adults and younger adults on four desktop and touchscreen tasks: pointing, dragging, crossing and steering. On the touchscreen, we also examined pinch-to-zoom. Our results show that while older adults were significantly slower than younger adults in general, the touchscreen reduced this performance gap relative to the desktop and mouse. Indeed, the touchscreen resulted in a significant movement time reduction of 35% over the mouse for older adults, compared to only 16% for younger adults. Error rates also decreased.
2013	Scenario-based interactive UI design	Clearly picturing user behavior is one of the key requirements when designing successful interactive software. However, covering all possible user behaviors with one UI is a complex challenge. The Scenario-based Interactive UI Design tool is designed to support the characterization of user behavior based on scenarios and then using the information in UI design. Scenarios make it easy to understand and share user behavior even if we have little design knowledge. However, they have two big weaknesses; 1) integrating several scenarios in one UI is difficult, even if we can create appropriate scenarios, 2) maintaining the links between scenarios and the UI is a heavy task in iterative design. Our tool solves the above problems through its hierarchical scenario structure and visualized overview of scenarios. It enhances the designer's skill in writing scenarios and designing UIs smoothly and easily.
2013	Configuring participation: on how we involve people in design	The term 'participation' is traditionally used in HCI to describe the involvement of users and stakeholders in design processes, with a pretext of distributing control to participants to shape their technological future. In this paper we ask whether these values can hold up in practice, particularly as participation takes on new meanings and incorporates new perspectives. We argue that much HCI research leans towards configuring participation . In exploring this claim we explore three questions that we consider important for understanding how HCI configures participation; Who initiates, directs and benefits from user participation in design? In what forms does user participation occur? How is control shared with users in design? In answering these questions we consider the conceptual, ethical and pragmatic problems this raises for current participatory HCI research. Finally, we offer directions for future work explicitly dealing with the configuration of participation.
2013	The efficacy of human post-editing for language translation	Language translation is slow and expensive, so various forms of machine assistance have been devised. Automatic machine translation systems process text quickly and cheaply, but with quality far below that of skilled human translators. To bridge this quality gap, the translation industry has investigated post-editing, or the manual correction of machine output. We present the first rigorous, controlled analysis of post-editing and find that post-editing leads to reduced time and, surprisingly, improved quality for three diverse language pairs (English to Arabic, French, and German). Our statistical models and visualizations of experimental data indicate that some simple predictors (like source text part of speech counts) predict translation time, and that post-editing results in very different interaction patterns. From these results we distill implications for the design of new language translation interfaces.
2013	A value sensitive action-reflection model: evolving a co-design space with stakeholder and designer prompts	We introduce a design method for evolving a co-design space to support stakeholders untrained in design. Specifically, the purpose of the method is to expand and shape a co-design space so that stakeholders, acting as designers, focus not only on the form and function of a tool being envisioned but also on the social context of its use and values that lie with individuals, groups, and societies. The method introduces value sensitive stakeholder prompts and designer prompts into a co-design process, creating a particular kind of reflection-on-action cycle. The prompts provide a means for bringing empirical data on values and theoretical perspective into the co-design process. We present the method in terms of a general model, the Value Sensitive Action-Reflection Model; place the model within discourse on co-design spaces; and illustrate the model with a discussion of its application in a lo-fi prototyping activity around safety for homeless young people. We conclude with reflections on the model and method.
2013	Probing bus stop for insights on transit co-design	Social computing provides a new way for citizens to engage with their public service. Our research investigates how social computing might support citizens co-design their transit service. We conducted a field study with public transit riders, exploring the issues and controversies that reveal conflicting communities. Our analyses revealed three insights. First, encourage citizens to share what they see as the rationale for current service offerings. Second, encourage citizens to share the consequences of current services and of proposed changes and new designs. Third, focus on producing a shared citizen and service provider understanding of what the goals and mission of the public service should be.
2013	Improving teamwork using real-time language feedback	We develop and evaluate a real-time language feedback system that monitors the communication patterns among students in a discussion group and provides real-time instructions to shape the way the group works together. As an initial step, we determine which group processes are related to better outcomes. We then experimentally test the efficacy of providing real-time instructions which target two of these group processes. The feedback system was successfully able to shape the way groups worked together. However, only appropriate feedback given to groups that were not working well together from the start was able to improve group performance.
2013	Same translation but different experience: the effects of highlighting on machine-translated conversations	Machine translation (MT) has the potential to allow members of multilingual organizations to interact via their own native languages, but issues with the quality of MT output have made it difficult to realize this potential. We hypothesized that highlighting keywords in MT output might make it easier for people to overlook translation errors and focus on what was intended by the message. To test this hypothesis, we conducted a laboratory experiment in which native English speakers interacted with a Mandarin-speaking confederate using machine translation. Participants performed three brainstorming tasks, under each of three conditions: no highlighting, keyword highlighting, and random highlighting. Our results indicated that people consider the identical messages clearer and less distracting when the keywords in the message are highlighted. Keyword highlighting also improved subjective impressions of the partner and the quality of the collaboration. These findings inform the design of future communication tools to support multilingual communications.
2013	Large-scale participation: a case study of a participatory approach to developing a new public library	In this paper, we present a case study of a participatory project that focuses on interaction in large-scale design, namely, the development of the new Urban Mediaspace Aarhus. This project, which has been under way for ten years, embodies a series of issues that arise when participatory design approaches are applied to large-scale, IT-oriented projects. At the same time, it highlights the issues public knowledge institutions face, when interactive technologies challenge their fundamental roles and practices; by extension, this case offers examples of how these challenges may be explored and addressed through IT-based participatory initiatives. We present a range of such activities carried out during the past ten years, and present the main lessons from the project, based on interviews with three key stakeholders. These lessons focus on how to make participation work in practice, how to align different paradigms of inquiry and practice in a project of this scale, and how to capture and anchor the insights from participatory events to inform the ongoing design process.
2013	SpatialEase: learning language through body motion	Games that engage both mind and body by targeting users' kinesthetic intelligence have the potential to transform the activity of learning across a wide variety of domains. To investigate this potential in the context of second language learning, we have developed SpatialEase: a Kinect game for the body-based learning of language that is grounded in space and motion. In this game, learners respond to audio commands in the second language by moving their bodies in space, while a game mechanic based on distributed cued-recall supports learning over time. Our comparison of SpatialEase with the popular Rosetta Stone software for learner of Mandarin Chinese showed similar learning gains over a single session and generated several key implications for the future design of mixed-modality learning systems.
2013	Regularly visited patches in human mobility	In this paper, we propose a new analytic unit for human mobility analysis -- the patch. We developed a process to identify Regularly Visited Patches (RVP) and a set of metrics to characterize and measure their spatial patterns. Using a large dataset of Foursquare check-ins as a test bed, we show that RVP analysis reveals fundamental patterns of human mobility and will lead to promising research with strong implications for businesses.
2013	Community insights: helping community leaders enhance the value of enterprise online communities	Online communities are increasingly being deployed in enterprises to increase productivity and share expertise. Community leaders are critical for fostering successful communities, but existing technologies rarely support leaders directly, both because of a lack of clear data about leader needs, and because existing tools are member - rather than leader-centric . We present the evidence-based design and evaluation of a novel tool for community leaders, Community Insights (CI). CI provides actionable analytics that help community leaders foster healthy communities, providing value to both members and the organization. We describe empirical and system contributions derived from a long-term deployment of CI to leaders of 470 communities over 10 months. Empirical contributions include new data showing: (a) which metrics are most useful for leaders to assess community health, (b) the need for and how to design actionable metrics, (c) the need for and how to design contextualized analytics to support sensemaking about community data. These findings motivate a novel community system that provides leaders with useful, actionable and contextualized analytics.
2013	Using fNIRS brain sensing to evaluate information visualization interfaces	We show how brain sensing can lend insight to the evaluation of visual interfaces and establish a role for fNIRS in visualization. Research suggests that the evaluation of visual design benefits by going beyond performance measures or questionnaires to measurements of the user's cognitive state. Unfortunately, objectively and unobtrusively monitoring the brain is difficult. While functional near-infrared spectroscopy (fNIRS) has emerged as a practical brain sensing technology in HCI, visual tasks often rely on the brain's quick, massively parallel visual system, which may be inaccessible to this measurement. It is unknown whether fNIRS can distinguish differences in cognitive state that derive from visual design alone. In this paper, we use the classic comparison of bar graphs and pie charts to test the viability of fNIRS for measuring the impact of a visual design on the brain. Our results demonstrate that we can indeed measure this impact, and furthermore measurements indicate that there are not universal differences in bar graphs and pie charts.
2013	CommunityCompare: visually comparing communities for online community leaders in the enterprise	Online communities are important in enterprises, helping workers to build skills and collaborate. Despite their unique and critical role fostering successful communities, community leaders have little direct support in existing technologies. We introduce CommunityCompare, an interactive visual analytic system to enable leaders to make sense of their community's activity with comparisons. Composed of a parallel coordinates plot, various control widgets, and a preview of example posts from communities, the system supports comparisons with hundreds of related communities on multiple metrics and the ability to learn by example. We motivate and inform the system design with formative interviews of community leaders. From additional interviews, a field deployment, and surveys of leaders, we show how the system enabled leaders to assess community performance in the context of other comparable communities, learn about community dynamics through data exploration, and identify examples of top performing communities from which to learn. We conclude by discussing how our system and design lessons generalize.
2013	Weighted graph comparison techniques for brain connectivity analysis	The analysis of brain connectivity is a vast field in neuroscience with a frequent use of visual representations and an increasing need for visual analysis tools. Based on an in-depth literature review and interviews with neuroscientists, we explore high-level brain connectivity analysis tasks that need to be supported by dedicated visual analysis tools. A significant example of such a task is the comparison of different connectivity data in the form of weighted graphs. Several approaches have been suggested for graph comparison within information visualization, but the comparison of weighted graphs has not been addressed. We explored the design space of applicable visual representations and present augmented adjacency matrix and node-link visualizations. To assess which representation best support weighted graph comparison tasks, we performed a controlled experiment. Our findings suggest that matrices support these tasks well, outperforming node-link diagrams. These results have significant implications for the design of brain connectivity analysis tools that require weighted graph comparisons. They can also inform the design of visual analysis tools in other domains, e.g. comparison of weighted social networks or biological pathways.
2013	Crowdfunding inside the enterprise: employee-initiatives for innovation and collaboration	We describe a first experiment in enterprise crowdfunding - i.e., employees allocating money for employee-initiated proposals at an Intranet site, including a trial of this system with 511 employees in IBM Research. Major outcomes include: employee proposals that addressed diverse individual and organizational needs; high participation rates; extensive inter-departmental collaboration, including the discovery of large numbers of previously unknown collaborators; and the development of goals and motivations based on collective concerns at multiple levels of project groups, communities of practice, and the organization as a whole. We recommend further, comparative research into crowd-funding and other forms of employee-initiated innovations.
2013	At the interface of biology and computation	Representing a new class of tool for biological modeling, Bio Model Analyzer (BMA) uses sophisticated computational techniques to determine stabilization in cellular networks. This paper presents designs aimed at easing the problems that can arise when such techniques - \'14using distinct approaches to conceptualizing networks\'14 - are applied in biology. The work also engages with more fundamental issues being discussed in the philosophy of science and science studies. It shows how scientific ways of knowing are constituted in routine interactions with tools like BMA, where the emphasis is on the practical business at hand, even when seemingly deep conceptual problems exist. For design, this perspective refigures the frictions raised when computation is used to model biology. Rather than obstacles, they can be seen as opportunities for opening up different ways of knowing.
2013	TapBoard: making a touch screen keyboard more touchable	A physical keyboard key has three states, whereas a touch screen usually has only two. Due to this difference, the state corresponding to the touched state of a physical key is missing in a touch screen keyboard. This touched state is an important factor in the usability of a keyboard. In order to recover the role of a touched state in a touch screen, we propose the TapBoard, a touch screen software keyboard that regards tapping actions as keystrokes and other touches as the touched state. In a series of user studies, we validate the effectiveness of the TapBoard concept. First, we show that tapping to type is in fact compatible with the existing typing skill of most touch screen keyboard users. Second, users quickly adapt to the TapBoard and learn to rest their fingers in the touched state. Finally, we confirm by a controlled experiment that there is no difference in text-entry performance between the TapBoard and a traditional touch screen software keyboard. In addition to these experimental results, we demonstrate a few new interaction techniques that will be made possible by the TapBoard.
2013	Octopus: evaluating touchscreen keyboard correction and recognition algorithms via	The time and labor demanded by a typical laboratory-based keyboard evaluation are limiting resources for algorithmic adjustment and optimization. We propose Remulation, a complementary method for evaluating touchscreen keyboard correction and recognition algorithms. It replicates prior user study data through real-time, on-device simulation. We have developed Octopus, a Remulation-based evaluation tool that enables keyboard developers to efficiently measure and inspect the impact of algorithmic changes without conducting resource-intensive user studies. It can also be used to evaluate third-party keyboards in a "black box" fashion, without access to their algorithms or source code. Octopus can evaluate both touch keyboards and word-gesture keyboards. Two empirical examples show that Remulation can efficiently and effectively measure many aspects of touch screen keyboards at both macro and micro levels. Additionally, we contribute two new metrics to measure keyboard accuracy at the word level: the Ratio of Error Reduction (RER) and the Word Score.
2013	Analyzing crowd workers in mobile pay-for-answer q&a	Despite the popularity of mobile pay-for-answer Q&A services, little is known about the people who answer questions on these services. In this paper we examine 18.8 million question and answer pairs from Jisiklog, the largest mobile pay-foranswer Q&A service in Korea, and the results of a complementary survey study of 245 Jisiklog workers. The data are used to investigate key motivators of participation, working strategies of experienced users, and longitudinal interaction dynamics. We find that answerers are rarely motivated by social factors but are motivated by financial incentives and intrinsic motives. Additionally, although answers are provided quickly, an answerer's topic selection tends to be broad, with experienced workers employing unique strategies to answer questions and judge relevance. Finally, analysis of longitudinal working patterns and community dynamics demonstrate the robustness of mobile pay-for-answer Q&A. These findings have significant implications on the design of mobile pay-for-answer Q&A.
2013	Morphees: toward high shape resolution in self-actuated flexible mobile devices	We introduce the term shape resolution , which adds to the existing definitions of screen and touch resolution. We propose a framework, based on a geometric model (Non-Uniform Rational B-splines), which defines a metric for shape resolution in ten features. We illustrate it by comparing the current related work of shape changing devices. We then propose the concept of Morphees that are self-actuated flexible mobile devices adapting their shapes on their own to the context of use in order to offer better affordances. For instance, when a game is launched, the mobile device morphs into a console-like shape by curling two opposite edges to be better grasped with two hands. We then create preliminary prototypes of Morphees in order to explore six different building strategies using advanced shape changing materials (dielectric electro active polymers and shape memory alloys). By comparing the shape resolution of our prototypes, we generate insights to help designers toward creating high shape resolution Morphees .
2013	Métamorphe: augmenting hotkey usage with actuated keys	Hotkeys are an efficient method of selecting commands on a keyboard. However, these shortcuts are often underused by users. We present Métamorphe, a novel keyboard with keys that can be individually raised and lowered to promote hotkeys usage. Métamorphe augments the output of traditional keyboards with haptic and visual feedback, and offers a novel design space for user input on raised keys (e.g., gestures such as squeezing or pushing the sides of a key). We detail the implementation of Métamorphe and discuss design factors. We also report two user studies. The first is a user-defined interface study that shows that the new input vocabulary is usable and useful, and provides insights into the mental models that users associate with raised keys. The second user study shows improved eyes-free selection performance for raised keys as well as the surrounding unraised keys.
2013	Promoting Hotkey use through rehearsal with ExposeHK	Keyboard shortcuts allow fast interaction, but they are known to be infrequently used, with most users relying heavily on traditional pointer-based selection for most commands. We describe the goals, design, and evaluation of ExposeHK, a new interface mechanism that aims to increase hotkey use. ExposeHK's four key design goals are: 1) enable users to browse hotkeys; 2) allow non-expert users to issue hotkey commands as a physical rehearsal of expert performance; 3) exploit spatial memory to assist non-expert users in identifying hotkeys; and 4) maximise expert performance by using consistent shortcuts in a flat command hierarchy. ExposeHK supports these objectives by displaying hotkeys overlaid on their associated commands when a modifier key is pressed. We evaluated ExposeHK in three empirical studies using toolbars, menus, and a tabbed \'18ribbon' toolbar. Results show that participants used more hotkeys, and used them more often, with ExposeHK than with other techniques; they were faster with ExposeHK than with either pointing or other hotkey methods; and they strongly preferred ExposeHK. Our research shows that ExposeHK can substantially improve the user's transition from a \'18beginner mode' of interaction to a higher level of expertise.
2013	Combining crowdsourcing and google street view to identify street-level accessibility problems	Poorly maintained sidewalks, missing curb ramps, and other obstacles pose considerable accessibility challenges; however, there are currently few, if any, mechanisms to determine accessible areas of a city a priori . In this paper, we investigate the feasibility of using untrained crowd workers from Amazon Mechanical Turk (turkers) to find, label, and assess sidewalk accessibility problems in Google Street View imagery. We report on two studies: Study 1 examines the feasibility of this labeling task with six dedicated labelers including three wheelchair users; Study 2 investigates the comparative performance of turkers. In all, we collected 13,379 labels and 19,189 verification labels from a total of 402 turkers. We show that turkers are capable of determining the presence of an accessibility problem with 81% accuracy. With simple quality control methods, this number increases to 93%. Our work demonstrates a promising new, highly scalable method for acquiring knowledge about sidewalk accessibility.
2013	Turkopticon: interrupting worker invisibility in amazon mechanical turk	As HCI researchers have explored the possibilities of human computation, they have paid less attention to ethics and values of crowdwork. This paper offers an analysis of Amazon Mechanical Turk, a popular human computation system, as a site of technically mediated worker-employer relations. We argue that human computation currently relies on worker invisibility. We then present Turkopticon, an activist system that allows workers to publicize and evaluate their relationships with employers. As a common infrastructure, Turkopticon also enables workers to engage one another in mutual aid. We conclude by discussing the potentials and challenges of sustaining activist technologies that intervene in large, existing socio-technical systems.
2013	MorePhone: a study of actuated shape deformations for flexible thin-film smartphone notifications	We present MorePhone, an actuated flexible smartphone with a thin-film E Ink display. MorePhone uses shape memory alloys to actuate the entire surface of the display as well as individual corners. We conducted a participatory study to determine how users associate urgency and notification type with full screen, 1 corner, 2 corner and 3 corner actuations of the smartphone. Results suggest that with the current prototype, actuated shape notifications are useful for visual feedback. Urgent notifications such as alarms and voice calls were best matched with actuation of the entire display surface, while less urgent notifications, such as software notifications were best matched to individual corner bends. While different corner actuations resulted in significantly different matches between notification types, medium urgency notification types were treated as similar, and best matched to a single corner bend. A follow-up study suggested that users prefer to dedicate each corner to a specific type of notification. Users would like to personalize the assignment of corners to notification type. Animation of shape actuation significantly increased the perceived urgency of any of the presented shapes.
2013	Don't hide in the crowd!: increasing social transparency between peer workers improves crowdsourcing outcomes	This paper studied how social transparency and different peer-dependent reward schemes (i.e., individual, teamwork, and competition) affect the outcomes of crowdsourcing. The results showed that when social transparency was increased by asking otherwise anonymous workers to share their demographic information (e.g., name, nationality) to the paired worker, they performed significantly better. A more detailed analysis showed that in a teamwork reward scheme, in which the reward of the paired workers depended only on the collective outcomes, increasing social transparency could offset effects of social loafing by making them more accountable to their teammates. In a competition reward scheme, in which workers competed against each other and the reward depended on how much they outperformed their opponent, increasing social transparency could augment effects of social facilitation by providing more incentives for them to outperform their opponent. The results suggested that a careful combination of methods that increase social transparency and different reward schemes can significantly improve crowdsourcing outcomes.
2013	LightCloth: senseable illuminating optical fiber cloth for creating interactive surfaces	This paper introduces an input and output device that enables illumination, bi-directional data communication, and position sensing on a soft cloth. This "LightCloth" is woven from diffusive optical fibers. Since the fibers are arranged in parallel, the cloth has one-dimensional position information. Sensor-emitter pairs attached to bundles of contiguous fibers enable bundle-specific light input and output. We developed a prototype system that allows full-color illumination and 8-bit data input by infrared signals. We present as an application a chair with a LightCloth cover whose illumination pattern is specified using an infrared light pen. Here we describe the implementation details of the device and discuss possible interactions using the device.
2013	Bending the rules: bend gesture classification for flexible displays	Bend gestures have a large number of degrees of freedom and therefore offer a rich interaction language. We propose a classification scheme for bend gestures, and explore how users perform these bend gestures along four classification criterion: location, direction, size, and angle. We collected 36 unique bend gestures performed three times by each participant. The results suggest a strong agreement among participants for preferences of location and direction. Size and angle were difficult for users to differentiate. Finally, users performed and perceived two distinct levels of magnitude. We propose recommendations for designing bend gestures with flexible displays.
2013	Control your game-self: effects of controller type on enjoyment, motivation, and personality in game	Whether they are made to entertain you, or to educate you, good video games engage you. Significant research has tried to understand engagement in games by measuring player experience (PX). Traditionally, PX evaluation has focused on the enjoyment of game, or the motivation of players; these factors no doubt contribute to engagement, but do decisions regarding play environment (e.g., the choice of game controller) affect the player more deeply than that? We apply self-determination theory (specifically satisfaction of needs and self-discrepancy represented using the five factors model of personality) to explain PX in an experiment with controller type as the manipulation. Our study shows that there are a number of effects of controller on PX and in-game player personality. These findings provide both a lens with which to view controller effects in games and a guide for controller choice in the design of new games. Our research demonstrates that including self-characteristics assessment in the PX evaluation toolbox is valuable and useful for understanding player experience.
2013	Playing with leadership and expertise: military tropes and teamwork in an arg	Ad-hoc virtual teams often lack tools to formalize leadership and structure collaboration, yet they are often successful. How does this happen? We argue that the emergence of leadership and the development of expertise occurs in the process of taking action and in direct response to a lack of structure. Using a twinned set of eight modality sliders, we examine the interactions of fourteen players in an alternate reality game. We find that players adopted military language and culture to structure and arrange their play. We determine that it is critical to account for the context of play across these modalities in order to design appropriately for effective in-game virtual organizing.
2013	HyperSlides: dynamic presentation prototyping	Presentations are a crucial form of modern communication, yet there is a dissonance between everyday practices with presentation tools and best practices from the presentation literature. We conducted a grounded theory study to gain a better understanding of the activity of presenting, discovering the potential for a more dynamic, automated, and story-centered approach to prototyping slide presentations that are themselves dynamic in their ability to help presenters rehearse and deliver their story. Our prototype tool for dynamic presentation prototyping, which we call HyperSlides, uses a simple markup language for the creation of hierarchically structured scenes, which are algorithmically transformed into hyperlinked slides of a consistent and minimalist style. Our evaluation suggests that HyperSlides helps idea organization, saves authoring time, creates aesthetic layouts, and supports more flexible rehearsal and delivery than linear slides, at the expense of reduced layout control and increased navigation demands.
2013	AutoGami: a low-cost rapid prototyping toolkit for automated movable paper craft	AutoGami is a toolkit for designing automated movable paper craft using the technology of selective inductive power transmission. AutoGami has hardware and software components that allow users to design and implement automated movable paper craft without any prerequisite knowledge of electronics; it also supports rapid prototyping. Apart from developing the toolkit, we have analyzed the design space of movable paper craft and developed a taxonomy to facilitate the design of automated paper craft. AutoGami made consistently strong showings in design workshops, confirming its viability in supporting engagement and creativity as well as its usability in storytelling through paper craft. Additional highlights include rapid prototyping of product design as well as interaction design such as human-robot interactions.
2013	Creativity support for novice digital filmmaking	Machinima is a new form of creative digital filmmaking that leverages the real time graphics rendering of computer game engines. Because of the low barrier to entry, machinima has become a popular creative medium for hobbyists and novices while still retaining borrowed conventions from professional filmmaking. Can novice machinima creators benefit from creativity support tools? A preliminary study shows novices generally have difficulty adhering to cinematographic conventions. We identify and document four cinematic conventions novices typically violate. We report on a Wizard-of-Oz study showing a rule-based intelligent system that can reduce the frequency of errors that novices make by providing information about rule violations without prescribing solutions. We discuss the role of error reduction in creativity support tools.
2013	Mastering the art of war: how patterns of gameplay influence skill in Halo	How do video game skills develop, and what sets the top players apart? We study this question of skill through a rating generated from repeated multiplayer matches called TrueSkill. Using these ratings from 7 months of games from over 3 million players, we look at how play intensity, breaks in play, skill change over time, and other games affect skill. These analyzed factors are then combined to model future skill and games played; the results show that skill change in early matches is a useful metric for modeling future skill, while play intensity explains eventual games played. The best players in the 7-month period, who we call "Master Blasters", have varied skill patterns that often run counter to the trends we see for typical players. The data analysis is supplemented with a 70 person survey to explore how players' self-perceptions compare to the gameplay data; most survey responses align well with the data and provide insight into player beliefs and motivation. Finally, we wrap up with a discussion about hiding skill information from players, and implications for game designers.
2013	Villains, architects and micro-managers: what tabula rasa teaches us about game orchestration	Players of digital games are limited by the constraints of the game's implementation. Players cannot fly a kite, plant a tree or make friends with a dragon if these activities were not coded within the game. Game orchestration relaxes these restrictions by allowing players to create game narratives and settings as the game is being played. This enables players to express their creativity beyond the strictures of the game's implementation. We present Tabula Rasa, a novel game orchestration tool based on an efficient tabletop interface. Based on a study of 20 game orchestration sessions using Tabula Rasa, we identify five behavioural patterns adopted by orchestrators, and four styles of collaborative interaction between orchestrators and players. Finally, we present recommendations for designers of game orchestration systems.
2013	SidePoint: a peripheral knowledge panel for presentation slide authoring	Presentation authoring is an important activity, but often requires the secondary task of collecting the information and media necessary for both slides and speech. Integration of implicit search and peripheral displays into presentation authoring tools may reduce the effort to satisfy not just active needs the author is aware of, but also latent needs that she is not aware of until she encounters content of perceived value. We develop SidePoint, a peripheral panel that supports presentation authoring by showing concise knowledge items relevant to the slide content. We study SidePoint as a technology probe to examine the benefits and issues associated with peripheral knowledge panels for presentation authoring. Our results show that peripheral knowledge panels have the potential to satisfy both types of needs in ways that transform presentation authoring for the better.
2013	Labor dynamics in a mobile micro-task market	The ubiquity of smartphones has led to the emergence of mobile crowdsourcing markets, where smartphone users participate to perform tasks in the physical world. Mobile crowdsourcing markets are uniquely different from their online counterparts in that they require spatial mobility, and are therefore impacted by geographic factors and constraints that are not present in the online case. Despite the emergence and importance of such mobile marketplaces, little to none is known about the labor dynamics and mobility patterns of agents. This paper provides an in-depth exploration of labor dynamics in mobile task markets based on a year-long dataset from a leading mobile crowdsourcing platform. We find that a small core group of workers (
2013	GravitySpace: tracking users and their poses in a smart room using a pressure-sensing floor	We explore how to track people and furniture based on a high-resolution pressure-sensitive floor. Gravity pushes people and objects against the floor, causing them to leave imprints of pressure distributions across the surface. While the sensor is limited to sensing direct contact with the surface, we can sometimes conclude what takes place above the surface, such as users' poses or collisions with virtual objects. We demonstrate how to extend the range of this approach by sensing through passive furniture that propagates pressure to the floor. To explore our approach, we have created an 8 m 2 back-projected floor prototype, termed GravitySpace , a set of passive touch-sensitive furniture, as well as algorithms for identifying users, furniture, and poses. Pressure-based sensing on the floor offers four potential benefits over camera-based solutions: (1) it provides consistent coverage of rooms wall-to-wall, (2) is less susceptible to occlusion between users, (3) allows for the use of simpler recognition algorithms, and (4) intrudes less on users' privacy.
2013	The effect of virtual achievements on student engagement	Badge-based achievement systems are being used increasingly to drive user participation and engagement across a variety of platforms and contexts. Despite positive anecdotal reports, there is currently little empirical evidence to support their efficacy in particular domains. With the recent rapid growth of tools for online learning, an interesting open question for educators is the extent to which badges can positively impact student participation. In this paper, we report on a large-scale ( n > 1000) randomized, controlled experiment measuring the impact of incorporating a badge-based achievement system within an online learning tool. We discover a highly significant positive effect on the quantity of students' contributions, without a corresponding reduction in their quality, as well as on the period of time over which students engaged with the tool. Students enjoyed being able to earn badges, and indicated a strong preference for having them available in the user interface.
2013	A trace-based framework for analyzing and synthesizing educational progressions	A key challenge in teaching a procedural skill is finding an effective progression of example problems that the learner can solve in order to internalize the procedure. In many learning domains, generation of such problems is typically done by hand and there are few tools to help automate this process. We reduce this effort by borrowing ideas from test input generation in software engineering. We show how we can use execution traces as a framework for abstracting the characteristics of a given procedure and defining a partial ordering that reflects the relative difficulty of two traces. We also show how we can use this framework to analyze the completeness of expert-designed progressions and fill in holes. Furthermore, we demonstrate how our framework can automatically synthesize new problems by generating large sets of problems for elementary and middle school mathematics and synthesizing hundreds of levels for a popular algebra-learning game. We present the results of a user study with this game confirming that our partial ordering can predict user evaluation of procedural difficulty better than baseline methods.
2013	Improving digital handoff using the space above the table	Object handoff - that is, passing an object or tool to another person - is an extremely common activity in collaborative tabletop work. On digital tables, object handoff is typically accomplished by sliding them on the table surface - but surface-only interactions can be slow and error-prone, particularly when there are multiple people carrying out multiple handoffs. An alternative approach is to use the space above the table for object handoff; this provides more room to move, but requires above-surface tracking. We have developed two above-the-surface handoff techniques that use simple and inexpensive tracking: a force-field technique that uses a depth camera to determine hand proximity, and an electromagnetic-field technique called ElectroTouch that provides positive indication when people touch hands over the table. We compared the new techniques to three kinds of surface-only handoff (sliding, flicking, and surface-only Force-Fields). The study showed that the above-surface techniques significantly improved both speed and accuracy, and that ElectroTouch was the best technique overall. This work provides designers with practical new techniques for substantially increasing performance and interaction richness on digital tables.
2013	An evaluation of state switching methods for indirect touch systems	Indirect touch systems combine a horizontal touch input surface with a vertical display for output. While this division is ergonomically superior to simple direct-touch displays for many tasks, users are no longer looking at their hands when touching. This requires the system to support an intermediate \'1ctracking\'1d state that lets users aim at objects without triggering a selection, similar to the hover state in mouse-based UIs. We present an empirical analysis of several interaction techniques for indirect touch systems to switch to this intermediate state, and derive design recommendations for incorporating it into such systems.
2013	Improving touch accuracy on large tabletops using predecessor and successor	Touch interfaces provide great flexibility in designing an UI. However, the actual experience is often frustrating due to bad touch recognition. On small systems, we can analyze yaw, roll, and pitch of the finger to increase touch accuracy for a single touch. On larger systems, we need to take additional factors into account as users have more flexibility for their limb posture and need to aim over larger distances. Thus, we investigated how people perform touch sequences on those large touch surfaces. We show that the relative location of the predecessor of a touch has a significant impact on the orientation and position of the touch ellipsis. We exploited this effect on an off-the-shelf touch display and showed that with only minimal preparation the touch accuracy of standard hardware can be improved by at least 7%, allowing better recognition rates or more UI components on the same screen.
2013	Touchbugs: actuated tangibles on multi-touch tables	We present a novel approach to graspable interfaces using Touchbugs, actuated physical objects for interacting with interactive surface computing applications. Touchbugs are active tangibles that are able to move across surfaces by employing vibrating motors and can communicate with camera based multi-touch surfaces using infrared LEDs. Touchbug's embedded inertial sensors and computational capabilities open a new interaction space by providing autonomous capabilities for tangibles that allow goal directed behavior.
2013	Wikipedia classroom experiment: bidirectional benefits of students' engagement in online production communities	Over the last decade, a citizen science movement has tried to engage students, laymen and other non-scientists in the production of science. However, there has been less attention in citizen science projects to use the public to disseminate scientific knowledge. Wikipedia provides a platform to study engagement of citizen scientists in knowledge dissemination. College and university students are especially appropriate members of the public to write science articles, because of the course-work and mentorship they receive from faculty. This paper describes a project to support students' writing of scientific articles in Wikipedia. In collaboration with a scientific association, we involved 640 students from 36 courses in editing scientific articles on Wikipedia. This paper provides details in the design of the program and our quantitative and qualitative approaches to evaluating it. Our results show that the Wikipedia classroom experiment benefits both the Wikipedia community and students. Undergraduate and graduate students substantially improved the scientific content of over 800 articles, at a level of quality indistinguishable from content written by PhD experts. Both students and faculty endorsed the motivational benefits of an authentic writing experience that would be read by thousands of people.
2013	TypeRighting: combining the benefits of handwriting and typeface in online educational videos	Recent years have seen enormous growth of online educational videos, spanning K-12 tutorials to university lectures. As this content has grown, so too has grown the number of presentation styles. Some educators have strong allegiance to handwritten recordings (using pen and tablet), while others use only typed (PowerPoint) presentations. In this paper, we present the first systematic comparison of these two presentation styles and how they are perceived by viewers. Surveys on edX and Mechanical Turk suggest that users enjoy handwriting because it is personal and engaging, yet they also enjoy typeface because it is clear and legible. Based on these observations, we propose a new presentation style, TypeRighting, that combines the benefits of handwriting and typeface. Each phrase is written by hand, but fades into typeface soon after it appears. Our surveys suggest that about 80% of respondents prefer TypeRighting over handwriting. The same fraction of respondents prefer TypeRighting over typeface, for videos in which the handwriting is sufficiently legible.
2013	WorldKit: rapid and easy creation of ad-hoc interactive applications on everyday surfaces	Instant access to computing, when and where we need it, has long been one of the aims of research areas such as ubiquitous computing. In this paper, we describe the WorldKit system, which makes use of a paired depth camera and projector to make ordinary surfaces instantly interactive. Using this system, touch-based interactivity can, without prior calibration, be placed on nearly any unmodified surface literally with a wave of the hand, as can other new forms of sensed interaction. From a user perspective, such interfaces are easy enough to instantiate that they could, if desired, be recreated or modified "each time we sat down" by "painting" them next to us. From the programmer's perspective, our system encapsulates these capabilities in a simple set of abstractions that make the creation of interfaces quick and easy. Further, it is extensible to new, custom interactors in a way that closely mimics conventional 2D graphical user interfaces, hiding much of the complexity of working in this new domain. We detail the hardware and software implementation of our system, and several example applications built using the library.
2013	IllumiRoom: peripheral projected illusions for interactive experiences	IllumiRoom is a proof-of-concept system that augments the area surrounding a television with projected visualizations to enhance traditional gaming experiences. We investigate how projected visualizations in the periphery can negate, include, or augment the existing physical environment and complement the content displayed on the television screen. Peripheral projected illusions can change the appearance of the room, induce apparent motion, extend the field of view, and enable entirely new physical gaming experiences. Our system is entirely self-calibrating and is designed to work in any room. We present a detailed exploration of the design space of peripheral projected illusions and we demonstrate ways to trigger and drive such illusions from gaming content. We also contribute specific feedback from two groups of target users (10 gamers and 15 game designers); providing insights for enhancing game experiences through peripheral projected illusions.
2013	SideWays: a gaze interface for spontaneous interaction with situated displays	Eye gaze is compelling for interaction with situated displays as we naturally use our eyes to engage with them. In this work we present SideWays , a novel person-independent eye gaze interface that supports spontaneous interaction with displays: users can just walk up to a display and immediately interact using their eyes, without any prior user calibration or training. Requiring only a single off-the-shelf camera and lightweight image processing, SideWays robustly detects whether users attend to the centre of the display or cast glances to the left or right. The system supports an interaction model in which attention to the central display is the default state, while "sidelong glances" trigger input or actions. The robustness of the system and usability of the interaction model are validated in a study with 14 participants. Analysis of the participants' strategies in performing different tasks provides insights on gaze control strategies for design of SideWays applications.
2013	High-precision pointing on large wall displays using small handheld devices	Rich interaction with high-resolution wall displays is not limited to remotely pointing at targets. Other relevant types of interaction include virtual navigation, text entry, and direct manipulation of control widgets. However, most techniques for remotely acquiring targets with high precision have studied remote pointing in isolation, focusing on pointing efficiency and ignoring the need to support these other types of interaction. We investigate high-precision pointing techniques capable of acquiring targets as small as 4 millimeters on a 5.5 meters wide display while leaving up to 93 % of a typical tablet device's screen space available for task-specific widgets. We compare these techniques to state-of-the-art distant pointing techniques and show that two of our techniques, a purely relative one and one that uses head orientation, perform as well or better than the best pointing-only input techniques while using a fraction of the interaction resources.
2013	Delivering patients to sacré coeur: collective intelligence in digital volunteer communities	This study examines the information-processing activities of digital volunteers and other connected ICT users in the wake of crisis events. Synthesizing findings from several previous research studies of digital volunteerism, this paper offers a new approach for conceptualizing the activities of digital volunteers, shifting from a focus on organizing to a focus on information movement. Using the lens of distributed cognition, this research describes collective intelligence as transformations of information within a system where cognition is distributed socially across individuals as well as through their tools and resources. This paper demonstrates how digital volunteers, through activities such as relaying, amplifying, verifying, and structuring information, function as a collectively intelligent cognitive system in the wake of disaster events.
2013	StrikeAPose: revealing mid-air gestures on public displays	We investigate how to reveal an initial mid-air gesture on interactive public displays. This initial gesture can serve as gesture registration for advanced operations. We propose three strategies to reveal the initial gesture: spatial division, temporal division and integration. Spatial division permanently shows the gesture on a dedicated screen area. Temporal division interrupts the application to reveal the gesture. Integration embeds gesture hints directly in the application. We also propose a novel initial gesture called Teapot to illustrate our strategies. We report on a laboratory and field study. Our main findings are: A large percentage of all users execute the gesture, especially with spatial division (56%). Users intuitively discover a gesture vocabulary by exploring variations of the Teapot gesture by themselves, as well as by imitating and extending other users' variations.
2013	A longitudinal study of follow predictors on twitter	Follower count is important to Twitter users: it can indicate popularity and prestige. Yet, holistically, little is understood about what factors -- like social behavior, message content, and network structure - lead to more followers. Such information could help technologists design and build tools that help users grow their audiences. In this paper, we study 507 Twitter users and a half-million of their tweets over 15 months. Marrying a longitudinal approach with a negative binomial auto-regression model, we find that variables for message content, social behavior, and network structure should be given equal consideration when predicting link formations on Twitter. To our knowledge, this is the first longitudinal study of follow predictors, and the first to show that the relative contributions of social behavior and mes-sage content are just as impactful as factors related to social network structure for predicting growth of online social networks. We conclude with practical and theoretical implications for designing social media technologies.
2013	Tweeting for class: co-construction as a means for engaging students in lectures	Motivating students to be active learners is a perennial problem in education, and is particularly challenging in lectures where instructors typically prepare content in ad-vance with little direct student participation. We describe our experience using Twitter as a tool for student "co-construction" of lecture materials. Students were required to post a tweet prior to each lecture related to that day's topic, and these tweets -- consisting of questions, examples and reflections -- were incorporated into the lecture slides and notes. Students reported that they found lectures including their tweets in the class slides to be engaging, interactive and relevant, and nearly 90% of them recommended we use our co-construction approach again.
2013	Does slacktivism hurt activism?: the effects of moral balancing and consistency in online activism	In this paper we explore how the decision of partaking in low-cost, low-risk online activism - slacktivism - \'14may affect subsequent civic action. Based on moral balancing and consistency effects, we designed an online experiment to test if signing or not signing an online petition increased or decreased subsequent contribution to a charity. We found that participants who signed the online petition were significantly more likely to donate money to a related charity, demonstrating a consistency effect. We also found that participants who did not sign the petition donated significantly more money to an unrelated charity, demonstrating a moral balancing effect. The results suggest that exposure to an online activism influences individual decision on subsequent civic actions.
2013	On the relation of ordinary gestures to TV screens: general lessons for the design of collaborative interactive techniques	We present an interaction analysis based on ethnographic fieldwork of how physical movements, including gestures, are produced by viewers in front of television screens in a sports bar. Understanding ordinary life and specifically television watching in social situations will benefit the discussion of the potential of gesture techniques for controlling interactive televisions in various locations. Challenges for system design include body movement recognition, since movements can have many different purposes and are directed simultaneously at the screen and co-viewers. Moreover, gestures as elements of conversation are sometimes negotiated and overlapping. Since these ordinary movements are hard to automatically track and analyse, suggested systems might lead to demands on viewers to restrain their accustomed movements and adapt them in ways that might be considered awkward. We also reveal new design opportunities that draw upon the ways viewers' gestures are influenced by ongoing broadcast.
2013	Understanding palm-based imaginary interfaces: the role of visual and tactile cues when browsing	, Imaginary Interfaces are screen-less ultra-mobile interfaces. Previously we showed that even though they offer no visual feedback they allow users to interact spatially, e.g., by pointing at a location on their non-dominant hand. The primary goal of this paper is to provide a deeper understanding of palm-based imaginary interfaces, i.e., why they work. We perform our exploration using an interaction style inspired by interfaces for visually impaired users. We implemented a system that audibly announces target names as users scrub across their palm. Based on this interface, we conducted three studies. We found that (1) even though imaginary interfaces cannot display visual contents, users' visual sense remains the main mechanism that allows users to control the interface, as they watch their hands interact. (2) When we remove the visual sense by blindfolding, the tactile cues of both hands feeling each other in part replace the lacking visual cues, keeping imaginary interfaces usable. (3) While we initially expected the cues sensed by the pointing finger to be most important, we found instead that it is the tactile cues sensed by the palm that allow users to orient themselves most effectively. While these findings are primarily intended to deepen our understanding of Imaginary Interfaces, they also show that eyes-free interfaces located on skin outperform interfaces on physical devices. In particular, this suggests that palm-based imaginary interfaces may have benefits for visually impaired users, potentially outperforming the touchscreen-based devices they use today.
2013	From codes to patterns: designing interactive decoration for tableware	We explore the idea of making aesthetic decorative patterns that contain multiple visual codes. We chart an iterative collaboration with ceramic designers and a restaurant to refine a recognition technology to work reliably on ceramics, produce a pattern book of designs, and prototype sets of tableware and a mobile app to enhance a dining experience. We document how the designers learned to work with and creatively exploit the technology, enriching their patterns with embellishments and backgrounds and developing strategies for embedding codes into complex designs. We discuss the potential and challenges of interacting with such patterns. We argue for a transition from designing 'codes to patterns' that reflects the skills of designers alongside the development of new technologies.
2013	Designing web-connected physical artefacts for the 'aesthetic' of the home	Web-based technologies are often built to capitalize on the flexibility and fluidity that is supported by the internet, with the value of 'access anywhere' underpinning a blurring of boundaries across home and work. Yet the home is well known in HCI to have a unique set of qualities that can use-fully be drawn upon when designing to support domestic life. In this paper we ask what it means to design domestic web-connected technologies, placing the aesthetic and material properties intrinsic to the home and home life at the centre of our design exploration. We present three concepts that were selected and prototyped from a broader process of research-through-design: Tokens of Search provides tangible handles to web resources; Hole in Space connects the home intimately to a remote place; and Manhattan enables the tangible exploration of events in the community, putting the home at the centre. Discussions in the paper consider not only how aesthetics is articulated in the material and digital properties of the artefacts, but also how a consideration of the properties of the home can create a potentially new design space to explore.
2013	Pass the iPad: collaborative creating and sharing in family groups	The increasingly cross-generational use of personal technology portrays families each absorbed in individual devices. Tablets potentially support multi-user working but are currently used as personal devices primarily for consumption, or individual or web-based games. Could tablets support creative co-located groupwork in families and how does such creative work differ from the same task on paper? We designed and evaluated an app requiring individual and group co-creation in families. 262 family groups visiting a science fair played the collaborative drawing game on paper and iPads. Group creations were rated significantly more original and cohesive on iPads than paper. Detailed video analysis of seven family groups showed how tablets support embodiment and use of digital traces, and how the different media sustain individual and shared actions at different stages in the creative process. We sketch out implications for ownership and 'scrap computers': going beyond personally-owned devices and developing collaborative apps to support groupwork with tablets.
2013	Write here, write now!: an experimental study of group maintenance in collaborative writing	Writing documents together using collaborative editing tools has become extremely common with the widespread availability of tools such as Google Docs. The design of such tools, rooted in early CSCW research, has historically been focused on providing awareness of the presence and activities of one's collaborators. Evidence from a recent qualitative study, however, suggests that people are also concerned about how their behaviors -- and they themselves -- will be perceived by others; and take steps to mitigate possible negative perceptions. We present an experimental study of dyads composing documents together, focusing in particular on group maintenance, impression management and relationship-focused behavior. Results suggest that communication is positively related to social relations, but only for synchronous writing in a shared space; the reverse can be true in asynchronous commenting and editing.
2013	Machinima production tools: a vernacular history of a creative medium	In recent years, HCI has shown a rising interest in the creative practices associated with massive online communities, including crafters, hackers, DIY, and other expert amateurs. One strategy for researching creativity at this scale is through an analysis of a community's outputs, including its creative works, custom created tools, and emergent practices. In this paper, we offer one such case study, a historical account of World of Warcraft (WoW) machinima (i.e., videos produced inside of video games), which shows how the aesthetic needs and requirements of video making community coevolved with the community-made creativity support tools in use at the time. We view this process as inhabiting different layers and practices of appropriation, and through an analysis of them, we trace the ways that support for emerging stylistic conventions become built into creativity support tools over time.
2013	Ad-binning: leveraging around device space for storing, browsing and retrieving mobile device content	Exploring information content on mobile devices can be tedious and time consuming. We present Around-Device Binning, or AD-Binning, a novel mobile user interface that allows users to off-load mobile content in the space around the device. We informed our implementation of AD-Binning by exploring various design factors, such as the minimum around-device target size, suitable item selection methods, and techniques for placing content in off-screen space. In a task requiring exploration, we find that AD-Binning improves browsing efficiency by avoiding the minute selection and flicking mechanisms needed for on-screen interaction. We conclude with design guidelines for off screen content storage and browsing.
2013	Revisiting social practices surrounding music	Music shapes our social lives. While previous research has provided a foundational understanding of the social affordances surrounding people's interactions with music, there is a need to update this understanding in light of recent key developments in our digital technological landscape. This paper describes a qualitative study of people's social activities and practices around music in households. It extends previous research by revealing the impact key technologies have on how, where, when, and with who people's interactions surrounding music occur. It also reveals people's creative attempts to design their musical experiences with others through reconfiguring and connecting to various digital technologies and digital platforms in order to pursue more opportunities for communicating, sharing, bonding, and celebrating lives with others.
2013	ARTFul: adaptive review technology for flipped learning	Internet technology is revolutionizing education. Teachers are developing massive open online courses (MOOCs) and using innovative practices such as flipped learning in which students watch lectures at home and engage in hands-on, problem solving activities in class. This work seeks to explore the design space afforded by these novel educational paradigms and to develop technology for improving student learning. Our design, based on the technique of adaptive content review, monitors student attention during educational presentations and determines which lecture topic students might benefit the most from reviewing. An evaluation of our technology within the context of an online art history lesson demonstrated that adaptively reviewing lesson content improved student recall abilities 29% over a baseline system and was able to match recall gains achieved by a full lesson review in less time. Our findings offer guidelines for a novel design space in dynamic educational technology that might support both teachers and online tutoring systems.
2013	Emotions, experiences and usability in real-life mobile phone use	Positive emotional experiences with an interactive product are assumed to lead to good user experience and, ultimately, to product success. However, the path from emotional experiences to product evaluation may not be direct, as emotions fluctuate over time, and some experiences are easier to recall than others. In this study, we examined emotions and experience episodes during real-life mobile phone use over a five-month period. The goal is to understand how emotions and memories are related to overall evaluation of a product: usability, user experience and behavioral intentions. The results show that both emotions and how people remember them had strong unique roles in the overall evaluation of the product. Positive emotions were mostly related to good user experience and negative emotions to low usability. In the early stages of use, users overestimated their positive emotions and seemed to focus on user experience, the importance of usability increased over time.
2013	Stories of the Smartphone in everyday discourse: conflict, tension & instability	As the smartphone proliferates in American society, so too do stories about its value and impact. In this paper we draw on advertisements and news articles to analyze cultural discourse about the smartphone. We highlight two common tropes: one calling for increased technological integration, the other urging individuals to dis-integrate the smartphone from daily life. We examine the idealized subject positions of these two stories and show how both simplistic tropes call on the same overarching values to compel individuals to take opposing actions. We then reflect on the conflicts individuals experience in trying to align and account for their actions in relation to multiple contradictory narratives. Finally, we call for CHI researchers to tell and provoke more complicated stories of technologies and their relationships with values in conversations, publications, and future designs.
2013	Front-camera video recordings as emotion responses to mobile photos shared within close-knit groups	People use social-photography services to tell stories about themselves and to solicit responses from viewers. State of the-art services concentrate on textual comments, "Like" buttons, or similar means for viewers to give explicit feedback, but they overlook other, non-textual means. This paper investigates how emotion responses--as video clips captured by the front camera of a cell phone and used as tags for the individual photo viewed--can enhance photo-sharing experiences for close-knit groups. Our exploration was carried out with a mobile social-photography service called Social Camera. Four user groups (N=19) used the application for two to four weeks. The study's results support the value of using front-camera video recordings to glean emotion response. It supports lightweight phatic social interactions not possible with comments and "Like" buttons. Most users kept sharing emotion responses throughout the study. They typically shared the responses right after they saw a just taken photo received from a remote partner. They used the responses to share their current contexts with others just as much as to convey nuanced feelings about a photo. We discuss the implications for future design and research.
2013	Challenges and opportunities for technology in foreign language classrooms	We present the results of a two-month ethnographic study of three introductory Russian classrooms. Through observation and interviews, we identify several distinct roles played by physical artifacts in the classrooms, such as providing a reference to necessary foreign-language material and serving as props in creative role-play. The range of roles taken on by artifacts and the attitudes students have toward them provide a basis for our discussion about how technology might be more effectively introduced into the socially negotiated environment of the introductory foreign-language classroom. We identify the need to balance between collaborative and personal technology in a stressful, but social, context. Our findings inform a range of roles that technology can undertake in replacing or augmenting existing classroom artifacts.
2013	AnyType: provoking reflection and exploration with aesthetic interaction	AnyType is a mobile application that generates unique typefaces from photographs of shapes that people find in their environment. In keeping with the principles of aesthetic interaction, the design of AnyType supports opportunities for surprise, storytelling, and expression. This paper presents data collected from two observational studies of AnyType. In both studies, we found that people appropriated the application to create highly personalized messages. They found inspiration in unexpected locations, created memories from nuanced details in their lives, and creatively explored the design space provided by the system. Drawing from our observations, we discuss possible roles mobile devices could play in people's personal meaning making, creative process, and discovery, in interaction with elements of their physical environment.
2013	iPhone in vivo: video analysis of mobile device use	Despite the widespread use of mobile devices, details of mobile technology use 'in the wild' have proven difficult to collect. This paper uses video data to gain new insight into the use of mobile computing devices. Our new method combines screen-capture of iPhone use with video recordings from wearable cameras. We use this data to analyse how mobile device use is threaded into other co-present activities, focusing on the use of maps and internet searches. Close analysis reveals novel aspects of gestures on touch screens, how they serve 'double duty' - both as interface gestures but as as resources for ongoing joint action. We go on to describe how users 'walk the blue dot' to orientate themselves, and how searches are occasioned by the local environment. In conclusion, we argue that mobile devices - rather than pushing us away from the world around us - are instead just another thread in the complex tapestry of everyday interaction.
2013	Tables in the wild: lessons learned from a large-scale multi-tabletop deployment	This paper presents the results and experiences of a six-week deployment of multiple digital tabletops in a school. Dillenbourg's orchestration framework was used both to guide the design and analysis of the study. Four themes, which directly relate to the design of the technology for the classroom, out of the 15 orchestration factors are considered. For each theme, we present our design choices, the relevant observations, feedback from teachers and students, and we conclude with a number of lessons learned in the form of design recommendations. The distinguishing factors of our study are its scale (in terms of duration, number of classes, subjects, and teachers), and its 'in-the-wild' character, with the entire study being conducted in a school, led by the teachers, and using teacher-prepared, curriculum-based tasks. Our primary contributions are the analysis of our observations and design recommendations for future multi-tabletop applications designed for and deployed within the classroom. Our analyses and recommendations meaningfully extend HCI's current design understandings of such settings.
2013	Building open bridges: collaborative remixing and reuse of open educational resources across organisations	In this paper we analyse the remixing and reuse of online learning materials offered as Open Educational Resources (OER). We explore the practices that developed as a set of course materials were released as OER from the UK, remixed for a US context by a cross-organisational, cross-cultural team, and then reused in a broad range of educational settings. We analyse the approaches taken during these remixing and reuse activities as novel forms of creative collaboration. As a basis for comparison, we explore similarities and differences with openness in other domains. We identify how openness provoked novel inter-organisational collaboration and forms of ownership; define forms of open practice that need support, and present issues that should be considered in devising and supporting open projects in education and beyond.
2013	Your left hand can do it too!: investigating intermanual, symmetric gesture transfer on touchscreens	This work examines intermanual gesture transfer, i.e., learning a gesture with one hand and performing it with the other. Using a traditional retention and transfer paradigm from the motor learning literature, participants learned four gestures on a touchscreen. The study found that touchscreen gestures transfer, and do so symmetrically. Regardless of the hand used during training, gestures were performed with a comparable level of error and speed by the untrained hand, even after 24 hours. In addition, the form of a gesture, i.e., its length or curvature, was found to have no influence on transferability. These results have important implications for the design of stroke-based gestural interfaces: acquisition could occur with either hand and it is possible to interchange the hand used to perform gestures. The work concludes with a discussion of these implications and highlights how they can be applied to gesture learning and current gestural systems.
2013	The dynamics of younger and older adult's paired behavior when playing an interactive silhouette game	In this paper, we report on the findings of an acute trial in which we evaluate the design of a novel gesture-based game. 60 younger and older players, divided into three separate group-types: (i) Young-Young, (ii) Old-Old, and (iii) Young-Old, took part in the study. The primary aim of this work was to evaluate the communicative and cooperative behavior of same-age and mixed-age pairs, with secondary interests in their perceived ease-of-use of the game. A mixed-method approach was used, comprising of direct observations, a post-game questionnaire and paired interviews. Our results identified noticeable differences between the group-types, with the Young-Old showing more physical cooperation, as compared to the same-age groups. The work elaborates on how the young and old differ in expectations and perceived interaction, and concludes with some recommendations for future research.
2013	NoteVideo: facilitating navigation of blackboard-style lecture videos	Khan Academy's pre-recorded blackboard-style lecture videos attract millions of online users every month. However, current video navigation tools do not adequately support the kinds of goals that students typically have, like quickly finding a particular concept in a blackboard-style lecture video. This paper reports on the development and evaluation of the new NoteVideo and its improved version, NoteVideo+ , systems for identifying the conceptual 'objects' of a blackboard-based video - and then creating a summarized image of the video and using it as an in-scene navigation interface that allows users to directly jump to the video frame where that object first appeared instead of navigating it linearly through time. The research consisted of iteratively implementing the system and then having users perform four different navigation tasks using three different interfaces: Scrubbing, Transcript , and NoteVideo . Results of the study show that participants perform significantly better on all four tasks while using the NoteVideo and its improved version - NoteVideo+ - as compared to others.
2013	Learning and performance with gesture guides	Gesture-based interfaces are becoming more prevalent and complex, requiring non-trivial learning of gesture sets. Many methods for learning gestures have been proposed, but they are often evaluated with short-term recall tests that measure user performance, rather than learning. We evaluated four types of gesture guides using a retention and transfer paradigm common in motor learning experiments and found results different from those typically reported with recall tests. The results indicate that many guide systems with higher levels of guidance exhibit high performance benefits while the guide is being used, but are ultimately detrimental to user learning. We propose an adaptive guide that does not suffer from these drawbacks, and that enables a smooth transition from novice to expert. The results contrasting learning and performance can be explained by the guidance hypothesis . They have important implications for the design and evaluation of future gesture learning systems.
2013	Echoes from the past: how technology mediated reflection improves well-being	As people document more of their lives online, some recent systems are encouraging people to later revisit those recordings, a practice we're calling technology-mediated reflection (TMR). Since we know that unmediated reflection benefits psychological well-being, we explored whether and how TMR affects well-being. We built Echo, a smartphone application for recording everyday experiences and reflecting on them later. We conducted three system deployments with 44 users who generated over 12,000 recordings and reflections. We found that TMR improves well-being as assessed by four psychological metrics. By analyzing the content of these entries we discovered two mechanisms that explain this improvement. We also report benefits of very long-term TMR.
2013	Memorability of pre-designed and user-defined gesture sets	We studied the memorability of free-form gesture sets for invoking actions. We compared three types of gesture sets: user-defined gesture sets, gesture sets designed by the authors, and random gesture sets in three studies with 33 participants in total. We found that user-defined gestures are easier to remember, both immediately after creation and on the next day (up to a 24% difference in recall rate compared to pre-designed gestures). We also discovered that the differences between gesture sets are mostly due to association errors (rather than gesture form errors), that participants prefer user-defined sets, and that they think user-defined gestures take less time to learn. Finally, we contribute a qualitative analysis of the tradeoffs involved in gesture type selection and share our data and a video corpus of 66 gestures for replicability and further analysis.
2013	The challenges and potential of end-user gesture customization	The vast majority of work on understanding and supporting the gesture creation process has focused on professional designers. In contrast, gesture customization by end users' - which may offer better memorability, efficiency and accessibility than pre-defined gestures - has received little attention. To understand the end-user gesture creation process, we conducted a study where 20 participants were asked to: (1) exhaustively create new gestures for an open-ended use case; (2) exhaustively create new gestures for 12 specific use cases; (3) judge the saliency of different touchscreen gesture features. Our findings showed that even when asked to create novel gestures, participants tended to focus on the familiar. Misconceptions about the gesture recognizer's abilities were also evident, and in some cases constrained the range of gestures that participants created. Finally, as a calibration point for future research, we used a simple gesture recognizer ($N) to analyze recognition accuracy of the participants' custom gesture sets: accuracy was 68-88% on average, depending on the amount of training and the customization scenario. We conclude with implications for the design of a mixed-initiative approach to support custom gesture creation.
2013	The power of mobile notifications to increase wellbeing logging behavior	Self-logging is a critical component to many wellbeing systems. However, self-logging often is difficult to sustain at regular intervals over many weeks. We demonstrate the power of passive mobile notifications to increase logging of wellbeing data, particularly food intake, in a mobile health service. Adding notifications increased the frequency of logging from 12% in a one-month, ten-user pilot study without reminders to 63% in the full 60-user study with reminders included. We will discuss the benefits of passive notifications over existing interruptive methods.
2013	Multiple notification modalities and older users	Multimodal interaction can make home care reminder systems more accessible to their users, most of whom are older and/or have sensory impairments. Existing research into the properties of different notification modalities have used younger participants rather than members of the older population at which they are aimed. This paper presents the results of a user study with older adults that examined how different notification modalities affected ( a ) performance in a card matching game and ( b ) how effective the different modalities were at delivering information. Participants were all aged over 50 and notifications were delivered using textual, pictographic, abstract visual, speech, Earcon, Auditory Icon, tactile and olfactory modalities while playing the game. The results showed that older users were influenced by the same factors as younger users, yet there were subjective differences. The implications for the design of multimodal reminder systems for home care are discussed.
2013	Analyzing user-generated youtube videos to understand touchscreen use by people with motor impairments	Most work on the usability of touchscreen interaction for people with motor impairments has focused on lab studies with relatively few participants and small cross-sections of the population. To develop a richer characterization of use, we turned to a previously untapped source of data: YouTube videos. We collected and analyzed 187 non-commercial videos uploaded to YouTube that depicted a person with a physical disability interacting with a mainstream mobile touchscreen device. We coded the videos along a range of dimensions to characterize the interaction, the challenges encountered, and the adaptations being adopted in daily use. To complement the video data, we also invited the video uploaders to complete a survey on their ongoing use of touchscreen technology. Our findings show that, while many people with motor impairments find these devices empowering, accessibility issues still exist. In addition to providing implications for more accessible touchscreen design, we reflect on the application of user-generated content to study user interface design.
2013	The dubuque electricity portal: evaluation of a city-scale residential electricity consumption feedback system	This paper describes the Dubuque Electricity Portal, a city-scale system aimed at supporting voluntary reductions of electricity consumption. The Portal provided each household with fine-grained feedback on its electricity use, as well as using incentives, comparisons, and goal setting to encourage conservation. Logs, a survey and interviews were used to evaluate the user experience of the Portal during a 20-week pilot with 765 volunteer households. Although the volunteers had already made a wide range of changes to conserve electricity prior to the pilot, those who used the Portal decreased their electricity use by about 3.7%. They also reported increased understanding of their usage, and reported taking an array of actions - both changing their behavior and their electricity infrastructure. The paper discusses the experience of the system's users, and describes challenges for the design of ECF systems, including balancing accessibility and security, a preference for time-based visualizations, and the advisability of multiple modes of feedback, incentives and information presentation.
2013	Cultivating energy literacy: results from a longitudinal living lab study of a home energy management system	This paper presents results of a three-year research project focused on the emplacement of Home Energy Management Systems (HEMS) in a living lab setting with seven households. The HEMS used in this study allowed householders to monitor energy consumption both in real-time and in retrospective on the TV and on mobile devices. Contrasting with existing research focused on how technology persuades people to consume less energy, our study uses a grounded approach to analyze HEMS emplacement. As an important result, we present here the issue of 'energy literacy'. Our study reveals that, by using HEMS, participants became increasingly literate in understanding domestic electricity consumption. We discuss the role HEMS played in that process and how the acquired literacy changed energy consumption patterns. We conclude that literacy in energy consumption has value on its own and explain how eco feedback system designs can benefit from this understanding.
2013	At home with agents: exploring attitudes towards future smart energy infrastructures	Energy systems researchers are proposing a broad range of future "smart" energy infrastructures to promote more efficient management of energy resources. This paper considers how consumers might relate to these future smart grids within the UK. To address this challenge we exploited a combination of demonstration and animated sketches to convey the nature of a future smart energy infrastructure based on software agents. Users' reactions suggested that although they felt an obligation to engage with energy issues, they were principally disinterested. Users showed a considerable lack of trust in energy companies raising a dilemma of design. While users might welcome agents to help in engaging with complex energy infrastructures, they had little faith in those that might provide them. This suggests the need to consider how to design software agents to enhance trust in these socio-economic settings.
2013	Direct space-time trajectory control for visual media editing	We explore the design space for using object motion trajectories to create and edit visual elements in various media across space and time. We introduce a suite of pen-based techniques that facilitate fluid stylization, annotation and editing of space-time content such as video, slide presentations and 2D animation, utilizing pressure and multi-touch input. We implemented and evaluated these techniques in DirectPaint, a system for creating free-hand painting and annotation over video.
2013	Everyday activities and energy consumption: how families understand the relationship	Energy consumption is a growing concern and it is important to inform families of their consumption and how they might reduce it. We conducted an interview study that focuses on the existing routines of families and how they currently understand their power and gas consumption based on standard utility bills. We also investigated how this understanding ties to their everyday activities as might be recorded on their calendars. This allowed us to assess calendars as an artifact for energy consumption awareness. Our results show that many people relate changes in energy consumption to high-level effects such as weather and temperature and not necessarily their own everyday activities. Events on calendars may aid this understanding but people do not currently record enough information on their calendars to make a strong tie. This suggests that if calendars are to be used as artifacts to aid energy consumption understanding, digital calendars need to provide support to include more energy-related information, including both activities and patterns of consumption.
2013	PointAssist: assisting individuals with motor impairments	We tested PointAssist , software that assists in pointing tasks by detecting difficulty through a sub-movement analysis and triggering help, with adjustments proposed to personalize the assistance provided to individuals with motor impairments. A within-subjects study with sixteen individuals with fine motor skills impairments resulted in statistically significant effects on accuracy using Friedman's test with ( Χ 2 (1)=6.4, p =.011 in favor of personalized PointAssist compared to no assistance.
2013	Swifter: improved online video scrubbing	Online streaming video systems have become extremely popular, yet navigating to target scenes of interest can be a challenge. While recent techniques have been introduced to enable real-time seeking, they break down for large videos, where scrubbing the timeline causes video frames to skip and flash too quickly to be comprehendible. We present Swifter, a new video scrubbing technique that displays a grid of pre-cached thumbnails during scrubbing actions. In a series of studies, we first investigate possible design variations of the Swifter technique, and the impact of those variations on its performance. Guided by these results we compare an implementation of Swifter to the previously published Swift technique, in addition to the approaches utilized by YouTube and Netfilx. Our results show that Swifter significantly outperforms each of these techniques in a scene locating task, by a factor of up to 48%.
2013	Understanding exergame users' physical activity, motivation and behavior over time	Effective exergames should increase the proportion of time users regularly spend in moderate to vigorous physical activity. There are currently few studies of exergame systems which evaluate the impact on physical activity over time. Those which do, show increases in light intensity exercise which although valuable, do not increase the proportion of moderate to vigorous activity required for optimal health benefits. Furthermore, longitudinal studies to date have encountered a plateau effect in physical activity as the novelty of the game wears off. This paper suggests how exergame designs based on deeper understandings of player motivations could address these problems. We report on longitudinal patterns of users' physical activity, motivations and behaviour when using exergames, based on case studies from a seven week long school based field trial. These new insights, interpreted through Bandura's theory of self efficacy, are of value to designers in the HCI community who wish to motivate users with a range of attitudes towards exercise to undertake regular moderate to vigorous physical activity.
2013	Exploring & designing tools to enhance falls rehabilitation in the home	Falls are the leading cause of accidental injury-related deaths in the elderly; a fall can lead to a loss of independence, and a fear of falling. Rehabilitation programmes involving exercise have proved the most successful way to reduce the risk of falls. However, the limitations of standard care (e.g. booklets) could prevent home users from receiving the full therapeutic benefit that rehabilitation offers. Having consulted users and health experts, we developed games, and visualizations for falls rehabilitation that we believe could potentially overcome the main barriers to effective rehabilitation in the home. In this paper, we describe user studies that we carried out with older adults to evaluate the use of these visual tools versus standard care, both in the laboratory and in the home. Our main findings show that our visualizations and games were able to overcome the major limitations of standard care, and that they were usable and acceptable to the end users.
2013	Make it move: a movement design method of simple standing products based on systematic mapping of torso movements & product messages	Human communication significantly relies on the expressivity of their body movements. Based on these body language experiences, humans tend to extract meanings even from movements of objects. This paper begins with the above human tendencies to create a design method that can help product designers make their products move to communicate. As a research vehicle, we created a robotic torso prototype and utilized it to collaborate with movement experts, and listed up possible expressive movement components. We then built a mapping matrix that links these movements to general product messages. A method which utilizes this mapping matrix was developed to help designers determine a set of effective movements that can communicate specific product messages. Lastly, a design workshop was conducted to identify the usefulness of the proposed method. We expect the procedures and findings of this study to help researchers and designers approach affective user experience through product movement design.
2013	Stroke rehabilitation with a sensing surface	This paper presents a new sensing and interaction environment for post-stroke and upper extremity limb rehabilitation. The device is a combination of camera-based multitouch sensing and a supporting therapeutic software application that advances the treatment, provides feedback, and records a user's progress. The image-based analysis of hand position provided by a Microsoft Surface is used as an input into a tabletop game environment. Tailored image analysis algorithms assess rehabilitative hand movements. Visual feedback is provided in a game context. Experiments were conducted in a sub-acute rehabilitation center. Preliminary user studies with a stroke-afflicted population determined essential design criteria. Hand and wrist sensing, as well as the goals of the supporting game environment, engage therapeutic flexion and extension as defined by consulted physicians. Participants valued personalization of the activity, novelty, reward and the ability to work at their own pace in an otherwise repetitive therapeutic task. A "character" - game element personifying the participant's movement - was uniquely motivating relative to the media available in the typical therapeutic routine.
2013	Information capacity of full-body movements	We present a novel metric for information capacity of full-body movements. It accommodates HCI scenarios involving continuous movement of multiple limbs. Throughput is calculated as mutual information in repeated motor sequences. It is affected by the complexity of movements and the precision with which an actor reproduces them. Computation requires decorrelating co-dependencies of movement features (e.g., wrist and elbow) and temporal alignment of sequences. HCI researchers can use the metric as an analysis tool when designing and studying user interfaces.
2013	Designing action-based exergames for children with cerebral palsy	Children with cerebral palsy (CP) want to play fast-paced action-oriented videogames similar to those played by their peers without motor disabilities. This is particularly true of exergames, whose physically-active gameplay matches the fast pace of action games. But disabilities resulting from CP can make it difficult to play action games. Guidelines for developing games for people with motor disabilities steer away from high-paced action, including recommendations to avoid the need for time-sensitive actions and to keep game pace slow. Through a year-long participatory design process with children with CP, we have discovered that it is in fact possible to develop action-oriented exergames for children with CP at level III on the Gross Motor Function Classification Scale. We followed up the design process with an eight-week home trial, in which we found the games to be playable and enjoyable. In this paper, we discuss the design of these games, and present a set of design recommendations for how to achieve both action-orientation and playability.
2013	Bodily interaction in the dark	In light of the growing interest in designing for new body-movement based interfaces through somaesthetics and somatic awareness, we created a sound-based interaction using the Microsoft Kinect device, which is performed in the dark. The absence of visual feedback led participants to deeply focus on the movement of their bodies, and to have a different awareness of their bodies and the space around them. The notable difference between performing this interaction in light and dark suggests that non-visual based interfaces are a fruitful area to explore in somaesthetic interaction.
2013	4 design themes for skateboarding	Interactive technology can support exertion activities, with many examples focusing on improving athletic performance. We see an opportunity for technology to also support extreme sports such as skateboarding, which often focus primarily on the experience of doing tricks rather than on athletic performance. However, there is little knowledge on how to design for such experiences. In response, we designed 12 basic skateboarding prototypes inspired by skateboarding theory. Using an autoethnographical approach, we skated with each of these and reflected on our experiences in order to derive four design themes : location of feedback in relation to the skater's body, timing of feedback in relation to peaks in emotions after attempts, aspects of the trick emphasized by feedback, and aesthetic fittingness of feedback. We hope our work will guide designers of interactive systems for skateboarding, and extreme sports in general, and will therefore further our understanding of how to design for the active human body.
2013	Pt Viz: towards a wearable device for visualizing knee rehabilitation exercises	We present a wearable sensory display for visualizing knee rehabilitation as part of an in-home physical therapy program. Currently, patients undergoing knee rehabilitation have limited ways of assessing exercise form and extent of movement at home. To address this issue, we developed an exploratory wearable electronic prototype to visualize knee bend. We evaluated the device with physical therapy patients to get feedback on the design and to help us understand some of the challenges they face. We discovered that our current design is better suited for patients recovering from surgery as opposed to patients with chronic conditions.
2013	Direct manipulation video navigation in 3D	Direct Manipulation Video Navigation (DMVN) systems allow a user to navigate a video by dragging an object along its motion trajectory. These systems have been shown effective for space-centric video browsing. Their performance, however, is often limited by temporal ambiguities in a video with complex motion, such as recurring motion, self-intersecting motion, and pauses. The ambiguities come from reducing the 3D spatial-temporal motion ( x, y, t ) to the 2D spatial motion ( x, y ) in visualizing the motion and dragging the object. In this paper, we present a 3D DMVN system that maps the spatial-temporal motion ( x, y, t ) to 3D space ( x, y, z ) by mapping time t to depth z , visualizes the motion and video frame in 3D, and allows to navigate the video by spatial-temporally manipulating the object in 3D. We show that since our 3D DMVN system preserves all the motion information, it resolves the temporal ambiguities and supports intuitive navigation on challenging videos with complex motion.
2013	Brainstorm, Chainstorm, Cheatstorm, Tweetstorm: new ideation strategies for distributed HCI design	In this paper we describe the results of a design-driven study of collaborative ideation. Based on preliminary findings that identified a novel digital ideation paradigm we refer to as chainstorming, or online communication brainstorming, two exploratory studies were performed. First, we developed and tested a distributed method of ideation we call cheatstorming, in which previously generated brainstorm ideas are delivered to targeted local contexts in response to a prompt. We then performed a more rigorous case study to examine the cheatstorming method and consider its possible implementation in the context of a distributed online ideation tool. Based on observations from these studies, we conclude with the somewhat provocative suggestion that ideation need not require the generation of new ideas. Rather, we present a model of ideation suggesting that its value has less to do with the generation of novel ideas than the cultural influence exerted by unconventional ideas on the ideating team. Thus brainstorming is more than the pooling of "invented" ideas, it involves the sharing and interpretation of concepts in unintended and (ideally) unanticipated ways.
2013	Panoinserts: mobile spatial teleconferencing	We present PanoInserts: a novel teleconferencing system that uses smartphone cameras to create a surround representation of meeting places. We take a static panoramic image of a location into which we insert live videos from smartphones. We use a combination of marker- and image-based tracking to position the video inserts within the panorama, and transmit this representation to a remote viewer. We conduct a user study comparing our system with fully-panoramic video and conventional webcam video conferencing for two spatial reasoning tasks. Results indicate that our system performs comparably with fully-panoramic video, and better than webcam video conferencing in tasks that require an accurate surrounding representation of the remote space. We discuss the representational properties and usability of varying video presentations, exploring how they are perceived and how they influence users when performing spatial reasoning tasks.
2013	The effect of time-based cost of error in target-directed pointing tasks	One of the fundamental operations in today's user interfaces is pointing to targets, such as menus, buttons, and text. Making an error when selecting those targets in real-life user interfaces often results in some cost to the user. However, the existing target-directed pointing models do not consider the cost of error when predicting task completion time. In this paper, we present a model based on expected value theory that predicts the impact of the error cost on the user's completion time for target-directed pointing tasks. We then present a target-directed pointing user study, which results show that time-based costs of error significantly impact the user's performance. Our results also show that users perform according to an expected completion time utility function and that optimal performance computed using our model gives good prediction of the observed task completion times.
2013	Fashionable shape switching: explorations in outfit-centric design	We present a design exercise illustrating how fashion practices and the fashion design process can be used to create new opportunities both in the mobile domain and in product design, as well as in wearable computing. We investigate the concept of outfit-centric design by extending the support for social and visual interaction with digital devices beyond the currently available shells and stickers, and drawing on the ways in which people vary their dress ensembles. We designed a set of mock-up samples in a local fashion style, as a first step in understanding possible applications of the emerging technology of organic interfaces. Initial user feedback shows how fashion-conscious participants creatively experimented with the set's variations of shape and color in outfits created from their personal wardrobes, which revealed the importance of the objects' size and location on the body. It also points out that a lack of integration with the fashion system's processes reduces the attractiveness of the samples.
2013	Body-centric design space for multi-surface interaction	We introduce BodyScape, a body-centric design space that allows us to describe, classify and systematically compare multi-surface interaction techniques, both individually and in combination. BodyScape reflects the relationship between users and their environment, specifically how different body parts enhance or restrict movement within particular interaction techniques and can be used to analyze existing techniques or suggest new ones. We illustrate the use of BodyScape by comparing two free-hand techniques, on-body touch and mid-air pointing, first separately, then combined. We found that touching the torso is faster than touching the lower legs, since it affects the user's balance; and touching targets on the dominant arm is slower than targets on the torso because the user must compensate for the applied force.
2013	MotionMA: motion modelling and analysis by demonstration	Particularly in sports or physical rehabilitation, users have to perform body movements in a specific manner for the exercises to be most effective. It remains a challenge for experts to specify how to perform such movements so that an automated system can analyse further performances of it. In a user study with 10 participants we show that experts' explicit estimates do not correspond to their performances. To address this issue we present MotionMA , a system that: (1) automatically extracts a model of movements demonstrated by one user, e.g. a trainer, (2) assesses the performance of other users repeating this movement in real time, and (3) provides real-time feedback on how to improve their performance. We evaluated the system in a second study in which 10 other participants used the system to demonstrate arbitrary movements. Our results demonstrate that MotionMA is able to extract an accurate movement model to spot mistakes and variations in movement execution.
2013	Putting things in focus: establishing co-orientation through video in context	In collaborative video communication systems, establishing co-orientation around physical objects, virtual objects and people is a critical requirement. This is problematic as the technical limitations of video fractures the display of conduct in the connected environments. We present the results of a study of one collaborative system, CamBlend, which aims to alleviate some of these problems by using screen based pointing tools to both physical spaces and virtual resources. We report on how participants achieved co-orientation when using this system. We relate these findings to previous research into the fractured ecologies of collaborative spaces, describing how the form and nature of fractures in CamBlend differ from earlier reported work.
2013	FFitts law: modeling finger touch with fitts' law	Fitts' law has proven to be a strong predictor of pointing performance under a wide range of conditions. However, it has been insufficient in modeling small-target acquisition with finger-touch based input on screens. We propose a dual-distribution hypothesis to interpret the distribution of the endpoints in finger touch input. We hypothesize the movement endpoint distribution as a sum of two independent normal distributions. One distribution reflects the relative precision governed by the speed-accuracy tradeoff rule in the human motor system, and the other captures the absolute precision of finger touch independent of the speed-accuracy tradeoff effect. Based on this hypothesis, we derived the FFitts model - an expansion of Fitts' law for finger touch input. We present three experiments in 1D target acquisition, 2D target acquisition and touchscreen keyboard typing tasks respectively. The results showed that FFitts law is more accurate than Fitts' law in modeling finger input on touchscreens. At 0.91 or a greater R 2 value, FFitts' index of difficulty is able to account for significantly more variance than conventional Fitts' index of difficulty based on either a nominal target width or an effective target width in all the three experiments.
2013	HomeProxy: exploring a physical proxy for video communication in the home	HomeProxy is a research prototype that explores supporting video communication in the home among distributed family members through a physical proxy. It leverages a physical artifact dedicated to representing remote family members to make it easier to share activities with them. HomeProxy combines a form factor designed for the home environment with a "no-touch" user experience and an interface that responsively transitions between recorded and live video messages. We designed and implemented a prototype and conducted a pilot study with eight pairs of users. Our study demonstrated the challenges of a no-touch interface and the promise of offering quick video messaging in the home.
2013	LongPad: a touchpad using the entire area below the keyboard of a laptop computer	In this paper, we explore the possibility of a long touchpad that utilizes the entire area below the keyboard of a laptop computer. An essential prerequisite for such a touchpad is a robust palm rejection method, which we satisfy using a proximity-sensing touchpad. We developed LongPad, a proximity-sensing optical touchpad that is as wide as a laptop keyboard, and implemented a palm rejection algorithm that utilizes proximity images from LongPad. In a user study conducted, we observed that LongPad rejected palm touches almost perfectly while participants were repeating typing and pointing tasks. We also summarize the new design space enabled by LongPad and demonstrate a few of the interaction techniques it facilitates.
2013	HACHIStack: dual-layer photo touch sensing for haptic and auditory tapping interaction	We present a novel photo touch sensing architecture, HACHIStack. It can measure the approaching velocity of an object and predict its contact time with the touch screen using two optical sensing layers above the surface. The photo sensing layers form three unique capabilities: high-speed sampling, velocity acquisition, and contact time prediction. This work quantitatively examines these capabilities through two laboratory experiments, and confirms that the capabilities of HACHIStack are sufficient for multimodal interaction, in particular, touch-based interaction with haptic enhancement. We then present three applications with HACHIStack: 1) chromatic percussions (xylophone and glockenspiel) with haptic feedback; 2) no-delay haptic feedback with the sensation of tapping on various simulated materials (e.g., rubber, wood and aluminum); and 3) a virtual piano instrument that allows players to perform weak and strong strokes by changing the tapping velocity.
2013	GaussBits: magnetic tangible bits for portable and occlusion-free near-surface interactions	We present GaussBits , which is a system of the passive magnetic tangible designs that enables 3D tangible interactions in the near-surface space of portable displays. When a thin magnetic sensor grid is attached to the back of the display, the 3D position and partial 3D orientation of the GaussBits can be resolved by the proposed bi-polar magnetic field tracking technique. This portable platform can therefore enrich tangible interactions by extending the design space to the near-surface space. Since non-ferrous materials, such as the user's hand, do not occlude the magnetic field, interaction designers can freely incorporate a magnetic unit into an appropriately shaped non-ferrous object to exploit the metaphors of the real-world tasks, and users can freely manipulate the GaussBits by hands or using other non-ferrous tools without causing interference. The presented example applications and the collected feedback from an explorative workshop revealed that this new approach is widely applicable.
2013	Swiss-cheese extended: an object recognition method for ubiquitous interfaces based on capacitive proximity sensing	Swiss-Cheese Extended proposes a novel real-time method for recognizing objects with capacitive proximity sensors. Applying this technique to ubiquitous user interfaces, it is possible to detect the 3D-position of multiple human hands in different configurations above a surface that is equipped with a small number of sensors. The retrieved object configurations can significantly improve a user's interaction experience or an application's execution context, for example by detecting multi-hand zoom and rotation gestures or recognizing a grasping hand. We emphasize the broad applicability of the proposed method with a study of a multi-hand gesture recognition device.
2013	Sublimate: state-changing virtual and physical rendering to augment interaction with shape displays	Recent research in 3D user interfaces pushes towards immersive graphics and actuated shape displays. Our work explores the hybrid of these directions, and we introduce sublimation and deposition , as metaphors for the transitions between physical and virtual states. We discuss how digital models, handles and controls can be interacted with as virtual 3D graphics or dynamic physical shapes, and how user interfaces can rapidly and fluidly switch between those representations. To explore this space, we developed two systems that integrate actuated shape displays and augmented reality (AR) for co-located physical shapes and 3D graphics. Our spatial optical see-through display provides a single user with head-tracked stereoscopic augmentation, whereas our handheld devices enable multi-user interaction through video seethrough AR. We describe interaction techniques and applications that explore 3D interaction for these new modalities. We conclude by discussing the results from a user study that show how freehand interaction with physical shape displays and co-located graphics can outperform wand-based interaction with virtual 3D graphics.
2013	Watchit: simple gestures and eyes-free interaction for wristwatches and bracelets	We present WatchIt, a prototype device that extends interaction beyond the watch surface to the wristband, and two interaction techniques for command selection and execution. Because the small screen of wristwatch computers suffers from visual occlusion and the fat finger problem, we investigated the use of the wristband as an available interaction resource. Not only does WatchIt use a cheap, energy efficient and invisible technology, but it involves simple, basic gestures that allow good performance after little training, as suggested by the results of a pilot study. We propose a novel gesture technique and an adaptation of an existing menu technique suitable for wristband interaction. In a user study, we investigated their usage in eyes-free contexts, finding that they perform well. Finally, we present techniques where the bracelet is used in addition to the screen to provide precise continuous control over list scrolling. We also report on a preliminary survey of traditional and digital jewelry that points to the high frequency of watches and bracelets in both genders and gives a sense of the tasks people feel like performing on such devices.
2013	Can we beat the mouse with MAGIC?	MAGIC pointing techniques combine eye tracking with manual input. Since the mouse performs exceptionally well in a desktop setting, previous research on MAGIC pointing either resulted in minor improvements, or the techniques were applied to alternative devices or environments. We design Animated MAGIC, a novel, target-agnostic MAGIC pointing technique, for the specific goal of beating the mouse in a desktop setting. To improve the eye-tracking accuracy, we develop a dynamic local calibration method that uses each selection as a local calibration point. We compare Animated MAGIC to mouse-only and Conservative MAGIC, one of the two original MAGIC pointing methods, in a Fitts' Law experiment. We conduct a user questionnaire to evaluate the usability of the interaction methods. Results suggest that Dynamic Local Calibration improves eye-tracking accuracy and, consequently, MAGIC pointing performance. Powered with Dynamic Local Calibration, Animated MAGIC outperformed mouse-only by 8% in terms of throughput. Both MAGIC pointing methods reduced the amount of hand movement by more than half.
2013	Reasons to question seven segment displays	Seven segment number displays are ubiquitous and popular. They are simple and familiar. They seem to make economic sense, and with only seven segments they require little wiring and electronics to support. They are cheap to buy and cheap to use; they make seemingly effective and unproblematic products. This paper illustrates many examples of problematic uses of seven segment displays that could have been avoided. More generally, the paper raises design questions and some solutions to be considered when designing numerical displays, and certainly before uncritically using seven segment displays. Although there are markets and applications where cost may be an overriding consideration, for safety critical and other dependable types of use (including general purpose devices that may sometimes be used for critical tasks) more legible alternatives than standard seven segment displays should be preferred.
2013	How low can you go?: human limits in small unidirectional mouse movements	Computer mouse sensors keep increasing in resolution. The smallest displacement they can detect gets smaller, but little is known on our ability to control such small movements. Small target acquisition has been previously tackled, but the findings do not apply to the problem of finding the useful resolution of a user with a mouse, which corresponds to the smallest displacement (s)he can reliably produce with that device. We detail this definition and provide an associated experimental protocol to measure it. We then report on the results of a study suggesting that high-end mice are not likely to be used to their full potential. We further comment on the different strategies used by participants to acheive best performance, and derive implications for user interfaces.
2013	Design metaphors for procedural content generation in games	Procedural content generation (PCG), the algorithmic creation of game content with limited or indirect user input, has much to offer to game design. In recent years, it has become a mainstay of game AI, with significant research being put towards the investigation of new PCG systems, algorithms, and techniques. But for PCG to be absorbed into the practice of game design, it must be contextualised within design-centric as opposed to AI or engineering perspectives. We therefore provide a set of design metaphors for understanding potential relationships between a designer and PCG. These metaphors are: tool, material, designer , and domain expert . By examining PCG through these metaphors, we gain the ability to articulate qualities, consequences, affordances, and limitations of existing PCG approaches in relation to design. These metaphors are intended both to aid designers in understanding and appropriating PCG for their own contexts, and to advance PCG research by highlighting the assumptions implicit in existing systems and discourse.
2013	Prototyping in PLACE: a scalable approach to developing location-based apps and games	The rising popularity of location-based applications and games (LBAGs) that break spatial, temporal, and social boundaries creates new challenges for designers. This paper introduces PLACE, an iterative, mixed-fidelity approach to Prototyping Location, Activities, Collective experience, and Experience over time in LBAGs. PLACE consists of 6 design principles: start small and scale up the fidelity, treat participants as co-designers, test in a representative space, focus on activities more than interfaces, respect authentic social experience, and represent time authentically. The effectiveness of PLACE was evaluated by prototyping Floracaching, a geocaching game for citizen science. This revealed the types of insights that PLACE provides, best practices for implementing PLACE, and how PLACE com-pares to other prototyping methods.
2013	SimMed: combining simulation and interactive tabletops for medical education	A large body of work asserts that interactive tabletops are well suited for group work, and numerous studies have examined these devices in educational contexts. However, few of the described systems support simulations for collaborative learning, and none of them explicitly address immersion. We present SimMed, a system allowing medical students to collaboratively diagnose and treat a virtual patient using an interactive tabletop. The hybrid user interface combines elements of virtual reality with multitouch input. The paper delineates the development process of the system and rationale behind a range of interface design decisions. Thereby, the role of realism in gaining procedural knowledge is discussed - in particular, the interplay between realism, immersion and training goals. We implemented several medical test cases and evaluated our approach with a user study that suggests the great potential of the system. Results show a high level of immersion, cooperation and engagement by the students.
2013	Designing reusable alternate reality games	Successful Alternate Reality Games (ARGs), such as The Lost Experience, I Love Bees and Urgent EVOKE have solicited thousands of active participants and, often, millions of spectators from around the world. ARGs require significant resources not only in terms of initial design, but also in implementation, since live, dynamic interplay between players and designers is an inherent aspect of their interactive storylines. This paper outlines a novel design framework for creating reusable ARGs that will help extend the lifespan of ARGs and allow them to permeate new domains such as education. The framework includes three key reusable design objectives (replayability, adaptability, extensibility), each of which can be enacted at different levels of depth. We also identify barriers to reusable ARGs and design strategies for overcoming those barriers, drawing upon ARG designer interviews and existing ARGs.
2013	How does it play better?: exploring user testing and biometric storyboards in games user research	Improving game design is a hard task. Few methods are available in games user research (GUR) to test formally how game designs work for players. In particular, the usefulness of user tests (UTs) for game designers has not been fully studied in the CHI community. We propose a novel GUR method called Biometric Storyboards (BioSt) and present a study demonstrating how a Classic UT and a BioSt UT both help designers create a better gameplay experience. In addition, we show that BioSt can help designers deliver significantly better visuals, more fun, and higher gameplay quality than designing without UTs and that classic UTs do not provide this significant advantage. Our interviews support the idea that BioSt provides more nuanced game design improvement. The design implication is that a game designed with the BioSt method will result in high gameplay quality.
2013	Imaging the body: embodied vision in minimally invasive surgery	Recent years have seen the possibilities of new imaging and interaction technologies for minimally invasive surgery such as touchless interaction and high definition renderings of three-dimensional anatomy. With this paper we take a step back to review the historical introduction and assimilation of imaging technologies in the surgical theatre in parallel with the productive and cross-referential nature of surgical practice and image use. We present findings from a field study of image use during neurosurgery where we see that the work to see medical images is highly constructed and embodied with the action of manipulating the body. This perspective lends itself to a discussion of the directions for new imaging interaction technologies.
2013	An interactive belt-worn badge with a retractable string-based input mechanism	In this paper we explore a new type of wearable computing device, an interactive identity badge. An embedded LCD presents dynamic information to the wearer and interaction is facilitated by sensing movement of the retractable string which attaches the unit to the wearer's belt. This form-factor makes it possible to interact using a single hand, providing lightweight and immediate access to a variety of information when it's not convenient to pick up, unlock and interact directly with a device like a smartphone. In this paper we present our prototype interactive badge, demonstrate the underlying technology and describe a number of usage scenarios and interaction techniques
2013	NailDisplay: bringing an always available visual display to fingertips	This work presents a novel and always-available nail mounted display known as NailDisplay . The proposed display augments the use of a finger by allowing for always-available visual feedback owing to its fast accessibility and binding user controls with the display, i.e. what you control is what you see (through the display). Potential benefits of NailDisplay are demonstrated in three applications: from displaying to combining it with user controls. In the first application, NailDisplay can reveal what is occluded under a finger touch, making it a solution to operate small UI elements. In the second application, NailDisplay is complementary to an imaginary interface, helping users to learn an imaginary interface ( e.g. , on the users' arms) and allowing them to reassure the interface when their memory of it becomes unclear. In the third application, NailDisplay is integrated with rich finger interactions, such as swiping in the air. We also report users' feedbacks gathered from an explorative user study.
2013	A matter of life and death: practical and ethical constraints in the development of a mobile verbal autopsy tool	Verbal autopsy (VA) involves interviewing relatives of the deceased to identify the probable cause of death and is typically used in settings where there is no official system for recording deaths or their causes. Following the interview, physician assessment to determine probable cause can take several years to complete. The World Health Organization (WHO) recognizes that there is a pressing need for a mobile device that combines direct data capture and analysis if this technique is to become part of routine health surveillance. We conducted a field test in rural South Africa to evaluate a mobile system that we designed to meet WHO requirements (namely, simplicity, feasibility, adaptability to local contexts, cost-effectiveness and program relevance). If desired, this system can provide immediate feedback to respondents about the probable cause of death at the end of a VA interview. We assessed the ethical implications of this technological development by interviewing all the stakeholders in the VA process (respondents, fieldworkers, physicians, population scientists, data managers and community engagement managers) and highlight the issues that this community needs to debate and resolve.
2013	I can do text analytics!: designing development tools for novice developers	Text analytics, an increasingly important application domain, is hampered by the high barrier to entry due to the many conceptual difficulties novice developers encounter. This work addresses the problem by developing a tool to guide novice developers to adopt the best practices employed by expert developers in text analytics and to quickly harness the full power of the underlying system. Taking a user centered task analytical approach, the tool development went through multiple design iterations and evaluation cycles. In the latest evaluation, we found that our tool enables novice developers to develop high quality extractors on par with the state of art within a few hours and with minimal training. Finally, we discuss our experience and lessons learned in the context of designing user interfaces to reduce the barriers to entry into complex domains of expertise.
2013	Authoring personal histories: exploring the timeline as a framework for meaning making	It has been argued that technologies for 'memory' should be designed to support creativity and meaning building, rather than the passive capture of cues for remembering [25]. We report findings from a study inspired by this insight, in which older people made personal digital timelines using a new tool called Project Greenwich. We explore how the constraints of the timeline metaphor offer a framework for authoring, and examine how timelines can be used to underpin meaning building in relation to personal content. We highlight the importance of making, this being a vehicle for connecting with others in the present, and a potential means of emphasizing those elements of the past felt to be most salient when looking back.
2013	Debugging support for end user mashup programming	Programming for the web can be an intimidating task, particularly for non-professional ("end-user") programmers. Mashup programming environments attempt to remedy this by providing support for such programming. It is well known, however, that mashup programmers create applications that contain bugs. Furthermore, mashup programmers learn from examples and reuse other mashups, which causes bugs to propagate to other mashups. In this paper we classify the bugs that occur in a large corpus of Yahoo! Pipes mashups. We describe support we have implemented in the Yahoo! Pipes environment to provide automatic error detection techniques that help mashup programmers localize and correct these bugs. We present the results of a think-aloud study comparing the experiences of end-user mashup programmers using and not using our support. Our results show that our debugging enhancements do help these programmers localize and correct bugs more effectively and efficiently.
2013	How groups of users associate wireless devices	Group association, the process of connecting a group of devices, opens up new opportunities for users to spontaneously share resources. Research has shown numerous techniques and protocols for group association; however, what people intuitively do to associate a group of devices remains an open question. We contribute a study of eliciting device association techniques from groups of non-technical people. In all, we collected and analysed 496 techniques from 61 participants. Our results show that mobility and physicality of devices influence how people perceive groups association. We present a complete set of user-defined techniques with subjective ratings and popularity scores. We examined people's rationale and the effects of different device form factors. We analysed the techniques based on the roles that users assume with respect to device association. Our findings draw out insights from the perspective of users for design of group association.
2013	Designing for the living room: long-term user involvement in a living lab	Living Labs provide a research infrastructure for long-term user involvement in Participatory Design processes. Users take part in software co-creation during context analysis, for concept development, reflecting on early-stage prototypes and evaluations in the field. In this paper we describe lessons learned from our Living Lab in the area of home entertainment, with 27 participants from 16 households, over a 2.5 year period. We show that this kind of long-term participation of users involves various challenges over the lifetime of the project. We highlight several aspects that need to be considered carefully when setting up such a Living Lab, concerning the selection of participants, maintenance of participants' motivation, establishment of a trust relationship, and the coordination of collaboration.
2013	Leaving the wild: lessons from community technology handovers	As research increasingly turns to work 'in the wild' to design and evaluate technologies under real-world conditions, little consideration has been given to what happens when research ends. In many cases, users are heavily involved in the design process and encouraged to integrate the resulting technologies into their lives before they are withdrawn, while in some cases technologies are being left in place after research concludes. Often, little is done to assess the impact and legacy of these deployments. In this paper, we return to two examples in which we designed technologies with the involvement of communities and examine what steps were taken to ensure their long-term viability and what happened following the departure of researchers. From these examples, we provide guidelines for planning and executing technology handovers when conducting research with communities.
2013	Use of an agile bridge in the development of assistive technology	Engaging with end users in the development of assistive technologies remains one of the major challenges for researchers and developers in the field of accessibility and HCI. Developing usable software systems for people with complex disabilities is problematic, software developers are wary of using user-centred design, one of the main methods by which usability can be improved, due to concerns about how best to work with adults with complex disabilities, in particular Severe Speech and Physical Impairments (SSPI) and how to involve them in research. This paper reports on how the adoption of an adapted agile approach involving the incorporation of a user advocate on the research team helped in meeting this challenge in one software project and offers suggestions for how this could be used by other development teams.
2013	MultiNet: reducing interaction overhead in domestic wireless networks	We present MultiNet, a novel method for securely associating devices with a domestic wireless network. We show that MultiNet has usability benefits over currently deployed commercial solutions while being backwards compatible with existing devices. MultiNet reduces the interaction overhead of secure association by focusing on users' interactions rather than the network's requirements. This leads to a novel architectural arrangement of the home network infrastructure: the network is dynamically re-configured to accept each pre-configured device, rather than the current norm where each device is configured to be acceptable to the pre-configured network. Assuming devices are pre-configured for a unique, device-specific network name and passphrase, MultiNet constructs an out-of-band visual channel via an intermediary network controller device to convey the device's configuration to the network. This makes the interaction to join a device to the wireless network lightweight and identical across all devices, considerably reducing the interaction overheads for users.
2013	Codeable objects: computational design and digital fabrication for novice programmers	The combination of computational design and digital fabrication offers many exciting possibilities for art, design, and creative expression. We seek to make computational design accessible by developing tools that allow novices to use programming and digital fabrication to produce personal and functional objects. In this paper, we describe our development of Codeable Objects, a preliminary computational-design programing tool developed to work in conjunction with digital-fabrication machines. We also present our evaluation of the tool based on a set of user studies in which people built computationally generated crafts, clothing, and accessories. These studies illuminated the viability (and challenges) of engaging novice programmers through design and digital fabrication, and provide a platform for future work in developing programming tools to support personal expression.
2013	Designing with traces	This paper draws on new materialist perspectives to introduce the analytic category of "material traces" to the field of human-computer interaction (HCI). Material traces reveal the dynamic and evocative nature of form by concretizing a unique location in time and space. Traces of skill, use, and time, for example, are valued for their emotional resonance in addition to the pragmatic goals in which they are embedded. Using this category, we develop a framework for design pedagogy that offers the lenses of attributes, entanglements, and trajectories as tools for gaining critical purchase on the objects produced. Mobilizing this framework within a classroom, design students envision poignant relationships to the non-human, engaged physics learning, and opportunities for reflection around breakage and repair. These design examples reveal how the category of material traces comes alive in practice and pedagogy. We end by discussing how this study of traces points to new opportunities for critical reflection in HCI.
2013	Tactile perceptions of digital textiles: a design research approach	Current interactive media presentations of textiles provide an impoverished communication of their 'textile hand', that is their weight, drape, how they feel to touch. These are complex properties experienced through the visual, tactile, auditory and proprioceptive senses and are currently lost when textile materials are presented in interactive video. This paper offers a new perspective from which the production of multi-touch interactive video representations of the tactile qualities of materials is considered. Through an understanding of hand properties of textiles and how people inherently touch and handle them, we are able to develop methods to animate and bring these properties alive using design methods. Observational studies were conducted, noting gestures consumers used to evaluate textile hand. Replicating the appropriate textile deformations for these gestures in interactive video was explored as a design problem. The resulting digital textile swatches and their interactive behavior were then evaluated for their ability to communicate tactile qualities similar to those of the real textiles.
2013	Talking about tactile experiences	A common problem with designing and developing applications with tactile interfaces is the lack of a vocabulary that allows one to describe or communicate about haptics. Here we present the findings from a study exploring participants' verbalizations of their tactile experiences across two modulated tactile stimuli (16Hz and 250Hz) related to two important mechanoreceptors in the human hand. The study, with 14 participants, applied the explicitation interview technique to capture detailed descriptions of the diachronic and synchronic structure of tactile experiences. We propose 14 categories for a human-experiential vocabulary based on the categorization of the findings and tie them back to neurophysiological and psychophysical data on the human hand. We finally discuss design opportunities created through this experiential understanding in relation to the two mechanoreceptors.
2013	Looking past yesterday's tomorrow: using futures studies methods to extend the research horizon	Doing research is, in part, an act of foresight. Even though it is not explicit in many projects, we especially value research that is still relevant five, ten or more years after it is completed. However, published research in the field of interactive computing (and technology research in general) often lacks evidence of systematic thinking about the long-term impacts of current trends. For example, trends on an exponential curve change much more rapidly than intuition predicts. As a result, research may accidentally emphasize near-term thinking. When thinking about the future is approached systematically, we can critically examine multiple potential futures, expand the set of externalities under consideration, and address both negative and positive forecasts of the future. The field of Futures Studies provides methods that can support analysis of long-term trends, support the identification of new research areas and guide design and evaluation. We survey methods for futuristic thinking and discuss their relationship to Human Computer Interaction. Using the sustainability domain an example, we present a case study of a Futures Studies approach - the Delphi Method. We show how Futures Studies can be incorporated into Human Computer Interaction and highlight future work such as rethinking the role of externalities in the validation process.
2013	The design and field observation of a haptic notification system for timing awareness during oral presentations	To moderate oral presentations a chair must manage time, and communicate time parameters to speakers through a variety of means. But speakers often miss time cues, chairs cannot confirm their receipt, and the broken dialogue can be a sideshow for the audience. We developed HaNS, a wireless wrist-worn chair-speaker Haptic Notification System that delivers tactile cues for time-managing oral presentations, and performed field observations at university research seminars and two mid-sized academic conferences (input from 66 speakers, 21 chairs, and 65 audience members). Results indicate that HaNS can improve a user's awareness of time, facilitate chair-speaker coordination, and reduce distraction of speaker and audience through its private communication channel. Eliminating overruns will require improvement in speaker 'internal' control, which our results suggest HaNS can also support given practice. We conclude with design guidelines for both conference-deployed and personal timing tools, using touch or another notification modality.
2013	Interaction techniques for creating and exchanging content with public displays	Falling hardware prices and ever more displays being connected to the Internet will lead to large public display networks, potentially forming a novel communication medium. We envision that such networks are not restricted to display owners and advertisers anymore, but allow also passersby (e.g., customers) to exchange content, similar to traditional public notice areas, such as bulletin boards. In this context it is crucial to understand emerging practices and provide easy and straight forward interaction techniques to be used for creating and exchanging content. In this paper, we present Digifieds , a digital public notice area we built to investigate and compare possible interaction techniques. Based on a lab study we show that using direct touch at the display as well as using the mobile phone as a complementing interaction technology are most suitable. Direct touch at the display closely resembles the interaction known from classic bulletin boards and provides the highest usability. Mobile phones preserve the users' privacy as they exchange (sensitive) data with the display and at the same time allow content to be created on-the-go or to be retrieved.
2013	Toying with time: considering temporal themes in interactive artifacts	This paper argues that there is a value in deliberately and systematically exploring potential temporal behaviors of an interactive artifact, either as a means to add new functions, or to change the interaction with it. An improved version of Temporal Themes [23] - a vocabulary describing how software can "use" time or sequences of events - will be presented, alongside a series of design cases. These exemplify how adding or changing temporal themes in existing applications can enhance functionality and/or interaction. Moreover, the cases also serve as a basis for a discussion of the issues coupled to temporality, control and interaction strategies. Finally, a design approach with focus on temporal aspects is outlined. As a result, the paper opens up for a more conscious use of time and temporality in interaction design.
2013	What makes you click: exploring visual signals to entice interaction on public displays	Most studies take for granted the critical first steps that prelude interaction with a public display: awareness of the interactive affordances of the display, and enticement to interact. In this paper we investigate mechanisms for enticing interaction on public displays, and study the effectiveness of visual signals in overcoming the 'first click' problem. We combined 3 atomic visual elements (color/greyscale, animation/static, and icon/text) to form 8 visual signals that were deployed on 8 interactive public displays on a university campus for 8 days. Our findings show that text is more effective in enticing interaction than icons, color more than greyscale, and static signals are more effective than animated. Further, we identify gender differences in the effectiveness of these signals. Finally, we identify a behavior termed "display avoidance" that people exhibit with interactive public displays.
2013	The roles of touch during phone conversations: long-distance couples' use of POKE in their homes	We report the roles of touch during phone conversations by observing long-distance couples' one month use of POKE in their homes. POKE enables users to deliver touches through an inflatable surface on the front of the device that receives index finger pressure inputs on the back of another device, while allowing the callers to maintain a conventional phone-calling posture. After a month of use by three couples, we found unexpected roles of touch in that it supported the couples in developing and sharing their tactile vocabularies by applying POKE during various conversational situations. Moreover, the findings confirmed the roles that touch play in face-to-face communication. In particular, POKE was useful for expressing and understanding emotions, resolving conversations smoothly by replacing the words, feeling close to the partner at a distance, and concentrating on the phone conversations. We conclude by discussing the unused situations, privacy issues, and usable targets to improve POKE as a way of future tactile phone conversations.
2013	Messaging to your doctors: understanding patient-provider communications via a portal system	The patient portal is a relatively new healthcare information technology that enables patients more convenient access to their healthcare information and allows them to send messages to their doctors. Our study examines the themes discussed in these messages and the different ways in which patients communicate with their providers via a portal employed in a large medical center. We also explore the differences between the patient portal and more traditional communication media, and investigated the advantages and potential problems of the portal system. Our findings show a wide variety of topics discussed in the communication messages (such as medication, appointments, laboratory tests, etc.) and how patients provide information, consult with their providers, and express psychosocial and emotional needs. We argue that the patient portal improves the accuracy of communication and could facilitate illness management for patients, especially over a longer term. However, messaging through the patient portal is not popular among patients and the simultaneous use of multiple communication media may create information gaps. More research is needed to better elucidate barriers to the use of patient portals and the optimal methods of communication and information integration given different contexts.
2013	Kolibri: tiny and fast gestures for large pen-based surfaces	Triggering commands on large interactive surfaces is less efficient than on desktop PCs. It requires either large physical movements to reach an interaction area (e.g., buttons) or additional operations to call context menus (e.g., dwell). There is a lack of efficient ways to trigger shortcuts. We introduce Kolibri - a pen-based gesture system that allows fast access of commands on interactive whiteboards. Users can draw tiny gestures (approx. 3 mm) anywhere on the surface to trigger commands without interfering with normal inking. This approach does neither require entering a gesture mode, nor dedicated gesture areas. The implementation relies on off-the-shelf hardware only. We tested the feasibility and explored the properties of this technique with several studies. The results from a controlled experiment show significant benefits of Kolibri comparing to an existing approach.
2013	Graduate student use of a multi-slate reading system	In laboratory studies, multi-surface slate-based reading systems have shown great promise as platforms for active reading. However, the true utility of such a system can only be ascertained through the rigors of real world use. We conducted month-long deployments of a multi-slate reading system to support the active reading activities of graduate students in the humanities. During these deployments we documented how the added display area and increased micro-mobility of multiple devices enhanced navigation and reading comfort. We also noted the essential role of writing and annotation. Finally, we observed how electronic affordances like synchronization across devices helped provide functionality that would not have been possible with paper documents. This paper contributes new information about how electronic reading solutions fit into real world reading workflows.
2013	A text message a day keeps the pulmonologist away	The goal of this study was to extend and replicate an SMS health intervention for pediatric asthma patients. This intervention was designed using the Health Belief Model (HBM). Thirty patients were randomly assigned to one of three conditions. In the Knowledge condition patients were queried about their asthma knowledge every other day. In the Knowledge and Symptoms condition patients received a daily text message. They were queried about their symptoms and knowledge of asthma on alternate days. The Control group received no texts. Our main finding is that daily text messages lead to improved health outcomes. We explain our results in the context of interview data and the HBM. We conclude by suggesting that the HBM can be used to inform and evaluate system design for chronic care beyond asthma and by considering the role that replication studies can play in HCI research.
2013	HeartLink: open broadcast of live biometric data to social networks	A number of studies in the literature have looked into the use of real-time biometric data to improve one's own physiological performance and wellbeing. However, there is limited research that looks into the effects that sharing biometric data with others could have on one's social network. Following a period of research on existing mobile applications and prototype testing, we developed a system, HeartLink, which collects real-time personal biometric data such as heart rate and broadcasts this data online. Insights gained on designing systems to broadcast real-time biometric data are presented. In this paper we also report emerging results from testing HeartLink in a pilot study and a user study that were conducted during sport events. The results showed that sharing heart rate data does influence the relationship of the persons involved and that the degree of influence seems related to the tie strength prior to visualizing the data.
2013	Squaring the circle: how framing influences user behavior around a seamless cylindrical display	Recent research has presented large public displays in novel non-flat shapes such as spheres, curved planes and cylinders, and looked at the influence of the form factor on user behavior. Yet, the basic shape cannot be considered in isolation when interpreting the behavior of passers-by around such displays. In this paper we investigate two further display factors, framedness and seamlessness , that have to be considered in conjunction with the form factor to understand user behavior in front of large non-flat displays. We present the findings from a field study with an interactive column display and take a closer look at how these factors influence actor and bystander behavior. Our results show that rectangular frames act as a sort of funnel for user position and can easily override effects of the non-flat shape on user position and interaction, even though the users didn't recall the presence of these frames.
2013	Technology preferences and routines for sharing health information during the treatment of a chronic illness	When a patient has a chronic illness, such as heart disease or cancer, it can be challenging for distributed family members to stay aware of the patient's health status. A variety of technologies are available to support health information sharing (e.g., phone, video chat, social media), yet we still do not have a detailed understanding of which technologies are preferred and what challenges people still face when sharing information with them. To explore this, we conducted a mixed-method study-involving a survey and in-depth interviews--with people about their health information sharing routines and preferences for different technologies. Regardless of physical distance between distributed family members, synchronous methods of communication afforded the opportunity to provide affective support while asynchronous methods of communication were deemed to be the least intrusive. With family members adopting certain roles during the treatment of chronic illnesses, our findings suggest the need to design tools that mediate sharing health information across distance and age gaps, with consideration to respecting patient privacy while sharing health information.
2013	Community enhanced tutorials: improving tutorials with multiple demonstrations	Web-based tutorials are a popular help resource for learning how to perform unfamiliar tasks in complex software. However, in their current form, web tutorials are isolated from the applications that they support. In this paper we present FollowUs, a web-tutorial system that integrates a fully-featured application into a web-based tutorial. This novel architecture enables community enhanced tutorials, which continuously improve as more users work with them. FollowUs captures video demonstrations of users as they perform a tutorial. Subsequent users can use the original tutorial, or choose from a library of captured community demonstrations of each tutorial step. We conducted a user study to test the benefits of making multiple demonstrations available to users, and found that users perform significantly better using our system with a library of multiple demonstrations in comparison to its equivalent baseline system with only the original authored content.
2013	Screenfinity: extending the perception area of content on very large public displays	We propose and validate a model of the perception area of content on public displays in order to predict from where users can read. From this model, we derive Screenfinity , a technique to rotate, translate, and zoom content in order to enable reading while passing by very large displays. Screenfinity is comfortable to read when close, supports different content for different users, does not waste screen real estate and allows expert passers-by to read content while walking. A laboratory study shows that expert users are able to perceive content when it moves. A field study evaluates the effect of Screenfinity on novice users in an ecologically valid setting. We find 1) first time users can read content without slowing down or stopping; 2) Passers-by stopping did so to explore the technology. Users explore the interaction, the limits of the system, manipulate the technology, and look behind the screen.
2013	The emotional wellbeing of researchers: considerations for practice	As technology progressively pervades all aspects of our lives, members of the HCI community are engaging with increasingly sensitive contexts in their research - for example, end of life, genocide, computer-mediated communication under oppressive regimes. The considerations generated by research in such contexts can go well beyond those addressed by generic ethical approval processes and institutional practice. Whilst it is standard to ensure that the wellbeing of participants is taken into account in research design and the ethical approval process, it is much less common for the researcher's own emotional wellbeing to be considered explicitly. This paper describes the role that a researcher's emotions may play in research, and the impact which research in sensitive contexts can have on researchers' emotional wellbeing and on research validity. A qualitative survey is described which investigated the support mechanisms which HCI researchers have in place in case they are distressed/troubled as a result of their research. The results of the survey are used, in combination with insights into how other disciplines address the topic, to synthesize suggestions for ways in which the HCI community can proactively incorporate consideration for the emotional wellbeing of the researcher into the research process.
2013	Digital artifacts as legacy: exploring the lifespan and value of digital data	Legacy is the meaningful and complex way in which information, values, and possessions are passed on to others. As digital systems and information become meaningfully parts of people's everyday and social relationships, it is essential to develop new insights about how technology intersects with legacy and inheritance practices. We designed three interactive systems to investigate how digital materials might be passed down in the future. We conducted in-home interviews with ten parents using the systems to provoke discussion about how technology might support or complicate their existing practices. Sessions revealed parents desired to treat their digital information in ways not fully supported by technology. Findings are interpreted to describe design considerations for future work in this emerging space.
2013	Fragmentation and transition: understanding perceptions of virtual possessions among young adults in Spain, South Korea and the United States	People worldwide are increasingly acquiring collections of virtual possessions. While virtual possessions have become ubiquitous, little work exists on how people value and form attachments to these things. To investigate, we conducted a study with 48 young adults from South Korea, Spain and the United States. The study probed on participants' perceived value of their virtual possessions as compared to their material things, and the comparative similarities and differences across cultures. Findings show that young adults live in unfinished spaces and that they often experience a sense of fragmentation when trying to integrate their virtual possessions into their lives. These findings point to several design opportunities, such as tools for life story-oriented archiving, and insights on better forms of Cloud storage.
2013	Benevolent deception in human computer interaction	Though it has been asserted that "good design is honest", [42] deception exists throughout human-computer interaction research and practice. Because of the stigma associated with deception - in many cases rightfully so - the research community has focused its energy on eradicating malicious deception, and ignored instances in which deception is positively employed. In this paper we present the notion of benevolent deception , deception aimed at benefitting the user as well as the developer. We frame our discussion using a criminology-inspired model and ground components in various examples. We assert that this provides us with a set of tools and principles that not only helps us with system and interface design, but that opens new research areas. After all, as Cockton claims in his 2004 paper "Value-Centered HCI" [13], "Traditional disciplines have delivered truth. The goal of HCI is to deliver value."
2013	Instagram at the museum: communicating the museum experience through social photo sharing	The everyday use of smartphones with high quality built-in cameras has lead to an increase in museum visitors' use of these devices to document and share their museum experiences. In this paper, we investigate how one particular photo sharing application, Instagram, is used to communicate visitors' experiences while visiting a museum of natural history. Based on an analysis of 222 instagrams created in the museum, as well as 14 interviews with the visitors who created them, we unpack the compositional resources and concerns contributing to the creation of instagrams in this particular context. By re-categorizing and re-configuring the museum environment, instagrammers work to construct their own narratives from their visits. These findings are then used to discuss what emerging multimedia practices imply for the visitors' engagement with and documentation of museum exhibits. Drawing upon these practices, we discuss the connection between online social media dialogue and the museum site.
2013	HCI in the press: online public reactions to mass media portrayals of HCI research	HCI researchers working in publically funded institutions are increasingly encouraged to engage the public in their research. Mass media is often seen as an effective medium with which to communicate research to large parts of the population. We present an account of three HCI projects that have used engagements with mass media in order to communicate research to the public. We describe the motivations for working with mass media and the mechanics of writing press releases. A grounded theory analysis of online public responses to the projects in the mass media leads us to identify a number of concerns about how research is portrayed by news outlets and thus interpreted by the public. Tensions about technologies and wider societal issues were revealed that might normally be hidden when using traditional user-centred methods. We critically reflect on the efficacy of using the mass media in research and provide guidance for HCI researchers wishing to engage in dialogues with the public in the future.
2013	Design for forgetting: disposing of digital possessions after a breakup	People are increasingly acquiring huge collections of digital possessions. Despite some pleas for 'forgetting', most theorists argue for retaining all these possessions to enhance 'total recall' of our everyday lives. However, there has been little exploration of the negative role of digital possessions when people want to forget aspects of their lives. We report on interviews with 24 people about their possessions after a romantic breakup. We found that digital possessions were often evocative and upsetting in this context, leading to distinct disposal strategies with different outcomes. We advance theory by finding strong evidence for the value of intentional forgetting and provide new data about complex practices associated with the disposal of digital possessions. Our findings led to a number of design implications to help people better manage this process, including automatic harvesting of digital possessions, tools for self-control, artifact crafting as sense-making, and digital spaces for shared possessions.
2013	Categorised ethical guidelines for large scale mobile HCI	The recent rise in large scale trials of mobile software using 'app stores' has moved current researcher practice beyond available ethical guidelines. By surveying this recent and growing body of literature, as well as established professional principles adopted in psychology, we propose a set of ethical guidelines for large scale HCI user trials. These guidelines come in two parts: a set of general principles and a framework into which individual app store-based trials can be assessed and ethical concerns exposed. We categorise existing literature using our scheme, and explain how researchers could use our framework to classify their future user trials to determine ethical responsibility, and the steps required to meet these obligations.
2013	The wheels are turning: content rotation on steering wheel displays	The steering wheel is a promising space for the integration of displays since in the car there is very limited space for integrating interactive modalities for the driver that are close to the preferred field of view as well as in an easy to reach position. When the wheel is turned, the screen content could change its orientation to increase the readability and therefore reduce the distraction from the road. Thus, this paper describes three different content rotation behaviors for steering wheel displays. To investigate what effect these behaviors have on the driver in terms of visual distraction from the road we conducted a user study with eye tracking asking participants to read the current speed. We found no differences in terms of distraction and response time between the different rotation behaviors. Compared to a similar display in a dashboard position the visual distraction was reduced.
2013	In-body experiences: embodiment, control, and trust in robot-mediated communication	Communication technologies are becoming increasingly diverse in form and functionality, making it important to identify which aspects of these technologies actually improve geographically distributed communication. Our study examines two potentially important aspects of communication technologies which appear in robot-mediated communication - physical embodiment and control of this embodiment. We studied the impact of physical embodiment and control upon interpersonal trust in a controlled laboratory experiment using three different videoconferencing settings: (1) a handheld tablet controlled by a local user, (2) an embodied system controlled by a local user, and (3) an embodied system controlled by a remote user ( n = 29 dyads). We found that physical embodiment and control by the local user increased the amount of trust built between partners. These results suggest that both physical embodiment and control of the system influence interpersonal trust in mediated communication and have implications for future system designs.
2013	I see you there!: developing identity-preserving embodied interaction for museum exhibits	Museums are increasingly embracing technologies that provide highly-individualized and highly-interactive experiences to visitors. With embodied interaction experiences, increased localization accuracy supports greater nuance in interaction design, but there is usually a tradeoff between fast, accurate tracking and the ability to preserve the identity of users. Customization of experience relies on the ability to detect the identity of visitors, however. We present a method that combines fine-grained indoor tracking with robust preservation of the unique identities of multiple users. Our model merges input from an RFID reader with input from a commercial camera-based tracking system. We developed a probabilistic Bayesian model to infer at run-time the correct identification of the subjects in the camera's field of view. This method, tested in a lab and at a local museum, requires minimal modification to the exhibition space, while addressing several identity-preservation problems for which many indoor tracking systems do not have robust solutions.
2013	Powering the cellphone revolution: findings from mobile phone charging trials in off-grid Kenya	Can human-powered devices solve the electricity gap for the millions of rural Africans adopting mobile phones? Findings from our long-term evaluation of two personal crank-based charging systems in Kenya reveal that small hand and leg-powered devices do have potential to meet the needs of rural mobile phone users. Unfortunately, device breakage, theft and incompatibility with handsets, coupled with lack of consumer credit and poorly functioning markets for these goods mean these represent only a partial solution to the mobile phone charging problem. Drawing from our fieldwork, we motivate a HCI4D/ICTD design and evaluation agenda that better accounts for unique individuals' geographic, financial, and economic circumstances or their human computer ecosystem. Key strategies for implementing this agenda are engaging with diverse users on their own terms and conducting long-term qualitative evaluations to reveal how acceptance and usability change over time.
2013	Designing for perceptual crossing: designing and comparing three behaviors	Perceptual crossing is the reciprocal interplay of perceiving while being perceived. In this paper we discuss the last iteration of our ongoing research project on designing for perceptive qualities in systems of interactive products. We describe the design of explorative behavior in an artifact to enable the artifact and a person to engage in perceptual crossing. The explorative behavior is compared to the following and active behavior, the results of two earlier iterations. Through the iterations we formulated, applied and evaluated design relevant knowledge in the form of seven design notions. These notions inform design-researchers and design-practitioners on how to design for perceptive qualities in systems of interactive products. Here we specifically focus on how the artifact detects active perceptive behavior of a person, and how the artifact becomes aware of bygone perception and anticipates on future perception. An experiment shows how participants preferred the resulting explorative behavior that is closest to our theoretical framework based on phenomenology.
2013	The effects of tactile feedback and movement alteration on interaction and awareness with digital embodiments	Collaborative tabletop systems can employ direct touch, where people's real arms and hands manipulate objects, or indirect input, where people are represented on the table with digital embodiments. The input type and the resulting embodiment dramatically influence tabletop interaction: in particular, the touch avoidance that naturally governs people's touching and crossing behavior with physical arms is lost with digital embodiments. One result of this loss is that people are less aware of each others' arms, and less able to coordinate actions and protect personal territories. To determine whether there are strategies that can influence group interaction on shared digital tabletops, we studied augmented digital arm embodiments that provide tactile feedback or movement alterations when people touched or crossed arms. The study showed that both augmentation types changed people's behavior (people crossed less than half as often) and also changed their perception (people felt more aware of the other person's arm, and felt more awkward when touching). This work shows how groupware designers can influence people's interaction, awareness, and coordination abilities when physical constraints are absent.
2013	Crossing the bridge over norman's gulf of execution: revealing feedforward's true identity	Feedback and affordances are two of the most well-known principles in interaction design. Unfortunately, the related and equally important notion of feedforward has not been given as much consideration. Nevertheless, feedforward is a powerful design principle for bridging Norman's Gulf of Execution. We reframe feedforward by disambiguating it from related design principles such as feedback and perceived affordances, and identify new classes of feedforward. In addition, we present a reference framework that provides a means for designers to explore and recognize different opportunities for feedforward.
2013	Q-methodology as a research and design tool for HCI	A "discount" version of Q-methodology for HCI, called "HCI-Q", can be used in iterative design cycles to explore, from the point of view of users and other stakeholders, what makes technologies personally significant . Initially, designers critically reflect on their own assumptions about how a design may affect social and individual behavior. Then, designers use these assumptions as stimuli to elicit other people's points of view. This process of critical self-reflection and evaluation helps the designer to assess the fit between a design and its intended social context of use. To demonstrate the utility of HCI-Q for research and design, we use HCI-Q to explore stakeholders' responses to a prototype Alternative and Augmentative Communication (AAC) application called Vid2Speech . We show that our adaptation of Q-methodology is useful for revealing the structure of consensus and conflict among stakeholder perspectives, helping to situate design within the context of relevant value tensions and norms.
2013	DesignLibs: a scenario-based design method for ideation	Generating potential design ideas through ideation often benefits from the spontaneity of random ideas. Having potential users participate in this process can be beneficial, but is often difficult to implement. We present a new method for generating design ideas with potential users. The method uses scenarios with missing words, which potential users fill in to generate ideas for features and attributes of new technology designs, similar to the children's game of Mad Libs. We developed three different formats of DesignLibs, including 1) "Mad Libs-style": blanks presented before seeing the scenario, 2) "Fill-in-the-Blanks": blanks presented within the context of the scenario, and 3) "Q&A": blanks presented as questions and answers. We found that Design-Libs generated a number of new ideas, with the Fill-in-the-Blanks method providing the highest ratings for usefulness, feasibility, and diversity of answers. All three formats provided equal ratings for creativity.
2013	Design research at CHI and its applicability to design practice	This note describes our analysis of 35 papers from CHI 2011 that aim to improve or support interaction design practice. In our analysis, we characterize how these CHI authors conceptualize design practice and the types of contributions they propose. This work is motivated by the recognition that design methods proposed by HCI researchers often do not fit the needs and constraints of professional design practice. As a complement to the analysis of the CHI papers we also interviewed 13 practitioners about their attitudes towards learning new methods and approaches. We conclude the note by offering some critical reflections about how HCI research can better support actual design practice.
2013	Let's get together: the formation and success of online creative collaborations	In online creative communities, members work together to produce music, movies, games, and other cultural products. Despite the proliferation of collaboration in these communities, we know little about how these teams form and what leads to their ultimate success. Building on theories of social identity and exchange, we present an exploratory study of an online songwriting community. We analyze four years of longitudinal behavioral data using a novel path-based regression model that accurately predicts and reveals key variables about collab formation. Combined with a large-scale survey of members, we find that communication, nuanced complementary interest and status, and a balanced effort from both parties contribute to successful collaborations. We also discuss several applications of these findings for socio-technical infrastructures that support online creative production.
2013	Predicting users' first impressions of website aesthetics with a quantification of perceived visual complexity and colorfulness	Users make lasting judgments about a website's appeal within a split second of seeing it for the first time. This first impression is influential enough to later affect their opinions of a site's usability and trustworthiness. In this paper, we demonstrate a means to predict the initial impression of aesthetics based on perceptual models of a website's colorfulness and visual complexity. In an online study, we collected ratings of colorfulness, visual complexity, and visual appeal of a set of 450 websites from 548 volunteers. Based on these data, we developed computational models that accurately measure the perceived visual complexity and colorfulness of website screenshots. In combination with demographic variables such as a user's education level and age, these models explain approximately half of the variance in the ratings of aesthetic appeal given after viewing a website for 500ms only.
2013	Deep conservation in urban India and its implications for the design of conservation technologies	Rapid depletion of fossil fuels and water resources has become an international problem. Urban residential households are among the primary consumers of resources and are deeply affected by resource shortages. Despite the global nature of these problems, most of the solutions being developed to address these issues are based on studies done in the developed world. We present a study of energy, water and fuel conservation practices in urban India. Our study highlights a culture of deep conservation and the results raise questions about the viability of typical solutions such as home energy monitors. We identify new opportunities for design such as point-of-use feedback technologies, modular solutions, distributed energy storage, harnessing by-products and automated load shifting.
2013	The mobile media actor-network in urban India	Building on a growing body of human-computer interaction (HCI) literature on information and communication technology (ICT) use in the developing world, this paper describes the vast, growing mobile media consumption culture in India, which relies on the ubiquity of informal socioeconomic practices for reproducing, sharing, and distributing pirated digital media. Using an Actor-Network Theory (ANT) based approach, we show how piracy not only fuels media consumption, but also drives further technology adoption and promotes digital literacy. To do this, we first uncover the role of piracy as a legitimate actor that brings ICT capability to underserved communities and reveal the heterogeneous character of the pirated mobile media distribution and consumption infrastructure in India. We then emphasize the benefits of an ANT-based theory-driven analysis to HCI's efforts in this arena. In particular, ANT enables us to one, draw attention to the ties in the pirate media network that facilitate the increased decentralization of piracy in India; two, highlight the progressive transition from the outsourcing to the self-sourcing of users' media needs as this network evolves; and three, recognize the agency of human and non-human entities in this inherently sociotechnical ecosystem.
2013	A tribute to Mad skill: expert amateur visuality and world of Warcraft Machinima	In this paper, we look at the prominent World of Warcraft machinima community as an expert amateur online com-munity and present a multi-part study of a canon of the most successful works (i.e., machinima videos) produced by this community. By focusing our study on its roughly 300 most successful examples, the determination of which we explain in the paper, we are able to highlight the evolv-ing visual practices, tools, and aesthetic sensibilities of the community. Chiefly, our study identifies how creativity support tools and visual practices are inextricably linked and mutually support the in-kind development of the other. For WoW machinima and its producers, the affordance of creativity tools and the cultivation of visual skill synced at key moments and in powerful ways to support the rapid growth, experimentation, and refinement of amateur exper-tise at the individual and community levels.
2013	Virtual birding: extending an environmental pastime into the virtual world for citizen science	This paper investigates engaging experienced birders, as volunteer citizen scientists, to analyze large recorded audio datasets gathered through environmental acoustic monitoring. Although audio data is straightforward to gather, automated analysis remains a challenging task; the existing expertise, local knowledge and motivation of the birder community can complement computational approaches and provide distinct benefits. We explored both the culture and practice of birders, and paradigms for interacting with recorded audio data. A variety of candidate design elements were tested with birders. This study contributes an understanding of how virtual interactions and practices can be developed to complement existing practices of experienced birders in the physical world. In so doing this study contributes a new approach to engagement in e-science. Whereas most citizen science projects task lay participants with discrete real world or artificial activities, sometimes using extrinsic motivators, this approach builds on existing intrinsically satisfying practices.
2013	Fighting against the wall: social media use by political activists in a Palestinian village	We analyze practices of political activists in a Palestinian village located in the West Bank. Activists organize weekly demonstrations against Israel's settlement policy and the separation wall. Over a period of 28 months, we conducted a field study consisting of eight days 'on the ground' observation and interviewing, and extensive monitoring of Internet communication. We describe the activists' background and their efforts to organize these demonstrations under conditions of military occupation. Over time, we observe the role both digital and material factors play in the organization of protest. Specifically, we analyze how Email and Facebook were appropriated to facilitate interaction 'on the ground'.
2013	Cascade: crowdsourcing taxonomy creation	Taxonomies are a useful and ubiquitous way of organizing information. However, creating organizational hierarchies is difficult because the process requires a global understanding of the objects to be categorized. Usually one is created by an individual or a small group of people working together for hours or even days. Unfortunately, this centralized approach does not work well for the large, quickly changing datasets found on the web. Cascade is an automated workflow that allows crowd workers to spend as little at 20 seconds each while collectively making a taxonomy. We evaluate Cascade and show that on three datasets its quality is 80-90% of that of experts. Cascade has a competitive cost to expert information architects, despite taking six times more human labor. Fortunately, this labor can be parallelized such that Cascade will run in as fast as four minutes instead of hours or days.
2013	Warping time for more effective real-time crowdsourcing	In this paper, we introduce the idea of "warping time" to improve crowd performance on the difficult task of captioning speech in real-time. Prior work has shown that the crowd can collectively caption speech in real-time by merging the partial results of multiple workers. Because non-expert workers cannot keep up with natural speaking rates, the task is frustrating and prone to errors as workers buffer what they hear to type later. The TimeWarp approach automatically increases and decreases the speed of speech playback systematically across individual workers who caption only the periods played at reduced speed. Studies with 139 remote crowd workers and 24 local participants show that this approach improves median coverage (14.8%), precision (11.2%), and per-word latency (19.1%). Warping time may also help crowds outperform individuals on other difficult real-time performance tasks.
2013	Extracting usability and user experience information from online user reviews	Internet review sites allow consumers to write detailed reviews of products potentially containing information related to user experience (UX) and usability. Using 5198 sentences from 3492 online reviews of software and video games, we investigate the content of online reviews with the aims of (i) charting the distribution of information in reviews among different dimensions of usability and UX, and (ii) extracting an associated vocabulary for each dimension using techniques from natural language processing and machine learning. We (a) find that 13%-49% of sentences in our online reviews pool contain usability or UX information; (b) chart the distribution of four sets of dimensions of usability and UX across reviews from two product categories; (c) extract a catalogue of important word stems for a number of dimensions. Our results suggest that a greater understanding of users' preoccupation with different dimensions of usability and UX may be inferred from the large volume of self-reported experiences online, and that research focused on identifying pertinent dimensions of usability and UX may benefit further from empirical studies of user-generated experience reports.
2013	Love it or hate it!: interactivity and user types	This paper investigates general and individual evaluations of User Experience (UX) with interactive web sites. A series of studies investigate user judgment on web sites with different interactivity levels over repeated exposures. The more interactive websites produced more positive affect, had better design quality ratings, which improved with exposure, and were preferred. Differences between the more interactive sites indicated overall UX was influenced by users' preferences for interactive styles, with both sites having enthusiast, potential adopter, and non-adopter users. The implications for models and frameworks of UX are discussed.
2013	Visual challenges in the everyday lives of blind people	The challenges faced by blind people in their everyday lives are not well understood. In this paper, we report on the findings of a large-scale study of the visual questions that blind people would like to have answered. As part of this year-long study, 5,329 blind users asked 40,748 questions about photographs that they took from their iPhones using an application called VizWiz Social. We present a taxonomy of the types of questions asked, report on a number of features of the questions and accompanying photographs, and discuss how individuals changed how they used VizWiz Social over time. These results improve our understanding of the problems blind people face, and may help motivate new projects more accurately targeted to help blind people live more independently in their everyday lives.
2013	UMUX-LITE: when there's no time for the SUS	In this paper we present the UMUX-LITE, a two-item questionnaire based on the Usability Metric for User Experience (UMUX) [6]. The UMUX-LITE items are This system's capabilities meet my requirements and This system is easy to use." Data from two independent surveys demonstrated adequate psychometric quality of the questionnaire. Estimates of reliability were .82 and .83 -- excellent for a two-item instrument. Concurrent validity was also high, with significant correlation with the SUS (.81, .81) and with likelihood-to-recommend (LTR) scores (.74, .73). The scores were sensitive to respondents' frequency-of-use. UMUX-LITE score means were slightly lower than those for the SUS, but easily adjusted using linear regression to match the SUS scores. Due to its parsimony (two items), reliability, validity, structural basis (usefulness and usability) and, after applying the corrective regression formula, its correspondence to SUS scores, the UMUX-LITE appears to be a promising alternative to the SUS when it is not desirable to use a 10-item instrument.
2013	SPRWeb: preserving subjective responses to website colour schemes through automatic recolouring	Colours are an important part of user experiences on the Web. Colour schemes influence the aesthetics, first impressions and long-term engagement with websites. However, five percent of people perceive a subset of all colours because they have colour vision deficiency (CVD), resulting in an unequal and less-rich user experience on the Web. Traditionally, people with CVD have been supported by recolouring tools that improve colour differentiability, but do not consider the subjective properties of colour schemes while recolouring. To address this, we developed SPRWeb, a tool that recolours websites to preserve subjective responses and improve colour differentiability - thus enabling users with CVD to have similar online experiences. To develop SPRWeb, we extended existing models of non-CVD subjective responses to CVD, then used this extended model to steer the recolouring process. In a lab study, we found that SPRWeb did significantly better than a standard recolouring tool at preserving the temperature and naturalness of websites, while achieving similar weight and differentiability preservation. We also found that recolouring did not preserve activity, and hypothesize that visual complexity influences activity more than colour. SPRWeb is the first tool to automatically preserve the subjective and perceptual properties of website colour schemes thereby equalizing the colour-based web experience for people with CVD.
2013	Analyzing users' narratives to understand experience with interactive products	Recent research in user experience (UX) has studied narratives, users' account of their interaction with technology. It has emphasized specific constructs (e.g., affect, needs, hedonics) and their interrelation, but rarely analyzed the content of the narratives. We analyze the content and structure of 691 user-generated narratives on positive and negative experiences with technology. We use a multi-method approach consisting of manual (structural analysis of narratives) as well as of automated content analysis methods (psycholinguistic analysis and machine learning). These analyses show converging evidence that positive narratives predominantly concern social aspects such as family and friends. In addition, technology is positively experienced when it enables users to do things more efficiently or in a new way. In contrast, negative narratives often express anger and frustration due to technological failures. Our multi-method approach illustrates the potential of automated (as opposed to manual) content analysis methods for studying text-based experience reports.
2013	Accessible photo album: enhancing the photo sharing experience for people with visual impairment	While a photograph is a visual artifact, studies reveal that a number of people with visual impairments are also interested in being able to share their memories and experiences with their sighted counterparts in the form of a photograph. We conducted an online survey to better understand the challenges faced by people with visual impairments in sharing and organizing photos, and reviewed existing tools and their limitations. Based on our analysis, we developed an accessible mobile application that enables a visually impaired user to capture photos along with audio recordings for the ambient sound and memo description and to browse through them eyes-free. Five visually impaired participants took part in a study in which they used our app to take photographs in naturalistic settings and to share them later with a sighted viewer. The participants were able to use our app to identify each photograph on their own during the photo sharing session, and reported high satisfaction in having been able to take the initiative during the process.
2013	Listen to it yourself!: evaluating usability of what's around me? for the blind	Although multiple GPS-based navigation applications exist for the visually impaired, these are typically poorly suited for in-situ exploration, require cumbersome hardware, lack support for widely accessible geographic databases, or do not take advantage of advanced functionality such as spatialized audio rendering. These shortcomings led to our development of a novel spatial awareness application that leverages the capabilities of a smartphone coupled with worldwide geographic databases and spatialized audio rendering to convey surrounding points of interest. This paper describes the usability evaluation of our system through a task-based study and a longer-term deployment, each conducted with six blind users in real settings. The findings highlight the importance of testing in ecologically valid contexts over sufficient periods to face real-world challenges, including balancing quality versus quantity for audio information, overcoming limitations imposed by sensor accuracy and quality of database information, and paying appropriate design attention to physical interaction with the device.
2013	Non-parametric decision trees and online HCI	This paper proposes that online HCI studies (such as web-surveys and remotely monitored usability tests) can benefit from statistical data analysis using modern statistical learning methods such as classification and regression trees (CARTs). Applying CARTs to the often large amount of data yielded by online studies can easily provide clarity concerning the most important effects underlying experimental data in situations where myriad possible factors are under consideration. The feedback provided by such an analysis can also provide valuable reflection on the experimental methodology. We discuss these matters with reference to a study of 1300 participants in a structured experiment concerned with head-interaction techniques for first-person-shooter games.
2013	Flights in my hands: coherence concerns in designing Strip'TIC, a tangible space for air traffic controllers	We reflect upon the design of a paper-based tangible interactive space to support air traffic control. We have observed, studied, prototyped and discussed with controllers a new mixed interaction system based on Anoto, video projection, and tracking. Starting from the understanding of the benefits of tangible paper strips, our goal is to study how mixed physical and virtual augmented data can support the controllers' mental work. The context of the activity led us to depart from models that are proposed in tangible interfaces research where coherence is based on how physical objects are representative of virtual objects. We propose a new account of coherence in a mixed interaction system that integrates externalization mechanisms. We found that physical objects play two roles: they act both as representation of mental objects and as tangible artifacts for interacting with augmented features. We observed that virtual objects represent physical ones, and not the reverse, and, being virtual representations of physical objects, should seamlessly converge with the cognitive role of the physical object. Finally, we show how coherence is achieved by providing a seamless interactive space.
2013	The space between the notes: adding expressive pitch control to the piano keyboard	This paper addresses the question of how to extend the capabilities of a well-established interface in a way that respects users' existing expertise. The piano-style keyboard is among the most widely used and versatile of digital musical interfaces. However, it lacks the ability to alter the pitch of a note after it has been played, a limitation which prevents the performer from executing common expressive techniques including vibrato and pitch bending. We present a system for controlling pitch from the keyboard surface using capacitive touch sensors to measure the locations of the player's fingers on the keys. The large community of trained pianists makes the keyboard a compelling target for augmentation, but it also poses a challenge: how can a musical interface be extended while making use of the existing techniques performers have spent thousands of hours learning? In this paper, user studies with conservatory pianists explore the constraints of traditional keyboard technique and evaluate the usability of the continuous pitch control system. The paper also discusses implications for the extension of other established interfaces in musical and non-musical contexts.
2013	SeeSay and HearSay CAPTCHA for mobile interaction	Speech certainly has advantages as an input modality for smartphone applications, especially in scenarios where using touch or keyboard entry is difficult, on increasingly miniaturized devices where useable keyboards are difficult to accommodate, or in scenarios where only small amounts of text need to be input, such as when entering SMS texts or responding to a CAPTCHA challenge. In this paper, we propose two new alternative ways to design CAPTCHAs in which the user says the answer instead of typing it with (a) output stimuli provided visually (SeeSay) or (b) auditorily (HearSay). Our user study results show that SeeSay CAPTCHA requires less time to be solved and users prefer it over current text-based CAPTCHA methods.
2013	PixelTone: a multimodal interface for image editing	Photo editing can be a challenging task, and it becomes even more difficult on the small, portable screens of mobile devices that are now frequently used to capture and edit images. To address this problem we present PixelTone , a multimodal photo editing interface that combines speech and direct manipulation. We observe existing image editing practices and derive a set of principles that guide our design. In particular, we use natural language for expressing desired changes to an image, and sketching to localize these changes to specific regions. To support the language commonly used in photo-editing we develop a customized natural language interpreter that maps user phrases to specific image processing operations. Finally, we perform a user study that evaluates and demonstrates the effectiveness of our interface.
2013	A study on icon arrangement by smartphone users	The number of available mobile applications is steadily increasing. People have rapidly adopted application stores as means to customize their devices with various functionalities that go beyond communication. Understanding the principles of mobile application usage is crucial for supporting users within this new ecosystem. In this paper, we investigate how people organize applications they have installed on their devices. We asked more than 130 participants for their habits for icon arrangement and collected more than 1,400 screenshots of their devices' menus to further ground our findings. Based on this data we can distinguish five different concepts for arranging icons on smartphone menus, e.g. based on application usage frequency and applications' functional relatedness. Additionally, we investigated how these concepts emerge in relation to frequency of application installations, removals and icon rearrangements, as well as users' experience levels. Finally we discuss implications for the design of smartphone launchers, and highlight differences to icon arrangement on stationary computers.
2013	Swipe vs. scroll: web page switching on mobile browsers	Tabbed web browsing interfaces enable users to multi-task and easily switch between open web pages. However, tabbed browsing is difficult for mobile web browsers due to the limited screen space and the reduced precision of touch. We present an experiment comparing Safari's pages-based switching interface using horizontal swiping gestures with the stacked cards-based switching interface using vertical scrolling gestures, introduced by Chrome. The results of our experiment show that cards-based switching interface allows for faster switching and is less frustrating, with no significant effect on error rates. We generalize these findings, and provide design implications for mobile information spaces.
2013	Reflexive loopers for solo musical improvisation	Loop pedals are real-time samplers that playback audio played previously by a musician. Such pedals are routinely used for music practice or outdoor "busking". However, loop pedals always playback the same material, which can make performances monotonous and boring both to the musician and the audience, preventing their widespread uptake in professional concerts. In response, we propose a new approach to loop pedals that addresses this issue, which is based on an analytical multi-modal representation of the audio input. Instead of simply playing back prerecorded audio, our system enables real-time generation of an audio accompaniment reacting to what is currently being performed by the musician. By combining different modes of performance - e.g. bass line, chords, solo - from the musician and system automatically, solo musicians can perform duets or trios with themselves, without engendering the so-called canned (boringly repetitive and unresponsive) music effect of loop pedals. We describe the technology, based on supervised classification and concatenative synthesis, and then illustrate our approach on solo performances of jazz standards by guitar. We claim this approach opens up new avenues for concert performance.
2013	Phoneprioception: enabling mobile phones to infer where they are kept	Enabling phones to infer whether they are currently in a pocket, purse or on a table facilitates a range of new interactions from placement-dependent notifications setting to preventing "pocket dialing". We collected data from 693 participants to understand where people keep their phone in different contexts and why. Using this data, we identified three placement personas: Single Place Pat, Consistent Casey, and All-over Alex. Based on these results, we collected two weeks of labeled accelerometer data in-situ from 32 participants. We used this data to build models for inferring phone placement, achieving an accuracy of approximately 85% for inferring whether the phone is in an enclosed location and for inferring if the phone is on the user. Finally, we prototyped a capacitive grid and a multispectral sensor and collected data from 15 participants in a laboratory to understand the added value of these sensors.
2013	Facilitating parallel web browsing through multiple-page view	Parallel web browsing describes the behavior where users visit web pages in multiple concurrent threads. Qualitative studies have observed this activity being performed with multiple browser windows or tabs. However, these solutions are not satisfying since a large amount of time is wasted on switch among windows and tabs. In this paper, we propose the multiple-page view to facilitate parallel web browsing. Specifically, we provide users with the experience of visiting multiple web pages in one browser window and tab with extensions of prevalent desktop web browsers. Through user study and survey, we found that 2-4 pages within the window size were preferred for multiple-page view in spite of the diverse screen sizes and resolutions. Analytical results of logs from the user study also showed an improvement of 26.3% in users' efficiency of performing parallel web browsing tasks, compared to traditional browsing with multiple windows or tabs.
2013	Focused and casual interactions: allowing users to vary their level of engagement	We describe the focused-casual continuum , a framework for describing interaction techniques according to the degree to which they allow users to adapt how much attention and effort they choose to invest in an interaction conditioned on their current situation. Casual interactions are particularly appropriate in scenarios where full engagement with devices is frowned upon socially, is unsafe, physically challenging or too mentally taxing. Novel sensing approaches which go beyond direct touch enable wider use of casual interactions, which will often be 'around device' interactions. We consider the degree to which previous commercial products and research prototypes can be considered as fitting the focused-casual framework, and describe the properties using control theoretic concepts. In an experimental study we observe that users naturally apply more precise and more highly engaged interaction techniques when faced with a more challenging task and use more relaxed gestures in easier tasks.
2013	Designing engagement-aware agents for multiparty conversations	Recognizing users' engagement state and intentions is a pressing task for computational agents to facilitate fluid conversations in situated interactions. We investigate how to quantitatively evaluate high-level user engagement and intentions based on low-level visual cues, and how to design engagement-aware behaviors for the conversational agents to behave in a sociable manner. Drawing on machine learning techniques, we propose two computational models to quantify users' attention saliency and engagement intentions. Their performances are validated by a close match between the predicted values and the ground truth annotation data. Next, we design a novel engagement-aware behavior model for the agent to adjust its direction of attention and manage the conversational floor based on the estimated users' engagement. In a user study, we evaluated the agent's behaviors in a multiparty dialog scenario. The results show that the agent's engagement-aware behaviors significantly improved the effectiveness of communication and positively affected users' experience.
2013	Activity-centric support for ad hoc knowledge work: a case study of co-activity manager	Modern knowledge work consists of both individual and highly collaborative activities that are typically composed of a number of configuration, coordination and articulation processes. The desktop interface today, however, provides very little support for these processes and rather forces knowledge workers to adapt to the technology. We introduce co-Activity Manager, an activity-centric desktop system that (i) provides tools for ad hoc dynamic configuration of a desktop working context, (ii) supports both explicit and implicit articulation of ongoing work through a built-in collaboration manager and (iii) provides the means to coordinate and share working context with other users and devices. In this paper, we discuss the activity theory informed design of co-Activity Manager and report on a 14 day field deployment in a multi-disciplinary software development team. The study showed that the activity-centric workspace supports different individual and collaborative work configuration practices and that activity-centric collaboration is a two-phase process consisting of an activity sharing and per-activity coordination phase.
2013	Ownership and control of point of view in remote assistance	In this paper we investigate user performance and user behavior, related to the issue of who controls the point of view in a remote assistance scenario. We describe an experiment that examined users completing two different tasks with the aid of a remote gesturing device under two conditions: when control of the camera and gesturing point of view was in the hands of the remote helper, and when it was in the hands of the worker. Results indicate that in general, when most of the knowledge is with the helper, it is preferable to leave control in the hands of the helper. However, these results may depend on the situation and task at hand.
2013	Effects of peer feedback on contribution: a field experiment in Wikipedia	One of the most significant challenges for many online communities is increasing members' contributions over time. Prior studies on peer feedback in online communities have suggested its impact on contribution, but have been limited by their correlational nature. In this paper, we conducted a field experiment on Wikipedia to test the effects of different feedback types (positive feedback, negative feedback, directive feedback, and social feedback) on members' contribution. Our results characterize the effects of different feedback types, and suggest trade-offs in the effects of feedback between the focal task and general motivation, as well as differences in how newcomers and experienced editors respond to peer feedback. This research provides insights into the mechanisms underlying peer feedback in online communities and practical guidance to design more effective peer feedback systems.
2013	Exploring the effects of space and place on engagement with an interactive installation	Very little research has concurrently explored the influence of both physical space and social context (or place) on the way people engage with a public interactive display. We addressed this issue with a novel approach: studying how people engaged with the same interactive installation in ten situations with varying spatial and social properties. The main finding across these studies is that place trumps space: a conducive social context could overcome a poor physical space and encourage interaction; conversely, an inappropriate social context could inhibit interaction in spaces that might normally facilitate engagement. We discuss this finding in terms of the salience of the display within the space, the visibility of incidental interactions with the installation, the different understandings of place that people can have in the same location and the role of emergent champions and comperes in encouraging interaction.
2013	Turbulence in the clouds: challenges of cloud-based information work	We report on a qualitative study of the user experience of cloud-based information work. We characterize the information work practices and challenges that exist largely at the different intersections of three constructs - cloud-based services, collaborations, and digital identifiers. We also demonstrate how the misalignment of these three constructs is experienced as a "losing battle" that has led to miscommunication among collaborators, the abandonment of cloud-based services, and the irreparable blurring of digital identities.
2013	8D: interacting with a relightable glasses-free 3D display	We present an 8-dimensional (8D) display that allows glasses-free viewing of 3D imagery, whist capturing and reacting to incident environmental and user controlled light sources. We demonstrate two interactive possibilities enabled by our lens-array-based hardware prototype, and realtime GPU-accelerated software pipeline. Additionally, we describe a path to deploying such displays in the future, using current Sensor-in-Pixel (SIP) LCD panels, which physically collocate sensing and display elements.
2013	Factors impacting community response in an interest-sharing network	The arrival of a new interest-sharing network, So.cl, provides for a new opportunity to explore human behavior as it relates to constructing public contributions and receiving community response. This study looks at archival data in order to better understand how types of shared content receive interaction from others. The results suggest that a So.cl user should include more photos and less links on their post to increase the quantity of likes and comments the community gives to the post, among other discoveries.
2013	The challenges of specifying intervals and absences in temporal queries: a graphical language approach	In our burgeoning world of ubiquitous sensors and affordable data storage, records of timestamped events are being produced across nearly every domain of personal and professional computing. The resulting data surge has created an overarching need to search these records for meaningful patterns of events. This paper reports on a two-part user study, as well as a series of early tests and interviews with clinical researchers, that informed the development of two temporal query interfaces: a basic, menu-based interface and an advanced, graphic-based interface. While the scope of temporal query is very broad, this work focuses on two particularly complex and critical facets of temporal event sequences: intervals (events with both a start time and an end time), and the absence of an event. We describe how users encounter a common set of difficulties when specifying such queries, and propose solutions to help overcome them. Finally, we report on two case studies with epidemiologists at the US Army Pharmacovigilance Center, illustrating how both query interfaces were used to study patterns of drug use.
2013	Carpé data: supporting serendipitous data integration in personal information management	The information processing capabilities of humans enable them to opportunistically draw and integrate knowledge from nearly any information source. However, the integration of digital, structured data from diverse sources remains difficult, due to problems of heterogeneity that arise when data modelled separately are brought together. In this paper, we present an investigation of the feasibility of extending Personal Information Management (PIM) tools to support lightweight, user-driven mixing of previously un-integrated data, with the objective of allowing users to take advantage of the emerging ecosystems of structured data currently becoming available. In this study, we conducted an exploratory, sequential, mixed-method investigation, starting with two pre-studies of the data integration needs and challenges, respectively, of Web-based data sources. Observations from these pre-studies led to DataPalette , an interface that introduced simple co-reference and group multi-path-selection mechanisms for working with terminologically and structurally heterogeneous data. Our lab study showed that participants readily understood the new interaction mechanisms which were introduced. Participants made more carefully justified decisions, even while weighing a greater number of factors, moreover expending less effort, during subjective-choice tasks when using DataPalette, than with a control set-up.
2013	Using an open card sort with children to categorize games in a mobile phone application store	This paper presents a study aimed at better understanding how children categorize different games. The paper reports the results of an open card sort where participants were asked to categorize games from the Google Play Store (formerly the 'Android Marketplace'). The key contribution of the paper is that when compared with existing categories in the Google Play Store, children used categorization criteria much more aligned to the goals of the game rather than more abstract categories currently found in mobile phone application stores. The paper provides examples of existing categories that are not generally used by children and provides new examples of categorization criteria that are used by children to categorize existing games.
2013	How fast is fast enough?: a study of the effects of latency in direct-touch pointing tasks	Although advances in touchscreen technology have provided us with more precise devices, touchscreens are still laden with latency issues. Common commercial devices present with latency up to 125ms. Although these levels have been shown to impact users' perception of the responsiveness of the system [16], relatively little is known about the impact of latency on the performance of tasks common to direct-touch interfaces, such as direct physical manipulation. In this paper, we study the effect of latency of a direct-touch pointing device on dragging tasks. Our tests show that user performance decreases as latency increases. We also find that user performance is more severely affected by latency when targets are smaller or farther away. We present a detailed analysis of users' coping mechanisms for latency, and present the results of a follow-up study demonstrating user perception of latency in the land-on phase of the dragging task.
2013	Improving navigation-based file retrieval	Navigating through a file hierarchy is one of the most common methods for accessing files, yet it can be slow and repetitive. New algorithms that predict upcoming file accesses have the potential to improve navigation-based file retrieval, but it is unknown how best to present their predictions to users. We present three design goals aiming to improve navigation-based file retrieval interfaces: minimise the time spent at each hierarchical level en route to the target file; reduce the number of levels traversed by providing shortcuts; and promote rehearsal of the retrieval mechanics to facilitate expertise. We introduce three interfaces that augment standard file browsers based on each of these goals: Icon Highlights give greater prominence to predicted items in the current folder; Hover Menus provide shortcuts to predicted folder content; and Search Directed Navigation uses predictive highlighting to guide users through the hierarchy in response to query terms. Results from a user evaluation show that all three interfaces improve file retrieval times, with Icon Highlights and Hover Menus best suited for frequently accessed items and Search Directed Navigation best suited for infrequent ones. We also show that the benefits are larger when folder content is spatially unstable. Finally, we discuss how the interfaces could be combined and deployed in existing file browsers.
2013	Augmented letters: mnemonic gesture-based shortcuts	We propose Augmented Letters, a new technique aimed at augmenting gesture-based techniques such as Marking Menus [9] by giving them natural, mnemonic associations. Augmented Letters gestures consist of the initial of command names, sketched by hand in the Unistroke style, and affixed with a straight tail. We designed a tentative touch device interaction technique that supports fast interactions with large sets of commands, is easily discoverable, improves user's recall at no speed cost, and supports fluid transition from novice to expert mode. An experiment suggests that Augmented Letters outperform Marking Menu in terms of user recall.
2013	TouchViz: a case study comparing two interfaces for data analytics on tablets	As more applications move from the desktop to touch devices like tablets, designers must wrestle with the costs of porting a design with as little revision of the UI as possible from one device to the other, or of optimizing the interaction per device. We consider the tradeoffs between two versions of a UI for working with data on a touch tablet. One interface is based on using the conventional desktop metaphor (WIMP) with a control panel, push buttons, and checkboxes -- where the mouse click is effectively replaced by a finger tap. The other interface (which we call FLUID) eliminates the control panel and focuses touch actions on the data visualization itself. We describe our design process and evaluation of each interface. We discuss the significantly better task performance and preference for the FLUID interface, in particular how touch design may challenge certain assumptions about the performance benefits of WIMP interfaces that do not hold on touch devices, such as the superiority of gestural vs. control panel based interaction.
2013	W3touch: metrics-based web page adaptation for touch	Web designers currently face the increased proliferation and diversity of new touch devices which pose major challenges to the design task. This paper presents W3Touch - an interface instrumentation toolkit for web designers to collect user performance data for different device characteristics in order to help them identify potential design problems for touch interaction. Web designers can visualise the data aggregated by W3Touch and use simple metrics to automate the adaptation process for many different viewing and interaction contexts. In a series of experiments with web designers and users, we show that W3Touch is able to detect interaction problems that are hard to find using conventional methods and demonstrate how the tool was successfully used to automate the desktop-to-mobile migration of Wikipedia as an example.
2013	FlashTouch: data communication through touchscreens	FlashTouch is a new technology that enables data communication between touchscreen-based mobile devices and digital peripheral devices. Touchscreen can be used as communication media using visible light and capacitive touch. In this paper, we designed a stylus prototype to describe the concept of FlashTouch. With this prototype, users can easily transfer data from one mobile device to another. It eliminates the complexity associated with data sharing among mobile users, which is currently achieved by online data sharing services or wireless connections for data sharing that need a pairing operation to establish connections between devices. Therefore, it can prove to be of particular significance to people who are not adept at current software services and hardware functions. Finally, we demonstrate the valuable applications in online settlements via mobile device, and data communication for mobile robots.
2013	Shared joy is double joy: the social practices of user networks within group shopping sites	Group shopping sites are beginning to rise in popularity amongst eCommerce users. Yet we do not know how or why people are using such sites, and whether or not the design of group shopping sites map to the real shopping needs of end users. To address this, we describe an interview study that investigates the friendship networks of people who participate in group shopping sites (e.g., Groupon) with the goal of understanding how to best design for these experiences. Our results show that group shopping sites are predominently used to support social activities; that is, users do not use them first and foremost to find 'deals'. Instead, group shopping sites are used for planning group activities, extending and building friendships, and constructing one's social identity. Based on these findings, we suggest improved social network integration and impression management tools to improve user experience within group shopping sites.
2013	All the news that's fit to read: a study of social annotations for news reading	As news reading becomes more social, how do different types of annotations affect people's selection of news articles? This paper reports on results from two experiments looking at social annotations in two different news reading contexts. The first experiment simulates a logged-out experience with annotations from strangers, a computer agent, and a branded company. Results indicate that, perhaps unsurprisingly, annotations by strangers have no persuasive effects. However, surprisingly, unknown branded companies still had a persuasive effect. The second experiment simulates a logged-in experience with annotations from friends, finding that friend annotations are both persuasive and improve user satisfaction over their article selections. In post-experiment interviews, we found that this increased satisfaction is due partly because of the context that annotations add. That is, friend annotations both help people decide what to read, and provide social context that improves engagement. Interviews also suggest subtle expertise effects. We discuss implications for design of social annotation systems and suggestions for future research.
2013	Beyond the filter bubble: interactive effects of perceived threat and topic involvement on selective exposure to information	We investigated participants' preferential selection of information and their attitude moderation in an online environment. Results showed that even when opposing views were presented side-to-side, people would still preferentially select information that reinforced their existing attitudes. Preferential selection of information was, however, influenced by both situational (e.g., perceived threat) and personal (e.g., topic involvement) factors. Specifically, perceived threat induced selective exposure to attitude consistent information for topics that participants had low involvement. Participants had a higher tendency to select peer user opinions in topics that they had low than high involvement, but only when there was no perception of threat. Overall, participants' attitudes were moderated after being exposed to diverse views, although high topic involvement led to higher resistance to such moderation. Perceived threat also weakened attitude moderation, especially for low involvement topics. Results have important implication to the potential effects of "information bubble" - selective exposure can be induced by situational and personal factors even when competing views are presented side-by-side.
2013	Back-of-device authentication on smartphones	This paper presents BoD Shapes , a novel authentication method for smartphones that uses the back of the device for input. We argue that this increases the resistance to shoulder surfing while remaining reasonably fast and easy-to-use. We performed a user study ( n =24) comparing BoD Shapes to PIN authentication, Android grid unlock, and a front version of our system. Testing a front version allowed us to directly compare performance and security measures between front and back authentication. Our results show that BoD Shapes is significantly more secure than the three other approaches. While performance declined, our results show that BoD Shapes can be very fast (up to 1.5 seconds in the user study) and that learning effects have an influence on its performance. This indicates that speed improvements can be expected in long-term use.
2013	I need to try this?: a statistical overview of pinterest	Over the past decade, social network sites have become ubiquitous places for people to maintain relationships, as well as loci of intense research interest. Recently, a new site has exploded into prominence: Pinterest became the fastest social network to reach 10M users, growing 4000% in 2011 alone. While many Pinterest articles have appeared in the popular press, there has been little scholarly work so far. In this paper, we use a quantitative approach to study three research questions about the site. What drives activity on Pinterest? What role does gender play in the site's social connections? And finally, what distinguishes Pinterest from existing networks, in particular Twitter? In short, we find that being female means more repins, but fewer followers, and that four verbs set Pinterest apart from Twitter: use, look, want and need . This work serves as an early snapshot of Pinterest that later work can leverage.
2013	Does my password go up to eleven?: the impact of password meters on password selection	Password meters tell users whether their passwords are "weak" or "strong." We performed a laboratory experiment to examine whether these meters influenced users' password selections when they were forced to change their real passwords, and when they were not told that their passwords were the subject of a study. We observed that the presence of meters yielded significantly stronger passwords. We performed a followup field experiment to test a different scenario: creating a password for an unimportant account. In this scenario, we found that the meters made no observable difference: participants simply reused weak passwords that they used to protect similar low-risk accounts. We conclude that meters result in stronger passwords when users are forced to change existing passwords on "important" accounts and that individual meter design decisions likely have a marginal impact.
2013	My profile is my password, verify me!: the privacy/convenience tradeoff of facebook connect	We performed a laboratory experiment to study the privacy tradeoff offered by Facebook Connect: disclosing Facebook profile data to third-party websites for the convenience of logging in without creating separate accounts. We controlled for trustworthiness and amount of information each website requested, as well as the consent dialog layout. We discovered that these factors had no observable effects, likely because participants did not read the dialogs. Yet, 15% still refused to use Facebook Connect, citing privacy concerns. A likely explanation for subjects ignoring the dialogs while also understanding the privacy tradeoff - our exit survey indicated that 88% broadly understood what data would be collected - is that subjects were already familiar with the dialogs prior to the experiment. We discuss how our results demonstrate informed consent, but also how habituation prevented subjects from understanding the nuances between individual websites' data collection policies.
2013	Using Checksums to Detect Number Entry Error	Number entry is a common task in many domains. In safety-critical environments such as air traffic control or on hospital wards, incorrect number entry can have serious harmful consequences. Research has investigated how interface designs can help prevent users from making number entry errors. In this paper, we present an experimental evaluation of two possible interface designs aimed at helping users detect number entry errors using the idea of a checksum: an additional (redundant) number that is related to the to-be-entered numbers in such a way that it is sufficient to verify the correctness of the checksum, as opposed to checking each of the entered numbers. The first interface requires users to check their own work with the help of the checksum; the second requires the user to enter the checksum along with the other numbers so that the system can do the checking. In each case, two numbers needed to be entered, while the third number served as a checksum. With the first interface, users caught only 36% of their errors. The second interface resulted in all errors being caught, but the need to enter the checksum increased entry time by 46%. When participants were allowed to choose between the two interfaces, they chose the second interface in only 12% of the cases. Although these results cannot be generalized to other specific contexts, the results illustrate the strengths and weaknesses of each way of using checksums to catch number entry errors. Hence our study can serve as a starting point for efforts to improve each method.
2013	Using fake cursors to secure on-screen password entry	In this paper, we present a concept using fake cursors to disguise on-screen password entry. We performed two user studies with different amounts of dummy cursors and differently colored cursors. The results show that dummy cursors significantly improve security. At the same time, decrease in performance is kept within an acceptable range. Depending on the required degree of security, the studies favor 8 or 16 differently colored cursors as the best trade-off between security and usability.
2013	I am what i eat: identity & critical thinking in an online health forum for kids	As kids encounter food advertisements, it is important that they be able to critically evaluate the message's claims, the healthiness of the promoted product and their desire for it. To explore how technology might help kids develop these skills, we created an online forum called TalkBack that encourages children to critically analyze the messaging in food ads and their attitudes towards marketed foods. We evaluated TalkBack with twenty-eight middle school students in a summer camp program. We discuss how participants appeared to project and protect their sense of self through their interaction with TalkBack. We also describe the limited analytic depth of their forum contributions and suggest directions for HCI research that attempts to encourage critical thinking and health promotion in adolescents.
2013	Tailoring persuasive health games to gamer type	Persuasive games are an effective approach for motivating health behavior, and recent years have seen an increase in games designed for changing human behaviors or attitudes. However, these games are limited in two major ways: first, they are not based on theories of what motivates healthy behavior change. This makes it difficult to evaluate why a persuasive approach works. Second, most persuasive games treat players as a monolithic group. As an attempt to resolve these weaknesses, we conducted a large-scale survey of 642 gamers' eating habits and their associated determinants of healthy behavior to understand how health behavior relates to gamer type. We developed seven different models of healthy eating behavior for the gamer types identified by BrainHex. We then explored the differences between the models and created two approaches for effective persuasive game design based on our results. The first is a one-size-fits-all approach that will motivate the majority of the population, while not demotivating any players. The second is a personalized approach that will best motivate a particular type of gamer. Finally, to make our approaches actionable in persuasive game design, we map common game mechanics to the determinants of healthy behavior.
2013	Domestic food and sustainable design: a study of university student cooking and its impacts	In four university student kitchens over twenty-one days, we captured participants' food preparation activity, quantified the greenhouse gas emissions and direct energy connected to the food and cooking, and talked to participants about their food practices. Grounded in this uniquely detailed micro-account, our findings inform sustainable design for cooking and eating at home and quantify the potential impacts. We outline the relation of the impacts to our participants' approaches to everyday food preparation, the organisation of their time, and the role of social meals. Our technique allows evaluation of opportunities for sustainable intervention design: at the appliance, in the digitally-mediated organisation of meals and inventory management, and more broadly in reflecting upon and reshaping diet.
2013	Digital portraits: photo-sharing after domestic violence	This paper explores how technology could support the re-building of lives after domestic violence. We worked in the context of a women's centre where women are accessing support after leaving abusive relationships. The paper contributes a feminist participatory arts action research approach to studying photo-sharing practices and helps to frame an understanding of the ongoing tensions in the construction of self with others that the women experience. We argue that the affirmation of new bonds, control in sharing the process of 'moving on', and supporting discursive negotiations of privacy are important considerations for design focused on interpersonal social processes around the use of digital technology.
2013	Protecting the home: exploring the roles of technology and citizen activism from a burglar's perspective	For decades, HCI scholars have designed technology for the domestic space. Many of these systems aim to protect the home and its residents by requesting help from local authorities during emergency situations. While the use of these systems have been examined, few studies attempt to understand the behavior of potential offenders who can create such emergency situations (e.g., by attempting a burglary). This paper analyzes three panel sessions with 15 people who have been convicted of burglarizing homes, cars, and/or businesses. Participants describe in detail what they looked for when deciding to burglarize a home and what deterred them. Technologies such as security systems, alarms, and cameras do not dissuade burglars. Instead, evidence of neighborhood cohesion was named the strongest deterrent. This paper presents implications for designing technologies that will effectively discourage burglary and support citizen activism.
2013	Validating a mobile phone application for the everyday, unobtrusive, objective measurement of sleep	There is an identified need for objective, reliable, and scalable methods of measuring and recording sleep. Such methods must be designed for easy integration into people's lives in order to support both sleep therapy and everyday personal informatics. This paper describes the design and evaluation of a mobile phone application to record sleep, the design of which has substantive foundation in clinical sleep research. Two user studies were carried out which demonstrate that the application produces valid measurements of sleep quality and high levels of usability, whilst not seriously disturbing sleep or the sleep environment. These findings suggest that the app is suitable for both everyday sleep monitoring in a personal informatics context, and for integration into sleep interventions.
2013	Mobile advertising: evaluating the effects of animation, user and content relevance	The potential for user-relevant, context-appropriate, targeted advertising on mobile devices is enormous given device improvements and advances in personal and location-based data collection. However, little is known about how users experience display advertisements ('ads') on mobile devices, or what factors drive mobile ad effectiveness. In this paper, we investigate users' experiences of display advertising on mobile devices. We consider three factors that are often studied in desktop settings the ad's level of personal relevance to the user, its relevance to the page content, and within-ad properties, with a particular focus on the level of animation in the ad. Our findings reveal a few surprises. First, personal relevance to the user has little or no impact on ad efficacy measured by recall. Instead, content relevance boosts ad recall. Second, user relevance leads to a more pleasant and interesting experience, but content relevance has no effect. Third, contrary to the popular notion that animation often leads to more effective ads by garnering more user attention, we find that a simple type of animation, such as blinking animation, negatively affects user experience and reduces ad recall. Our findings, while focused on advertising, offer insights for design of mobile content presentation in general.
2013	Food practices as situated action: exploring and designing for everyday food practices with households	Household food practices are complex. Many people are unable to effectively respond to challenges in their food environment to maintain diets considered to be in line with national and international standards for healthy eating. We argue that recognizing food practices as situated action affords opportunities to identify and design for practiced, local and achievable solutions to such food problems. Interviews and shop-a-longs were carried as part of a contextual inquiry with ten households. From this, we identify food practices, such as fitting food, stocking up, food value transitions, and having fun with others and how these practices are enacted in different ways with varied outcomes. We explore how HCI might respond to these practices through issues of social fooding, the presence of others, conceptions about food practices and food routines.
2013	When the price is right: enabling time-dependent pricing of broadband data	In an era of 108% annual growth in demand for mobile data and $10/GB overage fees, Internet Service Providers (ISPs) are experiencing severe congestion and in turn are hurting consumers with aggressive pricing measures. But smarter practices, such as time-dependent pricing (TDP), reward users for shifting their non-critical demand to off-peak hours and can potentially benefit both users and ISPs. Although dynamic TDP ideas have existed for many years, dynamic pricing for mobile data is only now gaining interest among ISPs. Yet TDP plans require not only systems engineering but also an understanding of economic incentives, user behavior and interface design. In particular, the HCI aspects of communicating price feedback signals from the network and the response of mobile data users need to be studied in the real world. But investigating these issues by deploying a virtual TDP data plan for real ISP customers is challenging and rarely explored. To this end, we carried out the first TDP trial for mobile data in the US with 10 families. We describe the insights gained from the trial, which can help the HCI community as well as ISPs, app developers and designers create tools that empower users to better control their usage and save on their monthly bills, while also alleviating network congestion.
2013	Evaluating the efficiency of physical visualizations	Data sculptures are an increasingly popular form of physical visualization whose purposes are essentially artistic, communicative or educational. But can physical visualizations help carry out actual information visualization tasks? We present the first infovis study comparing physical to on-screen visualizations. We focus on 3D visualizations, as these are common among physical visualizations but known to be problematic on computers. Taking 3D bar charts as an example, we show that moving visualizations to the physical world can improve users' efficiency at information retrieval tasks. In contrast, augmenting on-screen visualizations with stereoscopic rendering alone or with prop-based manipulation was of limited help. The efficiency of physical visualizations seems to stem from features that are unique to physical objects, such as their ability to be touched and their perfect visual realism. These findings provide empirical motivation for current research on fast digital fabrication and self-reconfiguring interfaces.
2013	Real-time perception-level translation from audio signals to vibrotactile effects	In this paper, we propose a real-time perception-level audio-to-vibrotactile translation algorithm. Unlike previous signal-level conversion methods, our algorithm considers only perceptual characteristics, such as loudness and roughness, of audio and tactile stimuli. This perception-level approach allows for designing intuitive and explicit conversion models with clear understandings of their perceptual consequences. Our current implementation is tailored to accurate detection of special sound effects to provide well-synchronized audio-tactile feedback in immersive applications. We also assessed the performance of our translation algorithm in terms of the detection rate of special sound effects, computational performance, and user preference. All the experimental results supported that our algorithm works well as intended with better performance than the signal-level conversion methods, especially for games. Our algorithm can be easily realized in current products, including mobile devices, gaming devices, and 4D home theater systems, for richer user experience.
2013	Digital apartheid: an ethnographic account of racialised hci in Cape Town hip-hop	We describe findings from a 15-month ethnography of hip-hop performers in Cape Town, South Africa. Mobile communications and social media are hugely important to the development of these performers' careers, opening access to collaborators, production tools, audiences and distribution channels. This group go to extraordinary lengths to gain and maintain access to these technologies, often by exploiting their social capital through musical and ethnic networks. We document that even after nearly twenty years of democracy, a ridged separation along racial lines persists, which can be seen in all areas of life including access to and proficiency in digital technologies. We illustrate how hip-hop performers harness these divisions both on and offline in order to distinguish themselves from other artists. Our research raises a number of implications for post-colonial computing, highlighting difficulties related to discontinuous access, and how international preconceptions of identity and authenticity emerge as a consequence of the increased use of communication technology.
2013	Envisioning across generations: a multi-lifespan information system for international justice in rwanda	With this research we investigate how to account for multi-generational perspectives in the design of multi-lifespan information systems, particularly in support of long-term peace-building and international justice. We do our work in the context of the publicly available Voices from the Rwanda Tribunal testbed, a historically significant collection of video interviews with personnel from the International Criminal Tribunal for Rwanda. In the research reported here, we worked with 109 Rwandan adults and youth from perpetrator and survivor communities in three provincial cities in Rwanda (Byumba, Kibuye, and Gisenyi) to understand the potentials and challenges they envision for the interview collection. Participants envisioned five categories of long-term positive outcomes for individuals and society from a multi-lifespan information system for the interview collection; and eight categories of challenges to realize those potential outcomes. In terms of multi-generational perspectives, while adults and youth tended to share an overall vision for the long-term potential of such a system, adults emphasized actionable tasks while youth educational benefits. Based on the findings, we highlight issues for appropriation of multi-lifespan information systems and reflect on our methods for eliciting multi-generational perspectives on information system design in a post-conflict society.
2013	Gesture output: eyes-free output using a force feedback touch surface	We propose using spatial gestures not only for input but also for output. Analogous to gesture input, the proposed gesture output moves the user's finger in a gesture, which the user then recognizes. We use our concept in a mobile scenario where a motion path forming a "5" informs users about new emails, or a heart-shaped path serves as a mes- sage from a friend. We built two prototypes: (1) The long- RangeOuija is a stationary prototype that offers a motion range of up to 4cm; (2) The pocketOuija is self-contained mobile device based on an iPhone with up to 1cm motion range. Both devices actuate the user's fingers by means of an actuated transparent foil overlaid onto a touchscreen. We conducted three studies with the longRangeOuija in which participants recognized 2cm marks with 97% accu- racy, Graffiti digits with 98.8%, pairs of Graffiti digits with 90.5%, and Graffiti letters with 93.4%. Participants previ- ously unfamiliar with Graffiti identified 96.2% of digits and 76.4% of letters, suggesting that properly designed gesture output is guessable. After the experiment, the same participants were able to enter 100% of Graffiti digits by heart and 92.2% of letters. This suggests that participants learned gesture input as a side effect of using gesture output on our prototypes.
2013	Reality jockey: lifting the barrier between alternate realities through audio and haptic feedback	We present Reality Jockey, a system that confuses the participant's perception of the reality by mixing in a recorded past-reality. The participant will be immersed in a spatialized 3D sound environment that is a mix of sounds from the reality and from the past. The sound environment from the past is augmented with haptic feedback in cross-modality. The haptic feedback is associated with certain sounds such as the vibration in the table when stuff is placed on the table to make the illusion of it happening in live. The seamless transition between live and past creates immersive experience of past events. The blending of live and past allows interactivity. To validate our system, we conducted user studies on 1) does blending live sensations improve such experiences, and 2) how beneficial is it to provide haptic feedbacks in recorded pasts. Potential applications are suggested to illustrate the significance of Reality Jockey.
2013	LaserOrigami: laser-cutting 3D objects	We present LaserOrigami, a rapid prototyping system that produces 3D objects using a laser cutter. LaserOrigami is substantially faster than traditional 3D fabrication techniques such as 3D printing and unlike traditional laser cutting the resulting 3D objects require no manual assembly. The key idea behind LaserOrigami is that it achieves three-dimensionality by folding and stretching the workpiece, rather than by placing joints, thereby eliminating the need for manual assembly. LaserOrigami achieves this by heating up selected regions of the workpiece until they become compliant and bend down under the force of gravity. LaserOrigami administers the heat by defocusing the laser, which distributes the laser's power across a larger surface. LaserOrigami implements cutting and bending in a single integrated process by automatically moving the cutting table up and down--when users take out the workpiece, it is already fully assembled. We present the three main design elements of LaserOrigami: the bend, the suspender, and the stretch, and demonstrate how to use them to fabricate a range of physical objects. Finally, we demonstrate an interactive fabrication version of LaserOrigami, a process in which user interaction and fabrication alternate step-by-step.
2013	Muscle-propelled force feedback: bringing force feedback to mobile devices	Force feedback devices resist miniaturization, because they require physical motors and mechanics. We propose mobile force feedback by eliminating motors and instead actuating the user's muscles using electrical stimulation. Without the motors, we obtain substantially smaller and more energy-efficient devices. We present a prototype that fits on the back of a mobile phone. It actuates users' forearm muscles via four electrodes, which causes users' muscles to contract involuntarily, so that they tilt the device sideways. As users resist this motion using their other arm, they perceive force feedback. We demonstrate the interaction at the example of an interactive videogame in which users steer an airplane through winds rendered using force feedback. In a first user study, we found our device to cause users to produce up to 18.7N of force, when used to actuate their palm flexors. In a second study, participants played the video game de-scribed above; all ten participants reported to prefer the experience of muscle-propelled force feedback to vibrotactile feedback.
2013	uTouch: sensing touch gestures on unmodified LCDs	Current solutions for enabling touch interaction on existing non-touch LCD screens require adding additional sensors to the interaction surface. We present uTouch, a system that detects and classifies touches and hovers without any modification to the display, and without adding any sensors to the user. Our approach utilizes existing signals in an LCD that are amplified when a user brings their hand near or touches the LCD's front panel. These signals are coupled onto the power lines, where they appear as electromagnetic interference (EMI) which can be sensed using a single device connected elsewhere on the power line infrastructure. We validate our approach with an 11 user, 8 LCD study, and demonstrate a real-time system.
2013	Design to promote mindfulness practice and sense of self for vulnerable women in secure hospital services	In the field of mental health care technologies, very limited attention has been given to the design of interventions for individuals who undergo treatment for severe mental health problems in intense care contexts. Exploring novel designs to engage vulnerable psychiatric patients in therapeutic skills practice and expanding on the potential of technology to promote mental health, the paper introduces the design concept of the Spheres of Wellbeing . A set of interactive artifacts is developed specifically for women with a dual diagnosis of a Learning Disability and Borderline Personality Disorder, living in the medium secure services of a forensic hospital in the UK. The women present a difficult to treat group due to extremely challenging behaviors and a fundamental lack of motivation to engage in therapy. The Spheres are designed to assist the women in practices of mindfulness, to help them tolerate emotional distress and to strengthen their sense of self, all of which are vital components of their specialist treatment Dialectical Behavioral Therapy (DBT). The Spheres are intended to supplement the therapy of the women and to contribute to our understanding of designing technology to enhance mental wellbeing and quality of life more generally.
2013	Democratizing technology: pleasure, utility and expressiveness in DIY and maker practice	DIY, hacking, and craft have recently drawn attention in HCI and CSCW, largely as a collaborative and creative hobbyist practice. We shift the focus from the recreational elements of this practice to the ways in which it democratizes design and manufacturing. This democratized technological practice , we argue, unifies playfulness, utility, and expressiveness, relying on some industrial infrastructures while creating demand for new types of tools and literacies. Thriving on top of collaborative digital systems, the Maker movement both implicates and impacts professional designers. As users move more towards personalization and reappropriation, new design opportunities are created for HCI.
2013	Preference-based location sharing: are more privacy options really better?	We examine the effect of coarse-grained vs. fine-grained location sharing options on users' disclosure decisions when configuring a sharing profile in a location-sharing service. Our results from an online user experiment (N=291) indicate that users who would otherwise select one of the finer-grained options will employ a compensatory decision strategy when this option is removed. This means that they switch either in the direction of more privacy and less benefit, or less privacy and more benefit, depending on the subjective distance between the omitted option and the remaining options. This explanation of users' disclosure behavior is in line with fundamental decision theories, as well as the well-established notion of "privacy calculus". Two alternative hypotheses that we tested were not supported by our experimental data.
2013	A design-led inquiry into personhood in dementia	Writers and practitioners in dementia care have invoked personhood to offer potential for preserving the agency of people living with dementia. In this context we use personhood to explore how relationships bring agentive potential to experience-centered design through a co-creative, design-led inquiry with Gillian, a woman living with dementia, and John her husband. We designed bespoke probes to empathically engage the couple in the design of both jewellery and digital jewellery to support Gillian's personhood. Our design activity addressed the relationships involved in the context of Gillian's family life and the progression of her illness and how they could be mediated technologically. Reminiscence became, through Gillian and John's own hands, acts of sense making and legacy. The process of design became the way of conducting the inquiry and the designed artifacts became ways of posing questions to make sense of our experiences together.
2013	Why do people seek anonymity on the internet?: informing policy and design	In this research we set out to discover why and how people seek anonymity in their online interactions. Our goal is to inform policy and the design of future Internet architecture and applications. We interviewed 44 people from America, Asia, Europe, and Africa who had sought anonymity and asked them about their experiences. A key finding of our research is the very large variation in interviewees' past experiences and life situations leading them to seek anonymity, and how they tried to achieve it. Our results suggest implications for the design of online communities, challenges for policy, and ways to improve anonymity tools and educate users about the different routes and threats to anonymity on the Internet.
2013	Understanding the conflicting demands of family caregivers caring for depressed family members	Depression is one of the most common disabilities in developed countries. Despite its often devastating impact on families, scant research has focused on how to facilitate the well-being of family caregivers. The aim of this paper is to uncover the challenges faced by family caregivers and support their well-being with the use of technologies. To understand the emotional and social burden of caregivers and how they handle their stress, we conducted in-depth interviews with 15 individuals who have cared for a depressed family member. Our findings reveal the multifaceted dilemma of caring for a depressed family member as well as the various strategies engaged in by caregivers to improve their own situations. Based on our findings, we suggest design implications for healthcare technologies to improve the wellness of caregivers who are looking after depressed family members.
2013	Designing mobile health technology for bipolar disorder: a field trial of the monarca system	An increasing number of pervasive healthcare systems are being designed, that allow people to monitor and get feedback on their health and wellness. To address the challenges of self-management of mental illnesses, we have developed the MONARCA system - a personal monitoring system for bipolar patients. We conducted a 14 week field trial in which 12 patients used the system, and we report findings focusing on their experiences. The results were positive; compared to using paper-based forms, the adherence to self-assessment improved; the system was considered very easy to use; and the perceived usefulness of the system was high. Based on this study, the paper discusses three HCI questions related to the design of personal health technologies; how to design for disease awareness and self-treatment, how to ensure adherence to personal health technologies, and the roles of different types of technology platforms.
2013	The secret life of a persona: when the personal becomes private	Some organizations fail to involve users in systems development due to a widespread organization, high workload or secrecy issues. A remedy against this situation could be the persona method in which users and main stakeholders as represented as fictitious characters. Personas help eliciting user needs and requirements, facilitate design choices and are an overall communication aid where users cannot be present. An important part of the persona method, as portrayed in literature, is the personal details that make the personas trustworthy and alive. In this paper we present two cases in which personas have been developed and used, but where the personal is scarce or even non-existent because of a dispersed organisation, the organisational culture and secrecy issues. The paper describes how the personas were developed, used and received and how the method was altered in order to work in these special circumstances.
2013	The power of play: design lessons for increasing the lifespan of outdated computers	One consequence of rapid advances in computer technology is the obsolescence of hundreds of millions of computers each year. This paper explores strategies for increasing the reuse of outdated computers through an investigation of an 8-bit home computer that is still popular in developing countries. We observed the use of the computers in 16 households in Ahmedabad and Bangalore, India in order to gain insight into the contextual factors that support the continued popularity of the device. While most computers become obsolete in less than a decade, this 30-year-old computer technology remains useful because it provides exciting, multi-user family entertainment. While having minimal processing power and virtually no connectivity, the 8-bit computer supports input and output channels that are especially suited for co-located social game play. In contrast, PCs are primarily designed for individual use. Therefore, we offer low-cost design recommendations that would enable outdated PCs to support greater shared use and increased utility within the constrained material context of low-income households. These simple interventions, if adopted by computer refurbishment industries, have the potential to significantly extend the useful lifespan of PCs.
2013	I want to imagine how that place looks: designing technologies to support connectivity between africans living abroad and home	Uneven access to Information and Communication Technologies (ICTs) in parts of the African continent make it challenging for some Africans who migrate to the U.S. to communicate with family members in their countries of origin. However, Internet access is becoming more widespread throughout the continent and this development presents an opportunity to explore how future interactive systems can support exchanges between families with members living in developed and less developed countries. To investigate these design possibilities we interviewed 27 African-born students, currently living in Virginia, U.S., and asked them how they used ICTs to connect with family members in their home countries. Our findings informed the development of a low-fidelity prototype that eight students lived with for four to five months. Findings from this deployment study motivate a discussion regarding features to include in interfaces designed to support transnational family communication. Features include personally meaningful imagery, country specific content, and the ability to monitor the weather and changing currency rates in migrants' countries of origin.
2013	Consent for all: revealing the hidden complexity of terms and conditions	Terms and conditions are central in acquiring user consent by service providers. Such documents are frequently highly complex and unreadable, placing doubts on the validity of so called 'informed consent'. While readability and web accessibility have been major themes for some time in HCI, the core principles have yet to be applied beyond webpage content and are absent from the underpinning terms and conditions. Our concern is that accessible web pages will encourage consent, masking the complexities of the terms of usage. Using the SMOG readability formula and UK Energy services as a case study, we observed that a series of supplier terms and conditions were far beyond what a functionally literate adult could be expected to understand. We also present a browser based plug-in which compares SMOG readability scores to popular books. The intention is to use this plug-in to assist in surfacing the hidden complexities underpinning online consent.
2013	inAir: a longitudinal study of indoor air quality measurements and visualizations	Indoor air quality (IAQ) is important for health as people spend the majority of time indoors, and it is particularly interesting over outdoor air because it strongly ties to indoor activities. Some activities easily exacerbate IAQ, resulting in serious pollution. However, people may not notice such changes because many pollutants are colorless and odorless, while many activities are inconspicuous and routine. We implemented inAir, a system that measures and visualizes IAQ that households appropriate and integrate into everyday life. The research goals of this work include understanding the IAQ dynamics with respect to habitual behaviors and analyzing behavioral and quantitative changes towards improving IAQ by the use of inAir. From our longitudinal study for four months, we found that inAir successfully elicited the reflection upon, and the modification of habitual behaviors for healthy domestic environments, which resulted in the significant improvement of IAQ.
2013	Beyond being green: simple living families and ICT	Motivated by a need in sustainable HCI for studies of everyday practices, and a belief that a holistic view on sustainability is crucial to deeper understanding of how to design ICT to support sustainability, we here present a qualitative study of 11 simple living families in the US. Simple living refers to a lifestyle which is voluntarily simple out of concern for both the environment and quality of life. Our goal was to learn about a holistic view on sustainability and the role of ICT in helping and hindering families to live simply. The study contributes new insights about how holistic sustainability could be a valuable lens for HCI, revealing that sustainability is important to a wider range of areas in HCI than previously discussed. We conclude with implications for HCI for how to support sustainable practices beyond being "about" being green.
2013	Quantity estimation in visualizations of tagged text	A valuable task in text visualization is to have viewers make judgments about text that has been annotated (either by hand or by some algorithm such as text clustering or entity extraction). In this work we look at the ability of viewers to make judgments about the relative quantities of tags in annotated text (specifically text tagged with one of a set of qualitatively distinct colors), and examine design choices that can improve performance at extracting statistical information from these texts. We find that viewers can efficiently and accurately estimate the proportions of tag levels over a range of situations; however accuracy can be improved through color choice and area adjustments.
2013	Contextifier: automatic generation of annotated stock visualizations	Online news tools - for aggregation, summarization and automatic generation - are an area of fruitful development as reading news online becomes increasingly commonplace. While textual tools have dominated these developments, annotated information visualizations are a promising way to complement articles based on their ability to add context. But the manual effort required for professional designers to create thoughtful annotations for contextualizing news visualizations is difficult to scale. We describe the design of Contextifier , a novel system that automatically produces custom, annotated visualizations of stock behavior given a news article about a company. Contextifier's algorithms for choosing annotations is informed by a study of professionally created visualizations and takes into account visual salience, contextual relevance, and a detection of key events in the company's history. In evaluating our system we find that Contextifier better balances graphical salience and relevance than the baseline.
2013	FreeD: a freehand digital sculpting tool	In this paper, we present an approach to combining digital fabrication and craft, emphasizing the user experience. While many researchers strive to enable makers to design and produce 3D objects, our research seeks to present a new fabrication approach to make unique, one-of-a-kind artifacts. To that end, we developed the FreeD, a hand-held digital milling device. The system is guided and monitored by a computer while preserving the maker's freedom to sculpt and carve, and to manipulate the work in many creative ways. Relying on a predesigned 3D model, the computer gets into action only when the milling bit risks the object's integrity, by slowing down the spindle's speed or by drawing back the shaft, while the rest of the time it allows complete gestural freedom. We describe the key concepts of our work and its motivation, present the FreeD's architecture and technology, and discuss two projects made with the tool.
2013	Effects of visualization and note-taking on sensemaking and analysis	Many sophisticated tools have been developed to help analysts detect patterns in large datasets, but the value of these tools' individual features is rarely tested. In an experiment in which participants played detectives solving homicides, we tested the utility of a visualization of data links and a notepad for collecting and organizing annotations. The visualization significantly improved participants' ability to solve the crime whereas the notepad did not. Having both features available provided no benefit over having just the visualization. The results raise questions about the potential constraints on the usefulness of intelligence analysis tools.
2013	A comparative evaluation of multiple chat stream interfaces for information-intensive environments	For information workers who monitor numerous constantly updating data streams, conserving cognitive resources is crucial. This study evaluated how an interface affects information workers' ability to grasp critical information from multiple text-based chat streams under time pressure. We designed and built a working prototype that displays ten chat streams simultaneously in standard chat windows (ST) and ticker tapes (TT). We conducted a lab experiment to evaluate differences in how these two interfaces support signal and context detection. We found that with ST, participants detected significantly more target words (SAT words) with rarer frequency and significantly more context information (disaster facts) than with TT. Our results show that while TT is potentially better for overview scanning of multiple streams, ST is likely to be better for multi-tasking. Our study informs the design of future multi-chat systems so that large amounts of information can be easier to detect and process.
2013	Job opportunities through entertainment: virally spread speech-based services for low-literate users	We explore how telephone-based services might be mass adopted by low-literate users in the developing world. We focus on speech and push-button dialog systems requiring neither literacy nor training. Building on the success of Polly , a simple telephone-based voice manipulation and forwarding system that was first tested in 2011, we report on its first large-scale sustained deployment. In 24/7 operation in Pakistan since May 9, 2012, as of mid-September Polly has spread to 85,000 users, engaging them in 495,000 interactions, and is continuing to spread to 1,000 new people daily. It has also attracted 27,000 people to a job search service, who in turn listened 279,000 times to job ads and forwarded them 22,000 times to their friends. We report users' activity over time and across demographics, analyze user behavior within several randomized controlled trials, and describe lessons learned regarding spread, scalability and sustainability of telephone-based speech-based services.
2013	Some evidence for the impact of limited education on hierarchical user interface navigation	One of the greatest challenges in designing applications for economically poor communities is that potential users may have little or no education. We investigated how limited education appears to impact the ability to navigate a hierarchical UI, even when it has no text. We scored 60 participants from low-income communities in India using tests of textual literacy and Raven's Progressive Matrices. These were used as proxies for educational level and a subset of cognitive abilities. We then evaluated participants' performance on a UI task involving hierarchical navigation. First, our results confirm that textual literacy is correlated with scores on the Raven's test. In addition, we found that performance on both instruments are predictive of performance in navigating UI hierarchies, even when the UI is text-free. This provides statistically significant confirmation of previous anecdotal hypotheses. We conclude with design recommendations for UI hierarchies for people with limited education.
2013	Hustling online: understanding consolidated facebook use in an informal settlement in Nairobi	Facebook is a global phenomenon, yet little is known about use of the site in urban parts of the developing world where the social network's users are increasingly located. We qualitatively studied Facebook use among 28 young adults living in Viwandani, an informal settlement, or slum, in Nairobi, Kenya. We find that to overcome the costs associated with Internet use, participants consolidated diverse online activities onto Facebook; here we focus on the most common practice--using Facebook to support income generation. Viwandani residents used the site to look for employment opportunities, market themselves, and seek remittances from friends and family abroad. We use our findings to motivate a design agenda for the urban poor built on an understanding that Facebook is used, with mixed-success, to support income generation. A key part of this agenda calls for developing ICT interventions grounded in users' existing practices rather than introducing new and unfamiliar ones.
2013	Improving two-thumb text entry on touchscreen devices	We study the design of split keyboards for fast text entry with two thumbs on mobile touchscreen devices. The layout of KALQ was determined through first studying how users should grip a device with two hands. We then assigned letters to keys computationally, using a model of two-thumb tapping. KALQ minimizes thumb travel distance and maximizes alternation between thumbs. An error correction algorithm was added to help address linguistic and motor errors. Users reached a rate of 37 words per minute (with a 5% error rate) after a training program.
2013	VideoKheti: making video content accessible to low-literate and novice users	Designing ICT systems for rural users in the developing world is difficult for a variety of reasons ranging from problems with infrastructure to wide differences in user contexts and capabilities. Developing regions may include huge variability in spoken languages, and users are often low- or non-literate, with very little experience interacting with digital technologies. Researchers have explored the use of text-free graphical interfaces as well as speech-based applications to overcome some of the issues related to language and literacy. While there are benefits and drawbacks to each of these approaches, they can be complementary when used together. In this work, we present VideoKheti, a mobile system using speech, graphics, and touch interaction for low-literate farmers in rural India. VideoKheti helps farmers to find and watch agricultural extension videos in their own language and dialect. In this paper, we detail the design and development of VideoKheti and report on a field study with 20 farmers in rural India who were asked to find videos based on a scenario. The results show that farmers could use VideoKheti, but their success still greatly depended on their education level. While participants were enthusiastic about using the system, the multimodal interface did not overcome many obstacles for low-literate users.
2013	ZoomBoard: a diminutive qwerty soft keyboard using iterative zooming for ultra-small devices	The proliferation of touchscreen devices has made soft keyboards a routine part of life. However, ultra-small computing platforms like the Sony SmartWatch and Apple iPod Nano lack a means of text entry. This limits their potential, despite the fact they are quite capable computers. In this work, we present a soft keyboard interaction technique called ZoomBoard that enables text entry on ultra-small devices. Our approach uses iterative zooming to enlarge otherwise impossibly tiny keys to comfortable size. We based our design on a QWERTY layout, so that it is immediately familiar to users and leverages existing skill. As the ultimate test, we ran a text entry experiment on a keyboard measuring just 16 x 6mm - smaller than a US penny. After eight practice trials, users achieved an average of 9.3 words per minute, with accuracy comparable to a full-sized physical keyboard. This compares favorably to existing mobile text input methods.
2013	Gestures and widgets: performance in text editing on multi-touch capable mobile devices	We describe the design and evaluation of a gestural text editing technique for touchscreen devices. The gestures are drawn on top of the soft keyboard and interpreted as commands for moving the caret, performing selections, and controlling the clipboard. Our implementation is an Android service that can be used in any text editing task on Android-based devices. We conducted an experiment to compare the gestural editing technique against the widget-based technique available on a smartphone (Samsung Galaxy II with Android 2.3.5). The results show a performance benefit of 13-24% for the gestural technique depending on the font size. Subjective feedback from the participants was also positive. Because the two editing techniques use different input areas, they can co-exist on a device. This means that the gestural editing can be added on any soft keyboard without interfering with user experience for those users that choose not to use it.
2013	ContextType: using hand posture information to improve mobile touch screen text entry	The challenge of mobile text entry is exacerbated as mobile devices are used in a number of situations and with a number of hand postures. We introduce ContextType, an adaptive text entry system that leverages information about a user's hand posture (using two thumbs, the left thumb, the right thumb, or the index finger) to improve mobile touch screen text entry. ContextType switches between various keyboard models based on hand posture inference while typing. ContextType combines the user's posture-specific touch pattern information with a language model to classify the user's touch events as pressed keys. To create our models, we collected usage patterns from 16 participants in each of the four postures. In a subsequent study with the same 16 participants comparing ContextType to a control condition, ContextType reduced total text entry error rate by 20.6%.
2013	Making touchscreen keyboards adaptive to keys, hand postures, and individuals: a hierarchical spatial backoff model approach	We propose a new approach for improving text entry accuracy on touchscreen keyboards by adapting the underlying spatial model to factors such as input hand postures, individuals, and target key positions. To combine these factors together, we introduce a hierarchical spatial backoff model (SBM) that consists of submodels with different levels of complexity. The most general model includes no adaptive factors, whereas the most specific model includes all three. Considering that in practice people may switch hand postures (e.g., from two-thumb to one-finger) to better suit a situation, and that the specific submodels may take time to train for each user, a specific submodel should be applied only if its corresponding input posture can be identified with confidence, and if the submodel has enough training data from the user. We introduce the backoff mechanism to fall back to a simpler model if either of these conditions are not met. We implemented a prototype system capable of reducing the language-model-independent error rate by 13.2% using an online posture classifier with 86.4% accuracy. Further improvements in error rate may be possible with even better posture classification.
2013	Materials, materiality, and media	In HCI, and especially in interaction design, the material aspect of interactions is currently emphasized. Nevertheless, it is challenging to theoretically frame the variety of digital or immaterial, and physical materials. In order to contribute to this materiality discourse, we reflect on McLuhan's work on media analysis and on Latour's Actor-Network Theory in this paper. Both emphasize the active role of the material - be it media or any other kind of non-human actors - in the interplay with the human. Thus, we establish junctures between their findings and materials, as used in interaction design in HCI. We discuss McLuhan's claim to focus on new sensory effects and ways of interaction brought forth by new media. Furthermore, we illustrate how describing the connections between materials, designers, and users in terms of Latour's Actor-Networks can be beneficial for interaction design. Finally, we discuss the respective methodology and its relation to research through design.
2013	Using behavioral data to identify interviewer fabrication in surveys	Surveys conducted by human interviewers are one of the principal means of gathering data from all over the world, but the quality of this data can be threatened by interviewer fabrication. In this paper, we investigate a new approach to detecting interviewer fabrication automatically. We instrument electronic data collection software to record logs of low-level behavioral data and show that supervised classification, when applied to features extracted from these logs, can identify interviewer fabrication with an accuracy of up to 96%. We show that even when interviewers know that our approach is being used, have some knowledge of how it works, and are incentivized to avoid detection, it can still achieve an accuracy of 86%. We also demonstrate the robustness of our approach to a moderate amount of label noise and provide practical recommendations, based on empirical evidence, on how much data is needed for our approach to be effective.
2013	Infrastructure and vocation: field, calling and computation in ecology	HCI studies of computational change in the sciences have made important design and analytic contributions, to other fields of science and to HCI itself. But some of the longer-term effects and complexities of infrastructural change in the sciences aren't easily captured under short-term, design- or artifact-centered accounts. Drawing on extended ethnographic study of computational development in ecology, this paper explores the relationship between new computational infrastructure and the nature of ecology as a vocation : roughly, the deeply held sense of what it means to 'be' an ecologist, and to 'do' ecology. We analyze in particular the nature of the field and field work as a central site of ecological practice and identity; how new computational developments are remediating this crucial relation; and the emergent vocational values that new and more computationally-intensive forms of ecology may give rise to.
2013	Design-driven narrative: using stories to prototype and build immersive design worlds	This paper examines the role of narrative in the process of interactive experience design, focusing on the potential uses of narrative in prototyping and iteration efforts to uncover deeper and more meaningful responses from users by engaging them in the co-creation of narratives of use around the design. We created a series of narrative fictions with embedded design concepts, and built low-fi prototype artifacts for directed storytelling sessions with twelve participants. We conclude with a discussion of findings regarding the opportunities to more effectively use narrative techniques and immersive storytelling to create valuable experiences between designers and users.
2013	FACIT PD: a framework for analysis and creation of intergenerational techniques for participatory design	In this paper, we present a framework that describes commonly used design techniques for Participatory Design with children. Although there are many currently used techniques for designing with children, researchers working in differing contexts and in a changing technological landscape find themselves facing difficult design situations. The FACIT PD framework presented in this paper can aid in choosing existing design techniques or in developing new techniques regardless of the stage in the design cycle, the technology being developed, or philosophical approach to design method. The framework consists of eight dimensions, concerning the design partners, the design goal, and the design technique. The partner dimensions are partner experience and need for accommodation . The design goal dimensions are design space and maturity of design . The technique dimensions include: cost, portability, technology and physical interaction . Three cases will be presented which describe new techniques developed using the framework and two cases will describe existing techniques.
2013	Mobiles, music, and materiality	Building on recent HCI contributions that assert the materiality of digital information, we examine the material nature of digital media and information technology in the context of mobile music production, reproduction, and reception in rural and semi-urban India. We use ethnographic methods to study the recent adoption and use of mobile technology and discuss our findings in relation to the evolving materiality of music. We also investigate the sociotechnical configurations that emerge as a consequence of this materiality. Thus we contribute to HCI research by showing how the material representations of digital media affect the interactions of humans with technology.
2013	Design research by proxy: using children as researchers to gain contextual knowledge about user experience.	This paper explores the use of participants as research collaborators in the domain of contextual user research. In participatory- and co-design, users participate increasingly early in the design process. When conducting user research in order to gain contextual knowledge about the lives, experiences and wishes of users, collaborators can be of help in setting up, conducting research and analyzing the data. A case study was conducted to investigate if and how children are able to perform as research collaborators. Children conducted interviews with other participants, and in doing increased their knowledge about people close to them, and about themselves. The gained insights were personal and the used personas proved to be a valuable tool. In the role of researcher, the children discovered similarities and differences between themselves and others. Besides gaining valuable insights from their participants, they accessed and shared their own experiences, so while listening to others, the children got sensitized themselves. In other words, the current study found that next to gathering more data, "super-sources" are created when children become research collaborators.
2013	Interview approaches to researching embodiment	The methods of data collection that we choose determine the kinds of data that we have access to, and thus shape analyses. In the context of novel interfaces where different modes, available through the environment and context, mediate the interaction, understanding methodological approaches is critical. This paper examines alternative methods of data collection for exploring student's embodied interaction with novel technology in a learning context. Specifically it analyses non-facilitated interaction in a tangible learning environment, in conjunction with three different post activity interview approaches: semi-structured interviews; semi-structured interview with video prompted recall; and interviews using the technology itself. Findings suggest that the different interview approaches change the nature of information elicited, and that non-facilitated interaction offers clearer insight into interpretation, both in terms of the meaning that emerges through, and is, therefore, embodied in the interaction, and in terms of representation, directly informing design.
2013	Three tensions in participatory design for inclusion	One ideal of Participatory Design (PD) is active involvement by all stakeholders as co-designers. However, when PD is applied to real projects, certain compromises are unavoidable, no matter what stakeholders are involved. With this paper we want to shed light on some of the challenges in implementing "true" PD in the case of designing with children, in particular children with severe disabilities. We do this work to better understand challenges in an ongoing project, RHYME, and by doing so we hope to provide insight and inspiration for others.
2013	Influencing visual judgment through affective priming	Recent research suggests that individual personality differences can influence performance with visualizations. In addition to stable personality traits, research in psychology has found that temporary changes in affect (emotion) can also significantly impact performance during cognitive tasks. In this paper, we show that affective priming also influences user performance on visual judgment tasks through an experiment that combines affective priming with longstanding graphical perception experiments. Our results suggest that affective priming can influence accuracy in common graphical perception tasks. We discuss possible explanations for these findings, and describe how these findings can be applied to design visualizations that are less (or more) susceptible to error in common visualization contexts.
2013	Waves: exploring idiographic design for live performance	We explore whether idiographic design, a category of interaction design that focuses upon responding to detailed personal accounts of individuals' practices, can be used to support interaction designers in responding to the complex and multifaceted design space posed by live performance. We describe and reflect upon the application of an idiographic approach during the design of Waves, an interface for live VJ performance. This approach involved a close and dialogical engagement with the practices and experiences of an individual live performer, during a series of semi-structured interviews and then the discussion and iteration of an evolving prototypical design. Reflection on the experience of applying this approach highlights idiographic design as a practical means to support interaction designers in proposing innovative designs that respond sensitively to the kinds of subtle and complex issues that underpin people's lived and felt experiences of live performance and, potentially, many other domains.
2013	Costs and benefits of structured information foraging	People spend an enormous amount of time searching for and saving information online. Existing tools capture only a small portion of the cognitive processing a user engages in while making sense of a new domain. In this paper we introduce a novel interface for capturing online information in a structured but lightweight way. We use this interface as a platform to experimentally characterize the costs and benefits of structuring information during the sensemaking process. Our results contribute empirical knowledge relevant to theories of information seeking and sensemaking, and practical implications for the development of tools to capture and share online information.
2013	Footprint tracker: supporting diary studies with lifelogging	As HCI shifts "to the wild", in-situ methods such as Diary Methods and the Experience Sampling Method are gaining momentum. However, researchers have acknowledged the intrusiveness and lack of realism in these methods and have proposed solutions, notably through lightweight and rich media capture. In this paper we explore the concept of lifelogging as an alternative solution to these two challenges. We describe Footprint Tracker , a tool that allows the review of lifelogs with the aim to support recall and reflection over daily activities and experiences. In a field trial, we study how four different types of cues, namely visual, location, temporal and social context , trigger memories of recent events and associated emotions. We conclude with a number of implications for the design of lifelogging systems that support recall and reflection upon recent events as well as ones lying further in our past.
2013	Investigating self-reporting behavior in long-term studies	Self-reporting techniques, such as data logging or a diary, are frequently used in long-term studies, but prone to subjects' forgetfulness and other sources of inaccuracy. We conducted a six-week self-reporting study on smartphone usage in order to investigate the accuracy of self-reported information, and used logged data as ground truth to compare the subjects' reports against. Subjects never recorded more than 70% and, depending on the requested reporting interval, down to less than 40% of actual app usages. They significantly overestimated how long they used apps. While subjects forgot self-reports when no automatic reminders were sent, a high reporting frequency was perceived as uncomfortable and burdensome. Most significantly, self-reporting even changed the actual app usage of users and hence can lead to deceptive measures if a study relies on no other data sources. With this contribution, we provide empirical quantitative long-term data on the reliability of self-reported data collected with mobile devices. We aim to make researchers aware of the caveats of self-reporting and give recommendations for maximizing the reliability of results when conducting large-scale, long-term app usage studies.
2013	Play it by ear: a case for serendipitous discovery of places with musicons	Current location-based services (LBS) typically allow users to locate points of interest (POI) in their vicinity but can detract from the user's emotional experience of exploring a new location. In this paper, we examine how cues in the form of popular music (musicons) can emotionally engage users and enhance their experience of discovering nearby POIs serendipitously in unfamiliar places. The primary contribution of this paper is a field study, in which we evaluate the performance and emotional engagement of different types of audio-based cues for directing users' attention to specific POIs. Musicons and mixed-modality cues performed close to visual and speech cues, and significantly better than auditory icons, for POI identification while creating a much more pleasant and engaging user experience. We conclude that cues for POI discovery need not always be as explicit as the baseline visual cues. Indeed, the most challenging cues, auditory icons, led to a heightened sense of autonomy.
2013	Effects of the display angle in museums on user's cognition, behavior, and subjective responses	In order to achieve the intended level of communication with visitors in museums where large displays are installed, it is essential to understand how various display factors affect visitors. We explore the effects of the display angle on individual users. In our experiment, we set up three types of flat displays - vertical, horizontal, and tilted - and comprehensively tested users' cognitive, behavioral, and subjective aspects. The results showed that a significant difference could be discerned in regards to cognitive and subjective aspects. Test results for the cognitive aspect showed that the display angle on which the displayed content was easy to understand and remember differed depending on age. Test results for the subjective aspect showed that irrespective of age, users rated tilted displays as being quicker to attract attention and easier to peruse, to understand and remember the content, and to interact with, and such displays were the most preferred.
2013	Reifying social movement trajectories	In this paper we describe the development of a novel paper-digital interface for recording movement trajectories, designed to assist ethnographers and ethologists in analysis of social movement. While we focus on development of a system to aid analysis of elephant movement, the resulting interaction techniques and facilities are quite general. The paper highlights how our design evolved to balance the goals of researchers, their current practices, and the challenges of integrating the relatively unconstrained world of pen and paper with the relatively constrained world of digital systems.
2013	The effect of global instructions on think-aloud testing	Verbal protocols are the primary tool for understanding users' task-solving behaviors during usability testing. We investigated whether the classic think-aloud and a think-aloud with an explicit instruction leads to different task-solving performance compared to silent working. The results suggest that the classic method had no impact on task performance whereas the explicit instruction led to an increase in within-page and between-page navigation and scrolling activity. The classic method was linked to an increase in mental workload in terms of effort and frustration. The explicit think-aloud led to an increase in mental demand, performance, effort and frustration.
2013	Bezel-Tap gestures: quick activation of commands from sleep mode on tablets	We present Bezel-Tap Gestures, a novel family of interaction techniques for immediate interaction on handheld tablets regardless of whether the device is alive or in sleep mode. The technique rests on the close succession of two input events: first a bezel tap, whose detection by accelerometers will awake an idle tablet almost instantly, then a screen contact. Field studies confirmed that the probability of this input sequence occurring by chance is very low, excluding the accidental activation concern. One experiment examined the optimal size of the vocabulary of commands for all four regions of the bezel (top, bottom, left, right). Another experiment evaluated two variants of the technique which both allow two-level selection in a hierarchy of commands, the initial bezel tap being followed by either two screen taps or a screen slide. The data suggests that Bezel-Tap Gestures may serve to design large vocabularies of micro-interactions with a sleeping tablet.
2013	TrailMap: facilitating information seeking in a multi-scale digital map via implicit bookmarking	Web applications designed for map exploration in local neighborhoods have become increasingly popular and important in everyday life. During the information-seeking process, users often revisit previously viewed locations, repeat earlier searches, or need to memorize or manually mark areas of interest. To facilitate rapid returns to earlier views during map exploration, we propose a novel algorithm to automatically generate map bookmarks based on a user's interaction. TrailMap, a web application based on this algorithm, is developed, providing a fluid and effective neighborhood exploration experience. A one-week study is conducted to evaluate TrailMap in users' everyday web browsing activities. Results showed that TrailMap's implicit bookmarking mechanism is efficient for map exploration and the interactive and visual nature of the tool is intuitive to users.
2013	iGrasp: grasp-based adaptive keyboard for mobile devices	Multitouch tablets, such as iPad and Android tablets, support virtual keyboards for text entry. Our 64-user study shows that 98% of the users preferred different keyboard layouts and positions depending on how they were holding these devices. However, current tablets either do not allow keyboard adjustment or require users to manually adjust the keyboards. We present iGrasp, which automatically adapts the layout and position of virtual keyboards based on how and where users are grasping the devices without requiring explicit user input. Our prototype uses 46 capacitive sensors positioned along the sides of an iPad to sense users' grasps, and supports two types of grasp-based automatic adaptation: layout switching and continuous positioning . Our two 18-user studies show that participants were able to begin typing 42% earlier using iGrasp's adaptive keyboard compared to the manually adjustable keyboard. Participants also rated iGrasp much easier to use than the manually adjustable keyboard (4.2 vs 2.9 on five-point Likert scale.)
2013	IrotateGrasp: automatic screen rotation based on grasp of mobile devices	Automatic screen rotation improves viewing experience and usability of mobile devices, but current gravity-based approaches do not support postures such as lying on one side, and manual rotation switches require explicit user input. iRotateGrasp automatically rotates screens of mobile devices to match users' viewing orientations based on how users are grasping the devices. Our insight is that users' grasps are consistent for each orientation, but significantly differ between different orientations. Our prototype used a total of 44 capacitive sensors along the four sides and the back of an iPod Touch, and uses support vector machine (SVM) to recognize grasps at 25Hz. We collected 6-users' usage under 108 different combinations of posture, orienta-tion, touchscreen operation, and left/right/both hands. Our offline analysis showed that our grasp-based approach is promising, with 80.9% accuracy when training and testing on different users, and up to 96.7% if users are willing to train the system. Our user study (N=16) showed that iRo-tateGrasp had an accuracy of 78.8% and was 31.3% more accurate than gravity-based rotation.
2013	The whats and hows of programmers' foraging diets	One of the least studied areas of Information Foraging Theory is diet: the information foragers choose to seek. For example, do foragers choose solely based on cost, or do they stubbornly pursue certain diets regardless of cost? Do their debugging strategies vary with their diets? To investigate "what" and "how" questions like these for the domain of software debugging, we qualitatively analyzed 9 professional developers' foraging goals, goal patterns, and strategies. Participants spent 50% of their time foraging. Of their foraging, 58% fell into distinct dietary patterns - mostly in patterns not previously discussed in the literature. In general, programmers' foraging strategies leaned more heavily toward enrichment than we expected, but different strategies aligned with different goal types. These and our other findings help fill the gap as to what programmers' dietary goals are and how their strategies relate to those goals.
2013	Supporting orientation during search result examination	Search engines help their users decide which results to visit using captions comprising titles, URLs, and snippets containing the query keywords and proximal text from landing pages (the search results linked from the result page). Although caption content can be a key factor in these decisions, snippets provide only basic support for orienting users with landing page content from the search-engine result page (SERP), and no support during the transition to landing pages or once users reach the page following a selection decision. As a result, many searchers must employ inefficient strategies such as skimming and scanning the content of the landing page. In this paper we propose a novel method, called clickable snippets , to address this shortcoming. Clickable snippets provide searchers with a direct and actionable link between SERP captions and landing-page content. We describe a user study comparing clickable snippets with extant methods of orientation support such as query-term highlighting on the landing page and thumbnail previews on the SERP. We show that clickable snippets are preferred by participants, and lead to more effective and efficient searching. Our findings have implications for the design of the user experience in search systems.
2013	Pirates of the search results page	Search malware redirects nearly 100% of infected users' clicks on web search results to unintended websites. Most published research details how web-based malware works and technological interventions to stop it before users ever see it; however, the constant evolution of obfuscation techniques makes it difficult to prevent infection altogether. User interventions in the form of toolbars, dialogs, and user education have seen limited success. Previous research has focused on a prototypical type of malware; a sophisticated program that conceals itself (e.g., surreptitious download onto a host computer) or tries to fool the user by mimicking known, trusted websites (e.g., phishing attacks). The goal of our research is to understand users' experience, understanding of and response to search malware . The present research shows that even when confronted with blatantly unusual search behavior, people are unlikely to attribute blame to malware or to engage in behavior that may remedy the situation.
2013	Multi-touch rotation gestures: performance and ergonomics	Rotations performed with the index finger and thumb involve some of the most complex motor action among common multi-touch gestures, yet little is known about the factors affecting performance and ergonomics. This note presents results from a study where the angle, direction, diameter, and position of rotations were systematically manipulated. Subjects were asked to perform the rotations as quickly as possible without losing contact with the display, and were allowed to skip rotations that were too uncomfortable. The data show surprising interaction effects among the variables, and help us identify whole categories of rotations that are slow and cumbersome for users.
2013	Leading people to longer queries	Although longer queries can produce better results for information seeking tasks, people tend to type short queries. We created an interface designed to encourage people to type longer queries, and evaluated it in two Mechanical Turk experiments. Results suggest that our interface manipulation may be effective for eliciting longer queries.
2013	Adaptive automation and cue invocation: the effect of cue timing on operator error	Adaptive automation (AA) can improve performance while addressing the problems associated with a fully automated system. The best way to invoke AA is unclear, but two ways include critical events and the operator's state. A hybrid model of AA invocation, the dynamic model of operator overload (DMOO), that takes into account critical events and the operator's state was recently shown to improve performance. The DMOO initiates AA using critical events and attention allocation, informed by eye movements. We compared the DMOO with an inaccurate automation invocation system and a system that invoked AA based only on critical events. Fewer errors were made with DMOO than with the inaccurate system. In the critical event condition, where automation was invoked at an earlier point in time, there were more memory and planning errors, while for the DMOO condition, which invocated automation at a later point in time, there were more perceptual errors. These findings provide a framework for reducing specific types of errors through different automation invocation.
2013	Webzeitgeist: design mining the web	Advances in data mining and knowledge discovery have transformed the way Web sites are designed. However, while visual presentation is an intrinsic part of the Web, traditional data mining techniques ignore render-time page structures and their attributes. This paper introduces design mining for the Web: using knowledge discovery techniques to understand design demographics, automate design curation, and support data-driven design tools. This idea is manifest in Webzeitgeist, a platform for large-scale design mining comprising a repository of over 100,000 Web pages and 100 million design elements. This paper describes the principles driving design mining, the implementation of the Webzeitgeist architecture, and the new class of data-driven design applications it enables.
2013	Reducing disruption from subtle information delivery during a conversation: mode and bandwidth investigation	With proliferation of mobile devices that provide ubiquitous access to information, the question arises of how distracting processing information in social settings can be, especially during face-to-face conversations. However, relevant information presented at opportune moments may help enhance conversation quality. In this paper, we study how much information users can consume during a conversation and what information delivery mode, via audio or visual aids, helps them effectively conceal the fact that they are receiving information. We observe that users can internalize more information while still disguising this fact the best when information is delivered visually in batches (multiple pieces of information at a time) and perform better on both dimensions if information is delivered while they are not speaking. Interestingly, participants qualitatively did not prefer this mode as being the easiest to use, preferring modes that displayed one piece of information at a time.
2013	Modeling how people extract color themes from images	Color choice plays an important role in works of graphic art and design. However, it can be difficult to choose a compelling set of colors, or color theme , from scratch. In this work, we present a method for extracting color themes from images using a regression model trained on themes created by people. We collect 1600 themes from Mechanical Turk as well as from artists. We find that themes extracted by Turk participants were similar to ones extracted by artists. In addition, people tended to select diverse colors and focus on colors in salient image regions. We show that our model can match human-extracted themes more closely compared to previous work. Themes extracted by our model were also rated higher as representing the image than previous approaches in a Mechanical Turk study.
2013	How tools in IDEs shape developers' navigation behavior	Understanding source code is crucial for successful software maintenance, and navigating the call graph is especially helpful to understand source code [12]. We compared maintenance performance across four different development environments: an IDE without any call graph exploration tool, a Call Hierarchy tool as found in Eclipse, and the tools Stacksplorer [7]and Blaze [11]. Using any of the call graph exploration tools more developers could solve certain maintenance tasks correctly. Only Stacksplorer and Blaze, however, were also able to decrease task completion times, although the Call Hierarchy offers access to a larger part of the call graph. To investigate if this result was caused by a change in navigation behavior between the tools, we used a set of predictive models to create formally comparable descriptions of programmer navigation. The results suggest that the decrease in task completion times has been caused by Stacksplorer and Blaze promoting call graph navigation more than the Call Hierarchy tool.
2013	Distraction beyond the driver: predicting the effects of in-vehicle interaction on surrounding traffic	Recent studies of driver distraction have reported a number of detrimental effects of in-vehicle interaction on driver performance. This paper examines and predicts the potential effects of such interaction on other vehicles around the driver's vehicle. Specifically, the paper describes how computational cognitive models can be used to predict the complex interactions among several vehicles driving in a line when one or more of the vehicles' drivers are performing a secondary task (phone dialing). The results of simulating two distinct car-following scenarios illustrate that in-vehicle interaction by one driver can have significant downstream effects on other drivers, especially with respect to speed deviations relative to a lead vehicle. This work generalizes recent work developing computational evaluation tools for user interfaces in complex domains, and further serves as an example of how user interaction in some domains can have broader effects on the community at large.
2013	Picode: inline photos representing posture data in source code	Current programming environments use textual or symbolic representations. While these representations are appropriate for describing logical processes, they are not appropriate for representing raw values such as human and robot posture data, which are necessary for handling gesture input and controlling robots. To address this issue, we propose Picode , a text-based development environment integrated with visual representations: photos of human and robots. With Picode , the user first takes a photo to bind it to posture data. S/he then drag-and-drops the photo into the code editor, where it is displayed as an inline image. A preliminary in-house user study implied positive effects of taking photos on the programming experience.
2013	Informal cognitive walkthroughs (ICW): paring down and pairing up for an agile world	Agile software teams' frequent releases and fast iterations present a growing need for rigorous user experience research methods that are faster, lighter-weight, and more flexible. To this end, we developed the Informal Cognitive Walkthrough (ICW). This agile research methodology grew organically, over the course of three years, while working with a very large agile software development team. ICWs involve conducting one or more Simplified 'Streamlined Cognitive Walkthroughs' (SSCW), followed by one or more Simplified 'Pluralistic Walkthroughs' (SPW). In this paper, we present the ICW and provide a real-world example of its application. Preliminary experiences with the method revealed potential advantages over traditional lab studies, ranging from more quickly uncovering and fixing usability issues, to a stronger collaboration between the disciplines, and to acting as a forcing function in aligning diverse engineers to deliver on a common user goal.
2013	I feel for my avatar: embodied perception in VEs	Visual perception is dependent upon one's physical state. The apparent inclination of a hill is overestimated when the observer is carrying a heavy backpack. But, what if the hill is a virtual one and the user is about to navigate the virtual environment through an avatar? In a 2 (user with a backpack vs. user without the backpack) × 2 (avatar with a virtual backpack vs. avatar without a virtual backpack) × 2 (customized avatar vs. assigned avatar) between-subjects experiment ( N = 121), participants estimated the hill as being steeper when using a customized avatar rather than an assigned one. When the avatar is encumbered by a heavy virtual backpack, those with a customized avatar perceived the virtual hill as being more difficult to climb. Avatar customization and the physical resources of the avatar (operationalized here in the form of a 'virtual' backpack) were found to be key predictors of embodied perception in virtual environments (VE). This has implications for the design of games and interventions that make use of VEs.
2013	Evaluation of tablet apps to encourage social interaction in children with autism spectrum disorders	The increasing rates of diagnosis for Autism Spectrum Disorders (ASDs) have brought unprecedented attention to these conditions. Interventions during childhood can increase the likelihood of independent living later in life, but most adults with ASDs who benefited from early intervention do not live independently. There is a need for novel therapies and interventions that can help children with ASDs develop the social skills necessary to live independently. Since the launch of the iPad, there has been a great deal of excitement in the autism community about multitouch tablets and their possible use in interventions. There are hundreds of apps listed as possibly helping children with ASDs, yet there is little empirical evidence that any of them have positive effects. In this paper we present a study on the use of a set of apps from Open Autism Software at an afterschool program for children with ASDs. The apps are designed to naturally encourage positive social interactions through creative, expressive, and collaborative activities. The study compared activities conducted with the apps to similar activities conducted without the apps. We video recorded the activities, and coded children's behavior. We found that during the study children spoke more sentences, had more verbal interactions, and were more physically engaged with the activities when using the apps. We also found that children made more supportive comments during activities conducted with two of the apps. The results suggest the approach to using apps evaluated in this paper can increase positive social interactions in children with ASDs.
2013	Designing graphical menus for novices and experts: connecting design characteristics with design goals	This paper presents a design space for graphical menus. We model the design space as a set of design goals, a set of design characteristics, and connections between the two. The design goals are based on novice and expert behaviors. The connections link the choices for design characteristics with the positive or negative effects that these choices have on the design goals. The paper further synthesizes the design space into a succinct form of structured design recommendations. A case study demonstrates how these recommendations can be used to assess and compare the strengths and weaknesses of two menu designs.
2013	Canyon: providing location awareness of multiple moving objects in a detail view on large displays	Overview+Detail interfaces can be used to examine the details of complex data while retaining the data's overall context. Dynamic data introduce challenges for these interfaces, however, as moving objects may exit the detail view, as well as a person's field of view if they are working at a large interactive surface. To address this "off-view" problem, we propose a new information visualization technique, called Canyon. This technique attaches a small view of an off-view object, including some surrounding context, to the external boundary of the detail view. The area between the detail view and the region containing the off-view object is virtually "folded" to conserve space. A comparison study was conducted contrasting the benefits and limitations of Canyon to an established technique, called Wedge. Canyon was more accurate across a number of tasks, especially more complex tasks, and was comparably efficient.
2013	Testing the robustness and performance of spatially consistent interfaces	Relative spatial consistency - that is, the stable arrangement of objects in a 2D presentation - provides several benefits for interactive interfaces. Spatial consistency allows users to develop memory of object locations, reducing the time needed for visual search, and because spatial memory is long lasting and has a large capacity these performance benefits are enduring and scalable. This suggests that spatial consistency could be used as a fundamental principle for the design of interfaces. However, there are many display situations where the standard presentation is altered in some way: e.g., a window is moved to a new location, scaled, or rotated on a mobile or tabletop display. It is not known whether the benefits of spatial organization are robust to these common kinds of view transformation. To assess these effects, we tested user performance with a spatial interface that had been transformed in several ways, including different degrees of translation, rotation, scaling, and perspective change. We found that performance was not strongly affected by the changes, except in the case of large rotations. To demonstrate the value of spatial consistency over existing mechanisms for dealing with view changes, we compared user performance with a spatially-stable presentation (using scaling) with that of a 'reflowing' presentation (widely used in current interfaces). This study showed that spatial stability with scaling dramatically outperforms reflowing. This research provides new evidence of spatial consistency's value in interface design: it is robust to the view transformations that occur in typical environments, and it provides substantial performance advantages over traditional methods.
2013	Why do they still use paper?: understanding data collection and use in Autism education	Autism education programs for children collect and use large amounts of behavioral data on each student. Staff use paper almost exclusively to collect these data, despite significant problems they face in tracking student data in situ, filling out data sheets and graphs on a daily basis, and using the sheets in collaborative decision making. We conducted fieldwork to understand data collection and use in the domain of autism education to explain why current technology had not met staff needs. We found that data needs are complex and unstandardized, immediate demands of the job interfere with staff ability to collect in situ data, and existing technology for data collection is inadequate. We also identified opportunities for technology to improve sharing and use of data. We found that data sheets are idiosyncratic and not useful without human mediation; improved communication with parents could benefit children's development; and staff are willing, and even eager, to incorporate technology. These factors explain the continued dependence on paper for data collection in this environment, and reveal opportunities for technology to support data collection and improve use of collected data.
2013	Investigating the use of circles in social networks to support independence of individuals with autism	Building social support networks is crucial both for less-independent individuals with autism and for their primary caregivers. In this paper, we describe a four-week exploratory study of a social network service (SNS) that allows young adults with autism to garner support from their family and friends. We explore the unique benefits and challenges of using SNSs to mediate requests for help or advice. In particular, we examine the extent to which specialized features of an SNS can engage users in communicating with their network members to get advice in varied situations. Our findings indicate that technology-supported communication particularly strengthened the relationship between the individual and extended network members, mitigating concerns about over-reliance on primary caregivers. Our work identifies implications for the design of social networking services tailored to meet the needs of this special needs population.
2013	TOBY: early intervention in autism through technology	We describe TOBY Playpad, an early intervention program for children with Autism Spectrum Disorder (ASD). TOBY teaches the teacher -- the parent -- during the crucial period following diagnosis, which often coincides with no access to formal therapy. We reflect on TOBY's evolution from table-top aid for flashcards to an iPad app covering a syllabus of 326 activities across 51 skills known to be deficient for ASD children, such imitation, joint attention and language. The design challenges unique to TOBY are the need to adapt to marked differences in each child's skills and rate of development (a trait of ASD) and teach parents unfamiliar concepts core to behavioural therapy, such as reinforcement, prompting, and fading. We report on three trials that successively decrease oversight and increase parental autonomy, and demonstrate clear evidence of learning. TOBY's uniquely intertwined Natural Environment Tasks are found to be effective for children and popular with parents.
2013	Studying spatial memory and map navigation performance on projector phones with peephole interaction	Smartphones are useful personal assistants and omnipresent communication devices. However, collaboration is not among their strengths. With the advent of embedded projectors this might change. We conducted a study with 56 participants to find out if map navigation and spatial memory performance among users and observers can be improved by using a projector phone with a peephole interface instead of a smartphone with its touchscreen interface. Our results show that users performed map navigation equally well on both interfaces. Spatial memory performance, however, was 41% better for projector phone users. Moreover, observers of the map navigation on the projector phone were 25% more accurate when asked to recall locations of points of interest after they watched a user performing map navigation.
2013	Binocular cursor: enabling selection on transparent displays troubled by binocular parallax	Binocular parallax is a problem for any interaction system that has a transparent display and objects behind it, as users will see duplicated and overlapped images. In this note, we propose a quantitative measure called Binocular Selectability Discriminant (BSD) to predict the ability of the user to perform selection task in such a setup. In addition, we propose a technique called Binocular Cursor (BC) which takes advantage of this duplicating and overlapping phenomenon, rather than being hampered by it, to resolve binocular selection ambiguity by visualizing the correct selection point. An experiment shows that selection with BC is not slower than monocular selection, and that it can be significantly more precise, depending on the design of BC.
2013	Predicting postpartum changes in emotion and behavior via social media	We consider social media as a promising tool for public health, focusing on the use of Twitter posts to build predictive models about the forthcoming influence of childbirth on the behavior and mood of new mothers. Using Twitter posts, we quantify postpartum changes in 376 mothers along dimensions of social engagement, emotion, social network, and linguistic style. We then construct statistical models from a training set of observations of these measures before and after the reported childbirth, to forecast significant postpartum changes in mothers. The predictive models can classify mothers who will change significantly following childbirth with an accuracy of 71%, using observations about their prenatal behavior, and as accurately as 80-83% when additionally leveraging the initial 2-3 weeks of postnatal data. The study is motivated by the opportunity to use social media to identify mothers at risk of postpartum depression, an underreported health concern among large populations, and to inform the design of low-cost, privacy-sensitive early-warning systems and intervention programs aimed at promoting wellness postpartum.
2013	Understanding motivations for facebook use: usage metrics, network structure, and privacy	This study explores the links between motives for using a social network service and numerical measures of that activity. Specifically, it identified motives for Facebook use by employing a Uses and Gratifications (U&G) approach and then investigated the extent to which these motives can be predicted through usage and network metrics collected automatically via the Facebook API. In total, 11 Facebook usage metrics and eight personal network metrics served as predictors. Results showed that all three variable types in this expanded U&G frame of analysis (covering social antecedents, usage metrics, and personal network metrics) effectively predicted motives and highlighted interesting behaviors. To further illustrate the power of this framework, the intricate nature of privacy in social media was explored and relationships drawn between privacy attitudes (and acts) and measures of use and network structure.
2013	Evaluation of alternative glyph designs for time series data in a small multiple setting	We present the results of a controlled experiment to investigate the performance of different temporal glyph designs in a small multiple setting. Analyzing many time series at once is a common yet difficult task in many domains, for example in network monitoring. Several visualization techniques have, thus, been proposed in the literature. Among these, iconic displays or glyphs are an appropriate choice because of their expressiveness and effective use of screen space. Through a controlled experiment, we compare the performance of four glyphs that use different combinations of visual variables to encode two properties of temporal data: a) the position of a data point in time and b) the quantitative value of this data point. Our results show that depending on tasks and data density, the chosen glyphs performed differently. Line Glyphs are generally a good choice for peak and trend detection tasks but radial encodings are more effective for reading values at specific temporal locations. From our qualitative analysis we also contribute implications for designing temporal glyphs for small multiple settings.
2013	Motif simplification: improving network visualization readability with fan, connector, and clique glyphs	Analyzing networks involves understanding the complex relationships between entities, as well as any attributes they may have. The widely used node-link diagrams excel at this task, but many are difficult to extract meaning from because of the inherent complexity of the relationships and limited screen space. To help address this problem we introduce a technique called motif simplification, in which common patterns of nodes and links are replaced with compact and meaningful glyphs. Well-designed glyphs have several benefits: they (1) require less screen space and layout effort, (2) are easier to understand in the context of the network, (3) can reveal otherwise hidden relationships, and (4) preserve as much underlying information as possible. We tackle three frequently occurring and high-payoff motifs: fans of nodes with a single neighbor, connectors that link a set of anchor nodes, and cliques of completely connected nodes. We contribute design guidelines for motif glyphs; example glyphs for the fan, connector, and clique motifs; algorithms for detecting these motifs; a free and open source reference implementation; and results from a controlled study of 36 participants that demonstrates the effectiveness of motif simplification.
2013	i read my Twitter the next morning and was astonished: a conversational perspective on Twitter regrets	We present the results of an online survey of 1,221 Twitter users, comparing messages individuals regretted either saying during in-person conversations or posting on Twitter. Participants generally reported similar types of regrets in person and on Twitter. In particular, they often regretted messages that were critical of others. However, regretted messages that were cathartic/expressive or revealed too much information were reported at a higher rate for Twitter. Regretted messages on Twitter also reached broader audiences. In addition, we found that participants who posted on Twitter became aware of, and tried to repair, regret more slowly than those reporting in-person regrets. From this comparison of Twitter and in-person regrets, we provide preliminary ideas for tools to help Twitter users avoid and cope with regret.
2013	Limiting, leaving, and (re)lapsing: an exploration of facebook non-use practices and experiences	Despite the abundance of research on social networking sites, relatively little research has studied those who choose not to use such sites. This paper presents results from a questionnaire of over 400 Internet users, focusing specifically on Facebook and those users who have left the service. Results show the lack of a clear, binary distinction between use and non-use, that various practices enable diverse ways and degrees of engagement with and disengagement from Facebook. Furthermore, qualitative analysis reveals numerous complex and interrelated motivations and justifications, both for leaving and for maintaining some type of connection. These motivations include: privacy, data misuse, productivity, banality, addiction, and external pressures. These results not only contribute to our understanding of online sociality by examining this under-explored area, but they also build on previous work to help advance how we conceptually account for the sociological processes of non-use.
2013	What is critical about critical design?	Critical design is a research through design methodology that foregrounds the ethics of design practice, reveals potentially hidden agendas and values, and explores alternative design values. While it seems to be a timely fit for today's socially, aesthetically, and ethically oriented approaches to HCI, its adoption seems surprisingly limited. We argue that its central concepts and methods are unclear and difficult to adopt. Rather than merely attempting to decode the intentions of its originators, Dunne and Raby, we instead turn to traditions of critical thought in the past 150 years to explore a range of critical ideas and their practical uses. We then suggest ways that these ideas and uses can be leveraged as practical resources for HCI researchers interested in critical design. We also offer readings of two designs, which are not billed as critical designs, but which we argue are critical using a broader formulation of the concept than the one found in the current literature.
2013	Interactive horizon graphs: improving the compact visualization of multiple time series	Many approaches have been proposed for the visualization of multiple time series. Two prominent approaches are reduced line charts (RLC) , which display small multiples for time series, and the more recent horizon graphs (HG) . We propose to unify RLC and HG using a new technique - interactive horizon graphs (IHG) - which uses pan and zoom interaction to increase the number of time series that can be analysed in parallel. In a user study we compared RLC, HG, and IHG across several tasks and numbers of time series, focusing on datasets with both large scale and small scale variations. Our results show that IHG outperform the other two techniques in complex comparison and matching tasks where the number of charts is large. In the hardest task PHG have a significantly higher number of good answers (correctness) than HG (+14%) and RLC (+51%) and a lower error magnitude than HG (-64%) and RLC (-86%).
2013	Patina: dynamic heatmaps for visualizing application usage	We present Patina , an application independent system for collecting and visualizing software application usage data. Patina requires no instrumentation of the target application, all data is collected through standard window metrics and accessibility APIs. The primary visualization is a dynamic heatmap overlay which adapts to match the content, location, and shape of the user interface controls visible in the active application. We discuss a set of design guidelines for the Patina system, describe our implementation of the system, and report on an initial evaluation based on a short-term deployment of the system.
2013	Mind the theoretical gap: interpreting, using, and developing behavioral theory in HCI research	Researchers in HCI and behavioral science are increasingly exploring the use of technology to support behavior change in domains such as health and sustainability. This work, however, remain largely siloed within the two communities. We begin to address this silo problem by attempting to build a bridge between the two disciplines at the level of behavioral theory. Specifically, we define core theoretical terms to create shared understanding about what theory is, discuss ways in which behavioral theory can be used to inform research on behavior change technologies, identify shortcomings in current behavioral theories, and outline ways in which HCI researchers can not only interpret and utilize behavioral science theories but also contribute to improving them.
2013	The design space of body games: technological, physical, and social design	The past decade has seen an increased focus on body movement in computer games. We take a step further to look at body games : games in which the main source of enjoyment comes from bodily engagement. We argue that for these games, the physical and social settings become just as important design resources as the technology. Although all body games benefit from an integrated design approach, the social and physical setting become particularly useful as design resources when the technology has limited sensing capabilities. We develop our understanding of body games through a literature study and a concrete design experiment with designing multiplayer games for the BodyBug, a mobile device with limited sensing capabilities. Although the device was designed for free and natural movements, previous games fell short in realizing this design ideal. By designing the technology function together with its physical and social context, we were able to overcome device limitations. One of the games was subsequently incorporated in its commercial release.
2013	Beyond digital and physical objects: the intellectual work as a concept of interest for HCI	To understand activities of personal collecting and preservation, HCI researchers have investigated why people become attached to particular objects. These studies have examined ways that people relate to physical and digital objects, observing, for example, that people tend to cherish physical objects more than digital ones. This paper proposes that the value of digital objects may inhere less in an object's identity as a particular item and more in the object's ability to provide access to an intellectual work. The work, a familiar concept in information studies and textual studies, designates a general product of intellectual creation that may be instantiated in many versions. (For example, Shakespeare's Hamlet exists in many editions and forms, which may differ in both content and carrier and yet still are all Hamlet.) The paper demonstrates how the concept of the work can extend research on the perceived value of digital objects. It also shows how a flexible definition of the work can reveal new aspects of a design situation.
2013	Collaborative sensemaking on a digital tabletop and personal tablets: prioritization, comparisons, and tableaux	We describe an investigation of the support that three different display configurations provided for a collaborative sensemaking task: a digital table; personal tablets; and both the tabletop and personal tablets. Mixed-methods analyses revealed that the presence of a digital tabletop display led to improved sensemaking performance, and identified activities that were supported by the shared workspace. The digital tabletop supported a group's ability to prioritize information, to make comparisons between task data, and to form and critique the group's working hypothesis. Analyses of group performance revealed a positive correlation with equity of member participation using the shared digital table, and a negative correlation of equity of member participation using personal tablets. Implications for the support of sensemaking groups, and the use of equity of member participation as a predictive measure of their performance are discussed.
2013	Personal clipboards for individual copy-and-paste on shared multi-user surfaces	Clipboards are omnipresent on today's personal computing platforms. They provide copy-and-paste functionalities that let users easily reorganize information and quickly transfer data across applications. In this work, we introduce personal clipboards to multi-user surfaces. Personal clipboards enable individual and independent copy-and-paste operations, in the presence of multiple users concurrently sharing the same direct-touch interface. As common surface computing platforms do not distinguish touch input of different users, we have developed clipboards that leverage complementary personalization strategies. Specifically, we have built a context menu clipboard based on implicit user identification of every touch, a clipboard based on personal subareas dynamically placed on the surface, and a handheld clipboard based on integration of personal devices for surface interaction. In a user study, we demonstrate the effectiveness of personal clipboards for shared surfaces, and show that different personalization strategies enable clipboards, albeit with different impacts on interaction characteristics.
2013	A comparative evaluation of touch-based methods to bind mobile devices for collaborative interactions	We present a comparative evaluation of two touch-based group-binding methods, a leader-driven method and a peer-based method, against a more conventional group-binding method based on scanning and passwords. The results indicate that the participants strongly preferred the touch-based methods in both pragmatic and hedonic qualities as well as in the overall attractiveness. While the leader-driven method allowed better control over the group and required only one participant to be able to form a group, the peer-based method helped to create a greater sense of community and scaled better for larger group sizes and distances. As the optimal group-binding method depends on the social situation and physical environment, the binding methods should be flexible, allowing the users to adapt them to different contexts of use. For determining the order of the devices, manual arrangement was preferred over defining the order by touching.
2013	Critical perspective on persuasive technology reconsidered	Critical researchers in HCI have recently faulted Persuasive Technology (PT) for taking a modernist approach and suggested ways for redirecting research. This paper reflects on this critical perspective and compares it with Habermas's critical perspective. I claim that the recent critiques of PT are grounded on a narrow and pessimistic concept of modernism, and that Habermas's works, rarely taken into account in the HCI community, can serve as an alternative lens for reflective analysis and design and can provide a foundation for justifying design decisions while realizing the unfulfilled potentials of PT. Beyond offering critical analysis and reflections, this paper contributes to the HCI field by calling attention to alternative reflective concepts and emerging relevant works.
2013	Seeing movement qualities	With the increased availability of movement based interactive devices there is a growing interest in exploring the potential design space for engaging movement-based interactions. This has led to the exploration of different ways to sense and model movement such as Laban Movement Analysis' Effort qualities. However, little is understood in how movement qualities are perceived and experienced by users. We explored this in an interactive improvisational dance performance setting. From video analysis with a Laban Movement expert and post-performance interviews with audience members, we discuss the differences in how a movement quality was perceived. From these findings, we discuss implications for further efforts in designing interactive movement-based systems that strive to capitalize on movement qualities.
2013	CrashAlert: enhancing peripheral alertness for eyes-busy mobile interaction while walking	Mobile device use while walking, or eyes-busy mobile interaction , is a leading cause of life-threatening pedestrian collisions. We introduce CrashAlert, a system that augments mobile devices with a depth camera, to provide distance and location visual cues of obstacles on the user's path. In a realistic environment outside the lab, CrashAlert users improve their handling of potential collisions, dodging and slowing down for simple ones while lifting their head in more complex situations. Qualitative results outline the value of extending users' peripheral alertness in eyes-busy mobile interaction through non-intrusive depth cues, as used in CrashAlert. We present the design features of our system and lessons learned from our evaluation.
2013	How categories come to matter	In a study of users' interactions with Siri, the iPhone personal assistant application, we noticed the emergence of overlaps and blurrings between explanatory categories such as "human" and "machine". We found that users work to purify these categories, thus resolving the tensions related to the overlaps. This "purification work" demonstrates how such categories are always in flux and are redrawn even as they are kept separate. Drawing on STS analytic techniques, we demonstrate the mechanisms of such "purification work." We also describe how such category work remained invisible to us during initial data analysis, due to our own forms of latent purification, and outline the particular analytic techniques that helped lead to this discovery. We thus provide an illustrative case of how categories come to matter in HCI research and design.
2013	Indoor weather stations: investigating a ludic approach to environmental HCI through batch prototyping	In this project, we investigated how a ludic approach might open new possibilities for environmental HCI by designing three related devices that encourage environmental awareness while eschewing utilitarian or persuasive agendas. In addition, we extended our methodological approach by batch-producing multiple copies of each device and deploying them to 20 households for several months, gathering a range of accounts about how people engaged and used them. The devices, collectively called the 'Indoor Weather Stations', reveal the home's microclimate by highlighting small gusts of wind, the colour of ambient light, and temperature differentials within the home. We found that participants initially tended to relate to the devices in line with two 'orienting narratives' of environmental tools or ludic designs, finding the devices disappointing from either perspective. Most of our participants showed lingering affection for the devices, however, for a variety of reasons. We discuss the implications of this 'sporadic interaction', and the more general lessons from the project, both for environmental HCI and ludic design.
2013	Privacy as part of the app decision-making process	Smartphones have unprecedented access to sensitive personal information. While users report having privacy concerns, they may not actively consider privacy while downloading apps from smartphone application marketplaces. Currently, Android users have only the Android permissions display, which appears after they have selected an app to download, to help them understand how applications access their information. We investigate how permissions and privacy could play a more active role in app-selection decisions. We designed a short "Privacy Facts' display, which we tested in a 20-participant lab study and a 366-participant online experiment. We found that by bringing privacy information to the user when they were making the decision and by presenting it in a clearer fashion, we could assist users in choosing applications that request fewer permissions.
2013	Making design probes work	Probes have been adopted with great enthusiasm in both Design and HCI. The heterogeneity with which they have been used in practice reflects how the method has proved elusive for many. Originators and commentators of probes have discussed misinterpretations of the method, highlighting the lack of accounts that describe in detail the design of probes and their use with participants. This paper discusses our particular use of Design Probes as directed craft objects that are both tools for design and tools for exploration across a number of projects, spanning a decade, centered on self-identity and personal significance. In offering an example of what a framework for probe design and use might look like, we attempt to address the identified lacuna, providing a synthetic account of probe design and use over an extended period and conceptualizing the relationship between the properties of probes and their use in design projects.
2013	Shifting dynamics or breaking sacred traditions?: the role of technology in twelve-step fellowships	Twelve-step fellowships are the most common long-term maintenance program for recovery from alcoholism and addiction. Informed by six months of participatory observation of twelve-step fellowship meetings and service structure, I conducted in-depth interviews with twelve members of Alcoholics Anonymous (AA) and Narcotics Anonymous (NA) about the role of technology in recovery. I found that there are a number of tensions in how technology is perceived and adopted. As technology and twelve-step fellowships interact, issues of anonymity, identity, consensus, access, unity, autonomy, and physical presence are foregrounded. I relate these findings to the broader research landscape and provide implications for future design in this space.
2013	Everybody knows what you're doing: a critical design approach to personal informatics	We present an alternative approach to the design of personal informatics systems: instead of motivating people to examine their own behaviors, this approach promotes awareness of and reflection on the infrastructures behind personal informatics and the modes of engagement that they promote. Specifically, this paper presents an interface that displays personal web browsing data. The interface aims to reveal underlying infrastructure using several methods: drawing attention to the scope of mined data by displaying deliberately selected sensitive data, using purposeful malfunction as a way to encourage reverse engineering, and challenging normative expectations around data mining by displaying information in unconventional ways. Qualitative results from a two-week deployment show that these strategies can raise people's awareness about data mining, promote efficacy and control over personal data, and inspire reflection on the goals and assumptions embedded in infrastructures for personal data analytics.
2013	Slow design for meaningful interactions	In this paper we report on an exploration of how to apply the theory of Slow Design to mass produced products to establish more mindful usage of products; the intention behind this is to promote product attachment and the associated sustainable benefits of long term use. Slow Design is a design philosophy that focuses on promoting well-being for individuals, society, and the natural environment. It encourages people to do things at the right time and at the right speed which helps them to understand and reflect on their actions. Several authors have proposed Slow Design principles and cases have been reported in which these principles were applied in cultural design projects. These applications indicated that Slow Design can indeed have a positive impact on wellbeing. Although promising, this philosophy has not yet been used in the design of mass consumer products. In this paper we present a design case study in which we explored how the Slow Design principles can be applied in the design of an electric fruit juicer. Two studies are reported on where the conditions for implementing Slow Design are explored. The results led to a revision of the principles for use by product designers. The main finding from the case study is that the Slow Design principles can be used to create more 'mindful' interactions that stimulate positive user involvement. This is not from designing interactions that require more time per se, but by stimulating the user to use more time for those parts of the interaction that are meaningful and less for those that are not meaningful.
2013	Three perspectives on behavior change for serious games	Research into the effects of serious games often engages with interdisciplinary models of how human behaviors are shaped and changed over time. To better understand these different perspectives we articulate three cognitive models of behavior change and consider the potential of these models to support a deeper understanding of behavior change in serious games. Two of these models -- Information Deficit and Procedural Rhetoric -- have already been employed in the design of serious games, while the third -- Emergent Dialogue -- is introduced from the field of Environmental Studies. We situate this discussion within a context of designing games for public engagement with issues of environmental sustainability.
2013	Taking data exposure into account: how does it affect the choice of sign-in accounts?	Online services collect personal data from their users, sometimes with no clear need. We studied how users sign-in to web sites using federated IDs, and found that most survey respondents were not aware of the data they expose. However, when presented with the tradeoffs behind each sign-in option, respondents reported a willingness to change how they sign-in to reduce their data exposure or, in fewer cases, to increase it to receive more benefits from the service. Our findings suggest that data exposure is a concern for users, and that there is a need for finding clearer ways for communicating it for each sign-in option.
2013	Understanding the privacy-personalization dilemma for web search: a user perspective	Contemporary search engines use a variety of techniques to personalize search results based on users' past queries. While studies have found that users generally prefer personalized search results to non-personalized ones, recent surveys also indicate growing reservations with respect to personalization because of its privacy implications. In this paper, we take a deeper look at privacy considerations of users during web search and explore how users' preferences for privacy and personalization interact when undertaking this activity. We conduct an empirical study over Google search, involving 25 participants in India and their respective web search histories. Our finding is that users exhibit a slight preference for personalization in their search results but are usually willing to "give up" personalization when searching for topics they deem sensitive. We discuss implications of these results for the design of privacy-preserving tools for web search.
2013	Reveal-it!: the impact of a social visualization projection on public awareness and discourse	Public displays and projections are becoming increasingly available in various informal urban settings. However, their potential impact on informing and engaging citizens on relevant issues has still been largely unexplored. In this paper, we show that visualizations displayed in public settings are able to increase social awareness and discourse by exposing underlying patterns in data that is submitted by citizens. We thus introduce the design and evaluation of Reveal-it! , a public, interactive projection that facilitates the comparison of the energy consumptions of individuals and communities. Our in-the-wild deployment in three distinct physical locations provided insights into: 1) how people responded to this form of display in different contexts; 2) how it influenced people's perception and discussion of individual and communal data; and 3) the implications for a public visualization as a tool for increasing awareness and discourse. We conclude by discussing emerging participant behaviors, as well as some challenges involved in facilitating a socially motivated crowd-sourced visualization in the public context.
2013	Whoo.ly: facilitating information seeking for hyperlocal communities using social media	Social media systems promise powerful opportunities for people to connect to timely, relevant information at the hyper local level. Yet, finding the meaningful signal in noisy social media streams can be quite daunting to users. In this paper, we present and evaluate Whoo.ly, a web service that provides neighborhood-specific information based on Twitter posts that were automatically inferred to be hyperlocal. Whoo.ly automatically extracts and summarizes hyperlocal information about events, topics, people, and places from these Twitter posts. We provide an overview of our design goals with Whoo.ly and describe the system including the user interface and our unique event detection and summarization algorithms. We tested the usefulness of the system as a tool for finding neighborhood information through a comprehensive user study. The outcome demonstrated that most participants found Whoo.ly easier to use than Twitter and they would prefer it as a tool for exploring their neighborhoods.
2013	Social media and the police: tweeting practices of british police forces during the August 2011 riots	With this paper we take a first step to understand the appropriation of social media by the police. For this purpose we analyzed the Twitter communication by the London Metropolitan Police (MET) and the Greater Manchester Police (GMP) during the riots in August 2011. The systematic comparison of tweets demonstrates that the two forces developed very different practices for using Twitter. While MET followed an instrumental approach in their communication, in which the police aimed to remain in a controlled position and keep a distance to the general public, GMP developed an expressive approach , in which the police actively decreased the distance to the citizens. In workshops and interviews, we asked the police officers about their perspectives, which confirmed the identified practices. Our study discusses benefits and risks of the two approaches and the potential impact of social media on the evolution of the role of police in society.
2014	The influence of controllers on immersion in mobile games	The controls for digital games understandably have an important part in building up the gaming experiences that people have. Whilst there is substantial work on innovative controllers for consoles, like the XBox Kinect, relatively little has been done to understand the effect of the different control mechanisms that can be used to play games on mobile devices like smartphones. A well-defined framework of naturalness has emerged as potentially useful concept in area of game controllers. This paper reports two experiments that look at how the naturalness of the game controls influences the experience of immersion in mobile games. It seems that where there is an a prior natural mapping, this will improve immersion in the game but in the absence of a prior mapping, naturalness alone is not sufficient to account for immersion. This opens up the need for a more thorough investigation of this area.
2014	The MOY framework for collaborative play design in integrated shared and private interactive spaces	A novel Mine-Ours-Yours (MOY) interaction design framework is proposed for designing collaborative play activities in environments that combine both private and shared interactive spaces. A collaborative game designed on a system that integrates multiple mobile devices with an interactive tabletop was presented to demonstrate the implementation of the proposed MOY framework. Observations from field trials involving two groups of children were used to summarize the collaborative behaviors that are likely to be observed under the different interaction design configurations.
2014	VacuumTouch: attractive force feedback interface for haptic interactive surface using air suction	We present VacuumTouch, a novel haptic interface architecture for touch screens that provides attractive force feedback to the user's finger. VacuumTouch consists of an air pump and solenoid air valves that connect to the surface of the touch screen and suck the air above the surface where the user's finger makes contact. VacuumTouch does not require the user to hold or attach additional devices to provide the attractive force, which allows for easy interaction with the surface. This paper introduces the implementation of the VacuumTouch architecture and some applications for enhancement of the graphical user interface, namely a suction button, a suction slider, and a suction dial. The quantitative evaluation was conducted with the suction dial and showed that the attractive force provided by VacuumTouch improved the performance of the dial menu interface and its potential effects. At the end of this paper, we discuss the current prototype's advantages and limitations, as well as possible improvements and potential capabilities.
2014	Expressive touch: studying tapping force on tabletops	This paper investigates users' ability to perform force-sensitive tapping and explores its potential as an input modality in touch-based systems. We study force-sensitive tapping using Expressive Touch , a tabletop interface that infers tapping force from the sound waves created by the users' finger upon impact. The first part of the paper describes the implementation details of Expressive Touch and shows how existing tabletop interfaces can be augmented to reliably detect tapping force across the entire surface. The second part of the paper reports on the results of three studies of force-sensitive tapping. First, we use a classic psychophysic task to gain insights into participants' perception of tapping force (Study 1). Results show that although participants tap with different absolute tapping forces, they have a similar perception of relative tapping force. Second, we investigate participants' ability to control tapping force (Study 2) and find that users can produce two force levels with 99% accuracy. For six levels of force, accuracy drops to 58%. Third, we investigate the usability of force tapping by studying participants' reactions to seven force-sensitive touch applications (Study 3).
2014	Combining think-aloud and physiological data to understand video game experiences	Think-aloud protocols are commonly used to evaluate player experiences of video games but suffer from a lack of objectivity and timeliness. On the other hand, quantitative captures of physiological data are effective; providing detailed, unbiased and continuous responses of players, but lack contexts for interpretation. This paper documents how both approaches could be used together in practice by comparing video-cued retrospective think-aloud data and physiological data collected during a video gameplay experiment. We observed that many interesting physiological responses did not feature in participants' think-aloud data, and conversely, reports of interesting experiences were sometimes not observed in the collected physiological data. Through learnings from our experiment, we present some of the challenges when combining these approaches and offer some guidelines as to how qualitative and quantitative data can be used together to gain deeper insights into player experiences.
2014	A user study of different gameplay visualizations	With the rising interest in multiplayer gaming, gameplay statistics have become an increasingly important aspect of the overall game experience for many players. As a part of this trend, visualizations have gained great popularity among players, in particular heatmaps since they allow them to reenact the course of a game and to develop new strategies. In this paper we report results of a user study conducted with 29 players (i) to investigate how players use heatmaps and two further graphical representations that use clustering algorithms to interpret gameplay and (ii) to assess the three representations in regard to time efficiency, correctness, suitability, and player preference. Our results show that heatmaps were mainly used to detect hot spots while the cluster representations proved useful to compare variables, allowing the players to uncover relationships between them and in turn allowing a deeper insight into the gameplay data.
2014	Transient and transitional states: pressure as an auxiliary input modality for bimanual interaction	A novel investigation of pressure input is presented where it is characterised as a transient modality, one that has a natural inverse, bounce-back and a state that only persists during interaction. Three empirical studies are described that evaluate pressure for use as a non-dominant hand input modality, where the ability to target and maintain pressure while simultaneously performing a dominant-hand targeting task is investigated. Pressure accuracy was high (93%) and the impact on dominant-hand targeting was low. Mean pressure accuracy when selecting targets by releasing pressure was also high (89%) as was selecting targets by applying pressure from a non-zero starting point (94.4%). The ability to accurately maintain pressure over time was better with larger target pressures. Example applications and design guidelines are presented that enable designers to exploit the transient properties of pressure input in interaction design.
2014	Gaze gestures and haptic feedback in mobile devices	Anticipating the emergence of gaze tracking capable mobile devices, we are investigating the use of gaze as an input modality in handheld mobile devices. We conducted a study of combining gaze gestures with vibrotactile feedback. Gaze gestures were used as an input method in a mobile device and vibrotactile feedback as a new alternative way to give confirmation of interaction events. Our results show that vibrotactile feedback significantly improved the use of gaze gestures. The tasks were completed faster and rated easier and more comfortable when vibrotactile feedback was provided.
2014	Presstures: exploring pressure-sensitive multi-touch gestures on trackpads	In this paper, we present Presstures, an extension to current multi-touch operations that enriches common multi-finger gestures with pressure information. By using the initially applied pressure level for implicit mode switching, a gesture can be enhanced with different functionalities to enlarge the interaction space for multi-touch. To evaluate the feasibility of our concept, we conducted an experiment, which indicates good human sensorimotor skills for performing multi-touch gestures with a few number of pressure levels and without any additional feedback. Based on the experimental results, we discuss implications for the design of pressure-sensitive multi-touch gestures, and propose application scenarios that make optimal use of our concept.
2014	Juxtapoze: supporting serendipity and creative expression in clipart compositions	Juxtapoze is a clipart composition workflow that supports creative expression and serendipitous discoveries in the shape domain. We achieve creative expression by supporting a workflow of searching, editing, and composing: the user queries the shape database using strokes, selects the desired search result, and finally modifies the selected image before composing it into the overall drawing. Serendipitous discovery of shapes is facilitated by allowing multiple exploration channels, such as doodles, shape filtering, and relaxed search. Results from a qualitative evaluation show that Juxtapoze makes the process of creating image compositions enjoyable and supports creative expression and serendipity.
2014	Snuggle: designing for efficient socialization and ideological critique	Wikipedia, the encyclopedia "anyone can edit", has become increasingly less so. Recent academic research and popular discourse illustrates the often aggressive ways newcomers are treated by veteran Wikipedians. These are complex sociotechnical issues, bound up in infrastructures based on problematic ideologies. In response, we worked with a coalition of Wikipedians to design, develop, and deploy Snuggle, a new user interface that served two critical functions: making the work of newcomer socialization more effective, and bringing visibility to instances in which Wikipedians? current practice of gatekeeping socialization breaks down. Snuggle supports positive socialization by helping mentors quickly find newcomers whose good-faith mistakes were reverted as damage. Snuggle also supports ideological critique and reflection by bringing visibility to the consequences of viewing newcomers through a lens of suspiciousness.
2014	Supporting informal design with interactive whiteboards	Whiteboards serve an important role in supporting informal design, providing a fluid and flexible medium for collaborative design. Interactive whiteboards offer the potential for enhanced support for manipulating content, managing sketches, and distributed work, but little is known about how this support affects the practice of informal design. To understand the opportunities and challenges, we first conducted a literature review, identifying 14 behaviors that occur during informal design. We then designed an interactive whiteboard system to support all of these behaviors and deployed the system to three groups of designers. Through usage logs and interviews, we examined the effects of interactivity on whiteboard use across a wide spectrum of design behaviors, identifying ways in which interactive whiteboards support the practices used in physical whiteboards and where they enable designers to work more effectively.
2014	Offline painted media for digital animation authoring	We present an animation creation workflow for integrating offline physical, painted media into the digital authoring of Flash-style animations. Generally, animators create animations with standardized digital authoring software. However, the results tend to lack the individualism or atmosphere of physical media. In contrast, illustrators have skills in painting physical media but have limited experience in animation. To incorporate their skills, we present a workflow that integrates the offline painting and digital animation creation processes in a labor-saving manner. First, a user makes a rough sketch of the visual elements and defines their movements using our digital authoring software with a sketch interface. Then these images are exported to printed pages, and users can paint using offline physical media. Finally, the work is scanned and imported back into the digital content, forming a composite animation that combines digital and physical media. We present an implementation of this system to demonstrate its workflow. We also discuss the advantages of using physical media in digital animations through design evaluations.
2014	The impact of membership overlap on the survival of online communities	If the people belong to multiple online communities, their joint membership can influence the survival of each of the communities to which they belong. Communities with many joint memberships may struggle to get enough of their members' time and attention, but find it easy to import best practices from other communities. In this paper, we study the effects of membership overlap on the survival of online communities. By analyzing the historical data of 5673 Wikia communities, we find that higher levels of membership overlap are positively associated with higher survival rates of online communities. Furthermore, we find that it is beneficial for young communities to have shared members who play a central role in other mature communities. Our contributions are two-fold. Theoretically, by examining the impact of membership overlap on the survival of online communities we identified an important mechanism underlying the success of online communities. Practically, our findings may guide community creators on how to effectively manage their members, and tool designers on how to support this task.
2014	Selecting an effective niche: an ecological view of the success of online communities	Online communities serve various important functions, but many fail to thrive. Research on community success has traditionally focused on internal factors. In contrast, we take an ecological view to understand how the success of a community is influenced by other communities. We measured a community's relationship with other communities - its "niche" - through four dimensions: topic overlap, shared members, content linking, and shared offline organizational affiliation. We used a mixed-method approach, combining the quantitative analysis of 9495 online enterprise communities and interviews with community members. Our results show that too little or too much overlap in topic with other communities causes a community's activity to suffer. We also show that this main result is moderated in predictable ways by whether the community shares members with, links to content in, or shares an organizational affiliation with other communities. These findings provide new insight on community success, guiding online community designers on how to effectively position their community in relation to others.
2014	Goals and perceived success of online enterprise communities: what is important to leaders & members?	Online communities are successful only if they achieve their goals, but there has been little direct study of goals. We analyze novel data characterizing the goals of enterprise online communities, assessing the importance of goals for leaders, how goals influence member perceptions of community value, and how goals relate to success measures proposed in the literature. We find that most communities have multiple goals and common goals are learning, reuse of resources, collaboration, networking, influencing change, and innovation. Leaders and members agree that all of these goals are important, but their perceptions of success on goals do not align with each other, or with commonly used behavioral success measures. We conclude that simple behavioral measures and leader perceptions are not good success metrics, and propose alternatives based on specific goals members and leaders judge most important.
2014	Draco: bringing life to illustrations with kinetic textures	We present Draco, a sketch-based interface that allows artists and casual users alike to add a rich set of animation effects to their drawings, seemingly bringing illustrations to life. While previous systems have introduced sketch-based animations for individual objects, our contribution is a unified framework of motion controls that allows users to seamlessly add coordinated motions to object collections. We propose a framework built around kinetic textures , which provide continuous animation effects while preserving the unique timeless nature of still illustrations. This enables many dynamic effects difficult or not possible with previous sketch-based tools, such as a school of fish swimming, tree leaves blowing in the wind, or water rippling in a pond. We describe our implementation and illustrate the repertoire of animation effects it supports. A user study with professional animators and casual users demonstrates the variety of animations, applications and creative possibilities our tool provides.
2014	Performativity in sustainable interaction: the case of seasonal grocery shopping in ecofriends	The EcoFriends application was developed as an attempt to support grocery shopping adjusted to vegetables? seasonality through a performative approach to interaction and interactive applications. The design aimed at critical reflection and inspiration among users, rather than achieving a certain kind of persuasion. This guided the practical design to be modelled around open-endedness and social voices to challenge ideas and points of view. We argue that research addressing design for interactions about value-laden concepts such as sustainable action need to find ways of supporting various knowledge discourses, by distinguishing between performative and representational technologies. The approach allowed us to identify a number of design challenges regarding interactive technology and interaction design in relation to aspects of knowledge and truth, trust, negotiation and responsibility.
2014	ISSE: an interactive source separation editor	Traditional audio editing tools do not facilitate the task of separating a single mixture recording (e.g. pop song) into its respective sources (e.g. drums, vocal, etc.). Such ability, however, would be very useful for a wide variety of audio applications such as music remixing, audio denoising, and audio-based forensics. To address this issue, we present ISSE - an interactive source separation editor. ISSE is a new open-source, freely available, and cross-platform audio editing tool that enables a user to perform source separation by painting on time-frequency visualizations of sound, resulting in an interactive machine learning system. The system brings to life our previously proposed interaction paradigm and separation algorithm that learns from user-feedback to perform separation. For evaluation, we conducted user studies and compared results between inexperienced and expert users. For a variety of real-world tasks, we found that inexperienced users can achieve good separation quality with minimal instruction and expert users can achieve state-of-the-art separation quality.
2014	Depth perception with gaze-contingent depth of field	Blur in images can create the sensation of depth because it emulates an optical property of the eye; namely, the limited depth of field created by the eye's lens. When the human eye looks at an object, this object appears sharp on the retina, but objects at different distances appear blurred. Advances in gaze-tracking technologies enable us to reproduce dynamic depth of field in regular displays, providing an alternative way of conveying depth. In this paper we investigate gaze-contingent depth of field as a method to produce realistic 3D images, and analyze how effectively people can use it to perceive depth. We found that GC DOF increases subjective perceived realism and depth and can contribute to the perception of ordinal depth and distance between objects, but it is limited in its accuracy.
2014	SonicExplorer: fluid exploration of audio parameters	In digital music production, the phrase "in the box" refers to the increasing replacement of extraneous hardware devices with compatible software components. As controls move from hard to soft, we have seen an increase in usability issues for musicians and sound engineers dealing with a large number of temporal inputs and both continuous and discrete controls. We present the SonicExplorer application, which we developed to give users a new interface for exploring and manipulating audio. SonicExplorer leverages users' spatial and color perception to enhance exploration by visualizing the parameter space and providing implicit memory cues. The application also leverages bimanual input to aid in fluid exploration of multidimensional audio parameter spaces, and to minimize the need for switching between parameters.
2014	Expanding the input expressivity of smartwatches with mechanical pan, twist, tilt and click	Smartwatches promise to bring enhanced convenience to common communication, creation and information retrieval tasks. Due to their prominent placement on the wrist, they must be small and otherwise unobtrusive, which limits the sophistication of interactions we can perform. This problem is particularly acute if the smartwatch relies on a touchscreen for input, as the display is small and our fingers are relatively large. In this work, we propose a complementary input approach: using the watch face as a multi-degree-of-freedom, mechanical interface. We developed a proof of concept smartwatch that supports continuous 2D panning and twist, as well as binary tilt and click. To illustrate the potential of our approach, we developed a series of example applications, many of which are cumbersome -- or even impossible -- on today's smartwatch devices.
2014	The use of surrounding visual context in handheld AR: device vs. user perspective rendering	The magic lens paradigm, a commonly used descriptor for handheld Augmented Reality (AR), presents the user with dual views: the augmented view (magic lens) that appears on the device, and the real view of the surroundings (what the user can see around the perimeter of the device). The augmented view is typically implemented by rendering the video captured by the rear-facing camera directly onto the device's screen. This results in dual perspectives - the real world being captured from the device's perspective rather than the user's perspective (what an observer would see looking through a transparent glass pane). These differences manifest themselves in misaligned and/or incorrectly scaled transparency resulting in the dual-view problem. This paper presents two user studies comparing (a) device-perspective and (b) fixed Point-of-View (POV) user-perspective magic lenses to analyze the effect of the dual-view problem on the use of the surrounding visual context. The results confirm that the dual-view problem, a result of dual perspective, has a significant effect on the use of information from the surrounding visual context. The study also highlights that magnification and not the dual-view problem is the key factor explaining the correlation between magic lens size and the increased intensity of the magic lens type effect. From the results, we derive design guidelines for future magic lenses.
2014	Altering gameplay behavior using stereoscopic 3D vision-based video game design	We explore the potential of stereoscopic 3D (S3D) vision in offering distinct gameplay using an S3D-specific game called Deepress3D. Our game utilizes established S3D design principles for optimizing GUI design, visual comfort and game mechanics which rely on depth perception in time-pressured spatial conflicts. The game collects detailed S3D player metrics and allows players to choose between different, evenly matched strategies. We conducted a between subjects study comparing S3D and monoscopic versions of Deepress3D that examined player behavior and performance and measured user-reported data on presence, simulator sickness, and game experience. Confirming previous results, stereo users reported higher spatial presence. More importantly, for the first time, our game metrics indicate that S3D vision can measurably change player behavior depending on actual game content and level design, without necessarily affecting performance or emotional experience. These findings indicate the potential for optimizing applications for stereo users distinguishing them as a distinct group in HCI research.
2014	Imperceptible depth shifts for touch interaction with stereoscopic objects	While touch technology has proven its usability for 2D interaction and has already become a standard input modality for many devices, the challenges to exploit its applicability with stereoscopically rendered content have barely been studied. In this paper we exploit the properties of the visual perception to allow users to touch stereoscopically displayed objects when the input is constrained to a 2D surface. Therefore, we have extended and generalized recent evaluations on the user's ability to discriminate small induced object shifts while reaching out to touch a virtual object, and we propose a practical interaction technique, the attracting shift technique, suitable for numerous application scenarios where shallow depth interaction is sufficient. In addition, our results indicate that slight object shifts during touch interaction make the virtual scene appear perceptually more stable compared to a static scene. As a consequence, applications have to manipulate the virtual objects to make them appear static for the user.
2014	The boomRoom: mid-air direct interaction with virtual sound sources	In this paper we present a system that allows to "touch", grab and manipulate sounds in mid-air. Further, arbitrary objects can seem to emit sound. We use spatial sound reproduction for sound rendering and computer vision for tracking. Using our approach, sounds can be heard from anywhere in the room and always appear to originate from the same (possibly moving) position, regardless of the listener's position. We demonstrate that direct "touch" interaction with sound is an interesting alternative to indirect interaction mediated through controllers or visual interfaces. We show that sound localization is surprisingly accurate (11.5 cm), even in the presence of distractors. We propose to leverage the ventriloquist effect to further increase localization accuracy. Finally, we demonstrate how affordances of real objects can create synergies of auditory and visual feedback. As an application of the system, we built a spatial music mixing room.
2014	Evaluation of hear-through sound localization	Listening and interacting with audio commonly relies on using earphones which limit the ability of users to perceive their auditory environment. Earphone sets that integrate miniature microphones on their exterior can, however, be used to hear-through the auditory environment. We present an evaluation study in which sound localization when wearing such a hear-through system is compared to normal earphones, open headphones and unblocked ears. Although localization performance is improved compared to open headphones, we find that it is compromised in comparison to listening without earphones because confusions of sound direction increase and localization judgment distributions are more dispersed and show a weaker correlation to the test directions. The implications of the results to human computer interaction and possible improvements to hear-through system design are discussed.
2014	The doing of doing stuff: understanding the coordination of social group-activities	This paper explores how the adoption of mobile and social computing technologies has impacted upon the way in which we coordinate social group-activities. We present a diary study of 36 individuals that provides an overview of how group coordination is currently performed as well as the challenges people face. Our findings highlight that people primarily use open-channel communication tools (e.g., text messaging, phone calls, email) to coordinate because the alternatives are seen as either disrupting or curbing to the natural conversational processes. Yet the use of open-channel tools often results in conversational overload and a significant disparity of work between coordinating individuals. This in turn often leads to a sense of frustration and confusion about coordination details. We discuss how the findings argue for a significant shift in our thinking about the design of coordination support systems.
2014	Duet: exploring joint interactions on a smart phone and a smart watch	The emergence of smart devices (e.g., smart watches and smart eyewear) is redefining mobile interaction from the solo performance of a smart phone, to a symphony of multiple devices. In this paper, we present Duet -- an interactive system that explores a design space of interactions between a smart phone and a smart watch. Based on the devices' spatial configurations, Duet coordinates their motion and touch input, and extends their visual and tactile output to one another. This transforms the watch into an active element that enhances a wide range of phone-based interactive tasks, and enables a new class of multi-device gestures and sensing techniques. A technical evaluation shows the accuracy of these gestures and sensing techniques, and a subjective study on Duet provides insights, observations, and guidance for future work.
2014	More than touch: understanding how people use skin as an input surface for mobile computing	This paper contributes results from an empirical study of on-skin input, an emerging technique for controlling mobile devices. Skin is fundamentally different from off-body touch surfaces, opening up a new and largely unexplored interaction space. We investigate characteristics of the various skin-specific input modalities, analyze what kinds of gestures are performed on skin, and study what are preferred input locations. Our main findings show that (1) users intuitively leverage the properties of skin for a wide range of more expressive commands than on conventional touch surfaces; (2) established multi-touch gestures can be transferred to on-skin input; (3) physically uncomfortable modalities are deliberately used for irreversible commands and expressing negative emotions; and (4) the forearm and the hand are the most preferred locations on the upper limb for on-skin input. We detail on users' mental models and contribute a first consolidated set of on-skin gestures. Our findings provide guidance for developers of future sensors as well as for designers of future applications of on-skin input.
2014	Necessary, unpleasant, and disempowering: reputation management in the internet age	In this paper, we report on a qualitative study of how users manage their reputation online. We focus particularly on people who are bothered by content online about themselves and how they manage reputation damage and repair. We describe how users view reputation management chores as necessary but unpleasant, and how they feel disempowered to repair their online reputation. Participants were unable to identify feasible repair mechanisms and ultimately failed to resolve their problems. Given the current state of dysfunction indicated by our findings, we advocate for increased HCI research attention to this area.
2014	Effects of implicit sharing in collaborative analysis	When crime analysts collaborate to solve crime cases, they need to share insights in order to connect the clues, identify a pattern, and attribute the crime to the right culprit. We designed a collaborative analysis tool to explore the value of implicitly sharing insights and notes, without requiring analysts to explicitly push information or request it from each other. In an experiment, pairs of remote individuals played the role of crime analysts solving a set of serial killer crimes with both partners having some, but not all, relevant clues. When implicit sharing of notes was available, participants remembered more clues related to detecting the serial killer, and they perceived the tool as more useful compared to when implicit sharing was not available.
2014	Effects of simultaneous and sequential work structures on distributed collaborative interdependent tasks	Distributed online groups have great potential for generating interdependent and complex products like encyclopedia articles or product design. However, coordinating multiple group members to work together effectively while minimizing process losses remains an open challenge. We conducted an experiment comparing the effectiveness of two coordination strategies (simultaneous vs. sequential work) on a complex creative task as the number of group members increased. Our results indicate that, contrary to prior work, a sequential work structure was more effective than a simultaneous work structure as the size of the group increased. A mediation analysis suggests that social processes such as territoriality partially accounts for these results. A follow up experiment giving workers specific roles mitigated the detrimental effects of the simultaneous work structure. These results have implications for small group theory and crowdsourcing research.
2014	TouchSense: expanding touchscreen input vocabulary using different areas of users' finger pads	We present TouchSense, which provides additional touchscreen input vocabulary by distinguishing the areas of users' finger pads contacting the touchscreen. It requires minimal touch input area and minimal movement, making it especially ideal for wearable devices such as smart watches and smart glasses. For example, users of a calculator application on a smart watch could tap normally to enter numbers, and tap with the right side of their fingers to enter the operators (e.g. , -, =). Results from two human-factor studies showed that users could tap a touchscreen with five or more distinct areas of their finger pads. Also, they were able to tap with more distinct areas closer to their fingertips. We developed a TouchSense smart watch prototype using inertial measurement sensors, and developed two example applications: a calculator and a text editor. We also collected user feedback via an explorative study.
2014	Interaction on the edge: offset sensing for small devices	The touch screen interaction paradigm, currently dominant in mobile devices, begins to fail when very small systems are considered. Specifically, "fat fingers", a term referring to the fact that users' extremities physically obstruct their view of screen content and feedback, become particularly problematic. This paper presents a novel solution for this issue based on sensing touches to the perpendicular edges of a device featuring a front-mounted screen. The use of such offset contact points ensures that both a user's fingers and the device screen remain clearly in view throughout a targeting operation. The configuration also supports a range of novel interaction scenarios based on the touch, grip and grasp patterns it affords. To explore the viability of this concept, this paper describes EdgeTouch, a small (6 cm) hardware prototype instantiating this multi-touch functionality. User studies characterizing targeting performance, typical user grasps and exploring input affordances are presented. The results show that targets of 7.5-22.5 degrees in angular size are acquired in 1.25-1.75 seconds and with accuracy rates of 3%-18%, promising results considering the small form factor of the device. Furthermore, grasps made with between two and five fingers are robustly identifiable. Finally, we characterize the types of input users envisage performing with EdgeTouch, and report occurrence rates for key interactions such as taps, holds, strokes and multi-touch and compound input. The paper concludes with a discussion of the interaction scenarios enabled by offset sensing.
2014	Social media participation and performance at work: a longitudinal study	The use of social media at work is gaining traction, and there is evidence to suggest that various benefits accrue from its use. Yet the relationship between using social media at work and employee performance is not clear. Through a study of 75,747 employees of a large global company over the course of 3 years, we find that some social media usage (number of forum posts, forum post length, and status update length) was positively associated with performance ratings. This study is one of the first to show the relationship among different forms of social media use and employee performance ratings.
2014	Let's do it at my place instead?: attitudinal and behavioral study of privacy in client-side personalization	Many users welcome personalized services, but are reluctant to provide the information about themselves that personalization requires. Performing personalization exclusively at the client side (e.g., on one's smartphone) may conceptually increase privacy, because no data is sent to a remote provider. But does client-side personalization (CSP) also increase users' perception of privacy? We developed a causal model of privacy attitudes and behavior in personalization, and validated it in an experiment that contrasted CSP with personalization at three remote providers: Amazon, a fictitious company, and the "Cloud". Participants gave roughly the same amount of personal data and tracking permissions in all four conditions. A structural equation modeling analysis reveals the reasons: CSP raises the fewest privacy concerns, but does not lead in terms of perceived protection nor in resulting self-anticipated satisfaction and thus privacy-related behavior. Encouragingly, we found that adding certain security features to CSP is likely to raise its perceived protection significantly. Our model predicts that CSP will then also sharply improve on all other privacy measures.
2014	Stress and multitasking in everyday college life: an empirical study of online activity	While HCI has focused on multitasking with information workers, we report on multitasking among Millennials who grew up with digital media - focusing on college students. We logged computer activity and used biosensors to measure stress of 48 students for 7 days for all waking hours, in their in situ environments. We found a significant positive relationship with stress and daily time spent on computers. Stress is positively associated with the amount of multitasking. Conversely, stress is negatively associated with Facebook and social media use. Heavy multitaskers use significantly more social media and report lower positive affect than light multitaskers. Night habits affect multitasking the following day: late-nighters show longer duration of computer use and those ending their activities earlier in the day multitask less. Our study shows that college students multitask at double the frequency compared to studies of information workers. These results can inform designs for stress management of college students.
2014	Reflection or action?: how feedback and control affect location sharing decisions	Owing to the ever-expanding size of social and professional networks, it is becoming cumbersome for individuals to configure information disclosure settings. We used location sharing systems to unpack the nature of discrepancies between a person's disclosure settings and contextual choices. We conducted an experience sampling study ( N = 35 ) to examine various factors contributing to such divergence. We found that immediate feedback about disclosures without any ability to control the disclosures evoked feelings of oversharing. Moreover, deviation from specified settings did not always signal privacy violation; it was just as likely that settings prevented information disclosure considered permissible in situ . We suggest making feedback more actionable or delaying it sufficiently to avoid a knee-jerk reaction. Our findings also make the case for proactive techniques for detecting potential mismatches and recommending adjustments to disclosure settings, as well as selective control when sharing location with socially distant recipients and visiting atypical locations.
2014	The effect of developer-specified explanations for permission requests on smartphone user behavior	In Apple's iOS 6, when an app requires access to a protected resource (e.g., location or photos), the user is prompted with a permission request that she can allow or deny. These permission request dialogs include space for developers to optionally include strings of text to explain to the user why access to the resource is needed. We examine how app developers are using this mechanism and the effect that it has on user behavior. Through an online survey of 772 smartphone users, we show that permission requests that include explanations are significantly more likely to be approved. At the same time, our analysis of 4,400 iOS apps shows that the adoption rate of this feature by developers is relatively small: around 19% of permission requests include developer-specified explanations. Finally, we surveyed 30 iOS developers to better understand why they do or do not use this feature.
2014	Extracting references between text and charts via crowdsourcing	News articles, reports, blog posts and academic papers often include graphical charts that serve to visually reinforce arguments presented in the text. To help readers better understand the relation between the text and the chart, we present a crowdsourcing pipeline to extract the references between them. Specifically, we give crowd workers paragraph-chart pairs and ask them to select text phrases as well as the corresponding visual marks in the chart. We then apply automated clustering and merging techniques to unify the references generated by multiple workers into a single set. Comparing the crowdsourced references to a set of gold standard references using a distance measure based on the F 1 score, we find that the average distance between the raw set of references produced by a single worker and the gold standard is 0.54 (out of a max of 1.0). When we apply clustering and merging techniques the average distance between the unified set of references and the gold standard reduces to 0.39; an improvement of 27%. We conclude with an interactive document viewing application that uses the extracted references; readers can select phrases in the text and the system highlights the related marks in the chart.
2014	Under pressure: sensing stress of computer users	Recognizing when computer users are stressed can help reduce their frustration and prevent a large variety of negative health conditions associated with chronic stress. However, measuring stress non-invasively and continuously at work remains an open challenge. This work explores the possibility of using a pressure-sensitive keyboard and a capacitive mouse to discriminate between stressful and relaxed conditions in a laboratory study. During a 30 minute session, 24 participants performed several computerized tasks consisting of expressive writing, text transcription, and mouse clicking. During the stressful conditions, the large majority of the participants showed significantly increased typing pressure (>79% of the participants) and more contact with the surface of the mouse (75% of the participants). We discuss the potential implications of this work and provide recommendations for future work.
2014	Investigating the effects of using biofeedback as visual stress indicator during video-mediated collaboration	During remote video-mediated assistance, instructors often guide workers through problems and instruct them to perform unfamiliar or complex operations. However, the workers' performance might deteriorate due to stress. We argue that informing biofeedback to the instructor, can improve communication and lead to lower stress. This paper presents a thorough investigation on mental workload and stress perceived by twenty participants, paired up in an instructor-worker scenario, performing remote video-mediated tasks. The interface conditions differ in task, facial and biofeedback communication. Two self-report measures are used to assess mental workload and stress. Results show that pairs reported lower mental workload and stress when instructors are using the biofeedback as compared to using interfaces with facial view. Significant correlations were found on task performance with reducing stress (i.e. increased task engagement and decreased worry) for instructors and declining mental workload (i.e. increased performance) for workers. Our findings provide insights to advance video-mediated interfaces for remote collaborative work.
2014	Effects of security warnings and instant gratification cues on attitudes toward mobile websites	In order to address the increased privacy and security concerns raised by mobile communications, designers of mobile applications and websites have come up with a variety of warnings and appeals. While some interstitials warn about potential risk to personal information due to an untrusted security certificate, others attempt to take users' minds away from privacy concerns by making tempting, time-sensitive offers. How effective are they? We conducted an online experiment ( N = 220 ) to find out. Our data show that both these strategies raise red flags for users - appeals to instant gratification make users more leery of the site and warnings make them perceive greater threat to personal data. Yet, users tend to reveal more information about their social media accounts when warned about an insecure site. This is probably because users process these interstitials based on cognitive heuristics triggered by them. These findings hold important implications for the design of cues in mobile interfaces.
2014	MouStress: detecting stress from mouse motion	Stress causes and exacerbates many physiological and mental health problems. Routine and unobtrusive monitoring of stress would enable a variety of treatments, from break-taking to calming exercises. It may also be a valuable tool for assessing effects (frustration, difficulty) of using interfaces or applications. Custom sensing hardware is a poor option, because of the need to buy/wear/use it continuously, even before stress-related problems are evident. Here we explore stress measurement from common computer mouse operations. We use a simple model of arm-hand dynamics that captures muscle stiffness during mouse movement. We show that the within-subject mouse-derived stress measure is quite strong, even compared to concurrent physiological sensor measurements. While our study used fixed mouse tasks, the stress signal was still strong even when averaged across widely varying task geometries. We argue that mouse sensing "in the wild" may be feasible, by analyzing frequently-performed operations of particular geometries.
2014	The influence of aesthetics in usability testing: the case of dual-domain products	An experimental study examined whether the effects of aesthetic appeal on usability test outcomes are moderated by usage domain. The aesthetic appeal of a cell phone was experimentally manipulated in both home- and work-based usage domains. The two usage domains were modeled in a usability laboratory. 60 participants completed a series of typical cell phone user tasks. Dependent measures such as performance, perceived usability, and emotion were taken. The results showed that aesthetic appeal had a positive effect on perceived usability but a negative effect on performance. The effects of aesthetic appeal on usability test outcomes were not moderated by usage domain. The results of this study imply that it may be sufficient to test dual-domain products in only one of their usage domains.
2014	Metaphone: machine aesthetics meets interaction design	Through our art project, Metaphone , we explored a particular form of aesthetics referred to in the arts tradition as machine aesthetics. The Metaphone machine collects the participant's bio-data, Galvanic Skin Response (GSR) and Heart Rate (HR), creating a process of movement, painting and sound. The machine behaves in machine-like, aesthetically evocative ways: a shaft on two large wheels rotates on the floor, carrying paint that is dripped onto a large sheet of aquarelle paper on the floor according to bio-sensor data. A soundscape rhythmically follows the bio-sensor data, but also has its own machine-like sounds. Six commentators were invited to interact with the machine. They reported a strangely relaxing atmosphere induced by the machine. Based on these experiences we discuss how different art styles can help to describe aesthetics in interaction design generally, and how machine aesthetics in particular can be used to create interesting, sustained, stylistically coherent interactions.
2014	Quantifying visual preferences around the world	Website aesthetics have been recognized as an influential moderator of people's behavior and perception. However, what users perceive as "good design" is subject to individual preferences, questioning the feasibility of universal design guidelines. To better understand how people's visual preferences differ, we collected 2.4 million ratings of the visual appeal of websites from nearly 40 thousand participants of diverse backgrounds. We address several gaps in the knowledge about design preferences of previously understudied groups. Among other findings, our results show that the level of colorfulness and visual complexity at which visual appeal is highest strongly varies: Females, for example, liked colorful websites more than males. A high education level generally lowers this preference for colorfulness. Russians preferred a lower visual complexity, and Macedonians liked highly colorful designs more than any other country in our dataset. We contribute a computational model and estimates of peak appeal that can be used to support rapid evaluations of website design prototypes for specific target groups.
2014	Emerging sites of HCI innovation: hackerspaces, hardware startups & incubators	In this paper, we discuss how a flourishing scene of DIY makers is turning visions of tangible and ubiquitous computing into products. Drawing on long-term multi-sited ethnographic research and active participation in DIY making, we provide insights into the social, material, and economic processes that undergird this transition from prototypes to products. The contribution of this paper is three-fold. First, we show how DIY maker practice is illustrative of a broader "return to" and interest in physical materials. This has implications for HCI research that investigates questions of materiality. Second, we shed light on how hackerspaces and hardware start-ups are experimenting with new models of manufacturing and entrepreneurship. We argue that we have to take seriously these maker practices, not just as hobbyist or leisure practice, but as a professionalizing field functioning in parallel to research and industry labs. Finally, we end with reflections on the role of HCI researchers and designers as DIY making emerges as a site of HCI innovation. We argue that HCI is positioned to provide critical reflection, paired with a sensibility for materials, tools and design methods.
2014	Toss 'n' turn: smartphone as sleep and sleep quality detector	The rapid adoption of smartphones along with a growing habit for using these devices as alarm clocks presents an opportunity to use this device as a sleep detector. This adds value to UbiComp and personal informatics in terms of user context and new performance data to collect and visualize, and it benefits healthcare as sleep is correlated with many health issues. To assess this opportunity, we collected one month of phone sensor and sleep diary entries from 27 people who have a variety of sleep contexts. We used this data to construct models that detect sleep and wake states, daily sleep quality, and global sleep quality. Our system classifies sleep state with 93.06% accuracy, daily sleep quality with 83.97% accuracy, and overall sleep quality with 81.48% accuracy. Individual models performed better than generally trained models, where the individual models require 3 days of ground truth data and 3 weeks of ground truth data to perform well on detecting sleep and sleep quality, respectively. Finally, the features of noise and movement were useful to infer sleep quality.
2014	Persuasive technology in the real world: a study of long-term use of activity sensing devices for fitness	Persuasive technology to motivate healthy behavior is a growing area of research within HCI and ubiquitous computing. The emergence of commercial wearable devices for tracking health- and fitness-related activities arguably represents the first widespread adoption of dedicated ubiquitous persuasive technology. The recent ubiquity of commercial systems allows us to learn about their value and use in truly "in the wild" contexts and understand how practices evolve over long-term, naturalistic use. We present a study with 30 participants who had adopted wearable activity-tracking devices of their own volition and had continued to use them for between 3 and 54 months. The findings, which both support and contrast with those of previous research, paint a picture of the evolving benefits and practices surrounding these emerging technologies over long periods of use. They also serve as the basis for design implications for personal informatics technologies for long-term health and fitness support.
2014	Breakdown, obsolescence and reuse: HCI and the art of repair	This paper describes an integrated program of theoretical, ethnographic, and building work meant to explore post-humanist alternatives to questions around HCI creativity and design. We review recent theories in the humanities, social sciences, and HCI that argue for different ways of framing the relationship between human agents and the object world around them. We then describe a program of ethnographic work with artists who feature found and broken technologies as central methods and topics of work. Finally, we describe an installation and self-study project of our own, 'Scale,' that extends these lines of analysis through collaborative acts of building with broken and discarded technologies. We argue that such integrated programs of work offer one useful model for leveraging the theoretical, ethnographic and material dimensions of HCI work; and that the distinct 'propensities' of found and broken objects can challenge and extend HCI notions of creativity and design itself.
2014	A systematic review of quantitative studies on the enjoyment of digital entertainment games	Enjoyment has been identified as a central component of the player experience (PX), but various, overlapping concepts within PX make it difficult to develop valid measures and a common understanding of game enjoyment. We conducted a systematic review of 87 quantitative studies, analyzing different operationalizations and measures of game enjoyment, its determinants, and how these were related to other components of PX, such as flow, presence and immersion. Results suggest that game enjoyment describes the positive cognitive and affective appraisal of the game experience, and may in part be associated with the support of player needs and values. Further, we outline that enjoyment is distinct from flow in that it may occur independently of challenge and cognitive involvement, and argue that enjoyment may be understood as the valence of the player experience. We conclude with a discussion of methodological challenges and point out opportunities for future research on game enjoyment.
2014	The product of availability: understanding the economic underpinnings of constant connectivity	Constant connectivity and total availability to clients is the rule rather than the exception in many contemporary workplaces. Enabled by developments in information and communication technologies (ICTs), total availability of employees is possible and presumed. Scholars have explored how new technological affordances, cultural shifts, individual personality traits, and/or the development of social expectations that reinforce norms of constant connectivity have led to this state of affairs. We argue that a key factor has been overlooked in current scholarship about stress, intensive work, and constant connectivity. That is, current economic conditions are creating a marketplace in which firms increasing sell the availability of their employees as part of the services offered by the firm . In this paper we use qualitative data to illustrate how total availability is an integral aspect of the 'product' offered by professional service firms and is becoming increasingly prevalent in other service industries. We conclude with a discussion of how the HCI community might address this situation as a design challenge. Drawing on the work of Goffman and Perlow, we suggest that designers attend to the ways in which organizations might maintain front stage impressions of total availability while collectively managing individual time to restrict total availability behind the scenes.
2014	Understanding procedural content generation: a design-centric analysis of the role of PCG in games	Games that use procedural content generation (PCG) do so in a wide variety of ways and for different reasons. One of the most common reasons cited by PCG system creators and game designers is improving replayability by providing a means for automatically creating near-infinite amounts of content, the player can come back and replay the game and refine her strategies over a long period. However, this notion of replayability is both overly broad and incomplete as a motivation. This paper contributes an analytical framework and associated common vocabulary for understanding the role of PCG in games from a design standpoint, with an aim of unpacking some of the broad justifications for PCG use in games, and bringing together technical concerns in designing PCG systems with design concerns related to creating engaging playable experiences.
2014	Kinetica: naturalistic multi-touch data visualization	Over the last several years there has been an explosion of powerful, affordable, multi-touch devices. This provides an outstanding opportunity for novel data visualization techniques that leverage new interaction methods and minimize their barriers to entry. In this paper we describe an approach for multivariate data visualization that uses physics-based affordances that are easy to intuit, constraints that are easy to apply and visualize, and a consistent view as data is manipulated in order to promote data exploration and interrogation. We provide a framework for exploring this problem space, and an example proof of concept system called Kinetica. We describe the results of a user study that suggest users of Kinetica were able to explore multiple dimensions of data at once, identify outliers, and discover trends with minimal training.
2014	Visualizing dynamic networks with matrix cubes	Designing visualizations of dynamic networks is challenging, both because the data sets tend to be complex and because the tasks associated with them are often cognitively demand- ing. We introduce the Matrix Cube, a novel visual representation and navigation model for dynamic networks, inspired by the way people comprehend and manipulate physical cubes. Users can change their perspective on the data by rotating or decomposing the 3D cube. These manipulations can produce a range of different 2D visualizations that emphasize specific aspects of the dynamic network suited to particular analysis tasks. We describe Matrix Cubes and the interactions that can be performed on them in the Cubix system. We then show how two domain experts, an astronomer and a neurologist, used Cubix to explore and report on their own network data.
2014	The effectiveness (or lack thereof) of aim-assist techniques in first-person shooter games	Aim-assistance techniques have been shown to work for player balancing in 2D environments, but little information exists about how well these techniques will work in a 3D FPS game. We carried out three studies of the performance of five different aim assists in an Unreal-based game world. The assists worked well in a target-range scenario (study 1), but their performance was reduced when game elements were introduced in a walkthrough map (study 2). We systematically examined the relationships between realistic game elements and assist performance (study 3). These studies show that two techniques -- bullet magnetism and area cursor -- worked well in a wide variety of situations. Other techniques that worked well were too perceptible, and some previously-successful techniques did not work well in any game-like scenario. Our studies are the first to provide empirical evidence of the performance of aim assist techniques in 3D environments, and the first to identify the complexities in using these techniques in real FPS games.
2014	Traffigram: distortion for clarification via isochronal cartography	Most geographic maps visually represent physical distance; however, travel time can in some cases be more important than distance because it directly indicates availability. The technique of creating maps from temporal data is known as isochronal cartography, and is a form of distortion for clarification. In an isochronal map, congestion expands areas, while ideal travel conditions make the map shrink in comparison to the actual distance scale of a traditional map. Although there have been many applications of this technique, detailed user studies of its efficacy remain scarce, and there are conflicting views on its practical value. To attempt to settle this issue, we utilized a user-centered design process to determine which features of isochronal cartography might be most usable in practice. We developed an interactive cartographic visualization system, Traffigram, that features a novel combination of efficient isochronal map algorithms and an interface designed to give map users a quick and seamless experience while preserving geospatial integrity and aesthetics. We validated our design choices with multiple usability studies. We present our results and discuss implications for design.
2014	A table!: improving temporal navigation in soccer ranking tables	This article introduces A Table !, an enhanced soccer ranking table providing temporal navigation by combining two novel interaction techniques. Ranking tables order soccer teams represented as rows, according to values of columns containing attributes e.g ., accumulated points, or number of scored goals. Because they represent a snapshot of a championship at a time t , tables are regularly updated with new results. Such updates usually change the rows order, which makes the tracking of a specified team over time difficult. We observed that the tables available on the web do not support tracking such changes very well, are generally hard to read, and lack interactions. This contrasts with the extensive use of comments on temporal trends found in soccer analysts articles. To better support such analyzes, the two interactive techniques presented allow exploration of time, and are designed to preserve users' flow: DRAG-CELL is based on direct manipulation of values to browse ranks; VIZ-RANK uses a transient line chart of team ranks to visually explore a championship. An on-line evaluation with 143 participants shows that each technique efficiently supports a set of important temporal tasks not supported by current ranking tables. This paves the way for introducing efficient advanced visual exploration techniques to millions of soccer enthusiasts who use tables everyday.
2014	Smart subtitles for vocabulary learning	Language learners often use subtitled videos to help them learn. However, standard subtitles are geared more towards comprehension than vocabulary learning, as translations are nonliteral and are provided only for phrases, not vocabulary. This paper presents Smart Subtitles, which are interactive subtitles tailored towards vocabulary learning. Smart Subtitles can be automatically generated from common video sources such as subtitled DVDs. They provide features such as vocabulary definitions on hover, and dialog-based video navigation. In our pilot study with intermediate learners studying Chinese, participants correctly defined over twice as many new words in a post-viewing vocabulary test when they used Smart Subtitles, compared to dual Chinese-English subtitles. Learners spent the same amount of time watching clips with each tool, and enjoyed viewing videos with Smart Subtitles as much as with dual subtitles. Learners understood videos equally well using either tool, as indicated by self-assessments and independent evaluations of their summaries.
2014	Using annotations in online group chats	Annotating documents has long been a widely used strategy for distilling important contents and externalizing related thoughts and ideas in context. No one has studied the activity of annotating dynamic texts, such as online chat, although online conversation is an important communication media for global companies. In this paper, we investigate Instant Annotation (IA), a real-time annotation-enhanced chat tool. We contrast the use of the enhanced chat tool to a standard chat tool for multilingual groups doing a brainstorming and decision-making task. Results show that group satisfaction and perceived control of the conversation are enhanced for the participants who used IA. We also report new patterns of annotation use and discuss design implications for group chat tools.
2014	Coming in from the margins: amateur musicians in the online age	HCI is increasingly interested in amateurism, but the wider literature suggests that the amateur is a complex and distinctive phenomenon. An interview study reveals the nature of the amateur in the digital age. Even though operating non-professionally at a micro-scale, amateur musicians employ a plethora of online services to sustain local fanbases, reach out to new fans, collaborate internationally, and actively promote both digital and material products. Our findings lead to recommendations for event-oriented promotion tools; community-oriented analytics; tangible and embedded products; and limited-edition digital experiences. We conclude that HCI needs to recognise the amateur as an important class of user, one who is serious about their leisure, and who is also distinct from the professional as from the novice and hobbyist.
2014	Designing usable web forms: empirical evaluation of web form improvement guidelines	This study reports a controlled eye tracking experiment (N = 65) that shows the combined effectiveness of 20 guidelines to improve interactive online forms when applied to forms found on real company websites. Results indicate that improved web forms lead to faster completion times, fewer form submission trials, and fewer eye movements. Data from subjective questionnaires and interviews further show increased user satisfaction. Overall, our findings highlight the importance for web designers to improve their web forms using UX guidelines.
2014	skWiki: a multimedia sketching system for collaborative creativity	We present skWiki, a web application framework for collaborative creativity in digital multimedia projects, including text, hand-drawn sketches, and photographs. skWiki overcomes common drawbacks of existing wiki software by providing a rich viewer/editor architecture for all media types that is integrated into the web browser itself, thus avoiding dependence on client-side editors. Instead of files, skWiki uses the concept of paths as trajectories of persistent state over time. This model has intrinsic support for collaborative editing, including cloning, branching, and merging paths edited by multiple contributors. We demonstrate skWiki's utility using a qualitative, sketching-based user study.
2014	Watching the footwork: second screen interaction at a dance and music performance	Interactive mobile technologies have become part of audience experiences of live performances in terms of both general media sharing and specific (sometimes official) extra content. At the same time, high bandwidth affords streaming of live events to mobile devices. We take advantage of these technologies in our high resolution, panoramic image video stream and study a scenario of audience members viewing the very same live event they are watching on a tablet. The video stream on the tablet is navigational and enables audience members to pan and zoom in the real-time video feed. We studied audience interaction and impressions in three performances of a dance and music show and found distinct uses of the second screen video stream. We emphasize that despite initial reluctance, the observed utilization of the technology opened up for new potential practices. Our study shows how working with perceived conflict in technology can still open up design space for interactive technologies.
2014	Distributed analogical idea generation: inventing with crowds	Harnessing crowds can be a powerful mechanism for increasing innovation. However, current approaches to crowd innovation rely on large numbers of contributors generating ideas independently in an unstructured way. We introduce a new approach called distributed analogical idea generation , which aims to make idea generation more effective and less reliant on chance. Drawing from the literature in cognitive science on analogy and schema induction, our approach decomposes the creative process in a structured way amenable to using crowds. In three experiments we show that distributed analogical idea generation leads to better ideas than example-based approaches, and investigate the conditions under which crowds generate good schemas and ideas. Our results have implications for improving creativity and building systems for distributed crowd innovation.
2014	Streaming on twitch: fostering participatory communities of play within live mixed media	Previously, video streaming sites were at the fringes of online social media. In the past two years, live streams of video games, on sites such as Twitch.tv, have become very popular. Live streams serve as meeting grounds for player communities. The Twitch streaming medium combines broadcast video with open IRC chat channels. In conjunction with gameplay, viewer participation and community building gain emphasis. Twitch streams range in size and nature, from intimate communities with fifty viewers, to massive broadcasts with tens of thousands. In this paper, we present an ethnographic investigation of the live streaming of video games on Twitch. We find that Twitch streams act as virtual third places, in which informal communities emerge, socialize, and participate. Over time, stream communities form around shared identities drawn from streams? contents and participants? shared experiences. We describe processes through which stream communities form, the motivations of members, and emergent issues in the medium. Finally, we draw from our findings to derive implications for design of live mixed-media environments to support participatory online communities.
2014	Frenzy: collaborative data organization for creating conference sessions	Organizing conference sessions around themes improves the experience for attendees. However, the session creation process can be difficult and time-consuming due to the amount of expertise and effort required to consider alternative paper groupings. We present a collaborative web application called Frenzy to draw on the efforts and knowledge of an entire program committee. Frenzy comprises (a) interfaces to support large numbers of experts working collectively to create sessions, and (b) a two-stage process that decomposes the session-creation problem into meta-data elicitation and global constraint satisfaction. Meta-data elicitation involves a large group of experts working simultaneously, while global constraint satisfaction involves a smaller group that uses the meta-data to form sessions. We evaluated Frenzy with 48 people during a deployment at the CSCW 2014 program committee meeting. The session making process was much faster than the traditional process, taking 88 minutes instead of a full day. We found that meta-data elicitation was useful for session creation. Moreover, the sessions created by Frenzy were the basis of the CSCW 2014 schedule.
2014	End-users publishing structured information on the web: an observational study of what, why, and how	End-users are accustomed to filtering and browsing styled collections of data on professional web sites, but they have few ways to create and publish such information architectures for themselves. This paper presents a full-lifecycle analysis of the Exhibit framework - an end-user tool which provides such functionality - to understand the needs, capabilities, and practices of this class of users. We include interviews, as well as analysis of over 1,800 visualizations and 200,000 web interactions with these visualizations. Our analysis reveals important findings about this user population which generalize to the task of providing better end-user structured content publication tools.
2014	Choice overload in search engine use?	Search engines typically return so many results that choosing from the list might be predicted to suffer from the effects of "choice overload". Preliminary work has reported just such an effect [12]. In this paper a series of three experiments was conducted to investigate the choice overload effect in search engine use. Participants were given search tasks and presented with either six or twenty-four returns to choose from. The results revealed that the choice behaviour was strongly influenced by the ranking of returns, and that choice satisfaction was affected by the number of options and the decision time. The main results, from the third experiment, showed that large sets of options yielded a positive effect on participants' satisfaction when they made a decision without time limit. When time was more strongly constrained, choices from small sets led to relatively higher satisfaction. Our studies show how user satisfaction with found information can be affected by processing strategies that are influenced by search engine design features.
2014	Type-hover-swipe in 96 bytes: a motion sensing mechanical keyboard	We present a new type of augmented mechanical keyboard, capable of sensing rich and expressive motion gestures performed both on and directly above the device. Our hardware comprises of low-resolution matrix of infrared (IR) proximity sensors interspersed between the keys of a regular mechanical keyboard. This results in coarse but high frame-rate motion data. We extend a machine learning algorithm, traditionally used for static classification only, to robustly support dynamic, temporal gestures. We propose the use of motion signatures a technique that utilizes pairs of motion history images and a random forest based classifier to robustly recognize a large set of motion gestures on and directly above the keyboard. Our technique achieves a mean per-frame classification accuracy of 75.6% in leave-one-subject-out and 89.9% in half-test/half-training cross-validation. We detail our hardware and gesture recognition algorithm, provide performance and accuracy numbers, and demonstrate a large set of gestures designed to be performed with our device. We conclude with qualitative feedback from users, discussion of limitations and areas for future work.
2014	Gesture script: recognizing gestures and their structure using rendering scripts and interactively trained parts	Gesture-based interactions have become an essential part of the modern user interface. However, it remains challenging for developers to create gestures for their applications. This paper studies unistroke gestures, an important category of gestures defined by their single-stroke trajectories. We present Gesture Script, a tool for creating unistroke gesture recognizers. Gesture Script enhances example-based learning with interactive declarative guidance through rendering scripts and interactively trained parts. The structural information from the rendering scripts allows Gesture Script to synthesize gesture variations and generate a more accurate recognizer that also automatically extracts gesture attributes needed by applications. The results of our study with developers show that Gesture Script preserves the threshold of familiar example based gesture tools, while raising the ceiling of the recognizers created in such tools.
2014	Evolution of design competence in UX practice	There has been increasing interest in the adoption of UX within corporate environments, and what competencies translate into effective UX design. This paper addresses the space between pedagogy and UX practice through the lens of competence, with the goal of understanding how students are initiated into the practice community, how their perception of competence shifts over time, and what factors influence this shift. A 12-week longitudinal data collection, including surveys and interviews, documents this shift, with participants beginning internships and full-time positions in UX. Students and early professionals were asked to assess their level of competence and factors that influenced competence. A co-construction of identity between the designer and their environment is proposed, with a variety of factors relating to tool and representational knowledge, complexity, and corporate culture influencing perceptions of competence in UX over time. Opportunities for future research, particularly in building an understanding of competency in UX based on this preliminary framing of early UX practice are addressed.
2014	Personas is applicable: a study on the use of personas in Denmark	The persona method is gaining widespread use and support. Many researchers have reported from single cases and novel domains how they have used the method. Few have conducted literature studies in order to identify and discuss the different understandings of the method. Fewer still have reported on ethnographic studies of practice. This paper falls within the last category, reporting on a study on how practitioners in Denmark use the method, and their perceptions of benefits and challenges when using the method. Finally, different casts of personas obtained from the involved companies are analyzed. The findings are compared to reported studies of practice. Contrary to the existing findings the study reports that the method is well integrated into existing practices.
2014	Causal interactions	In this paper we present two design guidelines, causal order and continuity, to be used as rules of thumb for designing intuitive interactions based on principles of causal reasoning. We propose that designing interactions to behave like real-world systems of cause and effect makes them more intuitive. Using these basic principles avoids the limitations inherent to specific metaphors. In three experiments, participants solved puzzles using variations of a novel graphical interface. Participants using interfaces that were consistent with the causal guidelines consistently solved the puzzle faster than participants using inconsistent interfaces. We also discuss common interactions already consistent with the causal guidelines as well as areas where the guidelines are likely to apply successfully. The causal order guidelines provide specific utility while also demonstrating how principles of causal psychology can be applied to help interface designers better convey the functionality of their interfaces.
2014	Sketching in circuits: designing and building electronics on paper	The field of new methods and techniques for building electronics is quickly growing - from research in new materials for circuit building, to modular toolkits, and more recently to untoolkits, which aim to incorporate more off-the-shelf parts. However, the standard mediums for circuit design and construction remain the breadboard, protoboard, and printed circuit board (PCB). As an alternative, we introduce a method in which circuits are hand-made on ordinary paper substrates, connected with conductive foil tape and off-the-shelf circuit components with the aim of supporting the durability, scalability, and accessibility needs of novice and expert circuit builders alike. We also used electrified notebooks to investigate how the circuit design and build process would be affected by the constraints and affordances of the bound book. Our ideas and techniques were evaluated through a series of workshops, through which we found our methods supported a wide variety of approaches and results - both technical and expressive - to electronics design and construction.
2014	GestKeyboard: enabling gesture-based interaction on ordinary physical keyboard	Stroke gestures are intuitive and efficient but often require gesture-capable input hardware such as a touchscreen. In this paper, we present GestKeyboard, a novel technique for gesturing over an ordinary, unmodified physical keyboard that remains the major input modality for existing desktop and laptop computers. We discuss an exploratory study for understanding the design space of gesturing on a physical keyboard and our algorithms for detecting gestures in a modeless way, without interfering with the keyboard's major functionality such as text entry and shortcuts activation. We explored various features for detecting gestures from a keyboard event stream. Our experiment based on the data collected from 10 participants indicated it is feasible to reliably detect gestures from normal keyboard use, 95% detection accuracy within a maximum latency of 200ms.
2014	B#: chord-based correction for multitouch braille input	Braille has paved its way into mobile touchscreen devices, providing faster text input for blind people. This advantage comes at the cost of accuracy, as chord typing over a flat surface has proven to be highly error prone. A misplaced finger on the screen translates into a different or unrecognized character. However, the chord itself gathers information that can be leveraged to improve input performance. We present B#, a novel correction system for multitouch Braille input that uses chords as the atomic unit of information rather than characters. Experimental results on data collected from 11 blind people revealed that B# is effective in correcting errors at character-level, thus providing opportunities for instant corrections of unrecognized chords; and at word-level, where it outperforms a popular spellchecker by providing correct suggestions for 72% of incorrect words (against 38%). We finish with implications for designing chord-based correction system and avenues for future work.
2014	Representatively memorable: sampling the right phrase set to get the text entry experiment right	In text entry experiments, memorability is a desired property of the phrases used as stimuli. Unfortunately, to date there is no automated method to achieve this effect. As a result, researchers have to use either manually curated English-only phrase sets or sampling procedures that do not guarantee phrases being memorable. In response to this need, we present a novel sampling method based on two core ideas: a multiple regression model over language-independent features, and the statistical analysis of the corpus from which phrases will be drawn. Our results show that researchers can finally use a method to successfully curate their own stimuli targeting potentially any language or domain. The source code as well as our phrase sets are publicly available.
2014	Designing for slowness, anticipation and re-visitation: a long term field study of the photobox	We describe the design, implementation and deployment of Photobox, a domestic technology that prints four or five randomly selected photos from the owner's Flickr collection at random intervals each month. We deployed Photobox in three homes for fourteen months, to explore how the slow pace at which it operates could support experiences of anticipation and re-visitation of the past. Findings reveal changes in attitude toward the device, from frustration to eventual acceptance. Participants drew on the photos to reflect on past life events and reactions indicated a renewed interest for their Flickr collection. Photobox also provoked reflection on technology in and around the home. These findings suggest several opportunities, such as designing for anticipation, better supporting reflection on the past, and, more generally, expanding the slow technology research program within the HCI community.
2014	Generating implications for design through design research	A central tenet of HCI is that technology should be user-centric, with designs being based around social science findings about users. Nevertheless a repeated but critical challenge in design is translating empirical findings into actionable ideas that inform design, or generating implications for design . Despite various design methods aiming to bridge this gap, knowledge informing design is still seen as problematic. However there has been little empirical exploration into what design researchers understand by such design knowledge, the functions and principles behind their creation. We report on interviews with twelve expert HCI design researchers probing the roles and types of design implications, and the process of generating and evaluating them. We synthesize different types of design implications into a framework to guide their generation. Our findings identify a broader range than previously described, additional sources and heuristics supporting their development as well some important evaluation criteria. We discuss the value of these findings for interaction design research.
2014	Probabilistic palm rejection using spatiotemporal touch features and iterative classification	Tablet computers are often called upon to emulate classical pen-and-paper input. However, touchscreens typically lack the means to distinguish between legitimate stylus and finger touches and touches with the palm or other parts of the hand. This forces users to rest their palms elsewhere or hover above the screen, resulting in ergonomic and usability problems. We present a probabilistic touch filtering approach that uses the temporal evolution of touch contacts to reject palms. Our system improves upon previous approaches, reducing accidental palm inputs to 0.016 per pen stroke, while correctly passing 98% of stylus inputs.
2014	Reading critical designs: supporting reasoned interpretations of critical design	Critical Design has emerged as an important concept in HCI research and practice. Yet researchers have noted that its uptake has been limited by certain lacks of intellectual infrastructure theories, methodologies, canons and exemplars, and a community of practice. We argue that one way to create this infrastructure is to cultivate a community adept at reading that is, critically interpreting and making reasoned judgments about critical designs. We propose an approach to developing close readings of critical designs, which are both evidence-based and carefully reasoned. The approach highlights analytical units of analysis, the relevance of design languages and social norms, and the analytical contemplation of critical aspects of a design. It is intended to be relatively easy to learn, to try out, and to teach, in the hopes of inviting more members of the HCI community to engage in this practice. We exemplify the approach with readings of two critical designs and reflect on different ways that a design might serve a critical purpose or offer a critical argument about design, society, and the future.
2014	Investigating the effects of encumbrance on one- and two- handed interactions with mobile devices	In this paper, we investigate the effects of encumbrance (carrying typical objects such as shopping bags during interaction) and walking on target acquisition on a touchscreen mobile phone. Users often hold objects and use mobile devices at the same time and we examined the impact encumbrance has on one- and two- handed interactions. Three common input postures were evaluated: two-handed index finger, one-handed preferred thumb and two-handed both thumbs, to assess the effects on performance of carrying a bag in each hand while walking. The results showed a significant decrease in targeting performance when users were encumbered. For example, input accuracy dropped to 48.1% for targeting with the index finger when encumbered, while targeting error using the preferred thumb to input was 4.2mm, an increase of 40% compared to unencumbered input. We also introduce a new method to evaluate the user's preferred walking speed when interacting - PWS&I, and suggest future studies should use this to get a more accurate measure of the user's input performance.
2014	Modeling the functional area of the thumb on mobile touchscreen surfaces	We present a predictive model for the functional area of the thumb on a touchscreen surface: the area of the interface reachable by the thumb of the hand that is holding the device. We derive a quadratic formula by analyzing the kinematics of the gripping hand. Model fit is high for the thumb-motion trajectories of 20 participants. The model predicts the functional area for a given 1) surface size, 2) hand size, and 3) position of the index finger on the back of the device. Designers can use this model to ensure that a user interface is suitable for interaction with the thumb. The model can also be used inversely - that is, to infer the grips assumed by a given user interface layout.
2014	Coordination of tilt and touch in one- and two-handed use	Our goal is to enhance navigation in mobile interfaces with quick command gestures that do not make use of explicit mode-switching actions. TilTouch gestures extend the vocabulary of navigation interfaces by combining motion tilt with directional touch. We consider sixteen directional TilTouch gestures that rely on tilt and touch movements along the four main compass directions. An experiment explores their effectiveness for both one-handed and two-handed use. Results identify the best combinations of TilTouch gestures in terms of performance, motor coordination, and user preferences.
2014	28 frames later: predicting screen touches from back-of-device grip changes	We demonstrate that front-of-screen targeting on mobile phones can be predicted from back-of-device grip manipulations. Using simple, low-resolution capacitive touch sensors placed around a standard phone, we outline a machine learning approach to modelling the grip modulation and inferring front-of-screen touch targets. We experimentally demonstrate that grip is a remarkably good predictor of touch, and we can predict touch position 200ms before contact with an accuracy of 18mm.
2014	Orientation matters: efficiency of translation-rotation multitouch tasks	The translation and rotation of objects with two fingers is a well explored multitouch technique. However, there are some unsolved questions regarding the optimal conditions under which this technique functions best. Does it matter in which direction the movement is oriented? Does parallel or sequential performance of the two operations work best? This study attempts to answer this question using a typical Fitts' Law setup but with varying translation-rotation orientation combinations. The results show that right-oriented movements were faster and easier than left-oriented ones. Movement combinations which went in different directions (translation right, rotation left, and vice versa) were found more tiresome and resulted in more strategy switches compared to equi-directional combinations. Our findings can inform positioning decisions in interaction design and contribute to theoretical adjustments to Fitts' Law.
2014	Leakiness and creepiness in app space: perceptions of privacy and mobile app use	Mobile devices are playing an increasingly intimate role in everyday life. However, users can be surprised when informed of the data collection and distribution activities of apps they install. We report on two studies of smartphone users in western European countries, in which users were confronted with app behaviors and their reactions assessed. Users felt their personal space had been violated in "creepy" ways. Using Altman's notions of personal space and territoriality, and Nissenbaum's theory of contextual integrity, we account for these emotional reactions and suggest that they point to important underlying issues, even when users continue using apps they find creepy.
2014	Listening to the forest and its curators: lessons learnt from a bioacoustic smartphone application deployment	Our natural environment is complex and sensitive, and is home to a number of species on the verge of extinction. Surveying is one approach to their preservation, and can be supported by technology. This paper presents the deployment of a smartphone-based citizen science biodiversity application. Our findings from interviews with members of the biodiversity community revealed a tension between the technology and their established working practices. From our experience, we present a series of general guidelines for those designing citizen science apps.
2014	A field trial of privacy nudges for facebook	Anecdotal evidence and scholarly research have shown that Internet users may regret some of their online disclosures. To help individuals avoid such regrets, we designed two modifications to the Facebook web interface that nudge users to consider the content and audience of their online disclosures more carefully. We implemented and evaluated these two nudges in a 6-week field trial with 28 Facebook users. We analyzed participants' interactions with the nudges, the content of their posts, and opinions collected through surveys. We found that reminders about the audience of posts can prevent unintended disclosures without major burden; however, introducing a time delay before publishing users' posts can be perceived as both beneficial and annoying. On balance, some participants found the nudges helpful while others found them unnecessary or overly intrusive. We discuss implications and challenges for designing and evaluating systems to assist users with online disclosures.
2014	Broken display = broken interface': the impact of display damage on smartphone interaction	This paper is the first to assess the impact of touchscreen damage on smartphone interaction. We gathered a dataset consisting of 95 closeup images of damaged smartphones and extensive information about a device's usage history, damage severity, and impact on use. 88% of our participants continued to use their damaged smartphone for at least three months; 32% plan to use it for another year or more, mainly due to high repair and replacement costs. From the dataset, we identified three categories of damaged smartphone displays. Reading and text input were most affected. Further interviews ( n =11) revealed that users adapt to damage with diverse coping strategies, closely tailored to specific interaction issues. In total, we identified 23 different strategies. Based on our results, we proposed guidelines for interaction design in order to provide a positive user experience when display damage occurs.
2014	In situ with bystanders of augmented reality glasses: perspectives on recording and privacy-mediating technologies	Augmented reality (AR) devices are poised to enter the market. It is unclear how the properties of these devices will affect individuals' privacy. In this study, we investigate the privacy perspectives of individuals when they are bystanders around AR devices. We conducted 12 field sessions in cafés and interviewed 31 bystanders regarding their reactions to a co-located AR device. Participants were predominantly split between having indifferent and negative reactions to the device. Participants who expressed that AR devices change the bystander experience attributed this difference to subtleness, ease of recording, and the technology's lack of prevalence. Additionally, participants surfaced a variety of factors that make recording more or less acceptable, including what they are doing when the recording is being taken. Participants expressed interest in being asked permission before being recorded and in recording-blocking devices. We use the interview results to guide an exploration of design directions for privacy-mediating technologies.
2014	Making public things: how HCI design can express matters of concern	Science studies scholar Bruno Latour suggests that contemporary democracy is shifting from "matters of fact"to "matters of concern": contentious conditions entwined with everyday life. What is the role of human-computer interaction (HCI) design in this shift' In this paper we draw from five design projects to explore how design can express matters of concern by communicating the factors and consequences of issues. In the process, we consider the role of design in contributing to the formation of publics and discuss an emerging orientation to publics in HCI design.
2014	Everyday ideation: all of my ideas are on pinterest	We develop new understanding of how people engage in digital curation. We interview twenty users of Pinterest, a social curation platform. We find that through collecting, organizing, and sharing image bookmarks, users engage in processes of everyday ideation . That is, they use digital found objects as creative resources to develop ideas for shaping their lives. Curators assemble information into new contexts, forming and sharing ideas with practical and emotional value. We investigate cognitive and social aspects of creativity that affect the digital curation practices of everyday ideation. We derive implications for the design of curation environments that support information-based ideation.
2014	Personalisation and privacy in future pervasive display networks	There is increasing interest in using digital signage to deliver highly personalised content. However, display personalization presents a number of architectural design challenges in particular, how best to provide personalisation without unduly compromising viewers' privacy. While previous research has focused on understanding specific elements of the overall vision, our work presents details of the first significant attempt at a system that integrates future pervasive display networks and mobile devices to support display personalisation. We describe a series of usage models and design goals for display personalisation and then present Tacita, a system that supports these models and goals. Our architecture includes mobile, display and cloud-based elements and provides comprehensive personalisation features while preventing the creation of user profiles within the display infrastructure, thus helping to preserve users' privacy. An initial evaluation of our prototype implementation of the architecture is also included and demonstrates the viability of the Tacita approach.
2014	Just awful enough: the functional dysfunction of the something awful forums	The Something Awful Forums (SAF) is an online community comprised of a loosely connected federation of forums, united in a distinctive brand of humor with a focus on the quality of member contributions. In this case study we find that the site has sustained success while deviating from common conventions and norms of online communities. Humor and the quality of content contributed by SAF members foster practices that seem counterintuitive to the development of a stable and thriving community. In this case study we show how design decisions are contextual and inter-dependent and together these heuristics create a different kind of online third place that challenges common practices.
2014	Experience design theatre: exploring the role of live theatre in scaffolding design dialogues	While theatre has been used in HCI as a tool for engaging participants in design processes, the specific benefits of using live theatre over other communicative mediums, remains underexplored. In this paper we introduce Experience Design Theatre (EDT) as an approach to undertaking experience-centered design with multiple parties in the early stages of design. EDT was motivated by a need to involve several diverse groups of people in the design of a digitally coordinated care service - NetCarers. We used live theatre as a way to engage small groups of participants in dialogues around the design of NetCarers, to qualify their contributions in a refined performance, and to communicate their concerns and aspirations to domain experts. We highlight key benefits to using live theatre in experience-centered design and offer insights for researchers undertaking similar work in the future.
2014	Gifting personal interpretations in galleries	The designers of mobile guides for museums and galleries face three major challenges: fostering rich interpretation, delivering deep personalization, and enabling a coherent social visit. We propose an approach to tackling all three simultaneously by inviting visitors to design an interpretation that is specifically tailored for a friend or loved one that they then experience together. We describe a trial of this approach at a contemporary art gallery, revealing how visitors designed personal and sometimes provocative experiences for people they knew well. We reveal how pairs of visitors negotiated these experiences together, showing how our approach could deliver intense experiences for both, but also required them to manage social risk. By interpreting our findings through the lens of 'gift giving' we shed new light on ongoing explorations of interpretation, personalization and social visiting within HCI.
2014	Staccato social support in mobile health applications	Social support plays an important role in health systems. While significant work has explored the role of social support in CMC environments, less analysis has considered social support in mobile health systems. This paper describes socially supportive messages in VERA, a mobile application for sharing health decisions and behaviors. The short and bursty interactions in social awareness streams [36] afford a particular style of social support, for which we offer the label staccato social support. Results indicate that, in comparison to previous work, staccato social support is characterized by a greater prevalence of esteem support, which builds respect and confidence. We further note the presence of 'following up', a positive behavior that contributes to supportive interactions, likely via social pressure and accountability [7,38]. These findings suggest design recommendations to developers of mobile social support systems and contribute to understanding technologically mediated social support for health.
2014	The implicit fan cursor: a velocity dependent area cursor	We present the Implicit Fan Cursor (IFC) - a novel target pointing technique using a cursor with a fan-shape activation area. The IFC couples the cursor's activation area with its velocity, i.e., the speed and direction of the mouse motion, behaving like a 2D spotlight cursor at low speed and a circular area cursor at high speed. Thus, it enables the user to precisely acquire distant targets at low speed and easily acquire nearest targets at high speed, without explicit mode switching. This technique minimizes cursor movement, while taking into consideration of the precision of cursor movement at different speeds. It also ensures that only one target is captured at any time. The results of our controlled experiments show that the IFC outperforms the point cursor and the area cursor techniques, particularly in terms of cursor moving distance, and that its performance can be accurately modeled using the Fitts' law.
2014	Poverty on the cheap: estimating poverty maps using aggregated mobile communication networks	Governments and other organisations often rely on data collected by household surveys and censuses to identify areas in most need of regeneration and development projects. However, due to the high cost associated with the data collection process, many developing countries conduct such surveys very infrequently and include only a rather small sample of the population, thus failing to accurately capture the current socio-economic status of the country's population. In this paper, we address this problem by means of a methodology that relies on an alternative source of data from which to derive up to date poverty indicators, at a very fine level of spatio-temporal granularity. Taking two developing countries as examples, we show how to analyse the aggregated call detail records of mobile phone subscribers and extract features that are strongly correlated with poverty indexes currently derived from census data.
2014	An assistive robotic table for older and post-stroke adults: results from participatory design and evaluation activities with clinical staff	An inevitable new frontier for the CHI community is the development of complex, larger-scale, cyber-physical artifacts where advancements in design, computing and robotics converge. Presented here is a design exemplar: the Assistive, Robotic Table (ART), the key component of our envisioned home suite of networked, robotic furnishings for hospitals and homes, promoting wellbeing and independent living. We begin with the motivations for ART, and present our iterative, five-phase, participatory design-and-evaluation process involving clinicians at a rehabilitation hospital, focusing here on the final usability study. From our wide-ranging design-research activities, which may be characterized as research through design, we found ART to be promising but also challenging. As a design exemplar, ART offers invaluable lessons to the CHI community as it comes to design larger-scale, cyber-physical artifacts cultivating interactions across people and their surroundings that define places of social, cultural and psychological significance.
2014	Impact of form factors and input conditions on absolute indirect-touch pointing tasks	Absolute indirect interaction maps the absolute position of a device's end-effector to the absolute position of a remote on-screen object.Despite its long-time use with graphics tablets and growing use in research prototypes, little is known on the influence of form factors and input conditions on pointing performance with such a mapping. The input and display can have different sizes and aspect ratios, for example. The on-screen targets can vary in size. Users can look solely at the display or at the input device as well. They can also hold the input device in certain cases, or let it rest on a table. This paper reports on two experiments designed to investigate the influence of all these factors on absolute indirect-touch pointing performance. We also provide design guidelines for interaction in these situations based on the observed impacting factors.
2014	Non-finito products: a new design space of user creativity for personal user experience	Conventional wisdom says that to be successful, an idea must be concrete, complete, and certain. However, what if unfinished ideas work? This CHI paper proposes a new design space we call non-finito products for the HCI community. This new design space is about intentionally unfinished products and how they foster new creations by end-users as they are actually used to help people solve their own problems. The central idea comes from the background of the growing complexity associated with IT advancement and from the new way of dealing with it, with the assistance of user creativity in the actual use of the products. This paper begins with the exploration of non-finito products as a new design space for the end-user's creativity in the personal user experience. We then defined and proposed non-finito products. We discussed three case studies that will help to understand the design space of non-finito products, and we framed the new design space by revealing the beneficial contexts and values. Finally, we suggested the implications of designing non-finito products. We believe that non-finito products will open a new design space in HCI, prompt a new means of replacing value-destroying complexity with value-creating version, and help to make a product better fit to user experience.
2014	Mouse pointing endpoint prediction using kinematic template matching	We present a new method of predicting the endpoints of mouse movements. While prior approaches to endpoint prediction have relied upon normative kinematic laws, regression, or control theory, our approach is straightforward but kinematically rich. Our key insight is to regard the unfolding velocity profile of a pointing movement as a 2-D stroke gesture and to use template matching to predict the endpoint based on prior observed movements. We call our technique kinematic template matching (KTM), which is simple to implement, user-adaptable, and kinematically expressive. In a study of 17 able-bodied participants evaluated over movement amplitudes ranging from 100-800 pixels, we found KTM to predict endpoints that were within 83 pixels of the true endpoint at 50% of the way through the movement, within 48 pixels at 75%, and within 39 pixels at 90%, using 1000 templates per participant. These accuracies make KTM as successful an approach to endpoint prediction as any prior technique, while being easier to implement and understand than most.
2014	Research on research: design research at the margins: academia, industry and end-users	Design research processes often take place in publicly funded projects. Besides designers and users, public funding increasingly requires industry partners to participate in such projects. We present empirical insights from a joint research project in order to assess the claims connected with such funding structures and to report on challenges for design research within them. We identify three themes of conflict between academic and industry partners and elaborate on the sources of them. The presentation of our results builds on the distinction between 'academia' and 'industry', which is frequently applied by political funding agencies. The analysis of the respective stakeholders' actual interests, however, will prove such a dichotomy to be misleading and simplistic.
2014	Vulture: a mid-air word-gesture keyboard	Word-gesture keyboards enable fast text entry by letting users draw the shape of a word on the input surface. Such keyboards have been used extensively for touch devices, but not in mid-air, even though their fluent gestural input seems well suited for this modality. We present Vulture, a word-gesture keyboard for mid-air operation. Vulture adapts touch based word-gesture algorithms to work in mid-air, projects users' movement onto the display, and uses pinch as a word delimiter. A first 10-session study suggests text-entry rates of 20.6 Words Per Minute (WPM) and finds hand-movement speed to be the primary predictor of WPM. A second study shows that with training on a few phrases, participants do 28.1 WPM, 59% of the text-entry rate of direct touch input. Participants' recall of trained gestures in mid-air was low, suggesting that visual feedback is important but also limits performance. Based on data from the studies, we discuss improvements to Vulture and some alternative designs for mid-air text entry.
2014	In the blink of an eye: investigating latency perception during stylus interaction	While pen computing has become increasingly more popular, device responsiveness, or latency, still plagues such interaction. Although there have been advances in digitizer technology over the last few years, commercial end-to-end latencies are unfortunately similar to those found with touchscreens, i.e., 65 - 120 milliseconds. We report on a prototype stylus-enabled device, the High Performance Stylus System (HPSS), designed to display latencies as low as one millisecond while users ink or perform dragging tasks. To understand the role of latency while inking with a stylus, psychophysical just-noticeable difference experiments were conducted using the HPSS. While participants performed dragging and scribbling tasks, very low levels of latency could be discriminated, i.e., ~1 versus 2 milliseconds while dragging and ~7 versus 40 milliseconds while scribbling. The HPSS and our experimentation have provided further motivation for the implementation of latency saving measures in pen-based hardware and software systems.
2014	Pinch-drag-flick vs. spatial input: rethinking zoom & pan on mobile displays	The multi-touch-based pinch to zoom, drag and flick to pan metaphor has gained wide popularity on mobile displays, where it is the paradigm of choice for navigating 2D documents. But is finger-based navigation really the gold standard' In this paper, we present a comprehensive user study with 40 participants, in which we systematically compared the Pinch-Drag-Flick approach with a technique that relies on spatial manipulation, such as lifting a display up/down to zoom. While we solely considered known techniques, we put considerable effort in implementing both input strategies on popular consumer hardware (iPhone, iPad). Our results show that spatial manipulation can significantly outperform traditional Pinch-Drag-Flick. Given the carefully optimized prototypes, we are confident to have found strong arguments that future generations of mobile devices could rely much more on spatial interaction principles.
2014	Exploring the usefulness of finger-based 3D gesture menu selection	Counting using one's fingers is a potentially intuitive way to enumerate a list of items and lends itself naturally to gesture-based menu systems. In this paper, we present the results of the first comprehensive study on Finger-Count menus to investigate its usefulness as a viable option for 3D menu selection tasks. Our study compares 3D gesture-based finger counting (Finger Count menus) with two gesture-based menu selection techniques (Hand-n-Hold, Thumbs-Up), derived from existing motion-controlled video game menu selection strategies, as well as 3D Marking menus. We examined selection time, selection accuracy and user preference for all techniques. We also examined the impact of different spatial layouts for menu items and different menu depths. Our results indicate that Finger-Count menus are significantly faster than the other menu techniques we tested and are the most liked by participants. Additionally, we found that while Finger-Count menus and 3D Marking menus have similar selection accuracy, Finger-Count menus are almost twice as fast compared to 3D Marking menus.
2014	InkAnchor: enhancing informal ink-based note taking on touchscreen mobile phones	Although touchscreen mobile phones are widely used for recording informal text notes (e.g., grocery lists, reminders and directions), the lack of efficient mechanisms for combining informal graphical content with text is a persistent challenge. In this paper, we present InkAnchor, a digital ink editor that allows users to easily create ink-based notes by finger drawing and writing on a mobile phone touchscreen. InkAnchor incorporates flexible anchoring, focus-plus-context input, content chunking, and lightweight editing mechanisms to support the capture of informal notes and annotations. We describe the design and evaluation of InkAnchor through a series of user studies, which revealed that the integrated support enabled by InkAnchor is a significant improvement over current mobile note taking applications on a range of mobile note-taking tasks.
2014	Understanding quantified-selfers' practices in collecting and exploring personal data	Researchers have studied how people use self-tracking technologies and discovered a long list of barriers including lack of time and motivation as well as difficulty in data integration and interpretation. Despite the barriers, an increasing number of Quantified-Selfers diligently track many kinds of data about themselves, and some of them share their best practices and mistakes through Meetup talks, blogging, and conferences. In this work, we aim to gain insights from these "extreme users," who have used existing technologies and built their own workarounds to overcome different barriers. We conducted a qualitative and quantitative analysis of 52 video recordings of Quantified Self Meetup talks to understand what they did, how they did it, and what they learned. We highlight several common pitfalls to self-tracking, including tracking too many things, not tracking triggers and context, and insufficient scientific rigor. We identify future research efforts that could help make progress toward addressing these pitfalls. We also discuss how our findings can have broad implications in designing and developing self-tracking technologies.
2014	Understanding finger input above desktop devices	Using the space above desktop input devices adds a rich new input channel to desktop interaction. Input in this elevated layer has been previously used to modify the granularity of a 2D slider, navigate layers of a 3D body scan above a multitouch table and access vertically stacked menus. However, designing these interactions is challenging because the lack of haptic and direct visual feedback easily leads to input errors. For bare finger input, the user's fingers needs to reliably enter and stay inside the interactive layer, and engagement techniques such as midair clicking have to be disambiguated from leaving the layer. These issues have been addressed for interactions in which users operate other devices in midair, but there is little guidance for the design of bare finger input in this space. In this paper, we present the results of two user studies that inform the design of finger input above desktop devices. Our studies show that 2 cm is the minimum thickness of the above-surface volume that users can reliably remain within. We found that when accessing midair layers, users do not automatically move to the same height. To address this, we introduce a technique that dynamically determines the height at which the layer is placed, depending on the velocity profile of the user's initial finger movement into midair. Finally, we propose a technique that reliably distinguishes clicking from homing movements, based on the user's hand shape. We structure the presentation of our findings using Buxton's three-state input model, adding additional states and transitions for above-surface interactions.
2014	Perception of ultrasonic haptic feedback on the hand: localisation and apparent motion	Ultrasonic haptic feedback is a promising means of providing tactile sensations in mid-air without encumbering the user with an actuator. However, controlled and rigorous HCI research is needed to understand the basic characteristics of perception of this new feedback medium, and so how best to utilise ultrasonic haptics in an interface. This paper describes two experiments conducted into two fundamental aspects of ultrasonic haptic perception: 1) localisation of a static point and 2) the perception of motion. Understanding these would provide insight into 1) the spatial resolution of an ultrasonic interface and 2) what forms of feedback give the most convincing illusion of movement. Results show an average localisation error of 8.5mm, with higher error along the longitudinal axis. Convincing sensations of motion were produced when travelling longer distances, using longer stimulus durations and stimulating multiple points along the trajectory. Guidelines for feedback design are given.
2014	BodyDiagrams: improving communication of pain symptoms through drawing	Thousands of people use the Internet to discuss pain symptoms. While communication between patients and physicians involves both verbal and physical interactions, online discussions of symptoms typically comprise text only. We present BodyDiagrams, an online interface for expressing symptoms via drawings and text. BodyDiagrams augment textual descriptions with pain diagrams drawn over a reference body and annotated with severity and temporal metadata. The resulting diagrams can easily be shared to solicit feedback and advice. We also conduct a two-phase user study to assess BodyDiagrams' communicative efficacy. In the first phase, users describe pain symptoms using BodyDiagrams and a text-only interface; in the second phase, medical professionals evaluate these descriptions. We find that patients are significantly more confident that their BodyDiagrams will be correctly interpreted, while medical professionals rated BodyDiagrams as significantly more informative than text descriptions. Both groups indicated a preference for using diagrams to communicate physical symptoms in the future.
2014	Supporting treatment of people living with HIV / AIDS in resource limited settings with IVRs	We developed an interactive voice response (IVR) system called TAMA (Treatment Advice by Mobile Alerts) that provides treatment support to people living with HIV / AIDS (PLHA) in developing countries, who are on antiret-roviral therapy (ART). We deployed TAMA with 54 PLHA in 5 HIV clinics in India for a period of 12 weeks. During the study, we gathered feedback about TAMA's design and usage. Additionally, we conducted detailed qualitative interviews and analysed usage logs. We found that TAMA was usable and viable in the real life settings of PLHA and it had many desirable effects on their treatment adherence. We developed insights that inform the design of TAMA and some of these can be generalised to design of other long-term, frequent-use IVR applications for users in developing countries in the healthcare domain and beyond.
2014	DemoWiz: re-performing software demonstrations for a live presentation	Showing a live software demonstration during a talk can be engaging, but it is often not easy: presenters may struggle with (or worry about) unexpected software crashes and encounter issues such as mismatched screen resolutions or faulty network connectivity. Furthermore, it can be difficult to recall the steps to show while talking and operating the system all at the same time. An alternative is to present with pre-recorded screencast videos. It is, however, challenging to precisely match the narration to the video when using existing video players. We introduce DemoWiz, a video presentation system that provides an increased awareness of upcoming actions through glanceable visualizations. DemoWiz supports better control of timing by overlaying visual cues and enabling lightweight editing. A user study shows that our design significantly improves the presenters' perceived ease of narration and timing compared to a system without visualizations that was similar to a standard playback control. Furthermore, nine (out of ten) participants preferred DemoWiz over the standard playback control with the last expressing no preference.
2014	DDFSeeks same: sexual health-related language in online personal ads for men who have sex with men	The HIV/AIDS crisis of the 1980s fundamentally changed sexual practices of men who have sex with men (MSM) in the U.S., including increased usage of sexual health-related (SHR) language in personal advertisements. Analyzing online personal ads from Craigslist, we found a substantial increase in SHR language, from ~23% in 1988 to over 53% today, echoing continuing concern about rising HIV rates. We argue that SHR language in Craigslist ads can be used as a sensor to provide insight into HIV epidemiology as well as discourse among particular communities. We show a positive significant relationship between prevalence rate of HIV in an ad's location and use of SHR language in that location. Analysis highlights the opportunity for SHR information found in Craigslist personal ads to serve as a data source for HIV prevention research. More broadly, we argue for mining large-scale user-generated content to inform HCI design of health and other systems, and explore use of such data to examine temporal changes in language to facilitate improved user-interface design.
2014	Between theory and practice: bridging concepts in HCI research	We present the notion of "bridging concepts" as a particular form of intermediary knowledge in HCI research, residing between theory and practice. We argue that bridging concepts address the challenge of facilitating exchange between theory and practice in HCI, and we compare it to other intermediary forms of knowledge such as strong concepts and conceptual constructs. We propose that bridging concepts have three defining constituents: a theoretical foundation, a set of design articulations and a range of exemplars that demonstrate the scope and potential of their application. These constituents specify how bridging concepts, as a form of knowledge, are accountable to both theory and practice. We present an analysis of the concept of "peepholes" as an example of a bridging concept aimed at spurring user curiosity and engagement.
2014	Reflection through design: immigrant women's self-reflection on managing health and wellness	Women comprise nearly half of the immigrant population worldwide and are susceptible to a wider range of health challenges compared to immigrant men. We present the findings of four participatory design sessions with immigrant women from the Caribbean to identify health and wellness challenges they faced and to conceptualize technologies to help them manage these issues. Stress, dietary challenges (specifically obesity), mental health, and domestic abuse, as identified by the women, form the focal themes for the design sessions. Their design approaches emphasized rebuilding the support structure, reducing stressors through entertainment and relaxation and encouraging positive gradational lifestyle changes . In conceiving health and wellness technologies for immigrant women, our work highlights opportunities for HCI to consider the role of others (and who benefits) and to reflect on the role of design and the underlying values and themes designs encompass. Finally, we emphasize how the technologies conceived by these women support rather than replace social solutions to the health and wellness challenges faced by these and other immigrant women.
2014	Support matching and satisfaction in an online breast cancer support community	Research suggests that online health support benefits chronically ill users. Their satisfaction might be an indicator that they perceive group interactions as beneficial and a precursor to group commitment. We examined whether receiving emotional and informational support is satisfying in its own right, or whether satisfaction depends on matches between what users sought and what they received. Two studies collected judgments in a breast cancer support community of support users sought, support they received, and their expressed satisfaction. While receiving emotional or informational support in general positively predicted satisfaction, users expressed less satisfaction when they sought informational support but received emotional support. There was also a tendency for users to express more satisfaction when they sought and received informational support. On the other hand, users were equally satisfied with emotional and informational support after seeking emotional support. Implications for membership commitment and interventions in online support groups are discussed.
2014	PitchPerfect: integrated rehearsal environment for structured presentation preparation	Rehearsal is a critical component of preparing to give an oral presentation, yet it is frequently abbreviated, performed in ways that are inefficient or ineffective, or simply omitted. We conducted an exploratory study to understand the relationship between the theory and practice of presentation rehearsal, classifying our qualitative results into five themes to motivate more structured rehearsal support deeply integrated in slide presentation software. In a within-subject study ( N =12) comparing against participants' existing rehearsal practices, we found that our resulting PitchPerfect system significantly improved overall presentation quality and content coverage as well as provided greater support for content mastery, time management, and confidence building.
2014	SmartVoice: a presentation support system for overcoming the language barrier	In most cases, speeches or presentations at an international event are required to be given in a common language (e.g. English). However, for people who are not proficient in that common language, delivering presentations fluently is very difficult. Simultaneous translation seems to be a solution, but besides its high cost, simultaneous translation undermines the nature of the presentation by substituting the real voice of the lecturer as well as his/her emotions. In this paper, we propose "SmartVoice", a presentation support system, which aims to overcome language barriers. By tracking the lip motion of the lecturer, SmartVoice controls the playback of the narration, which is a sound data prepared in advance or created automatically using a voice synthesizer. SmartVoice also controls the intonation of the sound based on the position and shape of the lecturer's mouth. As the lecturer can talk at his/her own pace with the voice automatically following, it appears as if he/she talks in his/her own voice. In our user evaluation, we confirmed that audiences find it difficult to distinguish between the narration generated by SmartVoice and that by a real voice. We also discuss the possibility of applying SmartVoice to fields other than multi-language presentation support, such as Automated Dialogue Replacement and language study.
2014	TurningPoint: narrative-driven presentation planning	Once upon a time, people told stories unencumbered by slides. What modern presentations gain through visual slide support, however, is often at the expense of storytelling. We present TurningPoint, a probe to investigate the potential use of narrative-driven talk planning in slideware. Our study of TurningPoint reveals a delicate balance between narrative templates focusing author attention in ways that save time, and fixating attention in ways that limit experimentation.
2014	FrameBox and MirrorBox: tools and guidelines to support designers in prototyping interfaces for 3D displays	In this paper, we identify design guidelines for stereoscopic 3D (S3D) user interfaces (UIs) and present the MirrorBox and the FrameBox, two UI prototyping tools for S3D displays. As auto-stereoscopy becomes available for the mass market we believe the design of S3D UIs for devices, for example, mobile phones, public displays, or car dashboards, will rapidly gain importance. A benefit of such UIs is that they can group and structure information in a way that makes them easily perceivable for the user. For example, important information can be shown in front of less important information. This paper identifies core requirements for designing S3D UIs and derives concrete guidelines. The requirements also serve as a basis for two depth layout tools we built with the aim to overcome limitations of traditional prototyping when sketching S3D UIs. We evaluated the tools with usability experts and compared them to traditional paper prototyping.
2014	MotionMontage: a system to annotate and combine motion takes for 3D animations	We present MotionMontage, a system for recording multiple motion takes of a rigid virtual object and compositing them together into a montage. Our system incorporates a Kinect-based performance capture setup that allows animators to create 3D animations by tracking the motion of a rigid physical object and mapping it in realtime onto a virtual object. The animator then temporally annotates the best parts of each take. MotionMontage merges the annotated motions into a single composite montage using a combination of dynamic time warping and optimization of a Semi-Markov Conditional Random Field. Our system also supports the creation of layered animations in which multiple objects are moving at the same time. To aid the animator in coordinating the motions of the objects we provide spatial markers which indicate the positions of previously recorded objects at user-specified points in time. We perform a user study to evaluate the perceived quality of the montages created with our system and find that viewers (including both the original animators and new viewers) generally prefer the animation montage to any individual take.
2014	Stimulating a blink: reduction of eye fatigue with visual stimulus	Computers make incredible amounts of information available at our fingertips. As computers become integral parts of our lives, we spend more time staring at computer monitor than ever before, sometimes with negative effects. One major concern is the increasing number of people suffering from Computer Vision Syndrome (CVS). CVS is caused by extensive use of computers, and its symptoms include eye fatigue, frequent headaches, dry eyes, and blurred vision. It is possible to partially alleviate CVS if we can remind users to blink more often. We present a prototype system that uses a camera to monitor a user's blink rate, and when the user has not blinked in a while, the system triggers a blink stimulus. We investigated four different types of eye-blink stimulus: screen blurring, screen flashing, border flashing, and pop-up notifications. Users also rated each stimulus type in terms of effectiveness, intrusiveness, and satisfaction. Results from our user studies show that our stimuli are effective in increasing user blink rate with screen blurring being the best.
2014	Smart photo selection: interpret gaze as personal interest	Manually selecting subsets of photos from large collections in order to present them to friends or colleagues or to print them as photo books can be a tedious task. Today, fully automatic approaches are at hand for supporting users. They make use of pixel information extracted from the images, analyze contextual information such as capture time and focal aperture, or use both to determine a proper subset of photos. However, these approaches miss the most important factor in the photo selection process: the user. The goal of our approach is to consider individual interests. By recording and analyzing gaze information from the user's viewing photo collections, we obtain information on user's interests and use this information in the creation of personal photo selections. In a controlled experiment with 33 participants, we show that the selections can be significantly improved over a baseline approach by up to 22% when taking individual viewing behavior into account. We also obtained significantly better results for photos taken at an event participants were involved in compared with photos from another event.
2014	History assisted view authoring for 3D models	3D modelers often wish to showcase their models for sharing or review purposes. This may consist of generating static viewpoints of the model or authoring animated fly-throughs. Manually creating such views is often tedious and few automatic methods are designed to interactively assist the modelers with the view authoring process. We present a view authoring assistance system that supports the creation of informative view points, view paths, and view surfaces, allowing modelers to author the interactive navigation experience of a model. The key concept of our implementation is to analyze the model's workflow history, to infer important regions of the model and representative viewpoints of those areas. An evaluation indicated that the viewpoints generated by our algorithm are comparable to those manually selected by the modeler. In addition, participants of a user study found our system easy to use and effective for authoring viewpoint summaries.
2014	Pupil responses during discrete goal-directed movements	Pupil size is known to correlate with the changes of cognitive task workloads, but how the pupil responds to requirements of basic goal-directed motor tasks involved in human-machine interactions is not yet clear. This work conducted a user study to investigate the pupil dilations during aiming in a tele-operation setting, with the purpose of better understanding how the changes in task requirements are reflected by the changes of pupil size. The task requirements, managed by Fitts' index of difficulty (ID), i.e. the size and distance apart of the targets, were varied between tasks, and pupil responses to different task IDs were recorded. The results showed that pupil diameter can be employed as an indicator of task requirements in goal-directed movements-higher task difficulty evoked higher valley to peak pupil dilation, and the peak pupil dilation occurred after a longer delay. These findings contribute to the foundation for developing methods to objectively evaluate interactive task requirements using pupil parameters during goal-directed movements in HCI.
2014	Collocating interface objects: zooming into maps	May, Dean and Barnard (2003) used a theoretically based model to argue that objects in a wide range of interfaces should be collocated following screen changes such as a zoom-in to detail. Many existing online maps do not follow this principle, but move a clicked point to the centre of the subsequent display, leaving the user looking at an unrelated location. This paper presents three experiments showing that collocating the point clicked on a map so that the detailed location appears in the place previously occupied by the overview location makes the map easier to use, reducing eye movements and interaction duration. We discuss the benefit of basing design principles on theoretical models so that they can be applied to novel situations, and so designers can infer when to use and not use them.
2014	Direct drawing on 3D shapes with automated camera control	We present ACCD, an interaction technique that allows direct drawing of long curves on 3D shapes with a tablet display over both multiple depth layers and multiple viewpoints. ACCD reduces the number of explicit viewpoint manipulations by combining self-occlusion management and automated camera control. As such it enables drawing on occluded faces but also around a 3D shape while keeping a constant drawing precision. Our experimental results indicates the efficacy of ACCD over conventional techniques.
2014	Interactively stylizing camera motion	Movie directors and cinematographers impart style onto video using techniques that are learned through years of experience: camera movement, framing, color, lighting, etc. Without this experience and expensive equipment, it is very difficult to control stylistic aspects of a video. We introduce a novel approach for post-hoc editing of one specific aspect of cinematography -- camera motion style -- via an equalizer-like set of controls that manipulates the power spectra of a video's apparent motion path. We explore free manipulation of apparent camera motion as well as the transfer of motion styles from an example video to a new video to create a wide range of stylistic variations. We report on a user study confirming the ability of non-expert users to create motion styles.
2014	Design considerations for parallel performance tools	In recent years there has been a shift in microprocessor manufacture from building single-core processors towards providing multiple cores on the same chip. This shift has meant that a much wider population of developers are faced with the task of developing parallel software: a difficult, time consuming and expensive process. With the aim of identifying issues, emerging practices and design opportunities for support, we present in this paper a qualitative study in which we interviewed a range of software developers, in both industry and academia. We then perform a systematic analysis of the data and identify several cross-cutting themes. These analysis themes include the practical relevance of the probe effect, the significance of orchestration models in development and the mismatch between currently available tools and developers' needs. We also identify an important characteristic of parallel programming, where the process of optimisation goes hand in hand with the process of debugging, as opposed to clearer distinctions which may be made in traditional programming. We conclude with reflection on how the study can inform the design of software tools to support developers in the endeavour of parallel programming.
2014	Emergent, crowd-scale programming practice in the IDE	While emergent behaviors are uncodified across many domains such as programming and writing, interfaces need explicit rules to support users. We hypothesize that by codifying emergent programming behavior, software engineering interfaces can support a far broader set of developer needs. To explore this idea, we built Codex, a knowledge base that records common practice for the Ruby programming language by indexing over three million lines of popular code. Codex enables new data-driven interfaces for programming systems: statistical linting, identifying code that is unlikely to occur in practice and may constitute a bug; pattern annotation, automatically discovering common programming idioms and annotating them with metadata using expert crowdsourcing; and library generation, constructing a utility package that encapsulates and reflects emergent software practice. We evaluate these applications to find Codex captures a broad swatch of programming practice, statistical linting detects problematic code snippets, and pattern annotation discovers nontrivial idioms such as basic HTTP authentication and database migration templates. Our work suggests that operationalizing practice-driven knowledge in structured domains such as programming can enable a new class of user interfaces.
2014	Designing information savvy societies: an introduction to assessability	This paper provides first steps toward an empirically grounded design vocabulary for assessable design as an HCI response to the global need for better information literacy skills. We present a framework for synthesizing literatures called the Interdisciplinary Literacy Framework and use it to highlight gaps in our understanding of information literacy that HCI as a field is particularly well suited to fill. We report on two studies that lay a foundation for developing guidelines for assessable information system design. The first is a study of Wikipedians', librarians', and laypersons' information assessment practices from which we derive two important features of assessable designs: information provenance and stewardship. The second is an experimental study in which we operationalize these concepts in designs and test them using Amazon Mechanical Turk (MTurk).
2014	Cloudy forecast: an exploration of the factors underlying shared repository use	Many teams are now adopting shared repositories for their work. Such adoption is paradoxical, however, as past research has repeatedly shown major co-organizational barriers ; teams cannot agree a common organizational scheme, making it difficult to retrieve information organized by others. Another barrier is email competition ; email provides a reliable alternative for distributing files that are then personally organized. To address this paradox, we explored how 27 participants actively using shared repositories overcome these barriers in a qualitative study. We found teams addressed co-organization using 4 strategies. First they create ContentMaps that provide explicit structure to organize shared information. Participants also co-organize using implicit strategies based on task structure, expertise , and tool affordances . Greater shared repository use also leads to a changed role for email. Versioning problems mean email is not used for distributing attachments, instead for task management. We present technical implications suggesting how new tools might be better integrated with email facilitating these continued email uses.
2014	Curation through use: understanding the personal value of social media	Content generation on social network sites has been considered mainly from the perspective of individuals interacting with social network contacts. Yet research has also pointed to the potential for social media to become a meaningful personal archive over time. The aim of this paper is to consider how social media, over time and across sites, forms part of the wider digital archiving space for individuals. Our findings, from a qualitative study of 14 social media users, highlight how although some sites are more associated with 'keepable' social media than others, even those are not seen as archives in the usual sense of the word. We show how this perception is bound up with five contradictions, which center on social media as curated, as a reliable repository of meaningful content, as readily encountered and as having the potential to present content as a compelling narrative. We conclude by highlighting opportunities for design relating to curation through use and what this implies for personal digital archives, which are known to present difficulties in terms of curation and re-finding.
2014	Together alone: motivations for live-tweeting a television series	In this paper, we explore motivations for live-tweeting across a season of a television show. Using the third season of Downton Abbey as a case study, we followed 2,234 live-tweeters from the show's premiere episode to its finale, finding that nearly a third of users returned each week to tweet. Semi-structured interviews with 11 diverse live-tweeters revealed that the decision to live-tweet is dependent upon a variety of personal considerations and social conventions forming around this emerging TV viewing practice. This includes the desire to feel connected to a larger community that is interested in the show. Participants actively sought to protect the user experience of others by following good live-tweeting "etiquette", including limiting their number of posts and censoring content that might spoil the show for others. Over time, live-tweeting helped users build and maintain a network of fellow Downton Abbey viewers with shared interests.
2014	Understanding user adaptation strategies for the launching of facebook timeline	This paper applies coping theory to understand user adaptation strategies to major interface changes on Social Networking Sites (SNSs). Specifically, we qualitatively examine 1,149 user comments posted to the Facebook's official Timeline blog in order to get a large and unobtrusive sample of real Facebook users' perceptions about the launch of Timeline. Our data suggests a high level of stress associated with the transition to the new interface introduced by Timeline. We also found evidence which suggests that increasing users' perceptions of control over major interface changes may help facilitate user adaptation to these changes. This study offers valuable insights to SNSs for mitigating user stress and facilitating successful adaptation during major interface changes.
2014	Documentscape: intertextuality, sequentiality, & autonomy at work	On the basis of an ethnographic field study, this article introduces the concept of documentscape to the analysis of document-centric work practices. The concept of documentscape refers to the entire ensemble of documents in their mutual intertextual interlocking. Providing empirical data from a global software development case, we show how hierarchical structures and sequentiality across the interlocked documents are critical to how actors make sense of the work of others and what to do next in a geographically distributed setting. Furthermore, we found that while each document is created as part of a quasi-sequential order, this characteristic does not make the document, as a single entity, into a stable object. Instead, we found that the documents were malleable and dynamic while suspended in intertextual structures. Our concept of documentscape points to how the hierarchical structure, sequentiality, and authorless nature of documents serve as a constitutive platform for the development of iterative and emergent work practices, making it possible for highly distributed actors to collaborate with limited communication, as the documentscape serves as a vehicle of coordination.
2014	Addressing misconceptions about code with always-on programming visualizations	We present Theseus, an IDE extension that visualizes run-time behavior within a JavaScript code editor. By displaying real-time information about how code actually behaves during execution, Theseus proactively addresses misconceptions by drawing attention to similarities and differences between the programmer's idea of what code does and what it actually does. To understand how programmers would respond to this kind of an always-on visualization, we ran a lab study with graduate students, and interviewed 9 professional programmers who were asked to use Theseus in their day-to-day work. We found that users quickly adopted strategies that are unique to always-on, real-time visualizations, and used the additional information to guide their navigation through their code.
2014	Beating the bubble: using kinematic triggering in the bubble lens for acquiring small, dense targets	We present the Bubble Lens, a new target acquisition technique that remedies the limitations of the Bubble Cursor to increase the speed and accuracy of acquiring small, dense targets--precisely those targets for which the Bubble Cursor degenerates to a point cursor. When targets are large and sparse, the Bubble Lens behaves like the Bubble Cursor. But when targets are small and dense, the Bubble Lens automatically magnifies nearby targets, making them larger in both visual- and motor-space. Importantly, magnification is not governed by an explicit user-invoked mode-switch. Rather, magnification is activated through kinematic triggering, a technique that continuously examines an unfolding velocity profile to automatically trigger mode changes based on observed features. In a first study, we found the Bubble Cursor performed poorly when targets had an effective size smaller than 10 pixels. Using this threshold for the Bubble Lens in a second study, we found that the Bubble Lens significantly outperformed the Bubble Cursor, decreasing movement time by 10.2% and error rates by 37.9%, making the Bubble Lens the fastest current pointing technique.
2014	Research through design fiction: narrative in real and imaginary abstracts	This paper reflects on the uses of prototypes in "Research through Design" and considers "Design Fiction" as a technique for exploring the potential value of new design work. It begins with an analysis of Research through Design abstracts in the ACM digital library and identifies an emerging language and structure of papers in this emerging field. The abstracts: frame a problem space, introduce a study, often involving the deployment of a prototype, and conclude with considerations, reflections and discussion. This format is then pastiched in a series of design fictions written for a project investigating new and emerging forms of reproduction in Art. The fictions take the form of "imaginary abstracts" which summarize findings of papers that have not been written about prototypes that do not exist. It is argued that framing concept designs as fictional studies can provide a space for research focused critique and development.
2014	Doing the laundry with agents: a field trial of a future smart energy system in the home	Future energy systems that rely on renewable energy may bring about a radical shift in how we use energy in our homes. We developed and prototyped a future scenario with highly variable, real-time electricity prices due to a grid that mainly relies on renewables. We designed and deployed an agent-based interactive system that enables users to effectively operate the washing machine in this scenario. The system is used to book timeslots of washing machine use so that the agent can help to minimize the cost of a wash by charging a battery at times when electricity is cheap. We carried out a deployment in 10 households in order to uncover the socio-technical challenges around integrating new technologies into everyday routines. The findings reveal tensions that arise when deploying a rationalistic system to manage contingently and socially organized domestic practices. We discuss the trade-offs between utility and convenience inherent in smart grid applications; and illustrate how certain design choices position applications along this spectrum.
2014	Giving up Twitter for Lent: how and why we take breaks from social media	Social media use is widespread, but many people worry about overuse. This paper explores how and why people take breaks from social media. Using a mixed methods approach, we pair data from users who tweeted about giving up Twitter for Lent with an interview study of social media users. We find that 64% of users who proclaim that they are giving up Twitter for Lent successfully do so. Among those who fail, 31% acknowledge their failure; the other 69% simply return. We observe hedging patterns (e.g. "I thought about giving up Twitter for Lent but"?) that surfaced uncertainty about social media behavior. Interview participants were concerned about the tradeoffs of spending time on social media versus doing other things and of spending time on social media rather than in "real life." We discuss gaps in related theory that might help reduce users' anxieties and open design problems related to designing systems and services that can help users manage their own social media use.
2014	Global connectivity and multilinguals in the Twitter network	This article analyzes the global connectivity of the Twitter retweet and mentions network and the role of multilingual users engaging with content in multiple languages. The network is heavily structured by language with most mentions and retweets directed to users writing in the same language. Users writing in multiple languages are more active, authoring more tweets than monolingual users. These multilingual users play an important bridging role in the global connectivity of the network. The mean level of insularity from speakers in each language does not correlate straightforwardly with the size of the user base as predicted by previous research. Finally, the English language does play more of a bridging role than other languages, but the role played collectively by multilingual users across different languages is the largest bridging force in the network.
2014	Overload is overloaded: email in the age of Gmail	The term email overload has two definitions: receiving a large volume of incoming email, and having emails of different status types (to do, to read, etc). Whittaker and Sidner proposed the latter definition in 1996, noticing that email inboxes were far more complex than simply containing incoming messages. Sixteen years after Whittaker and Sidner, we replicate and extend their work with a qualitative analysis of Google's Gmail. We find that email overload, both in terms of volume and of status, is still a problem today. Our contributions are 1) updating the state of email overload, 2) extending our understanding of overload in the context of Gmail and 3) comparing personal with work email accounts: while work email tends to be status overloaded, personal email is also type overloaded. These comparisons between work and personal email suggest new avenues for email research.
2014	Effects of public vs. private automated transcripts on multiparty communication between native and non-native english speakers	Real-time transcripts generated by automated speech recognition (ASR) technologies have the potential to facilitate communication between native speakers (NS) and non-native speakers (NNS). Previous studies of ASR have focused on how transcripts aid NNS speech comprehension. In this study, we examine whether transcripts benefit multiparty real-time conversation between NS and NNS. We hypothesized that ASR transcripts would be more beneficial when the transcripts were publicly shared by all group members as opposed to when they were seen only by the NNS. To test our hypothesis, we conducted a lab experiment in which 14 groups of native and non-native speakers engaged in a story-telling task. Half of the groups received private transcripts that were available only to the NNS; the other half received publicly shared transcripts that were available to all group members. NS spoke more clearly, and both NS and NNS rated the quality of communication higher, when transcripts were publicly shared. These findings inform the design of future tools to support multilingual group communication.
2014	MinEMail: SMS alert system for managing critical emails	Email is the primary method of digital communication for most people, but the overwhelming quantity has led to a poverty of attention. Existing manual and automatic solutions that aim to save important emails from falling through the cracks have begun to address this problem, but may increase user workload, sacrifice efficiency, or fail to identify high value communications. In response, we developed MinEMail, an alert system that uses a text message (SMS) to remind and notify users of critical emails that may have been missed or forgotten. MinEMail provides an alert infrastructure as well as accurately labeling and predicting which emails are critical, and when and how they need to be addressed. To motivate our system, we also present an up-front study with 777 participants that aims to understand the state and limitations of email and SMS in enterprise. We conduct an experience sampling study of over 3000 emails in order to construct MinEMail's predictive models. Finally, we present the results from a 15 user ecologically valid real-world deployment of MinEMail in enterprise.
2014	Practical trigger-action programming in the smart home	We investigate the practicality of letting average users customize smart-home devices using trigger-action ("if, then") programming. We find trigger-action programming can express most desired behaviors submitted by participants in an online study. We identify a class of triggers requiring machine learning that has received little attention. We evaluate the uniqueness of the 67,169 trigger-action programs shared on IFTTT.com, finding that real users have written a large number of unique trigger-action interactions. Finally, we conduct a 226-participant usability test of trigger-action programming, finding that inexperienced users can quickly learn to create programs containing multiple triggers or actions.
2014	Making sustainability sustainable: challenges in the design of eco-interaction technologies	The smart home is here. One area where smart home devices promise to deliver great benefits is in the control of home heating, ventilation, and cooling (HVAC) systems. In this paper, we seek to inform the design of future heating and cooling systems by investigating users' experiences with the Nest Learning Thermostat, a commercially available smart home device. We conducted a qualitative study where we compared people's interactions with conventional thermostats with interactions with the Nest. A key finding was that the Nest impacted users' pattern of HVAC control, but only for a while, and caused new problems in unrealized energy savings. In leveraging these findings, we create a set of design implications for Eco-Interaction, the design of features and human-system interactions with the goal of saving energy.
2014	WaaZam!: supporting creative play at a distance in customized video environments	We present the design, and evaluation of WaaZam, a video mediated communication system designed to support creative play in customized environments. Users can interact together in virtual environments composed of digital assets layered in 3D space. The goal of the project is to support creative play and increase social engagement during video sessions of geographically separated families. We try to understand the value of customization for individual families with children ages 6-12. We present interviews with creativity experts, a pilot study and a formal evaluation of families playing together in four conditions: separate windows, merged windows, digital play sets, and customized digital environments. We found that playing in the same video space enables new activities and increases social engagement for families. Customization allows families to modify scenes for their needs and support more creative play activities that embody the imagination of the child.
2014	LACES: live authoring through compositing and editing of streaming video	Video authoring activity typically consists of three phases: planning (pre-production), capture (production) and processing (post-production). The status quo is that these phases occur separately, and the latter two have a significant amount of "slack time", where the camera operator is watching the scene unfold during capture, and the editor is re-watching and navigating through recorded footage during post-production. While this process is well suited to creating polished or professional video, video clips produced by casual video makers as seen in online forums could benefit from some editing without the overhead of current authoring tools. We introduce LACES, a tablet-based system enabling simple video manipulations in the midst of filming. Seamless in-situ integration of video capture and manipulation forms a novel workflow, allowing greater spontaneity and exploration of video creation.
2014	Visualization of personal history for video navigation	We present an investigation of two different visualizations of video history: Video Timeline and Video Tiles. Video Timeline extends the commonly employed list-based visualization for navigation history by applying size to indicate heuristics and occupying the full screen with a two-sided timeline. Video Tiles visualizes history items in a grid-based layout by following pre-defined templates based on items' heuristics and ordering, utilizing screen space more effectively at the expense of a clearer temporal location. The visualizations are compared against the state-of-the-art method (a filmstrip-based visualization), with ten participants tasked with sharing their previously-seen affective intervals. Our study shows that our visualizations are perceived as intuitive and both outperform and are strongly preferred to the current method. Based on these results, Video Timeline and Video Tiles provide an effective addition to video viewers to help manage the growing quantity of video. They provide users with insight into their navigation patterns, allowing them to quickly find previously-seen intervals, leading to efficient clip sharing, simpler authoring and video summarization.
2014	Towards an holistic view of the energy and environmental impacts of domestic media and IT	To date, research in sustainable HCI has dealt with eco-feedback, usage and recycling of appliances within the home, and longevity of portable electronics such as mobile phones. However, there seems to be less awareness of the energy and greenhouse emissions impacts of domestic consumer electronics and information technology. Such awareness is needed to inform HCI sustainability researchers on how best to prioritise efforts around digital media and IT. Grounded in inventories, interview and plug energy data from 33 undergraduate student participants, our findings provide the context for assessing approaches to reducing the energy and carbon emissions of media and IT in the home. In the paper, we use the findings to discuss and inform more fruitful directions that sustainable HCI research might take, and we quantify how various strategies might have modified the energy and emissions impacts for our participants.
2014	Searching for analogical ideas with crowds	Seeking solutions from one domain to solve problems in another is an effective process of innovation. This process of analogy searching is difficult for both humans and machines. In this paper, we present a novel approach for re-presenting a problem in terms of its abstract structure, and then allowing people to use this structural representation to find analogies. We propose a crowdsourcing process that helps people navigate a large dataset to find analogies. Through two experiments, we show the benefits of using abstract structural representations to search for ideas that are analogous to a source problem, and that these analogies result in better solutions than alternative approaches. This work provides a useful method for finding analogies, and can streamline innovation for both novices and professional designers.
2014	Beyond ethnography: engagement and reciprocity as foundations for design research out here	This paper explores an emerging paradigm for HCI design research based primarily upon engagement, reciprocity and doing. Much HCI research begins with an investigatory and analytic ethnographic approach before translating to design. Design may come much later in the process and may never benefit the community that is researched. However in many settings it is difficult for researchers to access the privileged ethnographer position of observer and investigator. Moreover rapid ethnographic research often does not seem the best or most appropriate course of action. We draw upon a project working with a remote Australian Aboriginal community to illustrate an alternative approach in Indigenous research, where the notion of reciprocity is first and foremost. We argue that this can lead to sustainable designs, valid research and profound innovation.
2014	Personal tracking as lived informatics	This paper characterises the use of activity trackers as "lived informatics". This characterisation is contrasted with other discussions of personal informatics and the quantified self. The paper reports an interview study with activity tracker users. The study found: people do not logically organise, but interweave various activity trackers, sometimes with ostensibly the same functionality; that tracking is often social and collaborative rather than personal; that there are different styles of tracking, including goal driven tracking and documentary tracking; and that tracking information is often used and interpreted with reference to daily or short term goals and decision making. We suggest there will be difficulties in personal informatics if we ignore the way that personal tracking is enmeshed with everyday life and people's outlook on their future.
2014	ThumbReels: query sensitive web video previews based on temporal, crowdsourced, semantic tagging	During online search, the user's expectations often differ from those of the author. This is known as the "intention gap" and is particularly problematic when searching for and discriminating between online video content. An author uses description and meta-data tags to label their content, but often cannot predict alternate interpretations or appropriations of their work. To address this intention gap, we present ThumbReels, a concept for query-sensitive video previews generated from crowdsourced, temporally defined semantic tagging. Further, we supply an open-source tool that supports on-the-fly temporal tagging of videos, whose output can be used for later search queries. A first user study validates the tool and concept. We then present a second study that shows participants found ThumbReels to better represent search terms than contemporary preview techniques.
2014	Panopticon as an eLearning support search tool	We present an evaluation of Panopticon, a video surrogate system, as an online eLearning support search tool for finding information within video lectures. A comparison was made with a standard video player (YouTube) in two scenarios with two classes of users: revision students and independent learners. Results showed that users of Panopticon were significantly faster at finding information within the lecture videos than users of the YouTube player. It was also found that videos predominantly featuring a talking lecturer took longest to navigate, presenting design implications for lectures to be uploaded to open eLearning platforms.
2014	Odin: contextual document opinions on the go	Information overload is a systemic problem for knowledge workers in enterprise. For a long time, information was scarce and therefore valuable. While, the explosion of digital information has made information plentiful, time to read and process that content is now scarce. This problem is only exacerbated by our increased mobility, and the expectation to be "on top" of the continuous barrage of documents while on the go. Knowledge workers in enterprise need solutions that are designed with quick methods for finding what to read in a large collection of documents (e.g. financial reports, legal documents, news), and ways of presenting it within small visual real estate. Unlike reviews, document collections are long, more varied, and context is extremely important. In response, we present Odin, a mobile web-based window onto a user's document corpus. Rather than performing corpus summarization, Odin users can quickly find opinions and documents that are Aligned or Divergent from the corpus' consensus, or those that are the most Relevant given the overall corpus' of opinions. Odin presents this information through a simple and intuitive mobile interface. To the authors' knowledge, this is the first UI/system (and support algorithm) to allow mobile users to place documents and their opinions in context through alignment rather than raw word count or sentiment. Positive results from two evaluations are also presented.
2014	Help beacons: design and evaluation of an ad-hoc lightweight s.o.s. system for smartphones	We present the design and evaluation of a lightweight mobile S.O.S. system that facilitates ad-hoc communication between first responders and victims in emergency situations. Our approach leverages established protocols and standards in unforeseen ways to provide a platform supporting the creation of short-lived communication links. The system comprises two mobile applications: one victim application that allows the broadcasting of distress signals by a novel use of Wi-Fi SSIDs; and a responder application that allows first responders to discover and trace the people broadcasting the signals. The main difference of our system with other platforms enabling communication in crisis situations is that our system is independent from existing network infrastructure and runs on off-the-shelf, commercially available smartphones. We describe the results of our evaluation process in the context of both a design evaluation during a real-world emergency response exercise and of two user workshops in preparation for an upcoming large-scale exercise.
2014	Upvoting hurricane Sandy: event-based news production processes on a social news site	This paper uses the case of Hurricane Sandy and reddit's topical community (subreddit) /r/sandy to examine the production and curation of news content around events on a social news site. Through qualitative analysis, we provide a coded topology of produced content and describe how types of networked gatekeeping impact the framing of a crisis situation. This study also examines, through quantitative modeling, what kind of information becomes negotiated and voted as relevant. We suggest that highly scored content shared in a social news setting focused more on human-interest media and perspective-based citizen journalism than professional news reports. We conclude by discussing how the mechanisms of social news sites conflict with the social norms and culture of reddit to produce differing expectations around news.
2014	Photographing information needs: the role of photos in experience sampling method-style research	The Experience Sampling Method (ESM) enables researchers to capture information about participants' experiences in the moment. Adding an end-of-day retrospective survey also allows participants to elaborate on those experiences. Although the use of photos in retrospective interviews and surveys for memory elicitation is well known, little research has investigated the use of photos in ESM studies. As smartphone adoption increases facilitating ESM studies and making photo sharing easier, researchers need to continuously evaluate the method and investigate the role of photos in such studies. We conducted a large-scale ESM and retrospective survey study via Android smartphones with more than 1,000 US participants, and analyzed participants' photo submissions, including how photo use correlated with participants' data quality and what, if any, value photos added for researchers. Our study sheds light on the role of photos in ESM and retrospective studies that researchers can reference when constructing future study designs.
2014	Monadic exploration: seeing the whole through its parts	Monadic exploration is a new approach to interacting with relational information spaces that challenges the distinction between the whole and its parts. Building on the work of sociologists Gabriel Tarde and Bruno Latour we turn to the concept of the monad as a useful lens on online communities and collections that expands the possibility for creating meaning in their navigation. While existing interfaces tend to emphasize either the structure of the whole or details of a part, monadic exploration brings these opposing perspectives closer together in continuous movements between partially overlapping points of view. We present a visualization that reflects a given node's relative position within a network using radial displacements and visual folding. To investigate the potential of monadic exploration we report on an iterative design process of a web-based visualization of a highly cross-referenced book and its six-month deployment.
2014	Online public communications by police & fire services during the 2012 Hurricane Sandy	Social media and other online communication tools are a subject of great interest in mass emergency response. Members of the public are turning to these solutions to seek and offer emergency information. Emergency responders are working to determine what social media policies should be in terms of their "public information" functions. We report on the online communications from all the coastal fire and police departments within a 100 mile radius of Hurricane Sandy's US landfall. Across four types of online communication media, we collected data from 840 fire and police departments. Findings indicate that few departments used these online channels in their Sandy response efforts, and that communications differed between fire and police departments and across media type. However, among the highly engaged departments, there is evidence that they bend and adapt policies about what constitutes appropriate public communication in the face of emergency demands; therefore, we propose that flexibility is important in considering future emergency online communication policy. We conclude with design recommendations for making online communication media more "listenable" for both emergency managers and members of the public.
2014	EmergencyMessenger: a text based communication concept for indoor firefighting	Finding and rescuing missing or injured people or fighting fire inside burning buildings is a central challenge for fire brigades. To ensure the safety of indoor work, monitoring the operations of firefighting units is crucial. As in most countries, firefighters in Germany utilize radio sets to establish voice communication between indoor operating units and the supervisory structure outside. Based on findings from a long term ethnographic study in cooperation with different German fire brigades over a time span of more than 5 years we analyzed the advantages and disadvantages of the current voice over radio communication tactics and techniques. We designed and evaluated a complementary text based communication device the EMERGENCY-MESSENGER to support the time critical work of indoor units working under harsh conditions, wearing Self-Contained-Breathing-Apparatus (SCBA). We conducted 13 full scale training missions including extensive debriefings to design and evaluate the communication concept and the corresponding device.
2014	The role of interactive biclusters in sensemaking	Visual exploration of relationships within large, textual datasets is an important aid for human sensemaking. By understanding computed, structural relationships between entities of different types (e.g., people and locations), users can leverage domain expertise and intuition to determine the importance and relevance of these relationships for tasks, such as intelligence analysis. Biclusters are a potentially desirable method to facilitate this, because they reveal coordinated relationships that can represent meaningful relationships. Bixplorer, a visual analytics prototype, supports interactive exploration of textual datasets in a spatial workspace with biclusters. In this paper, we present results of a study that analyzes how users interact with biclusters to solve an intelligence analysis problem using Bixplorer. We found that biclusters played four principal roles in the analytical process: an effective starting point for analysis, a revealer of two levels of connections, an indicator of potentially important entities, and a useful label for clusters of organized information.
2014	Design insights for the next wave ontology authoring tools	Ontologies have been employed across scientific and business domains for some time, and the proliferation of linked data means the number and range of potential authors is set to increase significantly. Ontologies using the Web Ontology Language (OWL) are complex artefacts, however: the authoring process requires not only knowledge of the application domain, but also skills in programming and logics. To date, there has been no systematic attempt to understand the effectiveness of existing tools, or explore what users really require to build successful ontologies. Here we address this shortfall, presenting insights from an interview study with 15 ontology authors. We identify the problems reported by authors, and the strategies they employ to solve them. We map the data to a set of design recommendations, which describe how tools of the future can support ontology authoring. A key challenge is dealing with information overload: improving the user's ability to navigate, populate and debug large ontologies will revolutionise the engineering process, and open ontology authoring up to a new generation of users.
2014	The dept. of hidden stories: playful digital storytelling for children in a public library	We detail the design of the Dept. of Hidden Stories (DoHS), a mobile-based game to support playful digital storytelling among primary school children in public libraries. Through a process of iterative design in collaboration with library staff and children's writers we designed DoHS to support the potential for playful storytelling through interactions with books. A deployment of DoHS with two classes of 8 to 10 years olds as part of their regular library visits revealed insights related to how to balance the expectations of a child-at-play and the requirement to further develop their creative reading and writing skills. Based on our experiences we recommend that designers create playful digitally based activities that encourage children to explore libraries and experience new interactions with physical books.
2014	Social dependency and mobile autonomy: supporting older adults' mobility with ridesharing ict	Alternative mobility modes for older adults are increasingly important for economic, ecological and social reasons. A promising option is ridesharing, defined as use of the same vehicle by two or more people traveling to a common destination. In particular, mobile computer supported ridesharing provides a promising way to enlarge older adults' mobility choices in addition to private driving and public transportation options. In order to understand the opportunities and obstacles of ridesharing from the point of view of elderly people, we conducted an interview study in order to examining ridesharing experiences. It turns out that "mobile independence" and "decisional autonomy" are key issues for mobile wellbeing. This partially conflicts with common ridesharing concepts. Hence, we further analyze older adults' strategies dealing with these conflicts and show that these strategies offer departure points for the design ridesharing solutions, which are better suited to the demands of older adults.
2014	Interface design for older adults with varying cultural attitudes toward uncertainty	This work reports on the design and evaluation of culturally appropriate technology for older adults. Our design context was Cognitive Testing on a Computer (C-TOC): a self-administered computerized test under development, intended to screen older adults for cognitive impairments. Using theory triangulation of cultural attitudes toward uncertainty, we designed two interfaces (one minimal and one rich) for one C-TOC subtest and hypothesized they would be culturally appropriate for older adult Caucasians and East Asians respectively. We ran an experiment with 36 participants to investigate cultural differences in performance, preference and anxiety. We found that Caucasians preferred the interface with minimal elements (i.e. those essential for the primary task) or had no preference. By contrast, East Asians preferred the rich interface augmented with security and learning support and felt less anxious with it than the minimal.
2014	Invisible connections: investigating older people's emotions and social relations around objects	The advent of the Internet of Things creates an interest in how people might interrelate through and with networks of internet enabled objects. With an emphasis on fostering social connection and physical activity among older people, this preliminary study investigated objects that people over the age of 65 years viewed as significant to them. We conducted contextual interviews in people's homes about their significant objects in order to understand the role of the objects in their lives, the extent to which they fostered emotional and social connections and physical activity, and how they might be augmented through internet connection. Discussion of significant objects generated considerable emotion in the participants. We identified objects of comfort and routine, objects that exhibited status, those that fostered independence and connection, and those that symbolized relationships with loved ones. These findings lead us to consider implications for the design of interconnected objects.
2014	Visualizing interactive narratives: employing a branching comic to tell a story and show its readings	This paper describes the design and evaluation of a branching comic to compare how readers recall a visual narrative when presented as an interactive, digital program, or as a linear sequence on paper. The layout of the comic is used to visualize this data as heat maps and explore patterns of users' recollections. We describe the theoretical justification for this based upon previous work in narrative visualizations, interactive stories and comics. Having tested the comic with school boys aged 11-12; we saw patterns in the data that complement other research in both interactive stories and visualizations. We argue that the heat maps helped identify these patterns, which have implications for future designs and analyses of interactive visual and/or narrative media.
2014	Always somewhere, never there: using critical design to understand database interactions	Structured databases achieve effective searching and sorting by enacting sharply delineated category boundaries around their contents. While this enables precise retrieval, it also distorts identities that exist between category lines. A choice between Single and Married, for example, blurs distinctions within the Single group: single, perhaps, merely because same-sex marriage is not legal in one's locality. Sociologists Susan Leigh Star and Geoffrey Bowker describe such residual states as inevitable byproducts of information systems. To minimize residuality, traditional practice for descriptive metadata seeks to demarcate clear and objective classes. In this study, we use critical design to question this position by creating information collections that foreground the residual, instead of diminishing it. We then interrogate our design experiments with solicited critical responses from invited experts and student designers. Inspired by the anthropologist Tim Ingold, we argue that our experiments illuminate a form of interacting with databases characterized by notions of wayfaring, or inhabiting a space, as opposed to notions of transport, or reaching a known destination. We suggest that the form of coherence that shapes a wayfaring database is enacted through its flow, or fluid integration between structure and content.
2014	FOCUS: enhancing children's engagement in reading by using contextual BCI training sessions	Reading is an important aspect of a child's development. Reading outcome is heavily dependent on the level of engagement while reading. In this paper, we present FOCUS, an EEG-augmented reading system which monitors a child's engagement level in real time, and provides contextual BCI training sessions to improve a child's reading engagement. A laboratory experiment was conducted to assess the validity of the system. Results showed that FOCUS could significantly improve engagement in terms of both EEG-based measurement and teachers' subjective measure on the reading outcome.
2014	From checking on to checking in: designing for low socio-economic status older adults	In this paper we describe the design evolution of a novel technology that collects and displays presence information to be used in the homes of older adults. The first two iterations, the Ambient Plant and Presence Clock, were designed for higher socio-economic status (SES) older adults, whereas the Check-In Tree was designed for low SES older adults. We describe how feedback from older adult participants drove our design decisions, and give an in-depth account of how the Check-In Tree evolved from concept to a final design ready for in situ deployment.
2014	Sensing a live audience	Psychophysiological measurement has the potential to play an important role in audience research. Currently, such research is still in its infancy and it usually involves collecting data in the laboratory, where during each experimental session one individual watches a video recording of a performance. We extend the experimental paradigm by simultaneously measuring Galvanic Skin Response (GSR) of a group of participants during a live performance. GSR data were synchronized with video footage of performers and audience. In conjunction with questionnaire data, this enabled us to identify a strongly correlated main group of participants, describe the nature of their theatre experience and map out a minute-by-minute unfolding of the performance in terms of psycho-physiological engagement. The benefits of our approach are twofold. It provides a robust and accurate mechanism for assessing a performance. Moreover, our infrastructure can enable, in the future, real-time feedback from remote audiences for online performances.
2014	Don't forget your pill!: designing effective medication reminder apps that support users' daily routines	Despite the fact that a third of all cases of unintentional medication non-adherence are caused by simple forgetfulness, the majority of interventions neglect this issue. Even though patients have access to smartphone applications ("apps") designed to help them remember medication, neither their quality nor effectiveness has been evaluated yet. We report the findings of a functionality review of 229 medication reminder apps and a thematic analysis of their 1,012 user reviews. Our research highlights the gap between the theory and practice: while the literature shows that many medication regimens are habitual in nature and the presence of daily routines supports remembering, existing apps rely on timer-based reminders. To address this disparity, we present design requirements for building medication reminders that support the routine aspect of medication-taking and its individual nature, and demonstrate how they could be implemented to move from passive alerts to a smarter memory and routine assistant.
2014	Uncertain text entry on mobile devices	Users often struggle to enter text accurately on touchscreen keyboards. To address this, we present a flexible decoder for touchscreen text entry that combines probabilistic touch models with a language model. We investigate two different touch models. The first touch model is based on a Gaussian Process regression approach and implicitly models the inherent uncertainty of the touching process. The second touch model allows users to explicitly control the uncertainty via touch pressure. Using the first model we show that the character error rate can be reduced by up to 7% over a baseline method, and by up to 1.3% over a leading commercial keyboard. Using the second model we demonstrate that providing users with control over input certainty reduces the amount of text users have to correct manually and increases the text entry rate.
2014	Both complete and correct?: multi-objective optimization of touchscreen keyboard	Correcting erroneous input (i.e., correction) and completing a word based on partial input (i.e., completion) are two important "smart" capabilities of a modern intelligent touchscreen keyboard. However little is known whether these two capabilities are conflicting or compatible with each other in the keyboard parameter tuning. Applying computational optimization methods, this work explores the optimality issues related to them. The work demonstrates that it is possible to simultaneously optimize a keyboard algorithm for both correction and completion. The keyboard simultaneously optimized for both introduces no compromise to correction and only a slight compromise to completion when compared to the keyboards exclusively optimized for one objective. Our research also demonstrates the effectiveness of the proposed optimization method in keyboard algorithm design, which is based on the Pareto multi-objective optimization and the Metropolis algorithm. For the development and test datasets used in our experiments, computational optimization improved the correction accuracy rate by 8.3% and completion power by 17.7%.
2014	@BabySteps: design and evaluation of a system for using twitter for tracking children's developmental milestones	The tracking of developmental milestones in young children is an important public health goal for ensuring early detection and treatment for developmental delay. While numerous paper-based and web-based solutions are available for tracking milestones, many busy parents often forget to enter information on a regular basis. To help address this need, we have developed an interactive system called @BabySteps for allowing parents who use Twitter to track and respond to tweets about developmental milestones using a special hashtag syntax. Parent responses are parsed automatically and written into a central database that can be accessed via the web. We deployed @BabySteps with 14 parents over a 3-week period and found that parents were able to learn how to use the system to track their children's progress, with some using it to communicate with other parents. The study helped to identify a number of ways to improve the approach, including simplifying the hashtag syntax, allowing for private responses via direct messaging, and improving the social component. We provide a discussion of lessons learned and suggestions for the design of interactive public health systems.
2014	Hooked on smartphones: an exploratory study on smartphone overuse among college students	The negative aspects of smartphone overuse on young adults, such as sleep deprivation and attention deficits, are being increasingly recognized recently. This emerging issue motivated us to analyze the usage patterns related to smartphone overuse. We investigate smartphone usage for 95 college students using surveys, logged data, and interviews. We first divide the participants into risk and non-risk groups based on self-reported rating scale for smartphone overuse. We then analyze the usage data to identify between-group usage differences, which ranged from the overall usage patterns to app-specific usage patterns. Compared with the non-risk group, our results show that the risk group has longer usage time per day and different diurnal usage patterns. Also, the risk group users are more susceptible to push notifications, and tend to consume more online content. We characterize the overall relationship between usage features and smartphone overuse using analytic modeling and provide detailed illustrations of problematic usage behaviors based on interview data.
2014	Real-time feedback for improving medication taking	Medication taking is a self-regulatory process that requires individuals to self-monitor their medication taking behaviors, but this can be difficult because medication taking is such a mundane, unremarkable behavior. Ubiquitous sensing systems have the potential to sense everyday behaviors and provide the objective feedback necessary for self-regulation of medication taking. We describe an unobtrusive sensing system consisting of a sensor-augmented pillbox and an ambient display that provides near real-time visual feedback about how well medications are being taken. In contrast to other systems that focus on reminding before medication taking, our approach uses feedback after medication taking to allow the individual to develop their own routines through self-regulation. We evaluated this system in the homes of older adults in a 10-month deployment. Feedback helped improve the consistency of medication-taking behaviors as well as increased ratings of self-efficacy. However, the improved performance did not persist after the feedback display was removed, because individuals had integrated the feedback display into their routines to support their self-awareness, identify mistakes, guide the timing of medication taking, and provide a sense of security that they are taking their medications well. Finally, we reflect on design considerations for feedback systems to support the process of self-regulation of everyday behaviors.
2014	Mobile attachment causes and consequences for emotional bonding with mobile phones	This paper addresses the phenomenon of emotional attachments to mobile phones. We introduce the term "mobile attachment" and define it as a bond between a person's self and a mobile phone that varies in strength. Based on a critical reflection of interdisciplinary literature, a conceptual mobile attachment model is developed. Within this model causes, consequences and influencing factors of mobile attachment are exposed and elaborated. We argue that mobile attachment emerges when the mobile phone becomes part of the user's self concept. The link between the user and their mobile phone may be fostered when it empowers, enriches, or gratifies the user's self. Attachment causes lead to "design space determinants" that enable user experience designers to design for mobile attachment. Attachment consequences may be operationalized for user experience evaluation.
2014	The influence of emotion on number entry errors	Given the proliferation of devices like infusion pumps in hospitals, number entry and in particular number entry error is an emerging important concern in HCI. There are clearly design features that could greatly improve accuracy in entering numbers but the context of the task could also play an important role. In particular, the emotional state of a person is known to strongly influence their response to a difficult situation and hence the errors that they make. In this paper, we consider the impact of the emotional state of the user on the accuracy with which people enter numbers. Our experiment shows that participants who are in a more positive emotional state are more accurate. The effect is small but could be very important when considering the potentially highly-charged emotional contexts where many healthcare devices are used.
2014	DoDo game, a color vision deficiency screening test for young children	This paper presents 'DoDo's Catching Adventure,' a new color vision deficient screening test for young children. Early detection of color blindness among children is useful for parents and teachers to better understand children's needs, to overcome difficulties in learning, and for life and career planning. Unfortunately, current color screening tests are not designed for young children; most require more advanced verbal or cognitive skills. DoDo game has taken a new approach by embedding game elements into a color vision screening test. A user study conducted at Singapore National Eye Centre on twenty-eight children, identified fourteen as Red-Green deficient subjects as did by Ishihara screening test, showed that DoDo was adequately effective in identifying Red-Green color vision deficiency and comparable to two current gold standard colorblind tests, Ishihara and D15.
2014	Show me the money!: an analysis of project updates during crowdfunding campaigns	Hundreds of thousands of crowdfunding campaigns have been launched, but more than half of them have failed. To better understand the factors affecting campaign outcomes, this paper targets the content and usage patterns of project updates -- communications intended to keep potential funders aware of a campaign's progress. We analyzed the content and usage patterns of a large corpus of project updates on Kickstarter, one of the largest crowdfunding platforms. Using semantic analysis techniques, we derived a taxonomy of the types of project updates created during campaigns, and found discrepancies between the design intent of a project update and the various uses in practice (e.g. social promotion). The analysis also showed that specific uses of updates had stronger associations with campaign success than the project's description. Design implications were formulated from the results to help designers better support various uses of updates in crowdfunding campaigns.
2014	Taking part: role-play in the design of therapeutic systems	Gaining an understanding of user needs is a central component of HCI design approaches such as user-centred design and participatory design. In some settings, such as mental health care, access to end-users is often constrained. This is a particular difficulty given that the experience of those with mental illness can be difficult for researchers to understand, and is further complicated by its associated stigma. In addition, the therapeutic setting is outside the common experience of most people and protected from outside intrusion. Although role-play has been used in varied ways in HCI, rarely has it been defined with sufficient clarity to enable others to deploy it in a nuanced manner. We argue that role-play is particularly suited for use in mental healthcare settings and, when used judiciously, can address some of the difficulties associated with working in this setting. This paper details a range of role-play formats appropriated from therapeutic role-play, drawing upon the HCI and mental health literature, therapist input and our experience of using role-play for a number of purposes at different stages of the development process. We consider how and why role-play can be used to generate empathy, gain understanding of therapy, provide feedback on designs before clinical use and help train therapists in using technology in the treatment room.
2014	Dive in!: enabling progressive loading for real-time navigation of data visualizations	We introduce Splash, a framework reducing development overhead for both data curators and visualization developers of client-server visualization systems. Splash streamlines the process of creating a multiple level-of-detail version of the data and facilitates progressive data download, thereby enabling real-time, on-demand navigation with existing visualization toolkits. As a result, system responsiveness is increased and the user experience is improved. We demonstrate the benefit of progressive loading for user interaction on slower networks. Additionally, case study evaluations of Splash with real-world data curators suggest that Splash supports iterative refinement of visualizations and promotes the use of exploratory data analysis.
2014	Simplifying orientation measurement for mobile audio augmented reality applications	Audio augmented reality systems overlay the physical world with a virtual audio space. Today's smartphones provide enough processing power to create the impression of virtual sound sources being located in the real world. To achieve this, information about the user's location and orientation is necessary which requires additional hardware. In a real-world installation, however, we observed that instead of turning their head to localize sounds, users tend to turn their entire body. Therefore, we suggest to simply measure orientation of the user's body - or even just the mobile device she is holding - to generate the spatial audio. To verify this approach, we present two studies: Our first study in examines the user's head, body, and mobile device orientation when moving through an audio augmented reality system in a lab setting. Our second study analyzes the user experience in a real-world installation when using head, body, or device orientation to control the audio spatialization. We found that when navigating close to sound sources head tracking is necessary, but that it can potentially be replaced by device tracking in larger or more explorative usage scenarios. These findings help reduce the technical complexity of mobile audio augmented reality systems (MAARS), and enable their wider dissemination as mobile software-only apps.
2014	Task-driven evaluation of aggregation in time series visualization	Many visualization tasks require the viewer to make judgments about aggregate properties of data. Recent work has shown that viewers can perform such tasks effectively, for example to efficiently compare the maximums or means over ranges of data. However, this work also shows that such effectiveness depends on the designs of the displays. In this paper, we explore this relationship between aggregation task and visualization design to provide guidance on matching tasks with designs. We combine prior results from perceptual science and graphical perception to suggest a set of design variables that influence performance on various aggregate comparison tasks. We describe how choices in these variables can lead to designs that are matched to particular tasks. We use these variables to assess a set of eight different designs, predicting how they will support a set of six aggregate time series comparison tasks. A crowd-sourced evaluation confirms these predictions. These results not only provide evidence for how the specific visualizations support various tasks, but also suggest using the identified design variables as a tool for designing visualizations well suited for various types of tasks.
2014	Walk this way: musically guided walking experiences	Musical soundtracks will be important features of future locative experiences from tours to games. We present a study designed to uncover potential relationships between higher-level musical structures such as harmony, melody, timbre, dynamic intensity and punctuation and users' spatial experiences. We observed twenty-two participants exploring an open field while listening to four contrasting musical compositions, and then interviewed them afterwards. We report their different approaches to interpreting the music, strategies for mapping zones, choice of stopping destinations, and their awareness and appreciation of the music. Our discussion of these findings in relation to the literature leads us to propose six initial principles to guide the composition of mobile and locative soundtracks, and also to articulate a three-layer framework of global, regional and local attachment to help guide the attachment of musical features to different regions within a locative experience.
2014	My journey compass: a preliminary investigation of a mobile tool for cancer patients	Health information management for cancer care is a challenging and personal process that changes over time based on one's needs, goals, and health status. While technologies supporting health information management appear promising, we do not fully understand how health information tools fit into patients? daily lives. To better understand the opportunities and usage barriers of these tools, we designed and deployed a mobile, tablet-based health management aid: My Journey Compass. After one month of use, we interviewed twelve breast cancer patients to investigate their initial patterns of adoption, adaptation, use and non-use. We found that developing a tool that was customizable, mobile, and integrated into the patients' healthcare system resulted in a set of surprising uses by breast cancer patients for a wide variety of tasks. Our study demonstrates the potential for health management tools to improve the cancer care experience and for HCI research to influence existing healthcare systems.
2014	Visual recognition in museum guide apps: do visitors want it?	In this paper, visual recognition (VisRec) is evaluated as a method to access background information on artworks in mobile museum guide applications (apps) by means of a field experiment. While museums and previous research have explored technical aspects, it is unclear whether visitors actually want to use VisRec. A prototype featuring VisRec, QR codes and number codes was developed and assessed with a usability study in two museums (N=89). The prototype confirms the efficacy of the recently introduced ORB-algorithm for VisRec. Compared to previous literature, the results highlight the context-dependency of perceived usability and variability in the importance of usability factors. The results reveal a clear preference for VisRec among participants (53%); only 14% preferred QR codes. Ease of use, enjoyability and distance are identified as the main factors. This provides strong evidence to further explore the potential of VisRec to improve visitors' museum experiences.
2014	A billion signposts: repurposing barcodes for indoor navigation	Barcodes are all around us--on books, groceries and other products--but these everyday markers are typically used for a single focused purpose. In this paper we explore the concept of "piggybacking" on ubiquitous markers to facilitate indoor navigation. Our initial probe--BookMark--allows library visitors to scan any nearby book to provide a custom map to the location of a desired item. In contrast to previous indoor navigation systems, our approach repurposes existing markers on physical items that are already in the navigation space, meaning that no additional infrastructure is required. We evaluated the BookMark probe in a large university library, showing its potential with real library users. In addition, we illustrate how the general technique shows further potential in other similar barcode-rich environments.
2014	Crowd storage: storing information on existing memories	This paper introduces the concept of crowd storage , the idea that digital files can be stored and retrieved later from the memories of people in the crowd. Similar to human memory, crowd storage is ephemeral, which means that storage is temporary and the quality of the stored information degrades over time. Crowd storage may be preferred over storing information directly in the cloud, or when it is desirable for information to degrade inline with normal human memories. To explore and validate this idea, we created WeStore , a system that stores and then later retrieves digital files in the existing memories of crowd workers. WeStore does not store information directly, but rather encrypts the files using details of the existing memories elicited from individuals within the crowd as cryptographic keys. The fidelity of the retrieved information is tied to how well the crowd remembers the details of the memories they provided. We demonstrate that crowd storage is feasible using an existing crowd marketplace (Amazon Mechanical Turk), explore design considerations important for building systems that use crowd storage, and outline ideas for future research in this area.
2014	EnergyBugs: energy harvesting wearables for children	EnergyBugs are energy harvesting wearables with features that invite children to move their bodies to generate tiny, yet usable amounts of electricity. EnergyBugs not only convert children's kinetic energy into usable electrical energy, but also let children power a specially designed LED lamp with the energy the children have personally harvested. EnergyBugs therefore turn the electrical energy into a tangible object that children can manipulate and think with. Two studies of EnergyBugs with 34 elementary school children have revealed that children carefully observed and negotiated the use of personally harvested energy with their classmates, as well as developed emotional connections to energy. In particular, moving their own bodies to generate energy led the children to more actively ask questions about energy from new perspectives. We report our iterative design process and discuss the implications of our results for HCI.
2014	Let me catch this!: experiencing interactive 3D cinema through collecting content with a mobile phone	The entertainment industry is going through a transformation, and technology development is affecting how we can enjoy and interact with the entertainment media content in new ways. In our work, we explore how to enable interaction with content in the context of 3D cinemas. This allows viewers to use their mobile phone to retrieve, for example, information on the artist of the soundtrack currently playing or a discount coupon on the watch the main actor is wearing. We are particularly interested in the user experience of the interactive 3D cinema concept, and how different interactive elements and interaction techniques are perceived. We report on the development of a prototype application utilizing smart phones and on an evaluation in a cinema context with 20 participants. Results emphasize that designing for interactive cinema experiences should drive for holistic and positive user experiences. Interactive content should be tied together with the actual video content, but integrated into contexts where it does not conflict with the immersive experience with the movie.
2014	Consumed endurance: a metric to quantify arm fatigue of mid-air interactions	Mid-air interactions are prone to fatigue and lead to a feeling of heaviness in the upper limbs, a condition casually termed as the gorilla-arm effect. Designers have often associated limitations of their mid-air interactions with arm fatigue, but do not possess a quantitative method to assess and therefore mitigate it. In this paper we propose a novel metric, Consumed Endurance (CE), derived from the biomechanical structure of the upper arm and aimed at characterizing the gorilla-arm effect. We present a method to capture CE in a non-intrusive manner using an off-the-shelf camera-based skeleton tracking system, and demonstrate that CE correlates strongly with the Borg CR10 scale of perceived exertion. We show how designers can use CE as a complementary metric for evaluating existing and designing novel mid-air interactions, including tasks with repetitive input such as mid-air text-entry. Finally, we propose a series of guidelines for the design of fatigue-efficient mid-air interfaces.
2014	How carat affects user behavior: implications for mobile battery awareness applications	Mobile devices have limited battery life, and numerous battery management applications are available that aim to improve it. This paper examines a large-scale mobile battery awareness application, called Carat, to see how it changes user behavior with long-term use. We conducted a survey of current Carat Android users and analyzed their interaction logs. The results show that long-term Carat users save more battery, charge their devices less often, learn to manage their battery with less help from Carat, have a better understanding of how Carat works, and may enjoy competing against other users. Based on these findings, we propose a set of guidelines for mobile battery awareness applications: battery awareness applications should make the reasoning behind their recommendations understandable to the user, be tailored to retain long-term users, take the audience into account when formulating feedback, and distinguish third-party and system applications.
2014	The vocal chorder: empowering opera singers with a large interactive instrument	With The Vocal Chorder , a large interactive instrument to create accompaniment, opera singers can get more power over the performance. The device allows performers to interactively accompany themselves through pushing, leaning on and bending steel wires. The design was guided by the unique needs of the solo-singer, explored through autobiographical design and material explorations, some on stage, and later tested by other singers. We discuss how designing for opera and for the stage requires extraordinary durability and how opera performances can change with a bodily-oriented instrument such as The Vocal Chorder. Through a designerly exploration, we arrived at a device that offered (1) a tool for singers to take control over the rhythmical pace and overall artistic and aesthetic outcome of their performances, (2) an enriched sense of embodiment between their voice and the overall performance; and (3) a means to empower opera singers on stage.
2014	OJAS: open source bi-directional inductive power link	We present the design, development and evaluation of a bi-directional inductive power transfer circuit for prototyping purposes in the watt-range. Our device does not require any configuration and is intended for the development of wearable and tangible systems. Our approach allows a bi-directional power flow without any change in the circuit, such that the same circuit can be used for charging and discharging a battery. The contribution of this work is an enabling technology for researchers and practitioners in the fields of Wearable Electronics, Ubiquitous Computing and Human-Computer Interaction interested in exploring new interactions powered by watt-range inductive links. It enables smaller battery sizes, and therefore lighter devices, as the power can be distributed in a way that has not been feasible before. We discuss the motivations, technical details and the workshop evaluating our inductive approach.
2014	Exploring percussive gesture on iPads with ensemble metatone	Percussionists are unique among western classical instrumentalists in that their artistic practice is defined by an approach to interaction rather than their instruments. While percussionists are accustomed to exploring non-traditional objects to create music, these objects have yet to encompass touch-screen computing devices to any great extent. The proliferation and popularity of these devices now presents an opportunity to explore their use in combining computer-generated sound together with percussive interaction in a musical ensemble. This paper examines Ensemble Metatone, a group formed to explore the "infiltration" of iPad-based musical instruments into a free-improvisation percussion ensemble. We discuss the design approach for two different iPad percussion instruments and the methodology for exploring them with the group over a series of rehearsals and performances. Qualitative analysis of discussions throughout this process shows that the musicians developed a vocabulary of gestures and musical interactions to make musical sense of these new instruments.
2014	Using asymmetric cores to reduce power consumption for interactive devices with bi-stable displays	Low power "helper" cores have been increasingly included on application processors to accomplish low intensity tasks such as music playing and motion sensing with minimum energy consumption. Recently, Guimbretière et al. [1] demonstrated that such helper cores can also be used to execute simple user interface tasks. We revisit this approach by implementing a similar system on an off-the-shelf application processor (TI OMAP4). Our study shows that in the case of high event rate interactions (pen inking and virtual keyboard), significant battery life gains (×1.7 and ×2.3 respectively) can be achieved with the helper core executing the interface. Having the helper core only dis-patch input events incurs a 18% penalty relative to the maximum savings rate, but allows for simplified deployment since it merely requires a change in toolkit infrastructure.
2014	Coding livecoding	Livecoding is an artistic programming practice in which an artist's low-level interaction can be observed with sufficiently high fidelity to allow for transcription and analysis. This paper presents the first reported "coding" of livecoding videos. From an identified corpus of videos available on the web, we coded performances of two different livecoding artists, recording both the (textual) programming edit events and the musical effect of these edits. Our analysis includes a novel, transition-matrix visualisation of the textual and musical dimensions of this data to create a "performer fingerprint". We show how detailed transcriptions of livecoding videos can be made which, we hope, will provide a foundation for further research into describing and understanding livecoding.
2014	Improving social presence in human-agent interaction	Humans have a tendency to consider media devices as social beings. Social agents and artificial opponents can be examined as one instance of this effect. With today's technology it is already possible to create artificial agents that are perceived as socially present. In this paper, we start by identifying the factors that influence perceptions of social presence in human-agent interactions. By taking these factors into account and by following previously defined guidelines for building socially present artificial opponents, a case study was created in which a social robot plays the Risk board game against three human players. An experiment was performed to ascertain whether the agent created in this case study is perceived as socially present. The experiment suggested that by following the guidelines for creating socially present artificial board game opponents, the perceived social presence of users towards the artificial agent improves.
2014	Posting for community and culture: considerations for the design of interactive digital bulletin boards	The next decade is likely to see a shift in digital public displays moving from non-interactive to interactive content. This will likely create a need for digital bulletin boards and for a better understanding of how such displays should be designed to encourage community members to interact with them. Our study addresses this by exploring community bulletin boards as a ubiquitous type of participatory non-digital display "in the wild". Our results highlight how they are used for content of local and contextual relevance, and how cultures of participation, personalization, location, the tangible character of architecture, access, control and flexibility might affect community members' level of engagement with them. Our analysis suggests entry points as design considerations intrinsically linked to the users' sense of agency within a delineated space. Overlaps with related work are identified throughout to provide further validation of previous findings in this area of research.
2014	Design patterns for exploring and prototyping human-robot interactions	Robotic products are envisioned to offer rich interactions in a range of environments. While their specific roles will vary across applications, these products will draw on fundamental building blocks of interaction, such as greeting people, narrating information, providing instructions, and asking and answering questions. In this paper, we explore how such building blocks might serve as interaction design patterns that enable design exploration and prototyping for human-robot interaction. To construct a pattern library, we observed human interactions across different scenarios and identified seven patterns, such as question-answer pairs. We then designed and implemented Interaction Blocks , a visual authoring environment that enabled prototyping of robot interactions using these patterns. Design sessions with designers and developers demonstrated the promise of using a pattern language for designing robot interactions, confirmed the usability of our authoring environment, and provided insights into future research on tools for human-robot interaction design.
2014	Robot gestures make difficult tasks easier: the impact of gestures on perceived workload and task performance	Gestures are important non-verbal signals in human communication. Research with virtual agents and robots has started to add to the scientific knowledge about gestures but many questions with respect to the use of gestures in human-computer interaction are still open. This paper investigates the influence of robot gestures on the users' perceived workload and task performance (i.e. information recall) in a direction-giving task. We conducted a 2 x 2 (robot gestures vs. no robot gestures x easy vs. difficult task) experiment. The results indicate that robot gestures increased user performance and decreased perceived workload in the difficult task but not in the easy task. Thus, robot gestures are a promising means to improve human-robot interaction particularly in challenging tasks.
2014	Let's kick it: how to stop wasting the bottom third of your large screen display	Large-scale touch surfaces have been widely studied in literature and adopted for public installations such as interactive billboards. However, current designs do not take into consideration that touching the interactive surface at different heights is not the same; for body-height displays, the bottom portion of the screen is within easier reach of the foot than the hand. We explore the design space of foot input on vertical surfaces, and propose three distinct interaction modalities: hand, foot tapping, and foot gesturing. Our design exploration pays particular attention to areas of the touch surface that were previously overlooked: out of hand's reach and close to the floor. We instantiate our design space with a working prototype of an interactive surface, in which we are able to distinguish between finger and foot tapping and extend the input area beyond the bottom of the display to support foot gestures.
2014	Communiplay: a field study of a public display mediaspace	We present Communiplay, a public display media space. People passing by see their own contour mirrored on a public display and can start to play with virtual objects. At the same time, they see others playing at remote displays within the same virtual space. We are interested whether people would use such a public display media space, and if so, how and why. We evaluate Communiplay in a field study in six connected locations and find a remote honey-pot effect, i.e. people interacting at one location attract people at other locations. The conversion rate (percentage of passers-by starting to interact) rose by +136% when people saw others playing at remote locations. We also provide the first quantification of the (local) honey-pot effect (in our case it raised the conversion rate by +604% when people saw others playing at the same location). We conclude that the integration of multiple public displays into a media space is a promising direction for public displays and can make them more attractive and valuable.
2014	Measuring operator anticipatory inputs in response to time-delay for teleoperated human-robot interfaces	Many tasks call for efficient user interaction under time delay-controlling space instruments, piloting remote aircraft and operating search and rescue robots. In this paper we identify an underexplored design opportunity for building robotic teleoperation user interfaces following an evaluation of operator performance during a time-delayed robotic arm block-stacking task in twenty-two participants. More delay resulted in greater operator hesitation and a decreased ratio of active to inactive input. This ratio can serve as a useful proxy for measuring an operator's ability to anticipate the outcome of their control inputs before receiving delayed visual feedback. High anticipatory input ratio (AIR) scores indicate times when robot operators enter commands before waiting for visual feedback. Low AIR scores highlight when operators must wait for visual feedback before continuing. We used this measurement to help us identify particular sub-tasks where operators would likely benefit from additional support.
2014	I can wait a minute: uncovering the optimal delay time for pre-moderated user-generated content on public displays	Public displays have advanced from isolated and non interactive "ad" displays which show images and videos to displays that are networked, interactive, and open to a wide variety of content and applications. Prior work has shown large potential of user-generated content on public displays. However, one of the problems with user-generated content on public displays is moderation as content may be explicit or troublesome for a particular location. In this work we explore the expectations of users with regard to content moderation on public displays. An online survey revealed that people not only think that display content should be moderated but also that a delay of up to 10 minutes is acceptable if display content is moderated. In a subsequent in the wild deployment we compared different moderation delays. We found that a moderation delay significantly decreases the number of user-generated posts while at the same time there is no significant effect on users' decision to repeatedly post on the display.
2014	Stay on the boundary: artifact analysis exploring researcher and user framing of robot design	In recent years, HCI researchers have increased their focus on studying the power relationships between researchers and users, and developing methodologies for eliciting design ideas that are sensitive to existing epistemic hierarchies in technology design. The differential value given to expert versus lay knowledge is a central factor in these debates. We apply Artifact Analysis, developed to help designers handle the complexity of digital artifacts, as a method to explore how experts and non-experts understand and frame robots, a technology characterized by significant complexity. Our results show that both non-expert users and expert researchers have knowledge that is significant to future robot development, but they focus on different aspects of the technology - users address mediated and interaction complexity while researchers focus on internal and external complexity. We also found that robots function as boundary objects between experts and users, and suggest that one task designers can perform is to "stay on the boundary" and mediate between the different ways in which experts and non-experts frame emerging technology to develop designs that benefit from insights from both user and researcher perspectives.
2014	Edit distance modulo bisimulation: a quantitative measure to study evolution of user models	When a user learns to use a new device, her understanding of it evolves. A progressive comparison of the evolving user models towards the device target model, for analysing learning, involves determining the behavioral proximity between them. To quantify the gap between a user model and a target model, we introduce an edit distance metric for measuring their behavioral proximity using a bisimulation-based equivalence relation. We define edit distance to be the minimum number of edges and states with incident edges required to be deleted from and/or added to a user model to make it bisimilar to the target model. We propose an algorithm to compute edit distance between two models and employ the heuristic procedure on experimental data for computing edit distance between target and user models. The data is organised into two experiments depending on the device the user interacted with: (a) a simple device resembling a vending machine and (b) a close to real-world vehicle transmission model. The results validate our proposed metric as edit distance converges with progressive user learning, increases for erroneous learning, and remains unchanged indicating no learning.
2014	Conversing with children: cartoon and video people elicit similar conversational behaviors	Interactive animated characters have the potential to engage and educate children, but there is little research on children's interactions with animated characters and real people. We conducted an experiment with 69 children between the ages of 4 and 10 years to investigate how they might engage in conversation differently if their interactive partner appeared as a cartoon character or as a person. A subset of the participants interacted with characters that displayed exaggerated and damped facial motion. The children completed two conversations with an adult confederate who appeared once as herself through video and once as a cartoon character. We measured how much the children spoke and compared their gaze and gesture patterns. We asked them to rate their conversations and indicate their preferred partner. There was no difference in children's conversation behavior with the cartoon character and the person on video, even among those who preferred the person and when the cartoon exhibited altered motion. These results suggest that children will interact with animated characters as they would another person.
2014	Do-it-yourself cellphones: an investigation into the possibilities and limits of high-tech diy	This paper describes our do-it-yourself cellphone and our use of it to investigate the possibilities and limits of high-tech DIY practice. We describe our autobiographical approach -- making the phone and using it in our daily lives -- and our work disseminating the cellphone in workshops and online. This informs a discussion of the implications of technology for DIY practice. We suggest an understanding of DIY as an individual's ability to combine existing technologies into a desired product, enabled and limited by ecosystems of industrial actors and individuals. We distinguish different pathways into high-tech DIY practice, consider the relationship between prototyping and production, and discuss the effect of technology on DIY's relevance and tools, and on notions of transparency. We conclude by reflecting on the relationship between DIY and empowerment: the extent to which making devices gives people control over the technology in their lives.
2014	The law of unintended consequences: the case of external subgoal support	Many interfaces have been designed to prevent or reduce errors. These interfaces may, in fact, reduce the error rate of specific error classes, but may also have unintended consequences. In this paper, we show a series of studies where a better interface did not reduce the number of errors but instead shifted errors from one error class (omissions) to another error class (perseverations). We also show that having access to progress tracking (a progress bar) does not reduce the number of errors. We propose and demonstrate a solution -- a predictive error system -- that reduces errors based on the error class, not on the type of interface.
2014	3D printed interactive speakers	We propose technology for designing and manufacturing interactive 3D printed speakers. With the proposed technology, sound reproduction can easily be integrated into vari-ous objects at the design stage and little assembly is required. The speaker can take the shape of anything from an abstract spiral to a rubber duck, opening new opportunities in product design. Furthermore, both audible sound and inaudible ultrasound can be produced with the same design, allowing for identifying and tracking 3D printed objects in space using common integrated microphones. The design of 3D printed speakers is based on electrostatic loudspeaker technology first explored in the early 1930s but not broadly applied until now. These speakers are simpler than common electromagnetic speakers, while allowing for sound reproduction at 60 dB levels with arbitrary directivity ranging from focused to omnidirectional. Our research of 3D printed speakers contributes to the growing body of work exploring functional 3D printing in interactive applications.
2014	Causality: a conceptual model of interaction history	Simple history systems such as Undo and Redo permit retrieval of earlier or later interaction states, but advanced systems allow powerful capabilities to reuse or reapply combinations of commands, states, or data across interaction contexts. Whether simple or powerful, designing interaction history mechanisms is challenging. We begin by reviewing existing history systems and models, observing a lack of tools to assist designers and researchers in specifying, contemplating, combining, and communicating the behaviour of history systems. To resolve this problem, we present CAUSALITY, a conceptual model of interaction history that clarifies the possibilities for temporal interactions. The model includes components for the work artifact (such as the text and formatting of a Word document), the system context (such as the settings and parameters of the user interface), the linear timeline (the commands executed in real time), and the branching chronology (a structure of executed commands and their impact on the artifact and/or context, which may be navigable by the user). We then describe and exemplify how this model can be used to encapsulate existing user interfaces and reveal limitations in their behaviour, and we also show in a conceptual evaluation how the model stimulates the design of new and innovative opportunities for interacting in time.
2014	Circuit stickers: peel-and-stick construction of interactive electronic prototypes	We present a novel approach to the construction of electronic prototypes which can support a variety of interactive devices. Our technique, which we call circuit stickers , involves adhering physical interface elements such as LEDs, sounders, buttons and sensors onto a cheap and easy-to-make substrate which provides electrical connectivity. This assembly may include control electronics and a battery for standalone operation, or it can be interfaced to a microcontroller or PC. In this paper we illustrate different points in the design space and demonstrate the technical feasibility of our approach. We have found circuit stickers to be versatile and low-cost, supporting quick and easy construction of physically flexible interactive prototypes. Building extra copies of a device is straightforward. We believe this technology has potential for design exploration, research proto-typing, education and for hobbyist projects.
2014	Modeling the perception of user performance	This paper studies how users perceive their own performance in two alternative user interfaces. We extend methodology from psychophysics to the study of interactive performance and conduct two experiments in order to create a model of users' perception of their own performance. In our studies, two interfaces are sequentially used in a pointing task, and users are asked to rate in which interface their performance was higher. We first differentiate the effects of objective performance (speed and accuracy) versus interface qualities (distance between elements and width of elements) on perceived performance. We then derive a model that predicts the amount of change required in an interface for users to reliably detect a difference. The model is useful as a heuristic for predicting if a new interface design is better enough for users to reliably appreciate the obtained gain in user performance. We validate the model via a separate user study, and conclude by discussing how to apply our findings to design problems.
2014	Involving children in content control: a collaborative and education-oriented content filtering approach	We present an approach to content control where parents and children collaboratively configure restrictions and filters, an approach that focuses on education rather than simple rule setting. We conducted an initial exploratory qualitative study with results highlighting the importance that parents place on avoiding inappropriate content. Building on these findings, we designed an initial prototype which allows parents and children to work together to select appropriate applications, providing an opportunity for parents to educate their children on what is appropriate. A second qualitative study with parents and children in the six to eight year-old age group revealed a favorable response to this approach. Our results suggest that parents felt that this approach helped facilitate discussions with their children and made the education more enjoyable and approachable, and that children may have also learned from the interaction. In addition, the approach provided some parents with insights into their children's interests and understanding of their notions of appropriate and inappropriate content.
2014	Bodies in motion: mobility, presence, and task awareness in telepresence	Robotic telepresence systems - videoconferencing systems that allow a remote user to drive around in another location - provide an alternative to video-mediated communications as a way of interacting over distances. These systems, which are seeing increasing use in business and medical settings, are unique in their ability to grant the remote user the ability to maneuver in a distant location. While this mobility promises increased feelings of "being there" for remote users and thus greater support for task collaboration, whether these promises are borne out, providing benefits in task performance, is unknown. To better understand the role that mobility plays in shaping the remote user's sense of presence and its potential benefits, we conducted a two-by-two (system mobility: stationary vs. mobile; task demands for mobility: low vs. high) controlled laboratory experiment. We asked participants ( N =40) to collaborate in a construction task with a confederate via a robotic telepresence system. Our results showed that mobility significantly increased the remote user's feelings of presence, particularly in tasks with high mobility requirements, but decreased task performance. Our findings highlight the positive effects of mobility on feelings of "being there," while illustrating the need to design support for effective use of mobility in high-mobility tasks.
2014	Learning to see the body: supporting instructional practices in laparoscopic surgical procedures	Learning the practices and the performance of physically manipulating instruments in minimally invasive surgeries is an impetus for the development of surgical training simulators. However, an often-overlooked aspect of surgical training is learning how to see the body through the various imaging mechanisms. With this study, we address the ways in which surgeons demonstrate and instruct residents in seeing the body during minimally invasive surgical procedures. Drawing on observations and analysis of video recordings of minimally invasive surgical operations, we examine how particular anatomy and movement within the body to see and conceptualize that anatomy are made visible by the instructive practices of the surgeon. We use these findings to discuss further directions for minimally invasive surgical training through mechanisms for making the body visible during situated surgical training and surgical training simulation systems.
2014	Remote handshaking: touch enhances video-mediated social telepresence	Since past studies on haptic and visual communication have tended to be isolated from each other, it has remained unclear whether a touch channel can still enrich mediated communication where video and audio channels are already available. To clarify this, we analyzed remote handshaking in which a robot hand that was attached just under a videoconferencing terminal's display moved according to the opening and closing motion of a conversation partner's hand. Combining touch and video channels raises a question as to whether the partner's action of touching a haptic device should be visible to the user. If it can be invisible, the action may be unnecessary, and a unilaterally controlled device may be enough to establish an effective touch channel. Our analysis revealed that the feeling of being close to the partner can be enhanced by mutual touch in which the partner's action needs to occur but should be invisible.
2014	Supporting learners in collecting and exploring data from immersive simulations in collective inquiry	Digitally augmented physical spaces (e.g., smart classrooms) offer opportunities to engage students in novel and potentially transformative learning experiences. This paper presents an immersive rainforest simulation and collective inquiry activity where students collect observational data from the environment and explore their peers' data through large visualization displays and personal mobile devices. Two iterations of the design were tested, which resulted in higher quality student explanations constructed. Images were found to be an important source of evidence for the explanations, more so than text-only evidence. We also found that patterns of collective ideas influenced student performance, and that visualizations, as ambient or plenary displays, supported both teacher and students in reviewing patterns of collected data.
2014	Exploring video streaming in public settings: shared geocaching over distance using mobile video chat	Our research explores the use of mobile video chat in public spaces by people participating in parallel experiences , where both a local and remote person are doing the same activity together at the same time. We prototyped a wearable video chat experience and had pairs of friends and family members participate in 'shared geocaching' over distance. Our results show that video streaming works best for navigation tasks but is more challenging to use for fine-grained searching tasks. Video streaming also creates a very intimate experience with a remote partner, but this can lead to distraction from the 'real world' and even safety concerns. Overall, privacy concerns with streaming from a public space were not typically an issue; however, people tended to rely on assumptions of what were acceptable. The implications are that designers should consider appropriate feedback, user disembodiment, and asymmetry when designing for parallel experiences.
2014	Showing face in video instruction: effects on information retention, visual attention, and affect	The amount of online educational content is rapidly increasing, particularly in the form of video lectures. The goal is to design video instruction to facilitate an experience that maximizes learning and satisfaction. A widely used but understudied design element in video instruction is the overlay of a small video of the instructor over lecture slides. We conducted an experiment with eye-tracking and recall tests to investigate how adding the instructor's face to video instruction affects information retention, visual attention, and affect. Participants strongly preferred instruction with the face and perceived it as more educational. They spent about 41% of time looking at the face and switched between the face and slide every 3.7 seconds. Consistent with prior work, no significant difference in short- and medium-term recall ability was found. Including the face in video instruction is encouraged based on learners' positive affective response. More fine-grained analytics combining eye-tracking with detailed learning assessment could shed light on the mechanisms by which the face aids or hinders learning.
2014	Information-building applications: designing for data exploration and analysis by elementary school students	The propagation of Inquiry Based Learning has lead to many more elementary students interacting with authentic scientific tools and practices. However, the more problematic realities of scientific data collection, such as noise and large data sets, are often deliberately hidden from students. Students will need to confront these realities and be able to make skillful data scoping decisions in order to make sense of ever more prevalent large datasets. We dub software designed to support these activities Information-Building Applications (IBAs). This paper presents the design considerations that went into building an exemplar IBA, PhotoMAT (Photo Management and Analysis Tool), a brief user study to show how the solutions enacted by following these principles are taken up by actual students, and a discussion of how the design considerations identified by our work might be applied to another IBA.
2014	OneSpace: shared visual scenes for active freeplay	Children engage in free play for emotional, physical and social development; researchers have explored supporting free play between physically remote playmates using videoconferencing tools. We show that the configuration of the video conferencing setup affects play. Specifically, we show that a shared visual scene configuration promotes fundamentally active forms of engaged, co-operative play.
2014	A gaze-preserving situated multiview telepresence system	Gaze, attention, and eye contact are important aspects of face to face communication, but some subtleties can be lost in videoconferencing because participants look at a single planar image of the remote user. We propose a low-cost cylindrical videoconferencing system that preserves gaze direction by providing perspective-correct images for multiple viewpoints around a conference table. We accomplish this by using an array of cameras to capture a remote person, and an array of projectors to present the camera images onto a cylindrical screen. The cylindrical screen reflects each image to a narrow viewing zone. The use of such a situated display allows participants to see the remote person from multiple viewing directions. We compare our system to three alternative display configurations. We demonstrate the effectiveness of our system by showing it allows multiple participants to simultaneously tell where the remote person is placing their gaze.
2014	Pay or delay: the role of technology when managing a low income	This paper reports on a qualitative study of 38 low-income individuals living in the North East of England. The participants' experiences of money, banking and the role digital technology plays in their financial practices were identified through semi-structured interviews in people's homes and group workshops. A grounded theory analysis of these data characterises how technology both helped and hindered participants to keep close control of their finances. These findings suggest design opportunities for future digital banking technologies that extend the already sophisticated practices of individuals managing a low income, focusing on: delaying, prioritising, planning, watching, and hiding monetary transactions.
2014	Sample-oriented task-driven visualizations: allowing users to make better, more confident decisions	We often use datasets that reflect samples, but many visualization tools treat data as full populations. Uncertain visualizations are good at representing data distributions emerging from samples, but are more limited in allowing users to carry out decision tasks. This is because tasks that are simple on a traditional chart (e.g. "compare two bars") become a complex probabilistic task on a chart with uncertainty. We present guidelines for creating visual annotations for solving tasks with uncertainty, and an implementation that addresses five core tasks on a bar chart. A preliminary user study shows promising results: that users have a justified confidence in their answers with our system.
2014	Fostering social capital in economically distressed communities	Past Information and Communication Technology (ICT) literature suggests that engaging in meaningful activities with ICTs may be related to socio-economic security, social inclusion, empowerment, and increased social capital. However, we identify a pervasive lack of understanding in existing literature, which raises an important research question: how can we build social capital where little social capital exists? We conducted a preliminary study to explore whether and if so, how, individuals in an economically distressed population with limited social capital use technologies to increase social capital and achieve socio-economic security. We contribute details about barriers affecting social capital (e.g., difficulties finding and making the right connections and an overall lack of trust within communities). We also suggest ways in which ICTs can assist populations that could benefit most from increased social capital and economic security.
2014	Learning to fail: experiencing public failure online through crowdfunding	Online crowdfunding platforms like Kickstarter are gaining attention among novice creatives as an effective platform for funding their ventures and engaging in creative work with others. However, a focus on financial success of crowdfunding has obscured the fact that over 58% of crowdfunding projects fail to achieve their funding goals. This population of failed creatives however, gives us an audience to study public creative failure in an online environment. We draw inspiration from work in organizational behavior on failure, and work in Human Computer Interaction (HCI) on online behavior, to study online public failure. Using a mixed-methods approach with data scraped from Kickstarter and interview data with failed crowdfunding project creators, we answer the following question: What do project creators on crowdfunding platforms learn and change through the process of failing? We find that creators who relaunch their projects succeed 43% of the time, and that most individuals find failure to be a positive experience. We conclude the paper with a series of design implications for future creative platforms where public failure is part of the creative process.
2014	Automatic generation of semantic icon encodings for visualizations	Authors use icon encodings to indicate the semantics of categorical information in visualizations. The default icon libraries found in visualization tools often do not match the semantics of the data. Users often manually search for or create icons that are more semantically meaningful. This process can hinder the flow of visual analysis, especially when the amount of data is large, leading to a suboptimal user experience. We propose a technique for automatically generating semantically relevant icon encodings for categorical dimensions of data points. The algorithm employs natural language processing in order to find relevant imagery from the Internet. We evaluate our approach on Mechanical Turk by generating large libraries of icons using Tableau Public workbooks that represent real analytical effort by people out in the world. Our results show that the automatic algorithm does nearly as well as the manually created icons, and particularly has higher user satisfaction for larger cardinalities of data.
2014	now that's definitely a proper hack: self-made tools in hackerspaces	Cultures of making - that is, social practices of hacking, DIY, tinkering, repair, and craft - continue to rise in prominence, and design researchers have taken note, because of their implications for sustainability, democratization, and alternative models of innovation, design, participation, and education. We contribute to this agenda by exploring our findings on self-made tools, which we encountered in a 9-month ethnographic study of a hackerspace. Self-made tools embody issues raised in two discourses that are of interest in design research on making: tools and adhocism. In this paper, we explore ways that tools and adhocism interface with each other, using our findings as a material to think with. We find that this juxtaposition of concepts helps explain a highly generative creative practice - tool-making - within the hackerspace we studied.
2014	Printing teddy bears: a technique for 3D printing of soft interactive objects	This paper considers the design, construction, and example use of a new type of 3D printer which fabricates three-dimensional objects from soft fibers (wool and wool blend yarn). This printer allows the substantial advantages of additive manufacturing techniques (including rapid turn-around prototyping of physical objects and support for high levels of customization and configuration) to be employed with a new class of material. This material is a form of loose felt formed when fibers from an incoming feed of yarn are entangled with the fibers in layers below it. The resulting objects recreate the geometric forms specified in the solid models which specify them, but are soft and flexible -- somewhat reminiscent in character to hand knitted materials. This extends 3D printing from typically hard and precise forms into a new set of forms which embody a different aesthetic of soft and imprecise objects, and provides a new capability for researchers to explore the use of this class of materials in interactive devices.
2014	Predictors of life satisfaction based on daily activities from mobile sensor data	In recent years much research work has been dedicated to detecting user activity patterns from sensor data such as location, movement and proximity. However, how daily activities are correlated to people's happiness (such as their satisfaction from work and social lives) is not well explored. In this work, we propose an approach to investigate the relationship between users' daily activity patterns and their life satisfaction level. From a well-known longitudinal dataset collected by mobile devices, we extract various activity features through location and proximity information, and compute the entropies of these data to capture the regularities of the behavioral patterns of the participants. We then perform component analysis and structural equation modeling to identify key behavior contributors to self-reported satisfaction scores. Our results show that our analytical procedure can identify meaningful assumptions of causality between activities and satisfaction. Particularly, keeping regularity in daily activities can significantly improve the life satisfaction.
2014	Money talks: tracking personal finances	How do people keep track of their money? In this paper we present a preliminary scoping study of how 14 individuals in the San Francisco Bay Area earn, save, spend and understand money and their personal and family finances. We describe the practices we developed for exploring the sensitive topic of money, and then discuss three sets of findings. The first is the emotional component of the relationship people have with their finances. Second, we discuss the tools and processes people used to keep track of their financial situation. Finally we discuss how people account for the unknown and unpredictable nature of the future through their financial decisions. We conclude by discussing the future of studies of money and finance in HCI, and reflect on the opportunities for improving tools to aid people in managing and planning their finances.
2014	Taking things apart: reaching common ground and shared material understanding	In this note we discuss and argue about how taking things apart and disassembling can be meaningful practices in explorative design projects. In particular, we report on an explorative design exercise about taking apart an unfamiliar device. Relating to this design situation, we provide accounts for how collaborative hands-on experience can support reaching common ground and acquiring shared material understanding in an interdisciplinary design team through establishing a material brief . In the end we reflect and discuss how this may complement our practices regarding materials and interaction design.
2014	Faces engage us: photos with faces attract more likes and comments on Instagram	Photos are becoming prominent means of communication online. Despite photos' pervasive presence in social media and online world, we know little about how people interact and engage with their content. Understanding how photo content might signify engagement, can impact both science and design, influencing production and distribution. One common type of photo content that is shared on social media, is the photos of people. From studies of offline behavior, we know that human faces are powerful channels of non-verbal communication. In this paper, we study this behavioral phenomena online. We ask how presence of a face, it's age and gender might impact social engagement on the photo. We use a corpus of 1 million Instagram images and organize our study around two social engagement feedback factors, likes and comments. Our results show that photos with faces are 38% more likely to receive likes and 32% more likely to receive comments, even after controlling for social network reach and activity. We find, however, that the number of faces, their age and gender do not have an effect. This work presents the first results on how photos with human faces relate to engagement on large scale image sharing communities. In addition to contributing to the research around online user behavior, our findings offer a new line of future work using visual analysis.
2014	KnowMe and ShareMe: understanding automatically discovered personality traits from social media and user sharing preferences	There is much recent work on using the digital footprints left by people on social media to predict personal traits and gain a deeper understanding of individuals. Due to the veracity of social media, imperfections in prediction algorithms, and the sensitive nature of one's personal traits, much research is still needed to better understand the effectiveness of this line of work, including users' preferences of sharing their computationally derived traits. In this paper, we report a two- part study involving 256 participants, which (1) examines the feasibility and effectiveness of automatically deriving three types of personality traits from Twitter, including Big 5 personality, basic human values, and fundamental needs, and (2) investigates users' opinions of using and sharing these traits. Our findings show there is a potential feasibility of automatically deriving one's personality traits from social media with various factors impacting the accuracy of models. The results also indicate over 61.5% users are willing to share their derived traits in the workplace and that a number of factors significantly influence their sharing preferences. Since our findings demonstrate the feasibility of automatically inferring a user's personal traits from social media, we discuss their implications for designing a new generation of privacy-preserving, hyper-personalized systems.
2014	Designing for movement: evaluating computational models using LMA effort qualities	While single-accelerometers are a common consumer embedded sensors, their use in representing movement data as an intelligent resource remains scarce. Accelerometers have been used in movement recognition systems, but rarely to assess expressive qualities of movement. We present a prototype of wearable system for the real-time detection and classification of movement quality using acceleration data. The system applies Laban Movement Analysis (LMA) to recognize Laban Effort qualities from acceleration input using a Machine Learning software that generates classifications in real time. Existing LMA-recognition systems rely on motion capture data and video data, and can only be deployed in controlled settings. Our single-accelerometer system is portable and can be used under a wide range of environmental conditions. We evaluate the performance of the system, present two applications using the system in the digital arts and discuss future directions.
2014	Design tactics for authentic interactive fiction: insights from alternate reality game designers	This paper presents insights from designers of Alternate Reality Games (ARGs) regarding the design tactics they employ to integrate participatory storytelling and "authentic fiction" into the transmedia experiences they create. Our approach was motivated by recent efforts in HCI to more closely align the development of interaction design theory to the craft knowledge and experiences of designers themselves. The resulting insights enhance our understanding of design approaches that a diverse group of ARG producers follow to create interactive, participatory narratives. We outline narrative-specific themes to support designers who craft similar interactive experiences.
2014	Gaining empathy for non-routine mobile device use through autoethnography	In this paper, we report on autoethnography as a method to access non-routine usage of mobile devices, such as during business trips, vacations, etc. Autoethnography, a self-study method with the researcher as participant, was employed for the evaluation of a wrist blood pressure monitor used by people with conditions such as hypertension. The findings from the study were surprising, especially with respect to the environmental and social impact on the use of the technology. Although the autoethnographic method can be disruptive for the researcher, it enables them to understand and empathize with the experiences mobile device users can face in difficult to access contexts. This method allows HCI researchers to better understand user experiences with mobile devices, including mobile medical technology, especially during non-routine times that can be difficult to study in-situ with traditional user studies.
2014	Jump and shoot!: prioritizing primary and alternative body gestures for intense gameplay	Motion gestures enable natural and intuitive input in video games. However, game gestures designed by developers may not always be the optimal gestures for players. A key challenge in designing appropriate game gestures lies in the interaction-intensive nature of video games, i.e., several actions/commands may need to be executed concurrently using different body parts. This study analyzes user preferences in game gestures, with the aim of accommodating high interactivity during gameplay. Two user-elicitation studies were conducted: first, to determine user preferences, participants were asked to define gestures for common game actions/commands; second, to develop effective combined-gestures, participants were asked to define possible game gestures using each body part (one and two hands, one and two legs, head, eyes, and torso). Our study presents a set of suitable and alternative body parts for common game actions/commands. We also present some simultaneously applied game gestures that assist interaction in highly interactive game situations (e.g., selecting a weapon with the feet while shooting with the hand). Interesting design implications are further discussed, e.g., transferability between hand and leg gestures.
2014	Does content determine information popularity in social media?: a case study of youtube videos' content and their popularity	We here investigate what drives the popularity of information on social media platforms . Focusing on YouTube, we seek to understand the extent to which content by itself determines a video's popularity. Using mechanical turk as experimental platform, we asked users to evaluate pairs of videos, and compared users' relative perception of the videos' content against their relative popularity reported by YouTube. We found that in most evaluations users could not reach consensus on which video had better content as their perceptions tend to be very subjective. Nevertheless, when consensus was reached, the video with preferred content almost always achieved greater popularity on YouTube, highlighting the importance of content in driving information popularity on social media.
2014	Photo sharing of the subject, by the owner, for the viewer: examining the subject's preference	Photo sharing activities on social networking sites concern not only the person sharing the information (owner) and the person receiving the information (viewer) but also the person who is in the photo (subject). In our exploratory lab study, we asked 29 participants about their comfort level in allowing a photo owner to share a picture containing both the participant (subject) and the owner. Our results show that the photo subject feels more comfortable in sharing a photo when i) the "closeness between the subject and the owner (SO closeness)" is higher, and ii) the "closeness between the subject and the viewer (SV closeness)" is higher. In addition, we observed that both SV and SO closeness are important in determining the subject's picture sharing preference level.
2014	You read what you value: understanding personal values and reading interests	This paper presents an experiment on the relationship between personal values and reading interests of online articles. Results suggest that individuals' values can predict their topical interests. For example, holding stronger universalism values predict interests towards environmental articles, whereas holding stronger achievement values predict interest towards work-related articles. Findings demonstrate the possibility of targeting based on individuals' personal values, but also highlight certain challenges and limitations when applying this approach for online content.
2014	RetroDepth: 3D silhouette sensing for high-precision input on and above physical surfaces	We present RetroDepth, a new vision-based system for accurately sensing the 3D silhouettes of hands, styluses, and other objects, as they interact on and above physical surfaces. Our setup is simple, cheap, and easily reproducible, comprising of two infrared cameras, diffuse infrared LEDs, and any off-the-shelf retro-reflective material. The retro-reflector aids image segmentation, creating a strong contrast between the surface and any object in proximity. A new highly efficient stereo matching algorithm precisely estimates the 3D contours of interacting objects and the retro-reflective surfaces. A novel pipeline enables 3D finger, hand and object tracking, as well as gesture recognition, purely using these 3D contours. We demonstrate high-precision sensing, allowing robust disambiguation between a finger or stylus touching, pressing or interacting above the surface. This allows many interactive scenarios that seamlessly mix together freehand 3D interactions with touch, pressure and stylus input. As shown, these rich modalities of input are enabled on and above any retro-reflective surface, including custom "physical widgets" fabricated by users. We compare our system with Kinect and Leap Motion, and conclude with limitations and future work.
2014	SurfaceLink: using inertial and acoustic sensing to enable multi-device interaction on a surface	We present SurfaceLink , a system where users can make natural surface gestures to control association and information transfer among a set of devices that are placed on a mutually shared surface ( e.g. , a table). SurfaceLink uses a combination of on-device accelerometers, vibration motors, speakers and microphones (and, optionally, an off-device contact microphone for greater sensitivity) to sense gestures performed on the shared surface. In a controlled evaluation with 10 participants, SurfaceLink detected the presence of devices on the same surface with 97.7% accuracy, their relative arrangement with 89.4% accuracy, and various single- and multi-touch surface gestures with an average accuracy of 90.3%. A usability analysis showed that SurfaceLink has advantages over current multi-device interaction techniques in a number of situations.
2014	Long tail TV revisited: from ordinary camera phone use to pro-am video production	Pro-Am live video producers broadcast events on a regular basis. They are here selected for an ethnographic study since their continuous content generation can teach us something of what it takes for amateurs, who currently struggle with mastering the video medium, to become proficient producers. We learn from media theory that Pro-Ams are distinguished from professionals in terms of inherent skills and identities, and have therefore focused on these characteristics. We add to this research by showing on-going challenges that the former face in their production, i.e. how their learning practices, such as learning through instructions, are situated and related to particular settings. Learning and development of skills were done as organizations, rather than as individuals. Furthermore, the recurrent nature of both events and broadcasts appears to be an important condition for establishing the terms needed to carry out a production, and to learn the skills of a producer. This understanding may explain in part why accounts in previous research, of single users struggling with the affordances of live video, point to such difficulties in mastering the medium. The findings guide design to better support activities contiguous with the set-up of the production, rather than the broadcast per se.
2014	Comparing flat and spherical displays in a trust scenario in avatar-mediated interaction	We report on two experiments that investigate the influence of display type and viewing angle on how people place their trust during avatar-mediated interaction. By monitoring advice seeking behavior, our first experiment demonstrates that if participants observe an avatar at an oblique viewing angle on a flat display, they are less able to discriminate between expert and non-expert advice than if they observe the avatar face-on. We then introduce a novel spherical display and a ray-traced rendering technique that can display an avatar that can be seen correctly from any viewing direction. We expect that a spherical display has advantages over a flat display because it better supports non-verbal cues, particularly gaze direction, since it presents a clear and undistorted viewing aspect at all angles. Our second experiment compares the spherical display to a flat display. Whilst participants can discriminate expert advice regardless of display, a negative bias towards the flat screen emerges at oblique viewing angles. This result emphasizes the ability of the spherical display to be viewed qualitatively similarly from all angles. Together the experiments demonstrate how trust can be altered depending on how one views the avatar.
2014	Seeking and sharing health information online: comparing search engines and social media	Search engines and social media are two of the most com-monly used online services; in this paper, we examine how users appropriate these platforms for online health activi-ties via both large-scale log analysis and a survey of 210 people. While users often turn to search engines to learn about serious or highly stigmatic conditions, a surprising amount of sensitive health information is also sought and shared via social media, in our case the public social plat-form Twitter. We contrast what health content people seek via search engines vs. share on social media, as well as why they choose a particular platform for online health activi-ties. We reflect on the implications of our results for design-ing search engines, social media, and social search tools that better support people's health information seeking and sharing needs.
2014	Unraveling abstinence and relapse: smoking cessation reflected in social media	Analysis of smokers' posts and behaviors on Twitter reveals factors impacting abstinence and relapse during cessation attempts. Combining automatic and crowdsourced techniques, we detect users trying to quit smoking and analyze tweet and network data from a sample of 653 individuals over a two-year window of quitting. Guided by theory and practice, we derive behavioral, social, and emotional measures to compare users who abstain and relapse. We also examine the cessation process, demonstrating that Twitter can help chronicle how some people go about quitting. Among other results, we show that those who fail in their smoking cessation are far heavier posters and use relatively less positive language, while those who succeed are more social in both network ties and in directed communication. We conclude with insights on how intelligent intervention systems can harness these signals to provide tailored behavior change support.
2014	Estimating county health statistics with twitter	Understanding the relationships among environment, behavior, and health is a core concern of public health researchers. While a number of recent studies have investigated the use of social media to track infectious diseases such as influenza, little work has been done to determine if other health concerns can be inferred. In this paper, we present a large-scale study of 27 health-related statistics, including obesity, health insurance coverage, access to healthy foods, and teen birth rates. We perform a linguistic analysis of the Twitter activity in the top 100 most populous counties in the U.S., and find a significant correlation with 6 of the 27 health statistics. When compared to traditional models based on demographic variables alone, we find that augmenting models with Twitter-derived information improves predictive accuracy for 20 of 27 statistics, suggesting that this new methodology can complement existing approaches.
2014	PrintSense: a versatile sensing technique to support multimodal flexible surface interaction	We present a multimodal on-surface and near-surface sensing technique for planar, curved and flexible surfaces. Our technique leverages temporal multiplexing of signals coming from a universal interdigitated electrode design, which is printed as a single conductive layer on a flexible substrate. It supports sensing of touch and proximity input, and moreover is capable of capturing several levels of pressure and flexing. We leverage recent developments in conductive inkjet printing as a way to prototype electrode patterns, and combine this with our hardware module for supporting the full range of sensing methods. As the technique is low-cost and easy to implement, it is particularly well-suited for prototyping touch- and hover-based user interfaces, including curved and deformable ones.
2014	Weaving clinical expertise in online health communities	Many patients visit online health communities to receive support. In face-to-face support groups, health professionals facilitate peer-patients exchanging experience while adding their clinical expertise when necessary. However, the large scale of online health communities makes it challenging for such health professional moderators' involvement to happen. To address this challenge of delivering clinical expertise to where patients need them, we explore the idea of semi-automatically providing clinical expertise in online health communities. We interviewed 14 clinicians showing them example peer-patient conversation threads. From the interviews, we examined the ideal practice of clinicians providing expertise to patients. The clinicians continuously assessed when peer-patients were providing appropriate support, what kinds of clinical help they could give online, and when to defer to patients' healthcare providers. The findings inform requirements for building a semi-automated system delivering clinical expertise in online health communities.
2014	Human factors of speed-based exergame controllers	Exergame controllers are intended to add fun to monotonous exercise. However, studies on exergame controllers mostly focus on designing new controllers and exploring specific application domains without analyzing human factors, such as performance, comfort, and effort. In this paper, we examine the characteristics of a speed-based exergame controller that bear on human factors related to body movement and exercise. Users performed tasks such as changing and maintaining exercise speed for avatar control while their performance was measured. The exergame controller follows Fitts' law, but requires longer movement time than a gamepad and Wiimote. As well, resistance force and target speed affect performance. User experience data confirm that the comfort and mental effort are adequate as practical game controllers. The paper concludes with discussion on applying our findings to practical exergame design.
2014	healthifying exergames: improving health outcomes through intentional priming	Exergames, video game systems that require exertion and interaction, have been rising in popularity in the past years. However, research on popular exergames shows mixed health benefits, potentially due to minimal energy expenditure and decreasing use over time. This paper presents a 2x2 experimental study (N = 44), using a popular exergame, where we vary the framing of intention (i.e., "Gameplay" or "Exercise") and feedback (i.e., "Health" or "No health") to explore their single and interactive impacts on perceived exertion, objectively measured energy expenditure, affect, and duration of usage in a single session. Our study showed that participants primed with exercise used the system significantly longer than those primed with game play ( M = 49.2 ±2.0 min versus M = 39.3 ±2.0 min). We discuss our results and possible design implications based on our single-session experiment. We conclude with a discussion on the potential impact of focusing on "healthifying" exergames -highlighting an exergames" dual purpose as both a game and exercise - as opposed to gamifying health behaviors.
2014	Highlighting interventions and user differences: informing adaptive information visualization support	There is increasing evidence that the effectiveness of information visualization techniques can be impacted by the particular needs and abilities of each user. This suggests that it is important to investigate information visualization systems that can dynamically adapt to each user. In this paper, we address the question of how to adapt . In particular, we present a study to evaluate a variety of visual prompts, called "interventions", that can be performed on a visualization to help users process it. Our results show that some of the tested interventions perform better than a condition in which no intervention is provided, both in terms of task performance as well as subjective user ratings. We also discuss findings on how intervention effectiveness is influenced by individual differences and task complexity.
2014	Structuring the space: a study on enriching node-link diagrams with visual references	Exploring large visualizations that do not fit in the screen raises orientation and navigation challenges. Structuring the space with additional visual references such as grids or contour lines provide spatial landmarks that may help viewers form a mental model of the space. However, previous studies report mixed results regarding their utility. While some evidence showed that grid and other visual embellishments improve memorability, experiments with contour lines suggest otherwise. In this work, we describe an evaluation framework to capture the impact of introducing visual references in node-link diagrams. We present the results of three controlled experiments that deepen our understanding on enriching large visualization spaces with visual structures. In particular, we provide the first tangible evidence that contour lines have significant benefits when navigating large node-link diagrams.
2014	What did spot hide?: a question-answering game for preschool children	Early literacy is critical to child development, and determines a child's later educational and life opportunities. Moreover, preschool children are incessantly inquisitive, and will readily engage in question answering and asking activities if given the opportunity. We argue here that question asking/answering technologies can play a major role in early literacy. We describe the design and evaluation of a conversational agent called Spot, with the goal of engaging children in a 20-questions game. Towards this goal, we conducted a feasibility study to determine if children's questions are "on-topic" and suitable for ASR/dialogue systems. We evaluated Spot's performance at conducting a game of 20-questions against that of a human partner.
2014	Establishing design guidelines in interactive exercise gaming: preliminary data from two posing studies	Interactive gaming has demonstrated promise as a low-cost, at-home training and fitness instruction alternative. Gaming systems offer convenience and the ability to provide enhanced reporting and progress data if body measurement information is collected effectively. However, commercially available systems today are designed primarily for entertainment and as a result, the quality of instruction delivery and level of involvement may not meet the needs of a user performing a disciplined activity. This paper will look at adapting for occlusion and lack of visibility; learning and orientation; and providing feedback in an effort to determine if there is an ideal visual demonstration delivery that maximizes pose understanding and user self-efficacy, determine whether supplementary modalities are important for instruction, and determine if there is an ideal feedback delivery that promotes pose comprehension, confidence and motivation. This information can provide a guideline for designing clear and supportive, interactive training systems that can engage users, prevent injury and help maintain fitness.
2014	A comparative study about children's and adults' perception of targeted web search engines	In this paper we describe an eye-tracking study where we compare children's and adults' search behavior and perception of search interface elements on search engine results pages (SERPs) during an informational and a navigational search with Google and a search engine for children. Our first results indicate that children employ an exhaustive scanning strategy combined with cued visual jumps. Then they navigate to the next result page and only then modify their query. Adults only scan the first three results, following the F-shaped strategy, and immediately reformulate the query. Children pay less attention to textual summaries and more to thumbnails than adults do. Children take notice of a navigational menu with categories while adults do not.
2014	Exertion in the small: improving differentiation and expressiveness in sports games with physical controls	Many sports video games contain elements such as running or throwing that are based on real-world physical activities, but the translation of these activities to game controllers means that the original physicality is lost. This results in games where players have limited opportunity to improve their physical skills, where there is little differentiation in people's physical abilities, and where skills do not change over the course of a game. To explore ways of adding these elements back into sports games, we developed two games with small-scale physical controls for running and throwing -- one game was a simple running race, and one was a team-based handball-style game called Jelly Polo. In two studies (three track-and-field tournaments for the running game, and a four-week league for Jelly Polo), we observed the effects of physical controls on gameplay. Our studies showed that the physical controls enabled substantial individual differences in running and passing skill, allowed people to increase their expertise over time, and led to fatigue-based changes in performance during a game. Physical controls increased the games' challenge, complexity, and unpredictability, and dramatically improved player interest, expressiveness, and enjoyment. Our work shows that game designers should consider the idea of "exertion in the small" as a way to improve play experience in games based on physical activities.
2014	Rafigh: a living media interface for speech intervention	Digital games can engage children in therapeutic and learning activities. Incorporating living media in these designs can create feelings of empathy and caring in users. We present, Rafigh, a living media interface designed to motivate children with speech disorders to use their speech to care for a living mushroom colony. The mushrooms' growth is used to communicate how much speech is used during interaction.
2014	Pixel-based methods for widget state and style in a runtime implementation of sliding widgets	Pixel-based methods offer unique potential for modifying existing interfaces independent of their underlying implementation. Prior work has demonstrated a variety of modifications to existing interfaces, including accessibility enhancements, interface language translation, testing frameworks, and interaction techniques. But pixel-based methods have also been limited in their understanding of the interface and therefore the complexity of modifications they can support. This work examines deeper pixel-level understanding of widgets and the resulting capabilities of pixel-based runtime enhancements. Specifically, we present three new sets of methods: methods for pixel-based modeling of widgets in multiple states, methods for managing the combinatorial complexity that arises in creating a multitude of runtime enhancements, and methods for styling runtime enhancements to preserve consistency with the design of an existing interface. We validate our methods through an implementation of Moscovich et al.'s Sliding Widgets, a novel runtime enhancement that could not have been implemented with prior pixel-based methods.
2014	Movement-based game guidelines	Movement-based digital games are becoming increasingly popular, yet there is limited comprehensive guidance on how to design these games. We present a set of guidelines for movement-based game design that has emerged from our research-based game development practice. These guidelines have been examined and refined by 14 movement-based game design experts with experience in the academic, independent and commercial game development domains. We contextualize the guidelines using current findings about movement-based game and interaction design, taken from both published research papers and game design venues. Our primary contribution is a body of generative intermediate-level knowledge in the design research tradition that is readily accessible and actionable for the design of future movement-based games.
2014	i-dentity: innominate movement representation as engaging game element	Movement-based digital games typically make it clear whose movement representation belongs to which player. In contrast, we argue that selectively concealing whose movement controls which representation can facilitate engaging play experiences. We call this "innominate movement representation" and explore this opportunity through our game "i-dentity", where players have to guess who makes everyone's controller light up based on his/her movements. Our work reveals five dimensions for the design of innominate movement representation: concealing the association between movement and representation; number of represented movements; number of players with representations; location of representation in relation to the body and technical attributes of representation. We also present five strategies for how innominate representation can be embedded into a play experience. With our work we hope to expand the range of digital movement games.
2014	Supporting the creative game design process with exertion cards	Advances in sensing technologies have led to research into exertion games that support physically effortful experiences. Despite the existence of theoretical frameworks that can be used to analyze such exertion experiences, there are few tools to support the hands-on practice of exertion game design. To address this, we present a set of design cards based on the "Exertion Framework", grounded in our experience of creating exertion games for over a decade. We present results demonstrating the value and utility of these Exertion Cards based on our studies of their use in three workshops held over seven sessions with 134 design students and experts. We also articulate lessons learned from transforming a theoretical framework into a design tool that aims to support designers in their practice.
2014	Effects of balancing for physical abilities on player performance, experience and self-esteem in exergames	Game balancing can help players with different skill levels play multiplayer games together; however, little is known about how the balancing approach affects performance, experience, and self-esteem'especially when differences in player strength result from given abilities, rather than learned skill. We explore three balancing approaches in a dance game and show that the explicit approach commonly used in commercial games reduces self-esteem and feelings of relatedness in dyads, whereas hidden balancing improves self-esteem and reduces score differential without affecting game outcome. We apply our results in a second study with dyads where one player had a mobility disability and used a wheelchair. By making motion-based games accessible for people with different physical abilities, and by enabling people with mobility disabilities to compete on a par with able-bodied peers, we show how to provide empowering experiences through enjoyable games that have the potential to increase physical activity and self-esteem.
2014	The usability of CommandMaps in realistic tasks	CommandMaps are a promising interface technique that flattens command hierarchies and exploits human spatial memory to provide rapid access to commands. CommandMaps have performed favorably in constrained cued-selection studies, but have not yet been tested in the context of real tasks. In this paper we present two real-world implementations of CommandMaps: one for Microsoft Word and one for an image editing program called Pinta. We use these as our experimental platforms in two experiments. In the first, we show that CommandMaps demonstrate performance and subjective advantages in a realistic task. In the second, we observe naturalistic use of CommandMaps over the course of a week, and gather qualitative data from interviews, questionnaires, and conversations. Our results provide substantial insight into users' reactions to CommandMaps, showing that they are positively received by users and allowing us to provide concrete recommendations to designers regarding when and how they should be implemented in real applications.
2014	WADE: simplified GUI add-on development for third-party software	We present the WADE Integrated Development Environment (IDE), which simplifies interface and functionality modification of existing third-party software without access to source code. WADE clones the Graphical User Interface (GUI) of a host program through dynamic-link library (DLL) injection, enabling modifications to (1) the GUI in a WYSIWYG fashion and (2) software functionality. We compare WADE with an alternative state-of-the-art runtime toolkit overloading approach in a user-study, whose results demonstrate that WADE significantly simplifies the task of GUI-based add-on development.
2014	On the selection of 2D objects using external labeling	We present an external labeling laid over small and/or overlapping 2D objects as an efficient representation for their selection. The approximation of objects with points allows us to transform the labeling problem to graph layout problem, which we solve by means of force-based algorithm. The input parameters allow us to influence the resulting layout of label boxes (e.g. to adapt their distance for imprecise input devices). In a study with 15 participants two implementations of our algorithm were compared against labeling method, where all label boxes share the same offset from corresponding objects. The results of the study show that implementation using a special functionality (temporary freezing of the label box position recalculation) was 14% faster with a comparable accuracy. The subjective evaluation revealed that the implementation with temporary freezing is perceived as most comfortable, fastest and most accurate. The implementation without temporary freezing showed much higher error rate and cannot be recommended.
2014	Novice use of a predictive human performance modeling tool to produce UI recommendations	This note describes two studies of the use of a performance modeling tool, CogTool, for making recommendations to improve a user interface. The first study replicates findings by Bonnie John [7]: the rates at which novice modelers made correct recommendations (88.1%) and supported them (68.2%) are close to the values in John's study (91.7% and 75.1%, respectively). A follow-on study of novice modelers on the same task without CogTool produced sig-nificantly lower values. CogTool improves the UI design recommendations made by novices.
2014	The patchworks code editor: toward faster navigation with less code arranging and fewer navigation mistakes	Increasingly, people are faced with navigating large information spaces, and making such navigation efficient is of paramount concern. In this paper, we focus on the problems programmers face in navigating large code bases, and propose a novel code editor, Patchworks, that addresses the problems. In particular, Patchworks leverages two new interface idioms - the patch grid and the ribbon - to help programmers navigate more quickly, make fewer navigation errors, and spend less time arranging their code. To validate Patchworks, we conducted a user study that compared Patchworks to two existing code editors: the traditional file-based editor, Eclipse, and the newer canvas-based editor, Code Bubbles. Our results showed (1) that programmers using Patchworks were able to navigate significantly faster than with Eclipse (and comparably with Code Bubbles), (2) that programmers using Patchworks made significantly fewer navigation errors than with Code Bubbles or Eclipse, and (3) that programmers using Patchworks spent significantly less time arranging their code than with Code Bubbles (and comparably with Eclipse).
2014	Causing commotion with a shape-changing bench: experiencing shape-changing interfaces in use	In this paper we describe results from testing coMotion, a shape-changing bench, in three different contexts: a concert hall foyer, an airport departure hall and a shopping mall. We have gathered insights from more than 120 people, with regard to how users experience and make sense of the bench's shape changing capability. The paper applies McCarthy and Wright's six different sense making processes ( anticipating, connecting, interpreting, reflecting, appropriating and recounting ) as an instrument to analyse people's experience with shape-changing furniture in the wild. The paper also introduces exploring as a seventh sense making process. Based on this analysis, the paper points to three relevant aspects when designing shape-changing artefacts for the wild, namely: 1) Affordance of shape-changing interfaces, 2) Transitions between background and foreground and 3) Interpreting physically dynamic objects.
2014	GaitAssist: a daily-life support and training system for parkinson's disease patients with freezing of gait	Patients with Parkinson's disease often experience freezing of gait, which bears a high risk of falling, a prevalent cause for morbidity and mortality. In this work we present GaitAssist, a wearable system for freezing of gait support in daily life. The system provides real-time auditory cueing after the onset of freezing episodes. Furthermore, GaitAssist implements training exercises to learn how to handle freezing situations. GaitAssist is the result of a design process where we considered the input of engineers, clinicians and 18 Parkinson's disease patients, in order to find an optimal trade-off between system wearability and performance. We tested the final system in a user study with 5 additional patients. They reported a reduction in the freezing of gait duration as a result of the auditory stimulation provided, and that they feel the system enhanced their confidence during walking.
2014	Is my phone alive?: a large-scale study of shape change in handheld devices using videos	Shape-changing handheld devices are emerging as research prototypes, but it is unclear how users perceive them and which experiences they engender. The little data we have on user experience is from single prototypes, only covering a small part of the possibilities in shape change. We produce 51 videos of a shape-changing handheld device by systematically varying seven parameters of shape change. In a crowd-sourced study, 187 participants watched the videos and described their experiences using rating scales and free text. We find significant and large differences among parameters of shape change. Shapes that have previously been used for notifications were rated the least urgent; the degree of shape change was found to impact experience more than type of shape change. The experience of shape change was surprisingly complex: hedonic quality were inversely related to urgency, and some shapes were perceived as ugly, yet useful. We discuss how to advance models of shape change and improve research on the experience of shape change.
2014	Paddle: highly deformable mobile devices with physical controls	We present the concept of highly deformable mobile devices that can be transformed into various special-purpose controls in order to bring physical controls to mobile devices. Physical controls have the advantage of exploiting people's innate abilities for manipulating physical objects in the real world. We designed and implemented a prototype, called Paddle, to demonstrate our concept. Additionally, we explore the interaction techniques enabled by this concept and conduct an in-depth study to evaluate our transformable physical controls. Our findings show that these physical controls provide several benefits over traditional touch interaction techniques commonly used on mobile devices.
2014	Smarties: an input system for wall display development	Wall-sized displays can support data visualization and collaboration, but making them interactive is challenging. Smarties allows wall application developers to easily add interactive support to their collaborative applications. It consists of an interface running on touch mobile devices for input, a communication protocol between devices and the wall, and a library that implements the protocol and handles synchronization, locking and input conflicts. The library presents the input as an event loop with callback functions. Each touch mobile has multiple cursor controllers, each associated with keyboards, widgets and clipboards. These controllers can be assigned to specific tasks, are persistent in nature, and can be shared by multiple collaborating users for sharing work. They can control simple cursors on the wall application, or specific content (objects or groups of them). The types of associated widgets are decided by the wall application, making the mobile interface customizable by the wall application it connects to.
2014	Temporal, affective, and embodied characteristics of taste experiences: a framework for design	We present rich descriptions of taste experience through an analysis of the diachronic and synchronic experiences of each of the five basic taste qualities: sweet, sour, salt, bitter, and umami. Our findings, based on a combination of user experience evaluation techniques highlight three main themes: temporality, affective reactions, and embodiment. We present the taste characteristics as a framework for design and discuss each taste in order to elucidate the design qualities of individual taste experiences. These findings add a semantic understanding of taste experiences, their temporality enhanced through descriptions of the affective reactions and embodiment that the five basic tastes elicit. These findings are discussed on the basis of established psychological and behavioral phenomena, highlighting the potential for taste-enhanced design.
2014	Opportunities for odor: experiences with smell and implications for technology	Technologies for capturing and generating smell are emerging, and our ability to engineer such technologies and use them in HCI is rapidly developing. Our understanding of how these technologies match the experiences with smell that people have or want to have is surprisingly limited. We therefore investigated the experience of smell and the emotions that accompany it. We collected stories from 439 participants who described personally memorable smell experiences in an online questionnaire. Based on the stories we developed 10 categories of smell experience. We explored the implications of the categories for smell-enhanced technology design by (a) probing participants to envision technologies that match their smell story and (b) having HCI researchers brainstorm technologies using the categories as design stimuli. We discuss how our findings can benefit research on personal memories, momentary and first time experiences, and wellbeing.
2014	SensaBubble: a chrono-sensory mid-air display of sight and smell	We present SensaBubble, a chrono-sensory mid-air display system that generates scented bubbles to deliver information to the user via a number of sensory modalities. The system reliably produces single bubbles of specific sizes along a directed path. Each bubble produced by SensaBubble is filled with fog containing a scent relevant to the notification. The chrono-sensory aspect of SensaBubble means that information is presented both temporally and multimodally. Temporal information is enabled through two forms of persistence: firstly, a visual display projected onto the bubble which only endures until it bursts; secondly, a scent released upon the bursting of the bubble slowly disperses and leaves a longer-lasting perceptible trace of the event. We report details of SensaBubble's design and implementation, as well as results of technical and user evaluations. We then discuss and demonstrate how SensaBubble can be adapted for use in a wide range of application contexts -- from an ambient peripheral display for persistent alerts, to an engaging display for gaming or education.
2014	TouchTools: leveraging familiarity and skill with physical tools to augment touch interaction	The average person can skillfully manipulate a plethora of tools, from hammers to tweezers. However, despite this remarkable dexterity, gestures on today's touch devices are simplistic, relying primarily on the chording of fingers: one -finger pan, two -finger pinch, four -finger swipe and similar. We propose that touch gesture design be inspired by the manipulation of physical tools from the real world. In this way, we can leverage user familiarity and fluency with such tools to build a rich set of gestures for touch interaction. With only a few minutes of training on a proof-of-concept system, users were able to summon a variety of virtual tools by replicating their corresponding real-world grasps.
2014	Prospective motor control on tabletops: planning grasp for multitouch interaction	Substantial amount of research in Psychology has studied how people manipulate objects in the physical world. This work has unveiled that people show strong signs of prospective motor planning, i.e., they choose initial grasps that avoid uncomfortable end postures and facilitate object manipulation. Interactive tabletops allow their users great flexibility in the manipulation of virtual objects but to our knowledge previous work has never examined whether prospective motor control takes place in this context. To test this, we ran three experiments. We systematically studied how users adapt their grasp when asked to translate and rotate virtual objects on a multitouch tabletop. Our results demonstrate that target position and orientation significantly affect the orientation of finger placement on the object. We analyze our results in the light of the most recent model of planning for manipulating physical objects and identify their implications for the design of tabletop interfaces. \
2014	Quantitative measurement of virtual vs. physical object embodiment through kinesthetic figural after effects	Over the past decade, multi-touch surfaces have become commonplace, with many researchers and practitioners describing the benefits of their natural, physical-like interactions. We present a pair of studies that empirically investigates the psychophysical effects of direct interaction with both physical and virtual artefacts. We use the phenomenon of Kinesthetic Figural After Effects-a change in understanding of the physical size of an object after a period of exposure to an object of different size. Our studies show that, while this effect is robustly reproducible when using physical artefacts, this same effect does not manifest when manipulating virtual artefacts on a direct, multi-touch tabletop display. We contribute quantitative evidence suggesting a psychophysical difference in our response to physical vs. virtual objects, and discuss future research directions to explore measurable phenomena to evaluate the presence of physical-like changes from virtual on-screen objects.
2014	Food messaging: using edible medium for social messaging	Food is more than just a means of survival; it is also a form of communication. In this paper, we investigate the potential of food as a social message carrier (a.k.a., food messaging). To investigate how people accept, use, and perceive food messaging, we conducted exploratory interviews, a field study, and follow-up interviews over four weeks in a large information technology (IT) company. We collected 904 messages sent by 343 users. Our results suggest strong acceptance of food messaging as an alternative message channel. Further analysis implies that food messaging embodies characteristics of both text messaging and gifting. It is preferred in close relationships for its evocation of positive emotions. As the first field study on edible social messaging, our empirical findings provide valuable insights into the uniqueness of food as a message carrier and its capabilities to promote greater social bonding.
2014	Social fabric fitness: the design and evaluation of wearable E-textile displays to support group running	Group exercise has multiple benefits including greater adherence to fitness regimens, increased enjoyment among participants, and enhanced workout intensity. While a large number of technology tools have emerged to support real-time feedback of individual performance, tools to support group fitness are limited. In this paper, we present a set of wearable e-textile displays for running groups called Social Fabric Fitness (SFF) . SFF provides a glanceable, shared screen on the back of the wearer's shirt to increase awareness and motivation of group fitness performance. We discuss parallel prototyping of three designs-one flexible e-ink and two flexible LED-based displays; the selection and refinement of one design; and two evaluations'a field study of 10 running groups and two case studies of running races. Our qualitative findings indicate that SFF improves awareness of individual and group performance, helps groups stay together, and improves in-situ motivation. We close with reflections for future athletic e-textile displays.
2014	Multi-finger chords for hand-held tablets: recognizable and memorable	Despite the demonstrated benefits of multi-finger input, todays gesture vocabularies offer a limited number of postures and gestures. Previous research designed several posture sets, but does not address the limited human capacity of retaining them. We present a multi-finger chord vocabulary, introduce a novel hand-centric approach to detect the identity of fingers on off-the-shelf hand-held tablets, and report on the detection accuracy. A between-subjects experiment comparing "random" to a "categorized" chord-command mapping found that users retained categorized mappings more accurately over one week than random ones. In response to the logical posture-language structure, people adapted to logical memorization strategies, such as 'exclusion', 'order', and 'category', to minimize the amount of information to retain. We conclude that structured chord-command mappings support learning, short-, and long-term retention of chord- command mappings.
2014	The personal cockpit: a spatial interface for effective task switching on head-worn displays	As wearable computing goes mainstream, we must improve the state of interface design to keep users productive with natural-feeling interactions. We present the Personal Cockpit, a solution for mobile multitasking on head-worn displays. We appropriate empty space around the user to situate virtual windows for use with direct input. Through a design-space exploration, we run a series of user studies to fine-tune our layout of the Personal Cockpit. In our final evaluation, we compare our design against two baseline interfaces for switching between everyday mobile applications. This comparison highlights the deficiencies of current view-fixed displays, as the Personal Cockpit provides a 40% improvement in application switching time. We demonstrate of several useful implementations and a discussion of important problems for future implementation of our design on current and near-future wearable devices.
2014	A low-cost transparent electric field sensor for 3d interaction on mobile devices	We contribute a thin, transparent, and low-cost design for electric field sensing, allowing for 3D finger and hand tracking and gestures on mobile devices. Our approach requires no direct instrumentation of the hand or body, and is non-optical, allowing for a compact form-factor that is resilient to ambient illumination. Our simple driver electronics are based on an off-the-shelf chip that removes the need for building custom analog electronics. We describe the design of our transparent electrode array, and present a machine learning algorithm for mapping from signal measurements at the receivers to 3D positions. We demonstrate non-contact motion gestures, and precise 3D hand and finger localization. We conclude by discussing limitations and future work.
2014	Permulin: mixed-focus collaboration on multi-view tabletops	We contribute Permulin, an integrated set of interaction and visualization techniques for multi-view tabletops to support co-located collaboration across a wide variety of collaborative coupling styles. These techniques (1) provide support both for group work and for individual work, as well as for the transitions in-between, (2) contribute sharing and peeking techniques to support mutual awareness and group coordination during phases of individual work, (3) reduce interference during group work on a group view, and (4) directly integrate with conventional multi-touch input. We illustrate our techniques in a proof-of-concept implementation with the two example applications of map navigation and photo collages. Results from two user studies demonstrate that Permulin supports fluent transitions between individual and group work and exhibits unique awareness properties that allow participants to be highly aware of each other during tightly coupled collaboration, while being able to unobtrusively perform individual work during loosely coupled collaboration.
2014	Exploring the use of hand-to-face input for interacting with head-worn displays	We propose the use of Hand-to-Face input, a method to interact with head-worn displays (HWDs) that involves contact with the face. We explore Hand-to-Face interaction to find suitable techniques for common mobile tasks. We evaluate this form of interaction with document navigation tasks and examine its social acceptability. In a first study, users identify the cheek and forehead as predominant areas for interaction and agree on gestures for tasks involving continuous input, such as document navigation. These results guide the design of several Hand-to-Face navigation techniques and reveal that gestures performed on the cheek are more efficient and less tiring than interactions directly on the HWD. Initial results on the social acceptability of Hand-to-Face input allow us to further refine our design choices, and reveal unforeseen results: some gestures are considered culturally inappropriate and gender plays a role in selection of specific Hand-to-Face interactions. From our overall results, we provide a set of guidelines for developing effective Hand-to-Face interaction techniques.
2014	Kinect-taped communication: using motion sensing to study gesture use and similarity in face-to-face and computer-mediated brainstorming	One key difference between face-to-face (F2F) communication and computer-mediated communication (CMC) is the availability of visual cues. It is often assumed that the reduction of visibility in audio and video conferencing may negatively impact the use of gesture to communicate, and thus negatively influence other outcomes. In this paper we "Kinect-taped" F2F and CMC communication in brainstorming groups by using motion sensors to record and analyze group members' hand movements during communication. We investigate how different media influence gesture use and gestural similarity, and how the use of gesture associates with level of understanding and brainstorming performance. Implications to future research and design are discussed.
2014	Is motion capture-based biomechanical simulation valid for HCI studies?: study and implications	Motion-capture-based biomechanical simulation is a non-invasive analysis method that yields a rich description of posture, joint, and muscle activity in human movement. The method is presently gaining ground in sports, medicine, and industrial ergonomics, but it also bears great potential for studies in HCI where the physical ergonomics of a design is important. To make the method more broadly accessible, we study its predictive validity for movements and users typical to studies in HCI. We discuss the sources of error in biomechanical simulation and present results from two validation studies conducted with a state-of-the-art system. Study I tested aimed movements ranging from multitouch gestures to dancing, finding out that the critical limiting factor is the size of movement. Study II compared muscle activation predictions to surface-EMG recordings in a 3D pointing task. The data shows medium-to-high validity that is, however, constrained by some characteristics of the movement and the user. We draw concrete recommendations to practitioners and discuss challenges to developing the method further.
2014	RecoFit: using a wearable sensor to find, recognize, and count repetitive exercises	Although numerous devices exist to track and share exercise routines based on running and walking, these devices offer limited functionality for strength-training exercises. We introduce RecoFit, a system for automatically tracking repetitive exercises - such as weight training and calisthenics - via an arm-worn inertial sensor. Our goal is to provide real-time and post-workout feedback, with no user-specific training and no intervention during a workout. Toward this end, we address three challenges: (1) segmenting exercise from intermittent non-exercise periods, (2) recognizing which exercise is being performed, and (3) counting repetitions. We present cross-validation results on our training data and results from a study assessing the final system, totaling 114 participants over 146 sessions. We achieve precision and recall greater than 95% in identifying exercise periods, recognition of 99%, 98%, and 96% on circuits of 4, 7, and 13 exercises respectively, and counting that is accurate to ±1 repetition 93% of the time. These results suggest that our approach enables a new category of fitness tracking devices.
2014	Designing tangible video games: lessons learned from the sifteo cubes	In this paper, we present a collaborative game designed for Sifteo Cubes, a new tangible interface for multiplayer games. We discuss how this game exploits the platform's interface to transfer some of the game mechanics into the non-digital world, and how this approach affects both the player's experience and the design process. We present the technical limitations encountered during game development and analyze video recordings of play sessions with regard to the play strategies developed by the players. Then, we identify two properties that this game shares with many other games on tangible platforms and discuss how these properties influence both the game design process and the player experience. We advocate that these properties provide players with more freedom and relatedness, while helping to create an easy-to-learn and customizable gameplay, despite their own design limitations.
2014	In-your-face, yet unseen?: improving head-stabilized warnings to reduce reaction time	One unique property of head-mounted displays (HMDs) is that content can easily be displayed at a fixed position within the user's field of view (head-stabilized). This ensures that critical information (e.g. warnings) is continuously visible and can, in principle, be perceived as quickly as possible. We examined this strategy with a physically and visually distracted driver. We ran two consecutive studies in a driving simulator, comparing different warning visualizations in a head-up display (HUD) and a HMD. In an initial study, we found no significant effects of warning type or display technology on the reaction times. In a second study, after modifying our visualization to include a visual reference marker, we found that with only this minor change, reaction times were significantly lower in the HMD when compared to the HUD. Our insights can help others design better head-stabilized notifications.
2014	Binding the material and the discursive with a relational approach of affordances	As Norman's vision of affordances developed twenty-six years ago is unable to address complex challenges faced by today's designers, we outline a view of affordances as discursive relations in HCI design. This argument is framed in the discussion of a larger trend of work beyond the HCI field, the scholarship on relational affordances from the fields of communication and organization studies. Through comparison and interrogation, we maintain a relational approach of affordances that bind the material and the discursive will help us to address design issues such as discursive power, cultural values, performed identities, mediated agency, and articulated voices in this increasingly globalized world and design culturally sensitive technology for transformation and emancipation. With a few cases, this paper deciphers the hidden power relationship of interaction design and suggests ways of we should design for social affordances.
2014	Is once enough?: on the extent and content of replications in human-computer interaction	A replication is an attempt to confirm an earlier study's findings. It is often claimed that research in Human-Computer Interaction (HCI) contains too few replications. To investigate this claim we examined four publication outlets (891 papers) and found 3% attempting replication of an earlier result. The replications typically confirmed earlier findings, but treated replication as a confirm/not-confirm decision, rarely analyzing effect sizes or comparing in depth to the replicated paper. When asked, most authors agreed that their studies were replications, but rarely planned them as such. Many non-replication studies could have corroborated earlier work if they had analyzed data differently or used minimal effort to collect extra data. We discuss what these results mean to HCI, including how reporting of studies could be improved and how conferences/journals may change author instructions to get more replications.
2014	What is a device bend gesture really good for?	Device deformation allows new types of gestures to be used in interaction. We identify that the gesture/use-case pairings proposed by interaction designers are often driven by factors relating improved tangibility, spatial directionality and strong metaphorical bonds. With this starting point, we argue that some of the designs may not make use of the full potential of deformation gestures as continuous, bipolar input techniques. In two user studies, we revisited the basics of deformation input by taking a new systematic look at the question of matching gestures with use cases. We observed comparable levels of UX when using bend input in different continuous bipolar interactions, irrespective of the choice of tangibility, directionality and metaphor. We concluded that device bend gestures use their full potential when used to control continuous bipolar parameters, and when quick reactions are needed. From our studies, we also identify relative strengths of absolute and relative mappings, and report a Fitts' law study for device bending input.
2014	A pool of dreams: facebook, politics and the emergence of a social movement	In this paper we present insights from an empirical analysis of data from an emergent social movement primarily located on a Facebook page to contribute understanding of the conduct of everyday politics in social media and through this open up research agendas for HCI. The analysis focuses on how interactions and contributions facilitated the emergence of a collective with political will. We lay out an exploration of the intrinsic relationship between cultural memories, cultural expression and everyday politics and show how diverging voices co-constructed dynamic collectives capable of political action. We look at how interactions through the Facebook page challenge traditional ways for conceiving politics and the political. We outline possible research agendas in the field of everyday politics, which are sensitive to the everyday acts of resistance enclosed in the ordinary.
2014	CHI 1994-2013: mapping two decades of intellectual progress through co-word analysis	This study employs hierarchical cluster analysis, strategic diagrams and network analysis to map and visualize the intellectual landscape of the CHI conference on Human Computer Interaction through the use of co-word analysis. The study quantifies and describes the thematic evolution of the field based on a total of 3152 CHI articles and their associated 16035 keywords published between 1994 and 2013. The analysis is conducted for two time periods (1994-2003, 2004-2013) and a comparison between them highlights the underlying trends in our community. More significantly, this study identifies the evolution of major themes in the discipline, and highlights individual topics as popular, core, or backbone research topics within HCI.
2014	The turn to practice in HCI: towards a research agenda	This paper argues that a new paradigm for HCI research, which we label the 'practice' perspective, has been emerging in recent years. This stands in contrast to the prevailing mainstream HCI paradigm, which we term the 'interaction' perspective. The 'practice turn', as it has been dubbed in the social sciences, provides a conceptual frame to organize a variety of issues emerging in more recent HCI research. While this approach has been present in certain strands of HCI research for some time, it has not been articulated fully to date. In this paper, we provide a short account of the main tenets of this perspective, and then show how it can illuminate some of the recent debates within HCI. Our argument is one which does not seek to replace extant HCI theories, but rather to provide an alternative, complementary theoretical lens which may illuminate the present confusion among both researchers and practitioners as to the direction of HCI. The paper articulates a set of issues which can help direct HCI research programs, as well as highlighting the potential contribution of the HCI field to this practice approach itself, in terms of a more nuanced understanding of emerging practices.
2014	SurfacePhone: a mobile projection device for single- and multiuser everywhere tabletop interaction	To maintain a mobile form factor, the screen real estate of a mobile device canIn this paper we present SurfacePhone; a novel configuration of a projector phone which aligns the projector to project onto a physical surface to allow tabletop-like interaction in a mobile setup. The projection is created behind the upright standing phone and is touch and gesture-enabled. Multiple projections can be merged to create shared spaces for multi-user collaboration. We investigate this new setup, starting with the concept that we evaluated with a concept prototype. Furthermore we present our technical prototype, a mobile phone case with integrated projector that allows for the aforementioned interaction. We discuss its technical requirements and evaluate the accuracy of interaction in a second user study. We conclude with lessons learned and design guidelines.
2014	Narco emotions: affect and desensitization in social media during the mexican drug war	Social media platforms have emerged as prominent information sharing ecosystems in the context of a variety of recent crises, ranging from mass emergencies, to wars and political conflicts. We study affective responses in social media and how they might indicate desensitization to violence experienced in communities embroiled in an armed conflict. Specifically, we examine three established affect measures: negative affect, activation, and dominance as observed on Twitter in relation to a number of statistics on protracted violence in four major cities afflicted by the Mexican Drug War. During a two year period (Aug 2010 - Dec 2012), while violence was on the rise in these regions, our findings show a decline in negative emotional expression as well as a rise in emotional arousal and dominance in Twitter posts: aspects known to be psychological markers of desensitization. We discuss the implications of our work for behavioral health, facilitating rehabilitation efforts in communities enmeshed in an acute and persistent urban warfare, and the impact on civic engagement.
2014	Shared values/conflicting logics: working around e-government systems	In this paper, we describe results from fieldwork conducted at a social services site where the workers evaluate citizens' applications for food and medical assistance submitted via an e-government system. These results suggest value tensions that result - not from different stakeholders with different values - but from differences among how stakeholders enact the same shared value in practice. In the remainder of this paper, we unpack the distinct and conflicting interpretations or logics of three shared values - efficiency, access, and education. In particular, we analyze what happens when social services workers have ideas about what it means to expand access, increase efficiency, and educate the public that conflict with the logics embedded in the e-government system. By distinguishing between overarching values and specific logics, we provide an analytic framework for exploring value tensions as values are enacted in practice.
2014	Model of visual search and selection time in linear menus	This paper presents a novel mathematical model for visual search and selection time in linear menus. Assuming two visual search strategies, serial and directed, and a pointing sub-task, it captures the change of performance with five fac- tors: 1) menu length, 2) menu organization, 3) target position, 4) absence/presence of target, and 5) practice. The novel aspect is that the model is expressed as probability density distribution of gaze, which allows for deriving total selection time. We present novel data that replicates and extends the Nielsen menu selection paradigm and uses eye-tracking and mouse tracking to confirm model predictions. The same parametrization yielded a high fit to both menu selection time and gaze distributions. The model has the potential to improve menu designs by helping designers identify more effective solutions without conducting empirical studies.
2014	Understanding physical activity through 3D printed material artifacts	In this paper, we advocate a novel approach of representing physical activity in the form of material artifacts. By designing such material representations, we aim to understand what these artifacts might offer in terms of reflecting upon physical activity. For example, what types of affect do material artifacts, representing ones' physical activity create for the user' In order to advance this understanding, we designed a system called SweatAtoms that transforms the physical activity data based on heart rate into 3D printed material artifacts. We conducted an 'in the wild study' by deploying our system in six households where participants were experiencing five different material representations of their physical activity for a period of two weeks each. We found that the material artifacts made participants more conscious about their involvement in physical activity and illustrated different levels of engagement with the artifacts. Along with reporting the gained insights from the deployments, we offer reflections on designing material representations for physical activity. We hope that our work will inspire designers to consider new possibilities afforded by digital fabrication to support user's experience with physical activity by utilizing interactive technologies at our disposal.
2014	MixFab: a mixed-reality environment for personal fabrication	Personal fabrication machines, such as 3D printers and laser cutters, are becoming increasingly ubiquitous. However, designing objects for fabrication still requires 3D modeling skills, thereby rendering such technologies inaccessible to a wide user-group. In this paper, we introduce MixFab, a mixed-reality environment for personal fabrication that lowers the barrier for users to engage in personal fabrication. Users design objects in an immersive augmented reality environment, interact with virtual objects in a direct gestural manner and can introduce existing physical objects effortlessly into their designs. We describe the design and implementation of MixFab, a user-defined gesture study that informed this design, show artifacts designed with the system and describe a user study evaluating the system's prototype.
2014	faBrickation: fast 3D printing of functional objects by integrating construction kit building blocks	We present a new approach to rapid prototyping of functional objects, such as the body of a head-mounted display. The key idea is to save 3D printing time by automatically substituting sub-volumes with standard building blocks'in our case Lego bricks. When making the body for a head-mounted display, for example, getting the optical path right is paramount. Users thus mark the lens mounts as "high-resolution" to indicate that these should later be 3D printed. faBrickator then 3D prints these parts. It also generates instructions that show users how to create everything else from Lego bricks. If users iterate on the design later, faBrickator offers even greater benefit as it allows re-printing only the elements that changed. We validated our system at the example of three 3D models of functional objects. On average, our system fabricates objects 2.44 times faster than traditional 3D printing while requiring only 14 minutes of manual assembly.
2014	Supporting the design and fabrication of physical visualizations	Physical visualizations come in increasingly diverse forms, and are used in domains including art and entertainment, business analytics, and scientific research. However, creating physical visualizations requires laborious craftsmanship and demands expertise in both data visualization and digital fabrication. We present three case studies that illustrate limitations of current visualization fabrication workflows. We then present MakerVis, a prototype tool that integrates the entire process of creating physical visualizations, from data filtering to physical fabrication. Design sessions with three end users demonstrate how tools such as MakerVis can dramatically lower the barriers to producing physical visualizations. Observations and interviews from these sessions highlighted future research areas, including customization support, using material properties to represent data variables, and allowing the reuse of physical data objects in new visualizations.
2014	Towards accurate and practical predictive models of active-vision-based visual search	Being able to predict the performance of interface designs using models of human cognition and performance is a long-standing goal of HCI research. This paper presents recent advances in cognitive modeling which permit increasingly realistic and accurate predictions for visual human-computer interaction tasks such as icon search by incorporating an "active vision" approach which emphasizes eye movements to visual features based on the availability of features in relationship to the point of gaze. A high fidelity model of a classic visual search task demonstrates the value of incorporating visual acuity functions into models of visual performance. The features captured by the high-fidelity model are then used to formulate a model simple enough for practical use, which is then implemented in an easy-to-use GLEAN modeling tool. Easy-to-use predictive models for complex visual search are thus feasible and should be further developed.
2014	Understanding multitasking through parallelized strategy exploration and individualized cognitive modeling	Human multitasking often involves complex task interactions and subtle tradeoffs which might be best understood through detailed computational cognitive modeling, yet traditional cognitive modeling approaches may not explore a sufficient range of task strategies to reveal the true complexity of multitasking behavior. This study proposes a systematic approach for exploring a large number of strategies using a computer-cluster-based parallelized modeling system. The paper demonstrates the efficacy of the approach for investigating and revealing the effects of different microstrategies on human performance, both within and across individuals, for a time-pressured multimodal dual task. The modeling results suggest that multitasking performance is not simply a matter of interleaving cognitive and sensorimotor processing but is instead heavily influenced by the selection of subtask microstrategies.
2014	How does knowing what you are looking for change visual search behavior?	When searching a display, users sometimes know what the target is but sometimes do not. It has generally been assumed that for this latter case people must engage in a deeper semantic evaluation of items during the search process. This idea is central to Information Foraging theory. But do people actually spend longer assessing items when engaged in a semantically demanding search task' We investigate this by having participants locate target items in 16-item menus. Participants were either told exactly what to look for (known-item search) or they were told the category that the target belonged to (semantic search). Participants were faster and more accurate at known-item searches. Eye-movement data show that this was because participants were more likely to skip over items when performing known-item searches. Contrary to expectation, we found limited empirical evidence to support the idea that deeper semantic evaluations of items lead to longer gaze durations (this occurred only when items were arranged very close together). This finding is important because it reveals how people adopt different eye gaze strategies depending on the kind of search activity they are engaged in.
2014	Automated nonlinear regression modeling for HCI	Predictive models in HCI, such as models of user performance, are often expressed as multivariate nonlinear regressions. This approach has been preferred, because it is compact and allows scrutiny. However, existing modeling tools in HCI, along with the common statistical packages, are limited to predefined nonlinear models or support linear models only. To assist researchers in the task of identifying novel nonlinear models, we propose a stochastic local search method that constructs equations iteratively. Instead of predefining a model equation, the researcher defines constraints that guide the search process. Comparison of outputs to published baselines in HCI shows improvements in model fit in seven out of 11 cases. We present a few ways in which the method can help HCI researchers explore modeling problems. We conclude that the approach is particularly suitable for complex datasets that have many predictor variables.
2014	The routines and needs of grandparents and parents for grandparent-grandchild conversations over distance	A variety of systems have been designed to support communication between distance-separated grandparents and grandchildren. Yet there are few studies of the actual conversational routines of these groups as well as the social challenges that might arise as a result of technology usage. To address this gap, we conducted an interview and diary study that explores the conversational practices of distance-separated grandparents and young grandchildren (aged 3-10) from the perspective of the grandparents and parents of the children. Our results describe the focus of grandparent-grandchild conversations and show that grandparent-grandchild communication is not without its challenges: grandparents sometimes feel self-conscious, perceive that parents or children will be annoyed if they ask too many questions, and do not want to interfere too much in their grandchildren's lives. The implication is that designs should attempt to support the conversation routines and needs of grandparents and grandchildren while attempting to mitigate the social challenges.
2014	Growing closer on facebook: changes in tie strength through social network site use	Scientists debate whether people grow closer to their friends through social networking sites like Facebook, whether those sites displace more meaningful interaction, or whether they simply reflect existing ties. Combining server log analysis and longitudinal surveys of 3,649 Facebook users reporting on relationships with 26,134 friends, we find that communication on the site is associated with changes in reported relationship closeness, over and above effects attributable to their face-to-face, phone, and email contact. Tie strength increases with both one-on-one communication, such as posts, comments, and messages, and through reading friends' broadcasted content, such as status updates and photos. The effect is greater for composed pieces, such as comments, posts, and messages than for 'one-click' actions such as 'likes.' Facebook has a greater impact on non-family relationships and ties who do not frequently communicate via other channels.
2014	Captioned photographs in psychosocial aged care: relationship building and boundary work	In this paper we examine the use of a novel social technology to support the provision of formal aged care services to clients who live in their own homes. Social technologies offer enormous potential for enhancing aged care, but research on their use in aged care has largely focused on institutional or informal care settings, rather than formal care in the home. Meanwhile, technologies for aging in place typically focus on monitoring and security, rather than psychosocial support. We conducted a field study in which aged care managers used a photo and message-sharing tool to communicate with clients living in their own homes. Our findings demonstrate that visual and social forms of communication are valuable for supporting psychosocial care-giving, but there are barriers to effectively adopting new communication tools in this setting. Time constraints inhibited care managers' use of the technology, which was also influenced by their efforts to carefully maintain boundaries between their personal and professional lives.
2014	My religious aunt asked why i was trying to sell her viagra: experiences with account hijacking	With so much of our lives digital, online, and not entirely under our control, we risk losing access to our communications, reputation, and data. Recent years have brought a rash of high-profile account compromises, but account hijacking is not limited to high-profile accounts. In this paper, we report results of a survey about people's experiences with and attitudes toward account hijacking. The problem is widespread; 30% of our 294 participants had an email or social networking account accessed by an unauthorized party. Five themes emerged from our results: (1) compromised accounts are often valuable to victims, (2) attackers are mostly unknown, but sometimes known, to victims, (3) users acknowledge some responsibility for keeping their accounts secure, (4) users' understanding of important security measures is incomplete, and (5) harm from account hijacking is concrete and emotional. We discuss implications for designing security mechanisms to improve chances for user adoption.
2014	Protibadi : A platform for fighting sexual harassment in urban Bangladesh	Public sexual harassment has emerged as a large and growing concern in urban Bangladesh, with deep and damaging implications for gender security, justice, and rights of public participation. In this paper we describe an integrated program of ethnographic and design work meant to understand and address such problems. For one year we conducted surveys, interviews, and focus groups around sexual harassment with women at three different universities in Dhaka. Based on this input, we developed " Protibadi ", a web and mobile phone based application designed to report, map, and share women's stories around sexual harassment in public places. In August 2013 the system launched, user studies were conducted, and public responses were monitored to gauge reactions, strengths, and limits of the system. This paper describes the findings of our ethnographic and design-based work, and suggests lessons relevant to other HCI efforts to understand and design around difficult and culturally sensitive problems.
2014	Conductor: enabling and understanding cross-device interaction	The proliferation of inexpensive connected devices has created a situation where a person, at any given moment, is surrounded by interactive computers. Despite this fact, there are very few means by which a user may take advantage of this large number of screens. We present Conductor, a prototype framework which serves as an exemplar for the construction of cross-device applications. We present a series of interaction methods by which users can easily share information, chain tasks across devices, and manage sessions across devices. We also present a cross-device usage scenario which utilizes several cross-device applications built within our prototype framework. We also describe a user study, which helped us to understand how users will take advantage of a large number of devices in support of performance of a sense making task.
2014	StepStream: a school-based pervasive social fitness system for everyday adolescent health	Computer-supported fitness interventions for adolescents have the potential to improve adolescents' attitudes and perceptions about physical activity through peer influence and interpersonal accountability. Past research has explored the potential of interventions based on competition and social-comparison mechanisms. We present a new approach: school-based, pervasive social fitness systems. We describe one such system: StepStream, a pedometer-based microblog we designed and deployed for four weeks with 42 US middle school students. StepStream users improved their attitudes about fitness and increased their sense of social support for fitness. The least-active students also increased their daily activity. We show that our school-based social fitness approach performed comparably in attitude and behavior change to more competitive or direct-comparison systems. These results expand the strategies available computer-supported fitness interventions. Our school-based social fitness approach to everyday adolescent health shows the potential for social computing systems to positively influence offline health behaviors in real-world settings.
2014	Motivating people with chronic pain to do physical activity: opportunities for technology design	Physical activity is important for improving quality of life in people with chronic pain. However, actual or anticipated pain exacerbation, and lack of confidence when doing physical activity, make it difficult to maintain and build towards long-term activity goals. Research guiding the design of interactive technology to motivate and support physical activity in people with chronic pain is lacking. We conducted studies with: (1) people with chronic pain, to understand how they maintained and increased physical activity in daily life and what factors deterred them; and (2) pain-specialist physiotherapists, to understand how they supported people with chronic pain. Building on this understanding, we investigated the use of auditory feedback to address some of the psychological barriers and needs identified and to increase self-efficacy, motivation and confidence in physical activity. We conclude by discussing further design opportunities based on the overall findings.
2014	Investigating the long-term use of exergames in the home with elderly fallers	Rehabilitation has been shown to significantly reduce the risk of falling in older adults. However, low adherence to rehabilitation exercises in the home means that seniors often do not get the therapy that they require. We propose that the use of tailored exergames could encourage adherence to falls rehabilitation in the home, as exergames have proved successful in clinical settings. We describe the results from the first known study to investigate the long-term (12 weeks) use of exergames, designed in close collaboration with elderly users, for falls rehabilitation in the home. Our findings suggest that there is an untapped potential of exergames for home rehabilitation use, as our findings show that there was better adherence to exercise in participants who used the exergames, versus those who used standard care. Finally, we make recommendations for designers, on the design of exergames for the rehabilitation of seniors.
2014	Panelrama: enabling easy specification of cross-device web applications	We present Panelrama, a web-based framework for the construction of applications using distributed user interfaces (DUIs). Our implementation provides developers with low migration costs through built-in mechanisms for the synchronization of a UI state, requiring minimal changes to existing languages. Additionally, we describe a solution to categorize device characteristics and dynamically change UI allocation to best-fit devices. We illustrate the use of Panelrama through three sample applications which demonstrate its support for known interaction methods, we also present the results of a developer study, which validates our belief that cross-device application experiences can be easily implemented using our framework.
2014	Is anyone out there?: unpacking Q&A hashtags on twitter	In addition to posting news and status updates, many Twitter users post questions that seek various types of subjective and objective information. These questions are often labeled with 'Q&A' hashtags, such as #lazyweb or #twoogle. We surveyed Twitter users and found they employ these Q&A hashtags both as a topical signifier (this tweet needs an answer!) and to reach out to those beyond their immediate followers (a community of helpful tweeters who monitor the hashtag). However, our log analysis of thousands of hashtagged Q&A exchanges reveals that nearly all replies to hashtagged questions come from a user's immediate follower network, contradicting users' beliefs that they are tapping into a larger community by tagging their question tweets. This finding has implications for designing next-generation social search systems that reach and engage a wide audience of answerers.
2014	Interactive development of cross-device user interfaces	Current GUI builders provide a design environment for user interfaces that target either a single type or fixed set of devices, and provide little support for scenarios in which the user interface, or parts of it, are distributed over multiple devices. Distributed user interfaces have received increasing attention over the past years. There are different, often model-based, approaches that focus on technical issues. This paper presents XDStudio--a new GUI builder designed to support interactive development of cross-device web interfaces. XDStudio implements two complementary authoring modes with a focus on the design process of distributed user interfaces. First, simulated authoring allows designing for a multi-device environment on a single device by simulating other target devices. Second, on-device authoring allows the design process itself to be distributed over multiple devices, as design and development take place on the target devices themselves. To support interactive development for multi-device environments, where not all devices may be present at design and run-time, XDStudio supports switching between the two authoring modes, as well as between design and use modes, as required. This paper focuses on the design of XDStudio, and evaluates its support for two distribution scenarios.
2014	What if we ask a different question?: social inferences create product ratings faster	Consumer product reviews are the backbone of commerce online. Most commonly, sites ask users for their personal opinions on a product or service. I conjecture, however, that this traditional method of eliciting reviews often invites idiosyncratic viewpoints. In this paper, I present a statistical study examining the differences between traditionally elicited product ratings (i.e., "How do you rate this product'") and social inference ratings (i.e., "How do you think other people will rate this product'"). In 5 of 6 trials, I find that social inference ratings produce the same aggregate product rating as the one produced via traditionally elicited ratings. In all cases, however, social inferences yield less variance . This is significant because using social inference ratings 1) therefore converges on the true aggregate product rating faster, and 2) is a cheap design intervention on the part of existing sites.
2014	Kickables: tangibles for feet	We introduce the concept of tangibles that users can manipulate with their feet. We call them kickables. Unlike traditional tangibles, kickables allow for very large interaction surfaces as kickables reside on the ground. The main benefit of kickables over other foot-based modalities, such as foot touch, is their strong affordance, which we validate in two user studies. This affordance makes kickables well-suited for walk-up installations, such as tradeshows or museum exhibits. We present a custom design as well as five families of standard kickables to help application designers create kickable applications faster. Each family supports multiple standard controls, such as push buttons, switches, dials, and sliders. Each type explores a different design principle, in particular different mechanical constraints. We demonstrate an implementation on our pressure-sensing floor.
2014	GaussBricks: magnetic building blocks for constructive tangible interactions on portable displays	This work describes a novel building block system for tangible interaction design, GaussBricks , which enables real-time constructive tangible interactions on portable displays. Given its simplicity, the mechanical design of the magnetic building blocks facilitates the construction of configurable forms. The form constructed by the magnetic building blocks, which are connected by the magnetic joints, allows users to stably manipulate with various elastic force feedback mechanisms. With an analog Hall-sensor grid mounted to its back, a portable display determines the geometrical configuration and detects various user interactions in real time. This work also introduce several methods to enable shape changing, multi-touch input, and display capabilities in the construction. The proposed building block system enriches how individuals interact with the portable displays physically.
2014	Choice-based preference elicitation for collaborative filtering recommender systems	We present an approach to interactive recommending that combines the advantages of algorithmic techniques with the benefits of user-controlled, interactive exploration in a novel manner. The method extracts latent factors from a matrix of user rating data as commonly used in Collaborative Filtering, and generates dialogs in which the user iteratively chooses between two sets of sample items. Samples are chosen by the system for low and high values of each latent factor considered. The method positions the user in the latent factor space with few interaction steps, and finally selects items near the user position as recommendations. In a user study, we compare the system with three alternative approaches including manual search and automatic recommending. The results show significant advantages of our approach over the three competing alternatives in 15 out of 24 possible parameter comparisons, in particular with respect to item fit, interaction effort and user control. The findings corroborate our assumption that the proposed method achieves a good trade-off between automated and interactive functions in recommender systems.
2014	Wearables and chairables: inclusive design of mobile input and output techniques for power wheelchair users	Power wheelchair users often use and carry multiple mobile computing devices. Many power wheelchair users have some upper body motor impairment that can make using these devices difficult. We believe that mobile device accessibility could be improved through designs that take into account users' functional abilities and take advantage of available space around the wheelchair itself. In this paper we present findings from multiple design sessions and interviews with 13 power wheelchair users and 30 clinicians, exploring the placement and form factor possibilities for input and output on a power wheelchair. We found that many power wheelchair users could benefit from chairable technology that is designed to work within the workspace of the wheelchair, whether worn on the body or mounted on he wheelchair frame. We present participants' preferences for chairable input and output devices, and identify possible design configurations for wearable and chairable devices.
2014	Current and future mobile and wearable device use by people with visual impairments	With the increasing popularity of mainstream wearable devices, it is critical to assess the accessibility implications of such technologies. For people with visual impairments, who do not always need the visual display of a mobile phone, alternative means of eyes-free wearable interaction are particularly appealing. To explore the potential impacts of such technology, we conducted two studies. The first was an online survey that included 114 participants with visual impairments and 101 sighted participants; we compare the two groups in terms of current device use. The second was an interview and design probe study with 10 participants with visual impairments. Our findings expand on past work to characterize a range of trends in smartphone use and accessibility issues therein. Participants with visual impairments also responded positively to two eyes-free wearable device scenarios: a wristband or ring and a glasses-based device. Discussions on projected use of these devices suggest that small, easily accessible, and discreet wearable input could positively impact the ability of people with visual impairments to access information on the go and to participate in certain social interactions.
2014	Visually impaired users on an online social network	In this paper we present the first large-scale empirical study of how visually impaired people use online social networks, specifically Facebook. We identify a sample of 50K visually impaired users, and study the activities they perform, the content they produce, and the friendship networks they build on Facebook. We find that visually impaired users participate on Facebook (e.g. status updates, comments, likes) as much as the general population, and receive more feedback (i.e., comments and likes) on average on their content. By analyzing the content produced by visually impaired users, we find that they share their experience and issues related to vision impairment. We also identify distinctive patterns in their language and technology use. We also show that, compared to other users, visually impaired users have smaller social networks, but such differences have decreased over time. Our findings have implications for improving the utility and usability of online social networks for visually impaired users.
2014	Scalable multi-label annotation	We study strategies for scalable multi-label annotation, or for efficiently acquiring multiple labels from humans for a collection of items. We propose an algorithm that exploits correlation, hierarchy, and sparsity of the label distribution. A case study of labeling 200 objects using 20,000 images demonstrates the effectiveness of our approach. The algorithm results in up to 6x reduction in human computation time compared to the naive method of querying a human annotator for the presence of every object in every image.
2014	The last meter: blind visual guidance to a target	Smartphone apps can use object recognition software to provide information to blind or low vision users about objects in the visual environment. A crucial challenge for these users is aiming the camera properly to take a well-framed picture of the desired target object. We investigate the effects of two fundamental constraints of object recognition -- frame rate and camera field of view -- on a blind person's ability to use an object recognition smartphone app. The app was used by 18 blind participants to find visual targets beyond arm's reach and approach them to within 30 cm. While we expected that a faster frame rate or wider camera field of view should always improve search performance, our experimental results show that in many cases increasing the field of view does not help, and may even hurt, performance. These results have important implications for the design of object recognition systems for blind users.
2014	Finding dependencies between actions using the crowd	Activity recognition can provide computers with the context underlying user inputs, enabling more relevant responses and more fluid interaction. However, training these systems is difficult because it requires observing every possible sequence of actions that comprise a given activity. Prior work has enabled the crowd to provide labels in real-time to train automated systems on-the-fly, but numerous examples are still needed before the system can recognize an activity on its own. To reduce the need to collect this data by observing users, we introduce ARchitect, a system that uses the crowd to capture the dependency structure of the actions that make up activities. Our tests show that over seven times as many examples can be collected using our approach versus relying on direct observation alone, demonstrating that by leveraging the understanding of the crowd, it is possible to more easily train automated systems.
2014	Exploiting thermal reflection for interactive systems	Thermal cameras have recently drawn the attention of HCI researchers as a new sensory system enabling novel interactive systems. They are robust to illumination changes and make it easy to separate human bodies from the image background. Far-infrared radiation, however, has another characteristic that distinguishes thermal cameras from their RGB or depth counterparts, namely thermal reflection . Common surfaces reflect thermal radiation differently than visual light and can be perfect thermal mirrors. In this paper, we show that through thermal reflection, thermal cameras can sense the space beyond their direct field-of-view. A thermal camera can sense areas besides and even behind its field-of-view through thermal reflection. We investigate how thermal reflection can increase the interaction space of projected surfaces using camera-projection systems. We moreover discuss the reflection characteristics of common surfaces in our vicinity in both the visual and thermal radiation bands. Using a proof-of-concept prototype, we demonstrate the increased interaction space for hand-held camera-projection system. Furthermore, we depict a number of promising application examples that can benefit from the thermal reflection characteristics of surfaces.
2014	Combining body pose, gaze, and gesture to determine intention to interact in vision-based interfaces	Vision-based interfaces, such as those made popular by the Microsoft Kinect, suffer from the Midas Touch problem: every user motion can be interpreted as an interaction. In response, we developed an algorithm that combines facial features, body pose and motion to approximate a user's intention to interact with the system. We show how this can be used to determine when to pay attention to a user's actions and when to ignore them. To demonstrate the value of our approach, we present results from a 30-person lab study conducted to compare four engagement algorithms in single and multi-user scenarios. We found that combining intention to interact with a 'raise an open hand in front of you' gesture yielded the best results. The latter approach offers a 12% improvement in accuracy and a 20% reduction in time to engage over a baseline 'wave to engage' gesture currently used on the Xbox 360.
2014	The effects of embodied persuasive games on player attitudes toward people using wheelchairs	People using wheelchairs face barriers in their daily lives, many of which are created by people who surround them. Promoting positive attitudes towards persons with disabilities is an integral step in removing these barriers and improving their quality of life. In this context, persuasive games offer an opportunity of encouraging attitude change. We created a wheelchair-controlled persuasive game to study how embodied interaction can be applied to influence player attitudes over time. Our results show that the game intervention successfully raised awareness for challenges that people using wheelchairs face, and that embodied interaction is a more effective approach than traditional input in terms of retaining attitude change over time. Based on these findings, we provide design strategies for embodied interaction in persuasive games, and outline how our findings can be leveraged to help designers create effective persuasive experiences beyond games.
2014	Haptic turk: a motion platform based on people	Motion platforms are used to increase the realism of virtual interaction. Unfortunately, their size and weight is proportional to the size of what they actuate. We present haptic turk, a different approach to motion platforms that is light and mobile. The key idea is to replace motors and mechanical components with humans. All haptic turk setups consist of a player who is supported by one or more turkers. The player enjoys an interactive experience, such as a flight simulation. The motion in the player's experience is generated by the turkers who manually lift, tilt, and push the player's limbs or torso. To get the timing and force right, timed motion instructions in a format familiar from rhythm games are displayed on turkers' mobile devices, which they attach to the player's body. We demonstrate a range of installations based on mobile phones, projectors, and head-mounted displays. In our user study, participants rated not only the experience as player as enjoyable (6.1/7), but also the experience as a turker (4.4/7). The approach of leveraging humans allows us to deploy our approach anytime anywhere, as we demonstrate by experimentally deploying at an art festival in the Nevada desert.
2014	MisTable: reach-through personal screens for tabletops	We present MisTable, a tabletop system that combines a conventional horizontal interactive surface with personal screens between the user and the tabletop surface. These personal screens, built using fog, are both see-through and reach-through. Being see-through provides direct line of sight of the personal screen and the elements behind it on the tabletop. Being reach-through allows the user to switch from interacting with the personal screen to reaching through it to interact with the tabletop or the space above it. The personal screen allows a range of customisations and novel interactions such as presenting 2D personal contents on the screen, 3D contents above the tabletop or augmenting and relighting tangible objects differently for each user. Besides, having a personal screen for each user allows us to customize the view of each of them according to their identity or preferences. Finally, the personal screens preserve all well-established tabletop interaction techniques like touch and tangible interactions. We explore the challenges in building such a reach-through system through a proof-of-concept implementation and discuss the possibilities afforded by the system.
2014	Spent: changing students' affective learning toward homelessness through persuasive video game play	To investigate whether a persuasive game may serve as a way to increase affective learning about homelessness, this study examined the effects of procedural rhetoric and ethos in a video game designed to put the player in the shoes of an almost-homeless person. Data were collected from 5139 students across four states. Examination revealed that playing the game or doing the reading significantly increased the affective learning score after treatment with the game group scoring 1.57 points higher and the reading group scoring .66 points higher out of a score of 6. Findings indicate that students who played Spent sustained significantly higher scores after three weeks. Overall, findings suggest that when students play a video game that is designed using persuasive mechanics an affective change can be measured empirically.
2014	Incentives to participate in online research: an experimental examination of surprise incentives	The recruitment of participants for online survey research presents many challenges. In this work, we present four experiments examining how two different kinds of "surprise" financial incentives affect the rate of participation in a longitudinal study when participants are initially solicited with either an appeal to intrinsic motivation to participate in research or one that also offers extrinsic financial incentives. We find that unexpected financial incentives ("existence surprises") presented to people who click a recruitment advertisement focused on intrinsic incentives lead to a lower recruitment rate than do the same incentives offered to those who clicked an advertisement that led them to expect it. However, when potential participants expect a financial incentive, surprising them with a higher amount ("amount surprises") yields a higher recruitment rate. We interpret these results in the context of crowding theory. Neither type of surprise affected ongoing participation, measured as the number of questions and questionnaires completed over the course of the study.
2014	Audience experience in social videogaming: effects of turn expectation and game physicality	Videogames are often played socially with both co-players and audiences. Audience members' experiences are not well understood, nor are the factors of videogaming sessions that influence their experience. We conducted a study to examine the effects of game physicality and turn anticipation on audience members' experiences in social videogaming sessions. Pairs of participants played games under three conditions of physicality (controller-based, Wii, and Kinect) and their expectation of turn-taking was manipulated. Their enjoyment, game engagement, social engagement and sense of participation were measured. We found that the introduction of turn-taking into the session had positive effects for audience members -- both anticipated and residual play effects -- and that Kinect gameplay resulted in a more enjoyable experience for audience members. We argue that audience members' experience changes as they become more active within a session, and suggest there are design opportunities between purely active 'players' and passive 'audience members'.
2014	Wave to me: user identification using body lengths and natural gestures	We introduce a body-based identification system that leverages individual differences in body segment lengths and hand waving gesture patterns. The system identifies users based on a two-second hand waving gesture captured by a Microsoft Kinect. To evaluate our system, we collected 8640 gesture measurements from 75 participants through two lab studies and a field study. In the first lab study, we evaluated the feasibility of our concept and basic properties of features to narrow down the design space. In the second lab study, our system achieved a 1% equal error rate in user identification among seven registered users after two weeks following initial registration. We also found that our system was robust even when lower body segments could not be measured because of occlusions. In the field study, our system achieved 0.5 to 1.6% equal error rates, demonstrating that the system also works well in ecologically valid situations. Lastly, throughout the studies, our participants were positive about the system.
2014	Dynamic difficulty using brain metrics of workload	Dynamic difficulty adjustments can be used in human-computer systems in order to improve user engagement and performance. In this paper, we use functional near-infrared spectroscopy (fNIRS) to obtain passive brain sensing data and detect extended periods of boredom or overload. From these physiological signals, we can adapt a simulation in order to optimize workload in real-time, which allows the system to better fit the task to the user from moment to moment. To demonstrate this idea, we ran a laboratory study in which participants performed path planning for multiple unmanned aerial vehicles (UAVs) in a simulation. Based on their state, we varied the difficulty of the task by adding or removing UAVs and found that we were able to decrease error by 35% over a baseline condition. Our results show that we can use fNIRS brain sensing to detect task difficulty in real-time and construct an interface that improves user performance through dynamic difficulty adjustment.
2014	Co-constructing child personas for health-promoting services with vulnerable children	The availability of health-promoting resources for young children diagnosed with cancer who are transitioning from intensive care to everyday life is limited. In the context of designing digital peer support services for children who are considered vulnerable due to clinical and age-related aspects, there are several challenges that put critical requirements on a user-centered design process. This paper reports on a new method for co-constructing child-personas that are tailored for developing health-promoting services where empirical data is restricted due to practical and ethical reasons. In particular, we are proposing to focus children design workshop sessions on salutogenesis, and complement this with a pathogenic perspective by interviewing healthcare professionals and parents. We also introduce the use of proxy personas, and redemption scenarios in the form of comicboards, both collaboratively constructed by children and designers through storytelling. By applying four progressive steps of data collection and analysis we arrive at authentic child-personas that can be used to design and develop health-promoting services for children in vulnerable life stages.
2014	Measuring the effect of think aloud protocols on workload using fNIRS	The Think Aloud Protocol (TAP) is a verbalisation technique widely employed in HCI user studies to give insight into user experience, yet little work has explored the impact that TAPs have on participants during user studies. This paper utilises a brain sensing technique, fNIRS, to observe the effect that TAPs have on participants. Functional Near-Infrared Spectroscopy (fNIRS) is a brain sensing technology that offers the potential to provide continuous, detailed insight into brain activity, enabling an objective view of cognitive processes during complex tasks. Participants were asked to perform a mathematical task under 4 conditions: nonsense verbalisations, passive concurrent think aloud protocol, invasive concurrent think aloud protocol, and a baseline of silence. Subjective ratings and performance measures were collected during the study. Our results provide a novel view into the effect that different forms of verbalisation have on workload during tasks. Further, the results provide a means for estimating the effect of spoken artefacts when measuring workload, which is another step towards our goal of proactively involving fNIRS analysis in ecologically valid user studies.
2014	An EEG-based approach for evaluating audio notifications under ambient sounds	Audio notifications are an important means of prompting users of electronic products. Although useful in most environments, audio notifications are ineffective in certain situations, especially against particular auditory backgrounds or when the user is distracted. Several studies have used behavioral performance to evaluate audio notifications, but these studies failed to achieve consistent results due to factors including user subjectivity and environmental differences; thus, a new method and more objective indicators are necessary. In this study, we propose an approach based on electroencephalography (EEG) to evaluate audio notifications by measuring users' auditory perceptual responses (mismatch negativity) and attention shifting (P3a). We demonstrate our approach by applying it to the usability testing of audio notifications in realistic scenarios, such as users performing a major task amid ambient noises. Our results open a new perspective for evaluating the design of the audio notifications.
2014	Canine-centered interface design: supporting the work of diabetes alert dogs	Many people with Diabetes live with the continuous threat of hypoglycemic attacks and the danger of going into coma. Diabetes Alert Dogs are trained to detect the onset of an attack before the condition of the human handler they are paired with deteriorates, giving them time to take action. We investigated requirements for designing an alarm system allowing dogs to remotely call for help when their human falls unconscious before being able to react to an alert. Through a multispecies ethnographic approach we focus on the requirements for a physical canine user interface, involving dogs, their handlers and specialist dog trainers in the design process. We discuss tensions between the requirements for canine and the human users, argue the need for increased sensitivity towards the needs of individual dogs that goes beyond breed specific physical characteristics, and reflect on how we can move from designing for dogs to designing with dogs.
2014	Balancing design tensions: iterative display design to support ad hoc and multidisciplinary medical teamwork	In this paper, we describe how we developed an information display prototype for trauma resuscitation teams based on design ideas and feedback from clinicians. Our approach is grounded in participatory design, emphasizing the importance of gaining long-term commitment from clinicians in system development. Through a series of participatory design workshops, heuristic evaluation, and simulated resuscitation sessions, we identified the main information features to include on our display. Our results focus on how we balanced the design tensions that emerged when addressing the ad hoc, hierarchical, and multidisciplinary nature of trauma teamwork. We discuss the implications of balancing role-based differences for each information feature, as well as two major design tensions: process-based vs. state-based designs and role-based vs. team-based displays.
2014	Error related negativity in observing interactive tasks	Error Related Negativity is triggered when a user either makes a mistake or the application behaves differently from their expectation. It can also appear while observing another user making a mistake. This paper investigates ERN in collaborative settings where observing another user (the executer) perform a task is typical and then explores its applicability to HCI. We first show that ERN can be detected on signals captured by commodity EEG headsets like an Emotiv headset when observing another person perform a typical multiple-choice reaction time task. We then investigate the anticipation effects by detecting ERN in the time interval when an executer is reaching towards an answer. We show that we can detect this signal with both a clinical EEG device and with an Emotiv headset. Our results show that online single trial detection is possible using both headsets during tasks that are typical of collaborative interactive applications. However there is a trade-off between the detection speed and the quality/prices of the headsets. Based on the results, we discuss and present several HCI scenarios for use of ERN in observing tasks and collaborative settings.
2014	Diversity for design: a framework for involving neurodiverse children in the technology design process	The neurodiversity movement seeks to positively reframe certain neurological conditions, such as autism spectrum disorders (ASD) and dyslexia, by concentrating on their strengths. In recent years, neurodiverse children have increasingly been involved in the technology design process, but the design approaches adopted have focused mostly on overcoming difficulties of working with these children, leaving their strengths untapped. We present a new participatory design (PD) framework, Diversity for Design (D4D), which provides guidance for technology designers working with neurodiverse children in establishing PD methods that capitalize on children's strengths and also support potential difficulties. We present two case studies of use of the D4D framework, involving children with ASD and dyslexia, showing how it informed the development and refinement of PD methods tailored to these populations. In addition, we show how to apply the D4D framework to other neurodiverse populations.
2014	Improving machine translation by showing two outputs	We propose to improve real-time communication between people who do not share a common language by foregrounding potential problems in machine translation. We developed a prototype chat tool that displays two parallel translations of each chat turn, with the thought that comparing the translations might both highlight problems and provide resources for resolving them. We conducted a user study to investigate how people use and like such an interface compared to a standard one-translation interface. On balance, users preferred two translations to one, using them to both notice differences and infer meaning from uncertain translations, with no increase in workload. This suggests that this interface may help improve cross-lingual communication in practical applications and lays the groundwork for a larger design space around systems that highlight possible errors to support communication.
2014	Exploring the design space of gestural interaction with active tokens through user-defined gestures	Multi-touch and tangible interfaces provide unique opportunities for enhancing learning and discovery with big data. However, existing interaction techniques have limitations when manipulating large data sets. Our goal is to define novel interaction techniques for multi-touch and tangible interfaces, which support the construction of complex queries for big data. In this paper, we present results from a study which investigates the use of gestural interaction with active tokens for manipulating large data sets. In particular, we studied user expectations of a hybrid tangible and gestural language engaging this space. Our main results include a vocabulary of user-defined gestures for interaction with active tokens, which extends beyond familiar multi-touch gestures; characterization of the design space of gestural interaction with active tokens; and insight into participants' mental models, including common metaphors. We also present implications for the design of multi-touch and tangible interfaces with active tokens.
2014	Stewarding a legacy: responsibilities and relationships in the management of post-mortem data	This paper extends research on the giving and inheriting of digital artifacts by examining social network site accounts post-mortem. Given the important role that social network sites play in online bereavement practices, we conducted a series of in-depth qualitative interviews to explore issues around inheritance and post-mortem data management of Facebook accounts. We found that participants focused less on ownership of the data, and instead on the duties and potential conflicts associated with maintaining an account post-mortem. Subsequently, we argue for 'stewardship' as an alternative to inheritance for framing post-mortem data management practices. Analysis of post-mortem data management activities highlights how stewards are accountable and responsible to the deceased and various survivors. However, weighing competing responsibilities is complicated by varied relationships with disparate survivors, as well as the inability to consult with the deceased. Based on our findings, we claim that post-mortem solutions need to account for the needs of stewards in addition to those of the deceased and survivors. We suggest that a model of stewardship better accounts for the interpersonal responsibilities that accompany online data than inheritance alone.
2014	Effects of display size and navigation type on a classification task	The advent of ultra-high resolution wall-size displays and their use for complex tasks require a more systematic analysis and deeper understanding of their advantages and drawbacks compared with desktop monitors. While previous work has mostly addressed search, visualization and sense-making tasks, we have designed an abstract classification task that involves explicit data manipulation. Based on our observations of real uses of a wall display, this task represents a large category of applications. We report on a controlled experiment that uses this task to compare physical navigation in front of a wall-size display with virtual navigation using pan-and-zoom on the desktop. Our main finding is a robust interaction effect between display type and task difficulty: while the desktop can be faster than the wall for simple tasks, the wall gains a sizable advantage as the task becomes more difficult. A follow-up study shows that other desktop techniques (overview+detail, lens) do not perform better than pan-and-zoom and are therefore slower than the wall for difficult tasks.
2014	Bigger is not always better: display size, performance, and task load during peephole map navigation	Dynamic peephole navigation is an increasingly popular technique for navigating large information spaces such as maps. Users can view the map through handheld, spatially aware displays that serve as peepholes and navigate the map by moving these displays in physical space. We conducted a controlled experiment of peephole map navigation with 16 participants to better understand the effect of a peephole's size on users' map navigation behavior, navigation performance, and task load. Simulating different peephole sizes from 4' (smartphone) up to 120' (control condition), we confirmed that larger peepholes significantly improve learning speed, navigation speed, and reduce task load; however, this added benefit diminishes with growing sizes. Our data shows that a relatively small, tablet-sized peephole can serve as a 'sweet spot' between peephole size and both user navigation performance and user task load.
2014	Mechanical force redistribution: enabling seamless, large-format, high-accuracy surface interaction	We present Mechanical Force Redistribution (MFR): a method of sensing which creates an anti-aliased image of forces applied to a surface. This technique mechanically focuses the force from a surface onto adjacent discrete forcels (force sensing cells) by way of protrusions (small bumps or pegs), allowing for high-accuracy interpolation between adjacent discrete forcels. MFR works with any force transducing technique or material, including force variable resistive inks, piezoelectric materials and capacitive force plates. MFR sensors can be tiled such that the signal is continuous across contiguous tiles. By minimizing active materials and computational complexity, MFR makes large-format interactive walls, collaborative tabletops and high-resolution floor tiles possible and economically feasible.
2014	Making big gestures: effects of gesture size on observability and identification for co-located group awareness	Co-located work environments allow people to maintain awareness by observing others' actions (called consequen-tial communication), but the computerization of many tasks has dramatically reduced the observability of work actions. The recent interest in gestural interaction techniques offers the possibility of recreating some of the noticeability of previous work actions, but little is known about the observability and identifiability of command gestures. To investigate these basic issues, we carried out a study that asked people to observe and identify different sizes and morphologies of gestures from different locations, while carrying out an attention-demanding primary task. We studied small (tablet sized), medium (monitor-sized), and large (full-arm) gestures. Our study showed that although size did have significant effects, as expected, even small gestures were highly noticeable (rates above 75%) and identifiable (rates above 69%). Our results provide empirical guidance about the ways that gesture size, morphology, and location affect observation, and show that gestural interaction has potential for improving group awareness in co-located environments.
2014	Multi-viewer gesture-based interaction for omni-directional video	Omni-directional video (ODV) is a novel medium that offers viewers a 360º panoramic recording. This type of content will become more common within our living rooms in the near future, seeing that immersive displaying technologies such as 3D television are on the rise. However, little attention has been given to how to interact with ODV content. We present a gesture elicitation study in which we asked users to perform mid-air gestures that they consider to be appropriate for ODV interaction, both for individual as well as collocated settings. We are interested in the gesture variations and adaptations that come forth from individual and collocated usage. To this end, we gathered quantitative and qualitative data by means of observations, motion capture, questionnaires and interviews. This data resulted in a user-defined gesture set for ODV, alongside an in-depth analysis of the variation in gestures we observed during the study.
2014	Pervasive information through constant personal projection: the ambient mobile pervasive display (AMP-D)	The vision of pervasive ambient information displays which show relevant information has not yet come true. One of the main reasons is the limited number of available displays in the environment which is a fundamental requirement of the original vision. We introduce the concept of an Ambient Mobile Pervasive Display AMP-D which is a wearable projector system that constantly projects an ambient information display in front of the user. The floor display provides serendipitous access to public and personal information. The display is combined with a projected display on the user's hand, forming a continuous interaction space that is controlled by hand gestures. The paper introduces this novel device concept, discusses its interaction design, and explores its advantages through various implemented application examples. Furthermore, we present the AMP-D prototype which illustrates the involved challenges concerning hardware, sensing, and visualization.
2014	A chair as ubiquitous input device: exploring semaphoric chair gestures for focused and peripheral interaction	During everyday office work we are used to controlling our computers with keyboard and mouse, while the majority of our body remains unchallenged and the physical workspace around us stays largely unattended. Addressing this untapped potential, we explore the concept of turning a flexible office chair into a ubiquitous input device. To facilitate daily desktop work, we propose the utilization of semaphoric chair gestures that can be assigned to specific application functionalities. The exploration of two usage scenarios in the context of focused and peripheral interaction demonstrates high potential of chair gestures as additional input modality for opportunistic, hands-free interaction.
2014	Expanding touch input vocabulary by using consecutive distant taps	In recent years, touch screens have emerged and matured as the main input interface for mobile and tablet computers calling for extended touch input possibilities. In this paper, we explore the use of consecutive distant taps to expand the touch screen input vocabulary. We analyzed time intervals and distances between consecutive taps during common applications on a tablet and verified that consecutive distant taps can be used conflict-free with existing touch gestures. We designed the two interaction techniques Ta-tap and Ta-Ta-tap that utilize consecutive distant taps. Ta-tap uses two consecutive distant taps to invoke alternative touch operations for multi-touch emulation, whereas Ta-Ta-tap uses a series of consecutive distant taps to define a spatial gesture. We verified the feasibility of both interaction techniques through a series of experiments and a user study. The high recognition rate of Ta-tap and Ta-Ta-tap gestures, the few conflicts with existing gestures, and the positive feedback from the participants assert the potential of consecutive distant taps as a new design space to enrich touch screen interactions.
2014	Towards crowd-based customer service: a mixed-initiative tool for managing Q&A sites	In this paper, we propose a mixed-initiative approach to integrate a Q&A site based on a crowd of volunteers with a standard operator-based help desk, ensuring quality of customer service. Q&A sites have emerged as an efficient way to address questions in various domains by leveraging crowd knowledge. However, they lack sufficient reliability to be the sole basis of customer service applications. We built a proof-of-concept mixed-initiative tool that helps a crowd-manager to decide if a question will get a satisfactory and timely answer by the crowd or if it should be redirected to a dedicated operator. A user experiment found that our tool reduced the participants' cognitive load and improved their performance, in terms of their precision and recall. In particular, those with higher performance benefited more than those with lower performance.
2014	Crossing-based selection with direct touch input	Fundamental performance results for crossing-based selec-tion tasks with direct touch input are presented. A close adaptation of Accot and Zhai's indirect stylus crossing ex-periment reveals similar trends for direct touch input: touch crossing task time is faster or equivalent to touch pointing; continuous selection of large orthogonal crossing targets is most effective; and continuous selection of small collinear targets is least effective. Unlike indirect stylus and mouse crossing, not every kind of direct touch pointing perfor-mance is modeled accurately with standard Fitts' law. Instead, Fitts' law, used previously for touch pointing with small targets, is used to more accurately model discrete touch crossing with a directionally constrained target. In addition, visual touch feedback is shown to have a strong effect on absolute accuracy. Our work empirically validates touch crossing as a practical and efficient selection technique, and motivates the exploration of novel forms of expressive multi-touch crossing.
2014	Understanding sustained community engagement: a case study in heritage preservation in rural argentina	HCI projects are increasingly evaluating technologies in the wild, which typically involves working with communities over extended periods, often with the goal of effecting sustainable change. However, there are few descriptions of projects that have been successful in the long-term. In this paper we investigate what factors are important for developing long lasting community ICT interventions. We do this by analysing a successful action research project and provide five recommendations for facilitating sustained community engagement. CrowdMemo aimed to preserve local heritage in a town in rural Argentina and the project was set up so that it could be continued by the community once researchers had left. Participants created videos about personal memories of the town and over 600 people attended the premiere where they were first screened. The impact has not just been short-term and there has been sustained engagement with the project by stakeholders in the town and wider region: the local school integrated digital storytelling into its curriculum; the approach has been adopted by two nearby towns; and the project has influenced regional government educational policy.
2014	Human values in curating a human rights media archive	Cultural institutions, such as museums, often curate politically and ethically sensitive materials. Increasingly, Internet-enabled, digital technology intersects with these curatorial practices offering new opportunities for public and scholarly engagement. We report on a case study of human rights media archiving at a genocide memorial centre in Rwanda, motivated by our interests in ICT support to memorialisation practices. Through an analysis of our discussions with staff about their work, we report on how accounts of the Rwandan Genocide are being captured and curated to support the centre's humanitarian agenda and associated values. We identify transferable curatorial concerns for human rights media communication amongst scholarly networks and public audiences worldwide, elucidating interaction design challenges for supportive ICT and contributing to HCI discourses on Value Sensitive Design and cultural engagement with sensitive materials.
2014	How technology supports family communication in rural, suburban, and urban kenya	Much ICTD research for sub-Saharan Africa has focused on how technology related interventions have aimed to incorporate marginalized communities towards global economic growth. Our work builds on this. We present results from an exploratory qualitative study on the family communication practices of family members who communicate both within and between rural, suburban, and urban settings in Kenya. Our findings reveal that family communication focuses on economic support, well-being, life advice, and everyday coordination of activities. We also outline social factors that affect family communication, including being an eldest child, having a widowed sibling, and having reduced access to technology because of gender, literacy, or one's financial situation. Lastly, we discuss new opportunities for technology design and articulate the challenges that designers will face if creating or deploying family communication technologies in Kenya.
2014	Estimating the social costs of friendsourcing	Every day users of social networking services ask their followers and friends millions of questions. These friendsourced questions not only provide informational benefits, but also may reinforce social bonds. However, there is a limit to how much a person may want to friendsource. They may be uncomfortable asking questions that are too private, might not want to expend others' time or effort, or may feel as though they have already accrued too many social debts. These perceived social costs limit the potential benefits of friendsourcing. In this paper we explore the perceived social costs of friendsourcing on Twitter via a monetary choice. We develop a model of how users value the attention and effort of their social network while friendsourcing, compare and contrast it with paid question answering in a crowdsourced labor market, and provide future design considerations for better supporting friendsourcing.
2014	Expert voices in echo chambers: effects of source expertise indicators on exposure to diverse opinions	We studied how a source expertise indicator impacted users' information seeking behavior when using a system aggregating diverse opinions, and how it interacted with a source position indicator to shape users' selectivity of information. We found that, for both attitude consistent and inconsistent information, the expertise indicator increased the selection of sources indicated to have high expertise and decreased that of low expertise. Moreover, when both source expertise and position indicators were present, users' selective exposure tendency, i.e., preferential selection of attitude consistent sources over inconsistent ones, decreased among expert sources. Moreover, we found that the expertise indicator could benefit encouraging common ground seeking with different others by increasing the agreement with, and perceived expertise of inconsistent sources indicated to be experts. Design implications for moderating selective exposure by highlighting the utility of dissonant information were discussed.
2014	Experimenting at scale with google chrome's SSL warning	Web browsers show HTTPS authentication warnings (i.e., SSL warnings) when the integrity and confidentiality of users' interactions with websites are at risk. Our goal in this work is to decrease the number of users who click through the Google Chrome SSL warning. Prior research showed that the Mozilla Firefox SSL warning has a much lower click-through rate (CTR) than Chrome. We investigate several factors that could be responsible: the use of imagery, extra steps before the user can proceed, and style choices. To test these factors, we ran six experimental SSL warnings in Google Chrome 29 and measured 130,754 impressions.
2014	Betrayed by updates: how negative experiences affect future security	Installing security-relevant software updates is one of the best computer protection mechanisms. However, users do not always choose to install updates. Through interviewing non-expert Windows users, we found that users frequently decide not to install future updates, regardless of whether they are important for security, after negative experiences with past updates. This means that even non-security updates (such as user interface changes) can impact the security of a computer. We discuss three themes impacting users' willingness to install updates: unexpected new features in an update, the difficulty of assessing whether an update is ``worth it', and confusion about why an update is necessary.
2014	Utilising insight journalism for community technology design	We describe the process of insight journalism , in which local amateur journalists were used to generate unique insights into the digital needs of a community. We position this as a means for communities to represent themselves to designers, both as a method of designing community technologies and as a first step towards supporting innovation at a local level. To demonstrate insight journalism, we present two case studies of community technologies that were directly inspired, informed and evaluated by journalistic content. Based on this experience, we evaluate the role that insight journalism can play in designing for communities, the particular characteristics that it lends to the design process and how it might be employed to support sustainable community innovation.
2014	Bored mondays and focused afternoons: the rhythm of attention and online activity in the workplace	While distractions using digital media have received attention in HCI, understanding engagement in workplace activities has been little explored. We logged digital activity and continually probed perspectives of 32 information workers for five days in situ to understand how attentional states change with context. We present a framework of how engagement and challenge in work relate to focus, boredom, and rote work. Overall, we find more focused attention than boredom in the workplace. Focus peaks mid-afternoon while boredom is highest in early afternoon. People are happiest doing rote work and most stressed doing focused work. On Mondays people are most bored but also most focused. Online activities are associated with different attentional states, showing different patterns at beginning and end of day, and before and after a mid-day break. Our study shows how rhythms of attentional states are associated with context and time, even in a dynamic workplace environment.
2014	NewsViews: an automated pipeline for creating custom geovisualizations for news	Interactive visualizations add rich, data-based context to online news articles. Geographic maps are currently the most prevalent form of these visualizations. Unfortunately, designers capable of producing high-quality, customized geovisualizations are scarce. We present NewsViews, a novel automated news visualization system that generates interactive, annotated maps without requiring professional designers. NewsViews' maps support trend identification and data comparisons relevant to a given news article. The NewsViews system leverages text mining to identify key concepts and locations discussed in articles (as well as potential annotations), an extensive repository of 'found' databases, and techniques adapted from cartography to identify and create visually 'interesting' thematic maps. In this work, we develop and evaluate key criteria in automatic, annotated, map generation and experimentally validate the key features for successful representations (e.g., relevance to context, variable selection, 'interestingness' of representation and annotation quality).
2014	Large-scale assessment of mobile notifications	Notifications are a core feature of mobile phones. They inform users about a variety of events. Users may take immediate action or ignore them depending on the importance of a notification as well as their current context. The nature of notifications is manifold, applications use them both sparsely and frequently. In this paper we present the first large-scale analysis of mobile notifications with a focus on users' subjective perceptions. We derive a holistic picture of notifications on mobile phones by collecting close to 200 million notifications from more than 40,000 users. Using a data-driven approach, we break down what users like and dislike about notifications. Our results reveal differences in importance of notifications and how users value notifications from messaging apps as well as notifications that include information about people and events. Based on these results we derive a number of findings about the nature of notifications and guidelines to effectively use them.
2014	Interrupted by a phone call: exploring designs for lowering the impact of call notifications for smartphone users	Mobile phones have evolved significantly in recent years from single-purpose communication devices to multi-purpose computing devices. Despite this evolution, the interaction model for how incoming calls are handled has barely changed. Current-generation smartphones still use abrupt full-screen notifications to alert users to incoming calls, demanding a decision to either accept or decline the call. These full-screen notifications forcibly interrupt whatever activity the user was already engaged in. This might be undesirable when the user's primary task was more important than the incoming call. This paper explores the design space for how smartphones can alert users to incoming calls. We consider designs that allow users to postpone calls and also to multiplex by way of a smaller partial-screen notification. These design alternatives were evaluated in both a small-scale controlled lab study as well as a large-scale naturalistic in-the-wild study. Results show that a multiplex design solution works best because it allows people to continue working on their primary task while being made aware that there is a caller on the line. The contribution of this work is an enhanced interaction design for handling phone calls, and an understanding of how people use it for handling incoming calls.
2014	Finding real people: trust and diversity in the interface between professional and citizen journalists	The increase of social media and web blogs has enabled a new generation of citizen journalism to provide new perspectives into local communities. However traditional news organisations are currently struggling to incorporate this new form of journalism into their existing organisational workflow. We present an analysis from 10 interviews with professional journalists and explore the current issues faced by professional journalists when searching for reliable and reputable local news sources as well as the perceived role of citizen journalists within a large news organisation. From this analysis we present a set of design implications for building systems that support interaction between citizen and professional journalists in order to encourage participatory news production and diversify national news perspectives.
2014	Structured labeling for facilitating concept evolution in machine learning	Labeling data is a seemingly simple task required for training many machine learning systems, but is actually fraught with problems. This paper introduces the notion of concept evolution , the changing nature of a person's underlying concept (the abstract notion of the target class a person is labeling for, e.g., spam email, travel related web pages) which can result in inconsistent labels and thus be detrimental to machine learning. We introduce two structured labeling solutions, a novel technique we propose for helping people define and refine their concept in a consistent manner as they label. Through a series of five experiments, including a controlled lab study, we illustrate the impact and dynamics of concept evolution in practice and show that structured labeling helps people label more consistently in the presence of concept evolution than traditional labeling.
2014	CRISP: an interruption management algorithm based on collaborative filtering	Interruptions can have a significant impact on users working to complete a task. When people are collaborating, either with other users or with systems, coordinating interruptions is an important factor in maintaining efficiency and preventing information overload. Computer systems can observe user behavior, model it, and use this to optimize the interruptions to minimize disruption. However, current techniques often require long training periods that make them unsuitable for online collaborative environments where new users frequently participate. In this paper, we present a novel synthesis between Collaborative Filtering methods and machine learning classification algorithms to create a fast learning algorithm, CRISP. CRISP exploits the similarities between users in order to apply data from known users to new users, therefore requiring less information on each person. Results from user studies indicate the algorithm significantly improves users' performances in completing the task and their perception of how long it took to complete each task.
2014	Customization bias in decision support systems	Many Decision Support Systems (DSS) afford customization of inputs or algorithms before generating recommendations to a decision maker. This paper describes an experiment in which users make decisions assisted by recommendations of a DSS in a fantasy baseball game. This experiment shows that the act of customizing a DSS can lead to biased decision making. I show that users who believe they have customized a DSS's recommendation algorithm are more likely to follow the recommendations regardless of their accuracy. I also show that this customization bias is the result of using a DSS to seek confirmatory information in a recommendation.
2014	Using extracted features to inform alignment-driven design ideas in an educational game	As educational games have become a larger field of study, there has been a growing need for analytic methods that can be used to assess game design and inform iteration. While much previous work has focused on the measurement of student engagement or learning at a gross level, we argue that new methods are necessary for measuring the alignment of a game to its target learning goals at an appropriate level of detail to inform design decisions. We present a novel technique that we have employed to examine alignment in an open-ended educational game. The approach is based on examining how the game reacts to representative student solutions that do and do not obey target principles. We demonstrate this method using real student data and discuss how redesign might be informed by these techniques.
2014	Persuasive technology for overcoming food cravings and improving snack choices	A central challenge in weight management is the difficulty of overcoming desires for excessive and unhealthy food. Yet, studies show that when people are able to resist their desires for unhealthy choices, they experience pride and satisfaction. In order to alleviate the former and support the latter, we designed, implemented and tested a mobile application for improving snacking behavior. Our application delivers a food craving reduction intervention at the moment of need and allows users to track how often they successfully resisted cravings. Our craving reduction intervention is based on recent research that shows that food cravings can be reduced through imagery techniques. We conducted a week-long evaluation of our application, comparing the effectiveness of our application to a basic tracking application. We found that our imagery application significantly reduced both overall snacking and unhealthy snacking compared to a simple snack-tracking application.
2014	CADament: a gamified multiplayer software tutorial system	We present CADament, a gamified multiplayer tutorial system for learning AutoCAD. Compared with existing gamified software tutorial systems, CADament generates engaging learning experience through competitions. We investigate two variations of our game, where over-the-shoulder learning was simulated by providing viewports into other player's screens. We introduce an empirical lab study methodology where participants compete with one another, and we study knowledge transfer effects by tracking the migration of strategies between players during the study session. Our study shows that CADament has an advantage over pre-authored tutorials for improving learners' performance, increasing motivation, and stimulating knowledge transfer.
2014	A game-based learning approach to road safety: the code of everand	Game and gamification elements are increasingly seeing use as part of interface designs for applications seeking to engage and retain users whilst transferring information. This paper presents an evaluation of a game-based approach seeking to improve the road safety behaviour amongst children aged 9-15 within the UK, made available outside of a classroom context as an online, browser-based, free-to-play game. The paper reports on data for 99,683 players over 315,882 discrete logins, supplemented by results from a nationally-representative survey of children at UK schools (n=1,108), an incentivized survey of the player-base (n=1,028), and qualitative data obtained through a series of one-to-one interviews aged 9-14 (n=28). Analysis demonstrates the reach of the game to its target demographic, with 88.13% of players within the UK. A 3.94 male/female ratio was observed amongst players surveyed, with an age distribution across the target range of 9-15. Noting mean and median playtimes of 93 and 31 minutes (n=99,683), it is suggested such an approach to user engagement and retention can surpass typical contact times obtained through other forms of web-based content. The size of the player-base attracted to the game and players' qualitative feedback demonstrates the potential for serious games deployed on a national scale.
2014	Spending real money: purchasing patterns of virtual goods in an online social game	Researchers have found that 'social' factors contribute to purchasing intentions of virtual goods in an online social game, but little is known about actual purchasing behavior. Study 1 examined the relationship between social factors and virtual goods purchasing patterns using large scale data obtained by server logs of an online social game. Exchange of virtual goods and number of friends increased the likelihood of spending real money compared to no spending. Among those who did spend real money, giving virtual goods to others was the strongest factor associated with the amount of spending. Study 2 examined purchasing patterns of players who spent real money: high real-money spenders were buying items for visual customization while low spenders were buying consumable items necessary to sustain playing the game.
2014	Towards automatic experimentation of educational knowledge	We present a general automatic experimentation and hypothesis generation framework that utilizes a large set of users to explore the effects of different parts of an intervention parameter space on any objective function. We also incorporate importance sampling, allowing us to run these automatic experiments even if we cannot give out the exact intervention distributions that we want. To show the utility of this framework, we present an implementation in the domain of fractions and numberlines, using an online educational game as the source of players. Our system is able to automatically explore the parameter space and generate hypotheses about what types of numberlines lead to maximal short-term transfer; testing on a separate dataset shows the most promising hypotheses are valid. We briefly discuss our results in the context of the wider educational literature, showing that one of our results is not explained by current research on multiple fraction representations, thus proving our ability to generate potentially interesting hypotheses to test.
2014	Brain points: a growth mindset incentive structure boosts persistence in an educational game	There is great interest in leveraging video games to improve student engagement and motivation. However, educational games are not uniformly effective, and little is known about how in-game rewards affect children's learning-related behavior. In this work, we argue that educational games can be improved by fundamentally changing their incentive structures to promote the growth mindset, or the belief that intelligence is malleable. We present "brain points," a system that encourages the development of growth mindset behaviors by directly incentivizing effort, use of strategy, and incremental progress. Through a study of 15,000 children, we show that the "brain points" system encourages more low-performing students to persist in the educational game Refraction when compared to a control, and increases overall time played, strategy use, and perseverance after challenge. We believe that this growth mindset incentive structure has great potential in many educational environments.
2014	Combining crowdsourcing and learning to improve engagement and performance	Crowdsourcing complex creative tasks remains difficult, in part because these tasks require skilled workers. Most crowdsourcing platforms do not help workers acquire the skills necessary to accomplish complex creative tasks. In this paper, we describe a platform that combines learning and crowdsourcing to benefit both the workers and the requesters. Workers gain new skills through interactive step-by-step tutorials and test their knowledge by improving real-world images submitted by requesters. In a series of three deployments spanning two years, we varied the design of our platform to enhance the learning experience and improve the quality of the crowd work. We tested our approach in the context of LevelUp for Photoshop, which teaches people how to do basic photograph improvement tasks using Adobe Photoshop. We found that by using our system workers gained new skills and produced high-quality edits for requested images, even if they had little prior experience editing images.
2014	L.IVE: an integrated interactive video-based learning environment	In this paper, we introduce L.IVE: an online interactive video-based learning environment with an alternative design and architecture that integrates three major interface components: video, comment threads, and assessments. This is in contrast with the approach of existing interfaces which visually separate these components. Our study, which compares L.IVE with existing popular video-based learning environments, suggests advantages in this integrated approach as compared to the separated approach in learning.
2014	HaptiMoto: turn-by-turn haptic route guidance interface for motorcyclists	A national study by the Australian Transport Safety Bureau revealed that motorcyclist deaths were nearly thirty times more prevalent than that of drivers of other vehicles. These fatalities represent approximately 5% of all highway deaths each year, yet motorcycles account for only 2% of all registered vehicles in the USA. Motorcyclists are highly exposed on the road, so maintaining situational awareness at all times is crucial. Route guidance systems enable users to efficiently navigate between locations using dynamic visual maps and audio directions, and have been well tested with motorists, but remain unsafe for use by motorcyclists. Audio/visual routing systems decrease motorcyclists' situational awareness and vehicle control, and thus elevate chances of an accident. To enable motorcyclists to take advantage of route guidance while maintaining situational awareness, we created HaptiMoto, a wearable haptic route guidance system. HaptiMoto uses tactile signals to encode the distance and direction of approaching turns, thus avoiding interference with audio/visual awareness. Our evaluations demonstrate that HaptiMoto is both intuitive and a safer alternative for motorcyclists compared to existing solutions.
2014	Digitally driven: how location based services impact the work practices of London bus drivers	This paper examines how an occupational group has adapted to the demands of working with a Location Based Service (LBS). Instead of following a rigid timetable, London's bus drivers are now required to maintain an equal distance between the bus in front and the one behind. Our qualitative study employs ethnographic fieldwork and in-depth semi-structured interviews to elicit drivers' perspectives of the new system and show how it has modified their driving and general work conditions. We explore how passengers influence the movement of the bus and how the technology frames bus drivers' relationships to their managers and commuters. This work contributes to our understanding of the impact of LBS in the workplace and shows how technological imperatives can be established that cause unanticipated consequences and gradually undermine human relationships.
2014	Slide to X: unlocking the potential of smartphone unlocking	Unlock gestures are performed by billions of users across the world multiple times a day. Beyond preventing accidental input on mobile devices, they currently serve little to no other purpose. In this paper, we explore how replacing the regular unlock screen with one that asks the user to perform a simple, optional task, can benefit a wealth of application domains, including data collection, personal-health metrics collection, and human intelligence tasks. We evaluate this concept, which we refer to as Slide to X. Further, we show that people are willing to perform microtasks presented through this interface and continue to do so throughout the day while they visit different locations as part of their daily routines. We then discuss how to implement this concept and demonstrate three applications.
2014	Twitch crowdsourcing: crowd contributions in short bursts of time	To lower the threshold to participation in crowdsourcing, we present twitch crowdsourcing: crowdsourcing via quick contributions that can be completed in one or two seconds. We introduce Twitch, a mobile phone application that asks users to make a micro-contribution each time they unlock their phone. Twitch takes advantage of the common habit of turning to the mobile phone in spare moments. Twitch crowdsourcing activities span goals such as authoring a census of local human activity, rating stock photos, and extracting structured data from Wikipedia pages. We report a field deployment of Twitch where 82 users made 11,240 crowdsourcing contributions as they used their phone in the course of everyday life. The median Twitch activity took just 1.6 seconds, incurring no statistically distinguishable costs to unlock speed or cognitive load compared to a standard slide-to-unlock interface.
2014	Experimental evaluation of user interfaces for visual indoor navigation	Mobile location recognition by capturing images of the environment (visual localization) is a promising technique for indoor navigation in arbitrary surroundings. However, it has barely been investigated so far how the user interface (UI) can cope with the challenges of the vision-based localization technique, such as varying quality of the query images. We implemented a novel UI for visual localization, consisting of Virtual Reality (VR) and Augmented Reality (AR) views that actively communicate and ensure localization accuracy. If necessary, the system encourages the user to point the smartphone at distinctive regions to improve localization quality. We evaluated the UI in a experimental navigation task with a prototype, informed by initial evaluation results using design mockups. We found that VR can contribute to efficient and effective indoor navigation even at unreliable location and orientation accuracy. We discuss identified challenges and share lessons learned as recommendations for future work.
2014	Rethinking plan A for sustainable HCI	This paper challenges the sustainable HCI community to move away from a focus on demand and instead address climate change as a supply problem. We identify a new route to impact, namely addressing the psychological barriers that interfere with political mobilization toward limiting the use of fossil fuels. Five barriers are explored as a means of re-focusing research objectives for the community.
2014	Crowdsourcing the future: predictions made with a social network	Researchers have long known that aggregate estimations built from the collected opinions of a large group of people often outperform the estimations of individual experts. This phenomenon is generally described as the "Wisdom of Crowds". This approach has shown promise with respect to the task of accurately forecasting future events. Previous research has demonstrated the value of utilizing meta-forecasts (forecasts about what others in the group will predict) when aggregating group predictions. In this paper, we describe an extension to meta-forecasting and demonstrate the value of modeling the familiarity among a population's members (its social network) and applying this model to forecast aggregation. A pair of studies demonstrates the value of taking this model into account, and the described technique produces aggregate forecasts for future events that are significantly better than the standard Wisdom of Crowds approach as well as previous meta-forecasting techniques.
2014	Smart flashlight: map navigation using a bike-mounted projector	While mobile phones affect our behavior and tend to separate us from our physical environment, this very environment could instead become a responsive part of the information domain. For navigation using a map while cycling in an urban environment, we studied two alternative solutions: smartphone display and projection on the road. This paper firstly demonstrates by proof-of-concept a GPS-based map navigation using a bike-mounted projector. Secondly, it implements a prototype using both a projector and a smartphone mounted on a bike, comparing them for use in a navigation system for nighttime cycling. Thirdly, it examines how visuo-spatial factors influence navigation. We believe that our findings will be useful for designing navigation systems for bikes and even for cars, helping cyclists and drivers be more attentive to their environment while navigating, and to provide useful information while moving.
2014	Partially intelligent automobiles and driving experience at the moment of system transition	The current study (N = 49) took a user-centered approach to explore how level of automation (pedal automated, wheel automated or fully automated driving) and the interface modality (switching automation on or off via touch or voice control) in automated vehicles influence drivers' perceived experience and performance. The results found that full or wheel automation in vehicles was perceived significantly more intelligent than pedal automation. Furthermore, drivers in the pedal automation condition reported greater nervousness when using the touch interface than the voice interface. This tendency was not found among drivers in the full and wheel automation conditions. Drivers who used the voice interface to control automated driving had fewer driving mistakes than those who operated the touch interface. Our findings have important psychological and practical implications for designing a user interface for automated vehicles.
2014	Addressing the subtleties in dementia care: pre-study & evaluation of a GPS monitoring system	In this work we present a user-centered development process for a GPS-based monitoring system to be used in dementia care. Our research covers a full design process including a qualitative-empirical pre-study, the prototyping process and the investigation of long-term appropriation processes of the stable prototypes in three different practice environments. Specifically, we deal with the problem of 'wandering' by persons suffering from late-phase dementia. Although GPS tracking is not a novel technological objective, the usage of those systems in dementia care remains very low. The paper therefore takes a socio-technical stance on development and appropriation of GPS technology in dementia care and assesses the practical and ideological issues surrounding care to understand why. We additionally provide design research in two different settings, familial and institutional care, and report on the design of a GPS-based tracking system reflecting these considerations. What comes to the fore is the need for ICT to reflect complex organizational, ideological and practical issues that form part of a moral universe where sensitivity is crucial.
2014	Classifying driver workload using physiological and driving performance data: two field studies	Understanding the driver's cognitive load is important for evaluating in-vehicle user interfaces. This paper describes experiments to assess machine learning classification algorithms on their ability to automatically identify elevated cognitive workload levels in drivers, leading towards the development of robust tools for automobile user interface evaluation. We look at using both driver performance as well as physiological data. These measures can be collected in real-time and do not interfere with the primary task of driving the vehicle. We report classification accuracies of up to 90% for detecting elevated levels of cognitive load, and show that the inclusion of physiological data leads to higher classification accuracy than vehicle sensor data evaluated alone. Finally, we show results suggesting that models can be built to classify cognitive load across individuals, instead of building individual models for each per-son. By collecting data from drivers in two large field studies on the highway (20 drivers and 99 drivers), this work extends prior work and demonstrates feasibility and potential of such measures for HCI research in vehicles.
2014	Investigating the feasibility of extracting tool demonstrations from in-situ video content	Short video demonstrations are effective resources for helping users to learn tools in feature-rich software. However manually creating demonstrations for the hundreds (or thousands) of individual features in these programs would be impractical. In this paper, we investigate the potential for identifying good tool demonstrations from within screen recordings of users performing real-world tasks. Using an instrumented image-editing application, we collected workflow video content and log data from actual end users. We then developed a heuristic for identifying demonstration clips, and had the quality of a sample set of clips evaluated by both domain experts and end users. This multi-step approach allowed us to characterize the quality of 'naturally occurring' tool demonstrations, and to derive a list of good and bad features of these videos. Finally, we conducted an initial investigation into using machine learning techniques to distinguish between good and bad demonstrations.
2014	Evaluating multimodal driver displays under varying situational urgency	Previous studies have investigated audio, visual and tactile driver warnings, indicating the importance of communicating the appropriate level of urgency to the drivers. However, these modalities have never been combined exhaustively and tested under conditions of varying situational urgency to assess their effectiveness both in the presence and absence of critical driving events. This paper describes an experiment evaluating all multimodal combinations of such warnings under two contexts of situational urgency: a lead car braking and not braking. The results showed that participants responded quicker to more urgent warnings, especially in the presence of a car braking. They also responded faster to the multimodal as opposed to unimodal signals. Driving behaviour improved in the presence of the warnings and the absence of a car braking. These results highlight the influence of urgency and number of modalities in warning design and indicate the utility of non-visual warnings in driving.
2014	Crowdsourcing step-by-step information extraction to enhance existing how-to videos	Millions of learners today use how-to videos to master new skills in a variety of domains. But browsing such videos is often tedious and inefficient because video player interfaces are not optimized for the unique step-by-step structure of such videos. This research aims to improve the learning experience of existing how-to videos with step-by-step annotations. We first performed a formative study to verify that annotations are actually useful to learners. We created ToolScape, an interactive video player that displays step descriptions and intermediate result thumbnails in the video timeline. Learners in our study performed better and gained more self-efficacy using ToolScape versus a traditional video player. To add the needed step annotations to existing how-to videos at scale, we introduce a novel crowdsourcing workflow. It extracts step-by-step structure from an existing video, including step times, descriptions, and before and after images. We introduce the Find-Verify-Expand design pattern for temporal and visual annotation, which applies clustering, text processing, and visual analysis algorithms to merge crowd output. The workflow does not rely on domain-specific customization, works on top of existing videos, and recruits untrained crowd workers. We evaluated the workflow with Mechanical Turk, using 75 cooking, makeup, and Photoshop videos on YouTube. Results show that our workflow can extract steps with a quality comparable to that of trained annotators across all three domains with 77% precision and 81% recall.
2014	EverTutor: automatically creating interactive guided tutorials on smartphones by user demonstration	We present EverTutor, a system that automatically generates interactive tutorials on smartphone from user demonstration. For tutorial authors, it simplifies the tutorial creation. For tutorial users, it provides contextual step-by-step guidance and avoids the frequent context switching between tutorials and users' primary tasks. In order to generate the tutorials automatically, EverTutor records low-level touch events to detect gestures and identify on-screen targets. When a tutorial is browsed, the system uses vision-based techniques to locate the target regions and overlays the corresponding input prompt contextually. It also identifies the correctness of users' interaction to guide the users step by step. We conducted a 6-person user study for creating tutorials and a 12-person user study for browsing tutorials, and we compared EverTutor's interactive tutorials to static and video ones. Study results show that creating tutorials by EverTutor is simpler and faster than producing static and video tutorials. Also, when using the tutorials, the task completion time for interactive tutorials were 3-6 times faster than static and video tutorials regardless of age group. In terms of user preference, 83% of the users chose interactive type as the preferred tutorial type and rated it easiest to follow and easiest to understand.
2014	Sweet Home: understanding diabetes management via a chinese online community	China has overtaken India and the U.S. as host to the largest diabetic population in the world. Many problems exist in the Chinese healthcare system and very small number of diabetes patients receives treatment. Our paper reports on a case study through the lens of an online diabetes patient community, Sweet Home. We conducted participant observations, text analysis, and interviews, to understand the health management of patients at Sweet Home. Our findings reveal that patients' understanding of diabetes, their choice of treatments, their routine management, and their interactions with others (in the physical world) and among themselves (in the online world) are influenced by many factors: belief in traditional Chinese versus western medicine, cultural and social norms regarding social eating and drinking, conflicts over self-images, and responses to comments and pressures of coworkers. That is, social context may significantly affect patients' behaviors and each individual patient's actions may also help reshape the social context. We draw out implications for how our society as a whole may respond to these issues, from the perspective of public health, education, and information technology design.
2014	A smartphone-based sensing platform to model aggressive driving behaviors	Driving aggressively increases the risk of accidents. Assessing a person's driving style is a useful way to guide aggressive drivers toward having safer driving behaviors. A number of studies have investigated driving style, but they often rely on the use of self-reports or simulators, which are not suitable for the real-time, continuous, automated assessment and feedback on the road. In order to understand and model aggressive driving style, we construct an in-vehicle sensing platform that uses a smartphone instead of using heavyweight, expensive systems. Utilizing additional cheap sensors, our sensing platform can collect useful information about vehicle movement, maneuvering and steering wheel movement. We use this data and apply machine learning to build a driver model that evaluates drivers' driving styles based on a number of driving-related features. From a naturalistic data collection from 22 drivers for 3 weeks, we analyzed the characteristics of drivers who have an aggressive driving style. Our model classified those drivers with an accuracy of 90.5% (violation-class) and 81% (questionnaire-class). We describe how, in future work, our model can be used to provide real-time feedback to drivers using only their current smartphone.
2014	TaggedComments: promoting and integrating user comments in online application tutorials	User comments posted to popular online tutorials constitute a rich additional source of information for readers, yet current designs for displaying user comments on tutorial webpages do little to support their use. Instead, comments are separated from the tutorial content they reference and tend to be ordered according to post date. We propose and evaluate the TaggedComments system, a new approach to displaying comments that users post to online tutorials. Using tags supplied by commenters, TaggedComments seeks to enhance the role of user comments by 1) improving their visibility, 2) allowing users to personalize their use of the comments according to their particular information needs, and 3) providing direct access to potentially helpful comments from the tutorial content. A laboratory evaluation with 16 participants shows that, in comparison to the standard comment layout, TaggedComments significantly improves users' subjective impressions of comment utility when interacting with Photoshop tutorials.
2014	Using personal examples to improve risk communication for security & privacy decisions	IT security systems often attempt to support users in taking a decision by communicating associated risks. However, a lack of efficacy as well as problems with habituation in such systems are well known issues. In this paper, we propose to leverage the rich set of personal data available on smartphones to communicate risks using personalized examples. Examples of private information that may be at risk can draw the users' attention to relevant information for a decision and also improve their response. We present two experiments that validate this approach in the context of Android app permissions. Private information that becomes accessible given certain permissions is displayed when a user wants to install an app, demonstrating the consequences this installation might have. We find that participants made more privacy-conscious choices when deciding which apps to install. Additionally, our results show that our approach causes a negative affect in participants, which makes them pay more attention.
2014	Easy does it: more usable CAPTCHAs	Websites present users with puzzles called CAPTCHAs to curb abuse caused by computer algorithms masquerading as people. While CAPTCHAs are generally effective at stopping abuse, they might impair website usability if they are not properly designed. In this paper we describe how we designed two new CAPTCHA schemes for Google that focus on maximizing usability. We began by running an evaluation on Amazon Mechanical Turk with over 27,000 respondents to test the usability of different feature combinations. Then we studied user preferences using Google's consumer survey infrastructure. Finally, drawing on the insights gleaned during those studies, we tested our new captcha schemes first on Mechanical Turk and then on a fraction of production traffic. The resulting scheme is now an integral part of our production system and is served to millions of users. Our scheme achieved a 95.3% human accuracy, a 6.7.
2014	A novel knee rehabilitation system for the home	In this paper, we describe the design and evaluation of an interactive home-based rehabilitation visualisation system used by a wide variety of ages (users in our studies were aged from 47-89) to undertake rehabilitation in the home following knee replacement surgery. We present the rehabilitation visualization system and the results of a randomized controlled study in which we investigated the usability and feasibility of the system in the home. We found that our users were able to use the system successfully for their rehabilitation with improved rehabilitation outcomes after 6 weeks when compared to the current rehabilitation care. Finally we highlight the lessons learned which will benefit prospective designers of home rehabilitation technology in ensuring successful home evaluations in clinical rehabilitation.
2014	A technology probe of wearable in-home computer-assisted physical therapy	Physical therapists could make better treatment decisions if they had accurate patient home exercise data but today this information is only available from patient self-report. A more accurate source of data could be gained from wearable computing designed for physical therapy exercise support. Existing systems have been tested in the lab but we have little information about issues they may face in home settings. We designed a technology probe, SenseCap, and deployed it for seven days in ten physical therapy patients' homes. SenseCap is a wearable physical therapy support system that gathers patient exercise compliance and performance data and summarizes the data in charts on an iPad Dashboard for physical therapists to view when patients return to the clinic. In this paper, we present the results of our deployment, show in-home patient exercise data gathered by the probe, and make design recommendations based on patient and physical therapist responses.
2014	LinearDragger: a linear selector for target acquisition on touch screens	Touch input is increasingly popular nowadays, especially for mobile devices such as smartphones and tablet computers. However, the human finger has considerably large fingertip size and finger input is imprecise. As such, acquiring small targets on a touch screen is still a challenging task. In this paper, we present the LinearDragger , a new and integrated one-finger target acquisition technique for small and clustered targets. The proposed method has three advantages. First, it allows users to select targets in dense clustered groups easily with a single touch-drag-release operation. Second, it maps the 2D selection problem into a more precise 1D selection problem, which is independent of the target distribution. Third, it avoids finger occlusion and does not create visual distraction. As a result, it is particularly suitable for applications with dense targets and rich visual elements. Results of our controlled experiments show that when selecting small targets, LinearDragger takes about 70% and 30% less selection time than target acquisition without using any techniques and with the state-of-the-art target acquisition technique that involves a single touch operation, respectively, while maintaining a reasonable error rate.
2014	Faster command selection on tablets with FastTap	Touch-based tablet UIs provide few shortcut mechanisms for rapid command selection; as a result, command selection on tablets often requires slow traversal of menus. We developed a new selection technique for multi-touch tablets, called FastTap, that uses thumb-and-finger touches to show and choose from a spatially-stable grid-based overlay interface. FastTap allows novices to view and inspect the full interface, but once item locations are known, FastTap allows people to select commands with a single quick thumb-and-finger tap. The interface helps users develop expertise, since the motor actions carried out as a novice rehearse the expert behavior. A controlled study showed that FastTap was significantly faster (by 33% per selection overall) than marking menus, both for novices and experts, and without reduction in accuracy or subjective preference. Our work introduces a new and efficient selection mechanism that supports rapid command execution on touch tablets, for both novices and experts.
2014	Changibles: analyzing and designing shape changing constructive assembly	Advances in shape changing assemblies have been made in reconfiguration algorithms, hardware designs and interaction techniques. However no tools exist for guiding designers in building those modular devices and especially for choosing the shape of the units. The task becomes even more complex when the units themselves can change their shapes to animate the entire assembly. In this paper, we contribute with the first analysis tool which helps the designer to both choose the right subset of forms for the units and to create an assembly with maximum accuracy from the set of given objects. We introduce the concept of Changibles that are interactive wireless units that can reshape themselves and be attached together to create an animated assembly. We present a use case to demonstrate the use of our tool, with an instantiation of six Changibles that are used to construct a pulsing heart assembly.
2014	Exploring the acceptability of google glass as an everyday assistive device for people with parkinson's	We describe a qualitative study investigating the acceptability of the Google Glass eyewear computer to people with Parkinson's disease (PD). We held a workshop with 5 PD patients and 2 carers exploring perceptions of Glass. This was followed by 5-day field trials of Glass with 4 PD patients, where participants wore the device during everyday activities at home and in public. We report generally positive responses to Glass as a device to instil confidence and safety for this potentially vulnerable group. We also raise concerns related to the potential for Glass to reaffirm dependency on others and stigmatise wearers.
2014	Evaluating the effectiveness of physical shape-change for in-pocket mobile device notifications	Audio and vibrotactile output are the standard mechanisms mobile devices use to attract their owner's attention. Yet in busy and noisy environments, or when the user is physically active, these channels sometimes fail. Recent work has explored the use of physical shape-change as an additional method for conveying notifications when the device is in-hand or viewable. However, we do not yet understand the effectiveness of physical shape-change as a method for communicating in-pocket notifications. This paper presents three robustly implemented, mobile-device sized shape-changing devices, and two user studies to evaluate their effectiveness at conveying notifications. The studies reveal that (1) different types and configurations of shape-change convey different levels of urgency and; (2) fast pulsing shape-changing notifications are missed less often and recognised more quickly than the standard slower vibration pulse rates of a mobile device.
2014	Non-intrusive tongue machine interface	There has been recent interest in designing systems that use the tongue as an input interface. Prior work however either require surgical procedures or in-mouth sensor placements. In this paper, we introduce TongueSee, a non-intrusive tongue machine interface that can recognize a rich set of tongue gestures using electromyography (EMG) signals from the surface of the skin. We demonstrate the feasibility and robustness of TongueSee with experimental studies to classify six tongue gestures across eight participants. TongueSee achieves a classification accuracy of 94.17% and a false positive probability of 0.000358 per second using three-protrusion preamble design.
2014	HCI as a means to prosociality in the economy	HCI research often involves intervening in the economic lives of people, but researchers only rarely give explicit consideration to what actually constitutes prosociality in the economy. Much has been said previously regarding sustainability but this has largely focused on environmental rather than interpersonal relations. This paper provides an analysis of how prosocial HCI has been discussed and continues to be defined as a research field. Based on a corpus of published works, we describe a variety of genres of work relating to prosocial HCI. Key intellectual differences are explored, including the epistemological and ethical positions involved in designing for prosocial outcomes as well as how HCI researchers posit economic decision-making. Finally, emerging issues and opportunities for further debate and collaboration are discussed in turn.
2014	Towards a closer dialogue between policy and practice: responsible design in HCI	Given the potent and pervasive nature of modern technologies, this paper lays out the complexities involved in achieving responsible design. In order to do this we will first compare an emerging policy-oriented programme of research known as RRI (Responsible Research and Innovation) with initiatives in HCI. A focus on the similarities and differences may highlight to what extent responsibility is already and successfully embedded within the concerns and practices of design and use, and what may yet need to be incorporated for responsible design. The paper then discusses the challenges of 'naturalising' the very ambitious programme of RRI within specific design activities and concerns, through the lens of four analytic concepts: reflexivity; responsiveness; inclusion; and anticipation. Finally, we make a case for a pragmatic, 'unromantic', but engaged reinterpretation of RRI for HCI.
2014	Can long passwords be secure and usable?	To encourage strong passwords, system administrators employ password-composition policies, such as a traditional policy requiring that passwords have at least 8 characters from 4 character classes and pass a dictionary check. Recent research has suggested, however, that policies requiring longer passwords with fewer additional requirements can be more usable and in some cases more secure than this traditional policy. To explore long passwords in more detail, we conducted an online experiment with 8,143 participants. Using a cracking algorithm modified for longer passwords, we evaluate eight policies across a variety of metrics for strength and usability. Among the longer policies, we discover new evidence for a security/usability tradeoff, with none being strictly better than another on both dimensions. However, several policies are both more usable and more secure that the traditional policy we tested. Our analyses additionally reveal common patterns and strings found in cracked passwords. We discuss how system administrators can use these results to improve password-composition policies.
2014	Towards community-centered support for peer-to-peer service exchange: rethinking the timebanking metaphor	Commercial peer-to-peer service exchange businesses, such as AirBnB, Lyft and TaskRabbit, are expanding rapidly, but their non-profit counterparts are lagging behind. We conducted a field study of the most prominent of these, timebanking; a system in which 'time dollars' are earned and spent by people providing services for and receiving them from each other. Our study exposed problems with the very metaphor of banking itself, which deter participation. In this paper we discuss how these problems can be tackled with user experience design for systems supporting timebanking. Our design ideas emphasize the personal and social benefits of participation, and avoid such unappealing concepts as debt and neediness that the timebanking metaphor falls afoul of.
2014	Now you see me, now you don't: protecting smartphone authentication from shoulder surfers	In this paper, we present XSide, an authentication mechanism that uses the front and the back of smartphones to enter stroke-based passwords. Users can switch sides during input to minimize the risk of shoulder surfing. We performed a user study (n = 32) to explore how switching sides during authentication affects usability and security of the system. The results indicate that switching the sides increases security while authentication speed stays relatively fast (≤ 4 seconds). The paper furthermore provides insights on accuracy of eyes-free input (as used in XSide) and shows how 3D printed prototype cases can improve the back-of-device interaction experience.
2014	Designing for dabblers and deterring drop-outs in citizen science	In most online citizen science projects, a large proportion of participants contribute in small quantities. To investigate how low contributors differ from committed volunteers, we distributed a survey to members of the Old Weather project, followed by interviews with respondents selected according to a range of contribution levels. The studies reveal a complex relationship between motivations and contribution. Whilst high contributors were deeply engaged by social or competitive features, low contributors described a solitary experience of 'dabbling' in projects for short periods. Since the majority of participants exhibit this small-scale contribution pattern, there is great potential value in designing interfaces to tempt lone workers to complete 'just another page', or to lure early drop-outs back into participation. This includes breaking the work into components which can be tackled without a major commitment of time and effort, and providing feedback on the quality and value of these contributions.
2014	Passhint: memorable and secure authentication	People find it difficult to remember multiple alphanumeric as well as graphical passwords. We propose a Passhint authentication system (PHAS), where the users have to choose four images and create hints for each one of them in order to register a new password. During authentication, they have to recognize only the target images, which are displayed with their corresponding hints, among collections of 15 decoy images, in a four step process. A usability study was conducted with 40 subjects. They created 1 Mikon, 1 doodle, 1 art and 1 object password and then recalled each password after a period of two weeks (without any practice sessions). The results demonstrated that the memorability of multiple passwords in PHAS is better than in existing Graphical authentication systems (GASs). Although the registration time is high, authentication time for successful attempts is either equivalent to or less than the time reported for previous GASs. A guessability study conducted with the same subjects revealed that art passwords are the least guessable, followed by Mikon, doodle and objects in that order. The results strongly suggest the use of art passwords in PHAS, which would offer usable as well as secure authentication. The preliminary results indicate that PHAS has solved the memorability problem with multiple passwords. We propose two new features that could enhance the security offered by PHAS, but the usability of these features would need to be tested before they could be adopted in practice.
2014	The presentation effect on graphical passwords	We provide a simple yet powerful demonstration of how an unobtrusive change to a graphical password interface can modify the distribution of user chosen passwords, and thus possibly the security it provides. The only change to the interface is how the background image is presented to the user in the password creation phase--we call the effect of this change the "presentation effect". We demonstrate the presentation effect by performing a comparative user study of two groups using the same background image, where the image is presented in two different ways prior to password creation. Our results show a statistically different distribution of user's graphical passwords, with no observed usability consequences.
2014	An implicit author verification system for text messages based on gesture typing biometrics	Gesture typing is a popular text input method used on smartphones. Gesture keyboards are based on word gestures that subsequently trace all letters of a word on a virtual keyboard. Instead of tapping a word key by key, the user enters a word gesture with a single continuous stroke. In this paper, we introduce an implicit user verification approach for short text messages that are entered with a gesture keyboard. We utilize the way people interact with gesture keyboards to extract behavioral biometric features. We propose a proof-of-concept classification framework that learns the gesture typing behavior of a person and is able to decide whether a gestured message was written by the legitimate user or an imposter. Data collected from gesture keyboard users in a user study is used to assess the performance of the classification framework, demonstrating that the technique has considerable promise.
2014	Social epistemic cognition in online interactions	Social media and online social networks dramatically change the way in which knowledge is acquired and disseminated. How do we re-understand about human knowledge and knowing? This work aims at extending the current understanding of human epistemic cognition in online social environments, where epistemic cognition refers to cognitions and cognitive processes related to epistemic matters such as knowledge and beliefs justification. We approach our inquiry with mixed methods: (1) quantitative study to test whether epistemic cognition might differ in individual and social contexts, and whether online interactions might mediate the later; and (2) social cognitive task analysis with interviews to manifest the intricate interplay of dynamics between social epistemic cognition and online interactions. We introduce the new construct of social epistemic cognition and contribute to the field of HCI with an evolved theory which states that epistemic cognition can be promoted in online social environments as mediated by online interactions.
2014	Nutriflect: reflecting collective shopping behavior and nutrition	A poor nutritional state, as is the case for many people today, can increase risks for cancer, cardiovascular disease and obesity. Technology supported approaches could potentially be used to positively influence food consumption. We present the Nutriflect system, which utilizes users' shopping data to inform them about their long term shopping behavior. In an initial study we conducted structured interviews in grocery stores. Based on the results we implemented a system that visualized a household's collective shopping information via situated displays. The aim was to raise awareness about shopping habits and to enable reflection about nutrition without burdening the users with the manual entry of their eating habits. We evaluated the system in a 4 week field study in 8 households with 21 users. The results indicate that contextually situated displays, showing shopping patterns against personal nutrition goals, can foster a reflective and respectful approach towards better shopping and nutrition.
2014	ZWERM: a modular component network approach for an urban participation game	As information technology is increasingly embedded in our cities, opportunities arise to design novel applications that benefit urban communities. We describe the design and evaluation of ZWERM (Dutch for the term ' swarm '), a public game that was specifically designed for augmenting community participation in urban neighborhoods. A network of ten components has been designed, some of which had different interfaces and design approaches: from totem-like Trees for gathering around with RFID cards to playful Sparrows that react on whistle sounds. After implementing the urban game in two city neighborhoods, we investigated the impact of each of these components on their communities. Our insights are useful for the public interaction design of future urban, interactive networks that aim to positively influence community participation and social cohesion.
2014	Share your view: impact of co-navigation support and status composition in collaborative online shopping	Collaborative online shopping, an emerging paradigm in e-commerce, allows remote shoppers to extend purchase-oriented social interactions into the digital environment. Online vendors have been experimenting ways to facilitate this activity. However, more research needs to be done on identifying what feature can create a pleasing shopping experience and ultimately encourage spending. In this paper, we present an exploration of the impact of co-navigation supports, including location cue, split screen, and shared view, on the experiences and performance of 60 co-shopper dyads. We also studied if status composition of shopping companions played a role in this process. By analyzing about 1800 minutes of eye-tracking data, video footages, and web logs, we found that split screen encouraged more diverse product search, shared view enabled better coordination, and location cue was the least distracting. Co-buyers achieved better factual and inference understanding, though buyer-advisor dyads were more likely to stay together.
2014	Didn't you see my message?: predicting attentiveness to mobile instant messages	Mobile instant messaging ( e.g. , via SMS or WhatsApp) often goes along with an expectation of high attentiveness, i.e. , that the receiver will notice and read the message within a few minutes. Hence, existing instant messaging services for mobile phones share indicators of availability, such as the last time the user has been online. However, in this paper we not only provide evidence that these cues create social pressure, but that they are also weak predictors of attentiveness. As remedy, we propose to share a machine-computed prediction of whether the user will view a message within the next few minutes or not. For two weeks, we collected behavioral data from 24 users of mobile instant messaging services. By the means of machine-learning techniques, we identified that simple features extracted from the phone, such as the user's interaction with the notification center, the screen activity, the proximity sensor, and the ringer mode, are strong predictors of how quickly the user will attend to the messages. With seven automatically selected features our model predicts whether a phone user will view a message within a few minutes with 70.6% accuracy and a precision for fast attendance of 81.2%
2014	Tensions in scaling-up community social media: a multi-neighborhood study of nextdoor	This paper presents a study of Nextdoor, a social media system designed to support local neighborhoods. While not the first system designed to support community engagement, Nextdoor has a number of attributes that make it distinct. Our study, across three communities in a major U.S. city, illustrates that Nextdoor inhabits an already-rich ecosystem of community-oriented social media, but is being appropriated by its users for use in different ways than these existing media. Nextdoor also raises tensions in how it defines the boundaries of neighborhoods, and in the privacy issues it raises among its users.
2014	Curated city: capturing individual city guides through social curation	We report on our design of Curated City, a website that lets people build their own personal guide to the city's neighborhoods by chronicling their favorite experiences. Although users make their own personal guides, they are immersed in a social curatorial experience where they are influenced directly and indirectly by the guides of others. We use a 2-week field trial involving 20 residents of Pittsburgh as a technological probe to explore the initial design decisions, and we further refine the design landscape through subject interviews. Based on this study, we identify a set of design recommendations for building scalable social platforms for curating the experiences of the city.
2014	Improving automatic speech recognition through head pose driven visual grounding	In this paper, we present a multimodal speech recognition system for real world scene description tasks. Given a visual scene, the system dynamically biases its language model based on the content of the visual scene and visual attention of the speaker. Visual attention is used to focus on likely objects within the scene. Given a spoken description the system then uses the visually biased language model to process the speech. The system uses head pose as a proxy for the visual attention of the speaker. Readily available standard computer vision algorithms are used to recognize the objects in the scene and automatic real time head pose estimation is done using depth data captured via a Microsoft Kinect. The system was evaluated on multiple participants. Overall, incorporating visual information into the speech recognizer greatly improved speech recognition accuracy. The rapidly decreasing cost of 3D sensing technologies such as the Kinect allows systems with similar underlying principles to be used for many speech recognition tasks where there is visual information.
2014	Studying digital graffiti as a location-based social network	Increasing amounts of geo-tagged social media have led to interest in how that media can be re-integrated into the physical environment. Yet, although location information is often automatically appended to media, little is know about how users consider location in its creation and viewing. Using Graffiti as a design meme, we developed a novel social media service to investigate these issues. A two week field study showed how users incorporated both utilitarian and playful aspects of location into their social media creation, as well as revealing a disconnect between the location-media relationship intended by creators and perceived by viewers. We outline implications of our work for services that seek to repurpose existing geo-tagged social media in the design of novel services.
2014	PIM and personality: what do our personal file systems say about us?	Individual differences are prevalent in personal information management (PIM). There is large variation between individuals in how they structure and retrieve information from personal archives. These differences make it hard to develop general PIM tools. However we know little about the origins of these differences. We present two studies evaluating whether differences arise from personality traits, by exploring whether different personalities structure personal archives differently. The first exploratory study asks participants to identify PIM cues that signal personality traits. While the aim was to identify cues, these cues also proved surprisingly accurate indicators of personality. In a second study, to evaluate these cues, we directly measure relations between structure and traits. We demonstrate that Conscientiousness predicts file organization, particularly PC users' desktops. Neurotic people may also keep more desktop files. One implication is that systems might be customized for different personalities. We also advance personality theory, showing that personal digital artifacts signal personality.
2014	Show me the invisible: visualizing hidden content	Content on computer screens is often inaccessible to users because it is hidden, e.g., occluded by other windows, outside the viewport, or overlooked. In search tasks, the efficient retrieval of sought content is important. Current software, however, only provides limited support to visualize hidden occurrences and rarely supports search synchronization crossing application boundaries. To remedy this situation, we introduce two novel visualization methods to guide users to hidden content. Our first method generates awareness for occluded or out-of-viewport content using see-through visualization. For content that is either outside the screen's viewport or for data sources not opened at all, our second method shows off-screen indicators and an on-demand smart preview. To reduce the chances of overlooking content, we use visual links, i.e., visible edges, to connect the visible content or the visible representations of the hidden content. We show the validity of our methods in a user study, which demonstrates that our technique enables a faster localization of hidden content compared to traditional search functionality and thereby assists users in information retrieval tasks.
2014	Finder highlights: field evaluation and design of an augmented file browser	Navigating to files through a hierarchy is often a slow, laborious, and repetitive task. Recent lab studies showed that file browser interface augmentations, such as Icon Highlights and Search Directed Navigation, have the potential to reduce file retrieval times. However, for this potential to be realised in actual systems, further study is necessary to address two important issues. First, there are important design and implementation challenges in advancing the research prototypes previously evaluated into complete interactive systems that can be used for real work. Second, it is unknown how real users would employ these systems while engaged in actual work; would the potential performance improvements suggested by the earlier lab studies be realised? We therefore describe the design, implementation, and longitudinal field study evaluation of Finder Highlights, a file browser plugin for the OS X 'Finder' that adds support for Icon Highlights and Search Directed Navigation. Study results confirm that the augmentations are effective in reducing real-world file retrieval times, with retrieval times 13% faster when using Finder Highlights compared to the standard tool (10.6 s versus 12.2 s), while also emphasising important differences between lab and field studies. In summary, the paper strongly suggests that large-scale deployment of interface augmentations to file browsers, particularly Icon Highlights, will have a marked effect in improving users' real-world file retrieval.
2014	Cognitively inspired task design to improve user performance on crowdsourcing platforms	Recent research in human computation has focused on improving the quality of work done by crowd workers on crowdsourcing platforms. Multiple approaches have been adopted like filtering crowd workers through qualification tasks, and aggregating responses from multiple crowd workers to obtain consensus. We investigate here how improving the presentation of the task itself by using cognitively inspired features affects the performance of crowd workers. We illustrate this with a case-study for the task of extracting text from scanned images. We generated six task-presentation designs by modifying two parameters - visual saliency of the target fields and working memory requirements - and conducted experiments on Amazon Mechanical Turk (AMT) and with an eye-tracker in the lab setting. Our results identify which task-design parameters (e.g. highlighting target fields) result in improved performance, and which ones do not (e.g. reducing the number of distractors). In conclusion, we claim that the use of cognitively inspired features for task design is a powerful technique for maximizing the performance of crowd workers.
2014	Searching for myself: motivations and strategies for self-search	We present findings from a qualitative study of self-search, also known as ego or vanity search. In the context of a broader study about personal online content, participants were asked to search for themselves using their own computers and the browsers and queries they would normally adopt. Our analysis highlights five motivations for self-search: as a form of identity management; to discover reactions to and reuse of user-generated media; to re-find personal content; as a form of entertainment; and to reveal lost or forgotten content. Strategies vary according to motivation, and may differ markedly from typical information-seeking, with users looking deep into the results and using image search to identify content about themselves. We argue that two dimensions underpin ways of improving self-search: controllability and expectedness, and discuss what these dimensions imply for design.
2014	TransPhoner: automated mnemonic keyword generation	We present TransPhoner: a system that generates keywords for a variety of scenarios including vocabulary learning, phonetic transliteration, and creative word plays. We select effective keywords by considering phonetic, orthographic and semantic word similarity, and word concept imageability. We show that keywords provided by TransPhoner improve learner performance in an online vocabulary learning study, with the improvement being more pronounced for harder words. Participants rated TransPhoner keywords as more helpful than a random keyword baseline, and almost as helpful as manually selected keywords. Comments also indicated higher engagement in the learning task, and more desire to continue learning. We demonstrate additional applications to tasks such as pure phonetic transliteration, generation of mnemonics for complex vocabulary, and topic-based transformation of song lyrics.
2014	AudioCanvas: internet-free interactive audio photos	In this paper we present a novel interaction technique that helps to make textual information more accessible to those with low or no textual literacy skills. AudioCanvas allows cameraphone users to interact directly with their own photos of printed media to receive audio feedback or narration. The use of a remote telephone-based service also allows our design to be used over a standard phone line, removing the need for data connections, which can be problematic in developing regions. We show the value of the technique via user evaluations in both a rural Indian village and a South African township.
2014	Maybe it was a joke: emotion detection in text-only communication by non-native english speakers	Previous studies have shown that people can effectively detect emotions in text-only messages written in their native languages. But is this the same for non-native speakers' In this paper, we conduct an experiment where native English speakers (NS) and Japanese non-native English speakers (NNS) rate the emotional valence in text-only messages written by native English-speaking authors. They also annotate all emotional cues (words, symbols and emoticons) that affected their rating. Accuracy of NS and NNS ratings and annotations are calculated by comparing their average correlations with author ratings and annotations used as a gold standard. Our results conclude that NNS are significantly less accurate at detecting the emotional valence of messages, especially when the messages include highly negative words. Although NNS are as accurate as NS at detecting emotional cues, they are not able to make use of symbols (exclamation marks) and emoticons to detect the emotional valence of text-only messages.
2014	The impact of visual contextualization on UI localization	Translating the text in an interface is a challenging task. Besides the jargon and technical terms, many of the strings are often very short, such as those shown in buttons and pull-down menus. Then, as a result of the lack of visual context in the traditional localization process, an important ambiguity problem arises. We study three approaches to solve this problem: using plain gettext (baseline condition), using gettext plus being able to operate the UI, and translating the UI in-place. We found that translators are substantially faster with plain gettext but commit a significantly higher number of errors in comparison to the other approaches. Unexpectedly, the mixed condition was slower and more error-prone than in-place translation. The latter was found to be comparable to plain gettext in terms of time, although some strings passed unnoticed as the UI was operated. Based on our results, we arrive at a set of recommendations to augment localization tools to improve translator's productivity.
2014	The lonely raccoon at the ball: designing for intimacy, sociability, and selfhood	Designing for sociable systems requires, among other abilities, a sensitivity to the meanings, structures, and nuances of technology-mediated experiences that are simultaneously felt by users to be intimate and also social. Such a sensitivity is not easily acquired, and design researchers have recommended the use of social theories to guide designers' readings of technology-mediated social experiences. We use philosopher Michel Foucault's theory of identity (and social power, discourse, sexuality, creativity, and style) known as "the care of the self," as a scaffold with which to produce a sensitive interpretation of the intimacy (and expert social creative) practices of adult users of the virtual world Second Life (SL) . This reading sheds light on several skilled and creative intimacy practices in SL . It also offers a philosophically grounded hermeneutic strategy for designers interested in analyzing intimate experiences.
2014	Being senior and ICT: a study of seniors using ICT in China	System design for seniors often focuses on the decline of their biological capabilities and social connectedness. This approach has been challenged as too simplistic to capture what it really means to be senior. This paper presents a qualitative study of 17 seniors in urban China (age ranging from 50s to 70s), who have adopted and incorporated ICT into their daily lives. Findings from this study show that the ways in which seniors attend to ICT are not simply shaped by changes in health or other wellbeing, but also by their life attitudes, value systems, relationships to younger generations as well as historical specifics during their coming of age. This paper contributes by showing that 1) what it means to be senior is shaped from within a whole social ecology of past and current experiences, values and interactions; 2) senior identities are not fixed, but continuously negotiated, articulated and enacted through ICT; 3) social interaction and access of technologies are highly intertwined.
2014	Never too old: engaging retired people inventing the future with MaKey MaKey	Within HCI, aging is often viewed in terms of designing assistive technologies to improve the lives of older people, such as those who are suffering from frailty or memory loss. Our research adopts a very different approach, reframing the relationship in terms of wisdom, creativity and invention. We ran a series of workshops where groups of retirees, aged between early 60s and late 80s, used the MaKey MaKey inventor's toolkit. We asked them to think about inventing the future and suggest ideas for new technologies. Our findings showed that they not only rose to the challenge but also mastered the technology, collaborated intensely together while using it and freely and at length discussed their own, their family's and others' relationship with technology. We discuss the value of empowering people in this way and consider what else could be invented to enable more people to be involved in the design and use of creative technologies.
2014	Exploring affective communication through variable-friction surface haptics	This paper explores the use of variable friction surface haptics enabled by the TPad Tablet to support affective communication between pairs of users. We introduce three haptic applications for the TPad Tablet (text messaging, image sharing, and virtual touch) and evaluate the applications with 24 users, including intimate couples and strangers. Participants used haptics to communicate literal texture, denote action within a scene, convey emotional information, highlight content, express and engage in physical playfulness, and to provide one's partner with an experience or sensation. We conclude that users readily associate haptics with emotional expression and that the intimacy of touch in the contexts we study is best suited for communications with close social partners.
2014	Recreating living experiences from past memories through virtual worlds for people with dementia	This paper describes a study aimed to understand the use of 3D virtual world (VW) technology to support life engagement for people with dementia in long-term care. Three versions of VW prototypes (reminiscence room, virtual tour and gardening) utilising gestured-base interaction were developed iteratively. These prototypes were tested with older residents (80+) with dementia in care homes and their caregivers. Data collection was based on observations of how the residents and care staff interacted collaboratively with the VW. We discussed in depth the use of VWs in stimulating past memories and how this technology could help enhance their sense of self through various means. We also highlighted key approaches in designing VWs to sustain attention, create ludic experiences and facilitate interaction for older people with dementia.
2014	Understanding digital and material social communications for older adults	Online technologies are promising for helping older adults maintain social connectedness, particularly with younger people, yet many older adults resist or participate minimally in the mainstream technologies used by younger members of their social network. We present results from an interview study involving 22 older adults (age 71-92) to understand communication preferences and values related to social media. Seniors articulate many concerns with online social media, including the time required for legitimate participation, the loss of deeper communication, content irrelevance, and privacy. Additionally, older adults engage in social practices that could be supported by online social technologies, but they rarely use such tools. The theme of material social communications emerges from our data, and we examine this in context of online social media. We conclude with design considerations for the development of social media for older adults, and as part of this we describe the notion of bridging technologies as a framework for intergenerational communication design.
2014	What's on your mind?: investigating recommendations for inclusive social networking and older adults	Social networking sites (SNSs) are becoming increasingly popular as a method for social interaction. While research has reported benefits associated with components of SNS usage, a digital divide has emerged between younger and older users. SNSs can be useful for communicating with family members and helping one feel digitally included; however, there are a wide range of reasons why many older adults choose not to use this kind of technology. We present a series of user studies investigating the barriers and challenges that SNSs can present to older users. These user studies led to the derivation of user recommendations to mitigate these barriers. The recommendations were then evaluated within a comparative evaluation which involved 25 older adults completing tasks on two interface versions of a simulation SNS. We present the recommendations and the methods of their creation and evaluation. Implications for developers of SNSs are discussed.
2014	Room for interpretation: the role of self-esteem and CMC in romantic couple conflict	This work explores the role of communication technologies during romantic couple conflict, and the impact that self-esteem has on behavior, preferences for communication channels, and attitudes about mediated communication during conflict. Results revealed that lower levels of self-esteem and communicating via text messaging (vs. face-to-face) were associated with increased distancing and perceived partner distancing behaviors. Lower levels of self-esteem and using mediated communication were also associated with a greater likelihood of thinking that a conflict had a negative impact on the relationship. Yet, there was no evidence to suggest that individuals with lower levels of self-esteem exhibited more negative behaviors and perceptions in text-based communication than in FtF communication. In addition, lower levels of self-esteem were associated with increased use of and preferences for text-based mediated communication over FtF communication during conflict. Overall, this study suggests that both self-esteem and communication channel impact the nature of romantic couple conflict.
2014	Wrigglo: shape-changing peripheral for interpersonal mobile communication	We introduce Wrigglo, a shape-changing smart phone peripheral that allows pairs of users to share wriggling movements with one another. Attached to a smart phone, Wrigglo captures the sender's motions and activates the receiver's Wrigglo which repeats the motion simultaneously. The result of our in-lab use observation with twelve couples showed that Wrigglo supported emotional and functional roles of body gestures and postures, creating vocabularies related to the motion of specific body parts and, to some extent, reflected the connected user's presence through the device's movement. Through its peripheral anthropomorphization, Wrigglo can deliver new forms of telepresence by embodied posturing and gesturing in mobile communication.
1982	Recent advances in user assistance	As interactive users find conventional methods of training and documentation inadequate, designers are providing systems with online reference information, descriptions of valid input, elaboration of error messages, and explanations of a system's behavior. This paper describes some existing commercial systems that offer online assistance and more experimental approaches by the research community. The following material was originally presented at the SIGSOC conference on Easier and More Productive Use of Computing Systems. An extended version will appear in a special issue of the IEEE Transactions on Systems, Man, and Cybernetics (Volume SMC-12, March/April, 1982), and is reprinted here with the permission of the IEEE.Online user assistance is now offered on commercial systems and is the subject of investigation in experimental settings. It is difficult to compare the advantages and limitations of different approaches because they vary along many dimensions and because there is no commonly accepted terminology. A grouping of these dimensions into major categories is a necessary first step towards more empirical evaluations. The major software-related features of online assistance appear to fall into four categories:• access method -- the way users can construct or enter requests for assistance;• data structure -- the manner in which different portions of assistance information are related to each other;• software architecture -- how assistance requests and their responses are communicated among a user, an operating system, application programs, and the assistance database; and• contextual knowledge -- how much information is retained about the assistance environment, including the user, the application, and the tasks being performed.
1981	Automatic construction of explanation networks for a cooperative user interface	This paper is concerned with providing automatically generated on-line explanations to the user of a functional computer subsystem or tool about what the tool can and cannot do, what parameters and options are available or required with a given command, etc.. The explanations are given through the COUSIN interface system which provides a cooperative tool-independent user interface for tools whose objects, operations, input syntax, display formats, etc. are declaratively represented in a tool description data base. The explanations are produced automatically from this data base, with no incremental effort on the part of the tool designer, and in a single uniform style for any tool that uses COUSIN as its interface. The explanation facility takes the form of a fine-grained, tightly linked network of text frames supported by the ZOG menu-selection system. Exactly what information the net building program, NB, extracts from a tool description, and the way in which this information is formatted in the text frames is controlled by a second declarative data base called the aspect description . The declarative nature of the aspect description makes it easy to adapt NB to changes in and extensions to the tool description formalism, and to experiment with the structure of the explanation network. We also describe how the appropriate network frame can be found and displayed in response to specific explanation requests from the user.
1981	Using offline documentation online	Current interactive programs usually provide some form of online documentation in addition to the traditional hard-copy user's manual. To save the expense of writing two documents covering the same material, it is not uncommon to find offline manuals that are available interactively as well as printed versions of material originally organized for online use. Because of the difficulties inherent in using the same material in different ways, neither approach is totally satisfactory. The THUMB system minimizes these problems by structuring offline documentation for interactive use. An expert on a particular text ( e.g. , its author) prepares a detailed representation of the organization of material within the document. Once this data structure (which resembles a thorough table of contents and heavily cross-referenced index) is available, users access information free from the strictures of linear text, simple indices, and page numbers. The expert's task is nontrivial, but it requires less effort than writing a new document. Creation and revision of text are made easy by supportive utilities. THUMB monitors reader's requests in order to provide experts with feedback about a document's use. Readers need not be aware of THUMB's underlying data structure or the tools available for experts.
1982	How shall we evaluate prototype natural language processors?	Recent years have seen important advances in computational linguistics and artificial intelligence. Although many problems remain, the goal of providing limited English-processing facilities for non-technical computer users is within sight. By the end of the decade, numerous systems providing limited coverage of "natural language" will be available for business and home use. Several systems (e.g. TQA [16]) have already become operational. One system (ROBOT [7]) has been supporting natural language inputs in a dozen or so different commercial database applications for at least three years. Many other systems have been developed to the prototype stage and will soon be able to be transferred, with varying degrees of effort, from a research to a production environment. Each system tends to provide special features of its own, and the future prospects for database, office, instructional, and other environments are quite exciting.
1981	Redesign of the user interface involving users of a large operational real-time system	Today many large systems exist which have had many designers, have been patched up over the years, were designed for a different type of user than current users, and were once (but no longer) state of the art. The Deep Space Network at Jet Propulsion Laboratory is such a system. In Australia, Spain, and California, operators of the system use inflexible, incompatible routines to route data to Pasadena. Worker motivation and accuracy have to remain high for the system to work. In an attempt to develop redesign guidelines, users were queried regarding their attitudes and difficulties with the system. Interface alternatives were isolated and incorporated into a prototype for assessing the impact of the alternatives on user behavior. The resulting guidelines form a user-oriented, experience-based basis for continuing system evolution.
1982	Evaluating the “friendliness” of a timesharing system	The decade of the Sixties served to introduce most university campuses to the computer; the Seventies brought the computer, via a terminal, into every facet of university life. Computing in the Eighties will cause every university and college to evaluate and reconsider its exploitation of modern computing equipment for education and research.For example, at Northwestern University, it was recognized that continued growth in timesharing would be a major factor in computing at NU in the 1980s and that this growth would come from a large community of new users and of casual users. In January 1980, the Computing Center began a long-range planning study. A five-year equipment enhancement and replacement plan was to be developed which was intended to reverse an unsatisfactory trend toward computer saturation, to further improve and modernize our computer offerings, and to ensure that NU remained on a path of excellence in computing. Since time-sharing had already increased to over 50\% of the total usage of the computer, a decision was made to begin the evaluation of modern timesharing systems, with special emphasis in two areas: 1) efficiency and reliability, and 2) the user interface.This paper describes the processes which were developed and used for the evaluation of the user interface, or as it came to be known, the "friendliness" study [1].
1982	Evolution of a query translation system	This paper presents the motivation, history, and idiosyncrasy of a query translation system. Detail of the translation process has also been described.
1982	The need for quantitative measurement of on-line user behavior	An argument is made for the systematic collection and analysis of data regarding user-computer interaction in an on-line setting. A suggested approach involving preliminary data collection/analysis, development of a conceptual framework or model, and validation of the model is described. The case for this approach is supported by presentation of some preliminary results from a study of monitor data collected from the National Library of Medicine's ELHILL transaction file. Follow-on steps are proposed including comparison of research results to other studies of the same system or studies using similar techniques.
1982	A statistical user interface for the Relational Model of data	In the decade since the introduction of the Relational Model as a user view of large stored data bases, a variety of user languages have been proposed and a number of experimental systems have been implemented. The current computer science literature is replete with papers on the theoretical and practical aspects of the Relational Model and its implementation, as are most recent texts on data management systems.Implicit in the design of the user languages of most database systems, including those based on the Relational Model, are assumptions regarding the patterns of access to and the usage of the content of the database. Somewhat oversimplified, the assumed pattern of access is to search for a particular occurrence (case, observation) in the database which satisfies a given condition, and then to display the values of all attributes (fields, variables) of that one occurrence. The languages are designed to permit users to pose queries such as, for example, "what widgets do we buy from ABC industries?" or "display Jones' employment history". Queries of this type are termed informational queries; and systems supporting such queries with appropriate user languages and internal data storage techniques and access methods are information systems .A statistical query, similarly oversimplified, specifies a pattern of access to most, if not all, of the occurrences in a database, and a usage pattern of at most a few of the attributes. Examples of statistical queries are "what is the average size of our purchase orders?" and "display the number of employees by race, sex, and job category". Current statistical systems have limited capability for performing analysis over large and complex data collections, and their user languages reflects this limitation. A statistical query, as defined here, need not involve sophisticated mathematical analysis; the distinction between informational and statistical is derived from the antithetical patterns of access to and usage of the data content of a database. Most work on access languages for relationally based data systems has been on information query languages; very little work has been done on statistical query languages.This paper, then, discusses some elements of a language for statistical queries for a data system employing the Relational Model as the user view of large stored data bases.
1981	Keyboard entry - can it be simplified?	The present keyboard arrangement cannot be defended as comfortable, logically arranged, or optimized for human efficiency. Information theory based experiments suggest measures for alternative arrangements. Character sets used in different tasks can be expected to yield different optimal key locations. New tasks are introducing new characters and changing the frequency of selected old ones. Numerous alternative arrangements for alphanumeric fingered entry have been designed, but none are supported by conclusive testing. The amateur keyboard user far outnumbers the professional. Computer entry and word-processors are overtaking the simple typewriter as common alphanumeric stroke entry devices. Compromise and selection of a simplified keyboard that is compatible with present mechanical and electronic designs is advocated.
1981	Adaptable user interfaces for portable, interactive computing software systems	In the context of this paper a computing software system consists of a database, an associated user interface which allows users to analyse the data and the routines or programs which implement the analytic functions available through the user interface. It is assumed that the complete system - source code and data - already exists in a form which is as easily portable as possible between different computer environments. For such systems adaptability is the problem of adjusting the user interface and analytic capabilities to suit different user communities when such a system is transferred from one environment to another. This may include adaptation to specific hardware facilities as well as user requirements.In 1977/8 the International Planned Parenthood Federation (IPPF) funded a project at University College Cardiff to implement a portable computing software system originating from the Population Dynamics Group (PDG) at the University of Illinois. This system allowed users to perform population projections under different demographic conditions showing in a graphical presentation how the population of a country varies over selected time spans. The database consisted of population statistics for a number of countries. When implemented at Cardiff it was intended that this system should be used as a demographic training aid by the post graduate diploma students in the David Owen Centre for Population Growth Studies. These students are an international group who are specialists in the field of demography but have little or no computing background.This paper will discuss briefly how this portable system was implemented on a PDP 11 minicomputer at Cardiff and then give a fuller description of the adaptation of the user interface and analytic capabilities to the local community and its computer facilities. General conclusions will be drawn as to how such systems should be written so as to ease the problems of adaptability.
1982	User consulting in three forms of network-based organization	The utility of computer networking to organizal tasks is discussed. Three forms of network organization are described, and some examples given. Problems of user consulting in each form of organization are discussed.
1981	Lexicon design using perfect hash functions	The research reported in this paper derives from the recent algorithm of Cichelli (1980) for computing machine-independent, minimal perfect hash functions of the form:hash value: hash key length + associated value of the key's first letter + associated value of the key's last letterA minimal perfect hash function is one which provides single probe retrieval from a minimally-sized table of hash identifiers [ keys]. Cichelli's hash function is machine-independent because the character code used by a particular machine never enters into the hash calculation.Cichelli's algorithm uses a simple backtracking process to find an assignment of non-negative integers to letters which results in a perfect minimal hash function. Cichelli employs a twofold ordering strategy which rearranges the static set of keys in such a way that hash value collisions will occur and be resolved as early as possible during the backtracking process. This double ordering provides a necessary reduction in the size of the potentially large search space, thus considerably speeding the computation of associated values.In spite of Cichelli's ordering strategies, his method is found to require excessive computation to find hash functions for sets of keys with more than about 40 members. Cichelli's method is also limited since two keys with the same first and last letters and the same length are not permitted.Alternative algorithms and their implementations will be discussed in the next section; these algorithms overcome some of the difficulties encountered when using Cichelli's original algorithm. Some experimental results are presented, followed by a discussion of the application of perfect hash functions to the problem of natural language lexicon design.
1982	Designing SENSE (a software environment for social science rEsearch): The role of software tools	In most general purpose computer systems there is a wide variety of software available to users. Such software is usually provided in one of three organisational forms - routines in a library; collections of related functions grouped in a package with a common interface; independent programs called through operating system commands. This interdependent tripartite structure creates problems for non-sophisticated users as it involves different levels of user interface complexity.At the routine level a user must write programs in an appropriate host programming language to use the software. If he wishes to use a selection of routines written in incompatible languages then he may have to familiarise himself with more than one host language. In each language he must be aware of the calling conventions for routines, the possible representations of various types of data, the methods of passing parameters and the ways of inputting and outputting data to and from the external environment. This type of interface occurs with libraries like NAG and IMSL. In the case of packages the imperative user interface is usually somewhat simpler, consisting essentially of a name identifying the function required and some associated parameters which identify variables, labels, files, options, control and code values, etc as appropriate. However, function calls of this form must normally be preceded by a non-trivial amount of declarative and other "red tape" information expressed in the package interface language. Also, package environments can be restrictive in that the user is constrained to the types of data structure and analysis supported by the chosen package unless he is prepared to write programs to transform his data for other packages or to analyse it independently. SPSS is typical of this kind of package. When software facilities are provided at the program level, the user interface often consists simply of one-line program invocation commands written in the local operating system's command language, with program options and data files identified by command parameters. Common examples of such facilities are sort and archiving programs. A program level interface becomes even simpler, and at the same time more powerful, if command sequences can be formed into parameterised command procedures and if programs are enabled to conmlunicate directly with one another without the need for explicit intermediate files. In the latter type of environment the application software user generally finds that there are analytic program tools available to meet only some of his requirements. Consequently he has to embrace either or both of the other levels in addition in order to increase the analytic power available to him. Transfer between levels is not easily accomplished in most systems as facilities do not normally exist to help the user move data between levels. This difficulty comes on top of the obvious problem of having to master more than one interface and more than one level of complexity. In the SENSE project (11), which is funded by the U.K. Social Science Research Council, we are creating a prototype computing environment for social science researchers which can accommodate non-sophisticated users. The aim is to provide an integrated environment where such users will have a complete range of application software available (packages, routines and programs) through a single, simple user interface. We believe that this can be achieved by exploiting and extending the concept of software tools propounded by Kernighan and Plauger (19), so that as far as possible all software can be used through a program level interface, with its attendant advantages. Following Kernighan and Plauger we believe that software tools "can be used to create a comfortable and effective interface to existing programs", as well as providing an ideal model for the structuring of brand new application software. This paper will consider various aspects of the initial design of the SENSE software environment with particular reference to the importance of software tools in that design.
1982	Building and accessing an REL database	This paper discusses the construction of an experimental database at Hewlett-Packard Laboratories using the REL ENGLISH software provided by Frederick and Bozena Thompson of the California Institute of Technology. Of special interest is the quasi-natural interface and its ability to tolerate ambiguities. This provides a support mechanism for multiple user views of the same data in which disambiguation is accomplished during semantic processing.
1982	Cognitive style, categorization, and vocational effectss on performance of REL database users	Twelve subjects from two job categories, sales engineers and programmer analysts, used an REL ENGLISH database to answer a set of questions. These questions were designed to require successively more complex interactions. The database contained Hewlett-Packard's Condensed Order Records, which were pertinent to the jobs of the sales engineers.All of the subjects were given a battery of cognitive tests measuring cognitive style and pattern extrapolation skills prior to using the database. They also received a brief training session on the structure of the database.Analysis of the subjects interactions with the REL ENGLISH database, particularly analysis of the errors made, showed: first, that cognitive style is significantly correlated with the number of questions successfully completed; second, that while sales engineers were able to access all levels of the hierarchy in the database, programmer analysts had significantly more difficulty accessing data from higher levels than they did with data from the same or lower levels than the standard, entry level; and third, that programmer analysts had less difficulty with the fixed-format, programming-language-like features of REL ENGLISH, while sales engineers has less difficulty with the free-format, English-like features of REL ENGLISH.These findings suggest that quasi-natural language database interfaces are appropriate for nonprogrammers who have a field-independent cognitive style and who already are domain experts in the area covered by the database.
1981	An integral approach to user assistance	User assistance is incorporated into some of today's interactive computing systems. The assistance is rarely consistent in its accuracy, availability, accessibility or style. In this paper we discuss general requirements for assistance systems and a characterization of different types of assistance which may be provided users. A technique for integrating the design of an assistance system with the design of an interactive computing system is described. The technique satisfies the expressed requirements and greatly facilitates the development of assistance systems. Finally, a brief discussion of techniques for evaluating the quality and effectiveness of an interactive assistance system is presented.
1981	Short-term friendly and long-term hostile?	Several authors have suggested, and we are hearing some additional papers on the subject at this conference, that our computer systems should be "friendly" -- that the new user, or the infrequent user, should be able to use them quickly, without any special learning, and without any resort to written materials. My colleagues and I are responsible for a large analysis system [1, 3] that has been in active use outside its development group for about five years and which has several philosophically similar predecessor systems that go back another three or four years [4, 5, 6]. It is interactive in the sense that one of its reasons for existence is to permit the user to interact with data and tease results out of them in a variety of ways -- it has never been, nor is it derived from, a front-end to a batch system or batch thinking. Its users have ranged in skill and background from the beginning student to the professional statistician developing new techniques; from the academic researcher to the clerk in commercial environments. We draw, from this experience, some differing views on what kinds of system designs are friendly and what sorts of assumptions lead to "friendly" systems.
1981	The mini-micro connection	The office of the future is defined. It is a work station dominated by a micro computer which is in communication with more powerful computers, large disks, printers, and other equipment which can be shared. The large computers, disks, printers, and all the rest already exist. Micro Computers or desk top computers already exist. There are only two steps left in realizing the office of the future. One step involves electronics; establishing high speed communication between the desk top computer and all of the other equipment. The second involves programming; defining and developing coherent software systems. This paper is about the way in which these two problems were handled by the department of political science at the university of Iowa. Weeg Computing Center provides academic computing services for the University of Iowa. They do this with a collection of computers; there is an I.B.M. 370, 5 Prime 750s, 4 Hewlett Packard 2000s, and a Vax. There are also disks, plotters, printers, and the whole panoply of equipment one expects in a university computing environment. In addition, a Gandalf communication system makes it possible to access any one of these computers at speeds up to 2400 bits per second. These facilities are normally accessed with the aid of one of the approximately 750 terminals on campus. With the support of Weeg computing Center the department of political science convinced the university administration that it would be worthwhile experimenting with desk top computers for an entire department. Money was made available, and 37 computers were purchased. Which brought us to the two problems: high speed (in this case 2400 bits per second) communication; and a coherent system of programs. Commodore 8032s were purchased, and this meant that we needed an interface which would translate into the serial signal the Gandalf system used. Several interfaces were available commercially, but we could not make any of them work at 2400 bits per second. Nor could we get the terminal emulator programs available commercially to print the screen at 2400 bits per second. The dominant speed in micro to larger computer communication is 300 b.p.s., fast means 1200 bits per second. An interface board was designed by the electronics shop at the University for us, and a machine language program was written which would handle sending and receiving at the requisite speed. In principle this seemed a straightforward task. In practice there was a stream of nitty gritty problems that seemed as though it would go on forever. But it was done. Three design considerations dominated the creation of the software system. One, it had to be as simple to use as possible. Half of the potential users had never used a computer before. That implied that the system must be as automatic as possible. Two, it had to, initially, provide a terminal to each user plus handle word processing and electronic mail for the department. Three, it had to allocate tasks between the desk top computers and the Weeg supplied computers in a way that, within reasonable bounds, maximized the work done on the desk top computers and minimized use of central resources. Two features of the system illustrate our attempt to make it as easy to use as possible. First, signing on to the central computer is almost automatic. Each person's copy of the machine language program contains their four codes required to sign on to the system. The individual can send these codes by pressing the control key and the up arrow or programs developed for this system will automatically send these codes. Signing off is equally automatic. When the Prime on the other end has finished sending or receiving a program or data it automatically signs off. Second, all choices are made from two lists. One list is on the Prime, and the other list is embedded in the software used on the CBM 8032. Physical contiguity of choices reduces the amount of recall necessary to use the system. A good screen based text editing program enhances one's ability to put words together. It does this by making it easy to write and revise. However, there are many tasks, in addition to writing and revising, that one needs to be able to carry out with the document being written. You must be able to save and recall the text. It is very nice to be able to append a second file to the one being written. It is very nice to be able to save a segment of the file being written. And the text must be sent to be printed. All of these operations can be performed with the aid of the list of commands in the text editing program. One presses 's' and gives a file name; the programs do the rest. In addition, one would like to be able to look at a list of files that have been created and saved, delete files that are no longer needed, transfer a file to the disk storage area of a collaborator for his or her review, send a file (program or program control information) to the batch processing system, and send a file directly from the disk to be printed. All of these tasks can be performed using the list of commands on the Prime. Most of the operations one can imagine wanting to perform on a text file can be accomplished with one of the two lists. That makes the system easy to learn; it provides coherence. In this system the Prime serves as the storage device and the medium of communication. Programs and text files are stored on the Prime disk; there are no disks for the desk top computers. In addition, sending a file to be printed or sending a file to a collaborator plus electronic mail are handled by the Prime. The desk top computers handle the writing and revising which is done with a program written in BASIC to run on these computers. Since writing is an exceedingly important part of the job of academics the computers are on all the time. But most of the time they are not on to the central computing resources; they are working as stand alone computers. When you walk up and down the hall in the department of political science you see lots of computers going. Writing has become much easier. And getting a final document produced has never been as easy or as fast. The mini-micro connection works.
1981	A program for social science computer literacy	A strategy for organizing the social science computer user community is presented. The strategy recognizes that social scientists have exceptional educational needs and unfavorable budgetary constraints. A series of workshops is proposed to reduce curriculum redundancy and avoid the costly "on demand" mode of consultation that has developed in most computer centers. An example of a workshop is provided.
1981	Interfacing to text using HELPME	HELPME is a Lisp based system designed to provide on-line help for novice and expert users of computer systems. HELPME permits the implementation of easy to use interfaces to existing documents by allowing a user familiar with a document (a 'document expert') to produce an index and incorporate information relating to the structure of the document into the interface. A typical user of HELPME can then interact with the document and index through a series of commands to quickly find the information desired.The primary advantage of a system like HELPME is that it permits construction of interfaces to existing on-line documents and provides three modes of interaction with the documents: simple display, indexed-based query and context overview. Simple display permits forward and reverse movement through a document while index-based query uses key-words to select relevant sections of the document hierarchy for display. Context overview permits a hierarchical view of the document. For example, the table of contents of a document can be used to construct this hierarchy. Each of these modes of interaction are independent and may be selected by the user at any point. The goal of HELPME is to allow a user to find any information in a document relating to the user's requests. Of course, many users do not have a good grasp on exactly what they are looking for but rely on inadvertent discovery. It is hoped that the flexibility of a HELPME-like system will satisfy the goals of an easy-to-use, extensible help system for computing environments. A long term goal for HELPME is to use domain knowledge and user models in user assistance and information management.
1982	Human diversity and the choice of interface: A design challenge	As part of a field trial, the Electronic Information Exchange System (EIES) provided a variety of interfaces and user aids. Users were permitted to freely choose from the available variety at any time. They were then asked to report on their frequency of use of the various alternatives at two points in time. We found that there is no one style of interface or source of user support which will satisfy all users at any point in time, or even the same user as experience and familiarity with the system change. While their generalizability is unknown, our observations suggest that human helpers (user consultants on EIES) are the single most valued source of user support, and that system designers should consider incorporating an integrated and somewhat redundant system of both menus and commands into the interface.
1981	Living taxonomies in the corporate world: The need for multinested data models	The complexity of information processing, disseminating and controlling is very high within a sizable corporation. Database design, targeted to carry out these functions, is constantly improving. Nevertheless, nonprogrammers have trouble accessing most databases. Layers of EDP personnel, as well as unresponsive and cumbersome systems, are an obstacle to effective database use.In this paper, we describe an exploratory investigation of databases based on REL ENGLISH [1]. In our system, data structures and access language were designed to map closely the corporate structure and its terminology. Our test vehicle was a portion of Hewlett-Packard's internal information network, the corporate Order Processing System. We have identified about a dozen job related perspectives belonging to geographically dispersed and functionally stratified end-users within various entities of the HP organization. A multinested data model is an intertwined hierarchy: the join of separate hierarchies with different lexicons but shared data events. For our test, we have selected two major intersecting multinested user views: sales and manufacturing. Our design accommodates users with differing perspectives of this model.The system data structures were constructed using the REL ENGLISH primitives. The Condensed Order Records (COR) base spanned a multinested hierarchy four levels deep for the Sales Organization taxonomy and five levels deep for the Manufactured Products taxomony. The design permits the user to query the COR base about the data model itself. He can, of course, also obtain the standard statistical views of the data.Corporate taxonomies are dynamically changing structures. The database model needs to reflect this change. In most cases, the user wants to manipulate data at three levels in his own job taxonomy and at all levels in the other taxonomies. The multinested data model is needed in order to permit the user to view the data from the same perspective that he views his job in the corporate organization.
1981	A study of procedure descriptions by non-programmers (abstract only)	Providing mechanisms for inexperienced users of computer systems to program the computer to repetitively perform tasks that the user normally does in his or her daily job is one of the most challenging tasks for designers of highly interactive computer systems oriented to naive users. This report presents early results of a study conducted to ascertain the written analogues of the programming structures iteration, conditional and variables . The study required users already familiar with office procedures to practice a routine forms fill-in and data verification task over a period of one week. At the end of that time, they were required to write a set of procedures as if they were instructing a new person in the performance of the job. These written protocols (in conjunction with verbal protocols taken during the learning phase) were analyzed in terms of the above-mentioned structures.It was found that a variety of structures are used by naive users, but more importantly, all users made serious errors of both omission and commission. In particular, events of low probability were not described at all. In certain cases the written instructions did not correspond with the way in which users actually performed the tasks.The implications for office systems designers, amongst others, are explored.
1982	The graphic design of friendly faces for information management (abstract only)	Principles of graphic design have been utilized in redesigning the interface for Seedis, a large information management system. The structure and processes of Seedis are briefly described. The graphic design approach is explained and graphic design principles are outlined. Examples of enhanced menus, prompts, help messages and data directories are shown to indicate the nature of improvements.
1981	The coming world of “what you see is what you get” (abstract only)	The term 'what you see is what you get' has been used to refer to the editing of fully formatted documents so that every edit change causes the text to be updated immediately to show the document as it would appear when printed, thus eliminating the immediate step of (periodically) invoking a formatter explicitly. This mode of working is generally agreed to result in more and better results with less effort, both because the real-world simulation of a document is easier to use than a mixture of format command statements and unformatted text, and because many errors show up more immediately in a real-world situation than in a complicated abstraction.What happens if we extend this notion throughout the interface between the user and the computer? We enter a world of constrained objects and functional (applicative) actions. If the constraints are algebraic, the result is VISICALC-Iike. If the constraints are formats, the result is format programs which are also (unfilled) documents and can be created and edited as document images. If the constraints are actions themselves, the result is islands of action-programs in a sea of constraints.We propose, as the user interface, a general constraints language for documents. The documents are also "templates" or "forms", and have a robustness that makes them hard to injure. Anything may be represented as a document, from a memo to a database to a protein molecule. The commands for applying constraints all take no arguments other than the thing the user is pointing at when the command is given. The user's world is then like a large Tinkertoy environment, for constructing active and passive things.Examples of working in this world, in black and white and in color, will be given covering traditional text operations, the construction and use of document templates, the equivalent of programming as we know it, the equivalent of programming as we don't know it, and finally a John Milton template to test the relation between Paradise Lost and the fundamental theorem of the calculus.
1981	Human factors studies with system message styles (abstract only)	Computer systems often contain messages which are imprecise ('SYNTAX ERROR'), hostile ('FATAL ERROR, RUN ABORTED'), cryptic ('IEH291H'), or obscure ('CTL DAMAGE, TRANS ERR'). Such messages may be acceptable to computer professionals who regularly use a specific system, but they lead to frustration for novices and for professionals who are using new features or facilities.We have conducted five studies using COBOL compiler syntax errors and text editor command errors to measure the impact of improving the wording of system messages. The results indicate that increased specificity, more positive tone, and greater clarity can improve correction rates and user satisfaction.An overview of the experimental results will be presented along with guidelines for writing system messages.
1981	Design issues for online documentation systems (abstract only)	The design of an effective interactive documentation system is introduced by tracing a hypothetical development effort aimed at shifting information contained in printed volumes of documentation to a form suitable for interactive access. Taking this approach presents a view of online documentation systems as the result of the process of adapting information conveyed in printed volumes to the constraint of interactive software considered as an information medium. The resulting discussion necessarily involves consideration of the demands which interactive software makes on both the organization of information about interactive programs and on the cognitive capacities of people using it.Existing documentation is typically intended to serve all of the informational needs of any person who uses an interactive software system. The requirements of software systems for structure and precision demand a more detailed understanding than currently exists of exactly how to provide information to people of varying levels of experience with a particular program or with computing in general. The interaction between the purposes of existing documentation and the requirements of an online system provide an interesting context for discussion of the major issues facing the designer of an interactive documentation system.
1982	Naive user behavior in a restricted interactive command environment (abstract only)	Results are reported showing the changing pattern of command use by introductory business data processing students. Using the ability of the University of Calgary's Honeywell Multics Operating System to tailor a command and response environment, a subset of commands and responses (called GENIE) was set up in a user-friendly environment to facilitate novice students programming at CRT terminals. Frequency and time of usage of all commands was metered and changing patterns of usage emerged as the semester progressed. For example, "help" usage -- which was originally quite extensive and broad -- limited itself over time to questions only about specific topics. Reluctance to use an "audit" facility to capture an interactive session disappeared as the commands for such usage were likened to a movie camera taking pictures over a student's shoulder. It is further noted that specific emphasis was placed on simplifying commands and reducing options.The whole idea of a restricted command environment is compared to the "abstract machine" concept of Hopper, Kugler, and Unger who are building a universal command and response language (NICOLA, a NI ce Standard CO mmand LA nguage). GENIE is seen as an example of what such an abstract machine could be if the Multics operating system were viewed as a basic or "parent" abstract machine. Interactive environments such as Multics provides are viewed as essential to providing a satisfactory timesharing system for the various, but frequently intermittent uses, in the social sciences.
1981	Design considerations for data base facilities on a desk top (abstract only)	The price of computing equipment is decreasing at a rate of about 30\% per year and the cost of professional time is steadily increasing, driving industry to focus on improving professional productivity.Computer-aided engineering (design, analysis, research, testing, and planning) is a problem area where professional creativity and equipment flexibility are of paramount importance to success. Engineers and scientists are not typically computer professionals; they intimately understand the application at hand and do not want to he bogged down either with computerese and 25 manuals which might contain a desired answer, or with explaining enough of the problem to a computer professional to have the program written by someone else. Ideally, the problem solution should come from the engineer or scientist when viewed from an efficiency perspective. In such application areas, price/performance is no longer the primary factor in selecting computing equipment; ease of adaptability and availability/accessibility are becoming more important criteria when identifying a computer which can provide effective man/machine synergy.The HP 9845 Computing System has the HP IMAGE DBM System capability available as a tool for its users. To help non-computer people to design data bases (the most difficult and frightening part of using data base), we have created a data base design kit manual. This manual will guide a user, through either an intuitive or a rigorous design technique, from problem definition to a working data base diagram. From this diagram, the user is ready to define, create, and use the data base. For this, we have developed a general purpose data base management program, called QUERY/45. QUERY/45 can define and create data bases, and also provides updating facilities including adding, modifying, and deleting information with or without user-defined forms. All of the helps and teaching tools will enable engineers and scientists to use a data base without having to write any programs. After they become more experienced, the helps and menus can be bypassed in favor of formal command mode.The human factors engineering in the design of this program helps the computer system to become a partner in problem solving for the engineer or scientist.
1981	Learning effectiveness: The impact of response time (abstract only)	Response time is one of the key components of the human interface in an interactive computer system. This study evaluated two different response times and their impact on learning effectiveness. Using a counterbalanced experimental design (2**2 combinations of 2 response times), this study measured completion times, lesson mastery, error rates, and attitude. Data were obtained from student questionnaires.The Control Data PLATO Computer-based Education system provided the environment for the study. The system was connected to two networks with different response time characteristics. The means of the two response times tested were .25 sec (response time A) and 1.3 seconds (response time B). The covariate analysis of variance and chi square tests were used to show the significant difference between the two response times (p < .05), giving the following results:1. The subjects using the shorter response time finished the lessons significantly faster than the subjects using the longer response time.2. The number of subjects that mastered the lessons was significantly higher for the subjects using the shorter response time.3. The performance of subjects using the shorter response time for time dependent tasks was significantly better than the subjects using the longer response time. However, for time independent tasks, the subjects using the longer response time performed significantly better.4. The subjects using the faster response time showed significantly more favorable attitudes toward the response time experienced than the subjects using the slower response time.In conclusion, the shorter response time (A) was more efficient for learning and was more favored by students.
1981	Designing considerate systems (abstract only)	Ease of Use can be thought of as consisting of two components: Ease of Learning and Ease of Doing. In the past, most of the attention in discussions of Ease of Use has focused on Ease of Learning. This is the motivation behind consideration for the "naive" or "casual" user. The most common approach has been to allow trading computing functionality for Ease of Learning. This makes the most commonly performed tasks very simple to perform, but prevents a wide range of other tasks from being performed at all. This affects Ease of Doing.Ease of Doing is a concept that has been primarily associated with expert users of computing systems. A task is only Easy to Do on a computer if the proper tools have been provided for doing it. Since there is an enormous range of tasks to apply systems to, there must also be a large collection of tools. A great variety of software tools that are finely tuned to particular applications should be made available to users. In addition, the system should be extensible to allow for ready customization.We feel that a sophisticated personal computing environment must provide a quick path for casual users to be able to operate parts of the system, and yet allow more habitual users a path to gain mastery over the more esoteric components of the system with time.
1981	Concise natural language interaction (abstract only)	Advances in both hardware and software continue to make it possible to design user oriented systems more easily. Because we have not had a language for describing the user orientation of computer systems, a variety of interpersonal metaphors have been used to aid in the comparative evaluations of systems. Recent cultural history has shaped the semantics of computer systems. Out of the turbulent, liberal strains of the 1960s emerged the movement to humanize computer systems. During the self-centered backlash of the 1970s the term friendly became a computer household word. During the 1980s we need to grow beyond a concern for friendliness alone and build systems that are considerate.Consideration supercedes friendliness in at least three major ways, First, it goes beyond satisfaction by focusing upon attempts to help and assist others. Secondly, it requires that a person take the role of another and take the other's needs into account. Thirdly, to be considerate is to be courteous and, most importantly, respectful. In these respects, the metaphor of the considerate system points to the essence of user orientation wltbout sacrificing other critical system features such as productivity. In fact, truly considerate systems will facilitate productivity because of improved communication clarity, greater tolerance for user errors and idiosyncrasies, and increased availability of options, i.e., user-directed socio-computer interaction.Designing and developing considerate systems is not easy and requires considerable time and effort. Representative users must he involved in the selection of system features and in the process (formative) evaluation as well as the outcome (summative) evaluation. Consequently, there is a very necessary and essential role for the social scientist in the development of present day socio-computer systems.
1982	Issues for Ease of Use in personal computing (abstract only)	It has been demonstrated that interactive natural language dialog is remarkably unruly, with many misspellings and grammatical errors. Although progress has been made in getting computers to process pristine English text, the day when computers will be able to process unlimited interactive natural language dialog is still very far off.The vast majority of the effort that has gone into designing interactive natural language systems has concentrated on the computer half of the human-computer dyad. Our approach concentrates on the human half. Specifically, the goal of our research is to define a human engineered subset of natural language that retains all of the user-oriented benefits of unrestricted natural language dialog, while greatly reducing the processing burden that true natural language interaction places on the computer. This paper is a preliminary examination of the possibility that these criteria may be satisfied by simply asking usres to be concise.
1981	A study of entity-based database interfaces (abstract only)	A study is presented of a database system interface in which an entity (a concept) and the relationships in which it is involved are displayed to the user: the user is permitted to move about in the database by selecting entities related to the current one displayed. The database system is intended as a personalized database (PDB) for a scientist, student, manager, or anyone who has a need for a fast mechanism for storing and organizing a wide variety of information. The study is exploratory recording baseline times and types of behavior for a variety of personal information management tasks performed by one individual. Data entry, information retrieval, and browsing behavior are examined and contrasted to behavior with more conventional storage media.
1982	An editor-based programming support environment (abstract only)	Users of interactive systems typically must deal with numerous interactive interfaces, including especially the text editor and the system command interpreter. Unfortunately, the various interfaces too often have differing and even conflicting conventions. This paper suggests that an enhanced text editor can serve as the interactive interface for most purposes. For example, consider the file directory instead of choosing among half a dozen or more system commands to view and modify it, the user can edit an image that represents the directory. Deletion, renaming, and movement to another directory are easily accomplished with ordinary editor commands. Other system commands can he supplanted by a mechanism of "creation sequences" for files. Rather than execute the creation sequence, the user simply asks to view the file resulting from it.To facilitate this form of interaction, the text editor must include some novel features. It must permit structured files; where the structure can be a field structure within records or a hierarchical structure between records. A suitable editor is sketched.
1981	A contribution towards the measurement of user behavior (abstract only)	A prerequisite for the design of better systems - in terms of human interface- is knowledge of its users, their problems and behavior. Within the context of a larger project comparing several large statistical program packages, attempts have been made to attack the problem of "knowing the user'. Among traditional methods like surveys, different ways of automatic data collection have been tried and their strengths and weaknesses can be discussed. A particularly powerful tool proved to be a logfile which is automatically updated each time certain software is used. It contains individual level data about size of job and data set, control cards and -statistical procedures used, types of errors and more. This gives valuable insights about:--the structure of the user community.--styles of package use,--weak points of packages.In my paper I will discuss some general problems of recording and analyzing user information, and will present data fre~ the logfile described. This should he considered as an example in the methodological discussion as well as a substantive contribution to the analysis of SPSS-use and -users.
1981	What makes computer games fun? (abstract only)	One can't deny the effectiveness of video arcade games in reachipg users! Just loop at the number of quarters pushed into the slots, the time spent by people of widely differing abilities, and the number of repeat encounters with the systems. At least part of the success is due to the ease of getting started (the first play of the game gets one comfortable with the procedures), the high degree of visualization of controls and results, and the responsiveness overall. Other factors will be taken up by the panelists.Review of the home computer market shows what can be accomplished by an easy-to-use accounting aid through advertising store demonstrations, and word of mouth. Visicalc has sold over a million dollars! Attendees will have an opportunity to try some of these impressive applications before and after the session.
1981	Direct manipulation: A step beyond programming languages (abstract only)	Direct manipulation is a style of interaction which has been used by implementers of widely varying systems. Direct manipulation permits novice users access to powerful facilities without the burden of learning to use a complex syntax and lengthy list of commands. Display editors use direct manipulation more than line editors. Form-fill-in is more direct than tag fields and delimiters. Spatial data management is more direct than query-by-example, which is more direct than SEQUEL. Computer arcade games and Visicalc are further examples.Direct manipulation involves three interrelated techniques:1. Provide a physically direct way of moving a cursor or manipulating the objects of interest.2. Present a concrete visual representation of the objects of interest and immediately change the view to reflect operations.3. Avoid using a command language and depend? on operations applied to the cognitive model which is shown on the display.
1981	What can be learned from arcade games and home computer applications? (A Panel Discussion): The case for considering games and home applications (abstract only)	The presentation deals with two questions:1) What makes games so captivating?2) How can the same features (that make computer games captivating) be used to make other user interfaces more interesting and enjoyable to use?First, three empirical studies are described. These studies analyze which features of several computer games are most important in making the games enjoyable. Then a set of heuristics for incorporating these features in other user interfaces will be outlined. The heuristics are organized in three categories: challenge, fantasy and curiosity.
1981	Learning how to confer: The interplay of theory and practice in computer conferencing (abstract only)	Members of the Merit staff first met Robert Parnes in the fall of 1975 and began participating in his experimental CONFERence shortly thereafter. It soon became evident that CONFER could help us provide consultation to our users, who were distributed over a large part of southeastern Michigan, and in January of 1976 Merit started what we believe to be the first CONFERence open to the general public, MNET: CAUCUS.Five years later CAUCUS is still alive and well, and we still use it to provide help to a widely-dispersed user community--in fact, with the advent of Telenet service later that same year, and with Telenet's subsequent expansion of service to Canadian and overseas networks, our users are spread all over the world. But we have learned over the years that computer conferencing is good for much more than simply facilitating the user-consultant relationship. As we gained experience with CONFER we found that it gave us a solution to problems that were so basic we had simply taken them as part of the environment. CONFER also provided a medium for communication among consultants--the Merit staff--and among users.
1981	The CONFER experience of the Merit Computer Network (abstract only)	CONFER emerged from a concern with small group governance in both its communications and decision making dimensions. This context will be described as well as the principles operationalized in the CONFER system: individual equality, freedom, privacy and flexibility, and the facilitation of individual participation. CONFER is based on the proposition that effective communication is an active process for all concerned. This activity is strongly encouraged in CONFER through a number of mechanisms designed to facilitate interaction between the user and the CONFER system, as well as interaction among all the users of the system. As well, growth of the system over time is promoted by interaction of the system designer with the user community. The development of Merit's use of CONFER was aided greatly by our continuing close relationship with Dr. Parnes and by the participation of many members of the Merit staff in the CONFERence for CONFER development that he eventually began. As we identified new aspects of CONFER use, we usually also were able to think of changes to CONFER that would facilitate them. For example, as we began to realize how important was the general conversation among our users--a critical need for the isolated user in particular--we led the lobbying effort for changes to make the voting structure more interactive. In response, CONFER over the years has radically altered the default form of participant comments from its original formal and anonymous style to a conversational model. Similarly, as CAUCUS grew to enormous size we asked for (and got) aids in managing, and then in re-starting, large Conferences. In a remarkably short time, CAUCUS became a general meeting place for many who were not Merit users at all, simply because it offered a place for users to meet one another and share problems and solutions. Eventually CAUCUS gave birth to a general-purpose CONFERence for users of one of the host systems--an idea that has since been implemented elsewhere as well. The growing use of CAUCUS as a communications medium for Merit staff eventually resulted in the birth of a CONFERence for that specific purpose. Before the use of CONFER there had been relatively little communication between the staff members at the central site and those located at the host computing centers except for occasional face-to-face meetings that were largely reportorial in content. Once CAUCUS showed the staff that network issues could be discussed in real time and that input from the host staffs could have weight, the pattern of decision-making began to change. With the inception of the MNET:STAFF CONFERence, and the resulting privacy for internal discussions, the role of the staff members--both centrally-located and at the hosts--continues to grow as we expound, lobby, and negotiate on network issues while (or even before) they are happening. It is no exaggeration to say that we members of the Merit staff could not do the job we do without CONFER. Merit's primary goal is to facilitate the use of remote computer resources for a heterogeneous and dispersed community of users. Without CONFER we would be working harder to accomplish much less of this objective.
1981	Case study of a user-oriented conferencing system (abstract only)	This session described how CONFER, a computer-based conferencing system at the University of Michigan, was developed with participation of users, and what impact the system has on communities of users. At this conference it may be especially interesting to discuss various ways in which help provided to new users has evolved. Some extrapolations may be made for other than electronic communication aids: orientation and training, on-line reference information, on-line consultation, etc.
1981	Uses of CONFER at Wayne State University (abstract only)	CONFER is used by a variety of organizations which have no direct contact with any MTS site (the CONFER host computer system). In many cases, the main contact of the CONFER user is with the third party vendor or consultant who is supporting the networking effort. Several problems arise when the third party relationship is not broadened to include the institutional consulting and documentation efforts. Such problems include:1. Overload on the time of the third-party consultant.2. Production of custom documentation which parallels the institutional documentation.3. User perceptions that they are not "ready" for institutional documentation.4. Development of abbreviated cognitive maps of the system and its user network.5. Users exchange superstitious views of how the system works.While it is not yet clear that the absorption of third-party, mediated networks will solve such problems, it is an obvious first step to a solution. MTS Help Facility A version of CONFER is tentatively planned for use as the principal Help Facility at WSU. A subset of CONFER capabilities will be employed to decrease demands on the system. Features of the Help Facility will include agenda string searches, execution of computer assisted instruction lessons from within tbe CONFERence, a "suggestion box" facility, and user modelling features intended to decrease user frustration and maximize efficiency. Existing help files will be called from the Help Facility to increase the redundancy of available help to the user. The agenda used will be multi-dimensional, allowing the user to search for help within subject areas, type of information and skill level. For example, the user would be able to view all items which serve as tutorials on statistical packages with the CONFER command: AGENDA TUTORIALS+STATISTICS. Similarly, the user will be able to search item descriptors or text for character strings, such as using WHICH "SPSS" to locate all items dealing with SPSS. Requests for help will be sent directly to various CSC departments, and responded to either via CONFER or telephone. User suggestions and requests will be screened on a continuing basis by CSC staff, and changes to the information contained in each item will be made as a result of these suggestions. Materials developed by users will be solicited for inclusion in the Help Facility.
1981	Third party consulting in the network environment (abstract only)	CONFER, first used at Wayne State University in 1979, has proven itself to be an extremely useful and adaptable communications medium. Some examples of present CONFER applicatons at WSU are: Computing Center Staff CONFERence Presently used to coordinate communication between the 180 staff members of the CSC. Communications between various departments isolated by distance and responsibility has been improved. Specialty CONFERences CONFERences exist on such varied topics as school transportation, text processing, nursing education, microcomputers and instructional technology. Project Management Used by the University's PLATO development staff for cross-campus management decision-making and communication. CONFER has reduced the need for staff meetings, has served as a "tracking device" for personnel appointments, and has kept a detailed log of project decisions. CONFER has also been used for CSC project development, notably for the design of an MTS Help Facility. Academic Communications CONFER has been used to facilitate communication between students in an undergraduate Computer Science course, for graduate students in Instructional Technology, and for individual student projects. This summer, a CONFERence will be implemented which will manage course communications for 300 students in a freshman Computer Science course.
1981	A TEXT-RETRIEVAL SYSTEM USED IN HUMANISTIC ARCHIVE APPLICATIONS (abstract only)	NOVA*STATUS is a text-retrieval system which is available at all Norwegian universities and several government institutions, running on computers from different manufacturers. NOVA*STATUS is a full-text retrieval system originally developed by AERE, Harwell, England, and redeveloped at the Norwegian Computing Centre for the Humanities and other Norwegian institutions. The data is divided into documents and each word (or a truncated part of it) in each document is potentially a key word. The format of the document is free. By use of prefixes it is possible to divide each document into specific fields of information. A request to the system can consist of a Boolean expression of words and prefixes and relational expressions between prefixed words. The system allows for macros which can be permanently stored which makes, for example, synonym lists possible. The system also contains procedures for off-line sorting and printing of catalogues and for the coding of data for statistical analysis by SPSS. At the Norwegian Computing Centre for the Humanities, NOVA*STATUS has been, and is still being used in a variety of humanistic archive applications. Several of these have a common data format which consists of 20-30 defined fields of fixed information and one or more fields of free-text description of e.g., photographs, paintings, archaeological and cultural artifacts, old buildings and documents. The second part of the paper will describe the actual use of the system in these various applications.
1981	Introductory sociology with the general social survey (abstract only)	The purpose of this presentation is to describe an alternative sociology course that links student computer skills with available social survey data. Students are given access to a file of SPSS programs which they can easily modify to fit their own purposes. Using the General Social Survey they can test hypotheses on current data reflecting their interests. The broad range of data allows beginning students with little or no previous computer experience to investigate a wide variety of topics.
1981	Comparison of some available packages for use in research data management	Data management features of SIR, SAS, and SPSS were applied to a sample hierarchical data base. For each package, the areas investigated included the logical definition of the data base, data entry, data retrieval, data integrity, security, reporting, and updating.
1981	Organizing the annual housing surveys as a very large relationally oriented data base	Since 1973, the Department of Housing and Urban Development, through the Bureau of the Census, has conducted a yearly nationwide survey of housing. Data on a wide range of topics are collected during face to face interviews with over 190,000 individuals. Plainly, the Annual Housing Surveys represent one of the largest longitudinal general social and economic data collection efforts ever undertaken.Due to changing policy and substantive interests, as well as government requirements, the interview schedules have changed significantly from year to year. Since the great potential for data from the Annual Housing Survey is in longitudinal analysis, it is necessary to have common variable definitions and consistent formats.To accomplish this, we have developed and implemented a system which includes: 1) documentation of the variables, questionnaires, and files across all years and surveys; 2) files created using one homogeneously defined data structure; 3) a simple system to produce custom user files; 4) a method to easily produce routine custom analyses and tabulations using the data.We have applied the relational model to create a small data base which documents the interview schedules, files and variable definitions. From this we produce up to date documentation and computer programs which are used to update the Annual Housing Survey data base, to handle custom file requests, and to perform analyses.
1981	The 1940 and 1950 Public Use Sample Project: Data quality issues	The 1940 and 1950 Public Use Sample Project is the creation of 1/100 household samples from the 1940 and 1950 Censuses of Population. The data source for the samples is the microfilmed original Population Schedules which contain the census enumerator's recording of household information. The procedure to sample the universe of household listings and transcribe the sample households' data is described in the paper. A pretest of the 1940 Public Use Sample included a comparison of three methods of sampling and transcription. The results of this comparison are reported. The applicability of these procedures to similar projects is discussed.
1981	The automation of data processing, analysis, and reporting in a large survey time-series database.	The May 1981 Survey will mark the 152nd Survey of Consumer Attitudes. Initiated in 1946, the purpose of the surveys is to measure changes in consumer attitudes and expectations, to understand why these changes occur, and to evaluate how they relate to consumer decisions to save, to borrow, or to make discretionary purchases under changing conditions.Each survey contains approximately 40 core questions, each of which probes a different aspect of consumer confidence. Open-ended questions are asked concerning evaluations of expectations about personal finances, employment, price changes, and the national business situation. Additional questions probe for the respondents appraisal of present market conditions for houses, and other durables. Demographic data obtained in these surveys include income, age, sex, race, education, and occupation, among others. While many questions designed to measure change in attitudes and behavior are repeated in identical form in each survey, special questionnaire supplements are added to most surveys by outside sponsors on a time share basis. Supplements to the ongoing surveys give sponsors prompt turnaround to survey materials while taking advantage of shared field expenses. When the research task is first undertaken, a maximum amount of time and effort can be spent in developing these survey materials, not in establishing and setting in motion standard sampling and interviewing procedures, questionnaire and code development for standard demographic items, and so forth.Although each survey task is unique in its time requirements, shared time participation on the ongoing Surveys of Consumer Attitudes is an effective and flexible approach for meeting many research needs. Current procedures include production of a fully documented computer data file available for analytic use within 48 hours of the close of interviewing. Within one week of the close of the survey, a report containing tabulations and charts of questions asked is sent to the sponsors.
1981	A new process for documenting and checking archival data	The Inter-university Consortium for Political and Social Research (ICPSR) is a data archive and repository for social science data. A major function of the ICPSR is to disseminate the data holdings in a reasonably standard format. For holdings that will be extensively used, additional effort is made to prepare comprehensive, machine-readable documentation, to cross-check the documentation against the data for accuracy and consistency, and to correct or document any inconsistencies discovered.In the past, "cleaning" and documenting the data involved using a number of different computer programs. A great deal of human time was expended on procedural matters: which programs to use, when to use them, and how to coordinate the various stages of the cleaning process. As staff costs and the number of new acquisitions skyrocketed, and computers increased in power and decreased in cost, it became imperative to automate as much as possible the procedure for preparing data for distribution. The GIDO software was developed to meet this need.GIDO is an interactive multi-function program package that guides staff members through the procedure for documenting and cleaning social science data. A cohesive history of the processing operations performed on the data is maintained automatically in machine-readable form. Video terminals are used to display "forms" which the staff fill out with the textual and technical documentation for the data. GIDO immediately verifies the contents of each form and provides an opportunity to make corrections. The forms allow the input of information without requiring knowledge of specialized syntax and conventions. After all documentary materials have been entered, GIDO checks the data for consistency with the original documentation, corrects or flags discrepancies encountered, reformats the data using uniform conventions, and produces machine-readable documentation in a form ready for dissemination.Use of GIDO enables the ICPSR archive to perform its data processing functions more efficiently and at lower cost, thus permitting the organization to meet ever-increasing demands on its resources.
1981	An automated system for responding to data service requests	During the 1970s, there was a steady decline in the cost and size of computing hardware with a corresponding phenomenal growth in computing capability. Computers now help store, manage, duplicate and interpret vast quantities of data with an ease and relative economy undreamed of in the past. These developments have, over the years, fostered the growth of new research methods in a variety of fields, including the social sciences. Large and more complex bodies of quantitative data have been collected as social scientists seek ways to understand human behavior with empirical research methods and scientific sampling techniques. In addition to collecting their own data, researchers have also utilized vast amounts of machine-readable data that have been prepared by other researchers, governmental agencies, and private organizations.The changes in the computing industry combined with the increased demand for services have made it feasible for organizations to consider automating as many tasks as possible. FAST (Facility to Aid Servicing Transactions) is one system that was created in response to these conditions. This paper describes FAST and its impact on the organization which developed it.
1981	Online searches of social science data sets: The RIQS system and ICPSR data	Every solution seems to generate a new problem. The problem of accurately assessing public opinion led to the invention of the sample survey. The subsequent problem of analyzing survey responses brought widespread use of machine-readable data. The problem of preserving machine-readable data for secondary analysis stimulated the creation of data depositories or "archives." Growth over time in the holdings of these social science data archives, however, has aroused needs for improved retrieval of data. This paper explains one method of dealing with such needs. It involves an interactive search of the holdings of the most diversified social science data archive, the Inter-University Consortium for Political and Social Research, using a general-purpose information retrieval system, RIQS, written for CDC computers.
1981	Developing an aggregated survey/macro-economic database for statistical and graphical social science applications	The Survey Research Center at The University of Michigan has routinely conducted surveys of consumer attitudes since 1946. The May 1981 survey is the 152nd in this series which provides regular assessments of consumer attitudes and expectations. The surveys are designed to explore why changes in consumer attitudes and expectations occur, and how these changes influence consumer spending and saving decisions. A major research objective of the project is to use this collected data to evaluate economic trends and prospects.Each survey contains "standard" questions asked at regular intervals, many of which have been included from the project's inception. The aggregated results of these surveys provide a wealth of time-series data with the potential to be an important factor in forecasting consumer behavior. The "standard" questions themselves can be disseminated into approximately 190 separate data series (including index transformations). When "nonstandard" (or non-core) questions are included, this total jumps considerably. With such a large number of data variables, many different areas of analysis are available to be researched. When the many macro-economic data series (e.g., Federal Reserve, Census, or Retail Sales data) are added to this compilation, the data management problems increase. The research results which could be achieved, then, are directly related to the development of a flexible method of data storage and retrieval.
1981	On-line manipulation of small area demographic data: AmericanProfile sm	A new approach to the way in which users interact with the computer in an on-line environment is presented. The method is designed specifically to provide both a friendly and highly productive means of communicating user requirements. Unlike systems which are targeted toward either novice computer users or experienced programmers, the approach we take is well suited for all levels along this continuum. AmericanProfile sm , a system which provides access to demographic and economic data for both standard geo-political units of analysis (states, counties, SMSA's, Zip codes, etc.) and unique small areas (polygons, circles, etc.), is discussed as an actual case point to illustrate our approach.
1981	Bibliometric analysis of ISI's Arts & Humanities Citation Index (abstract only)	The most frequently cited journal articles in the Arts & Humanities Citation Index (A&HCI) are analyzed in terms of their disciplinary classification. Four years (1976-79) of the A&HCI data base yielded 144 journal articles which were cited 10 or more times during the period. These articles are predominantly from the disciplines of Language and Linguistics (31\%), Philosophy (23\%), History (13\%), Religion (8\%), and Archeology (6\%).However, most citations in the A&HCI are to books rather than journal articles (96\% versus 4\% among those items cited 10 or more times). The discipline of Literature (or Literary Criticism) is predominant in the list of highly cited books.These statistics suggest systematic variation in the resources used by the different disciplines. Various other aspects of the A&HCI data base are explored, and some specific examples are discussed in depth.
1981	Bibliometric analysis of Amrican history data by FAMULUS (abstract only)	NOVA*STATUS is a text-retrieval system which is available at all Norwegian universities and several government institutions, running on computers from different manufacturers.NOVA*STATUS is a full-text retrieval system originally developed by AERE, Harwell, England, and redeveloped at the Norwegian Computing Centre for the Humanities and other Norwegian institutions. The data is divided into documents and each word (or a truncated part of it) in each document is potentially a key word. The format of the document is free. By use of prefixes it is possible to divide each document into specific fields of information.A request to the system can consist of a Boolean expression of words and prefixes and relational expressions between prefixed words. The system allows for macros which can be permanently stored which makes, for example, synonym lists possible. The system also contains procedures for off-line sorting and printing of catalogues and for the coding of data for statistical analysis by SPSS.At the Norwegian Computing Centre for the Humanities, NOVA*STATUS has been, and is still being used in a variety of humanistic archive applications. Several of these have a common data format which consists of 20-30 defined fields of fixed information and one or more fields of free-text description of e.g., photographs, paintings, archaeological and cultural artifacts, old buildings and documents. The second part of the paper will describe the actual use of the system in these various applications.
1981	Bibliometric analysis of isi's Arts & Humanities Citation index	Bibliometrics, the quantitative study of literature, has made a considerable contribution to the management of scientific libraries and to the understanding of the sociology of science. It has joined operations research as effective management tools in making substantial impact on optimization of library services, resources sharing and allocation in library networks. With the common belief that humanistic literatures are different, these analytic techniques have not been applied to any extent. We believe that although sociological factors may impact on the humanities in different ways, patterns of regularity in communication, individual contribution, and literature growth shall be studied. Knowledge of the characteristics of humanistic literatures may enable us to improve information access and to maximize available resources in space, manpower, and funds for books. A pilot study has been attempted on a bibliography of the history of the American Revolution.The data base is constructed from the Writings on American History: A Subject Bibliography of Articles under the heading "Revolution & Confederation (1763-1789)". To facilitate the analysis, the data management program FAMULUS was used. Selected Results : 1095 articles were published between 1962-1976 by 790 authors in 224 journals or publishing sources. The average author productivity is 1.39 which is similar to other fields studied. As expected, a few highly prolific authors dominated the field, and their productivity distribution follows the well-known Lotka's Law. The dispersion of publications over journals also adheres to Bradford's distribution, identifying the most productive journal in this field as the William and Mary Quarterly . Thus, scholarship in general assumes certain common characteristics regardless of the discipline. Yet differences exist. There are only 77 (10\%) authors who have ever co-authored in a mere 47 (4\%) of the total literature. This is a dramatic departure from the intensely collaborative enterprise of science in which almost all scientific writers co-author.From our experience, FAMULUS is a useful tool in bibliometric analysis in addition to being a good personal documentation system to replace our shoebox of cards. We have also used it in the teaching of indexing and retrieval of documents.
1981	A thesaurus for Canadian iconography (abstract only)	The Picture Division of The Public Archives of Canada has undertaken the construction of a thesaurus of iconographic terms as part of its preparations for a computerized inventory system. The thesaurus which complements an existing set of descriptive standards will serve as a terminological control device enabling indexers and researchers to translate natural language into a more restrained and logical system language. General characteristics of the thesaurus will be described. Special emphasis will be given to the impact of on-line information retrieval computer technology on the design and development of the system language. Sample pages of the thesaurus will be available for examination and further discussion. An overview of other Canadian experiments in the field of subject access to visual records will also be provided.
1981	The text's the thing: Concordances to literary texts (abstract only)	The history of computer-generated concordances is already one-third of a century long. Thousands of concordances have been generated; many have been published. Most of these are useful, but there are limitations to all of them. In this presentation I discuss a number of variations on concordance-making based on specific projects being carried out at the University of Colorado.A word-form concordance can be of considerable utility. Particularly for older states of language of which our knowledge is often less than perfect, this "primary" concordance form seems best for initial circulation, but such a concordance is insensitive to variants and ambiguities. It is often as suggestive of what might have been done as it is directly useful.With the increasing availability of microcomputers and various kinds of remote terminals, it is now possible to remove many of the difficulties of text-editing so that a "secondary" concordance edited toward particular applications can be produced more readily. At the University of Colorado, at which the majority of humanists who use computers wish to make maximum use of the available technology without becoming computing scientists, I have found it practical to suggest a particular synthesis of batch and interactive computing. This involves the use of a retrieval, concordance-generating, and editing system so modular in design that editorial intervention is practical at many points. This editing makes use of device-dependent text editors of sufficient sophistication that the user perceives little of the technical operation beyond requesting his programs and his text; otherwise he has the freedom of a typewriter coupled to the benefits of a screen for displaying modifications to his text as they are made, whether directly by him or by a variety of programmed functions. Stations built around "smart" terminals as well as "dumb" terminals with microcomputer and floppy disks are operational.Thus it is now more practical to produce second-generation concordances which more nearly reflect the perceived needs of a scholarly community: words may be (manually) disambiguated by meaning and function, contexts may be edited either to omit extraneous material or insert explanatory matter, and words may be clustered by dictionary or thesaurus. The result is concordances of far greater utility in specific areas and more meaningful statistics.The development of better equipment and new techniques has made it possible to interact more thoroughly with one's text. There is no need for premature data reduction, but rather the encouragement of what I call the "infinite loop of literary scholarship": one works with one's texts to produce results which suggesst work to produce more results which suggest still more work .... The newer technology seems to fit the humanist far better than did the old.
1981	Sift - searching in free text: A text retrieval system (abstract only)	The SIFT project is aimed at developing an advanced text retrieval system possessing the features of high modularity, high portability, possibilities for integration with word processing systems and a flexible user interface. Possible applications for such a system would be found wherever any sizable collection of information requires efficient retrieval. The SIFT system is mainly designed to solve the problems of searching in free, i.e. unstructured, text but extensive functions for dealing with structured information are also offered.The SIFT project is based on former experience in the use of other retrieval systems, particularly the Norwegian version of the British STATUS system, NOVA*STATUS, a system which has found application in various public agencies and at all Norwegian universities.The SIFT project was initiated on January 1, 1980, and a prototype version of the system will be implemented on a NORD computer towards the end of 1981. The final product will be made available free of charge.This presentation will treat the structure, characteristics and applications of the SIFT system.
1981	The role of the computer in ethnographic analysis (abstract only)	Art and architecture literature presents indexing difficulties due to the absence of a recognized controlled vocabulary. A recent investigation showed a number of independent partial efforts targeted to local needs. The Art and Architecture Thesaurus (AAT) group is building on the experience of others to create a unified, hierarchical thesaurus for these fields. Although the thesaurus itself will be in machine "readable form, the real value of automation will be the ability to search hierarchically the literature indexed with the AAT.
1981	Thesaurus on American works of art (abstract only)	FOLK is an online analysis and retrieval system developed for the 1801 census of Norway, which is machine readable in a full-text and a coded version, each with approximately 1,000,000 records on individuals. The main advantage of the system is speed. FOLK consists of several parts:- A fast program for statistical analysis of the simple kind. Cross tabulations can be done in 1/16 of the time used by SPSS.- An interface to statistical and graphical packages for more complicated analysis.- A retrieval system for finding subsets of the data base. The subset can be anything from a single person to a region. Information from the coded and the full text version can be used for subtracting individuals.- A recoding system for recoding the coded version using a simple semantic analysis of the full-text version.- A fully computerized record linkage system. Information from other sources can be automatically added to the records on the individuals in the census.
1981	Art and architecture thesaurus (abstract only)	Designing and providing subject access to works of art has traditionally been very subjective. This is due to the fact that there are no standardized word lists which can be expected to meet the scope of all art collections. Whereas tailoring subject terms to the scope of a given collection is the most practical approach for the curator in charge of the collection, the researcher, who may not be an art specialist, often is frustrated when the listing of subject terms does not include the terms relevant for his/her purposes. This presentation will explore how the development of a thesaurus resolves the conflict of subject vocabulary. Specific examples will be drawn from four computer projects at the National Museum of American Art. Each of the projects varies in scope, yet a single subject classification guide has been developed for purposes of providing subject access to the contents of each project.Because a separate subject word list was not originally designed for each project, a thesaurus is now being developed which will allow for a listing of terms not used for indexing but which are relevant to both the scope of each project and anticipated researcher needs.From a practical viewpoint, the presentation will demonstrate how the computer can be used to generate terminology to be included in the thesaurus.
1981	Folk (abstract only)	Ethnography is a methodology which emphasises a "soft" interpretative approach to social reality. It is often portrayed as being at the opposite pole to quantitative approaches as exemplified in the classic Merton-Lazarsfeld paradigm (Structural-Functionalism wedded to the survey method).Ethnography is a method in which the researcher actively engages in and records the life of a social group. This record of experience is essentially qualitative. It is primarily constructed in the form of textual description: an ongoing account of a person's observations, thoughts and feelings while in the "field". This text is usually given the generic title of field-notes.The Ethnographic researcher is therefore normally confronted with a vast amount of textual data. To get some understanding of, and control over this data, the Ethnographer must in some way split up this record of raw experience. He must in some way "chunk" up his data into easily manageable units or categories. It is this classificatory activity which forms the basis of Ethnographic analysis.In greater detail, Ethnographic data analysis may be generally portrayed as consisting of three analytically distinct, but empirically indistinct activities: represents a1. The reading of field-notes, accompanied by the recording of themes and hypotheses;2. The coding of important topics observed within the field-notes under different category headings;3. The disassembling of field-notes by coded category; the purpose being the creative filing and retrieving of one's data.The prime concern of this presentation will be to discuss means by which such analysis may be accomplished.It is the author's belief that the schema shown below possible evolutionary trend in Ethnographic data analysis: items lower down the schema give the Ethnographer greater power and flexibility in the way he handles text. Reference will be made to presently ongoing research at Cardiff as evidence of this claim.1. The Traditional Filing Cabinet.a. Simple chronological filing of text.b. Multiple filing: the actual disassembling of text into files.2. The Filing cabinet and Separate Indices.a. Chronological filing: card indices.b. Chronological filing: specialised indices.c. Chronological filing: computer indices.3. The Full Computer Approach.a. Indices and fieldnotes stored on UNIX.b. A System of Personalised Interactive Computing for Ethnographers. SPICE: a term purely invented to emphasise the "spice" of Ethnographic research.Finally, this presentation will also discuss the implications that this research has for textual management in general. The projected computer arrangement will, I believe, prove of advantage not only to the Ethnographer, but to any researcher who employs continuous text as his/her primary resource.
1981	New file management in P-STAT (abstract only)	In January of 1981, the Center for the Study of Youth Development initiated an on-line catalog of the holdings of its specialized library consisting of 10,000 monographs, journals, vertical file materials, etc. The present paper discusses the reactions of the end-user or patron population to the resource. The background of the library automation project -- including issues of cost-effectiveness, increased power, and user utility--is discussed in order to establish the initial goals of this activity. Then, attention is given to how the project was implemented; this includes a comparison of preliminary goals with what ultimately was delivered. The transition from a COM catalog to the on-line catalog required training of patrons (some of whom had little or no experience with a computer terminal), and only half of the Center staff participated in the initial training sessions. Preliminary patron behavior is reviewed, and an attempt to informally analyze both positive and negative experiences is offered. The initial experiences are summarized in a discussion of the problems and prospects of the user interface of the "query" portion of the on-line catalog software.
1981	Initial experiences with an on-line catalog (abstract only)	P-STAT began as a collection of integrated commands which read rectangular files sequentially. A simple modification language for recoding and case selection was added in the late 1960's. Commands were added throughout the 1970's. Recently, however, a major effort has gone into language enhancement and file structure improvements.P-RADE, a random access data enhancement to P-STAT, is an example. This type of file structure supports up to 10 indexing keys, allowing a case or a group of cases to be accessed very rapidly. In addition, any P-STAT command can read a P-RADE file sequentially in any key order.In some ways, this approach blends aspects of database technology into statistical software. Examples of its use will be given.
1981	Urben research in ethnic, demographic and household-economic structures with small area, micro-databases (abstract only)	Computerized U.S. Census data has been most widely used for (1) employment, fertility, demographic and stratification research involving Public Use Sample (PUS) microdata on the national level, and (2) applied research (for planning, administration, marketing, and other applications) with summary (aggregated) data for localized (i.e., block, tract, community, etc.) geographic units. A third, highly productive avenue of research, involving Census PUS micro-data for localized urban units (i.e., SMSAs, counties and especially selected large-city neighborhoods), has not received the attention it merits, either among sophisticated public data users or among novice users.Three forms of current or future small area, Census microdata constitute resources for urban research. First, conventional 1970 Census PUS data sets are available for counties and/or SMSAs (with minimum populations of 250,000). Second, special tabulations for the two largest U.S. cities permit analysis of 1970 household and person records group by (sub-county) urban neighborhoods (27 in New York City; 12 in Chicago). Third, 1980 Census microdata, by allowing identification of geographic areas of smaller population size (100,000 population), will vastly expand the applications of localized research with the conventional PUS or special tabulations. In addition, the 1980 PUS microdata will, for the first time, allow comparative time-series analyses of county (or SMSA) area populations, over the 1970-1980 decade.In contrast to national PUS microdata research, local level analyses have the advantages of (1) smaller data set size and processing costs, (2) more immediate integration of computerized research hypotheses with additional sources of (qualitative) information and questions (stemming from direct knowledge of the communities studied), and (3) increased ability to zero in on specialized ethnic, occupational-industrial, migrant, age, etc. urban population groups which are disproportionately represented in particular local environments. Our own research projects (at various stages of development) which attempt to exploit these advantages include computerized analysis of:1. Patterns of household composition, and source and structure of family income, among Upper East Side and Upper West Side Manhattan residents with family incomes of $ 50,000. or more (as reported in the 1970 Census)2. Employment patterns of married women of Cuban immigrant background, in relation to family class position and period of immigration, for Hudson County, New Jersey3. Contrasts in the occupational positions and household patterns of first-generation and second-generation husbands and wives of Italian background in a New York City working class community (Astoria-Long Island City, Queens)4. Wives' employment patterns in relation to ethnic background and husbands' occupations and income levels in a working class community located in a manufacturing center (South Side, Chicago)5. Change in the social and demographic characteristics of succeeding groups of migrants to an expanding "sunbelt" metropolitan area (Albuquerque, New Mexico)6. Contrasts in local housing markets and housing availability, involving analysis of the number and characteristics of vacant housing units for New Jersey counties.These, as well as other projects we have assisted, have been undertaken with varied software resources, including packages (such as CENTS-AID) with unique hierarchical file processing capabilities, as well as more versatile (non-hierarchical), general purpose packages (such as SPSS). The advantages and research applications of small area, micro-databases can be realized with a range of software techniques and user-formulated research strategies.
1981	Beyond cataloging functions for art museum data banks (abstract only)	A data management system for art museums is presented. In addition to providing conventional cataloging functions such as searching, sorting and indexing, the system is shown to be able to model complex relationships between entities relevant to the application. The importance of this capability with regard to representing higher levels of information (beyond pure physical characteristics) is pointed out. Alternative representations of such relationships are discussed and some directions of further work in the area of automation of a museum's catalog is cited.
1981	Making computer capabilities accessible to musicians (abstract only)	During the past ten years at The Ohio State University we have developed a large library of music-related computer programs, encompassing many aspects of music scholarship. These programs include procedures for performing basic music analysis functions as well as programs for information retrieval. We have also prepared a considerable library of encoded musical data and bibliographic information. All our programs and data are stored on disks on OSU's Amdahl 470, making them immediately accessible to any computer programmer who has been initiated into the mysteries of manipulating disk-stored data sets. We wanted, however, to make everything equally accessible to those musicians who are not particularly interested in mastering the complexities of computers, but who would nevertheless like to make use of computer-produced results. We have taken two significant steps toward solving this difficult problem:1. SLAM (Simple Language for Analyzing Music), a "super-high-level" language written in SPITBOL by Thomas G. Whitney (formerly on the staff of OSU's Instruction and Research Computer Center). With SLAM, the musician specifies which music analysis procedures and which musical data he would like to use, communicating with the computer in normal English using traditional music analysis terminology. Though he must satisfy certain syntactical requirements and must include certain key words, such constraints are minimal. For example, "Please count the intervals in the alto voice of Bach's chorale 308." and "Count intervals alto 308." are both legal SLAM commands which would produce the same results. SLAM translates the user's request into the appropriate job control language statements which call the programs and data necessary to perform the task.2. IRRS (Information Retrieval Request System), written in SPITBOL, currently under development. This system provides access to different types of bibliographic, textual, and descriptive data stored on the computer. The user makes his request in the appropriate format, and the computer executes the steps necessary to produce the requested information. For example, in order to retrieve a bibliography of books and articles written between 1960 and 1970, dealing with the perception of music intervals, the user enters "keyterm: perception, music intervals" and "year: 1960-1970" from a computer terminal. The terminal then prints a list of books and articles meeting these criteria.SLAM has been very succesful. Not only have the non-computer-programmers found SLAM invaluable, but even our musician-programmers have found it much easier to access existing programs through SLAM. The information retrieval programs are well under way, and we expect them to be equally useful in providing access to research materials. In short, we are achieving our goals: 1) to make available a variety of computer procedures and data to computer-shy musicians and 2) to eliminate the fears, disappointments, and general confusion too often associated with musicians' attempts to use computers.
1981	Requirements for improving the use of computers to support the development of policy decisions (abstract only)	Computer based information systems have been developed and used successfully for production and engineering and for lower level management tasks but they have yet to be widely applied to aiding management decision making at the higher policy making levels. Despite many attempts, the failures have been many and the successes few. This has resulted in large part from the fact that the technicians who have been engaged to design such systems have not correctly understood the nature of the problem environment with which they are dealing. Because they themselves have had no experience at the policy making levels, they have had a poor conception of the problems to be solved, and thus have made mistakes which they would not have made, had they been designing an information system for lower level tasks. In designing an inventory or process control system, for instance, the technicians have carefully studied the nature of the problems to be dealt with, and have decided which information is important and which not. They have not, in these cases, delivered reams of superfluous information to every point in the system. But when designing an information system to aid higher level decision making, they have tended to do the exact opposite. They have attempted to put every conceivable piece of information that could possibly be of the most remote interest at the fingertips of each and every policy maker -- each of whom is already suffering from a severe information overload. The decision maker could never possibly begin to digest all of this information, even if he found it useful, which, in general, he does not. This paper proposes methods for dealing with this crucial inhibiting problem.
1981	On the need for human rationing (abstract only)	The occasion for this discussion is our recent experience with a severe shortfall in computational capacity at The Pennsylvania State University. Although the details of this affliction may not be reproduced elsewhere, it is our opinion that the events we experienced stem from essential, underlying phenomena which do have wide currency. These are, first, that overall demand for computational facilities and services is increasing "exponentially" and shows no sign of slowdown, and, second, that resources (most especially including funds) to provide increases in the relevant supply of computing capacities are not keeping pace and can not be expected to do so.It is possible that technical advances can treat this disorder, but in the nature of the political/bureaucratic systems which are the vehicles for the delivery of such "fixes", acquiring them will not be painless. Concretely, it seems unlikely that faculty and students in colleges and universities can expect relief from recurrent boom-and-bust in computational resources, whether the duration of such cycles is measured in decades or days. It behooves us to ask whether the attendant pains must be endured, and whether they are conducive to easier and more productive use of computing systems. Our answers are, first, that such pain does not ennoble, and, second, that it often is counterproductive. Consequently, we must try to identify the proximate sources of the disrupting effects of these cyclic shortfalls and attempt to curb them, within our means.We propose that the appropriate guidelines for allocating scarce computing resources may be characterized as prescriptions for humane rationing. In the most general terms, these prescriptions are 1) that qualified users should be ensured a fair share of the available resource without unnecessary expenses of effort in competition for them and in queuing, and 2) that use of computing resources should be so governed as to insure that all user sessions are as free as possible of delays, encumbrances, and constraints induced by management practices rather than by inherent limits of hard and software.While rationing is unnecessary during the occasional boom in academic computing resources, we should have on the shelf the management tools which can make fair and effective allocation possible during the recurrent busts we may anticipate in the 1980's.
1981	Relational data base management systems: A tale of two systems (abstract only)	This project management system is designed to provide research administrators and department executives the capability to handle the financial accounting needs for 30 or more separately budgeted projects/departments on a computer with 64K of RAM and two floppy disks. The system generates a wide variety of flexible reports including: a Cost Accounting Summary showing previous period expenses, current period expenses, total expenses, budgeted amount, encumbrances, and remaining balance by line item; a Budgetary Summary which shows for the current period and year-to-date the actual expenses, the budgeted amount, the variance between actual and budget, and the percent of budget by line item expended; an Income Statement showing revenue and expenses; an Expense Report ; and a Transaction Register ; and more.
1981	A micro-based project management system (abstract only)	A comparison is made of systems the author has designed for a main frame and a microcomputer. The limitations and advantages of microcomputers for data base management are discussed. Example applications are presented. Advantages of the set theoretic approach are discussed. Applications most suitable for the relational model are described, and contrasted on both the large and small system.The systems discussed include a commercial system Condor Series 20 DBMS which runs on CP/M, on Z-80 microcomputers and MICRO, a system which runs on MTS on large virtual memory main frame computers. CP/M is the operating system of Digital Research. MTS is the operating system at the University of Michigan.
1981	Combining database management and statistical subroutinesunto a user-oriented data analysis facility (abstract only)	Most database management systems (DBMS) offer convenient and flexible data structures and very good data maintenance facilities. At the same time their data manipulation languages are usually limited and most data analysis applications require extensive programming in a host language. On the other hand, the packages of statistical subroutines (PSS) usually have very good data manipulation and analysis facilities, while at the same time they lack the well known advantages of DBMS. An attempt was made to combine the data definition and maintenance facilities of DBMS and the data manipulation and analysis facilities of PSS into a single user-oriented system. The additional software developed for this purpose performs the following functions:1. Allows the user to define his own analysis and (optionally) store it in a library for further reference.2. Allows the user to define the data on which analysis is to be performed.3. Allows the user to execute the (predefined) analysis in the following way:a. the user's description of analysis is translated into a sequence of data analysis and/or data manipulation subroutines of PSS.b. the required data are retrieved from a database under the control of DBMS and put into a temporary file, whose structure is determined by the analysis input requirements.c. the analysis is performed under the control of the executing program PSS.The outlined system is now being implemented, as an interdepartmental effort, in The Institute for Organization of the Medicine Industry, Warsaw, Poland. It utilizes IMS/VS as a database management system and the OSIRIS III package for statistical data processing. Although the system is still under development it is used not only by research workers but also by administrators and management for relatively simple analysis which are not routinely performed, standard reports. The main advantages of the outlined approach can be summarized as follows:a. reduction of time and cost of preparing the analysis,b. increasing the reliabilityc. presenting the tool for the actual decision makers to perform their own data analysis without the interference with programmers.
1981	Operating systems, editors and application packages: Conceptual and terminological problems facing new users of BMDP and SPSS (abstract only)	The purpose of this presentation is to describe an alternative sociology course that links student computer skills with available social survey data. Students are given access to a file of SPSS programs which they can easily modify to fit their own purposes. Using the General Social Survey they can test hypotheses on current data reflecting their interests. The broad range of data allows beginning students with little or no previous computer experience to investigate a wide variety of topics.
1981	Public use of an economic data base system. (Abstract Only)	The subject of this paper is the design of an economic data base system for public use, taking as a case study the Kentucky Economic Information System. This system offers its users facilities ranging from simple data retrieval and display to the capability to construct, maintain, and use econometric models online. It was designed originally to be user friendly to the trained econometrician, offering a semi-natural, verbal-mathematical free-format command language as the basic communication mechanism. However, with the development of the KEIS into a data base system that is widely used by government officials, academics, and others throughout Kentucky, the need has developed to provide a facility that is user friendly to any possible user. This paper considers the issue of user friendliness as a variable, depending upon the category of user. But it also considers tbe role played by the computer network and its operating conventions as a determinant of the user friendly features that are required. For example, in order to make the KEIS useable by reference librarians in universities, it was necessary to design a special interface; this necessity relates to the operating policies of the Kentucky Educational Computing Network, one of the computer networks the KEIS is resident upon. In addition, this paper considers the issue of user friendliness as it arises due to the specific characteristics of data and the operations performed: an economic data base system is inherently more difficult to operate than, say, a bibliographic data base system. Various other aspects of the KEIS have been considered in articles and papers appearing in such journals as the Journal of the American Society for Information Science and the Review of Public Data Use and in the proceedings of such conferences as the 1981 National Online Conference (March 1981) and the 8th European Urban Data Management Symposium, Oslo, Norway (June, 1981). A paper on the econometric modeling language (MODLER) that is available as part of the KEIS will be given at the 1981 Economic Control and Dynamics Conference, Copenhagen, Denmark (June 1981). This paper complements these other articles and papers.
1982	Learning and remembering interactive commands	There is a rich and expanding folklore concerning the consequences of inappropriate naming of computer commands. The problems are particularly acute for occasional users of interactive systems who may be unfamiliar with the jargon of computing. While “naming” has long been of interest to philosophers, linguists and psychologists [2], there is little systematic research on the psychological processes involved in the understanding and acquisition of the vocabularies of interactive computer systems. Since the names for interactive commands tend to be drawn from the wider vocabulary of natural language, occasional users are faced with the task of understanding, learning and remembering new meanings for the words.
1982	Learning and remembering command names	Natural language would seem to have a strong effect on users' behavior with artificial command languages for interacting with computer systems. We can divide the potential effects of natural language on command languages into: (a) effects on the names of commands, (b) effects on command arguments, and (c) effects on how command-argument units are interrelated (see Black and Sebrechts [2]). Others have investigated arguments (Barnard et al. [1]) and command-argument interrelations (Carroll [4]). In this paper, we describe our research concerning the first of these—namely, how the names of commands effect the learnability and memorability of the commands. Our investigation uses text-editing as the specific domain. Applied research in human-computer interaction is a subtle affair, with many pitfalls awaiting the unwary researcher. Thus, in addition to presenting research results, we will conclude this paper with some methodological lessons.
1982	Evaluating the suggestiveness of command names	An important feature of the design of human-computer interfaces is that of command languages: the vocabulary and syntax that allow a user to express commands to the system. If we look at command languages from the standpoint of natural languages, rather than formal ones, then there are three aspects to their user interface. The first is the overall structure of the user-system dialogue—its pragmatics, so to speak (e.g., [3]), which includes issues of contextual reference, presuppositions, and so on. The second aspect of command languages is their syntax (e.g., [1], [4]). The important issue here is the trade-off between consistency of the syntax and its similarity to that of natural language. The third aspect of command languages is their semantics, primarily that of their commands. Most command languages are fairly small, with simple data and control structures, and so their semantics are fairly trivial. More important is the “lexical” semantics of commands and their arguments and parameters. The crucial factor here is the names given to the entities and operations in the system by the command language: if those names are not apt, performance will be impaired just as with poorly designed syntax or dialogue structure. This paper investigates the psycholinguistic aspects of this naming problem.
1982	Computer commands labelled by users versus imposed commands and the effect of structuring rules on recall	In the office of the future, computers will be found in the work environment to accomplish many various tasks. Often times, one will find computer command languages built from words of natural language, thereby facilitating the use of these new office automation systems for users inexperienced with computers. The study presented here focuses on very simple languages, without embedded features and where each computer command label corresponds to only one function. Three different approaches have been taken in order to improve the design of such simple languages: evaluation of existing languages (Scapin [1]); study of experimental languages that differ on linguistic or semantic variables (Hammond et al. [2]; Carroll [3]; Scapin [4]); research on the design of languages by the users themselves (Carroll [3]; Bisseret et Scapin [5]).
1982	Psychological issues in the use of icons in command menus	Graphic symbols are being used more and more frequently in computer applications, as high resolution displays with advanced graphic capabilities become more common (for example, see [14]). The motivations for using graphic symbols—or icons , as they have been called—in command menus are similar to the reasons graphic symbols have long been popular for use on maps. Their commercial and technical advantages aside, to a large extent the effects of icons on users' performance with a system are unknown. The study summarized here is an initial attempt to understand how commands are represented graphically, to identify the characteristics of icons that make them easy or difficult to comprehend, and to identify the characteristics that lead to retention of the icon-command correspondences. More generally, it is an initial attempt to identify how the user's ability to learn and understand a system is affected by the way in which the commands are represented.
1982	Typographic design for interfaces of information systems	Principles of information-oriented graphic design have been utilized in redesigning the interface for a large information management system. These principles are explained and examples of typical screen formats are shown to indicate the nature of improvements.
1982	A systems analysis of stress-strain in VDT operation	The last half decade has witnessed a rapidly accelerating trend toward the application of video display terminal (VDT) technology for information management in the office workplace, and a growing body of scientific and anecdotal data on the implications of VDT use for the well-being of office workers [2,4,6-8,11,15,16]. A striking aspect of the research on this subject is the degree of conflict among reports regarding the type, magnitude, and causes of adverse changes in the health, comfort, and satisfaction of the VDT user, as is apparent in a recent review by Dainoff [5]. Methodological limitations of much of the work to date probably account for some of these inconsistencies. Many of the studies are demonstrations, or pre-experimental or field investigations with control or statistical measures which allow at best, only general and limited inferences regarding the effects of VDT work [4,8,11,16]. A more serious limitation involves the conceptualization or operational definition of VDT use which in turn determines the elements or factors which eventually figure into a VDT stress model or study design. As an operation or job demand, VDT use is clearly not a unidimensional phenomenon. Based upon findings in an investigation of health complaints and job stress surrounding VDT use in newspaper and insurance facilities, Smith, et al. [16] demonstrated that VDTs may present a wide range of organizational as well as physical or environmental job challenges. To date, numerous investigations have focused mainly on the physical ergonomic demands associated with VDT use [7]. A few have placed strong emphasis on job content, psychosocial, and related operational-organizational factors [8,11,16]. None have systematically examined the unique and integrated effects of these two sets of potential stressors. Smith, et al. [16] maintained that in studying the problems of VDT operators, the contributions of both work and workplace design factors and their interactions must be considered. This is the aim of the present study.
1982	The design, simulation, and evaluation of a menu driven user interface	As the number of system users increases, the degree of formal training of the typical user declines. Techniques such as menu selection, which can best accommodate the novice user, almost necessarily must be included in a strategy for person-computer communication. Yet care must be taken that the experienced or sophisticated user is not encumbered with an interface that involves frustratingly slow entry of commands or procedures. This paper details the process and techniques required to develop and test an interface that would satisfy the needs of a broad spectrum of users. Two design and evaluation iterations are described.
1982	Windowing vs scrolling on a visual display terminal	To study a different star the astronomer moves his telescope. To study a different bacterium the biologist moves his microscope slide. In the case of the astronomer, it is the viewing instrument that is being moved, while in the case of the biologist it is the viewed object that is being moved. These scientists have no choice, the nature of their equipment requires that they operate in a pre-defined way. The user of a video display terminal (VDT), however, can be given a choice. The VDT user views a representation of an area of computer memory. In most cases the portion of memory the user wishes to examine is much larger than that which will fit on the screen at one time. For this reason almost all VDT's are equipped with some sort of “scroll function” that allows the user to display data that is located beyond the limits of the screen.
1982	Notetaking and comprehension for computer-displayed messages: Personalized versus fixed formats	An experiment was performed to evaluate the usefulness of an option for users of an automated information system to construct their own preferred formats for receiving intelligence messages. It was hypothesized that such an option would enhance the acquisition and comprehension of intelligence data from each message. The results indicated that users who personalized the format arranged the message elements in an interpretable manner, and they took fewer notes during the subsequent paced presentation of messages in their individualized formats than users who received the messages in a reasonable, pre-experimentally fixed format. In addition, the users with personalized formats learned more with the fixed format. These data suggest that the personalization of the message format was useful and led to improved subjective organization of the intelligence data.
1982	Tapping into tacit programming knowledge	The Cognition and Programming Group at Yale University is engaged in two complementary efforts: 1. exploring the programming process empirically, paying special attention to the knowledge and strategies which expert and non-experts employ, and 2. building computer-based environments which aid novices learning to program. In this extended abstract we will focus on the empirical strand of our research program; in particular, we will describe an experimental technique we have just begun to use to more carefully study what it is that expert and novice programmers do—and don't—know. In [19, 20, 22, 18, 7] we describe additional empirical studies, while [21] describes MENO-II, our intelligent programming tutor for Pascal.
1982	Human-computer interface considerations in the design of personal computer software	This paper examines some aspects of the design considerations of the human-computer interface as related to personal computers. It is shown that the success of a popular personal computer software product, visiCalc, may be attributed to a thoughtful reconciliation of these design factors with the hardware constraints. The trends of advancement in personal computer software for management-science- engineering problem-solving and decision-making are exemplified by discussing the microcomputer implementation of the Question Answering System on mathematical models and related data bases.
1982	Heuristics for designing enjoyable user interfaces: Lessons from computer games	In this paper, I will discuss two questions: (1) Why are computer games so captivating? and (2) How can the features that make computer games captivating be used to make other user interfaces interesting and enjoyable to use? After briefly summarizing several studies of what makes computer games fun, I will discuss some guidelines for designing enjoyable user interfaces. Even though I will focus primarily on what makes systems enjoyable, I will suggest how some of the same features that make systems enjoyable can also make them easier to learn and to use.
1982	Political determinants of system design and content	Computerized information systems seemingly offer technical solutions to corporate organization and adjustment problems. This idea of the system as the solution has certainly become the focus of information industry rhetoric and sales propaganda. Industry advertising promotes ideas such as (1) the advantages of instant communication in the relative success of any business, or (2) the threat posed by the volume of information produced by a company and unorganized by a particular micro-system. The questions missing from the rhetoric and propaganda are what problems require solutions and what do those problems have to do with the capabilities of computerized information systems. The information industry has transformed these questions in a rather interesting way: they have been handed over to their sales and marketing divisions.
1982	How acceptable are computers to professional persons?	Although our lives are all touched by computers these days, a great many people seem to be ambivalent about them, either fearing them or exhibiting reluctance about interacting with them. The most relevant study about attitudes towards computers was conducted by Lee [1] in 1963. He found two major orthogonal factors: the computer viewed as a beneficial tool of man, and as a superhuman thinking machine that downgrades man's previously unique significance in the order of things. Not only have computers changed quite dramatically since 1963, they have also become increasingly common. It would seem likely then that attitudes towards computers have also changed and hence need to be re-evaluated in the present decade. In this study, the attitudes of certified public accountants (CPAs), lawyers, pharmacists, and physicians were investigated. Professionals were studied because many marketing and electronics analysts have commented that industry is currently designing computers for professional persons [2]. Computer availability, however, does not necessarily lead to computer acceptability. Therefore, the primary question this study sought to answer was - how acceptable are computers to professional persons?
1982	Human relations, scientific management, and human factors research	Human Factors research is concerned primarily with minimizing unpredictable behavior in computer-based systems. Much Human Factors research stresses simplification of computer-based work into discrete, standard, and measurable sub-tasks. The performance of these elemental work-fragments can then be compared against “expert” performance times. In addition to increased worker output, simplified and standardized jobs allow managers to control work more completely. Similarly, standardized jobs usually allow the use of less-skilled labor. This aspect of Human Factors research is an outgrowth of Scientific Management (“time and motion” studies) and, ironically, the management theories of Charles Babbage, the 19th-century inventor of the computer. Scientific Management and Human Factors research share a number of important assumptions. For the most part, these assumptions have not been subjected to careful scrutiny. In time, they may prove the source of significant problems for both systems designers and users.
1982	Software guideline development: Proposed methodology	Too often Human Factors guidelines or checklists are of limited value. The reasons for following them and the degree to which they should be followed are not always apparent. These problems in conjunction with the fact that they are usually full of words or concepts that are not adequately defined, result in guidelines which are misused and/or grossly under-consulted. A methodology will be advocated that will help alleviate these problems. This methodology, when followed, will produce guidelines which can be shown to be effective and are unambiguous in their use and interpretation. Guidelines produced by this procedure become useful tools for objectively evaluating software products.
1982	A test-bed for user interface designs	Most presently available interactive computer interfaces treat their users in an unfriendly, uncooperative, and inflexible way, resulting in feelings of frustration and a conseqeuent loss of productivity for the users. These problems have led to attempts (e.g. [6, 8, 12, 13]) to make interfaces appear more friendly and cooperative through the addition of advanced interface features such as spelling correction, on-line help, personalized defaults, etc.. While common-sense suggests such features may be helpful, there is little hard evidence about how helpful they are or whether they are worth the overheads they entail. A primary reason for this lack of information is the practical difficulty of experimentation. Many of these features are time-consuming to implement, are usually implemented without adequate instrumentation, and are implemented in different and difficult to compare ways from system to system (see [10], for example). These problems in evaluation suggest the need for a test-bed interface in which various advanced features could be tried out in a consistent and adequately instrumented way with a variety of application systems. In this paper, we present a detailed rationale and a partially implemented design for a test-bed of this kind.
1982	Controversies in the design of computer-mediated communication systems: A Delphi study	Computer-mediated communication systems represent a fairly new development in interactive computer systems. This paper will summarize the procedures followed in the Delphi survey, and the results and will then turn to a more detailed treatment of the disagreements that were discovered, presenting the arguments which underlie the disagreements. We will conclude with a brief discussion of the extent to which Delphi approaches may be generally useful design tools for summarizing the “state of the art” and pinpointing research priorities for new types of systems. The purpose of the synthesis of design choices presented in this paper is to familiarize the reader with the range of capabilities and characteristics that currently exist, and to summarize the “collective wisdom” of designers so as to establish design guidelines and options for future systems.
1982	DMS: A comprehensive system for managing human-computer dialogue	As the complexity of human-computer interfaces increases, those who use these interfaces as well as those reponsible for their design have recognized an urgent need for substantive research in the human factors of software development [2], [5]. Because of the magnitude of the task of producing software for individual human-computer interfaces, appropriate tools are needed for defining and improving such interfaces, both in research and production environments. This paper describes the research being carried out to construct DMS (Dialogue Management System), which is a complete system for defining, modifying, executing, and metering human-computer dialogues.
1982	Comparison of two information retrieval methods on videotex: Tree-structure versus alphabetical directory	Videotex systems are two-way communnication systems intended to give users access to large amounts of stored information from their homes and offices. These systems link computer databases to modified television sets over the telephone network. A central computer is used as a large information storage device, monitoring requests for information from several users at one time, finding and sending the information to the person who requested it. It is possible however, that the addition of an inexpensive supplement to the hierarchical tree search will improve user search performance without substantially altering the cost-benefits of the menu selection approach. One such method of retrieval is the on-line alphabetical directory approach where users look for a search term from a list of alphabetically organized items by menu selection. An example will indicate the difference between this method and a typical hierarchical search:
1982	Toward the design and development of style-independent interactive systems	The research project in which we are involved seeks to improve the technical climate for experimentation with the human factors of interactive systems by developing tool Kits to aid the experimenter [3,5]. These capabilities are in two general areas: languages and metrics to support the specification of user interfaces [1] and the evaluation of them with respect to ergonomic factors; and tools to facilitate the development of user interfaces at moderate cost and with short lead time. The latter area, which we have called “style-independent interactive systems”, or “abstract interaction handlers”, is taken up in this report.
1982	Indentation, documentation and programmer comprehension	Recent investigations into the psychological factors underlying computer programming have focused on the effects of internal documentation and statement indentation on programmer performance [1, 5, 7]. Using memory recall approaches several studies have concentrated on the relationship between logic segments of a program's algorithm and the memory organization of the programmer. Since memory organization appears to be a functional psychological process, it seems reasonable to assume that indentation and documentation function as aids to comprehension rather than as organizers for memory [4]. The purpose of this study was to examine experimentally the relationship between documentation, indentation and the comprehension of computer programs.
1982	An empirical evaluation of software documentation formats	The success of any software development project depends in part on the quality of the communication among the individuals involved: users, designers, coders and managers. On large systems, a variety of individuals perform various tasks at different points in time. The efficiency and correctness with which later tasks are performed depends critically on the documentation supplied during previous phases of the development cycle. This paper describes a series of three experiments designed to examine the effects of documentation format on the performance of programmers on different software-related tasks.
1982	A theoretical analysis of the role of documentation in the comprehension of computer programs	The Problem of Optimizing Computer Program Documentation Thls assessment is entlrely by trial and error, usually of the most informal and anecdotal kind. Given the propensity of computer sclence to invent and propose new kinds of documentation, a useful task for engineerlng psychology is the development of a set of design guides for the selection of these devices. Not only would such information be useful for assessing new devices, but it could also be used to suggest where existing devices could be improved. Hence, development of such design guides is a task of immediate and practical relevance to improving software development and maintenance.
1982	The impact of development aids on the systems development process	Increasing the productivity of programmers has become a “hot” topic with both data processing managers and information systems researchers. Currently, there are not enough systems analysts and programmers available to develop all the applications that users need. Consequently, there is a need to produce more output from the available programmers and analysts. This has led to the development of tools and methods that aid analysts and programmers in system development. For example, automatic code generators simplify programming and debugging for many applications. Structured analysis and design methods aid developers in determining user needs and developing system specifications. There has been a great deal of literature written addressing the question: What affects do systems development aids have on the productivity of systems development personnel? This paper will summarize this body of literature from a research perspective. It will concentrate on aids used in business application development, focusing on the early stages of the software lifecycle: systems analysis, design, and coding.
1982	Evaluation of text editors	This paper presents a methodology for evaluating computer text editors from the viewpoint of their users—from novices learning the editor to dedicated experts who have mastered the editor. The dimensions which this methodology addresses are: — Time to perform edit tasks by experts. — Errors made by experts. — Learning of basic edit tasks by novices. — Functionality over all possible edit tasks. The methodology is objective and thorough, yet easy to use. The criterion of objectivity implies that the evaluation scheme not be biased in favor of any particular editor's conceptual model—its way of representing text and operations on the text. In addition, data is gathered by observing people who are equally familiar with each system. Thoroughness implies that several different aspects of editor usage be considered. Ease-of-use means that methodology is usable by editor designers, managers of word processing centers, or other non-psychologists who need this kind of information, but have limited time and equipment resources. In this paper, we explain the methodology first, then give some interesting empirical results from applying it to several editors.
1982	An ease of use evaluation of an integrated document processing system	Designers of systems intended to be easy to use have many guidelines available to them in the literature. Most of these recommendations are based on the intuition and experiences of particular designers with particular systems. Very few of them have been evaluated experimentally, so one must be cautious not to attribute more authority to these guidelines than they deserve [6]. This paper summarizes the results of an experimental evaluation of the Etude text processing system [8]. Section 2 provides a brief overview of Etude. Section 3 describes the development of suitable ease of use criteria. Section 4 presents the experimental protocol. Section 5 discusses the results of the evaluation. A complete description of the experiment can be found in [7].
1982	An analysis of line numbering strategies in text editors	Many techniques are employed in numbering lines for text editing. The simplest approach uses a single integer that changes each time a line is added or deleted (1). BASIC, in addition to other systems, uses fixed multi-digit numbers bound to each line. This approach has problems: only a fixed number of lines can be inserted between two consecutive lines of text, otherwise the original text must be renumbered. This negates one advantage of line numbers: the ability to compare different versions of the same document. In order to overcome these disadvantages, two basic schemes have been proposed and implemented. The following grammar defines the two schemes: fractional line numbering (FLN) and hierarchical line numbering (HLN).
1982	Can we expect to improve text editing performance?	For some time now we have also been interested in studying human factors aspects of computer text editors. We have surveyed the literature [9], and we have conducted several investigations of our own [10] ranging from an application of file-comparison algorithms in editor research [1], through prediction of editing performance [7], to the design and implementation of SIMPLE, our own editing system for beginners [8, 11]. Currently we are concentrating our efforts on gathering data to determine how much time users spend performing various editing activities. We intend to extend the work begun in previous studies, to investigate suboptimal editor performance including errors and nonoptimal means of achieving goals, and to study the broder aspects of editing such as file manipulation and job control that have largely been ignored.
1982	An automated office communications study in an operational setting	In recent years there has been a proliferation of electronic office products developed under the umbrella label of “office of the future”. The justification for office automation has been the promise of increased office productivity and significant cost-benefits to the user. In most cases these systems have been driven by the rapid evolution of technological advances in the computer industry. As a result, these technologically leading edge solutions often must then search for a set of office problems to solve. The present study evolved out of the identification of one such set of office problems. Office communications have increasingly been identified as a major source of inefficiency and frustration. The purpose of the present study was to investigate ways of solving the variety of problems associated with the use of the telephone. The telephone has been labelled as probably the most intrusive device on work flow in the office (Bair, Farber, & Uhlig, 1980). Typically office principals, particularly those without a personal secretary, don't have any means of screening themselves from telephone interruptions. Unsuccessful attempts to call someone are another source of inefficiency.
1982	Communication and management support in system development environments	A System Development Support Environment that assists in communication and management tasks of software project members should aid the development of large, evolutionary computer systems. The environment proposed in this paper will include integrated capabilities for project management, system evaluation, documentation/help, and intelligent communication between designers/users, and either the system or other designers. The goal is to have the environment help collect, organize and disseminate information about a project, using a model of the underlying system. The work is based on the idea that people perform “Communication Acts” (ACTs) such as: questioning, griping, planning, requesting or informing, while interacting with a system, and that processing of these ACTs can be automated. A Taxonomy of “simple” ACTs has been created from initial, informal studies of system/user interaction. A knowledge-based synthesis approach is used to create an experimental environment to support a program synthesis (software) project [Phillips-81]. The environment design and framework, which is part of the author's Ph.D. thesis work in progress [Kedzierski-80], is discussed.
1982	LAMP: Language for active message protocols	Among the most prominent aspects of office automation is the concept of electronic mail. Despite the fact that numerous “Office of the Future&" descriptions seem to focus upon electronic mail as a great opportunity, seldom is it treated as a phenomenon in its own right rather than product. More often it seems to be a technological byproduct, available to counter certain specific business ailments, most notably the inefficiency of transportation of packaged messages. Despite the obvious advantages of E-mail, it is not seen as either essential to office of the future as a concept or as theoretically interesting to researchers. Several commentators, however, have pointed out that messaging may be an alternative form of interpersonal communication (See Bair [l]), without especially treating messaging as a core concept in office automation. This paper proposes to open the debate, not into the technical or behavioral feasibility of E-mail or the other messaging manifestations, nor into the economic benefits of implementation, but rather into the foundations of pre-programmed, non-real-time verbal interaction (printed and oral) as a general phenomenon.
1982	Communication - Nets for the specification of operator dialogs	The model of a man - machine - system is the basis of the proposed notation. It consists of the components man and machine. With these (statical) components a (dynamic) process, called man - machine - communication or man - machine - dialog, is realized. The (three) possible dynamic interfaces are described. According to /CAR;69/ an evaluation, decision and control module for the exchange of information belongs to an active bidirectional communication. An operator dialog is such a communication.
1982	Performance-based evaluation of graphic displays for nuclear power plant control rooms	This paper reports several methodologies for evaluating the perceptual and perceptual/decision making aspects of displays used in the control rooms of nuclear power plants. This NRC funded study focuses upon the Safety Parameter Display System (SPDS) and relates the utility of the display to objective performance and preference measures obtained in experimental conditions. The first condition is a traditional laboratory setting where classical experimental methodologies can be employed. The second condition is an interactive control room simulation where the operator's performance is assessed while he/she operates the simulator. The third condition is a rating scale designed to assess operator preferences and opinions regarding a variety of display formats. The goal of this study is the development of a cost-efficient display evaluation methodology which correlates highly with the operators ability to control a plant.
1982	User perceptual mechanisms in the search of computer command menus	Menu-based command systems, in which a user selects a command from a set of choices displayed to him, have acquired widespread use as a human-computer interface technique. The technique is especially attractive for use with new or untrained users since the user need not recall the command he wishes, but merely recognize it. But menu systems also find application in more sophisticated systems meant for expert users (for example, Teitelman, 1977) where they can be used to reduce the complexity of the options with which the user is presented.
1982	The role of integral displays in decision making	A common approach to designing human-computer decision systems is to divide decision tasks between the person and the computer. The success of this approach depends on knowledge of the specific task components and their interactions, information important for allocating tasks to man and machine. Such knowledge is often unavailable for complex, realistic decision situations. Also, people are reluctant to relinquish part of their decision-making responsibilities. One way to circumvent these problems is to provide general assistance to the decision maker that is independent of any particular decision situation. We propose to use the computer to reduce the decision maker's cognitive load rather than his task load. Specifically, we hope to show that human decision processes can be aided by displaying decision-relevant information in ways that capitalize on certain characteristics of the human perceputal system.
1982	An experimental evaluation of multivariate graphical point representations	In a generally optimistic assessment of progress in the psychology of human-computer interaction, Moran [30] reported that the field “needs to work more at bringing existing areas of cognitive psychology and traditional human factors to bear on user behavior.” This caveat applies especially to the area of computer graphics because of the dearth of experiments and theory on the effectiveness of various types of graphical displays. Broad applications of psychological theory to graphic design have been presented in [6], [19], [28], [32] and [33]. These articles have drawn heavily on Gestalt theory, memory models, and the theory of cognitive schemas in human judgment. They present little experimental evidence relevant to complex visual displays, however.
1982	A review of human factors research on programming languages and specifications	This paper presents a partial review of the human factors work on computer programming. It begins by giving an overview of the behavioral science approach to studying programming. Because of space limitations this review will concentrate on cognitive models of programmer problem solving and the experimental research on language characteristics and specification formats. Areas not reviewed include debugging, programming teams, individual differnces, and research methods. The conclusions discuss promising directions for future theory and research.
1982	Cognitive correlates of programming tasks in novice programmers	The study presented here had two primary goals. First, to identify a set of subtasks which constitute a typology of the task of computer programming—specifically, the task structure of FORTRAN programming as perceived by novice programmers; second, to assess the relationship between individual differences in cognitive functioning (human information-processing characteristics) and performance on the perceived programming subtasks. The criterion instrument was a 77-item test of programming skill and knowledge, arranged by sections of homogeneous items. Each section included items representing one of three major subtask categories (composition, comprehension and debugging). Skill and knowledge acquisition was not studied as this would have required a longitudinal study. Likewise, program modification was omitted as Schneiderman and Mayer have defined it as an amalgam of the three primary tasks. Cognitive ability dimensions have been empirically defined in a large number of studies. Ekstrom, French and Harman [3] have reviewed the status of 24 factors which have been replicated in several studies, and are well established. Of interest are those dimensions which appear to have explanatory power for programming tasks. A listing of these factors follows.
1982	Analyzer-generated and human-judged predictors of computer program readability	The readability of a computer program has recently attained a high level of interest deriving in part from its expected close relationship with program maintainability; debugging and modification expenses are understood to account for a large proportion of software costs over the life of the software. A computable measure of readability would therefore be useful to program developers during coding and to those assuming responsibility for maintenance of software developed elsewhere. In a series of Algol 68 programs, analyzer generated (machine-computable) and human-judged program factors were examined. The first two present authors found that program length and reasonable practice concerning identifier length were excellent predictors of judgments of readability. These predictors were chosen from a large set of analyzer-generated predictors including software science measures as defined by Halstead and several others; the analyzer-generated predictors were found to replicably estimate a high proportion (41 percent) of variance in readability in new readability judgments. While an estimate of readability based only on analyzer-generated predictors would be clearly useful, human ratings (such as quality of comments, logicality of control flow, and meaningfulness of identifier names) were examined to determine whether they could add significantly to the quality of estimates of readability. The addition of the rating of well structured control flow to the set of analyzer-generated predictors increased the proportion of replicably estimated variance in new readability judgments from 41 to 72 percent.
1982	The subjective nature of programming complexity	One of the more difficult problems confronting software engineers today is the construction of accurate predictive models of the software development process, [2],[8] and [9]. It has long been recognized that one of the most essential elements of any successful model of this process is a quantification of the complexity of software systems. During the past several years a great deal of work has been performed by researchers such as Halstead [3], McCab [5], and others in an attempt to develop metrics which adequately capture the complexity of software systems. Yet one very important aspect of software development complexity seems to have been overlooked in the rush to develop software complexity metrics, q.e. it's psychological nature. A basic tenet of our research is that the effort to develop a software system is a function of it's 'perceived' complexity; which in turn is dependent upon both the physical nature of the software system being developed and the psychological nature of the individual(s) performing the development. The immediate goal of the research reported on in this paper was to examine this dual dependency. In order to do so we collected data from two sections (same instructor) of a college sophomore - level class on PL/I which consisted of fifty-six students. During this class each student was given six written programming assignments which were relatively simple in scope.
1982	Error-correcting strategies and human interaction with computer systems	Human problem-solving strategies may be classified as error-preventing (no response is chosen until one can be selected with relatively high confidence) or error-correcting (a tentative solution is formulated immediately, subject to revision in the light of subsequent evidence). Recent work in the author's laboratory indicates a strong preference for error-correcting over error-preventing strategies on the part of human problem-solvers. Unfortunately, most contemporary computer languages and programming environments enforce an error-preventing rather than error-correcting strategy. Using Marvin Minsky's concept of a frame , an error-correcting programming strategy may be thought of as obtaining a program frame with all parameters pre-set to their default values, and then revising those values until a script corresponding to a successful solution is arrived at. The present paper defines a frame-based programming environment which can accommodate error-correcting programming strategies, and discusses the application of such environments to different types of programming languages.
1982	Learning performance and attitudes as a function of the reading grade level of a computer-presented tutorial	The purpose of this study was to determine the most appropriate level of language sophistication, or “readability” of the text of a computer-presented tutorial. The tutorial teaches first-time users how to operate a display terminal. The effects of readability on performance and attitudes of adults with different levels of reading ability were examined.
1982	Warming up to computers: A study of cognitive and affective interaction over time	This experiment studies how people learn to use computers. Four computer-naive persons performed six computer tasks at each of 20 task sessions over a one month period. Participants were allowed to choose a menu-driven or command-driven dialogue at any point during the study. Cognitive, affective, and performance variables were closely monitored. Results generally support the appropriateness of a menu-driven dialogue for novice users and the transition to a command-driven dialogue after approximately 16 - 20 hours of task experience. With experience, users were shown to a) choose b) perform better, and c) be more satisfied with a command driven dialogue. Results are explained within the context of a “cognitive schema” theory.
1982	Statistical semantics: How can a computer use what people name things to guess what things people mean when they name things?	The descriptors or categories assigned to entries in an information system form the basis of most retrieval mechanisms (e.g., menu or key word). These descriptors are the primary means of communication between system designers and end users. In this paper we analyze some of the factors which influence this communication link. Our goal is to uncover some psychological principles that will help us to understand naming and describing behavior and thus improve the communication between designers and users. In traditional communication (e.g., conversation) the communicator can accommodate to different listeners, both by shifting perspective and by attending to explicit feedback from the listener. In describing items in a data base, however, system designers are at a disadvantage in that they do not usually get explicit, immediate, and continuous feedback from users. Knowing how people describe common objects and shift their descriptions for audiences of different levels of sophistication may help designers build systems whose information is accessible to the widest possible audience.
1982	Assessing the climate for change: A methodology for managing human factors in a computerized information system implementation	It is now well established that computers and other information technologies are instruments of organizational change. That is, successful implementation of an information system will change the way in which organizational members do their work. There is an extensive literature on social change which characterizes the change process and how to manage it. In particular, there is a subset of this literature which concerns the implementation of computerized information systems
1982	IBM system/38—an IBM usability experience	Although advancing technology is making more and more complex systems available to the small-system user, the interface between the user and such systems cannot become correspondingly more complex. Instead, the interface must become easier to use so that more people can take advantage of the richer function. In the small business environment, in particular, it is crucial that new systems be usable by a customer's current staff and not require the addition of new and sophisticated data processing expertise. Personnel costs already comprise 45-50\% of most data processing budgets (1). Much of the ease-of-use of smaller systems has been due to their limited function. The user has been able to learn to use the system interfaces because each interface involved only a few functions and the interfaces were few in number. Conversely, very large and complex systems have traditionally been programmed and managed by high powered, highly trained staffs with the resources and the sophistication to cope with complex challenges. Here too, however, the high cost and the limited availability of such people increase the need for ease-of-use breakthroughs(5).
1982	Some human factors aspects of computers in air traffic control	This paper reviews some of the human factors issues arising during eight years of systems research into computer-based concepts for air traffic control (ATC), carried out by the Royal Signals and Radar Establishment (RSRE) on behalf of the U.K. Civil Aviation Authority (CAA). The Ergonomics Development Unit (EDU) at Aston has been responsible for the human factors aspects.
1982	Experience with advanced office automation techniques for project management	This paper describes experiences gained during the course of a fairly large, multi-site project in which an integrated, computer-based electronic message and document preparation system was employed as the principal coordinating mechanism for the project. Approximately 60 individuals had direct access to this system and used it as their primary means of communication for the duration of the project.
1982	Electronic mail usage analysis	An electronic mail system (EMS) has been in operation within Digital Equipment Corporation now for several years. The function of the system is to help serve the internal communication needs of this geographically distributed corporation. In particular, the system was intended to increase the effectiveness of managers, although secretaries, engineers, and other employees also use the system. As the mail system grew from a pilot operation to a global communications utility, the system's managers continued to receive a wide range of informal feedback concerning users' perceptions and utilization of the system. In order to assess reliably how users were reacting to this new communication mode, usage aspects of the electronic mail system were investigated by a random survey of the user population and by an analysis of EMS learning behavior. The survey portion of the study will be discussed in this paper.
1982	The impact of electronics on humans and their work environment	The American industry experiences today the “Information Revolution”, a phenomenon which affects greatly the development of modern technology, and which follows a universal movement toward great scientific innovation and a tremendous increase in information processing needs. The backbone of this “Information Revolution” is the computer. As a result we find that the computer, so far restricted in the backstage of a secluded computer room, expands rapidly onto every work-station in the plant and the office environment. This expansion presents a serious concern to many sociologists, psychologists, environmentalists, computer scientists, designers, architects and industrial engineers. Our concern emanates from the possible effects that this new intruder to the work environment will have on its human operators. An inkling of these effects is presented to us today when we visit a data center: wide open areas with huge display tubes planted like in a grove, is the first thing we see; behind them are the people working with them. They are slouching in front of a keyboard which is located on a standard height desk, and they are staring at a display tube through the hazy reflections of the ceiling lights and their own face. They are hiding from each other with the help of three-foot high piles of computer printouts located on their desk, on a chair, on the floor, in the waste paper basket. They are talking to the terminal, sometimes lovingly, sometimes cursingly. They are talking to each other with a confusing jargon. It is here where we can see that the side effects of this computer invasion have already created some problems with the interaction between the human and the computer.
1982	Designing the Human-Computer Interface	There is a growing awareness in the academic and industrial computing communities of the need to introduce human factors considerations into the design of computer systems. At the School of Information and Computer Science of the Georgia Institute of Technology, this need is being met through a well-funded graduate research program in the human factors of computer systems as well as the introduction of courses that emphasize usability in designing the human-computer interface. The course detailed in this paper has the title “Human-Computer Interface.”
1982	Teaching the Design and evaluation of User-Computer Interfaces	In this paper we describe a graduate Computer Science course, “The Design of User-Computer Interfaces”, which the author developed and has taught since 1979. Students taking the course are normally in their second year of graduate study, and have thus been exposed to several different interactive computing environments.
1982	Applying cognitive psychology to computer systems: A graduate seminar in psychology	This paper describes a graduate seminar given by the authors at Stanford University in the Department of Psychology in the Spring of 1980. Although the seminar was also listed as a Computer Science course and was attended by students and faculty from Computer Science and other departments, the course was addressed to Ph.D. students in cognitive psychology. The seminar assumed that the students were familiar with modern cognitive psychology, but did not assume that they necessarily had much experience with interactive computing.
1982	Teaching software psychology experimentation through team projects	This paper describes an undergraduate human factors course which emphasizes psychologically oriented experimentation on the human use of computers. The reductionist principles of the scientific method are emphasized throughout the course: lucid statement of testable hypotheses, alteration of independent variables, measurement of dependent variables, selection and assignment of subjects, control for biasing, and statistical testing. Term-length team projects are highly motivating for students and have led to worthwhile research contributions.
1982	Further developments toward using formal grammar as a design tool	First, we will describe how some kinds of “cognitive” information can be incorporated into a formal grammar. This information will permit us to describe a system, formally, for different classes of users. Most current models are limited to specific classes of users. They do not, for example, permit us to describe a system differently for naive and for expert users. Next, we will describe, explicitly, the prediction process. The last point to be discussed is our general approach to testing the use of formal grammar as a design tool. This idea is being developed and tested using an IBM editor as an example.
1982	Towards specifying and evaluating the human factors of user-computer interfaces	Despite the current interest in user-computer interfaces, the design of a good interface remains to a great extent an art, with much argument over guidelines and principles for interface design. Pertinent information, scattered throughout the literature of psychology, graphic design. linguistics, hardware design, and under the general umbrella of computer science, is only gradually being gathered into survey publications for application by computer scientists [1,4,12,15]. Our purpose is to design a specification language which will serve as a vehicle for the design of and experimentation with user-computer interfaces. The specification language not only defines the external characteristics of the interface, but can also be analyzed to determine whether the interface meets a set of generally-accepted human factors guidelines. We believe the language is general enough to be used with principles of interface design other than those we have proposed.
1982	Using formal specifications in the design of a human-computer interface	This paper surveys specification techniques that can be applied to human-computer interfaces, provides examples of specifications, and presents some conclusions drawn from the author's experience using the techniques for specifying the user interface of the message system.
1982	The acquisition of text editing skills	The study of text editing is a significant undertaking for at least two reasons. Our study sought to examine text editing more extensively in two regards. First, we wanted to discover how the basic task develops into a routine cognitive skill, i.e., how does the novice user differ from the expert and how is that expertise eventually acquired. Second, we wanted to determine possible ways of improving the techniques for training people in the use of text editors, based on knowledge of how text editing skills develop.
1982	User models of text editing command languages	The present study was aimed at developing a method for determining novice and expert user's models of interactive text editing by empirically analyzing patterns of command language usage. These models, in turn, can form the basis for developing an interactive editor which is designed from the user, rather than the system, point of view.
1982	Reducing manual labor: An experimental analysis of learning aids for a text editor	It is by now a truism to say that computational systems should be designed with ease of use in mind. Indeed, Shneiderman [10] collects together nearly a dozen lists of advice produced by authors in the past decade on how to meet this laudable goal. The advice that is given seems often to be quite good, but it is almost always qualitative in nature, rather vague, and sometimes contradictory. Remarkably little work has been done examining the actual usefulness of carrying out some of the advice, the extent of savings that can be realized by so doing, or the theoretical rationale behind it. In this paper we will present the rationale for investigating two variables that may aid the user, in particular the novice user, and we will describe an extensive experiment designed to examine the actual effects of these two variables. The goals of the work are (1) to understand better the acquisition, representation, and utilization of knowledge by novice or occasional users of computer-based information systems, and (2) to put to the test some ideas derived from current views of memory and attention.
1982	Learner characteristics that predict success in using a text-editor tutorial	Today, it is not unusual for secretaries to use computer-based word-processing systems to deal with manuscripts, correspondence, and memos. In the future, such functions as updating personal calendars, filing, and leaving messages undoubtedly will be handled by computers. For all these functions, people without a technical background are required to interact effectively with a computer system. A person's introduction to computers often begins with an attempt to learn how to use a text editor. Thus, knowing how to use a text editor is a requirement for a growing number of jobs. The importance of text editing is underscored by the recent psychological research devoted to understanding this skill [1,2,3,5].
1982	Patterned prose for automatic specification generation	Writing functional system specifications is a significant job in the early stages of most system development programs. Computer aids for automatic generation of draft material could help produce comprehensive specifications more quickly. To create such computer aids, we must find some way to input defined requirements. A functional capabilities checklist has been proposed for that purpose. And we must find a way to output the appropriate words to describe those requirements. A novel technique called “patterned prose” is proposed for this purpose. The use of patterned prose for automatic specification generation must still be evaluated in practical application. If that evaluation proves successful, this technique may offer promise as a means of organizing knowledge derived from past experience so that it can be used effectively in future work.
1982	An exploratory, human engineering study of DARCOM human-computer interfaces in management information systems	The field which studies human-machine interaction is usually called human factors or human engineering. The DARCOM Directorate of Management Information (DMIS) requested the US Army Human Engineering Laboratory (HEL) to investigate human factors aspects of current MIS systems and provide guidelines for use by system designers. The study involved the use of semi-structured interviews and observations at seven DARCOM installations covering a wide variety of MIS applications to obtain a composite picture of DARCOM MIS users, positive human engineering aspects of current systems, and problems in human-computer interaction. MIS users, for this study, were defined broadly as those who design and program systems, those who are involved in the preparation or input of data into a computer, those who receive or obtain information from a computer system, and those who manage computer systems.
1982	The development of dialogue design guidelines for a computer based local information system to be used by the general public	A number of trends over the last twenty years have brought the prospect of instant computer power to the ordinary man and woman to near fruition. The arrival of interactive computing coupled with developments in the communications field have enabled man and computer to converse both at high speed and at long distance. Furthermore the decreasing cost of microprocessor hardware has made the acquisition of a computer or remote computer access, affordable by most establishments and many ordinary people. A need exists therefore, to develop usable software interfaces or man-computer dialogues to support this equipment. This abstract reports on an experiment which was carried out as part of a research project /5/ to investigate the use which was made of a computer access system, developed by the author, to provide local information to the public.
1982	Decision situations, decision processes, and decision functions: Towards a theory-based framework for decision-aid design	Decision augmentation systems differ qualitatively from current man-computer interactive systems because they involve intelligent, complex, and largely symbiotic man-machine relationships. They thus provide the stimulus for the development of a new branch of human factors, one concerned with the human engineering of relationships between humans and intelligent, quasi-autonomous, computer-based systems. The threefold objective of the research described in this paper has therefore been to identify the human factors problems which such a framework should address, to generate the basic information around which it should be built, and to determine the general structure which it should take.
1982	Eyes at the interface	There is little dispute that the main channels of intercommunication of people with the world at large are: sight, sound, and touch; and for people with other people: eye-contact, speech, gesture. Advanced human-computer interfaces increasingly implicate speech i/o, and touch or some form of manual input.
1982	The intelligent voice-interactive interface	“Put That There” is a voice and gesture interactive system implemented at the Architecture Machine Group at MIT. It allows a user to build and modify a graphical database on a large format video display. The goal of the research is a simple, conversational interface to sophisticated computer interaction. Natural language and gestures are used, while speech output allows the system to query the user on ambiguous input. This project starts from the assumption that speech recognition hardware will never be 100\% accurate, and explores other techniques to increase the usefulness (i.e., the “effective accuracy”) of such a system. These include: redundant input channels, syntactic and semantic analysis, and context-sensitive interpretation. In addition, we argue that recognition errors will be more tolerable if they are evident sooner through feedback and easily corrected by voice.
1982	Composing letters with a simulated listening typewriter	Speech recognition is not yet advanced enough to provide people with a reliable listening typewriter with which they could compose documents. The aim of this experiment was to determine if an imperfect listening typewriter would be useful for highly experienced dictators. Participants dictated either in isolated words or in continuous speech, and used a simulated listening typewriter which recognized a limited vocabulary as well as one which recognized an unlimited one. Results suggest that reducing the rate at which people dictate, either through limitations in vocabulary size or through speaking in isolated words, led to reductions in people's performance. For these first-time users, no version of the listening typewriter was better than traditional dictating methods.
1982	Presenting information in sound	In the past few years, the increase in interactive use of computers has led to an emphasis on human factors and the ways in which digital information can best be presented to users. Computer graphics has been at the forefront of this growth involving vision as an active aid in interpreting data. Bar charts, psuedo-color image processing, and 3-dimensional figures are but a few means of providing the viewer with data information. As the use of computers increases, the need for a variety of alternatives of interacting with computers also increases. Computer-generated sound is one capability not being fully utilized in the computer/human interface. Just as an x-y plot reveals relationships in data, sounds might also reveal relationships in data. This report focuses on the potential for using computer generated sounds to present data information. The first section addresses multivariate data problems which might be aided by sound output. The second describes experiments performed to determine whether listeners can discriminate among data sets based on sound. The final section discusses ongoing work and future directions.
1982	Steps toward a cognitive engineering: Design rules based on analyses of human error	This paper uses the analysis of human error to provide a tool for the development of principles of system design, both to minimize the occurrence of error and to minimize its effects. Eventually, it should be possible to establish a systematic set of guidelines, with explicit, quantitative cost-benefit tradeoffs that can lead toward a design discipline—a “Cognitive Engineering.” This short note starts the process.
1982	Analogy considered harmful	The computer is like a typewriter. The computer is like a filing cabinet. The computer is a personal servant ready to obey your every command. It is often claimed (e.g., Carroll and Thomas [3], Rumelhart and Norman [7]) that the best way to introduce a new user to a computer system is to draw an analogy between the computer and some situation familiar to the user. Given the analogy, the new user can draw upon his knowledge about the familiar situation in order to reason about the workings of the mysterious new computer system. For example, if the new user wants to understand about how the computer file system works, he need only think about how an office filing cabinet works and then carry over this same way of thinking to the computer file system.
1982	Learning to use a text processing system: Evidence from “thinking aloud” protocols	There is growing interest in cognitive science in the the mental processes that underly learning and using computer systems (e. g., Bott {1}; Mayer, {2}; Card, Moran & Newell {3}). In this paper we report generalizations about the problems people who are not experienced with computers have learning to use a text-processing system. We are especially interested in unaided self-instruction, because of the practical interest in reducing the role of experienced personel in the training process. We analyze these difficulties in terms of the interaction between the cognitive characteristics of the learner, and the design of self-instruction, and the interface. Finally, we are also interested in implications of these problems for designing better training methods and computer interfaces that are easier to learn.
1982	A production-system model of human-computer interaction	This paper presents what we believe to be a novel application of production systems to the modeling of complex human-computer interaction. Within the limits of this paper we will briefly describe a production system and discuss its use to model human-computer interaction. We will also mention some existing research supporting its plausibility as a modeling technique. We describe a relatively complex task requiring human-computer interaction that provided experimental data to test the applicability of production systems to this problem area. The completion of this task by individuals was modeled using a set of psychologically plausible productions. The results of this process indicated that a production system may be a powerful empirical and theoretical technique for studying the human factors associated with computer systems.
1983	Design principles for human-computer interfaces	If the field of Human Factors in Computer Systems is to be a success it must develop design principles that are useful, principles that apply across a wide range of technologies. In the first part of this paper I discuss some the properties that useful principles should have. While I am at it, I warn of the dangers of the tar pits and the sirens of technology. We cannot avoid these dangers entirely, for were we to do so, we would fail to cope with the real problems and hazards of the field. The second part of the paper is intended to illustrate the first part through the example of tradeoff analysis. Any single design technique is apt to have its virtues along one dimension compensated by deficiencies along another. Tradeoff analysis provides a quantitative method of assessing tradeoff relations for two attributes x i and x j by first determining the User Satisfaction function for each, U(x) , then showing how U ( x i ) trades off against U ( x j ). In general, the User Satisfaction for a system is given by the weighted sum of the User Satisfaction values for the attributes. The analysis is used to examine two different tradeoffs of information versus time and editor workspace versus menu size. Tradeoffs involving command languages versus menu-based systems, choices of names, and handheld computers versus workstations are examined briefly.
1983	Manual dexterity-a user-oriented approach to creating computer documentation.	This paper will not advocate list of firm recommendations about document design because it is recognised that design decisions will vary with many factors. Instead, the present discussion will emphasize that when making these decisions it is necessary for designers to take account of how readers will use the information provided. In order to help them do this, a simple framework is proposed which outlines the rudiments of how people interact with technical documents. The advantages of this framework will be illustrated by using it to motivate design decisions at two decision levels. At a “macro” level the document designer must make broad decisions about the contents and format of the manual. At a “micro” level the designer must select particular combinations of linguistic, graphic and typographic options which will help readers locate, understand and implement the information given in the manual.
1983	Soft machines: A philosophy of user-computer interface design	Machines and computer systems differ in many characteristics that have important consequences for the user. Machines are special-purpose, have forms suggestive of their functions, are operated with controls in obvious one-to-one correspondence with their actions, and the consequences of the actions on visible objects are immediately and readily apparent. By contrast, computer systems are general-purpose, have inscrutable form, are operated symbolically via a keyboard with no obvious correspondence between keys and actions, and typically operate on invisible objects with consequences that are not immediately or readily apparent. The characteristics possessed by machines, but typically absent in computer systems, aid learning, use and transfer among machines. But “hard,” physical machines have limitations: they are inflexible, and their complexity can overwhelm us. We have built in our laboratory “soft machine” interfaces for computer systems to capitalize on the good characteristics of machines and overcome their limitations. A soft machine is implemented using the synergistic combination of real-time computer graphics to display “soft controls,” and a touch screen to make soft controls operable like conventional hard controls.
1983	Building a user-defined interface	A measurably easy-to-use interface has been built using a novel technique. Novices attempted an electronic mail task using a command-line interface containing no help, no menus, no documentation, and no instruction. A hidden operator intercepted commands when necessary, creating the illusion of a true interactive session. The software was repeatedly revised to recognize users' new commands; in essence, the users defined the interface. This procedure was used on 67 subjects. The first version of the software could recognize only 7\% of all the subjects' spontaneously generated commands; the final version could recognize 76\% of those commands. This experience contradicts the idea that people are not good at designing their own command languages. Through careful observation and analysis of user behavior, a mail interface unusable by novices evolved into one that let novices do useful work within minutes.
1983	Executable specifications for a human-computer interface	It is useful to be able to specify a proposed human-computer interface formally before building it, particularly if a mockup suitable for testing can be obtained directly from the specification. A specification technique for user interfaces, based on state transition diagrams, is introduced and then demonstrated for a secure message system application. An interpreter that executes the resulting specification is then described. Some problems that arise in specifying a user interface are addressed by particular features of the technique: To reduce the complexity of the developer's task, a user interface is divided into the semantic, syntactic, and lexical levels, and a separate executable specification is provided for each. A process of stepwise refinement of the syntactic specification, leading from an informal specification to an executable one is also presented. Since the state diagram notation is based on a non-deterministic model, constraints necessary to realize the system with a deterministic interpreter are given.
1983	Formal specifications for modeling and developing human/computer interfaces	High quality human/computer interfaces have become a major topic of research. This paper describes a new method for modeling, designing, and developing dialogues, a method that has a strong formal basis and allows a uniform syntactic and semantic specification. This formal descriptive technique has the added advantage of being executable, that is, it has widely available translators. The technique chosen here allows a very high level specification of human/computer interaction enabling rapid development and easy modification. This paper describes the nature of the formal specifications written in first order logic using Prolog, and the successful specification and development of a carrier air traffic controller (CATC) dialogue. These experiments demonstrate the utility of Prolog as a high level specification language and point the way to a full dialogue development system that can incorporate a multi-layered concept of human/computer interaction.
1983	Design practice and interface usability: Evidence from interviews with designers	Research into human-computer interaction (HCI) is mainly conducted by engineering psychologists, cognitive psychologists and computer scientists. The principal consumers of applied HCI research, on the other hand, are human factors practitioners and system designers and developers. The HCI researcher who believes his or her findings to be of practical relevance has therefore to consider the interface between researcher and practitioner as well as that between system and user: the products of HCI research must not only be relevant but also “user-friendly” to the practitioner. This problem is not merely one of communication between different professional communities, as the optimal route for the translation of research findings into terms that will be of practical use in the design process is itself a matter of considerable uncertainty and debate. Thus there are many instances in the research literature where apparently contradictory recommendations can all too easily be drawn from findings based on sound but, by its very nature, limited experimentation (e.g., compare the findings of Landauer et al., in press, Ledgard et al., 1980, and Scapin, 1981, on naming text-editing operations). One of the prerequisites for tackling both the communication problem and the translation problem is an understanding of relevant aspects of decision-making in design which influence the usability of the end-user interface. This is so for three reasons. First, an appreciation of the nature of design practice will at least help identify those areas where research input might have the greatest impact and allow researchers to direct their efforts towards them. Second, it may identify possible modifications to existing design practice which would allow research input to be used more effectively. Finally, it would be somewhat surprising if current design practice were not to furnish researchers with any insights into the underlying processes of users. The experience and skills of the practitioner should be a valuable source of information for the HCI researcher. For these reasons, we have been documenting some of the relationships between design practice and the usability of systems for use by non-experts. While there is considerable literature on programming behaviour (e.g. Mayer, 1981), reports of design behaviour are rare, other than occasional descriptions by practitioners of the interface design of their own products (e.g., Botterill, 1982; Smith et al., 1982). This paper focusses on the influence of the individual designer's decision-making. Evidence is taken from interviews with experienced system designers concerning design issues influencing the nature of the user interface which had arisen with systems they had recently worked on. For two of the systems usability investigations had been performed (see Lewis & Mack, 1982 and Hammond et al., 1983).
1983	Getting into a system: External-internal task mapping analysis	A task analysis technique, called ETIT analysis, is introduced. It is based on the idea that tasks in the external world must be reformulated into the internal concepts of a computer system before the system can be used. The analysis is in the form of a mapping between sets of external tasks and internal tasks. An example analysis of several text editing systems is presented, and various properties of the systems are derived from the analysis. Further, it is shown how this analysis can be used to assess the potential transfer of knowledge from one system to another, i.e., how much knowing one system helps with learning another. Several issues are briefly discussed.
1983	Designing for usability—key principles and what designers think	Any system designed for people to use should be (a) easy to learn; (b) useful, i.e., contain functions people really need in their work; (c) easy to use; and (d) pleasant to use. In this note we present theoretical considerations and empirical data relevant to attaining these goals. First, we mention four principles for system design which we believe are necessary to attain these goals; Then we present survey results that demonstrate that our principles are not really all that obvious, but just seem obvious once presented. The responses of designers suggest they may sometimes think they are doing what we recommend when in fact they are not. This is consistent with the experience that systems designers do not often recommend or use them themselves. We contrast some of these responses with what we have in mind in order to provide a more useful description of our principles. Lastly, we consider why this might be so. These sections are summaries of those in a longer paper to appear elsewhere (Gould & Lewis, 1983). In that paper we elaborate on our four principles, showing how they form the basis for a general methodology of design, and we describe a successful example of using them in actual system design (IBM's Audio Distribution System).
1983	Evaluation and analysis of users' activity organization	Our analyses of the activities performed by users of computer systems show complex patterns of interleaved activities. Current human - computer interfaces provide little support for the kinds of problems users encounter when attempting to accomplish several different tasks in a single session. In this paper we develop a framework for discussing the characteristics of activities, in terms of activity structures, and provide a number of conceptual guidelines for developing an interface which supports activity coordination. The concept of a workspace is introduced as a unifying construct for reducing the mental workload when switching tasks, and for supporting contextually-driven interpretations of the users' activity structures.
1983	Computer response time and user performance.	Nearly everyone agrees that computer response time is very important to the users of interactive systems. Many papers have been written describing the bad effects of computer response times that are too long or too short, and many sets of “guidelines” for appropriate human-engineered computer response times in human-machine systems have been published, as well. Nearly all these sets of guidelines are direct descendants of the set published by Robert Miller (1968) about 15 years ago. When Miller wrote his guidelines, he was quite open in describing them as based only on his experience, and he called for experimental data that would allow for the formulation of better, empirically-based rules for setting computer response time for optimal human performance. About fifteen years later, these studies are still missing, for the most part. Aside for the problem-solving studies of Grossberg, et al. (1976), Goodman and Spence (1981), Bergrnan, et al. (1981), and others, the literature is sadly lacking in empirical data to support the simplest assertions about how computer response time affects computer users. Though there is only the sparsest data to support them, several assertions about computer response time and user performance have become accepted as common knowledge.
1983	Computer communication system design affects group decision making	The impact of computer-based communication on group performance depends upon the structure enforced by the communication system. While the ability to introduce structures which enhance human communication processes has been applauded, research to evaluate the impact of various design features is lacking. This research has explored the impact of two synchronous systems which vary in the role of immediacy of interaction and feedback on group decision making. One system is message-oriented, requiring a conferee to complete a message before interacting with others. The other displays what each group member is typing in a separate window on the screens of all participants. In this system, comments can be made as ideas are expressed. Groups were asked to solve a problem first individually and then cooperatively using one of the two systems. All groups produced decisions superior to the average initial individual solutions. Window system groups both improved more and produced significantly higher quality decisions. These groups focused on fewer topics at one time while spending less time discussing how to organize both system and task efforts. By influencing the group's ability to organize and focus its attention, the design of the communication system influenced decision quality.
1983	A methodology for objectively evaluating error messages	Message quality is a critical factor in influencing user acceptance of a program product. Good error messages can reduce the time and cost to create and maintain software, as well as help users learn about the product. We have developed a methodology for conducting controlled usability evaluations of error messages. The Message Test Program is easily modified to adapt to different product situations, and messages can be evaluated even before working code exists. The Message Test Program can be used to test error messages for a batch product, as well as messages for an interactive product. It can also be used for stand-alone messages, for products that offer on-line help, or messages that provide additional information in a reference manual. Message testing enables us to objectively evaluate error messages and provide specific feedback about the difficulties users encounter and how error messages can be improved.
1983	Human factors testing in the design of Xerox's 8010 “Star” office workstation	Integral to the design process of the Xerox 8010 “Star” workstation was constant concern for the user interface. The design was driven by principles of human cognition. Prototyping of ideas, paper-and-pencil analyses, and human-factors experiments with potential users all aided in making design decisions. Three of the human-factors experiments are described in this paper: A selection schemes test determined the number of buttons on the mouse pointing device and the meanings of these buttons for doing text selection. An icon test showed us the significant parameters in the shapes of objects on the display screen. A graphics test evaluated the user interface for making line drawings, and resulted in a redesign of that interface.
1983	Playback: A method for evaluating the usability of software and its documentation	A methodology is described for obtaining objective measures of product usability. The Playback program developed at the IBM Human Factors Center in San Jose collects performance data of the user interface without impact upon the user or the system being evaluated. While a user is working with the system, keyboard activity is timed and recorded by a second computer. This log of stored activity is later played back through the host system for analysis. An observer watching television monitors enters time-stamped codes and comments concerning the users employment of system publications. The advantages of this approach are: (1) data-collection programs are external to the product being evaluated, (2) no modifications of the Playback program are required for testing different software applications, (3) the data-collection process does not intrude on the user's thoughts or activities, (4) problem determination is performed at an accelerated rate during playback analysis, and (5) all data collection is performed on line.
1983	Questionnaires as a software evaluation tool	This paper reports on a study investigating the strengths and weaknesses of questionnaires as software evaluation tools. Two major influences on the usefulness of questionnaire-based evaluation responses are examined: the administration of the questionnaire, and the background and experience of the respondent. Two questionnaires were administered to a large number of students in an introductory programming class. The questionnaires were also given to a group of more experienced users (including course proctors). Respondents were asked to evaluate the text editor used in the class along a number of dimensions; evaluation responses were solicited using a number of different question types. Another group of students received the questionnaire individually, with part of it presented on the computer; a third group also evaluated an enhanced version of the editor in followup sessions.
1983	Changes that users demanded in the human interface to the Hermes Message System	The Hermes Message System has evolved in response to the needs and criticisms of users. This paper gives examples of some less than successful features, many of which have been changed, so that future designers will know what didn't work, as well as what does. Principles derived from this experience are: (a) What you see should be what you can type. (b) Commands and syntax should be uniform. (c) Commands and objects should be organized into groups. (d) Hierarchy is great for organizing things you know about but much less useful for finding things you don't know. Even with careful design, it is impossible to predict what users will dislike so it is important to design programs so they can be easily changed.
1983	Computing on a shoestring: Initial data entry for service organizations	This paper addresses the feasibility of computerized record-keeping for low-budget volunteer organizations, and presents results of an experiment designed to determine a fast, reliable, and comfortable data entry technique for enabling non-computer-user to enter large amounts of manually recorded data into a computer file.
1983	The Consul/CUE interface: An integrated interactive environment	Consul and CUE are two systems that combine to support an interface to interactive computer services that is integrated across a variety of interface methods. Consul is an experimental natural language interface system designed to be customized to a set of specific interactive computer services: electronic mail, personal calendar, word processing, etc. CUE is a window- and object-based run-time support environment for interactive services with a command language, pointing device and menu interface. Using the Consul/CUE interface, the user sees a single system that is capable of handling a wide variety of input in a completely uniform service environment. The success of the combined system derives from a large knowledge base formalizing facts in the interactive service environment in an artificial intelligence network structure.
1983	A generalized transition network representation for interactive systems	A general method for describing the behavior of an interactive system is presented which is based on transition networks generalized enough to describe even very complex systems easily, as shown by an example description of a word processor. The key feature is the ability to easily describe hierarchies of modes or states of the system. The representation system is especially valuable as a design tool when used in a simulation of a proposed user interface. In order to characterize the interaction between a user and a system, an explicit and formal representation of the behavior of the system itself is needed. To be of value in the design of user interfaces, the representation should be independent of the actual implementation of the system, but also reflect the structural properties of the system's behavior, such as its hierarchical form, the possible modes, and the consistent patterns of interaction. At the same time, the representation must be easy to define and understand. This paper presents a representation notation with these properties.
1983	Application of a model of human decision making for human/computer communication	When a human and computer perform similar tasks in parallel, it is important that an effective line of communication exist between the two entities. Since overt communication may add to the human's workload, an implicit method of communication is suggested in which the computer has a model of human performance on which to base actions. A two-stage model of human performance is employed in an experimental situation in which both a human and a computer act as decision makers. Results indicate that the implementation of a model significantly improves the human's performance and the overall system performance, without degrading the computer's performance. Research into additional experimental and real-world situations is suggested.
1983	Using examples to describe categories	The successful use of menu-based information retrieval systems depends critically on users understanding the category names and partitions used by system designers. Some of the problems in this endeavor are psychological and have to do with naming large and ill-defined categories so that users can understand their contents, and effectively partitioning large sets of objects. Systems of interest (like home information systems) often consist of new and frequently changing content in large and varied domains, and are particularly prone to these problems. We explored several ways in which one might name categories in one such domain (Yellow Page category headings) - category names, category names plus examples, and examples alone. We found that three examples alone were essentially as good a way to name these categories as either an expertly chosen name or a name plus examples. Examples provide a promising possibility both as a means of flexibly naming menu categories and as a methodological tool to study certain categorization problems.
1983	A featural approach to command names	A variety of aspects of command names have been studied, such as suggestiveness, memorability, and the use of icons. A single framework for these disparate studies is desirable, and it is proposed that the concept of featural analysis prevalent in linguistics and psycholinguistics be adopted as an approach to command name design. Examples of the breadth of application of this approach are given for the naming issues of suggestiveness, learning and memory, congruence and hierarchicalness, universal commands, the relationships of names to the command language syntax, and the use of non-words as names.
1983	Command use and interface design	Designing a human interface to a computer system is more art than science. Systematic research on the human interface to computer systems, when it is performed, is generally an after-the-fact evaluation of an almost finished product. This sort of evaluation is often too specific to a particular product to provide general prescriptions for future interface design and often occurs too late to have a substantial impact on product development. Rarely do research and evaluation provide guidance throughout the development cycle. We propose that an examination of people's natural use of already existing computer systems, using research methods adopted from studies of social behavior (e.g., Kraut & Johnston, 1982; Hooff, 1982) will provide a richer source of information for guiding development. A multivariate examination of naturally occurring human-computer interaction may provide insights into its complex structure in ways that are denied to more experimentally oriented, human-factors research.
1983	Is there really trouble with UNIX?	Donald Norman has claimed that UNIX has cryptic and inconsistent command names. As Michael Lesk has remarked, the lack of objective data makes it difficult to evaluate the significance of Norman's criticisms. In an effort to explore this controversy we taught one group of novice users the UNIX command language and another group an English-based command language (NUIX). The number of errors and calls for on-line assistance were compared. The subjects in this study were 22 high school women with no formal exposure to computers. The results reveal that the UNIX group made fewer errors than the NUIX group in two training sessions a week apart. Although calls for on-line assistance for the two groups in the first session were comparable, the UNIX group made over twice as many calls for on-line assistance in the second session as the NUIX group. Our findings suggest that even though the UNIX command language may not be harder for novice users to learn, it is probably more difficult for them to use.
1983	Enhancing the usability of an Office Information System through direct manipulation	In Office Information Systems, the primary focus has been to integrate facilities for the communication and management of information. However, the human factors aspects of the design of office systems are equally important considerations if such office systems are to gain widespread acceptance and use. The application of design techniques from Human Factors can help enhance the usability of an office system. In this paper, we describe the user interface of an office system developed by adapting such design techniques.
1983	An assessment of computer generated space situation map projections	C 3 environments have increasingly incorporated computer controlled maps as decision aids. The design of map displays in space oriented C 3 systems has taken on greater importance due to the complex spatial relationships among orbiting objects. The large number of objects orbiting the globe and their great speeds further complicates efforts to quickly and accurately portray their positions graphically. This paper describes an experimental plan aimed at evaluating a new 2D/3D “hybrid” space situation map display. The Hybrid display is created by opening a globe at the south pole and flattening it into a platter. A third dimension is obtained by tilting the platter. It was hypothesized that the Hybrid display would offer an advantage to C 3 system operators and analysts dealing with three dimensional problems. The test plan focuses on perceptual parameters and user preference issues concerning conventional and Hybrid display techniques. The results of this study will be examined to direct future work on dynamic displays, and the impact of display design approach on cognitive performance.
1983	An effective graphics user interface for rules and inference mechanisms	As the technology of rule-based inference mechanisms matures, knowledge acquisition—the creation, structuring, and verification of rules—becomes increasingly important. The accuracy and completeness of the rules in the knowledge base determine expert system performance, and the cost of acquiring that knowledge base dominates all other hardware and software costs in practical systems. To reduce knowledge acquisition time and error rate, a new interactive graphics interface for rules is being designed and implemented in GE Corporate Research and Development. In the new system, each set of rules is represented as an AND/OR graph and parts of the rule base are displayed on a CRT screen as an AND/OR tree. A user—even an unsophisticated user—can navigate the AND/OR graph, identify nodes to be modified, analyze the behavior of the graph, verify its correctness graphically, and follow the execution of inference engines.
1983	Effect of font and medium on recognition/confusion	Systematic differences in recognition/confusion due to font variation is estimated by using confusion matrices of the full 26 capital letters of the English alphabet in 5 × 7 dot matrix font and “Keepsake” conventional stroke font. Average correct recognition was controlled to 50\% by limiting brightness and duration of tachistoscopic displays for each font to individually determined levels for each of the four subjects. Each stimulus symbol was presented 45 times to each subject, resulting in 180 trials per letter per font. By comparing the obtained data to that reported by Townsend (1971), Craig (1979) and Gilmore et al.(1979), estimates of the differences in recognition/confusion attributable to medium, font and subject differences were isolated. This comparison reveals a substantial difference in recognition/confusion processes when the observer sees the display on a video screen versus seeing it projected on a white screen.
1983	The effects of positional constancy on searching menus for information	One of the more popular methods today for instructing software designers on how to structure man-display interfaces is with guidelines. Numerous design guidelines have been promulgated in the last several years (Engel and Granda, 1975; Ramsey and Atwood, 1980; Smith, 1980; Kennedy, 1974; Pew and Rollins, 1975) and there is still much current activity in collecting and expanding screen guidelines (Smith, 1981; Smith & Aucella, 1982) In the past few years an increased number of empirical investigations quantifying directly the behavioral impacts of individual design guidelines have appeared in the literature. Issues such as the depth of menu hierarchies (Miller, 1981), eye movements during menu viewing (Card, 1982; Kolers, Duchnicky, and Ferguson, 1981), or location of screen entry areas (Granda, Teitelbaum, and Dunlap, 1982) have been experimentally studied.
1983	Usable natural language interfaces through menu-based natural language understanding	Conventional natural language interfaces suffer from several ease-of-use problems. They require a user to type and to formulate questions in a way that the system can understand. They have high failure rates which often frustrate users, and users often do not use features of the systems because they are unaware of them or don't trust them. In addition, conventional natural language systems are expensive to build and require large amounts of storage to use. This paper describes a new approach to natural language interfaces called menu-based natural language understanding. This new approach solves the problems listed above. The paper compares the menu-based natural language approach to conventional natural language interfaces and to other forms of interface and discusses the advantages and limitations of this new approach.
1983	Query languages for the casual user: Exploring the middle ground between formal and natural languages	In the past the non-programmer who wanted the information contained in a computer database had to employ an expert programmer knowledgeable in the language and structure of the database. Now languages are being developed that are designed to be used by an infrequent or “casual” user who has limited knowledge of how the data is stored or retrieved by the computer. These special purpose query languages which allow these casual users to retrieve information from computer databases are commonly referred to as “nonprocedural” (Leavenworth and Sammet, 1974) because users need only describe the data to be retrieved, not how it is to be retrieved. These languages can be classified into two basic types which are characterized by the level of constraint imposed on the syntax and vocabulary of the language (Ehrenreich, 1981). Formal query languages have a very constrained syntax and vocabulary, while natural query languages have a relatively unconstrained syntax and vocabulary. If we consider the level of constraint that can be imposed on a query language as a continuum, then formal and natural query languages represent the two ends of this continuum. There has been considerable debate over the issue of which end of this continuum best meets the needs of the casual database user (e.g. Hill, 1972; Petrick, 1976; Shneiderman, 1980). Proponents of formal languages contend that these users benefit from learning a constrained language which teaches a concise and unambiguous way of communicating with the computer. Proponents of natural languages, on the other hand, contend that more people would be able to access database information if they could use their own natural languages. Evidence from studies of the use of some of these query languages however, indicate that neither formal, nor natural languages are easy to use. These studies suggest that the casual user will have difficulty operating at either end of the level-of-constraint continuum.
1983	A comparative study of moded and modeless text editing by experienced editor users	As interactive text editing systems become more and more pervasive on the job, at school, and in the home, the necessity for good human engineering in the design of such interactive systems becomes increasingly apparent. The issue we are concerned with in this paper is not that of modes in general, but rather the more specific question of how editors should handle text insertions. In this context, moded editing means that the editor user must enter a special command before text is inserted and another special command to end the text insertion and return to the command mode. Ordinary printing characters typed while in an insertion mode are entered as text. The same characters entered while the editor is in the command mode are treated as commands. Modeless editing is different; ordinary characters are entered directly as text. There are no special commands required to enter or stop entering text.
1983	Patterns of experience in text editing	What are the effects of experience on text editing behavior? Do users inevitably develop optimal strategies for getting their work done? The answer to such questions are becoming increasingly important, as more and more individuals begin to use word processing equipment routinely. In the best of all possible worlds, experienced users do become experts, able to quickly and accurately choose and execute optimal procedures to accomplish any given goal. Such a state of affairs would make designers of editing systems very happy indeed. But another alternative exists, that at least some proportion of experienced and frequent users stabilize at some nonoptimal level of skill. An initial survey of relevant research is encouraging. So, for example, Card, Moran, and Newell (1980) were able to deduce selection rules from experienced users' editing behavior that predicted 80\% of their editing decisions, suggesting that experienced users have fairly well-defined heuristics for carrying out editing tasks. Tyler and Roth (1982) followed up on this work, demonstrating that novices were less likely to demonstrate selection rules than experienced users, preferring instead to rely on a single, sometimes inefficient, strategy. Finally, Folley and Williges (1982) demonstrated that when confronted with the description of a novel editor, users experienced on other systems make use of a greater number of commands in carrying out a paper-and-pencil application of the editor than do complete novices.
1983	How interface design determines Who has difficulty learning to use a text editor	In previous studies two background characteristics of computer novices were consistently correlated with their success in learning to use a line-based computer text editor. Older people and those who scored low on a standard test of Spatial Memory had more difficulty than younger people and those with higher Spatial Memory test scores. In the present study, we observed computer novices as they learned to use a screen-based editor, which presumably reduced spatial memory load. Contrary to expectations, performance using a screen-based editor was again strongly correlated with Spatial Memory test scores. However, the correlation between performance and subjects' age was significantly reduced. Overall, subjects were able to perform the same text editing exercises almost twice as fast using the screen editor compared to subjects in previous experiments using the line editor. These results are discussed in terms of the different cognitive demands placed on users by line and screen text editors.
1983	How you tell your computer what you mean: Ostension in interactive systems	An important part of communication is being able to point to an object without referring to its components or to the area surrounding it. How to do this is the problem of ostension. We observed many ostension errors in novices learning to use a full-screen text editor. Specifically, the novices erroneously tried to use keys that are appropriate for pointing when using a typewriter but incorrect in screen editors (e.g., space bar, backspace key, etc.), they frequently missed the location they intended by one character, they inadvertently pointed to the wrong occurrcnce of a string using a FIND command, they incorrectly specified boundaries by forgetting about “invisible” characters (e.g., formatting characters), and they mistakenly attempted to point to non-typing areas of the screen that were off-limits.
1983	A qualitative reasoning approach to mathematical and heuristic knowledge integration	Human problems solvers use heuristic knowledge. Heuristics can be justified in a given problem solving context by reasoning about 'deeper' domain theories. A working computer program, an air traffic control expert system, uses a qualitative reasoning approach to justify heuristically generated plans. The justification is based on mathematical knowledge of aircraft performance which is computationally too complex for use in the normal planning process.
1983	The effects of limited grammar on interactive natural language	What is the best way for novice users to interact with computers? Three alternatives that are generally offered are: menu selection, query languages, and natural language. In menu selection, the user chooses from a set of preprogrammed options by entering an associated key. This technique has the advantage of placing a minimal parsing burden on the computer. However, for certain applications, such as conversational interaction, menu systems are inadequate because they severely limit the strategies available to the user. Query languages are special sets of designed specifically for interaction with the computer. They place a greater parsing burden on the computer, and are somewhat less limiting to the user. However, they suffer from human factors problems in that they are often very difficult for the user to learn (Reisner, 1981).
1983	An empirical methodology for writing user-friendly natural language computer applications	A six-step, iterative, empirical, human factors design methodology was used to develop CAL, a natural language computer application to help computer-naive business professionals manage their personal calendars. Language is processed by a simple, non-parsing algorithm having limited storage requirements and a quick response time. CAL allows unconstrained English inputs from users with no training (except for a 5 minute introduction to the keyboard and display) and no manual (except for a two-page overview of the system). In a controlled test of performance, CAL correctly responded to between 86\% and 97\% of the inputs it received, according to various criteria. This research demonstrates that the methodological tools of the engineering psychologist can help build user-friendly software that accommodates the unruly language of computer-naive, first-time users by eliciting the cooperation of such users as partners in an iterative, empirical development process. The principal purpose of the research reported here was to design and test a systematic, empirical methodology for developing natural language computer applications. This paper describes that methodology and its successful use in the development of a natural language computer application: CAL, C alendar A ccess L anguage. The limited context or domain in which the application operates is the management of a personal calendar, or appointment book, data base by computer-naive business professionals.
1983	Correcting misconceptions: What to say when the user is mistaken	Because people's knowledge is often partial and/or faulty, it is inevitable that misconceptions will be revealed in the course of a conversation. If recognized, the other person may say something to correct the misconception, and the conversation continues. Just as this is the case when people interact with each other, so must it be when users interact with a computer system. For example, in interacting with an expert system, a user may reveal misconceptions about objects modelled by the system. By failing to correct such misconceptions, the system may not only confirm the original misconception, but may cause the user to develop further misconceptions. It must therefore be up to the system to recognize and respond to misconceptions in an effective way. In this paper the space of possible object misconceptions is characterized according to the kind of incorrect information involved. It has been found that this characterization is often useful in determining how the user arrived at the misconception, and therefore the kind of information to include in the response. Using such a characterization, a system will be able to effectively correct object misconceptions in a domain independent way. Factors which affect the amount of information included in a correction (such as discourse and situational context) are also examined.
1983	The user's perception of the interaction language: A two-level model	Users perceive consistency and inconsistency in syntax, and family resemblances among syntactic constructions. These factors are not captured in conventional BNF-like grammars. We argue that a generalised form of a two-level grammar is a better model of the user's perceptions, and show how the model relates to current psychological notions of organisation in recall and language learning. The model provides a unified interpretation of many previous results in HCI: we analyse here findings by Reisner (1981) and Barnard et al. (1981). Two preliminary experimental tests supporting the model are described.
1983	Learning text editor semantics by analogy	This paper presents a cognitive model for one aspect of how novices learn text editors—the acquisition of procedural skill by problem solving in problem spaces and the use of analogy for building a representation of the semantics of text-editor commands (which we call operators). Protocol data of computer-naive subjects learning the EMACS text editor suggests that they use their knowledge of typewriting to decide which commands to use in performing editing tasks. We propose a formal method of analysis that compares operators in two problem spaces and generates misconceptions. The comparison of these predicted misconceptions with verbal comments, error data, and task difficulty lends support to this analysis.
1983	Mental models and problem solving in using a calculator	It has often been suggested that users understand and reason about complex systems on the basis of a mental model of the system's internal mechanics. This paper describes an empirical study of how mental model knowledge is used in operating a stack calculator. One group of naive users were taught step-by-step procedures for solving typical problems on the calculator. A second group of naive users were taught the same procedures in conjunction with an explicit model of the calculator's stack mechanism. The users then solved problems on the calculator while thinking aloud. Analysis of the performance of these two groups indicates that the model had little effect in routine problem solving situations, but significantly improved performance for novel problems. Analyses of the think-aloud protocols indicate that the users employed five distinct modes of problem solving: skilled methods, problem reduction strategies, a conversion algorithm, model-based problem space search, and methods-based problem space search. Skilled methods, problem reduction strategies and the conversion algorithm were used for solving more routine problems and did not necessarily depend on mental model knowledge. Problem space search was used in the novel problems. For the model users, the states and operations of the stack mechanism served as the problem space to be searched for a problem solution. In contrast, the no-model users employed a less effective search strategy based on the recombination of pieces of known procedures. These results indicate that explicitly teaching naive users an appropriate mental model of a system can provide a psychologically effective and robust basis for operating the machine.
1983	Planning units in text editing behavior	The organization of text editing behavior can be characterized by graph structures containing goals, subgoals, goal outcomes, and actions. Here we propose a model to represent the goals and plans of text editor users based on goal-fate analysis (Schank & Abelson, 1977). The representation captures relationships between a user's multiple goals and shows how errors can result from badly formed plans. We discuss some data from a psychological experiment which supports the hypothesis that text editing behavior is chunked into distinct plan units. The cognitive components of pause times between keystrokes were revealed by statistically removing the physical time required between keystrokes. Finally, we suggest how a system which builds goal-fate graphs from keystroke input might be useful in providing specific help information that is keyed to a user's intentions.
1983	Remindings and their effects in learning a text editor	How can learning in text-editing be characterized? Much recent work has focused on the use of analogies from prior experience. In this paper, we investigate the retrievals of earlier experiences within the editor and how they might be used by analogy to accomplish the task and learn the editor. An experiment is presented that demonstrates the effects of these “remindings” on performance. In addition, some possible determinants of these remindings are investigated. This experiment points out the need to consider not only the general form of instruction, but also the specifics of the instructional sequence as well. Irrelevant aspects of the task may have strong effects on performance. We consider three teaching techniques, designed to take advantage of these effects in different ways.
1983	Learning in an instructionless environment: Observation and analysis	In an instructionless environment, there are neither teachers nor books. The only feedback comes from interaction with the target. All information appears from within the subject or from observation of the environment. In this setting, subjects rely upon experimentation to develop an understanding of the target. They form hypotheses by analogy or inference and test these hypotheses via experiments of calibration, replication, confirmation, exploration, and discrimination. This paper describes subjects' performance in a particular instructionless environment. The target object is a programmable toy robot tank. We use the hypotheses formed by subjects and form of the experiments performed, to assess subjects' knowledge of the system. This knowledge falls into distinguishable categories: syntactic knowledge of the programming language, semantic knowledge of the actions of the device, and model knowledge which addresses the structure of the device. Exemplary selections of our protocols are used to support the various aspects of the learning model.
1983	Human-computer discourse in the design of a PASCAL tutor	An effective human-computer discourse system requires more than a clever grammar or a rich knowledge base. It needs knowledge about the user and his understanding of the domain in order to produce a relevant and coherent discourse. We describe MENO, a prototype tutor for elementary PASCAL, which uses a set of speech patterns modelled after complex human discourse and a richly annotated knowledge base to produce a flexible interactive system for the user.
1983	What do novice programmers know about recursion	Recent research into differences between novice and expert computer programmers has provided evidence that experts know more than novices, and what they know is better organized. The conclusion is only as interesting as it is intuitive. This paper reports an experiment which was designed to determine precisely what novice programmers understand about the behaviour of recursive procedures, and exactly how their understanding differs from an expert's understanding of the process. The results show that different novices understand, or misunderstand, different things. Implications of the findings are discussed with respect to other research into novice and expert programming performance.
1983	Beyond numbers: Don't ask “how many” ... ask “why”	While programmers may differ in their assessment of the comprehensibility of a program, there are nonetheless some clear cut cases of programs that are truly difficult to understand. In this paper, we analyze three programs—two of which are relatively incomprehensible—using Halstead's Volume Metric, Propositional Analysis and Plan Analysis. We argue that only Plan Analysis provides a satisfactory explanation for why the programs in question differ with respect to understandability. Moreover, we suggest that a qualitative analysis, such as provided by Plan Analysis, is the desired type of evaluation: rather than simply providing a numerical ranking for programs, the qualitative analysis can pinpoint the troublesome area in the code and provide prescriptive information for correcting the difficulty.
1983	Aesthetics and programming	The paper at hand is based on interviews with a total of eight so-called "superprogrammers", software people, who show exceptional performance quantitatively as well as qualitatively. It becomes apparent that these people do not experience programming as a purely rational activity, but that for them it possesses strong intuitive components. Programs are visualized wholistically as three-dimensional structures. In this, aesthetics plays a special part: the structure must please optically, be elegant—then it is functionally acceptable. Logical mistakes manifest themselves as interfering with this aesthetics. The author suggests that in the area of software as well there is something like the absolute beautiful: perfect solutions with a maximum of transparence beyond all rivaling design parameters. He has a feeling that the faculties described in this paper are widespread and may open up a totally new dimension in programming.
1983	On enhancing the interface to the source code of computer programs	This paper addresses issues in the human factors of computer program documentation. We develop a framework for research on enhancing the interface to the source code of computer programs through designing and automating the production of effective typeset representations of the source text. Principles underlying the design research and examples of sample production are presented. This work was supported by the U.S. Defense Advanced Research Projects Agency under DARPA Order 4469. We are grateful for valued assistance to the other members of the research team, Michael Arent, Design Director, Aaron Marcus and Associates, and Paul Breslin, John Jackson, Allen McIntosh, and Christopher Sturgess, Human Computing Resources Corporation, and to Trigraph Typesetters, Toronto.
1983	Documentation of concurrent programs	A complete software package always includes documentation. Although its importance is often overlooked, documentation may be the only source of program design information. Major tasks in the software life cycle, such as design, coding, testing and maintenance, are often performed by different individuals. Lientz and Swanson (1979) found that, typically, only about half of a software system's maintenance personnel had been involved in its development. Poor documentation techniques can, therefore, dramatically increase labor costs throughout the labor intensive software life cycle by making both development and maintenance tasks more difficult. Recent research in this area (Boehm-Davis, Sheppard, & Bailey, 1982; Sheppard, Kruesi, & Bailey, in press; Sheppard, Kruesi, & Curtis, 1981) has been directed toward determining performance on a set of software tasks as a function of the type of documentation. In these studies, programmer performance was examined on comprehension, coding, debugging, and modification tasks as a function of the type of documentation provided. The documentation formats were constructed from the factorial combination of three types of symbology with three types of spatial arrangement. These formats were chosen because they represent the primary dimensions for categorizing the way in which available documentation aids configure the information they present to programmers (Jones, 1979). The three types of symbology in which information was presented consisted of normal English, abbreviated English (such as program design language), and ideograms. The spatial arrangements of the information used in these experiments were sequential, branching, and hierarchical. While each of the four tasks pursued in this research produced slightly different results, there was a general trend towards the superiority of succinct symbology and a branching spatial arrangement in each.
1983	Use of mouse buttons	Two experimental tasks were designed to test use of multiple-button mice. In the first, number of errors made and time to complete subtasks were measured as subjects attempted to depress one, two, or three buttons under three sets of conditions. In the second, subjects were asked to indicate true or false either by pressing one of two different buttons or by clicking a single button one or two times. People tended to be faster and more accurate using different buttons than different numbers of clicks.
1983	Speech recognition at two field sites	The performance of two speech recognition systems installed at two field sites was analyzed. The speech systems were part of larger computer systems that were performing real functions in industrial environments. The two sites appeared to be polarized in terms of expected suitability for speech recognition. The variables looked at included task complexity, memory load, requirements for verification and error correction, vocabulary and syntax, microphone, operator experience and complexity of host computer software. Accuracy and throughput were measured for the speech recognition system at each site. The same measurements were made for keyboard entry. Operator differences account for most of the variance in results. Accuracy with voice input was higher than with keyboard for most operators. The most accurate operators with keyboard also tended to be the most accurate with voice. Throughput data appears more sensitive to individual differences in dealing with voice input, although the throughput data was clouded by slow host system response times overall. The discussion suggests that one to one replacement of keyboard with voice overlooks some possible advantages of voice. It is also possible to find operators who work well with voice. For those who do not work well with voice, the problems appear to be related to general work habits and attitude, rather than to specific difficulties with speech.
1983	Lighting characteristics of visual display terminals from an ergonomic point of view	Measuring procedures were developed to assess those lighting characteristics of VDTs which are of importance for visual comfort and for legibility: Luminance oscillation, sharpness, contrasts, stability and dimensions of characters as well as reflections on the display surfaces. 30 different VDT models of various European and US manufacturers disclosed great differences, indicating a big potential for improving the ergonomic qualities of VDTs.
1983	An experimental evaluation of on-line HELP for non-programmers	An interactive computer system was made easier to learn for non-programmers by modifying the on-line HELP and error messages of a system designed primarily for programmers. The modifications included supplementing the existing HELP command with a HELP key, making the content of HELP and error messages more concrete, responding to command synonyms, and more. The systems were evaluated in a between-groups experiment in which office workers with no programming experience were asked to perform a typical office task using one of the unfamiliar interactive computer systems. The results of the experiment supported the inclusion of the modifications. Non-programmers using the modified system completed the computer task in less time, with greater accuracy, and with better resulting attitudes than those who used the system designed primarily for programmers.
1983	A proposal for user centered system documentation	This paper outlines a set of proposals for the development of system documentation based on an analysis of user needs. It is suggested that existing documentation is not sensitive enough to the variety of levels of user expertise, nor to the variety of contexts in which on-line help is required. We outline three specific proposals for fulfilling these needs: a quick reference facility, a command-line database, and a facility for full explanation and instruction, and suggest a number of ways in which users might access these facilities. Finally, we suggest a way of combining these facilities into an integrated structured manual, offering more effective user support than is currently provided.
1983	Autobiography of a first-time discretionary microcomputer user	Research in the area of human-computer interaction has typically concentrated on hardware and software design characteristics which increase the usability of the system, or the effectiveness of the relationship between the user and the system in the accomplishment of a task (Bennett, 1979). Few of these studies have concentrated on documentation. This is striking since the documentation of a computer system is a major portion of the user's learning experience with the system and also the primary interface when difficulties with the system occur. There is a growing market of users who are expected to learn how to use a computer system solely by reading the documentation, namely, the personal computer users. The number of privately authored books on “how to survive the personal computer experience” bespeak both the growing number of such users and the inadequacy of the documentation provided by the vendors.
1985	The effect of VDU text-presentation rate on reading comprehension and reading speed	The effect of video display unit presentation rate on reading performance was investigated. Reading material was presented at one of the following presentation-rates: 15, 30, 120, 960 cps, or “instant”. In the instant condition, the full text appeared simultaneously on the screen. In the other conditions, text appeared one character at a time starting in the upper left corner of the screen, from left to right and top to bottom. Reading comprehension was highest under the 30 cps and instant presentation conditions. Total time to perform the reading task was equivalent for all conditions except the 15 cps rate which required a longer time to complete the task. In terms of comprehension and time to perform the task, a slow rate of 15 cps, contrary to previous recommendations, is not desirable for novice computer users.
1985	Effects of cursor speed on text-editing	Nine participants used a full screen computer text-editor (XEDIT) with an IBM 3277 terminal to edit marked-up documents at each of three cursor speeds (3.3, 4.7, and 11.0 cm/sec.). Results show that 9\% of editing time was spent controlling and moving the cursor, regardless of cursor speed. The variations in cursor speed studied did not seem to act as a pacing device for the entire editing task.
1985	The importance of percent-done progress indicators for computer-human interfaces	A “percent-done progress indicator” is a graphical technique which allows the user to monitor the progress through the processing of a task. Progress indicators can be displayed on almost all types of output devices, and can be used with many different kinds of programs. Practical experience and formal experiments show that prograss indicators are an important and useful user-interface tool, and that they enhance the attractiveness and effectiveness of programs that incorporate them. This paper discusses why progress indicators are important. It includes the results of a formal experiment with progress indicators. One part of the experiment demonstrates that people prefer to have progress indicators. Another part attempted to replicate earlier findings to show that people prefer constant to variable response time in general, and then to show that this effect is reversed with progress indicators, but the results were not statistically significant. In fact, no significant preference for constant response time was shown, contrary to previously published results.
1985	The utility of natural language interfaces (panel session)	Natural language interfaces are frequently proposed as a solution to the problems of “user-unfriendliness” present in many existing computer system interfaces. The panel will examine this claim, and discuss in what circumstances (if any) it is (or could be) true. As a starting point, let us define a natural language interface as an interface to a computer system that allows the user to control the system by English 1 commands or queries. Sometimes the output seen by the user will also be in natural language. Currently, most natural language interfaces only accept typed, rather than spoken, input. Also, such interfaces typically can only handle input related to the restricted world of their underlying application, and moreover, only a subset (albeit expressively comprehensive) of that. Set against these advantages are the following standardly cited disadvantages: verboseness: English commands or queries can take many more keystrokes to enter than equivalent formal command lines or menu-based selection. coverage restrictions: Since current natural language interfaces cannot handle all natural language inputs, not even all those relevant to their domain of discourse, the user is faced with the task of learning what the system can and cannot deal with, usually by trial and error. Given these conflicting arguments, it seems better to avoid the general question of whether natural language interfaces are Good or Bad. Instead, the panel will concentrate on how the utility of natural language interfaces is affected by the environment (broadly conceived) in which they operate. We will also be concerned with how the utility of specific natural language or other types of interface can be determined in specific circumstances. Factors affecting the utility of natural language interfaces include: Type of user: Natural language interfaces are better suited to novice or casual users rather than expert or frequent users of a system. An expert or frequent user can afford the cost of learning a command language because of the terseness it allows. On the other hand, it may be more economical for a novice or infrequent user to enter a verbose natural language input than to find out the correct terse command line. Combination with other input types: It may be possible to build interfaces which combine natural language and other types of interface in way that retains the best features of both, while reducing the impact of their negative features. The above list of issues does not pretend to be comprehensive, out is intended as a basis for discussion. Many other issues will no doubt arise during the course of the panel.
1985	A multi-touch three dimensional touch-sensitive tablet	A prototype touch-sensitive tablet is presented. The tablet's main innovation is that it is capable of sensing more than one point of contact at a time. In addition to being able to provide position coordinates, the tablet also gives a measure of degree of contact, independently for each point of contact. In order to enable multi-touch sensing, the tablet surface is divided into a grid of discrete points. The points are scanned using a recursive area subdivision algorithm. In order to minimize the resolution lost due to the discrete nature of the grid, a novel interpolation scheme has been developed. Finally, the paper briefly discusses how multi-touch sensing, interpolation, and degree of contact sensing can be combined to expand our vocabulary in human-computer interaction.
1985	A subjective judgment study of polygon based curved surface imagery	In the past computer graphics efforts, several researchers have demonstrated that polygon models can be used to produce images of curved surfaces that appear to be smooth and accurate. However, the authors know of no attempt to appraise such imagery by using multiple human observation ratings. The effectiveness of curved surface imagery generated from polygon models was investigated in a judgment study. Research subjects evaluated sphere model imagery derived from several polygon densities and shading procedures including flat shading, shade interpolation (Gouraud) and normal interpolation (Phong). Results of the evaluations indicated that little was gained by reducing the average polygon areas below approximately 110 pixels per polygon for spheres of 95 pixel radii displayed on a 512 x 512 resolution monitor. Evaluations for both shade and normal interpolution placed polygon image quality reasonably close to an “ideal” image. Although the evaluations indicated that normal interpolation was slightly superior to the shade interpolation, shade interpolation required significantly less computation. Most significantly, results from this study provide strong support for the notion that polygons can be used effectively to produce smooth shaded imagery of curved surface models.
1985	VIDEOPLACE—an artificial reality	The human-machine interface is generalized beyond traditional control devices to permit physical participation with graphic images. The VIDEOPLACE System combines a participant's live video image with a computer graphic world. It also coordinates the behavior of graphic objects and creatures so that they appear to react to the movements of the participant's image in real-time. A prototype system has been implemented and a number of experiments with aesthetic and practical implications have been conducted.
1985	Psychological research methods in the human use of computers (panel session)	Psychological research methods have been used with increasing frequency in work on computer-human interaction. Judging from the state of the literature and from remarks heard in the halls at conferences such as this, the utility and appropriate roles of such methods are not yet clear. Panel members, who are all research psychologists working on issues related to human use of computers, will present a variety of contrasting views on how to go about such research, and on its proper goals. John Gould will describe two different but complimentary approaches, applied research on general design issues, and formative human factors participation in development. John Anderson will discuss the use of formal models of human cognition. Phil Barnard will consider the role of applied research in the discovery of underlying principles to guide design. Tom Landauer will propose that psychological research can be the basis for invention of new “;cognitive tools”. Short synopses of the positions they will take e given below. Panel members hope that the audience will join them in bringing out important differences between the various approaches and methods and arguing their absolute and relative merits.
1985	Where the bugs are	In this paper we propose one explanation of why some novice programs are buggier than others. Central to our explanation is the notion of merged goals/plans in which multiple goals are achieved in a single integrated plan. Our arguments are based on our theory of the knowledge — plans and goals — used by a novice in creating a program, and an analysis of actual buggy novice programs.
1985	Extending the spreadsheet interface to handle approximate quantities and relationships	Conventional spreadsheet programs offer a very convenient user interface for many quantitative tasks, but they are restricted to handling precisely-specified quantities and calculations. ASP is a generalized spreadsheet that extends the basic spreadsheet paradigm to encompass quantities which are not known exactly, and functions which are not known well enough to permit calculation. ASP works by propagating assertions about quantities and functions through the network of relationships that the spreadsheet defines.
1985	Estimating the distribution of software complexity within a program	This paper proposes an approach to the characterization of complexity within computer software source texts. We estimate the information content of individual program tokens as the basis for a relative ordering of tokens by their 'uncertainty' or 'perculiarity' within the context of the program in which they reside. The analysis method used is in part an extension of software science methods. The information gained from the analysis highlights language usage anomalies and potential errors. This information may be useful in guiding software review activities. More theoretical work and experimental validation will be necessary before the analysis technique may be used in a productive environment.
1985	Interfaces in organizations (panel session): supporting group work	Research on human factors in computer systems has emphasized supporting individuals. This panel will discuss new issues that emerge when computer systems support groups of people and whole organizations. Malone (see following paper) will suggest a broadening of the definition of user interfaces to include “organizational interfaces” and will indicate how a theoretical base for such an endeavor might be developed. Then Cashman will describe a “coordinator tool” in use at DEC for tracking the assignment of tasks to people in activities such as software maintenance. Finally, Brown will suggest how computer systems can be designed to radically increase the bandwidth of cooperation in groups by, for example, exploiting linguistic notions of context.
1985	Designing organizational interfaces	This paper argues that it will become increasingly important to extend our concept of user interfaces for individual users of computers to include organizational interfaces for groups of users. A number of suggestions are given for how to develop a theoretical base for designing such interfaces. For instance, examples are used to illustrate how traditional cognitive points of view can be extended to include information processing by multiple agents in organizations. Examples of design implications from other perspectives such as motivational, economic, and political are also included.
1985	Selection from alphabetic and numeric menu trees using a touch screen: breadth, depth, and width	Goal items were selected by a series of touch-menu choices among sequentially subdivided ranges of integers or alphabetically ordered words. The number of alternatives at each step, b , was varied, and, inversely, the size of the target area for the touch. Mean response time for each screen was well described by T = k + c log b , in agreement with the Hick-Hyman and Fitts' laws for decision and movement components in series. It is shown that this function favors breadth over depth in menus, whereas others might not. Speculations are offered as to when various functions could be expected.
1985	Designing a menu-based interface to an operating system	The development of a large menu-based interface to an operating system posed a number of interesting user interface questions. Among those were how to determine the user's view of the relationships among the myriad of functions in the system, and how to reflect those relationships in a menu hierarchy. An experiment utilizing a sorting technique and hierarchical cluster analysis was quite effective in learning the user's perception of the relationships among the system functions. A second experiment comparing a “broad” menu hierarchy to a “deep” menu hierarchy showed that users made significantly fewer inappropriate menu selections with the broad hierarchy.
1985	Connecting theory and practice: a case study of achieving usability goals	This paper describes a case study of the Human Factors design, development, and testing of a computer-based financial analysis package. The project applied the “usability goals” method proposed by Bennett (1984) to structure the definition, design, and testing of the new system. Learnability was defined as a key attribute in the product concept because of its salience in users' perception of system quality. The learnability attribute was assigned an operational definition in terms of time to mastery and error avoidance/recovery. The “back-to-front” strategy of Didner & Butler (1982) was applied for designing the menus. Empirical testing of user performance on sample problems in the alpha stage indicated that the new system surpassed the learnability objective. Lessons learned from this case study concern leverage in getting better managerial attention for Human Factors considerations in development projects, and clearer structure to direct needed research.
1985	The use of logging data in the design of a new text editor	Many different human factors techniques are available to the designer of a new computer system. This case study examines how one technique, the use of logging data, was used throughout the design of a new text editor which is measurably easy to learn and easy to use. Logging data was used in four areas: keyboard design, the initial design of the editor's command set, refinements made later in the design cycle, and the construction of a system performance benchmark.
1985	The evaluation of text editors: a critical review of the Roberts and Morgan methodology based on new experiments	Three text editors were studied using the editor evaluation methodology developed by Roberts and Moran [3, 4]. The results are presented as an extension of the studies by Roberts and Moran, with comparisons to the editors they studied earlier. In addition, supplementary measurements were taken that suggest minor flaws in the Roberts and Moran methodology. Further problems with the methodology are discussed, with an eye toward improving the methodology for future use. Although three significant problems with the methodology are reported, the problems are interesting primarily as lessons for the design of future evaluation methodologies. The Roberts and Moran methodology remains largely useful for the purposes for which it was designed.
1985	Evaluating the user interface: the candid camera approach	In the development of a new interactive graphics application, considerable effort was spent on designing a user interface which would be easy to use. When a portion of the application was completed, typical potential users were brought in to help evaluate the interface. They were given a sample task and a short introduction to the application; then their efforts to complete the task were observed and videotaped. This method of evaluating the user interface provided the development staff with quite a bit of valuable information. Changes were made, and more testing was done, including using some subjects for a second time. This paper describes how this evaluation method was used for two purposes: to point out problem areas in the interface, and to verify that changes made have improved the user interface.
1985	Communicating with sound (panel session	The Communicating with Sound panel for CHI '85 will focus on ways of expanding the user interface by using sound as a significant means of output. As a user's communication from the computer has progressed from large (and often smeary) printout to a teletypewriter and, finally, to the multi-window workstation displays of today, the emphasis has remained primarily on visual output. Although many user terminals and workstations have the capability of generating sound, that capability is rarely used for more than audio cues (indicating status such as an error condition or task completion) and simple musical tunes. Research shows that sounds convey meaningful information to users. With examples of such research, the panel members will demonstrate a variety of uses of sound output, discuss issues raised by the work, and suggest further directions. The intent of the panel is to stimulate thinking about expanding the user interface and to discuss areas for future research. In the statements that follow, each panelist will describe his or her own work, including the data and audio dimensions used, the value of the research, remaining issues to be addressed, and suggestions for future research and application. A list of references is included for those who wish further reading.
1985	When does an abbreviation become a word? and related questions	An experiment is reported in which subjects previously naive to text editing learned to use a set of editing commands. Some subjects used abbreviations from the beginning. Others began by using full command names, then switched to the (optional) use of abbreviations, either of their own devising or of our selection. We found significant differences in the number and nature of the errors produced by subjects in the different conditions. People who created their own abbreviations did most poorly, and did not appear to learn from this experience. Those who used abbreviations from the start were more likely to fall into error through misrecalling the referent names. The results suggest aspects of the underlying cognitive representations, with implications for the design of software interfaces.
1985	A comparison of symbolic and spatial filing	The traditional and still dominant form of object reference in computing systems is symbolic - data files, programs, etc. are initially labeled and subsequently referred to by name. This approach is being supplemented on some systems by a spatial alternative which is often driven by an office or desktop metaphor (e.g. Apple's Lisa and MacIntosh systems, or Bolt's 1979 Spatial Data Management System). In such systems, an object is placed in a simulated two- or three-dimensional space, and can later be retrieved by pointing to its location. In order to begin to understand the relative merits of spatial and symbolic filing schemes for representing and organizing information, we compared four ways of filing computer objects. We found location information to be of limited utility, either by itself or in combination with symbolic information. This calls into question the generality and efficacy of the desktop metaphor for information retrieval.
1985	Experience with an adaptive indexing scheme	Previous work has shown that there is a major vocabulary barrier for new or intermittent users of computer systems. The barrier can be substantially lowered with a rich, empirically defined, frequency weighted index. This paper discusses experience with an adaptive technique for constructing such an index. In addition to being an easy way for system designers to collect the necessary data, an adaptive system has the additional advantage that data is collected from real users in real situations, not in some laboratory approximation. Implementation considerations, preliminary results and future theoretical directions are discussed.
1985	Computer human factors in computer interface design (panel session)	Human factors psychologists contribute in many ways to improving human-computer interaction. One contribution involves evaluating existing or prototype systems, in order to assess usability and identify problems. Another involves contributing more directly to the design of systems in the first place: that is, not only evaluating systems but bringing to bear empirical methods and theoretical considerations that help specify what are plausible designs in the first place. The goal of this panel is to discuss four case studies emphasizing this role of cognitive human factors, and identify relevant methods and theoretical considerations. The panelists will present examples of prototypes or products to whose design they contributed, with the aim of characterizing the problem (or problems) they tried to solve, the approach to identifying a design solution for that problem, and evidence that the approach was useful. Robert Mack will discuss an editor prototype designed to get novices started doing meaningful work quickly and helping them to continue acquiring new skills, with virtually no explicit instruction. The prototype is being designed in large part by identifying key novice problems and expectations, and trying to design the interface to better accommodate these expectations. The first goal of getting novices started relatively quickly has been achieved but problems remain as novices try to acquire further text-editing skill. These problems — and solutions to them — are being identified through a process of iterative design and evaluation. Dennis Wixon will discuss implications for designing usable interfaces of the User-Derived-Interface project (Good, M., Whiteside, J., Wixon, D. and Jones, S., 1984). The project involved a simulation of a restricted natural language interface for an electronic mail system. The design process was driven by the behavioral goal of getting users started relatively quickly with little or no instruction or interface aids. Actual user interaction with the simulation coupled with iterative design and evaluation provided interface specifications. This prototype illustrates a number of techniques for bringing usability into the software engineering process. These presentations will discuss the role of empirical methods such as verbal protocol techniques for identifying user problems with existing computer systems (e.g., Lewis, 1982; Mack, Lewis & Carroll, 1983; Douglas & Moran, 1983), including variations aimed at identifying user expectations that may be able to guide design (e.g., Mack, 1984); interface simulations for studying user interactions again with the aim of letting user behavior guide interface design (e.g., Kelley, 1984; Good, Whiteside, Wixon & Jones, 1984), and iterative design and evaluation of interfaces, aimed at achieving behavioral goals (e.g., Carroll & Rosson, 1984; Gould & Lewis, 1983).
1985	Expanded design procedures for learnable, usable interfaces (panel session)	Designers of interactive computer systems have begun to incorporate a number of good techniques in the design process to insure that the system will be easy to learn and easy to use. Though not all design projects use all the steps recommended, the steps are well known: Define the tasks the user has to perform, Know the capabilities of the user, Gather relevant hardware/software constraints, From guidelines, design a first prototype, Test the prototype with users, Iterate changes in the design and repeat the tests until the deadline is reached. In our experience designing a new interface, steps 1 and 4 were the ones that were the most difficult and step 5 was the one that took extra time to plan well. We had difficulty defining what would go into a new task, and from broad guidelines, we had to develop one specific implementation for our tasks. Furthermore, so that in each test we would learn something of value for future designs, we knew that we wanted to test pairs of prototypes that differed in only one feature. Choosing which single feature to alter in each pair required careful planning. In what follows, I describe each of these difficulties more fully and show how we approached each in our environment. Normally, a task is defined as a computer-based analog of an existing task, such as wordprocessing being the computer-based analog of typing. Since we had to build an interface for an entirely new task, we had to invent how the user would think about the task. We had to invent the objects on which the user would operate and then the actions that would be performed on those objects. We had to specify the mental representation in the absence of previous similar tasks. In our case, we were designing the interface for a communications manager to designate the path to be taken for routing 800-calls to their final destination as a function of time of day, day of week, holidays, percentage distribution, etc. From the large set of known formal representations of data, e.g. lists, pictures, tables, hierarchies, and networks, we found three that seemed to capture the information sufficient for our task. We found that a hierarchy (tree structure), a restricted programming language in which there were only IF-THEN-ELSEs and definitions, and a long form to be filled out with all possible ordered combinations of the desired features, were all sufficient representations. We then asked potential users in casual interviews which format they found easiest to understand. It was immediately clear even from a relatively small number of subjects that the tree representation was preferred. The second aspect of defining the task involved specifying what actions the user would take on this representation. Since in all interfaces, users have to move about, select an item to work on, enter information, delete information, and change modes (from data entry to command, typically), we looked for these kinds of actions in our task. The actions immediately fell into place, with commands being generated for moving about a tree, entering nodes and branches, etc. After gathering information on who the end users were and what hardware constraints we had, we designed our first prototype. This was our next most involved chore. Our broad guidelines said that we should: Present information on the computer in a representation as close as possible to the user's mental representation. Minimize the long-term and short-term memory loads (e.g. make retrieval of commands and codes easy, give the user clues about where he or she is in a complicated procedure or data structure). Construct a dialog that holds to natural conversational conventions (e.g., make pauses predictable, acknowledge long delays, use English imperative structure in the command syntax). Our initial design on paper was fairly easy to construct. We followed that, however, with an important analysis step before we built our first prototype. For each part of the design, we constructed an alternative design that seemed to fit within the same constraints and within the guidelines. That is, we identified the essential components of our interface: the representation of the data, the organization of the command sector, the reminders, and the specific command implementations such as how to move around the data representation. For example, in the command sector there are alternative ways to arrange the commands for display: they could be grouped by similar function so that all “move” commands were clustered and all “entry” commands were clustered, etc, or they could be grouped into common sequences, such as those that people naturally follow in initially entering the nodes and branches of the tree structures. Once each component had an alternative, we debated the merits of each. Our first prototype, then, was the result of this first paper design plus the alterations that were generated by this analysis procedure. The next step entailed testing our design with real users. Since we wanted to test our prototypes so that we learned something useful for our next assignment, we chose to test two prototypes at a time. If we were to learn something from the test, then only one component could differ between the two prototypes. The difficulty arose in deciding which component was to be tested in each pair. For this task, we went back to our initial component-by-component debate about the prototype. For each of the components and its alternative, we scored the choice on three dimensions: That is, first, for some alternatives, the better choice was predictable. For example, displaying command names was known to be more helpful than not displaying them. Testing this alternative would not teach us very much. Second, we needed to choose some alternatives early, so that the developers could begin immediately with some preliminary work. For example, our developers needed to know early whether the data would be displayed as a form or a tree so they could set up appropriate data structures. And third, some alternatives would appear again in future design projects. For example, all projects require some way of moving about the data but few deal directly with trees. Knowledge gained now about the movement function would pay off in the future whereas how to display trees may not. Once we prioritized our alternatives on these dimensions, we were able to choose the alternative for the first prototype test. After the test, we found other ideas to incorporate in the next iteration, but went through the same analysis procedure, listing the components, debating alternatives, and prioritizing those to be tested in the next iteration. In summary, the procedure we followed in designing and testing our prototypes was standard in overall form, flowing from defining the task, user, and constraints; building prototypes; and testing them with users. We differed, however, in three of our steps. We spent important initial time considering the best task representation to display to the user. We analyzed the individual components of our first prototype, generating a design for actual implementation that was more defensibly good than our first paper design. And, in our iterative testing procedure, we selected pairs of prototypes for test, the pairs differing on only one component of the design. The component for testing was selected according to whether the test would teach us something, whether it was important to decide early in the development process, and whether the component would appear again in designs we encountered in the future. These expanded steps in the design process not only added to our confidence that our early design was reasonably good, but also gave us the data and theory with which to convince others, notably developers and project managers, of the merit of our design. And, the process taught us something of use for our next design project.
1985	Engineering for usability (panel session): lessons from the user derived interface	The focus here is on the lessons learned from the UDI project for building usability into the software development process. In the UDI project we attempted to engineer a usable system. That process involved: defining an appropriate metric for measuring usability, setting explicit levels of usability to be achieved determining an appropriate methodology for building usability into the system, delivering a seemingly functional system with an easily changed interface very early in the development cycle, and recognizing the tentative nature of the initial design. Using the UDI project as an example, each of the above principles will be discussed in detail.
1985	Prompting, feedback and error correction in the design of a scenario machine	The recent technical literature abounds with a variety of studies documenting and analyzing the problems people encounter in learning to use contemporary computer equipment. This has been a major focus of the recent work in our laboratory ([6], [9]). The project such work must entrain is the development of design approaches to these problems. We have been and are developing alternate designs for training manuals and for in-system training ([2], [4], [5], [7]). This paper is a report of work in progress in this area. We describe a design approach to in-system training referred to as the Scenario Machine, and describe some initial results from an empirical learning study of four scenario machines.
1985	Information sought and information provided: an empirical study of user/expert dialogues	Transcripts of computer-mail users seeking advice from an expert were studied to investigate the complementary claims that people often do not know what information they need to obtain in order to achieve their goals, and consequently, that experts must identify inappropriate queries and infer and respond to the goals behind them. This paper reports on one facet of the transcript analysis, namely, the identification of the types of relation that hold between the action that an advice-seeker asks about and the action that an expert tells him how to perform. Three such relations between actions are identified: generates, enables, and is-alternative-to . The claim is made that a cooperative advice-providing system, such as a help system or an expert system, must be able to compute these relations between actions.
1985	Knowledge-based help systems	Our research goals are to understand the nature of, construct and evaluate intelligent interfaces as knowledge-based systems. In this paper we demonstrate the need for help systems as an essential part of human-computer communication. Help strategies are based on a model of the task (to understand what the user is doing or which goals he/she 1 wants to achieve) and a model of the user (to guarantee that these systems are non-intrusive and that they pay attention to the needs of individual users). We illustrate that passive and active help systems have to be constructed as knowledge-based systems. Two operational systems (PASSIVIST and ACTIVIST) are described to show the usefulness of this approach.
1985	Design alternatives for user interface management sytems based on experience with COUSIN	User interface management systems (UIMSs) provide user interfaces to application systems based on an abstract definition of the interface required. This approach can provide higher-quality interfaces at a lower construction cost. In this paper we consider three design choices for UIMSs which critically affect the quality of the user interfaces built with a UIMS, and the cost of constructing the interfaces. The choices are examined in terms of a general model of a UIMS. They concern the sharing of control between the UIMS and the applications it provides interfaces to, the level of abstraction in the definition of the information exchanged between user and application, and the level of abstraction in the definition of the sequencing of the dialogue. For each choice, we argue for a specific alternative. We go on to present COUSIN, a UIMS that provides graphical interfaces for a variety of applications based on highly abstracted interface definitions. COUSIN'S design corresponds to the alternatives we argued for in two out of three cases, and partially satisfies the third. An interface developed through, and run by COUSIN is described in some detail.
1985	ADM — a dialog manager	ADM is a system for developing user interfaces. We call it a dialog manager; it is similar to what others call a “User Interface Management System” [8]. Although ADM is still being developed, it has been used to construct several applications. A dialog manager divides an application into an “interaction handler,” which interacts with the user, and an “underlying application,” which processes user commands and data. With ADM the application designer writes the underlying application in a conventional programming language and defines the interface between interaction handler and underlying application in terms of “tasks,” things the user can do, and “states,” sets of tasks that are active at one time. The user interface designer defines the interaction handler in terms of “presentation techniques,” which present tasks to the user, and “structuring techniques,” which describe screen layout. Design decisions made for ADM include using a precompiled, declarative dialog description, a flexible division between interaction handler and underlying application, allowing either interaction handler or underlying application to maintain control, and the inclusion of help and error support.
1985	User performance with command, menu, and iconic interfaces	Performance and subjective reactions of 76 users of varying levels of computer experience were measured with 7 different interfaces representing command, menu, and iconic interface styles. The results suggest three general conclusions: there are large usability differences between contemporary systems, there is no necessary tradeoff between ease of use and ease of learning, interface style is not related to performance or preference (but careful design is). Difficulties involving system feedback, input forms, help systems, and navigation aids occurred in all styles of interface: command, menu, and iconic. New interface technology did not solve old human factors problems.
1985	Listener training for speech-output applications	The specificity of the adaptation to synthetic speech known to occur with practice was examined by giving listeners selective exposure to a subset of English phonemes (a control group was “trained” on analogous materials produced by a human speaker), and then testing their ability to identify words created from both the previously heard and novel phonemes. The results indicated that while synthetic voice training was generally facilitative, it was most helpful in the identification of the sounds heard before. However, this specific learning effect occured for only certain phonemes. The findings imply that one way to maximize early adaptation to synthetic speech is to identify the “learnable” sounds, and to increase users' exposure to them during introductory or training dialogs.
1985	Speech recognition and manner of speaking in noise and in quiet	Currently speech recognition is accomplished by matching spoken utterances with reference patterns of words that were spoken by an individual at an earlier time. Recognition is highly dependent upon background noise. The purpose of this study was to assess the extent to which subjects “manner” of speaking in noise, as separate from the noise itself, affected recognition. Subjects generated reference patterns in quiet and in noise and then spoke lists of digits in quiet and in noise for the speech system to recognize. Noise was delivered over earphones so it would not go into the speech recognition system through the microphone. Training and recognition were done from tape recordings, with the playback level of the tape was always set to the same, intermediate level. The data suggest that manner of speaking, for about half of the subjects is very different in noise compared with quiet. The data also imply that if recognition will be done in both quiet and noise, the safest alternative is to start out with patterns generated in noise.
1985	Why is synthetic speech harder to remember than natural speech?	Previous research has demonstrated that synthetic speech is less well recalled than natural speech. Luce et al (1983) concluded that this was because synthetic speech increases the effort involved in encoding and/or rehearsal of presented information. Results of the experiments described here, which involved ordered recall of lists of ten words spoken in either a synthetic or a natural voice, with repetition of the words as a measure of successful encoding, indicate that most of the memory deficit with synthetic speech is due to encoding difficulties, rather than problems with item retention. There is evidence that encoding synthetic speech involves more processing capacity than does encoding natural speech, but that once it is encoded it is stored just as efficiently.
1985	A quantitative model of the learning and performance of text editing knowledge	A model of manuscript editing, implemented as a simulation program, is described in this paper. The model provides an excellent, quantitative description of learning, transfer, and performance data from two experiments on text editing methods. Implications of the underlying theory for the design process are briefly discussed.
1985	A theory of stimulus-response compatibility applied to human-computer interaction	A GOMS theory of stimulus-response compatibility is presented and applied to remembering computer command abbreviations. Two abbreviation techniques, vowel-deletion and special-character-plus-first-letter, are compared in an encoding task. Significant differences are found in the time to type the first letter of the abbreviation, and in the time to complete the typing of the abbreviation. These differences are analyzed using the theory which produces an excellent quantitative fit to the data (r 2 = 0.97).
1985	BASIC versus natural language: is there one underlying comprehension process?	This study determined the response time (RT) for subjects to comprehend eight different BASIC statements and eight corresponding English procedural statements. First, there was no significant interaction between language and statement, and there was a high correlation (r = .85) between English and BASIC RT performance. Second, the microstructure of each statement (the number of actions required) and the macrostructure (the number of other statements in the program) were strongly related to RT performance for both BASIC and English. Apparently, comprehension of procedural statements is related to underlying structural characteristics common to both languages.
1985	Microcomputer user interface toolkits (panel session): the commercial state-of-the-art	A well-designed user interface is a very valuable asset: the best available today are based on hundreds of man-years of work combining results of research in human factors, tasteful design reviewed and modified through extensive end-user testing, and many rounds of implementation effort. As a result, the user interface “toolkit” is emerging as the hottest new software item. A toolkit can provide software developers with a programming environment in which the user interface coding is already done so that new applications programs can automatically be integrated with other workstation functions. The panel will evaluate this new trend. Tesler and MacGregor, will present the designs of the leading toolkit products from Apple and Microsoft, respectively. Reed will analyze the choices from the point of view of the third party software vendors' requirements. Noting that the effort going into these products may well result in de facto standard setting, Buxton will question the appropriateness of making this commitment based on microcomputer hardware.
1986	Of moles and men: the design of foot controls for workstations	Workstations require use of the hands both for text entry and for cursor-positioning or menu-selection. The physical arrangement does not allow these two tasks to be done concurrently. To remove this restriction, various alternative input devices have been investigated. This work focuses on the class of foot-operated computer input devices, called moles here. Appropriate topologies for foot movement are identified, and several designs for realising them are discussed.
1986	Seven plus or minus two central issues in human-computer interaction	This paper offers seven issues and specific challenges for researchers and developers of human-computer interaction. These issues are: interaction styles, input techniques, output organization, response time, error handling, individual differences, explanatory and predictive theories.
1986	The information lens: an intelligent system for information sharing in organizations	This paper describes an intelligent system to help people share and filter information communicated by computer-based messaging systems. The system exploits concepts from artificial intelligence such as frames, production rules, and inheritance networks, but it avoids the unsolved problems of natural language understanding by providing users with a rich set of semi-structured message templates. A consistent set of “direct manipulation” editors simplifies the use of the system by individuals, and an incremental enhancement path simplifies the adoption of the system by groups. One of the key problems that arises when any group of people cooperates to solve problems or make decisions is how to share information. Thus one of the central goals of designing good “organizational interfaces” (Malone, 1985) should be to help people share information in groups and organizations. In this paper, we will describe a prototype system, called the Information Lens, that focuses on one aspect of this problem: how to help people share the many diverse kinds of qualitative information that are communicated via electronic messaging systems. It is already a common experience in mature computer-based messaging communities for people to feel flooded with large quantities of electronic “junk mail” (Denning, 1982; Palme, 1984; Wilson, 1984; Hiltz & Turoff, 1985), and the widespread availability of inexpensive communication capability has the potential to overwhelm people with even more messages that are of little or no value to them. At the same time, it is also a common experience for people to be ignorant of facts that would facilitate their work and that are known elsewhere in their organization. The system we will describe helps solve both these problems: it helps people filter, sort, and prioritize messages that are already addressed to them, and it also helps them find useful messages they would not otherwise have received. The most common previous approach to structuring information sharing in electronic messaging environments is to let users implicitly specify their general areas of interest by associating themselves with centralized distribution lists or conference topics related to particular subjects (e.g., Hiltz & Turoff, 1978). Since these methods of disseminating information are often targeted for relatively large audiences, however, it is usually impossible for all the information distributed to be of interest to all recipients. The Information Lens system uses much more detailed representations of message contents and receivers' interests to provide more sophisticated filtering possibilities. One of the key ideas behind this system is that many of the unsolved problems of natural language understanding can be avoided by using semi-structured templates (or frames) for different types of messages. These templates are used by the senders of messages to facilitate composing messages in the first place. Then, the same templates are used by the receivers of messages to facilitate constructing a set of rules to be used for filtering and categorizing messages of different types.
1986	Graphic interfaces for knowledge-based system development	Creating and debugging knowledge-based systems, such as expert systems, requires easy access to rules and facts in a vast, loosely-connected system. Three graphic representations were devised for a system development tool that integrates forward chaining, backward chaining, and full truth maintenance. In one representation, possible interactions among rules, determined by syntactically parsing the rules, are displayed as a directed graph. In a second representation, actual interactions among facts and rules are displayed dynamically. The third representation is a fish-eye view of the knowledge base that explains why a fact was asserted. In addition, the text of rules and facts is displayed in editing windows.
1986	Generalized fisheye views	In many contexts, humans often represent their own “neighborhood” in great detail, yet only major landmarks further away. This suggests that such views (“fisheye views”) might be useful for the computer display of large information structures like programs, data bases, online text, etc. This paper explores fisheye views presenting, in turn, naturalistic studies, a general formalism, a specific instantiation, a resulting computer program, example displays and an evaluation.
1986	Human computer interaction in the year 2000	Much of the work in the field of computer human interaction consists of finding out what is wrong with existing interfaces or which of several existing alternatives is better. Over the next few decades, the possibilities for computer human interaction will explode. This will be due to: 1) continued decrease in the costs of processing and memory, 2) new technologies being invented and existing technologies (e.g., handwriting recognition, speech synthesis) being extended, 3) new applications and 4) new ideas about how people can interact with computers. While changes along these lines are bound to occur, we need not take the view that investigators in human-computer interaction are to be passive observers of some uncontrolled and uncontrollable evolution. Indeed, we can help steer this process by visions of what the future of human computer interaction could and should be like.
1986	The formal specification of adaptive user interfaces using command language grammar	The design and implementation of adaptive systems as opposed to non-adaptive systems creates new demands on user interface designers. This paper discusses a few of these demands as encountered by the authors while utilising a formal notation for the design of an adaptive user interface to an electronic mail system. Recommendations for the extension of this formal notation are proposed and discussed.
1986	An input-output model of interactive systems	Interactive user interfaces depend critically on underlying computing system facilities for input and output. However, most computing systems still have input-output facilities designed for batch processing. These facilities are not adequate for interfaces that rely on graphical output, interactive input, or software constructed with modern methodologies. This paper details the deficiencies of batch-style input-output for modern interactive systems, presents a new model for input-output that overcomes these deficiencies, and suggests software organizations to take advantage of the new model.
1986	Formatting space-related displays to optimize expert and nonexpert user performance	NASA Space Station missions will include crewmembers who are highly experienced in the use of the Space Station computer system, as well as others who are novices. Previous research into novice-expert differences has strongly implied that user interface changes that aid novices tend to impair experts and vice versa. This experiment investigated the impact reformatting alphanumeric information on current Space Shuttle computer displays had on the speed and accuracy of experts and nonexperts in two different search tasks. Large improvements in speed and accuracy were found for nonexperts on the reformatted displays. Experts had fewer errors but no response time difference on the reformatted displays. Differences in expert and nonexpert search strategies and implications for the design of computer displays are discussed.
1986	Designing in the dark: logics that compete with the user	Skills developed by software user interface designers to solve problems in communication, management, implementation, and other areas may influence design decisions in the absence of sufficient knowledge of user populations. Given today's rapid change in both “faces” to the software interface — user populations and software functionality — the first pass at a design may be made without sufficient understanding of the relevant goals and behaviors of the eventual users. Without this information, designers are less able to grasp “user logic”, and may rely on more familiar “logics” that are useful in other problem-solving arenas. Understanding how these approaches can affect a design may help us recognize them across a wide range of contexts and enable us to focus the human factors contribution to the design evolution process.
1986	A formal interface design methodology based on user knowledge	In this paper we propose a formal interface design methodology based on user knowledge. The general methodology consists of 1) obtaining distance estimates for pairs of system units (objects, actions, concepts), 2) transforming the distance estimates using scaling techniques (e.g., Pathfinder network analysis), and 3) organizing the system interface based on the scaling solution. Thus, the organization of the system is based on the cognitive models of users rather than the intuitions of designers. As an example, we discuss the application of our methodology to the design of a network-based indexing aid for the UNIX on-line documentation system (MAN).
1986	The memory extender personal filing system	The benefits of electronic information storage are enormous and largely unrealized. As its cost continues to decline, the number of files in the average user's personal database may increase substantially. How is a user to keep track of several thousand, perhaps several hundred thousand, files? The Memory Extender (ME) system improves the user interface to a personal database by actively modeling the user's own memory for files and for the context in which these files are used. Files are multiply indexed through a network of variably weighted term links. Context is similarly represented and is used to minimize the user input necessary to disambiguate a file. Files are retrieved from the context through a spreading-activation-like process. The system aims towards an ideal in which the computer provides a natural extension to the user's own memory.
1986	A model of mental model construction	Learning to control a computer system from limited experience with it seems to require constructing a mental model adequate to indicate the causal connections between user actions, system responses, and user goals. While many kinds of knowledge could be used in building such a model, a small number of simple, low-level heuristics is adequate to interpret some common computer interaction patterns. Designing interactions so that they fall within the scope of these heuristics may lead to easier mastery by learners.
1986	Intelligent interfaces: user models and planners	To meet the challenge of constructing interfaces for increasingly complex multifunctional products, designers will be attracted by the promise offered by “intelligent” systems. However, the value of such sophisticated systems must be measured in terms of the quality of their user's models. One such intelligent interface — an Expert Help System — has been designed, implemented, and evaluated. We argue that the operability problems noted in users' interactions with this system are attributable to lack of a strong user model in the system interface. Such a model plays a critical role in determining the effectiveness of the system's ability to monitor the user's planning activities. We discuss the requirements of a strong user model and provide an example of how such a model might be integrated into a planner-based intelligent interface.
1986	A study in two-handed input	Two experiments were run to investigate two-handed input. The experimental tasks were representative of those found in CAD and office information systems. Experiment one involved the performance of a compound selection/positioning task. The two sub-tasks were performed by different hands using separate transducers. Without prompting, novice subjects adopted strategies that involved performing the two sub-tasks simultaneously. We interpret this as a demonstration that, in the appropriate context, users are capable of simultaneously providing continuous data from two hands without significant overhead. The results also show that the speed of performing the task was strongly correlated to the degree of parallelism employed. Experiment two involved the performance of a compound navigation/selection task. It compared a one-handed versus two-handed method for finding and selecting words in a document. The two-handed method significantly outperformed the commonly used one-handed method by a number of measures. Unlike experiment one, only two subjects adopted strategies that used both hands simultaneously. The benefits of the two-handed technique, therefore, are interpreted as being due to efficiency of hand motion. However, the two subjects who did use parallel strategies had the two fastest times of all subjects.
1986	Autocompletion in full text transaction entry: a method for humanized input	A method for interactive validation of transaction data with autocompletion is introduced and analyzed in a library information system for periodical publications. The system makes it possible to identify the periodicals by using the full title thus making a separate coding phase unnecessary. Only the characters that are needed to distinguish the title from other ones have to be typed. In our library this is in the average 4.3 characters. We have noticed that it is faster to use the auto-completion system compared with the use of short codes and a code catalogue. The auto-completion feature causes more errors at least for the novices because the work differs from normal typing. The errors are, however, very easy to correct with the assistance of the system.
1986	Medical cognitive graphics	Medical inference problems that seem too complex for intuitive solution can be made tractable if the problem information is presented in the form of a graphic display. The medical cognitive graphics approach to aiding complex problem solving conceives of a medical professional as a person trying to form a mental model of the patient's situation. Appropriate computer graphics make mental models easier to form and easier to explore. This paper develops the notion of medical cognitive graphics via two examples drawn from medical diagnosis and monitoring.
1986	How are windows used? Some notes on creating an empirically-based windowing benchmark task	Users of a windowing system were studied for the purpose of creating an empirically based windowing benchmark. Each filled out a paper questionnaire that sampled subjective opinions of windowing commands, and were observed for approximately 22 minutes while performing typical daily activities on the computer. Subjects were also asked to demonstrate a typical log-on procedure and were personally interviewed. Windowing command frequencies, and screen layout characteristics were collected and analyzed. The data revealed a relatively high use of a small number of commands that were primarily concerned with moving between windows. This study enabled the creation of a more accurate windowing benchmark task.
1986	A comparison of tiled and overlapping windows	It is widely believed that overlapping windows are preferable to tiled (non-overlapping) ones, but there is very little research to support that belief. An analysis of the basic characteristics of windowing regimes predicts that there are, in fact, situations where overlapping windows are inferior to tiled. An experiment to test this prediction verified that there are indeed tasks and users for which tiled windows yield faster performance. This result suggests a need for closer study of the principles underlying windowing regimes, so that designers have a better understanding of the tradeoffs involved in using them.
1986	A cognitive model of database querying: a tool for novice instruction	Two experiments examine the effects of incorporating user knowledge into the design of training materials for a database querying system. In Experiment 1 an informal cognitive model of a query language is derived from the verbal reports of expert users, and incorporated into existing documentation. Two groups of subjects were then asked to solve queries using either the revised or original manual. In Experiment 2 the cognitive model was formalized to explicitly describe the conceptual and procedural information that was incorporated into training materials. Three groups of subjects then received either a conceptual model, procedural model, or neither in addition to basic instructions, and then solved four sets of queries. The results show that whether or not a given type of information facilitates performance depends on the type of query, and whether the model is consistent with the operation of the query system.
1986	DOMAIN/DELPHI: retrieving documents online	DOMAIN/DELPHI is the retrieval component of Apollo's in-house, integrated publishing system. It retrieves and displays documentation in a networked workstation environment in which each workstation has access to a common database of user and systems documents. Users can find information by “browsing” through a table of contents or by an indexed search for all documents on a subject. DELPHI incorporates a graphical, menu-driven user interface and displays output with multiple fonts and line art.
1986	The effects of structured, multi-level documentation	The effects of general global documentation, detailed step-by-step documentation, and combined global and detailed documentation were examined for high, medium, and low experienced students. The 198 students in this study used a word-processing program to complete two problems during a two-hour session. Results from univariate and multivariate analyses indicated that both general time measures for reading documentation and completing problems as well as the student users' reactions to the documentation, the program, and the computer system were affected by either the type of documentation, the level of experience, or both of these factors.
1986	Socio-tech: what is it (and why should we care)?	At a time when more and different people are using more and different computer systems, there is growing awareness that if technology is to give companies the “competitive edge” they are seeking, it must be used to support business goals. This means that systems must work within the existing organization to improve and extend its functioning. This also means that the design of these systems must enhance the organization, not disrupt it. Yet technology is, by its very nature, a stimulus for change. The question then becomes: How can this intrinsically de-stabilizing technology be designed and implemented in a way which supports the organization, without destroying it? It is the purpose of this panel to explore this basic question. Sociotechnical systems theory is a method to deal with this dilemma. At its core is the assumption that to be successful, technology must be designed in tandem with the receiving organization. So-called socio-tech focuses on how the organization can use technology, in an attempt to establish a “best fit” between the technical and the social aspects of the workplace. This is in contrast both to “old style” systems design, which concentrates on technical aspects only and to the “traditional” Human Factors approach, which considers how to design for “typical” users and how they think and perceive. (Some people have dubbed this new approach “Macroergonomics” as a way of distinguishing it from this more traditional Human Factors approach.)
1986	Animated graphical interfaces using temporal constraints	Algorithm animation has an acknowledged and growing role in computer aided algorithm design, as well as in documentation and technology transfer, since the medium of interactive graphics is a broader, richer channel than text by which to communicate information. Since an animation constitutes the interface between a user and an algorithm, a kit that facilitates the construction of such has all the basic elements of a User Interface Management System. Constraint languages are useful in constructing such an interface construction kit, whereby consistency is maintained among the elements of a structure and among those of a view of that structure presented to the user. But constraints specify only static state in current implementations. To specify the evolution of structures and views by discrete time increments, as in animation, requires a extension to current constraint languages to allow expression of specifications of temporal behavior.
1986	Defining constraints graphically	A number of constraint-oriented, interactive graphical systems have been constructed. A typical problem in such systems is that, to define a new kind of constraint, the user must leave the graphical domain and write code in the underlying implementation language. This makes it difficult for less experienced users to add new kinds of constraints. As a step toward solving this problem, the system described here allows the graphical definition of constraints. An interface has been built in which a user can conveniently construct a new kind of object, annotating it with the relations that it must obey.
1986	Learning modes and subsequent use of computer-mediated communication systems	New users of four computer-mediated communication systems were asked to indicate which of a variety of learning modes they had used, including reading written manuals, using online automated help facilities, personal or group lessons from a human teacher, and trial-and-error learning. Despite often elaborate documentation and online help, the most frequent mode actually selected by users is trial and error learning. Rather than bemoaning the fact that users do not make proper use of written documentation, the implication for system implementation is that it should be designed to effectively encourage and support trial-and-error learning. An experimental intervention offering a guided learning activity supports this conclusion.
1986	Voice messaging enhancing the user interface design based on field performance	Computer-based voice messaging systems are used to send and receive confidential messages via touch-tone telephones. Auditory prompts guide users through a series of menus, listing options as users proceed through their sessions. This report describes how a voice messaging system was enhanced and redesigned based on thinking aloud protocols, customer site interviews, and usage statistics that described summary patterns of behavior. The goal of the human factors effort was to optimize system use. The evaluation of the length, wording and phrasing of auditory prompts as well as ease-of-accessibility provided by the menu structure led to specific enhancements and redesign. Feedback also helped define an audio HELP/OTHER OPTIONS system that (1) provided context sensitive assistance and (2) documented infrequently used options that enabled streamlining of routine transactions.
1986	Integrated software usage in the professional work environment: evidence from questionnaires and interviews	In a field study of use of integrated business software by business professionals, we found several characteristics of the real-world situation leading to the under-utilization of integrated software and being of importance for its human factors. Professionals work in a heterogeneous software environment filled with practical problems, they follow “satisficing” strategies of sub-optimal usage, and they have problems migrating to more advanced uses. Current levels of software integration do not always adequately or easily support the “task integration” requirements of real tasks such as handling many small things.
1986	Debugging by skilled and novice programmers	Two experiments investigated expert-novice differences in debugging computer programs. Debugging was done on programs provided to the subject, and were run on a microcomputer. The programs were in LOGO in Exp. 1 and Pascal in Exp. 2. Experts debugged more quickly and accurately, largely because they generated high quality hypotheses on the basis of less study of the code than novices. Further, novices frequently added bugs to the program during the course of trying to find the original one. At least for these simple programs, experts superior debugging performance seemed to be due primarily to their superior ability to comprehend the program.
1986	Does programming language affect the type of conceptual bugs in beginners' programs? A comparison of FPL and Pascal	The effect of the graphical programming language FPL (First Programming Language) on the occurrence of conceptual bugs in programs written by novices was studied. The type and location for each bug, and the frequency for each type were all recorded following procedures developed in an earlier Yale University study of novice Pascal programming. The findings were compared with those of the earlier study, and suggest that FPL may help beginning programmers avoid some common conceptual errors in their programming.
1986	Alternatives to construct-based programming misconceptions	In this paper, we investigate whether or not most novice programming bugs arise because students have misconceptions about the semantics of particular language constructs. Three high frequency bugs are examined in detail — one that clearly arises from a construct-based misconception, one that does not, and one that is less cut and dry. Based on our empirical study of 101 bug types from three programming problems, we will argue that most bugs are not due to misconceptions about the semantics of language constructs.
1986	Designing a quality voice: an analysis of listeners' reactions to synthetic voices	Eight subjects listened to a set of synthetic voices reflecting a crossing of four voice qualities: head size, pitch, richness and smoothness. The listeners evaluated the voices on sixteen perceptual scales, and judged each voice's appropriateness for twenty voice-output scenarios. Factor analysis of the perceptual ratings recovered two factors, fullness and clarity. A similar analysis of the appropriateness ratings revealed three situational factors, information, entertainment and feedback. Further analyses indicated that the voice qualities associated with the three situational factors were quite different, and suggest ways to optimize voices used for a particular purpose.
1986	Speech recognition enhancement by lip information	Though technology in speech recognition has progressed recently, Automatic Speech Recognition (ASR) is vulnerable to noise. Lip-information is thought to be useful for speech recognition in noisy situations, such as in a factory or in a car. This paper describes speech recognition enhancement by lip-information. Two types of usage are dealt with. One is the detection of start and stop of speech from lip-information. This is the simplest usage of lip-information. The other is lip-pattern recognition, and it is used for speech recognition together with sound information. The algorithms for both usages are proposed, and the experimental system shows they work well. The algorithms proposed here are composed of simple image-processing. Future progress in image-processing will make it possible to realize them in real-time.
1986	Comparison of elderly and younger users on keyboard and voice input computer-based composition tasks	An experiment was run in which elderly and younger people used a keyboard editor and a simulated listening typewriter to compose letters. Performance was measured and participants rated the systems used. Our general conclusions were as follows: There are no major differences in performance between elderly computer users and their younger counterparts in carrying out a computer-based composition task. Elders appear to be more enthusiastic users of computer systems than are younger people. This is shown by preference ratings, behavioral observations, and post-experimental debriefings. Voice input does not improve performance on composition tasks, but it is greatly preferred over the traditional keyboard input method.
1986	Rapid prototyping and system development: examination of an interface toolkit for voice and telephony applications	This paper discusses a set of tools supporting the rapid development of voice and telephony applications. The tools allow interfaces to be rapidly prototyped, tested and installed without impacting the underlying system. Used directly by behavioral specialists, they have played a key role in the building of two production systems. We review several essential features of this facility and then outline its role in the rapid development of a voice messaging system for the athletes and officials at the 1984 Summer Olympics in Los Angeles.
1986	The Trillium user interface design environment	Trillium is a computer-based environment for simulating and experimenting with interfaces for simple machines. For the past four years it has been use by Xerox designers for fast prototyping and testing of interfaces for copiers and printers. This paper defines the class of “functioning frame” interfaces which Trillium is used to design, discusses the major concerns that have driven the design of Trillium, and describes the Trillium mechanisms chosen to satisfy them.
1986	An interactive environment for dialogue development: its design, use and evaluation; or, is aide useful?	The Author's Interactive Dialogue Environment (AIDE) of the Dialogue Management System is an integrated set of direct manipulation tools used by a dialogue author to design and implement human-computer interfaces without writing source code. This paper presents the conceptual dialogue transaction model upon which AIDE is based, describes AIDE, and illustrates how a dialogue author develops an interface using AIDE. A preliminary empirical evaluation of the use of AIDE versus the use of a programming language to implement an interface shows very encouraging results.
1986	The elicitation of system knowledge by picture probes	A technique is described in which a user's knowledge of a software package is elicited by means of a series of photographs depicting the system in a variety of states. The resultant verbal protocols were codified and scored in relation to the way in which the system actually worked. In the illustrative study described, the probes were administered twice after 5 and 10 hrs of system experience with an office product (VisiOn*). The number of true claims elicited increased with experience but the number of false claims remained stable. The potential value of the technique and its output are discussed.
1986	User-derived impact analysis as a tool for usability engineering	A unified approach to improved usability can be identified in the works of Gilb (1981, 1984), Shackel (1984), Bennett (1984), Carroll and Rosson (1985), and Butler (1985). We term this approach “usability engineering,” and seek to contribute to it by showing, via a product development case study, how user-derived estimates of the impact of design activities on engineering goals may be made. 1
1986	On designing for usability: an application of four key principles	In a recent paper, Gould and Lewis (1983a) argued for the importance of four key principles in computer system design. These principles are: early focus on users, interactive design, empirical measurement, and iterative design. Gould and Lewis also express their belief that these principles are essential to successful design and refer to an example of their use (Gould and Lewis, 1983b). It is the purpose of this paper to report another example of how these principles played a major role and proved their worth in the design of a successful system.
1986	User modeling in UC, the UNIX consultant	UC is a natural language computer consultant system for the UNIX operating system. The user model in UC encodes the user's knowledge state and allows UC to tailor its responses to the user. The model encodes apriori knowledge in a double stereotype system that is extremely efficient. Models of individual users are updated dynamically and build on top of the user's stereotype. The model deals with uncertainty in apriori information and attempts to deduce the user's level during the course of a session.
1986	TNT: a talking tutor 'n' trainer for teaching use of interactive computer systems	Tutor 'N' Trainer (TNT) is an automated tutor for vi, the UNIX™ system screen editor. TNT fosters learning by doing. The Tutor component guides the student's practice with spoken instruction and feedback. The Trainer component assures safety during practice by permitting only previously taught and appropriate operations. Individualization and effectiveness are achieved in two ways: special helper keys enable slow learners to get extra help and repeat troublesome tasks; and practice loops force slow learners to practice tasks repeatedly until competency is achieved.
1986	Advising roles of a computer consultant	Several hours of advisory protocols from a consultant for Personal Computing were taped and analysed in terms of the role which the advisor played in the interaction. The advisor's role was determined by the user's initial approach and the advisor's perception of the needs of the user: informing the user about available information, defining terms or procedures, indexing into appropriate solution sources or methods for more complex problems or structuring a nebulous or poorly understood problem. A taxonomy of stages of information exchange is outlined and the patterns of alternation within each advisor role is described. We suggest implications of this study for the design of advisory systems.
1986	The enhancement of understanding through visual representations	It has been argued for a long time that the representation of a problem is of crucial importance to understanding and solving it. Equally accepted is the fact that the human visual system is a powerful system to be used in information processing tasks. However, there, exist few systems which try to take advantage of these insights. We have constructed a variety of system components which automatically generate graphical representations of complex structures. We are pursuing the long-range goal of constructing a software oscilloscope which makes the invisible visible. Our tools are used in a variety of contexts: in programming environments, in intelligent tutoring systems, and in human-computer interaction in general by offering aesthetically pleasing interfaces.
1986	Design principles for the enhanced presentation of computer program source text	In order to make computer programs more readable, understandable, appealing, memorable, and maintainable, the presentation of program source text needs to be enhanced over its conventional treatment. Towards this end, we present five basic design principles for enhanced program visualization and a framework for applying these principles to particular programming languages. The framework deals comprehensively with ten fundamental areas that are central to the structure of programming languages. We then use the principles and the framework to develop a novel design for the effective presentation of source text in the C programming language.
1986	Visual programming, programming by example, and program visualization: a taxonomy	There has been a great interest recently in systems that use graphics to aid in the programming, debugging, and understanding of computer programs. The terms “Visual Programming” and “Program Visualization” have been applied to these systems. Also, there has been a renewed interest in using examples to help alleviate the complexity of programming. This technique is called “Programming by Example.” This paper attempts to provide more meaning to these terms by giving precise definitions, and then uses these definitions to classify existing systems into a taxonomy. A number of common unsolved problems with most of these systems are also listed.
1986	Transfer between word processing systems	A study was conducted to examine knowledge transfer between word processing systems. The study examined the performance of naive subjects learning to use a word processing system, as well as performance of individuals with word processing experience as they learned to use a new system. Subjects initially familiar with one system carried out a series of tasks on this system and then were asked to carry out a similar series of tasks on a second system with which they were initially unfamiliar. The second systems varied in similarity to the first system along several dimensions. Subject performance was significantly slower on the second set of tasks for all groups compared to a control group using a single system. The reduced performance is attributed primarily to 'syntactic' differences in the user interfaces of the systems.
1986	Learning and transfer for text and graphics editing with a direct manipulation interface	For a Direct Manipulation interface, transfer of skill between text and graphics editing tasks has been investigated. A learning experiment has been carried out with two groups of novice users starting with a series of sessions in one task domain and then switching over to the other domain. The empirical results are discussed in the framework of the “cognitive complexity” theory of Polson and Kieras.
1986	A test of a common elements theory of transfer	All discussions of interface design criteria emphasize the importance of consistent operating procedures both within and across applications. This paper presents a model for positive transfer and thus a theoretical definition of consistency. An experiment manipulating training orders for utility tasks was designed to evaluate the transfer model. The experimental manipulations produced large transfer effects. Quantitative predictions were derived from the Kieras and Polson (1985) theory of human-computer interaction and the transfer model and fit using regression techniques. The transfer model accounted for 88\% of the variance of the 31 cell means.
1986	Classifying users: a hard look at some controversial issues	It has become a common recommendation to computer interface designers that they should “Know the User” (e.g., Rubinstein and Hersh, 1984). This panel discussion will examine the issues that arise from this advice.
1987	What kind of minimal instruction manual is the most effective	An empirical study examined the effectiveness of four different versions of a self-instruction manual for a word processing system: a Skeletal version that explicitly states only the essential information, an Inferential version that has the users infer some of the essential information, a Rehearsal version that is like the Skeletal manual, but adds opportunities to rehearse the explicitly stated information, and a Lengthy version that adds nonessential explanatory and descriptive information to the Skeletal version. The best learning performance was obtained with the inferential approach, particularly for more realistic tasks.
1987	Intelligent help in a one-shot dialog: a protocol study	A database of 150 interactions conducted via electronic mail was analyzed. The database had been constructed as an on-line tool for users and advisors, but the interactions can also be regarded as modelling intelligent help dialog in which posing a query and providing a response are each accomplished in “one-shot”. The types of questions users ask and the advisory strategies employed for imcomplete queries without follow-up questioning are described. The goal is to understand this new on-line tool for advising and its implications as a model of one-shot intelligent help dialogs.
1986	Learning a word processing system with training wheels and guided exploration	A Training Wheels interface creates a reduced functionality system intended to prevent new users from suffering the consequences of certain types of common errors when they exercise system functions and procedures. This has been shown to be an effective training system design for learning basic text editing functions [4]. We extend this result by examining the extent to which training wheels learners can transfer their skills to interaction with the full-function system. The experiment reported here indicates that training wheels subjects were better able to perform advanced full-system editing functions than subjects who were trained on the full system itself.
1986	Behavioral experiments on handmarkings	Handmarkings, e.g., handwritten proofeditors' marks, can be used as direct editing commands to an interactive computer system. Three exploratory experiments studied the potential value of handmarkings for editing text and pictures. Results showed that circles are the most frequently used scoping mark and arrows are the most frequently used operator and target indicators. Experimental comparisons showed that handmarkings have the potential to be faster than keyboards and mice for editing tasks. But their ultimate value will depend upon the style and details of their user interface implementation.
1987	An evaluation of an eye tracker as a device for computer input2	Since humans direct their visual attention by means of eye movements, a device which monitors eye movements should be a natural “pick” device for selecting objects visually present on a monitor. The results from an experimental investigation of an eye tracker as a computer input device are presented. Three different methods were used to select the object looked at; these were a button press, prolonged fixation or “dwell” and an on screen select button. The results show that an eye tracker can be used as a fast selection device providing that the target size is not too small. If the targets are small speed declines and errors increase rapidly.
1987	A hand gesture interface device	This paper reports on the development of a hand to machine interface device that provides real-time gesture, position and orientation information. The key element is a glove and the device as a whole incorporates a collection of technologies. Analog flex sensors on the glove measure finger bending. Hand position and orientation are measured either by ultrasonics, providing five degrees of freedom, or magnetic flux sensors, which provide six degrees of freedom. Piezoceramic benders provide the wearer of the glove with tactile feedback. These sensors are mounted on the light-weight glove and connected to the driving hardware via a small cable. Applications of the glove and its component technologies include its use in conjunction with a host computer which drives a real-time 3-dimensional model of the hand allowing the glove wearer to manipulate computer-generated objects as if they were real, interpretation of finger-spelling, evaluation of hand impairment in addition to providing an interface to a visual programming language.
1987	Developing computer animation packages (panel)	Specialized computer architectures can provide better price/performance for executing image processing and graphics applications than general purpose designs. Two processors are presented that use parallel SIMD data paths to support common graphics data structures as primitive operands in arithmetic expressions. A variant of the C language has been implemented to allow high level language coding of user applications on these processors. High level programming support is designed into the processor architecture that implements parallel object data typing and parallel conditional evaluation in hardware.
1987	Learning about hidden events in system interactions	Understanding how to use a computer system often requires knowledge of hidden events: things which happen as a result of user actions but which produce no immediate perceptible effect. How do users learn about these events? Will learners explain the mechanism in detail or only at the level at which they are able to use it? We extend Lewis' EXPL model of causal analysis, incorporating ideas from Miyake, Draper, and Dietterich, to give an account of learning about hidden events from examples. We present experimental evidence suggesting that violations of user expectations trigger a process in which hidden events are hypothesized and subsequently linked to user actions using schemata for general classes of situations which violate user expectations.
1987	Transfer of learning: beyond common elements	An experiment on transfer of learning using text editors revealed significant differences in performance, based on the learning experience of the subjects. The set of commands of a text editor was divided into four subsets. Different groups of subjects learned these subsets in different orders. Depending on the order of learning, subjects formed different concepts of the editor as manifest by their choice of commands, their errors, and their model of the editor, elicited by a sorting task. Pragmatic production model approaches to transfer would need significant enhancement to accommodate this result.
1987	Sophisticated image rendering in environmental design review	The Landscape Architecture Programme and the Computer Systems Research Institute at the University of Toronto undertook two studies using advanced rendering tools pioneered in the areas of computer animation and graphic art. Through two professional landscape architectural design studies we explored the potential role and impact of computer simulation in the initial, more creative phases of the design work. Advanced image rendering hardware and software were used to produce high quality computer drawings of design concepts. The techniques employed in this study are unique in their application to environmental design where they dramatically improve the designer's opportunities to simulate realistic images of proposed design alternatives and to consider the visual and spatial implications of such alternatives. The case studies represented in the paper were undertaken for the National Capital Commission in Ottawa, Canada. The first project is an urban design massing study called the “Parliamentary Precinct Study” and the second project is a detailed design of the “Ceremonial Routes” in Ottawa.
1986	The user interface and program structure of a graphical VLSI layout editor	In this paper the user interface and program organization of the SYMPLE VLSI symbolic layout editor is examined. The user interface is driven by a small interpreter that is constructed from a LISP-like language at run time and has access to a consistent library of menus and graphical information-gathering functions. To improve maintainability, the editor has been constructed in a modular form with well-defined interfaces.
1986	Specifying complex dialogs in ALGAE	The complexity and high development costs of user interfaces has led to research into the design of User Interface Management Systems (UIMSs). At the heart of a UIMS is a facility for specifying a dialog control component, which processes user actions and coordinates program responses. This paper describes a language called ALGAE, which allows the specification of multi-threaded, event driven dialogs.
1987	Modular implementation of presentations	The presentation of an application program specifies how the data and operations provided by an application are presented to users. Most traditional techniques for implementing presentations lead to unstructured, unmodular implementations that are hard to construct and change. We present a model of presentation that identifies the dependencies between the presentation and functionality portions of an application. Based on this model, we show how several implementation techniques can be used to construct presentations in a modular way.
1986	Event-response systems: a technique for specifying multi-threaded dialogues	Event-Response Systems are a technique for specifying the syntax of multi-threaded dialogues. They are based on the paradigm of specifying system responses to events generated by the user. They can compactly represent the concurrency needed to implement multi-threaded dialogues. This concurrency support also allows interfaces to be structured differently than is possible with existing dialogue specification systems based on state transition specifications or grammars. This flexibility allows many interfaces, especially direct manipulation interfaces, to be specified with a more modular structure than most existing systems allow. Event-Response Systems are described formally, and a dialogue specification language based on the ERS formalism is informally presented. Some example uses and implementation techniques are also described.
1987	Towards a model of user perception of computer systems response time	The foundational structure of a new model of user perception of computer system response time is proposed. It is suggested that the development of such a model is now of central importance to the computer system configuration design effort. The new model is seen to explain the success of an earlier measure, designed for the non-interactive environment, in predicting user estimates of response time for interactive systems. The results of new empirical studies, designed to delineate specific components of the model, are also discussed.
1987	A comparison of rule-based and positionally constant arrangements of computer menu items	An experiment was conducted to evaluate user performance under four different menu item arrangements: alphabetic, probability of selection (most popular choices are positioned near the beginning of the list), random, and positionally constant (consistent assignment of individual items to screen positions). During the initial stages of practice, the rule-based approaches produced faster mean search times, but after moderate amounts of practice, the positionally constant arrangement appeared to be most efficient. People seem to remember quite easily the location of items on a display, indicating that positional constancy can be an important factor in increasing the efficiency of the search of computer menus and other displays.
1986	Comparing a form-based and a language-based user interface for instructing a mail program	In the domain of interaction languages, forms have been found to be of value in allowing users, especially non-programmers, to specify objects and operations with a minimum of training, time, and errors. Most of that research, however, has been on the use of data base query languages. The present research found that in a procedural task of specifying mail filtering instructions, non-programmers using a form were as fast as programmers using a procedural language, although programmers using the form were faster still.
1987	Intelligence in interfaces (panel)	The purpose of this symposium is three-fold: First, by presenting a selection of our work as examples, we seek to define a model of intelligent interaction and illustrate points in the interface process where artificial intelligence can play a role. Second, by comparing the approaches represented in our efforts, we intend to explore a fundamental philosophical difference in the field of intelligent interfaces: the distinction between the power tools vs. the intelligent assistant paradigms. (As part of this discussion, we intend to consider how to mine the rich ground that lies between these two extremes.) Third, by examining the design process underlying our examples, we seek to provide a better understanding of the relationship between AI interface tools and the applications that they communicate with.
1986	Creating dynamic interaction techniques by demonstration	When creating highly-interactive, Direct Manipulation interfaces, one of the most difficult design and implementation tasks is handling the mouse and other input devices. Peridot, a new User Interface Management System, addresses this problem by allowing the user interface designer to demonstrate how the input devices should be handled by giving an example of the interface in action. The designer uses sample values for parameters, and the system automatically infers the general operation and creates the code. After an interaction is specified, it can immediately be executed and edited. This promotes extremely rapid prototyping since it is very easy to design, implement and modify mouse-based interfaces. Peridot also supports additional input devices such as touch tablets, as well as multiple input devices operating in parallel (such as one in each hand) in a natural, easy to specify manner. This is implemented using active values , which are like variables except that the objects that depend on active values are updated immediately whenever they change. Active values are a straightforward and efficient mechanism for implementing dynamic interactions.
1986	Panther: a specification system for graphical controls	An experimental graphical control specification system, called Panther, has been written in C for UNIX®-based applications. Unlike similar systems, which focus on combining interaction techniques, Panther allows the specification of low-level interactions by invoking user-selectable subroutines for input-device transitions. A Panther interface is specified in a textual table as a set of hierarchically nested regions . Regions can model any control device, such as menu buttons, slider-bars, switches, alphanumeric displays, or even combinations of other regions. Panther does not rely on special hardware, extensive software, or interprocess communication.
1986	A control panel interface for graphics and image processing applications	This paper describes a graphical interface for application programs. The interface is based on the notion of a control panel . A control panel contains a browsable list of an application's parameters and a set of functions to control the application's execution. A variety of graphical knobs and gauges may be associated with any or all of the parameters to permit fine-grain execution control, including animation of an application's output. The control panel interface is integrated into the framework of an interactive programming environment for graphics and image processing applications. This integration is an important feature of the overall interface design.
1987	The use of scenarios in human-computer interaction research: turbocharging the tortoise of cumulative science	A scenario is an idealised but detailed description of a specific instance of human-computer interaction (HCI). A set of scenarios can be used as a “filter bank” to weed out theories whose scope is too narrow for them to apply to many real HCI situations. By helping redress the balance between generality and accuracy in theories derived from cognitive psychology, this use of scenarios (1) allows the researcher to build on empirical findings already established while avoiding the tar-pits associated with the experimental methodology, (2) enables the researcher to consider a range of phenomena in a single study, thereby directly addressing the question of the scope of the theory, and (3) ensures that the resulting theory will be applicable in HCI contexts.
1986	Structural analysis of verbal data	Current methods of analyzing verbal reports (Protocol Analysis) from human-computer interactions fall short of their potential. Although there are systematic methods for collecting complete and objective verbal reports applicable to a broad range of problem-solving tasks, currently available analyses of verbal reports are ad hoc and apply only to well constrained tasks. Structural Analysis is a systematic method, currently under development, for analyzing real-world tasks involving human-computer interaction. Starting with a rule that assigns utterances to two dichotomous categories related to a behavior of interest, rules are generated that expose the goal building and evaluation underlying that behavior. The resulting data yield time distributions that characterize subjects' goal-directed behavior and that allow comparisons among tasks or among subjects.
1986	Evaluating user and system models: applying scaling techniques to problems in human-computer interaction	A user's mental model of a system should be an important determinant of performance and as well as a means of understanding why particular user errors occur. In particular, experienced users' models should be in closer agreement with the system than less experienced users' models, and deviations of expert models from the system should correspond to difficulties in performance and suggest ways that system usability could be improved. The present study explored the utility of scaling techniques for defining and comparing user and system models. The results support the assertion that with experience users' mental models approach the system model. However, even experienced users had significant deviations from the system model, leading to predictions of where experts would have difficulty using the system and suggestions for improving usability.
1987	Whiter (or wither) UIMS?	The subject of User Interface Management Systems (UIMS) has been a topic of research and debate for the last several years. The goal of such systems has been to automate the production of user interface software. The problem of building quality user interfaces within available resources is a very important one as the demand for new interactive programs grows. Prototype UIMSs have been built and some software packages are presently being marketed as such. Many papers have been published on the topic. There still, however, remain a number of unanswered questions. Is a UIMS an effective tool for building high quality user interfaces or is the run-time cost of abstracting out the user interface too high? Why are there not more UIMSs available and why are they not more frequently used? Is simple programmer productivity alone sufficient motivation for learning and adopting yet another programming tool? What is the difference, if any, between a “user interface toolbox”, a windowing system and a UIMS? What are the differences between a UIMS and the screen and editor generators found in fourth generation languages? In fact, exactly what is a UIMS? In order to discuss these questions and to reassess the state of the UIMS art, SIGGRAPH sponsored a workshop on these issues (proceedings will be published in Computer Graphics in 1987). The panelists represent four subgroups who have each addressed these problems from different points of view.
1987	Evolution of an organizational interface: the new business department at a large insurance firm	This paper describes how the work organization and computer system of the New Business Department at a large life insurance firm have interacted and evolved over time. The dynamics of interaction are explained largely in terms of the economic incentive to reduce the length of transaction processing chains and the more political goal of extending managerial control. It is argued that examining the interaction of organizations and computer systems Can contribute to a better theoretical understanding of the development of large computer systems and offer guidance to designers of user-computer interfaces. A graphical technique for depicting organizational interfaces is presented.
1987	Social and psychological factors influencing the design of office communications systems	Office automation is used by groups of people with complex communication needs to help them reach business goals such as scheduling, tracking, reviewing, and delegating. Effective individual and group decisions are heavily dependent on communication protocols and social conventions. Because these conventions are so ingrained, they are sometimes not readily available to conscious inspection during the design of communication systems. Even more problematic, system designers may not have first hand knowledge of the conventions and protocol for the range of environments in which their systems will be used. Nevertheless, office systems must work in tandem with these conventions. Wang Laboratories has a continuing program of research directed at identifying the psychological and social factors that come into play during the adoption and use of computer communication systems and the implications of these factors for the design of those systems. Highlights of a three year program of research are presented covering implications for voice mail, electronic mail, and electronic calendars.
1986	The social dimensions of computerization	While industrialized countries have been rapidly computerizing, the ultimate forms of computerization and their social consequences are still somewhat open-ended. The general directions of equipment developments have been relatively clear - toward computer-based systems which run on faster, smaller, and cheaper hardware; toward equipment architectures which distribute computing (and work); and software which is generally more flexible and more likely to support graceful interactions between person and machine. Computerization is more than placing computing equipment in offices, homes, boats, planes, automobiles, or shopping areas. Computerization refers to the social practices through which computer-based systems and services are made available to various groups, arrangements for training people in the variety of skills they need to use systems effectively, practices that alter accountability, changes in patterns of control, etc. Computerization is a combination of technical, social and political processes [12]. Computerization touches the lives of millions of people in many key spheres of work, education, commerce, dealing with public agencies, etc. It is tempting to find some simple formula to summarize the consequences of computerization for people, groups, and the larger social order. Simple capsule formulas which concisely summarize a meaning for computerization tend to be deterministic and grossly oversimplified [11]. Our most reliable knowledge about the specific social consequences of computerization comes from careful field studies of specific computer-based systems in specific social settings [10]. There are a myriad of systems and settings and varied computerization practices employed throughout the industrialized nations. Moreover, analysts bring their own differing theoretical assumptions to their studies [6, 10, 22]. Consequently, the findings of research studies sometimes appear inconsistent [1, 10, 19, 21]. There are serious debates about whether computerization will naturally lead to better or worse jobs [4, 7, 8, 17, 23, 24], lead people to make better or worse decisions [20], lead work groups to be more or less flexible [17], reinforce or redistribute patterns of social power [3], make bureacracies less accountable to the public [2], etc. Much of the popular and professional discourse about the consequences and conditions of computer use is relatively deterministic. Deterministic stories can be optimistic [5] or pessimistic [7, 23]. During the last decade scholars have begun to develop some interesting explanatory models to help understand how computerization &ldquoworks” as a social and technical process. Research on the social impacts of computing indicates that few “deterministic” consequences of introducing computer-based systems into social settings such as organizations [12, 18, 20, 25]. Under different conditions and different computerization strategies, jobs may become more or less skilled; work groups may gain or lose flexibility; decisions may be “better” or more confused; power may shift to or from central administrators, etc. Changes such as these depend upon both social and technical contingencies, such as: the kinds of systems introduced, who controls them, the kind of infrastructure devoted to their support, etc [17]. Computer-based systems which can be perfectable under static laboratory conditions and when supported by a rich array of resources may be very problematic when introduced into dynamic social settings, settings rife with social conflict, or when computerization strategies limit support resources. Contextual characteristics, such as these, are a powerful influence on the kinds of computer-based systems adopted, the ways they are organized, and their consequences for people and groups. As a consequence, the simple development of “good technologies” is not sufficient to insure that social life will be improved for many participants. This talk will examine some organizing ideas to help understand how computerization strategies and their outcomes depend upon the social contexts in which people sad groups enact them by introducing web models [14,18]. Web models examine the social context in which a computer-based system is adopted, developed, or used; they view the infrastructure for supporting a computer-based system as an integral element of its operational form; and they situate the computing developments being studies in light of the history of related computing developments and related social practices within key social settings. The examples for this talk will be drawn primarily from the computerization of workplaces. Web models help explain 1) the social leverage provided by computing arrangements; 2) the co-requisites for smoothly operating systems; and 3) the ways in which the social settings in which computing arrangements are developed and used shape their configurations and consequences. We contrast web models with conventionally rational “discrete-entity” models which are a-contextual, a-historical, and assume that adequate infrastructure can always be available as needed. Predictions of computing development sad use based on discrete-entity models usually underestimate the problems of implementation and underestimate the extent to which computer-based systems play important roles other than as direct aids in leveraging information processing capabilities in a work organization. Web models shed greater light on socially and technically complex, embedded computing developments than do discrete-entity models. At best, discrete-entity models account for some of the potential (dis)advantages provided by a new technology or organizational arrangements. Since they are context-free, discrete-entity models can be used to describe the results of many simple experiments. In discrete-entity analyses, all things being equal is the rule, while the social setting of technical development and use is largely ignored. That neglect is usually untenable when the organizational setting or the technology itself is complex. Even simple technologies may be compromised by complex, demanding settings [13]. Web models draw “large” social boundaries around a focal computing resource so that the defining situation includes: the ecology of participants who influence the adoption and use of computer-based technologies, the infrastructures for supporting system development and use, and the history of local computing developments [3, 8, 13, 16]. The social boundaries for a given computing resource can extend far beyond the work places where it is developed and used. Useful social boundaries contain work groups laced throughout a given organization and through other organizations on which the focal organization depends for resources such as staff, equipment, income, and legitimacy. These boundaries are often ir- regular in that they often do not conform to the formal boundaries of organizations and their subunits. They can also be idiosyncratic in that they differ from one organizational setting to another, even when the same technologies are in use. Within these social boundaries, web models link computing developments to routine organizational activities and critical negotiations. Web models help explain the actual leverage of computing developments, their carrying costs, and the ways that systems are valued by different participants. Computer-based systems increasingly extend beyond the narrow boundaries of a work group or small scale organizational unit and are increasingly an element in more complex social relations. Consequently, discrete-entity models are becoming less relevant as a basis for guiding research on the social dimensions of computerization. Web models of computing appear especially appropriate when 1) the production or support of computer-based systems is socially complex or 2) their adoption or operation depends upon social relations that extend far beyond the behavioral setting in which the technology is developed or used. Web models examine the social simplicity/complexity of computing arrangements, not just their technical simplicity/complexity. As computer-based systems become more socially complex, web models will become increasingly critical as approaches for explaining the development and use of computing.
1986	A case example of human factors in product definition: needs finding for a voice output workstation for the blind	Human factors efforts can contribute to product design at every design phase from conception through evaluation of a product in the field. Early human factors involvement has certain advantages. The major advantage is that it can have greater “leverage” by influencing more far-reaching aspects of a product. Input at later design phases, on the other hand, may delay product schedules or require a major re-design effort. Input at earlier stages can diminish these problems. As a case example, a needs finding study for a voice output workstation for the blind is described. Users of these workstations participated in a semi-structured interview to determine their needs. Results identified specific features needed. The findings also indicated that the original scope of the project, word processing, should be broadened to include other applications.
1987	Towards universality of access: interfacing physically disabled students to the Icon educational microcomputer	A micro-processor based Interface Unit and Teacher Utility have been developed at the Hugh MacMillan Medical Centre that will facilitate physically disabled users' access to the Icon educational microcomputer. The Interface Unit allows a variety of alternate input devices to be used with the Icon computer. Evaluations of the use of the Icon by physically disabled students without and with the Interface Unit were completed. The Teacher Utility offers on-line instruction and support for teachers with physically disabled students who have problems accessing the Icon. The design of the Teacher Utility is presented from three perspectives: the teacher, the physically disabled student, and the developers.
1986	A user interface for deaf-blind people (preliminary report)	A user interface suitable for deaf-blind users is presented and justified. The interface is designed for small paperless Braille displays, large font visual displays, or other low-bandwidth displays. Some of the key properties of the interface are that it uses a hierarchical approach to structure both commands and data, has a small universal command set, and has pervasive editing capability. DBNet, a system employing the user interface, has been built and tested with deaf-blind users. DBNet will provide various communication services to the deaf-blind community including electronic news, mail, and bulletin boards.
1987	Interface design: a neglected issue in educational software	The user interface is particularly important for educational software because 1) it must provide an entry to the content domain of the program rather than vice versa and 2) it must be sensitive to the general skill and/or developmental level of the user. In spite of these special characteristics, interface design for educational software has been given little attention. This study evaluates a representative interface from arithmetic software now used in the schools. It was found that the interface caused students a large number of difficulties. These difficulties were sufficient to interfere with the instructional effectiveness of the software. Designing interfaces that will benefit educational software will require careful study of the users of these programs along with an in-depth understanding of the domains being taught.
1987	Cognition-sensitive design and user modeling for syntax-directed editors	Syntax-directed editors were created with the intent of aiding in and improving the programming process. Despite their potential, they have not been successful, as evidenced by limited use. In general, they are perceived as being too difficult to use and the benefits of their use are outweighed by the difficulties. We believe that the cognitive styles and skills of the users have been ignored in the design process. In this paper we present some of our initial results which show that cognitive styles vary over a significant spectrum and that their consideration in the design of a syntax-directed editor will result in an intelligent tool that will be right for the cognitive skills and expertise of an individual user. In turn, an approach to design that takes cognitive variation into account would support the construction of syntax-directed editors which are successfully used.
1986	A self-regulating adaptive system	The viability of providing adaptive user interfaces has been demonstrated ([3], [5]). Such systems identify differences between users in order to provide purposeful change at the user interface. Thus, adaptive systems have objectives, as indicated by the term 'purposeful.' The research reported here takes an important step forward by demonstrating that adaptive systems can be built that regulate their own behaviour by assessing whether their adaptations are being successful in meeting these objectives.
1986	The definition, editing, and contouring of surfaces for the analysis of field problems	This paper reports on an interactive system for manipulating a tensor-product B-spline approximation to field data for applications in which contours are of interest. The features of the system are: an interpolation technique for approximating fields defined from scattered or gridded data by tensor-product B-splines, an interactive display providing control-vertex manipulation of the resulting B-spline approximation, and a contouring algorithm that is designed specifically for B-spline surfaces.
1986	From contours to surfaces: testbed and initial results	This paper is concerned with the problem of reconstructing the surface of three-dimensional objects, given a collection of planar contours representing cross-sections through the objects. This is an important problem, with applications in clinical medicine, bio-medical research and instruction, and industrial inspection. Current solutions to this problem have raised interesting theoretical questions about search techniques and the exploitation of domain-specific aspects of such search problems. In this paper, we survey known reconstruction techniques, describe a testbed for evaluating these techniques and present an improvement on the simple divide-and-conquer method analyzed by Fuchs, Kedem and Uselton [5].
1987	Social science and system design: interdisciplinary collaborations	Contributions from the behavioral sciences to the design of computer systems have come primarily from psychology, and have focused on individual cognition. In this symposium, we consider the applicability to system design of approaches that focus on social interaction. The participants comprise pairs of researchers engaged in projects that aim to bring together systematic studies of naturally occurring human activities with the design of computer-based technology. Each of the projects emphasizes the importance of the social organization of communities, everyday communication and practice. The symposium participants — anthropologists, linguists and computer scientists — bring interdisciplinary perspectives to bear on the problem of how to design tools that incorporate the right mix of support for current work practices, solutions to recognized problems, and innovations in the way that work gets done. The aim of the symposium is to explore the possibilities for a productive relationship between research on socially organized human activities and system design. In this forum we will examine the problems that such interdisciplinary efforts face and the payoffs that they produce. Drawing on experience with their respective research projects, the participants will address the following questions concerning the development of a design process grounded in empirical studies: what is the relevance of activity studies to the design of new technology? What people do in everyday work settings is an obvious subject matter for social science, but just what is the relationship between that subject matter and system design? What part should an understanding of what people do now, with existing technological resources, play in the design of new technologies? How has new technology changed the nature of everyday work activities? The technological resources available in the domain of intellectual work, for example, are continually changing. Given this moving technological base, new forms of interaction between people emerge. What are the implications of those new forms, made possible by system design, for social science research? What social theory and methods do you draw on in your studies of work practice? What are the difficult theoretical or methodological problems, and what are the consequences of looking at everyday activities with the aim of designing new technology? What is the motivation behind your system design effort? That is, what problem in the domain of interest is your design intended to address? How has your design approach been affected by your empirical research? How has working with your collaborator changed your view of the problem domain? What has been most difficult about your collaboration and what has been most valuable? How have you negotiated differences in technical background, methods, conceptualization of the problem domain? To ground the discussion, participants will offer examples from their ongoing research projects. Brief descriptions of those projects are included here, but the symposium is intended as a lively debate of the questions posed, not as a presentation of findings. We hope through our discussion and through the participation of the symposium audience to shed light on the issues, while encouraging the development of new collaborations between social and computer scientists.
1986	Positioning human factors in the user interface development chain	Human factors professionals are not completely free to support the optimization of user interface design within the time span of individual software development projects. Interface design is constrained by conservative forces, such as the expectations of users of existing systems in the installed base and emerging de facto or formal standards. At the same time, human factors involvement with a particular product may ultimately have its greatest impact on future product releases. In this paper we explore an expanded time line for influencing product design. This time line brings middle- and upper-management concerns into focus, revealing critical opportunities for effectively positioning and applying human factors resources.
1987	The interface is often not the problem	Computer systems in the form of tools for specific functions within a work environment are becoming increasingly common. Because the users are not computer experts, and because the introduction of the new tools can dramatically change their tasks, problems arise. It is argued that even if the proper design of the MMI is very important, this will not solve all the problems. More basic problems concern what functions should be included in the system and how the users can understand what the system can do in different work situations and how the response should be evaluated in the context of the work situations. This is demonstrated by experiences from application projects. It is concluded that more research must be devoted to these problem areas. Another important result is the fact that the possibilities to develop more generally applicable computer based tools are limited. Adaption to local circumstances and needs is usually a necessity.
1986	Designing for designers: an analysis of design practice in the real world	Twenty-two designers were interviewed about their design of interactive systems. They were asked to select a recent project having a significant user interface component, and were probed about the general design process involved, how the design of the user interface fit into that process, and their personal strategies for exploring ideas. Analysis of their responses pointed to two models of the design process. The relationship of these models to the type of user testing done and the strategies used for generating ideas is discussed, especially with respect to the implications for developing tools to support design.
1987	Automated lip-synch and speech synthesis for character animation	An automated method of synchronizing facial animation to recorded speech is described. In this method, a common speech synthesis method (linear prediction) is adapted to provide simple and accurate phoneme recognition. The recognized phonemes are then associated with mouth positions to provide keyframes for computer animation of speech using a parametric model of the human face. The linear prediction software, once implemented, can also be used for speech resynthesis. The synthesis retains intelligibility and natural speech rhythm while achieving a “synthetic realism” consistent with computer animation. Speech synthesis also enables certain useful manipulations for the purpose of computer character animation.
1987	Story driven animation	An animation system has been developed which generates animations from stories written in natural language. The system consists of three modules: story understanding module, stage directing module and action generating module. The story understanding module extracts actions that are not explicitly described in the story and makes a scenario. The stage directing module adapts the scenario by determining the actors' positions on the stage and setting the stage. Actors are defined as 3-Dimensional articulated figures. Each component of an actor has its primitive motion method. To achieve complicated actions, primitive motions are combined. Referring to these complicated actions, the action generating module produces animated sequences from the adapted scenario. These three modules are tightly coupled with their knowledge bases. As an example, the story of the “Hare and Tortoise” from Aesop's Fables, written for elementary schoolchildren is used. This example proves that it is possible to produce computer animation directly from the story written in natural language, now in Japanese.
1987	Issues limiting the acceptance of user interfaces using gesture input and handwriting character recognition (panel)	Recently there has been increasing attention to character recognition/graphical user interfaces under the name of “gesture input”. This technique actually has a long history: “sketch recognition” interfaces of 15 or more years ago were highly praised [Applicon 73], and user interfaces using handwriting input before the wide use of text keyboards were one of the first research goals in computer science [Bledsoe 59]. The underlying character and symbol recognition technologies have been a major research area in their own right since the early 1950s [Suen 80]. The last two years have seen an upsurge in the number of developments in this area, both from commercial companies attempting to exploit new character and symbol recognition technologies, [CIC 85] [Pencept 84] [Cooper 82] and from researchers starting from fundamental questions in user interactions [Buxton 86] [Wolf 86]. However, one question still remains: “Why has this set of techniques had so little impact on user interface design practice, despite its long history and promise?” This panel discussion should give many answers to this question. Panelists include the leading commercial developers of handwriting input products, well-known researchers in the psychological aspects of graphical user interactions, and representatives of the research community for character recognition. The issue of supporting this type of interface is very timely: recent standardization efforts such as PHIGS and GKS for graphics interactions are known to have the unfortunate side effects of excluding some of the current user interface designs using this class of technology [10].
1987	Designing optimum CRT text blinking video image presentation	A reference scale has been established to assist in the determination of optimum text blinking times for portions of video image texts being presented on CRT display systems. Optimum text blinking time herein is considered to be that time which most effectively catches and holds viewer attention and quickens his understanding of message import. Three experiments involving questions of the psychology of blinking time were conducted. The first experiment examined subjects' preconceived notions of optimum blinking time, i.e. what they imagined, within their own minds, such times would be for specific text portions. The second experiment determined the gap between those preconceived notions and the subjects' changed concepts of optimum blinking times, based on their experience of visual trials. The third experiment applied a scale of blinking times, based on the experience gained in the second experiment, to a new set of subjects in order to further refine our understanding of optimum intervals. For the portions of text used here, optimum blinking times centered about 1.0 second. Moreover, through an adaptation to the video image presentation system, the effectiveness of the optimum text blinking times and the psychological scale was confirmed.
1987	Why reading was slower from CRT displays than from paper	Experiments, including our own (Gould et al., 1982; 1984; 1986), have shown that people read more slowly from CRT displays than from paper. Here we summarize results from a few of our fifteen experiments that have led us to conclude that the explanation centers on the image quality of the CRT characters. Reading speeds equivalent to those on paper were found when the CRT displays contained character fonts that resembled those on paper (rather than dot matrix fonts, for example), had a polarity of dark characters on a light background, were anti-aliased (e.g., contained grey level), and were shown on displays with relatively high resolution (e.g., 1000 x 800). Each of these variables probably contributes something to the improvement, but the trade-offs have not been determined. Other general explanations for the reading speed difference that can be excluded include some inherent defect in CRT technology itself or personal variables such as age, experience, or familiarity at reading from CRT displays.
1987	On the parameters of human visual performance: an investigation of the benefits of antialiasing	A two-part experiment was conducted to investigate the effects of aliasing artifacts and screen resolution on a simple visual recognition task. The results indicate that in many cases far less realism may be necessary in synthetic computer-generated imagery than is often assumed in the literature. The first part of the experiment comprised a subjective rating of image quality, the second part measured task effectiveness of image quality. In the second part subjects were asked to discriminate between images of two types of objects built from cubes, similar to objects used in experiments involving mental rotation. At higher resolutions the elimination of aliasing artifacts did not significantly improve subjects' performance. At intermediate and low resolutions, comparable to what might be used for iconic menus, the reduction in aliasing artifacts resulted in improved performance. The subjective ratings indicate that for both high and low resolution the elimination of aliasing artifacts does not improve “quality,” whereas images rendered at intermediate resolutions are significantly degraded by aliasing artifacts to the extent that antialiasing improves the subjective rating. An interpretation of these results is given in the context of an ongoing research program aimed at identifying the parameters of real-time human performance for graphics workstations.
1987	Approximate modelling of cognitive activity: towards an expert system design aid	Constructs from theoretical psychology can be used to decompose the representational and processing resources of cognition. The decomposition supports “cognitive task analysis” through which user performance can be related to the functioning of resources. Such functional relationships have been formalised and embodied in an expert system. This builds approximate models which describe cognitive activity associated with the execution of dialogue tasks. Attributes of these “cognitive task models” can be used to predict likely properties of user performance.
1987	Transfer between text editors	This paper describes a successful test of a quantitative model that accounts for large positive transfer effects between similar screen editors, between different line editors and from line editors to a screen editor, and between text and graphic editors. The model is tested in an experiment using two very similar full-screen text-editors differing only in the structure of their editing commands, verb-noun vs noun-verb. Quantitative predictions for training time were derived from a production system model based on the Polson and Kieras (1985) model of text editing.
1987	Predicting the time to recall computer command abbreviations	A GOMS theory of stimulus-response compatibility is shown to predict response-time performance on a command/abbreviation encoding task. Working with parameters that were set by an earlier study and which have rational, task-meaningful interpretations as mapping, motor, perception and retrieval operators, zero-parameter predictions were made that fit the observed performance with r 2 = 0.776 (p<0.05). The reasonableness of the parameters, the algorithms used to generate the predictions, and the weighting assumption used to combine algorithms into a single prediction are discussed.
1987	Voice: technology searching for communication needs	Voice technology is just beginning to gain a foothold in the information processing world. Applications such as voice mail, credit verification, order entry and airline reservation systems are slowly being introduced. Critics of voice systems frequently point out their limitations with little understanding of their power or advantages. One key determinant of the success or failure of voice systems is the USER INTERFACE. It is important that the dialogue structure, prompts, system feedback and error messages be designed based on user input, testing and evaluation. Another key determinant of the success of voice systems is the careful matching of users, tasks and environment to the technology. Voice technology is often broken down into 3 major categories. Speech compression. Processing allows analog patterns of human speech to be digitized. Once stored in digital form, the information can be transmitted and played back. Common Applications: Voice Mail, Voice Annotation. Text-to-Speech. Processing allows computer-stored text to be translated and retrieved via a “synthesized” voice. Common applications: Remote retrieval of information (E-Mail, Calendar Appointments), Aids to Visually or Vocally Handicapped. Speech Recognition. Processing allows analog patterns of human speech to be translated into their text-based equivalent or into computer commands. Common Applications: Data Entry, Voice Activated Typewriter.
1987	Notecards in a nutshell	NoteCards is an extensible environment designed to help people formulate, structure, compare, and manage ideas. NoteCards provides the user with a “semantic network” of electronic notecards interconnected by typed links. The system provides tools to organize, manage, and display the structure of the network, as well as a set of methods and protocols for creating programs to manipulate the information in the network. NoteCards is currently being used by more than 50 people engaged in idea processing tasks ranging from writing research papers through designing parts for photocopiers. In this paper we briefly describe NoteCards and the conceptualization of idea processing tasks that underlies its design. We then describe the NoteCards user community and several prototypical NoteCards applications. Finally, we discuss what we have learned about the system's strengths and weaknesses from our observations of the NoteCards user community.
1987	A multiple, virtual-workspace interface to support user task switching	An interface is presented that is designed to help users switch among tasks on which they are concurrently working. Nine desirable properties for such an interface are derived. It is argued that a key constraint to building interfaces that support task switching is that low user-overhead switching among tasks requires a large amount of display space, whereas actual display space is limited. A virtual workspace design is presented that greatly speeds the inevitable task-switching induced window faulting. The resulting interface is presented as a study in theory-based human-interface design. It is shown how in this case theory is important in inspiring a design, but design entailments outside the theory raise new issues that must be faced to make the design viable. These design experiences, in turn, help inspire new theory.
1987	Experiences with the alternate reality kit: an example of the tension between literalism and magic	This paper presents an overview of the Alternate Reality Kit (ARK), an animated environment for creating interactive simulations. ARK is built upon a physical-world metaphor: all objects have an image, a position, a velocity, and can experience forces. Users manipulate objects with a mouse-operated “hand” which enables them to carry and throw objects, to press buttons, and to operate sliders. The interface features are discussed in light of a general user interface tension between literalism and magic . Literal features are defined to be those that are true to the interface's metaphor. Literal features enhance an interface's learnability. Magical features are defined to be those capabilities that deliberately violate the metaphor in order to provide enhanced functionality. Discussion of each ARK feature includes informal observations of early ARK users, an assessment of the feature's learnability, of its usefulness, and of its position on the magical-literal axis. Even though ARK includes magical features, applications-level users have be trained in a few minutes. Although this paper is about ARK, the tension between literalism and magic raises some interesting questions on its own. Some of these questions are presented briefly in the conclusion.
1988	SAUCI: a knowledge-based interface architecture	Most current approaches to the design of the human-computer interface result in systems that are difficult for users to master. This can be attributed to the absence of several key features, including: interface modularity; adaptability to the individual user; direct support of user intentions; and an intelligent advising capability. An architecture for the interface which facilitates the attainment of these four criteria is proposed. The architecture relies upon production system rules and various kinds of knowledge bases to tailor the user-computer dialogue to the ongoing context of the interaction. A prototype of this architecture has been implemented in LOOPS for interfacing to the UNIX system, and has been shown to enhance substantially the performance of novice users of the system.
1988	Task-oriented parsing - a diagnostic method to be used adaptive systems	In order to be able to show context-dependent responses to the user's actual needs, adaptive systems have to be provided with models of possible task contexts. Existing methods for the representation of tasks in HCI are insufficient for this purpose as they do not support task-oriented parsing (i.e. analysing the input stream in terms of higher level task units). This paper presents a Prolog implementation of a task-oriented parser (+ generator) based on a grammar notation called LEXITAS. As an application, an online coach for a UNIX-like file management system is described. Further applications, such as automated macro detection from given interaction protocols, are discussed.
1988	Plan-based representations of pascal and fortran code	The first step in program modification is comprehension. Several researchers argue that programmers utilize plan-based representations when composing or comprehending code. In this study we tested the psychological validity of this proposal and examined the nature of plan-based program representations. Experienced programmers were asked to segment code and sort programs. The segmenting data showed that programmers agree on the major components of a program and that these components are defined by goals in a plan representation. Pascal and FORTRAN programs that employ the same plan structure were segmented into similar components. Program sorting data also showed clustering into plan groups. However task related dimensions are also important parts of program representations.
1988	Providing the requisite knowledge via software documentation	Software documentation should be useful to the programmer trying to understand a program. The key in that sentence was the word should: by and large documentation has a very bad reputation. We have been working on trying to improve documentation, in order that it may realize its potential. In this case study, we examine a programmer's use of documentation constructed along some specific guidelines. These guidelines, developed from our previous studies of documentation, are intended to help programmers draw causal connections between non-contiguous portions of programming plans in the program. This documentation appears to be helpful to a particular class of programmers, i.e., those who come to a program without the requisite background knowledge.
1988	Control of cognitive processes during software design: what tools are needed?	A verbal protocol study of professional software designers has revealed three design process control strategies. At least one of them, the generation of opportunistic solutions at different levels of detail accompanied by problem domain modeling, had not been observed in previous empirical studies nor had been acknowledged in the software engineering practices. Specific breakdowns (difficulties) were associated with the different design process control strategies. Software tools should be provided to designers to alleviate these breakdowns. Parts of a cognitive model of software design, based on distributed control from specialists such as design schemas, design heuristics, and design methods, are presented to account for the observed control strategies.
1988	Travel around a learning support environment: rambling, orienteering or touring?	The traditionally separate application areas supported by database systems and instructional systems are merging in the area of learning support environments (LSEs). We discuss the provision of tools in LSEs for navigating around large knowledge bases. The optimal form of navigation will depend on the nature of the user and of the learning requirements, and thus a variety of tools must be provided. We propose the use of a travel holiday metaphor as a means for structuring a set of navigation tools and illustrate its use in a system for teaching non-formal fields of knowledge.
1988	Palenque: an interactive multimedia digital video interactive prototype for children	The Palenque interactive multimedia digital video interactive prototype is based on themes, locations, and characters from The Second Voyage of the Mimi television show, which is being produced at Bank Street College. In the TV show, a cast of scientists and children explore the Yucatan's ancient Maya ruins and are introduced to the science of archeology. The Palenque prototype incorporates this theme to the extent that the user's experience is based on a virtual travel exploration of an ancient Maya site, Palenque, and on the perusal of a multimedia Palenque Museum database. One of our goals was to create a visually interesting database environment in which information in many formats could be browsed through spatially and thematically by children. In addition, we experimented with icon and window-based interface conventions that would make navigation around the video environment motivating and comprehensible for young users.
1988	Using latent semantic analysis to improve access to textual information	This paper describes a new approach for dealing with the vocabulary problem in human-computer interaction. Most approaches to retrieving textual materials depend on a lexical match between words in users' requests and those in or assigned to database objects. Because of the tremendous diversity in the words people use to describe the same object, lexical matching methods are necessarily incomplete and imprecise [5]. The latent semantic indexing approach tries to overcome these problems by automatically organizing text objects into a semantic structure more appropriate for matching user requests. This is done by taking advantage of implicit higher-order structure in the association of terms with text objects. The particular technique used is singular-value decomposition, in which a large term by text-object matrix is decomposed into a set of about 50 to 150 orthogonal factors from which the original matrix can be approximated by linear combination. Terms and objects are represented by 50 to 150 dimensional vectors and matched against user queries in this “semantic” space. Initial tests find this completely automatic method widely applicable and a promising way to improve users' access to many kinds of textual materials, or to objects and services for which textual descriptions are available.
1988	Online help systems: design and implementation issues (panel)	This panel session examines major issues in the design and implementation of online help systems.
1988	Grasping reality through illusion—interactive graphics serving science	I treat three related subjects: virtual-worlds research—the construction of real-time 3-D illusions by computer graphics; some observations about interfaces to virtual worlds; and the coming application of virtual-worlds techniques to the enhancement of scientific computing. We need to design generalized interfaces for visualizing, exploring, and steering scientific computations. Our interfaces must be direct-manipulation, not command-string; interactive, not batch; 3-D, not 2-D; multisensory, not just visual. We need generalized research results for 3-D interactive interfaces. More is known than gets reported, because of a reluctance to share “unproven” results. I propose a shells-of-certainty model for such knowledge.
1988	Exploratory evaluation of a planar foot-operated cursor-positioning device	The use of feet instead of hands to perform workstation cursor-positioning and related functions has been the subject of an on-going investigation. In the exploratory study reported here, a particular foot-operated device, the planar slide mole, was assessed against a mouse in a target-selection task. The study showed that novices can learn to select fairly small targets using a mole; for a target size of 1/8? square, the response time equaled that of the mouse when keyboard homing time was taken into account.
1988	An improved automatic lipreading system to enhance speech recognition	Current acoustic speech recognition technology performs well with very small vocabularies in noise or with large vocabularies in very low noise. Accurate acoustic speech recognition in noise with vocabularies over 100 words has yet to be achieved. Humans frequently lipread the visible facial speech articulations to enhance speech recognition, especially when the acoustic signal is degraded by noise or hearing impairment. Automatic lipreading has been found to improve significantly acoustic speech recognition and could be advantageous in noisy environments such as offices, aircraft and factories. An improved version of a previously described automatic lipreading system has been developed which uses vector quantization, dynamic time warping, and a new heuristic distance measure. This paper presents visual speech recognition results from multiple speakers under optimal conditions. Results from combined acoustic and visual speech recognition are also presented which show significantly improved performance compared to the acoustic recognition system alone.
1988	Improving the accuracy of touch screens: an experimental evaluation of three strategies	A study comparing the speed, accuracy, and user satisfaction of three different touch screen strategies was performed. The purpose of the experiment was to evaluate the merits of the more intricate touch strategies that are possible on touch screens that return a continuous stream of touch data. The results showed that a touch strategy providing continuous feedback until a selection was confirmed had fewer errors than other touch strategies. The implications of the results for touch screens containing small, densely-packed targets were discussed.
1988	Perspectives on algorithm animation	Systems for animating algorithms have received considerable interest of late as effective means for understanding computer programs. Thus far, nothing has been reported in the literature concerning nature of the displays nor to what extent displays can be created automatically. This paper addresses these two issues. The first part presents a taxonomy of displays prevalent in algorithm animation systems; the second part uses the taxonomy to analyze those types of displays that can and cannot be created automatically from unmodified source code.
1988	A graphical programming language interface for an intelligent LISP tutor	We describe an intelligent tutor for programming embedded in a graphical programming language. The tutor monitors students' problem solving and provides feedback and guidance. Explanations are generated from the content of the ideal model's problem solving rules. The graphical interface is designed to facilitate the acquisition of causal models of programming. Students work in a medium that corresponds to their planning operations. The interface enables forward and backward chaining, thus conveying the structure of the planning more effectively than a text-based interface. The interface also provides a graphical record of the solution history and current goals.
1988	Users' preferences among different techniques for displaying the evaluation of LISP functions in an interactive debugger	Two experiments investigated various techniques for displaying the evaluation of LISP functions in an interactive debugger. The studies examined three techniques of highlighting the flow of evaluation in a LISP function and two display formats for displaying LISP function information. The subjects in both experiments included highly experienced LISP programmers and occasional LISP users with moderate to little LISP experience. The dependent measure was the subjects' preference rating for each display technique. The results showed that occasional LISP users preferred range highlighting, an interlaced display of evaluation results, and a simultaneous display of called functions. However, expert LISP programmers had no differential preferences for highlighting techniques.
1988	Retrieval systems for the information seeker: can the role of the intermediary be automated?	The introduction of automated information retrieval (IR) systems was met with great enthusiasm and predictions that manual literature searching soon would be replaced. Three decades later, IR systems have not progressed to the stage where any but the dedicated few can operate them without a highly skilled human intermediary acting as interface between user and system. In the interim, we have learned that the retrieval process is extremely complex both in terms of understanding people and their communication and in terms of understanding scientific information and technical vocabulary. Experiments with new techniques suggest to many the possibility of eliminating the human intermediary, either in large part or altogether; others would argue that the retrieval problems are too complex to be resolved for more than highly restricted domains. The possibility of eliminating the human intermediary is of current research interest to the several disciplines that are represented on this panel. The discussion will revolve around one central question: Is our inability to get end-users to search primarily a problem of understanding people and their communication, or is it primarily a problem of understanding scientific information and technical vocabulary? Among the constituent issues the panel will address are these: Which are the most fundamental problems in constructing retrieval interfaces for the information seeker? How successful have been the attempts to build end-user oriented interfaces? Is a single, elegant solution to the problems of language handling, query negotiation, user modeling, and information retrieval possible? What techniques hold the most promise for automating the functions of the intermediary? What approaches are likely to be fruitless? Under what conditions is it possible and appropriate to automate some or all of the intermediary's skills and function?
1988	Transferring skills from training to the actual work situation: the role of task application knowledge, action styles and job decision latitude	In a field study (29 engineers), the transfer from expertise acquired in training to software use at work was shown to be mediated by task application knowledge (i.e. knowledge used to connect skills learned in training with tasks at work). Moreover, person variables like setting long range goals and developing detailed plans and an organizational variable like job decision latitude (i.e. how much freedom do workers have to do their work) influenced the transfer process. People with high goal orientation and planfulness and with high job decision latitude showed a higher transfer.
1988	A case study of CSCW in a dispersed organization	Pacific Bell conducted a trial of The Coordinator, a tool for computer-supported cooperative work. The trial group had diverse job functions and was dispersed across a variety of geographical locations and computing environments. The trial attempted to both measure the effectiveness of The Coordinator as a communications tool and to evaluate the speech act communications paradigm on which it is based. Only the first of these two goals was realized. Changes in subjects' cognition were assessed using a series of semantic differential scales. One negative cognitive shift was supported by the data. However, the anecdotal evidence was far more negative, suggesting that the experimental methodology be enhanced to include measurement of affective dimensions of group dynamics. Implementation and support for cooperative work systems were found to be more difficult than anticipated. The test group was not convinced that The Coordinator offered functionality that was worth the effort involved in learning to use the product. An improved interface, more flexible terminology, and better implementation support is needed for successful installation of The Coordinator, or similar products.
1988	A knowledge-based user interface management system	A knowledge base which defines a user-computer interface is described. The knowledge base serves as input to a user interface management system, which implements the user interface. However, the knowledge base represents user interface design knowledge at a level of abstraction higher than is typical of user interface management systems. In particular, it represents objects, actions, attributes of objects, an object class hierarchy, and pre- and post-conditions on the actions. The knowledge base can be algorithmically transformed into a number of functionally equivalent interfaces, each of which is slightly different from the original interface. The transformed interface definition can be input to the UIMS, providing a way to quickly experiment with a family of related interfaces.
1988	A grammar-based approach to automatic generation of user-interface dialogues	An effective user interface requires a dialogue layer that can handle multiple threads of interaction simultaneously. We propose a notation for specifying dialogues based on context-free attributed grammars with two extensions: fork operators for specifying sub-dialogues and context attributes for dispatching tokens. The notation is useful both as a means of communicating the behavior of the dialogue layer to designers and as input to a dialogue compiler that generates program code. In this paper we explain the motivation for our work and provide practical examples of the use of fork and context. In addition, we outline algorithms for parsing and for generating parser tables.
1988	The design of auditory interfaces for visually disabled users	Recent developments in the design of human-machine interfaces have resulted in interfaces which make access to computer-based equipment more difficult for visually disabled people. The aim of this project was to explore whether it is possible to adapt such interfaces so as to make them usable by people who cannot see a screen. The approach adopted was based upon two principles: the replacement of visual interface entities by auditory analogues and appropriately constraining the resultant interface. Two forms of sound were used to embody the auditory interface: musical tones and synthetic speech. In order to test the principles a word processing program was implemented which demonstrated that a visual program might be adapted to be accessed through such an interface.
1988	Multifunctional cursor for direct manipulation user interfaces	The multifunctional cursor (MC) is a technique for representing multiple operations in direct manipulation user interfaces. Icons for each of several simultaneously-available operations are overlaid into the cursor image. The MC improves user interface practice by removing syntactic inconsistencies, by reducing cognitive load, and by providing support for repeated operations.
1988	An empirical comparison of pie vs. linear menus	Menus are largely formatted in a linear fashion listing items from the top to bottom of the screen or window. Pull down menus are a common example of this format. Bitmapped computer displays, however, allow greater freedom in the placement, font, and general presentation of menus. A pie menu is a format where the items are placed along the circumference of a circle at equal radial distances from the center. Pie menus gain over traditional linear menus by reducing target seek time, lowering error rates by fixing the distance factor and increasing the target size in Fitts's Law, minimizing the drift distance after target selection, and are, in general, subjectively equivalent to the linear style.
1988	Color-coding categories in menus	Categorical menu layouts are currently designed according to conventions and opinions, rather than by employing formal techniques. In this paper we describe a formal methodology for categorically organizing menus. We go on to show how color-coding can be applied to these layouts either to emphasize organization or to provide additional information. The results of a controlled study comparing layouts based on frequency of co-occurrence and similarity show that the formal menu-layout methodology is effective. However, the use of color-coding to identify categories is not supported. Potential reasons for this failure are discussed.
1988	Transfer between menu systems	This paper investigates whether changes in the user/computer dialogue structure will affect the performance of users who are familiar with an earlier version of the product. Quantitative predictions using the Kieras and Polson (1985) production system model were derived to test whether changing the lexical attributes and structure of a popular menu-driven word-processor would permit transfer of existing knowledge of the word-processor to a new version. The results show that changes to the dialogue structure of the menu-system are not detrimental, while changes to the lexical attributes of the menus will hinder user performance.
1988	The data model is the heart of interface design	For the past six years, we have been developing a commercial hypermedia system (KMS) based on our previous research with the ZOG system at Carnegie Mellon University. Our experience with ZOG and KMS has convinced us that the data model underlying an interactive system is more important than the user interface in shaping the overall system. In this paper, we show how the KMS data model has influenced important aspects of the user interface. In particular, we show how the properties of KMS frames—their spatial nature, breadth-first view, homogeneity, small size, etc.—affect the nature of the KMS user interface.
1988	Navigating integrated facilities: initiating and terminating interaction sequences	Human performance data are reported for two dialogue conventions involving menu interactions with integrated facilities. Users prepared material for overhead foils in a six session experiment. An initiation style of dialogue in a flexible menu hierarchy was compared with a strict hierarchy involving explicit termination of dialogue sequences. Although tasks could be performed in the same number of steps with either interface, initiation had greater time and transaction costs than termination. The results are discussed in relation to the trade-offs that need to be considered in designing for navigational flexibility and to requirements for modeling user behavior.
1988	Pictures and category labels as navigational aids for catalog browsing	We describe two experiments that compare the relative utility of pictures, labels, and the combination of both as navigational aids for computerized catalog browsing. The results point to the usefulness of example pictures as search aids in the context of menu traversal through hierarchically structured pictorial databases. We take this outcome to be a reflection of the disambiguating role that pictures can play for verbal category labels.
1988	Choosing between methods: analysing the user's decision space in terms of schemas and linear models	We offer an account of how users choose between alternative methods which take different times to accomplish the same task. Users offered a choice between two methods do not necessarily pick the faster. We argue that users reduce the complexity of the decision space by applying a 'simple compensation schema' acquired from everyday experience. Linear models of performance time enable us to predict how users will view the situation in terms of this schema, and how accurate assessment of the optimal choices within the schema-based assimilations can result in an apparent bias in favour of one method.
1988	A general user modelling facility	An important component of adaptable interactive systems is the ability to model the system's users. Previous systems have relied on user models tailored to the particular needs of that system alone. This paper presents the notion of a general user model, and describes some of our research on building a general user modelling facility that could be used by a variety of applications. This work focuses on the representation, maintenance, and acquisition issues of modelling long-term beliefs of the user, and describes a general facility for accomplishing these tasks.
1988	Misconceived misconceptions?	Detailed user activity scripts from two previous studies of novice users working at a command language or a direct representation interface were submitted to independent expert judges for the justified ascription of misconceptions . Our initial hypothesis was that behavioral evidence for such misconceptions comes about as a result of well-articulated hypothetical reasoning. Although the evidence we obtained supports this view, it also suggests that for the direct representation case some activity normally attributed to misconceptions is non-reasoned in nature and governed by inherent powers of the representation.
1988	Integrating human factors and software development	Approaches to integrating human factors or user interface knowledge and expertise with software development are still exploratory and evolving. The human-computer interface provides a broader range of user interface challenges than earlier technology, but human factors is only now starting to be widely recognized as a distinct discipline requiring integration with system development. Devoting human and computer resources to user interface enhancement has been considered a luxury, and in many places still is, but the falling cost of computational power and the growing user resistance to poor interfaces, as well as a rising need for product differentiation in the marketplace, insure that human factors will become a necessity where it has not already. The need to develop organizational approaches to support the integration of human factors or user interface expertise with product development is thus a relatively new concern. The integration problems that have been identified include some that are shared with more established support activities such as technical writing, and others that are particular to human factors or result from the relative unfamiliarity of the discipline. Approaches that have been taken to managing human factors resources in order to maximize influence on user interface development include: hiring human factors engineers or psychologists directly into development teams, concentrating human factors engineers in a support organization, making use of external consultants with user interface knowledge, placing a development group under the leadership of a human factors professional, and forming an educational center in which software engineers learn about human factors approaches. Below, each panelist focuses on the advantages of one particular approach.
1988	A new conceptual model for interactive user recovery and command reuse facilities	This paper generalises approaches to modelling an undo facility for interactive systems into a comprehensive user recovery and command reuse facility. It separates different undoing actions into distinct undoing functions and incorporates redoing capability in a more general command reuse capacity. Four adequacy criteria for such a facility are proposed and a general model is developed to meet these requirements. Partial, patterned and repetitive undoing and redoing actions are allowed on simple, complex and meta commands. The model subsumes the functionality of prior models.
1988	How users repeat their actions on computers: principles for design of history mechanisms	Several striking characteristics of how often people repeat their actions on interactive systems are abstracted from usage data gleaned from many users of different classes over a period of months. Reformulated as empirically-based general principles, these provide design guidelines for history mechanisms specifically and modern user interfaces generally. Particular attention is paid to the repetition of command lines, and to the probability distribution of the next line given a sequential “history list” of previous ones. Several ways are examined of conditioning this distribution to enhance predictive power. A brief case study of actual use of a widely-used history system is also included.
1988	Planning for advising	Effective advice depends on knowledge of the plans and goals of the person requiring help. Planning advice must be at a cognitively appropriate level for the user. HICCUPS, a dynamic planning system for a direct manipulation statistics program, is based on an ideal user model. Plans are generated from goals inferred from explicit goal statements from the user, knowledge about the statistics program, and the recent interactions with the interface. This exploitation of environmental information and inherent domain structure to restrict the amount of search and inferencing is a vital part of intelligent reasoning which is both fast and effective.
1988	Justified advice: a semi-naturalistic study of advisory strategies	“Wizard of Oz” techniques were used to observe the interaction between users of a statistical package and a human playing the role of an simulated intelligent advisory system. The results emphasized the complexities of the advisory process. More than half of the clients' requests sought help on planning actions toward achieving task goals. Further, protocols collected from the advisor while advice was given revealed the importance of constructing models of the user's current and past interaction with the application, and of addressing the high-level goals that underlie clients' explicit questions. The relevance of these findings to the development of intelligent advisory systems is discussed.
1988	How to interface to advisory systems? Users request help with a very simple language	Advisory systems can be very powerful general tools for users. Formal query languages, menus, and direct manipulation interfaces might not suffice to access advisory systems' full functionality. The capabilities of natural language interfaces could be required. Unfortunately, natural language interfaces are not meeting the needs yet. Wide syntactic coverage is often traded off against handling ungrammatical sentences. However, this study shows that users request help with a very simple and restricted English, characteristic of unplanned or of child language . Moreover, users' utterances are frequently ungrammatical. It is argued that the simple syntax and the ungrammaticalities are determined by features intrinsic to advisory systems: users request help by typing to perform another primary task under real-time production constraints. Because of intrinsic performance constraints, users naturally resort to earlier and simpler forms of syntax. Natural language interfaces to advisory systems need not cover a wide variety of syntactic constructions but they must emphasize robust parsing.
1988	Designing keybindings to be easy to learn and resistant to forgetting even when the set of commands is large	We formulated a set of rules for producing key-commands that are alternatives for activating commands with a mouse from a menu. Because software is getting increasingly complex, it was important that the rules cover a wide variety of commands. The rules combined verb-modifier-object order and mnemonic abbreviations for the words in each slot. Our keybindings were shown not only to cover a wide set, but to be far easier to learn than EMACs (a common keybinding set) and a more robust form with respect to negative interference from prior and post-learning of another set.
1988	Effects of interface design upon user productivity	Eight subjects experienced in the use of both 7000 and 11000 series oscilloscopes performed four typical tasks with each scope. The 7000 interface is a dedicated physical control system, while the 11000 system employs icons, pop-up menus, assignable controls, and a touch panel. On each trial the task time and measurement accuracy were recorded. Each experimental session was video recorded and verbal protocols were collected. These allowed decomposition of the subjects' behaviors into categories that would account for performance differences between the two scopes. A 77\% performance difference is explained in terms of the cognitive factors of strategy selections and recall of operational details.
1988	Development of an instrument measuring user satisfaction of the human-computer interface	This study is a part of a research effort to develop the Questionnaire for User Interface Satisfaction (QUIS). Participants, 150 PC user group members, rated familiar software products. Two pairs of software categories were compared: 1) software that was liked and disliked, and 2) a standard command line system (CLS) and a menu driven application (MDA). The reliability of the questionnaire was high, Cronbach's alpha=.94. The overall reaction ratings yielded significantly higher ratings for liked software and MDA over disliked software and a CLS, respectively. Frequent and sophisticated PC users rated MDA more satisfying, powerful and flexible than CLS. Future applications of the QUIS on computers are discussed.
1988	A critical assessment of hypertext systems	Over forty years ago, Vannevar Bush articulated his vision of a “Memex” machine: “associative indexing, … whereby any item may be caused at will to select immediately and automatically another” [Bush 45]. In the sixties, Engelbart [Engelbart, English 68] built collaborative systems to provide idea structuring and sharing. Nelson [Nelson 81] coined “hypertext” and proposed world-wide networks for publishing, linking, annotating and indexing multiple versions of documents. With increasing numbers of research projects, papers, panels and conferences, and commercially available systems (e.g. Notecards by Xerox, Guide by Owl and HyperCard by Apple) in recent years, hypertext may be an idea whose time has finally come — or at least a phenomenon not to be ignored. The goal of this panel is not to define hypertext or hypermedia (at its simplest: non-linearly arranged and accessed information), debate its uniqueness, explain implementation issues, or survey the many applications and contributions in the field (see [Conklin 87] for an excellent survey of Hypertext, and the Proceedings of Hypertext '87 Workshop at University of North Carolina, Chapel Hill). Rather, we intend to approach it from the perspective of the information user: reader, searcher, author. The panel will address the following issues: Are the processes of authoring and understanding helped or hindered by the non-linear structure of hypertext, for which kinds of tasks and users? What is the difference between a hypertext writer and a knowledge engineer? In searching for information, what is the difference between browsing and querying? What experiments need to be done? What tools, environment or interfaces can improve the process of information creation and access? Can the overhead of creating or interpreting structure be reduced? When will hypertext replace paper, or should it? How do functions of author and reader co-evolve? Could this revolutionize society like the printing press? Why didn't the panelists create a multi-versioned, highly crossreferenced online entry for the proceedings? Is hypertext a technology in search of a problem?
1988	Multimodal response planning: an adaptive rule based approach	This paper describes the architecture and prototype of a system which dynamically determines how to present information to a user. The system utilizes a rule based approach to select one or more modalities for presenting information. Next the system determines one or more techniques to present the information within each of the previously selected modalities. This system also adapts to individual users providing flexibility not found in traditional presentation systems. Finally, models are used for storing knowledge about the user resulting in a system which can be easily enhanced as new data is obtained and can adapt to the needs of its users.
1989	Some strategies of reuse in an object-oriented programming environment	In a single-subject study of a software developer working in an object-oriented programming environment, we found evidence of a development style characterized by pervasive software reuse. The subject employed regular strategies for template selection and coding in her work, and avoided techniques requiring deep understanding of code details or symbolic execution whenever possible. Within the limits of the design of the study, the subject's performance is related to attributes of object-oriented programming and our interpretation of the mature mental model with which she approached her task.
1989	A spreadsheet interface for logic programming	We present PERPLEX, a programming environment intended for the end-user. In its design, the concepts of logic programming and spreadsheets are combined. Thus, on the one hand, logic programming becomes an interactive, incremental task where the user gets direct visual feedback, on the other hand, functionality and scope of a conventional spreadsheet program are considerably extended. In order to perform calculations and queries, constraints are imposed on the contents of the spreadsheet cells. New predicates can be defined using a programming-by-example technique: Rules are extracted from the user's solutions for example problems. Thus, concrete intermediate results take over the role of abstract logic variables in the programming process. PERPLEX has been successfully implemented on a Symbolics Lisp Machine.
1989	On-line tutorials: What kind of inference leads to the most effective learning?	This paper presents an empirical study comparing the effectiveness of four different versions of an on-line database tutorial, each of which calls upon the student to perform a different kind of inference. The general-to-specific version presents instructions in the form of general rules, from which the students expected to infer how to apply the rule in the give context. The explanation-to-specific version supplies information about the functional organization of the database program in addition to general rules. The specific-to-specific condition gives an example of the use of a command; the student must infer how to apply the command in a slightly different context. The control version gives explicit instructions. The best performance on a post-test consisting of realistic tasks was obtained from the general-to-specific and explanation-to-specific conditions.
1989	How some advice fails	Video data for thirty-four cases of advice seeking, giving and following behavior at a graphical computer interface were analyzed in detail. The evidence indicated that clients followed prescriptive advice effectively and efficiently in slightly more than half the cases. For other cases, clients performed twice as many actions as needed in three times as much time and never reached prescribed states. A hypothesis that observed advice following difficulties were correlated with advice abstractness was not supported. Rather, it seems advice did not match well with clients' knowledge of the system in particular isolated details.
1989	Responding to :20HUH?”: answering vaguely articulated follow-up questions	Expert and advice-giving systems produce complex multi-sentential responses to user's queries. Results from analyses of novice/expert dialogues indicate that novices often do not understand an expert's response and rarely ask a well-formulated follow-up question. Thus systems must be able to provide further information in response to vaguely articulated questions. However, current systems cannot clarify misunderstood explanations or elaborate on previous explanations. In this paper we describe an approach to explanation generation that expands a system's explanatory capabilities and enables the production of clarifying or elaborating explanations in response to follow-up questions or indication that the explanation was not understood.
1989	Protecting user interfaces through copyright: the debate	This paper will provide an overview of the legal controversy about the extent of copyright protection that is appropriate for software user interfaces. The controversy reflects different views of how traditional principles of copyright law should be applied to software. After a brief introduction to copyright principles, the paper will set forth an argument for maximal copyright protection for software user interfaces, and then an argument for minimal copyright protection for user interfaces. Both arguments apply copyright principles; they simply draw on different parts of copyright doctrine in doing so. The paper does not aim to resolve the debate, but only to familiarize the user interface design community of the legal context in which the debate is taking place.
1989	Drama and personality in user interface design	The title of this panel immediately leaps out as being out of place. Of all the things that come to mind when one thinks of computers and user interfaces, drama and personality are among the last. The point here is not to make using computers more dramatic, per se, but to learn and borrow from the performing arts about techniques that could improve main stream interface design. The contributions described in this panel are borrowed from the theatrical world, film producing and music. In all the panelists work, the user is at the very center of creating the actual user interface experience, either through direct user participation or via engaging the individual viewer's personality. The panelists' pioneering research has produced and created several examples of new user interface experiences and designs. The discussion will focus on what techniques offer the most promise for facilitating the design of really new experiential user interfaces.
1989	Cumulating the science of HCI: from s-R compatibility to transcription typing	In keeping with our claim that an applied psychology of HCI must be based on cumulative work within a unified framework, we present two extensions of the Model Human Processor. A model of immediate response behavior and stimulus-response (S-R) compatibility is presented and extended to a new domain: transcription typing. Parameters are estimated using one S-R compatibility experiment, used to make a priori predictions in four other S-R compatibility tasks, and then carried over into the area of typing. A model of expert transcription typing is described and its prediction of typing phenomena is demonstrated and summarized.
1989	Learning and transfer of measurement tasks	This study presents a theoretically motivated analysis of learning and performance on a micro-processor based oscilloscope. An analysis of the knowledge required to make basic measurements was done using the GOMS model and Cognitive Complexity Theory (CCT). From these analyses and the criterion used in Polson, Muncher, and Engelbeck (1986), tasks were selected for an experiment evaluating training order manipulations using naive users of oscilloscopes. Production system models for each training task were derived from CCT. The models successfully predicted transfer between tasks and training order effects. Implications for the design of systems with embedded micro-processors are discussed.
1989	Skilled financial planning: the cost of translating ideas into action	We use GOMS models to predict error rates and mental times for translating financial concepts into equations in two widely used interface representations. The first of these, common to spreadsheet packages, is characterized by non-mnemonic naming and absolute referencing of variables. The second, common to non-procedural command-driven software, is characterized by mnemonic naming conventions and relative referencing of variables. These predictions were tested in an experiment using experienced financial analysts. Although the interface that allows mnemonic and relative names (called keyword) takes longer overall, it produces seventy-five percent fewer simple errors and requires less mental effort. Given the overall serious cost of errors in financial models, we conclude that interfaces having the keyword representation are far superior.
1989	A case study of user interface management system development and application	This paper discusses the design and applications of an object-oriented user interface management system (UIMS). Specifically, the Lockheed User Interface System (LUIS) is described. LUIS is based on a user interface model that includes declarative and procedural components. The package has been used by both non-programmers and programmers in several applications at Lockheed. Experiences derived from applications of the package are used to address several key issues in the UIMS field, such as procedural versus declarative specification, separation of the user interface from applications, UIMS flexibility, and UIMS support for design evaluation.
1989	A high-level user interface management system	A high-level UIMS which automatically generates the lexical and syntactic design of graphical user interfaces is presented. The interfaces generated by the UIMS can easily and rapidly be refined by the designer by using highly interactive and graphical facilities. The UIMS accepts a high-level description of the semantic commands supported by the application, a description of the implementation device, and optionally, the end user's preferences. Based on these inputs the UIMS generates graphical user interfaces in which the commands are selected from menus and command arguments are provided through interaction with graphical interaction techniques.
1989	Graphical specification of user interfaces with behavior abstraction	The Application Display Generator (ADG) is a graphical environment for the design and implementation of embedded system user interfaces. It is a major component of the Graphical Specification Subsystem (GSS) in Lockheed's Express knowledge-based software development environment. ADG gives non-programmers simple and flexible methods for graphically specifying the presentation and behavior of embedded system user interfaces. In the ADG methodology arbitrary presentations are attached to abstract object behaviors. This approach makes it possible to provide unconstrained presentations, intelligent user support, rapid prototyping, and flexible facilities for composing complex objects.
1989	Center for coordination science, MIT	The costs and capabilities of information technology are improving by orders of magnitude every decade, but we are only beginning to understand the opportunities these changes provide for new ways of organizing human activity and new kinds of technology to help people work together. The new MIT Center for Coordination Science conducts multidisciplinary research to help understand these possibilities better. Research in the center draws upon many parts of MIT and ongoing projects in a variety of fields, including: computer science, organization theory, psychology, information systems, management science, and economics. We believe that a powerful source of intellectual leverage on questions about how groups of people can use computers will result from a better understanding of the nature of coordination. Therefore, work in the center focuses on how coordination can occur, both with and without technology. The center includes projects in the following areas: Coordination technology - designing and studying innovative computer systems that help people work together in small or large groups (e.g., “groupware”, “computer-supported cooperative work”, and “electronic markets”). Organizational structures and information technology - observing, analyzing, and predicting how information technology affects organizational structures and processes and how organizations can use information technology more effectively. Coordination theory - developing and testing theories about how the activities of separate actors can be coordinated. These theories are expected to draw upon and illuminate coordination among people and also coordination in distributed or parallel processing computer systems. In addition to research projects in these areas, the Center also sponsors seminars, workshops, working papers, and conferences.
1989	Bat brushes: on the uses of six position and orientation parameters in a paint program	A geometry is described for converting hand position and orientation into six useful variables for computer input. The application is that of controlling form and color in an experimental computer “paint” program. We find that the most easily controlled parameters of hand placement are x,y and z cartesian coordinates and a twist parameter which approximates the wrist action that occurs when a dial is turned. The two remaining parameters are horizontal and vertical wrist rotations. In order to capture these it is necessary to correct for the rotation about the elbow which naturally occurs when the hand is translated. However, these two parameters are difficult to control independently of hand translations. Computer paint “brushes” are described which allow the real-time control of size, color and position on the screen using the hand parameters described.
1989	Circling: a method of mouse-based selection without button presses	A method for selecting graphical objects with a mouse by circling them is described. Circling motions are detected automatically; no button presses are required. Trials conducted on a Sun 3 workstation indicate that, for the object size and layout chosen, even users experienced with mouse selection via button presses and unfamiliar with circling are able to select pairs of objects in approximately the same amount of time with either method. The number of target misses between circling and clicking also compare well for both single and paired object cases. Furthermore, many users showed a measurable preference for the circling method when given a choice.
1989	Systemic implications of leap and an improved two-part cursor	The lowly text cursor is a non-issue for most interface designers. Nonetheless, current text cursor designs suffer from at least two problems: one-off errors and a lack of visibility of function. These problems are exacerbated in an editing environment which uses the extremely fast Leap cursor-moving technology. This paper presents solutions to these cursor design problems and reveals the surprising way many other aspects of system design can be improved as a consequence of designing the cursor correctly.
1989	A programming language basis for user interface	The Mickey UIMS maps the user interface style and techniques of the Apple Macintosh onto the declarative constructs of Pascal. The relationships between user interfaces and the programming language control the interface generation. This imposes some restrictions on the possible styles of user interfaces but greatly enhances the usability of the UIMS.
1989	Statemaster: A UIMS based on statechart for prototyping and target implementation	Most User Interface Management systems are state based and some use state transition diagrams for dialog specification. Although these diagrams have significant advantages, they suffer from drawbacks that make them impractical for the specification of complex user interfaces. Statecharts are a hierarchical extension of state transition diagrams and are well suited for specification of complex user interface dialogs. Statemaster is a UIMS implemented in C + + that uses statecharts for dialog specification. It has been successfully used both for rapid prototyping and target implementation of user interfaces. This paper describes the use of statecharts for dialog specification and the implementation of Statemaster.
1989	Task-oriented representation of asynchronous user interfaces	A simple, task-oriented notation for describing user actions in asynchronous user interfaces is introduced. This User Action Notation (UAN) allows the easy association of actions with feedback and system state changes as part of a set of asynchronous interface design techniques, by avoiding the verbosity and potential vagueness of prose. Use within an actual design and implementation project showed the UAN to be expressive, concise, and highly readable because of its simplicity. The task- and user-oriented techniques are naturally asynchronous and a good match for object-oriented implementation. Levels of abstraction are readily applied to allow definition of primitive tasks for sharing and reusability and to allow hiding of details for chunking. The UAN provides a critical articulation point, bridging the gap between the task viewpoint of the behavioral domain and the event-driven nature of the object-oriented implementational domain. The potential for UAN task description analysis may address some of the difficulties in developing asynchronous interfaces.
1989	Innovation in user interface development: obstacles and opportunities	Case studies of two software development organizations suggest that common practices of these organizations pose obstacles to innovation. Although software development organizations have good reasons to be conservative and resist innovation, they recognize the importance of innovations to the competitiveness of their products. But organizations experienced at development of regularly scheduled releases are not well suited to development of innovations. In this research investigators worked with the user interface teams in two organizations while interviewing people throughout the organizations. Both organizations developed prototypes, but only small design changes were prototyped and tested early in development. Innovative changes were evaluated late, when resistance to iteration was great. User interface designs and prototypes were often not shown to users. Mechanisms for coordinating development were another conservative influence. Both organizations successfully overcame these obstacles by departing from established practices.
1989	User interface design in large corporations: coordination and communication across disciplines	This report describes some of the results of a survey constructed to address the multidisciplinary, collaborative nature of user interface design as it is practiced in large software development organizations today. Survey forms were prepared for Software Engineers, Human Factors Engineers, Industrial Design Engineers, Technical Writers, Training Developers, and Marketing representatives. The survey was filled out by over 200 designers from multiple sites within 7 large companies. Previous interview studies of user interface design have relied on far smaller samples taken primarily from single organizations, and have focused on the individual designer's perspective, primarily that of programmers or software engineers. While surveys have limitations as information-gathering tools, the findings in this report suggest specific places where organizational change or tool development might improve the coordination or communication among the different professionals and managers who contribute to interface design in large company settings.
1989	Behavioral evaluation and analysis of a hypertext browser	Students performed a variety of tasks using a statistics text presented either in conventional printed form or via the text browser “SuperBook” (Remde, Gomez and Landauer [18]). Students using SuperBook answered more search questions correctly, wrote higher quality “open-book” essays, and recalled certain incidental information better than students using the conventional text. Subjective ratings overwhelmingly favored SuperBook. The advantage of SuperBook appears to be particularly strong for questions that are not anticipated by the author's organization of a text.
1989	How do experienced information lens users use rules?	The Information Lens provides electronic mail users with the ability to write rules that automatically sort, select, and filter their messages. This paper describes preliminary results from an eighteen-month investigation of the use of this system at a corporate test site. We report the experiences of 13 voluntary users who have each had at least three months experience with the most recent version of the system. We found that: People without significant computer experience are able to create and use rules effectively. Useful rules can be created based on the fields present in all messages (e.g., searching for distribution lists or one's own name in the address fields or for character strings in the subject field), even without any special message templates. People use rules both to prioritize messages before reading them and to sort messages into folders for storage after reading them. People use delete rules primarily to filter out messages from low-priority distribution lists, not to delete personal messages to themselves.
1989	Performance, preference, and visual scan patterns on a menu-based system: implications for interface design	This study was conducted to provide evidence for the nature of visual search processes with menus, and to derive design principles for menu-based natural language (MBNL) interfaces to databases. The effects of window size, window activity, and query length were investigated. It was found that longer queries were performed faster with single active windows, but multiple active windows were rated as more 'natural'. Query times increased with query length, as did eye fixation frequencies, fixation durations, and dwell times. Errors were most likely to occur on the longest query. Fixation durations also varied with window size. However, visual behavior depended on the area being viewed and on the interaction between window activity and query length. In contrast with previous studies, it was also found that menus were not scanned randomly. However, scanpaths were less deterministic with multiple active windows and became even more unconstrained as query length increased. User interface design recommendations were derived from the findings.
1989	Synergistic use of direct manipulation and natural language	This paper shows how the integration of natural language with direct manipulation produces a multimodal interface that overcomes limitations of these techniques when used separately. Natural language helps direct manipulation in being able to specify objects and actions by description, while direct manipulation enables users to learn which objects and actions are available in the system. Furthermore, graphical rendering and manipulation of context provides a partial solution to difficult problems of natural language anaphora.
1989	A synthetic visual environment with hand gesturing and voice input	This paper describes a practical synthetic visual environment for use in CAD and teleoperation. Instead of using expensive head mounted display systems, we use a standard display and compute smooth shaded images using an AT&T Pixel Machine. The interface uses a VPL DataGlove [9] to track the hand, bringing the synthetic world into the same space as the hand. Hand gesturing is used to implement a virtual control panel, and some 3D modeling tasks. When simple speech recognition was added it markedly improved the interface. We also outline what extensions might be needed for using this kind of interface for teleoperation.
1989	Speech and gestures for graphic image manipulation	An experiment was conducted with people using gestures and speech to manipulate graphic images on a computer screen. A human was substituted for the recognition devices. The analysis showed that people strongly prefer to use both gestures and speech for the graphics manipulation and that they intuitively use multiple hands and multiple fingers in all three dimensions. There was surprising uniformity and simplicity in the gestures and speech. The analysis of these results provides strong encouragement for future development of integrated multi-modal interaction systems.
1989	Design rationale: the argument behind the artifact	We assert that the product of user interface design should be not only the interface itself but also a rationale for why the interface is the way it is. We describe a representation for design based around a semi-formal notation which allows us explicitly to represent alternative design options and reasons for choosing among them. We illustrate the approach with examples from an analysis of scrolling mechanisms. We discuss the roles we expect such a representation to play in improving the coherence of designs and in communicating reasons for choices to others, whether designers, maintainers, collaborators or end users.
1989	Conversational resources for situated action	Suchman (1987) has recently drawn attention to the situated nature of human social action and its implications for the design of interactive computer systems. In particular, she has highlighted the shortcomings of globally managing human computer dialogues by matching user actions to some idealised plan for carrying out a task. In this paper we outline a scheme for the local management of dialogues based on the findings of conversation analysis. The scheme makes available a variety of communicative resources to both user and system, including the ability to give and take turns at talk, to initiate and carry out repair work, and to continue or change the topic of conversation. An implementation of the scheme in a welfare rights Advice System is described.
1989	Prototyping techniques for different problem contexts	Rapid prototyping and other experimental techniques are playing an increasingly important role in software development. Some common issues that concern their adoption are identifying the place in a system's life cycle where they may be appropriate, and selecting which tools to use. This paper presents a model of different problem types, suggesting that a fit must be found between the nature of the problem at hand and the features associated with available techniques. Emphasis is placed on the fact that most commercial tools are suitable for only certain problem types. Some areas of further development are highlighted and implications concerning human-computer interaction discussed.
1989	Design environments for constructive and argumentative design	Design Environments are computer systems which support design by enabling cooperative problem solving between designer and computer. There are two complementary problem solving activities in design: constructive design and argumentative design. We have created two computer-supported environments, CRACK and VIEWPOINTS, to support these two activities. CRACK is a knowledge-based critic which has knowledge about how kitchen appliances can be assembled into functional kitchens. VIEWPOINTS is a hypertext system based on the IBIS design methodology and contains useful information about the principles of kitchen design. The integration of these two types of systems will eliminate shortcomings of the individual systems.
1989	Generating highly interactive user interfaces	Developers of User Interface Management Systems (UIMS) have demonstrated that separating the application from its user interface supports device independence and customization. Interfaces produced in UIMS are typically crafted by designers expert in human factors and graphic arts. Little attention has been paid, however, to capturing the knowledge of such experts so that interfaces might be automatically generated by the application of style rules to additional applications. This paper considers how toolkits and style rules can be structured so that the resulting interfaces take advantage of the best human factors and graphic arts knowledge, and are consistently styled.
1989	Directed dialogue protocols: verbal data for user interface design	The development of an interface design tool called “directed dialogue protocols” is discussed. The tool is based upon Kato's (1986) method of verbal data collection, “question-asking protocols.” Three extensions to the question-asking method are detailed: 1) an experimental procedure of atomic tasks which facilitate the quantization of verbal data; 2) interventions by the experimenter that probe the subject's expectations and prompt verbalizations; and 3) a technique for answering subject queries called sequential disclosure. Also discussed are applications of the directed dialogue that have identified design choices which build learnability and usability into a product's user-interface.
1989	Conversational hypertext: information access through natural language dialogues with computers	One need not create a natural language understanding system in order to create a hypertext data base that can be traversed with unconstrained natural language. The task is simplified because the computer creates a constrained context, imposes a non-negotiable topic, and elicits simple questions. Two small hypertext data bases describing the authors' organization and the terms and rules of baseball were implemented on an IBM PC. When ten untrained people were allowed to search through these data bases, 59 per cent of their queries were answered correctly by the first data base and 64 per cent by the second.
1989	Transforming text into hypertext for a compact disc encyclopedia	A hypertext version of a multi-volume engineering encyclopedia on a compact disc is described. The methods for characterizing the explicit and implicit structure of the document, the novel user interface to the compact disc version, and the design and development lessons that apply to any hypertext project involving realistic amounts of text and graphics are discussed.
1989	The tourist artificial reality	This paper describes a prototype system designed to meet the needs of the next generation of user interfaces. We address research questions of information complexity, multiple shared semantically-oriented views, and customizable tool environments. Our domain of interest is software systems that require interfaces for teams of people to large bodies of design artifacts. This prototype is built around the metaphor of tourists and tour guides.
1989	Planar maps: an interaction paradigm for graphic design	Compared to traditional media, computer illustration software offers superior editing power at the cost of reduced freedom in the picture construction process. To reduce this discrepancy, we propose an extension to the classical paradigm of 2D layered drawing, the map paradigm , that is conducive to a more natural drawing technique. We present the key concepts on which the new paradigm is based: a) graphical objects, called planar maps , that describe shapes with multiple colors and contours; b) a drawing technique, called map sketching , that allows the iterative construction of arbitrarily complex objects. We also discuss user interface design issues in map based illustration software.
1989	Encapsulating interactive behaviors	Although there has been important progress in models and packages for the output of graphics to computer screens, there has been little change in the way that input from the mouse, keyboard and other input devices is handled. New graphics standards are still using a ten year old model even though it is widely accepted as inadequate, and most modern window managers simply return a stream of device-dependent input events. This paper presents a new model for how input devices can be handled for highly-interactive, direct manipulation, graphical user interfaces. This model encapsulates interactive behaviors into a few “interactor” object types. Application programs can then create instances of these interactor objects, and the details of the handling of the input devices are separated from the application and from the output graphics.
1989	Constraint grammars–a new model for specifying graphical applications	User Interface Management Systems often attempt to separate the graphical and nongraphical aspects of an application, but rarely succeed. Constraint grammars provide a new model for specifying interfaces that achieves this goal by encapsulating the data structures in a single package, and providing a powerful transformation-based editing model for manipulating them. Constraint grammars incorporate a number of important tools, such as the part-whole hierarchy, almost hierarchical structures , and multidirectional constraints , that permit designers to specify a wide variety of graphical applications, including simulation systems, program visualization systems, and visual programming environments.
1989	The effects of device technology on the usability of advanced telephone functions	This paper presents a pilot study that addresses the effect that device technology has on the usability of advanced telephone functions. We prototyped telephone systems using three technologies: the current 12-button phone set, the current phone set augmented with speech synthesis, and a phone set augmented with a display and pointing device. The functions that we offered included call routing, call screening, and message retrieval. Experiments showed that a display-based phone was the fastest to use and was preferred; an interface that used voice-prompting was the slowest and least liked. This points out that future work on prompting interfaces will have to address user control and efficiency issues without causing learning/forgetting problems.
1989	An experiment into the use of auditory cues to reduce visual workload	The potential utility of dividing the information flowing from computer to human among several sensory modalities is investigated by means of a rigorous experiment which compares the effectiveness of auditory and visual cues in the performance of a visual search task. The results indicate that a complex auditory cue can be used to replace cues traditionally presented in the visual modality. Implications for the design of multimodal workstations are discussed.
1989	The design of phone-based interfaces for consumers	This paper identifies guidelines for designing human-computer interfaces using telephones as terminals. Although they are ubiquitous and convenient to use, phones differ from screen terminals in two important ways: the information display is auditory and serial, and users do not have a pointer. The differences result in limitations for the interface designer. The guidelines focus on developing an effective interface within the limitations. Ongoing analysis, design, development, and testing work at IBM Poughkeepsie and literature are synthesized into guidelines. They present design options for user input, system output, and the system and user roles in a phone-based dialogue.
1989	Tools for supporting cooperative work near and far: highlights from the CSCW conference	The second conference on Computer Supported Cooperative Work has provided focus on use of computers for supporting workers that are at various levels of geographic dispersion. The participants in this panel reported case studies at that conference on group work (1) in face-to-face meetings, (2) in the same building, and (3) distributed across a number of sites. Each panelist therefore brings insight about the communication needs of their research subjects and both the value and limitations of particular technologies for supporting the communication that ties the members of the groups together as geographic distance varies. Each of the panelists will address the following two questions: What are the preferred types of communication (visual, written, spoken) for people working together at particular geographic distances? What are the benefits and shortcomings of available technologies (video, electronic-mail, telephone/voice mail) for supporting these types of communication?
1989	Helgon: extending the retrieval by reformulation paradigm	People who attempt to use a complex information store on a computer encounter a number of problems: They do not know what information exists or how to find information, they get no support in articulating a question, and they are unable to phrase their question in terms that the system understands. Helgon, an intelligent environment that supports limited cooperative problem solving, helps people deal with complex information stores. Helgon supports retrieval and editing by reformulation with multiple specification techniques, and it acquaints the user with the system model of the information store. Within the current Helgon system, a number of different information stores have been implemented. Empirical evaluations have shown that Helgon supports effective communication. In addition, the evaluations have shown interesting extensions for future work.
1989	User-interface design for a clinical neurophysiological intensive monitoring system	We describe the functional requirements and design reasoning leading to a user-interface for an automated clinical neurophysiological monitoring system. The design provides a versatile, high-performance system in which computer-naive users have access to functions typically requiring dedicated training. The system provides real-time data acquisition, signal processing, and graphical output, specifically tailored for the diagnosis and characterization of cases of epilepsy. The development of a user-interface was based on a collaborative effort, in which designers and users worked with a common functional model, and developed working metaphors for system operations. In addition, an interactive screen was designed to facilitate the management of multiple concurrent operations in an intuitive and easy to learn fashion.
1989	A document layout system using automatic document architecture extraction	A document layout system based on automatic extraction of document architecture including logical and reference structures has been developed for reducing users' effort in document preparation, and has been implemented in a practical Japanese word processor. The extracted document architecture is used for both automatic text formatting and layout of text, figures and tables. Automatic text element recognition is performed by morphological analysis using keywords. Through intra-line (one sentence) and inter-line (relations between sentences) analysis, logical and reference structures are obtained. The automatic layout system effectively lays out the document using the extracted document architecture and knowledge about the layout.
1989	Models of user interactions with graphical interfaces: 1. statistical	Three models of human interactions with computer-displayed statistical graphics were developed and tested in an experiment which examined users' speed and accuracy on identification and comparison questions using 17 graph types. The results indicated that response time and accuracy were influenced by the perceptual and informational complexity of the graph, as well as the relation between the figure and axes, (Model 1); by the physical elements of the graph — points, lines, and areas (Model 2); and by the data-ink ratio and data density (Model 3). The discussion focuses on the development of a single integrated model of interactions with graphics.
1989	Understanding Bayesian reasoning via graphical displays	Bayesian reasoning, updating subjective probability in light of new information, is notoriously difficult. One factor that may contribute to this difficulty is lack of a mental model for how to combine the three key parameters in any Bayesian problem. An experiment was conducted contrasting four representations of Bayesian problems: three types of diagrams and a two by two contingency table. All four representations led to extremely good performance on a Bayesian task. This advantage also extended to a superficially dissimilar task and also persisted beyond the day of training, suggesting that graphic and tabular representation can lead to flexible and durable changes in the way people think about such problems.
1989	Mathematical formula editor for CAI	Many students in lower grades who study mathematics with computers have difficulty in inputting formulas by using existing methods. It would be much easier for them if they could input formulas naturally, as they appear in textbooks. This paper describes such an interface program module for use in CAI. This module makes it easy for students to input and edit complex formulas solely by key operations, without using a mouse. The difference between the module and existing mathematical expression editors is that it converts formulas into character strings syntactically. In this way, CAI programs can understand the meanings of the formulas.
1989	Generalization, consistency, and control	Easy learning of a user interface depends in part on users being able to generalize successfully about it. Philosophical doctrine, and some recent work in human-computer interaction, argues that causal analysis of interactions can support generalization. But neither the philosophical literature nor the HCI literature provides a rigorous theory of causal analysis adequate for problems in human-computer interaction. We propose such a rigorous theory here, and show how it accounts for two robust generalizations, using certain general assumptions. We then present evidence that these assumptions are accepted by people. Finally we compare this theory with other treatments of consistency.
1989	Artifact as theory-nexus: hermeneutics meets theory-based design	We suggest that HCI designs characteristically embody multiple, distinct psychological claims, that virtually every aspect of a system's usability is overdetermined by independent psychological rationales inherent in its design. These myriad claims cohere in being implemented together in a running system. Thus, HCI artifacts themselves are perhaps the most effective medium for theory development in HCI. We advance a framework for articulating the psychological claims embodied by artifacts. This proposal reconciles the contrasting perspectives of theory-based design and hermeneutics, and clarifies the apparent paradox of HCI application leading HCI theory.
1989	Programmable user models for predictive evaluation of interface designs	A Programmable User Model (PUM) is a psychologically constrained architecture which an interface designer is invited to program to simulate a user performing a range of tasks with a proposed interface. It provides a novel way of conveying psychological considerations to the designer, by involving the designer in the process of making predictions of usability. Development of the idea leads to a complementary perspective, of the PUM as an interpreter for an “instruction language”. The methodology used in this research involves the use of concrete HCI scenarios to assess different approaches to cognitive modelling. The research findings include analyses of the cognitive processes involved in the use of interactive computer systems, and a number of issues to be resolved in future cognitive models.
1989	LIZA: an extensible groupware toolkit	Software for supporting groups of cooperating users — groupware — raises a number of new issues in user interface design. This paper gives a definition of groupware and presents a model of group tools based on active objects . The model has been applied to the design and implementation of an extensible groupware toolkit known as LIZA. The paper describes the architecture of LIZA. Examples of group tools running under LIZA are used to illustrate some of the problems in the design of multi-user interfaces.
1989	Collaboration in KMS, a shared hypermedia system	This paper describes how we use a hypermedia system (KMS) for our collaborative work. Based on our experience with KMS and our previous research with the ZOG system at Carnegie Mellon University, we believe that a shared-database hypermedia system provides a powerful foundation for collaboration. In this paper, we show how the shared-database capability of KMS, plus particular aspects of its data model, address six of the fundamental issues facing designers of collaborative work systems.
1989	The effects of bargaining orientation and communication medium on negotiations in the bilateral monopoly task: a comparison of decision room and computer conferencing communication media	Pairs of subjects with either a competitive or an integrative bargaining orientation completed the Bilateral Monopoly Task in one of four communication media (text- only, text-plus-visual-access, audio-only, and audio-plus-visual-access). As hypothesized, an integrative bargaining orientation and/or an audio mode of communication led to a higher joint outcome. In addition, visual access resulted in higher joint outcomes for subjects with integrative bargaining orientations, but lower joint outcomes for those with competitive orientations. The support for negotiation offered by decision room and computer conferencing technologies is compared based on the efficiency and richness of the communication media available in each.
1989	What is EuroParc?	EuroPARC is a systems research laboratory supported by Rank Xerox Limited and allied with the Xerox Palo Alto Research Center (PARC). The decision to create EuroPARC was announced in November of 1986, and the lab was officially dedicated in June of 1988. EuroPARC's research charter is human-computer interaction. The research program is coordinated with PARC's, but the goal is to combine PARC-style systems research with European points of view, issues, and approaches.
1989	NYNEX intelligent systems group	The Intelligent Interfaces Group is an interdisciplinary group with interests in artificial intelligence, human-computer interaction, and cognitive science. The primary mission is to provide research and development support to both the regulated and unregulated business units of NYNEX (the Regional Bell Operating Company for New York and New England). The Group was started in October 1986. The Intelligent Interfaces Group is part of the Artificial Intelligence Laboratory; other groups in this Laboratory are Expert Systems, Neural Networks and Machine Learning, and Speech Technologies. Staff members have interests in tutoring systems and tutoring strategies, the design and use of multi-modal communications systems, the evaluation of interactive systems, the development of software toolkits, and similar areas. Projects are selected to support these interests as well as have near-term practical benefits. Some projects are conducted at the request of NYNEX family units, others are initiated by staff members. All projects are funded by NYNEX.
1989	Inducing programs in a direct-manipulation environment	End users who need to program within highly interactive direct-manipulation interfaces should be able to communicate their intentions through concrete demonstration rather than in terms of symbolic abstraction. This paper describes a system that learns procedures in interactive graphics taught to it “by example” by minimally trained users. It shows how techniques of machine learning and reactive interfaces can support one another—the former providing generalization heuristics to identify constraints implicit in user actions, the latter offering immediate feedback to help the user clarify hidden constraints and correct errors before they are planted into the procedure. The teacher's attention is focused on the learning system's perceptual and inferential shortcomings through a metaphorical apprentice called Metamouse, which generalizes action sequences on the fly and eagerly carries out any actions it can predict. The success of the induction process is assessed quantitatively by counting erroneous predictions made during example tasks.
1989	A system for example-based programming	We present an approach to programming environments that integrates syntax-directed editors with concepts borrowed from software reuse. We call our approach example-based programming , and we define it as programming using examples as visual aids or to fully or partially copy into programs. To implement an example-based programming environment, we augmented a syntax-directed editor with a window for example programs. The example programs, which are easily accessible, can be used as examples of language constructs, thus providing syntactic information through instantiations of templates, or as examples of algorithms or programs. The code in the example window can be viewed, totally or partially copied, or run. We discuss the motivation for example-based programming, describe our system implementing example-based programming in greater depth, and report on the results of an experiment to see how the system is used by programmers.
1990	CHI systems, incorporated (lab review)	CHI Systems Incorporated was formed in 1985 to provide high quality research and development services and products related to Computer-Human Interaction (CHI). We focus on specialized or expert domains — environments where the typical user is highly expert in the application task being performed. Within these domains, we emphasize: cognitive analysis of the task and the expertise it requires, allocation of functions between computer and human, and design of interfaces and intelligent support tools for domain-expert system users. We design and apply advanced methodologies and design/analysis tools for each of these steps. The primary domains in which we work are aerospace, command and control, and biotechnology. CHI Systems functions as both an applied and basic research laboratory. In applied research, we develop innovative solutions to real-world problems in CHI posed by our clients. In basic research, we investigate basic problems involved in the design and analysis of interfaces for domain-expert end-users. We also emphasize formal and/or theory-based approaches. We have developed tools for: formal specification of object-oriented interfaces, simulation-based function allocation and task analysis of new interface systems, cognitive analysis and functional design of decision support systems, and cognitive task analysis of CHI in real-time multitasking environments
1990	User interface requirements for face to face groupware	This paper discusses the user interface of the Capture Lab, a computer-supported meeting room that has been in operation since late 1987. One goal of the Capture Lab design is to support meetings of business people (who are often novice computer users) without requiring an additional person to serve as a computer technician or facilitator. This paper discusses the user interface features a system should have to support face to face meetings. It describes the Capture Lab and how it is used, and presents our approach to satisfying those interface requirements. Finally, we discuss a few of our observations about the Capture Lab's user interface, and how a computer-supported meeting environment affects meetings.
1990	Collaboration awareness in support of collaboration transparency: requirements for the next generation of shared window systems	Shared window systems enable existing applications to be shared in the context of a real-time teleconference. The development and successful use of several such systems, albeit within limited user communities, testifies to the merits of the basic idea. However, experience to date has suggested a number of areas that have not been adequately addressed, namely: spontaneous interactions, shared workspace management, floor control, and annotation and telepointing. This paper focuses on the ramifications, for the software designer, of various user requirements in these areas. While the recommendations that result are motivated by the desire to enable continued use of collaboration-transparent applications, addressing them involves the development of systems software that is distinctly collaboration-aware .
1990	VideoDraw: a video interface for collaborative drawing	This paper describes VideoDraw, a shared drawing tool, and the process by which it is being designed and developed. VideoDraw is a prototype, videobased, tool that provides a shared “virtual sketchbook” among two or more collaborators. It not only allows the collaborators to see each others' drawings, but also conveys the accompanying hand gestures and the process of creating and using those drawings. Its design stems from studying how people collaborate using shared drawing spaces. Design implications raised by those studies were embodied in a prototype, which was in turn observed in use situations. Continued research studying the use of VideoDraw (in comparison with other collaborative media) will lead to a better understanding of collaborative drawing activity and inform the continued technical development of VideoDraw.
1990	Infinite detail and emulation in an ontologically minimized HCI	By default, we attempt to define practical areas of technological endeavor as “applications.” For example, the applied psychology of human-computer interaction has characteristically been defined in terms of the methods and concepts basic psychology can provide. This has not worked well. An alternative approach is to begin from a characterization of current practice, to take seriously the requirements of the domain of endeavor, and to define areas of “science” and “application” as possible and appropriate in that context.
1990	Contextual design: an emergent view of system design	We offer an introduction to contextual design as an emergent method for building effective systems. Contextual design addresses a number of the inadequacies in previous methods by emphasizing: interview methods conducted in the context of the user's work, codesigning with the user, building an understanding of work in context, and summarizing conclusions through out the research. We contrast this design method to usability engineering and artifact examination.
1990	Using critics to empower users	We describe the critiquing approach to building knowledge-based interactive systems. Critiquing supports computer users in their problem solving and learning activities. The challenges for the next generation of knowledge-based systems provide a context for the development of this paradigm. We discuss critics from the perspective of overcoming the problems of high-functionality computer systems, of providing a new class of systems to support learning, of extending applications-oriented construction kits to design environments, and of providing an alternative to traditional autonomous expert systems. One of the critiquing systems we have built — JANUS, a critic for architectural design — is used as an example of the key aspects of the critiquing process. We also survey additional critiquing systems developed in our and other research groups.
1990	Reflections on participatory design: lessons from the trillium experience	In recent years system engineers, product designers, and human interface designers have become increasingly interested in developing ways of involving users in the design and evolution of computer-based systems. Some have turned for guidance and inspiration to an approach to systems design pioneered in Scandinavia and often referred to as Participatory Design. In this paper we examine the development of a computer-based design tool, Trillium, which on the surface looked like an example of Participatory Design in that users were directly involved in the development of the technology. Our analysis leads us to conclude, however, that Trillium's development departed in critical ways from our current model of Participatory Design and to suggest that the manner in which users are involved in the development effort plays an important role in the success of the endeavor.
1990	The organizational implementation of an electronic meeting system: an analysis of the innovation process	Electronic Meeting Systems (EMS) are slowly moving out of university environments into work organizations. They constitute an innovative method of supporting group meetings. This paper reports on the innovation process in one organization that has recently adopted and implemented an EMS. The paper traces the innovation process through four stages: conception of an idea: proposal; decision to adopt; and implementation. Important factors from the innovation literature are considered as explanators of the innovation process involving EMS in this particular organization.
1990	Design of a loading plan format for an expert cargo loading system	Many computer systems assist users in the performance of tasks by providing metaphors for the tasks themselves. The success of such systems hinge on how accurately and effectively the user interface represents those tasks. In this paper we describe such a representation for the task of loading boxed appliances into truck trailers. This representation was used to provide the format for the loading plans generated by an expert system constructed to plan the loading of such products. These plans tell the warehouse personnel that actually load the trucks just where each product is to be placed in the truck, how it is to be oriented, as well as where extra padding and filler material should be placed.
1990	Research for human-computer interaction at the MRC Applied Psychology Unit (lab review)	Since its formation in World War II, and under a series of distinguished directors (Craik, Bartlett, Mackworth, Broadbent, and currently, Baddeley), the APU has developed a broad base of research capability. Areas now covered are audition, vision, attention, memory, language, reasoning, motor behavior, psychophysiology, clinical and neuropsychology. Our work on human interaction with real world artifacts focuses on the preparation and comprehension of information in documents, car driving, and, of course, the use of computers. Across these areas, the APU has often played a pioneering role, not only in individual research contributions, but in helping to establish the paradigms, theory, and practice of a given field of research. The Unit is funded by the Department of Education and Science through the Medical Research Council. Our core budget is supplemented by external grants and contracts, providing in total for a research staff of around 45 and a support staff of 30. Each year we also have 10-12 graduate students and 6-15 visiting scientists.
1990	Evaluating hypermedia systems (panel)	Hypermedia systems provide online access to complex networks of information with the goal of making it easier to find and use information. To validate the utility of their systems, several researchers and system developers have attempted to collect evaluation data on the usability and effectiveness of their systems and the features in their systems. Because of the potential complexity of hypermedia systems and the information structures they may represent, a variety of evaluation measures and methods have been used. These trade off the need for timely feedback in the development of new technology, the difficulty of controlling one or two variables in systems with dozens or hundreds of components, and the goal of gaining an understanding of hypermedia systems.
1990	Designers' models of the human-computer interface	An experiment investigated the organization of declarative knowledge about the human computer interface (HCI). Two groups of experts in user interface design (human factors experts and software experts), and a control group sorted HCI concepts into categories. The data were transformed into measures of dissimilarity and analyzed using (1) hierarchical cluster analysis and (2) Pathfinder, a program that generates network representations of the data. Both expert groups had greater numbers of clusters, more elaborate clusters, and better organized networks than did the controls. The two expert groups differed with respect to the clustering of concepts related to display coding and software. The Pathfinder networks for the two expert groups differed in organization, with human factors experts' networks consisting of highly interrelated subnetworks and software experts networks consisting of central nodes and fewer, less interconnected subnetworks. The networks also differed in the number of concepts linked with such concepts as graphics, natural language, function keys, and speech recognition. The discussion focuses on (1) specific differences in cognitive models between HCI experts and novices and between different types of experts, and (2) the role of cognitive models in HCI design and in communications within a multidisciplinary design team.
1990	Semantic analysis during exploratory learning	This paper addresses the problem of how a novice computer user, engaged in exploratory learning, accounts for the behaviour of the device. Exploratory learning is the norm for many users who encounter computers in the work place. Exploratory learners must acquire methods from a suboptimal stream of task directed behaviour and its observable effects. A candidate model of analysis, EXPL [9] is taken as the baseline for the development of a new model, called Explor, which employs semantic knowledge of the lexical items used in the interface to relate user actions to system responses. The strengths and weaknesses of Explor are illustrated and discussed.
1990	Empowering the student: prospects for an unintelligent tutoring system	Computer based instructional systems either direct students so modelling their actions is tractable, or provide them with total autonomy, but give little support to learning and problem solving processes. Instructional principles for empowering the student are emerging whereby more of the responsibility of diagnosis and goal-setting is placed on the student. Critical to this view is providing an environment which makes the ramifications of students' actions clear so students can meaningfully assess their own performance. In the domain of word algebra, the meaning of formal expressions can be reflected in computer animation which depicts the corresponding situation. An unintelligent tutor — knowing nothing of the problem being solved and possessing no student model — helps students to understand problems and debug formal expressions.
1990	Track—a trace construction kit	TRACK is a kit to interactively construct environments that trace the execution of methods and the flow of messages between SMALLTALK-80 objects. It enables the user to set up traces by means of direct manipulation. This is done by placing obstacles between icons representing specific classes and instances much in the way a jumping course is set up. TRACK may be used to generate multiple visualizations of programs which may be concurrently run. It is a browsing and debugging tool as well as an algorithm animation tool. TRACK is tightly integrated with the standard tools of the SMALL- TALK-80 programming environment.
1990	Smalltalk scaffolding: a case study of minimalist instruction	A curriculum was developed to introduce users to the Smalltalk object-oriented programming language. Applying the Minimalist model of instruction [3], we developed a set of example-based learning scenarios aimed at supporting real work, getting started fast, reasoning and improvising, coordinating system and text, supporting error recognition and recovery, and exploiting prior knowledge. We describe our initial curriculum design as well as the significant changes that have taken place as we have observed it in use.
1990	A view matcher for learning Smalltalk	The View Matcher is a structured browser for Smalltalk/V. It presents a set of integrated and dynamic views of a running application, intended to coordinate and rationalize a programmer's early understanding of Smalltalk and its environment. We describe the system through two user scenarios involving exploration of the model-view-controller paradigm.
1990	Designers: meet your users (panel)	Too few interface designers actually use an iterative design process. Too few interface designers actually involve their anticipated users throughout the design of an interface. In order to build better interfaces, we need to build faster and more numerous prototypical interface examples. These prototypes, from early sketches to working systems, should be shown frequently and often to users for their feedback. This panel is a vignette that illustrates an interface design cycle. Our panelists will be given a real world interface design problem, and the audience will follow them through their usual process of design. Users will be involved in the process, to help in interface specification and to provide prototype feedback. We expect that although the panelists involved users throughout their design process, users will still have a good deal more to contribute to the interface design before a product is finalized. On stage we will witness real users, with varied backgrounds, providing comments and feedback on the working prototypes. The issue here is to remind designers that there is never enough user involvement in an interface design. We need to iterate our interface designs, based on users' feedback, more often and continuously if our interfaces are to be effective,
1990	What can we teach about human-computer interaction? (plenary address)	This paper is the closing address for CHI '90. It addresses the problem of educating computer professionals in the area of human-computer interaction, arguing that standard approaches within computer science need to be augmented and that new models of education can aid us in producing students with broad competence in the design of computer systems for human use.
1990	Designing casual-user hypertext: the CHI'89 InfoBooth	An interactive electronic information kiosk was created for the CHI '89 conference. Based on Macintosh® technology, the “InfoBooth” included a custom HyperCard® interface built by a team at Apple Computer. The design was initiated by examining the desires of potential users. Design changes, influenced by the results of informal user testing, were numerous. During the conference, user actions were recorded using an embedded “trace” program to allow for later usage assessment. This paper offers a case study for designers of similar systems. Aspects of the pre-conference design evolution are described. The impact of user testing is discussed and findings from the analysis of the trace data are presented.
1990	Redefining tomorrow's user interface (plenary address)	When computers first appeared, input-output commands were minor afterthoughts to cohesive, often well crafted and occasionally pretentious programming languages. Today, these commands occupy over 70 percent of a programming system's instructions. Yet they, along with the user interface structures that they define, are far from cohesive, and, at least up until now, immune to standardization. We must therefore turn our thinking around and create a new breed of programming languages that are first and foremost input-output oriented and that integrate traditional processing commands into new user-oriented structures. And just as we know today that traditional commands fall into a handful of fixed categories - decision, repetition, naming, procedure definition and use — we need to search for and identify the corresponding natural classes of commands for user interfaces. But even if user interfaces were ideally programmed in divine new languages, they would still be ineffective, under our current mindset. For it is an unfortunate fact that despite a great deal of hype about look and feel, today's user interfaces have not appreciably reduced the difficulty of interaction between humans and machines. How can we explain, for example, the disturbing paradox that although computing accounts for some 10 percent of the U.S. G.N.P., it has not resulted in any measurable gains in conventionally measured productivity except in very few areas, like computer aided design. In fact, among office workers, net productivity seems to have decreased during the same period that computer purchases and uses have surged. Let us then ask what we should do in tomorrow's user interfaces to increase productivity and empower people, as the theme of this conference charges. In simpler terms, let us turn our attention on what we can do to help ordinary mortals who are trying to get a job done in spite of the well meaning efforts of hardware and software designers and managers. I, for one, believe that we can do a great deal and can improve immensely human-computer productivity. For example, we can ensure that people do not succumb to the additive fault of doing in the computer age, all that they did before plus a whole set of new actions — this is one of the most common ways of wasting human work. We should also avoid the learning fault by trying to reduce radically the amount of new knowledge that must be learned and retained by information workers, even if the resultant power and flexibility loom seductively before us. And we should design our systems and procedures so that they do not encourage the perfection fault, i.e. working on our systems well beyond the point of diminishing returns, in the interest of perfection. Much more can and should be done, for example by making user interfaces smarter so that they can anticipate, even small portions of our intent, instead of brutally forcing us through a litany of repetitive and dumb rituals. And we should ensure that our machines enable and enhance rather than fight human-to-human interaction and coordination, which is such an important part of our everyday productive activity. These issues and observations raise serious questions of balance among extremes that are today either addressed indirectly or downright ignored. For example, in tomorrow's interface, will users crave for aesthetics or intelligence? Flexibility and power, or simplicity? Integration or isolation of disparate user systems? A brave new world of flat screens, 3-d CRT goggles and speech and gesture detectors, — or more effective use of blander systems? And what are we going to do to plan, measure and ensure that the vocabulary of user intent is well matched by the vocabulary of interface actions? It is these kinds of questions that we need to address from the common-sense perspective of making computers effective and useful to ordinary people. No one is potentially better suited for doing this than the professional whose responsibility is the interface between people and machines. But to do this, we need to redefine the profession, from its current narrow confines of dealing with windows, mice and ergonomic factors to a far broader discipline that encompasses and seeks to improve everything that humans and computers do together, including purpose — in other words the total user interface of and for tomorrow.
1990	A gaze-responsive self-disclosing display	An information display system is described which uses eye-tracking to monitor user looking about its graphics screen. The system analyzes the user's patterns of eye movements and fixations in real-time to make inferences about what item or collection of items shown holds most relative interest for the user. Material thus identified is zoomed-in for a closer look, and described in more detail via synthesized speech.
1990	What you look at is what you get: eye movement-based interaction techniques	In seeking hitherto-unused methods by which users and computers can communicate, we investigate the usefulness of eye movements as a fast and convenient auxiliary user-to-computer communication mode. The barrier to exploiting this medium has not been eye-tracking technology but the study of interaction techniques that incorporate eye movements into the user-computer dialogue in a natural and unobtrusive way. This paper discusses some of the human factors and technical considerations that arise in trying to use eye movements as an input medium, describes our approach and the first eye movement-based interaction techniques that we have devised and implemented in our laboratory, and reports our experiences and observations on them.
1990	Measuring the true cost of command selection: techniques and results	A technique that measures the impact of command selection on task time and errors is described. Users were timed while performing a drawing task, then while performing the same task with interpolated command selections. The difference between these times, consisting of both the time to select the command and to resume drawing, is the time cost of command selection. Several interface configurations were evaluated with this method including selected combinations of single mouse, two mice, voice and touch. Touch and voice input resulted in faster command selection times (approximately 1 sec) than any of the mouse conditions (approximately 3 sec).
1990	Automatic, look-and-feel independent dialog creation for graphical user interfaces	Jade is a new interactive tool that automatically creates graphical input dialogs such as dialog boxes and menus. Application programmers write a textual specification of a dialog's contents. This specification contains absolutely no graphical information and thus is look-and-feel independent. The graphic artist uses a direct manipulation graphical editor to define the rules, graphical objects, interaction techniques, and decorations that will govern the dialog's look-and-feel, and stores the results in a look and feel database. Jade combines the application programmer's specification with the look-and-feel database to automatically generate a graphical dialog. If necessary, the graphic artist can then edit the resulting dialog using a graphical editor and these edits will be remembered by Jade, even if the original textual specification is modified. By eliminating all graphical references from the dialog's content specification, Jade requires only the absolutely minimum specification from the application programmer. This also allows a dialog box or menu's look and feel to be rapidly and effortlessly changed by simply switching look and feel databases. Finally, Jade permits complex inter-field relationships to be specified in a simple manner.
1990	Surface interaction: a paradigm and model for separating application and interface	From the point of view of the application designer, user interface services work by factoring some domain common to a range of applications, and implementing this separately. Existing services, such as window managers, UIMSs, or toolkits, either lack generality, or are limited in their separability. A new interface paradigm, here called surface interaction , separates application and interface by factoring presentation and its manipulation, rather than dialogue or functionality. The surface is thus a medium which can be controlled equally by the user or by the application. This paper outlines Presenter , an implementation of a model for surface interaction.
1990	Using constraints to achieve stability in automatic graph layout algorithms	Automatic layout algorithms are commonly used when displaying graphs on the screen because they provide a “nice” drawing of the graph without user intervention. There are, however, a couple of disadvantages to automatic layout. Without user intervention, an automatic layout algorithm is only capable of producing an aesthetically pleasing drawing of the graph. User- or application-specified layout constraints (often concerning the semantics of a graph) are difficult or impossible to specify. A second problem is that automatic layout algorithms seldom make use of information in the current layout when calculating the new layout. This can also be frustrating to the user because whenever a new layout is done, the user's orientation in the graph is lost. This paper suggests using layout constraints to solve both of these problems. We show how user-specified layout constraints may be easily added to many automatic graph layout algorithms. Additionally, the constraints specified by the current layout are used when calculating the new layout to achieve a more stable layout. This approach allows a continuum between manual and automatic layout by allowing the user to specify how stable the graph's layout should be.
1990	Propositional production systems for dialog description	The Propositional Production System (PPS) for describing interactive dialogs is defined. It is shown to be a superset of state machines, window event translation tables and event response systems. It is shown how dialogs can be expanded by means of inheritance and how semantic control information can be uniformly integrated into the dialog model. Optimizations are defined which can tune the executable machine for either minimal space or minimal execution time.
1990	Adaptive semantic snaping—a technique for semantic feedback at the lexical level	This paper describes the implementation of semantic snapping — an interaction technique that provides semantic feedback at the lexical level while dragging a graphical object on the screen. Like conventional snapping, or gravity fields , semantic snapping includes a geometric component where objects in close proximity are drawn together or “snap” into position. However, semantic snapping goes further by allowing non-geometric (semantic) properties of objects to place additional constraints on snapping. Semantic snapping also provides more complex lexical feedback which reflects potential semantic consequences of a snap. This paper motivates the use of semantic snapping and describes how this technique has been implemented in a window-based toolkit. This implementation works in an adaptive manner to provide the best interactive response in situations where semantic tests are very time consuming and strain the limits of acceptable performance.
1990	Help by guided tasks: utilizing UIMS knowledge	A help delivery mechanism integrated with a semantic UIMS is presented. The guided task paradigm is implemented where a user participates in a guided step-by- step demonstration. Help authors create task scripts composed of statements drawn from the semantic definition of the user interface. The help delivery system automatically translates such statements into user instructions which guide the user through the actions necessary to accomplish a task. Any application developed using this UIMS automatically gets this help authoring and presentation facility with no added effort.
1990	Human-computer interaction research at the University of Illinois (lab review)	The Engineering Psychology program at the University of Illinois is interdisciplinary in nature and involves the participation of faculty members, undergraduate, graduate and post-doctoral students from the Department of Psychology, Department of Industrial Engineering, the Institute of Aviation, and the Beckman Institute. While the interests of the faculty members and the students run the gamut from nuts and bolts ergonomics to the design of intelligent systems there are two topics, the design of displays and the acquisition of perceptual-motor and cognitive skills, which serve as a unifying focus of research in Human-Computer Interaction. The examination of issues in display design and skill acquisition ranges from basic research on visual psychophysics and automatization to applied research and design projects on aviation displays and computer-based tutorials. Three laboratories within the Engineering Psychology program contribute to these research efforts: the Visual Information Processing laboratory, the Human-Computer Interaction laboratory, and the Aviation Research laboratory. In the description that follows we will indicate the mission of each of these laboratories and the manner in which they contribute to the interdisciplinary research programs on displays and skill acquisition. The core faculty members conducting Human-Computer Interaction research within the interdisciplinary Engineering Psychology program include: John Andersen (Psychology) John Flach (Engineering) Arthur Kramer (Psychology) Gavan Lintern (Aviation) George McConkie (Psychology) Neville Moray (Engineering) Penelope Sanderson (Engineering) Alan Stokes (Aviation) Brian Ross (Psychology) Christopher Wickens (Aviation)
1990	User interface and quality planning department (lab review)	The primary mission of the User Interface and Quality Planning Department is to design user interfaces for AT&T network-based products and services. Working with other members of the Research and Development community, we strive to develop high quality user interfaces. We bring special expertise in the design of graphical user interfaces for customer network management, in the design of interfaces for voice-based network services, and in the use of state-of-the-art technology for documentation and training. Our work covers products and services for users both outside of AT&T and inside AT&T (e.g., attendants and technicians). The User Interface and Quality Planning Department also plays a leadership role in maintaining a company-wide community of behavioral scientists. The department consists of four user interface groups and one quality planning group. With quality planning and user interface design in the same department, we can effectively highlight the importance of the user interface to the user's perception of quality. The user interface groups are directly funded by AT&T business units for user interface design work on specific products and services. Bruce Fetz is the Department Head; there are four user interface supervisors and about 23 Members of Technical Staff (MTS). The supervisors and MTS have doctorates in some area of experimental psychology; many also have a strong background in computer science. In addition, there are several laboratory support people, and we bring in software developers as they are needed on specific projects. Our user interface laboratory has development, testing, and presentation rooms, with flexible configuration and communication capabilities. Our equipment includes a high-capacity network of Sun workstations, and state-of-the-art audio/video production and editing equipment. Our philosophy regarding human factors work in service and product development has two major themes. First, human factors specialists should work as full team members with the product planners, systems engineers and developers responsible for a service or product. Second, human factors specialists should be involved as team members throughout the entire product realization process — from initial concept, through design and development, to customer evaluation after the product or service has been introduced. Rapid prototyping (of both voice-based user interfaces and graphical user interfaces) is central to our design process. Prototypes allow us to try out design concepts, to obtain feedback from users at every stage of the design process, to communicate our ideas more effectively, and to conduct laboratory evaluations. At the end of the design process, prototypes often serve as the “user interface requirements” for a product. In addition to product-specific efforts, we also engage in exploratory design and development using new user interface technologies. Also, department members contribute to the creation and evaluation of user interface standards that support the consistency of user interfaces across different products and services.
1990	Human computer interaction group, University of York, U.K. (lab review)	Staff in the Departments of Computer Science and Psychology at the University of York have been cooperating in interdisciplinary research since 1983. The mainstream of York's approach is to apply theory developed in these parent disciplines to HCI design. Our goal is to integrate formal and empirical methods. By formal methods we mean mathematical models that are capable of capturing properties of a user interface. By empirical methods we mean the observation and measurement of user behaviour. Integration of these two approaches is achieved by an iterative design process in which formal models are successively refined by testing their predictions against the results of user trials.
1990	Using a knowledge analysis to predict conceptual errors in text-editor usage	The knowledge analysis of a device and a task, when written in an external Instruction Language and translated into rules for a programmable cognitive architecture, enables a designer to predict conceptual errors in device usage. This kind of prediction lies outside the scope of GOMS-based models. The cognitive architecture, which is referred to as a “Programmable User Model” (PUM), incorporates a limited problem-solving capability based upon means-ends analysis and multiple problem spaces. The example presented, concerning a simple text editor, illustrates the application of a PUM and demonstrates that a correct description of local knowledge does not necessarily lead to correct behaviour. This can serve to alert the designer to difficulties with the usability of a proposed interface.
1990	Designing minimal documentation using a GOMS model: a usability evaluation of an engineering approach	The Minimal Manual proposed by Carroll, Smith-Kerker, Ford, and Mazur [6] has been demonstrated to improve the performance of novices learning a word processing system. However, little research exists to suggest a practical methodology for implementing the important features of a minimal manual. Using the GOMS model, we incrementally modified a manual to include certain minimal manual features: reduced verbiage, focus on real tasks, and error recovery support. An evaluation of the manuals with novice users demonstrated significant improvements in learning performance when the manual was modified to be task-oriented with explicit procedural steps for accomplishing real tasks.
1990	Extensions of GOMS analyses to expert performance requiring perception of dynamic visual and auditory information	GOMS models of telephone toll and assistance operators (TAOS) are being constructed in an effort to provide theoretical predictions of expert performance on several dedicated workstations. This applied effort has pushed the development of GOMS modeling techniques into the area of speech input and output, and into a task where information is not always available when it is required by the TAO. This paper describes the task, heuristics for constructing the GOMS models, and parameters for making quantitative predictions of performance time.
1990	The design space of input devices	A bewildering variety of devices for communication from humans to computers now exists on the market. In order to make sense of this variety, and to aid in the design of new input devices, we propose a framework for describing and analyzing input devices. Following Mackinlay's semantic analysis of the design space for graphical presentations, our goal is to provide tools for the generation and test of input device designs. The descriptive tools we have created allow us to describe the semantics of a device and measure its expressiveness . Using these tools, we have built a taxonomy of input devices that goes beyond earlier taxonomies of Buxton & Baecker and Foley, Wallace, & Chan. In this paper, we build on these descriptive tools, and proceed to the use of human performance theories and data for evaluation of the effectiveness of points in this design space. We focus on two figures of merit, footprint and bandwidth, to illustrate this evaluation. The result is the systematic integration of methods for both generating and testing the design space of input devices.
1990	Stereophonic and surface sound generation for exploratory data analysis	The analysis and interpretation of very high dimensional data require the development and use of data presentation techniques that harness human perceptual powers. The University of Lowell's Exploratory Visualization project (Exvis) aims at designing, implementing, and evaluating perceptually-based tools for data presentation using both visual and auditory domains. This paper describes several auditory data presentation techniques, including the generation of stereophonic sound with apparent depth and sound that appears to emanate from a two-dimensional area. Both approaches can produce sound with auditory texture .
1990	Issues in multimedia interface design: media integration and interface agents	A central challenge in the design of multimedia databases is integrating information from different media sources while reducing the cognitive load imposed on users by the tasks of learning and operating the interface. In light of results from a prototype multimedia project developed at Apple, we believe that an agent-style interface addresses this challenge in several ways. This paper discusses techniques for achieving media integration and details the use of interface agents in facilitating 'navigation', enhancing content through point of view, and supporting users in a variety of instrumental and experiential tasks.
1990	Usable OCR: what are the minimum performance requirements?	Forty-two subjects used a microcomputer and word processing software to type and proofread a 450-word document and then to correct errors in a number of other documents (of the same length) that had been created by OCR simulation [i.e., the documents looked like those typically obtained when using an optical character recognition (OCR) device for text entry]. The “OCR documents” contained both recognition errors (substitution errors, insertion errors, and deletion errors) and unrecognized characters. The percentage of characters requiring correction was varied from document to document. Text entry by OCR was found to be faster than manual entry (i.e., typing) if the OCR device can correctly recognize at least 94\% of the individual alphanumeric characters. However, 98\% correct recognition and computer-assisted proofreading were required in order to consistently obtain finished documents that had no more residual errors than typed documents.
1990	Spreadsheet-based interactive graphics: from prototype to tool	The NoPumpG prototype [7,8] suggested that the spreadsheet model of computation could simplify the creation of some types of interactive graphical application when compared with other approaches. We report here experience in developing an enhanced follow-on system, NoPumpII, and describe three applications developed using it. We conclude that (1) the potential advantages of the spreadsheet model are realized in this application experience, (2) revisions to the prototype design have permitted an increase in the complexity and scale of applications, and (3) there remain limitations in the current design which, if redressed, would further enlarge the scope of application. More generally we conclude that alternative computational models are an important area of exploration for HCI research.
1990	Business instrument panel: a new paradigm for interfacing with financial data	The business instrument panel uses visualization to present, in a comprehensive and integrated manner, all the important elements found in traditional financial statements. By means of analog representation in a simple computer generated picture, the business instrument panel replaces the four traditional financial statements (balance sheet, income statement, cash flow statement, and retained earnings statement). The business instrument panel also embodies a new paradigm for understanding the business world and empowers the user with an unparalleled quick understanding of any firm.
1990	Tools for interaction with the creative process of composition	This paper explores the nature of creative composition particularly as it applies to dance, and describes the development of interactive computer based tools to assist the composer. The hierarchical nature of the composition process calls for an interface which allows the composer the flexibility to move back and forth between alternate views and conceptual levels of abstraction. COMPOSE, an interactive system for the composition of dance has been implemented on Silicon Graphics and Apple workstations. The user visually composes in space and in time using menus of postures and sequences. Paths can be edited and an animation of the dance composition allows the final result to be evaluated.
1990	User-tailorable systems: pressing the issues with buttons	It is impossible to design systems which are appropriate for all users and all situations. We believe that a useful technique is to have end users tailor their systems to match their personal work practices. This requires not only systems which can be tailored, but a culture within which users feel in control of the system and in which tailoring is the norm. In a two-pronged research project we have worked closely with a group of users to develop a system to support tailoring and to help the users evolve a “tailoring culture”. This has resulted in a flexible system based around the use of distributed on-screen Buttons to support a range of tailoring techniques.
1990	End-user modifiability in design environments	Convivial systems encourage users to be actively engaged in generating creative extensions to the artifacts given to them. Convivial systems have the potential to break down the counterproductive barrier between programming and using programs. Knowledge-based design environments are prototypes for convivial systems. These environments support human problem-domain communication, letting users work within their domains of expertise. One of the design rationales behind design environments is to ease the construction and modification of artifacts designed within the environment. But because design environments are intentionally not general purpose programming environments, situations will arise that require modifications to the design environment itself. The rationale and the techniques for these later modifications are discussed in this paper. Our conceptual framework for end-user modifiability is illustrated in the context of JANUS, an environment for architectural design. Evaluating our system building efforts against our objectives shows the subtleties of integrating end-user modifiability in these kinds of systems.
1990	Data characterization for intelligent graphics presentation	An automatic presentation system is an intelligent interface component which receives information from a user or application program and designs a combination of graphics and text that effectively conveys it. It is a facility that assumes the presentation responsibilities for other programs. An important research question has been how information should be specified or described by an application program for it to be presented by an automatic presenter. This paper proposes a taxonomy of information characteristics which would need to be provided to either human or computer designers for them to create presentations reflecting the individual needs of a diverse group of users. The proposed taxonomy of characteristics defines the representational goals for intelligent interfaces which reason about graphical displays.
1990	IShell: a visual UNIX shell	IShell is a visual user interface for interaction using gestures under the UNIX operating system. A visual script language for building commands — IScript — is an integral part of the IShell environment. The user can directly describe and execute pipelined command sequences using gestures. The user is constantly guided by visual cues.
1990	Powermice and user performance	Claims of increased pointing speed by users and manufacturers of variable-gain mice (“powermice”) have become rife. Yet, there have been no demonstrations of this claim, and theoretical considerations suggest it may not even be true. In this paper, the claim is tested. A search of the design space of powermice failed to find a design point that improved performance compared to a standard mouse. No setting for the gain for a constant-gain mouse was found that improved performance. No threshold setting for a variable gain mouse was found that improved performance. In fact, even gain and threshold combinations favored by powermouse enthusiasts failed to improve performance. It is suggested that the real source of enthusiasm for powermice is that users are willing to accept reduced pointing speed in return for a smaller desk footprint.
1990	A comparison of selection time from walking and pull-down menus	This paper reports on an experiment that investigated factors which effect selection time from walking menus and bar or pull-down menus. The primary focus was on the use of impenetrable borders and on expanding target areas on the two menus types. The results show that both factors can be used to facilitate menu selection, with the use of borders being most beneficial. In addition, the results suggest that even on large monitors, the time required to access items from a bar menu is less than that required for the best walking menu.
1990	How does Fitts' law fit pointing and dragging?	Two experiments examined selecting text using a movement sequence of pointing and dragging. Experiment 1 showed that, in the Point-Drag sequence, the pointing time was related to the pointing distance but not to the width of the text to be selected; in contrast, pointing time was related to both the pointing distance and the width of the text in the Point-Click sequence. Experiment 2 demonstrated that both the pointing and dragging times for the Point-Drag sequence were sensitive to the height of the text that was selected. The discussion of the results centers around the application of Fitts' Law to pointing and dragging in a point-drag sequence, proposing that the target for pointing is the leftmost edge of the text to be selected, and the target for dragging is the rightmost edge of the text.
1990	Testing a walkthrough methodology for theory-based design of walk-up-and-use interfaces	The value of theoretical analyses in user interface design has been hotly debated. All sides agree that it is difficult to apply current theoretical models within the constraints of real-world development projects. We attack this problem in the context of bringing the theoretical ideas within a model of exploratory learning [19] to bear on the evaluation of alternative interfaces for walk-up-and-use systems. We derived a “cognitive walkthrough” procedure for systematically evaluating features of an interface in the context of the theory. Four people independently applied this procedure to four alternative interfaces for which we have empirical usability data. Consideration of the walkthrough sheds light on the consistency with which such a procedure can be applied as well as the accuracy of the results.
1990	Updating an older interface	Much of the research in the field of human/computer interface is aimed at the interface designer who begins from scratch. A different set of needs confronts the designer who must update an existing interface without throwing away the good elements of the old design and the knowledge base of experienced users. In this paper, the factors that contribute to the need for interface changes are presented, along with the special challenges that make change more difficult than new design. Approaches are suggested for dealing with the problems of updating an interface to make it effective for both old and new users.
1990	Heuristic evaluation of user interfaces	Heuristic evaluation is an informal method of usability analysis where a number of evaluators are presented with an interface design and asked to comment on it. Four experiments showed that individual evaluators were mostly quite bad at doing such heuristic evaluations and that they only found between 20 and 51\% of the usability problems in the interfaces they evaluated. On the other hand, we could aggregate the evaluations from several evaluators to a single evaluation and such aggregates do rather well, even when they consist of only three to five people.
1990	The computer reaches out: the historical continuity of interface design	This paper examines the evolution of the focus of user interface research and development from the first production of commercial computer systems in the 1950s through the present. The term “user interface” was not needed in the beginning, when most users were engineers and programmers; it may again become inappropriate when more applications are written for groups than for individuals. But there is a continuity to the outward movement of the computer's interface to its external environment, from hardware to software to increasingly higher-level cognitive capabilities and finally to social processes. As the focus shifts, the approaches to design and the skills required of practitioners changes. In this paper five foci or levels of development are identified. Most development today is positioned in the third level and considerable research is directed at the fourth. Some attention is now being given to the fifth: repositioning the interface in the work group or organization itself. Work at the different levels is not entirely independent, so establishing a comprehensive framework may enable us to position existing research and development efforts and plan future work more effectively.
1990	Developmental scenario analysis of Smalltalk programming	In order to understand long-term learning and the acquisition of expertise, human-computer interaction needs to take a developmental turn. Adopting a developmental approach means using longitudinal research methods, building developmental sequence models of the acquisition of expertise, and analyzing tasks as scenarios specific to developmental levels. The psychology of programming seems particularly amenable to a developmental approach because of the length of time that it takes to become an expert. We propose a model of seven developmental levels for Smalltalk/V programming, and provide sample scenarios for each level. We conclude that developmentally ordered scenarios convey valuable design information that would be lost in the standard “average user” approach to scenarios.
1990	Why good engineers (sometimes) create bad interfaces	This paper presents a view of system design that shows how good engineering practice can lead to poor user interfaces. From the engineer's perspective, the ideal interface reflects the underlying mechanism and affords direct access to the control points of the mechanism. The designer of the user interface is often also the designer of the mechanism (or at least is very familiar with the mechanism), and thus has a strong bias toward basing the interface on the engineering model. The user, however, wants to complete a task, and an interface that is based on the task is often more appropriate than one based on the system mechanism. We discuss these issues, and also discuss where to position the user interface between the poles of the engineering model and the task model.
1990	Human-computer interface laboratory—Virginia Polytechnic Institute and State University (lab review)	A description of the staff, facilities, and research focus of the Human-Computer Interface Laboratory at Virginia Polytechnic Institute and State University is provided. Representative research projects as well as the relationship between this laboratory and the human factors engineering graduate program are also described.
1990	CHI in the applied research divisions at Bellcore (lab review)	Bellcore has several active research programs relevant to human-computer interaction. This talk describes research conducted in the Cognitive Science and Interpersonal Communications Research Groups. We describe their research on information retrieval and on collaboration and pay particular attention to the styles of research employed in these groups and to the way in which behavioral investigations have guided technical invention.
1992	A window system with leafing through mode: BookWindow	This paper describes “Book Window” that we implemented, a window system based on the “book” metaphor, that displays information not by scrolling but by using the animation of paging through. The BookWindow system equips some bookmarks, tabs, etc., by which we can access to an expected page through our requirements. BookWindow can support our work environment which navigates us through information space flexibly, because human beings are quite familiar with “books”.
1992	In search of the ideal prototype	Common wisdom states rapid prototyping will result in a better product. Many tools are available to assist the practitioner in producing prototypes. Yet, few indications exist to show rapid prototyping has substantially improved how products are built. This panel will look at the following issues: Can rapid prototyping dramatically improve product development? How do developers integrate rapid prototyping into their existing development process? Are high fidelity tools helpful or do they actually impede development? What is the ideal prototype and how can we build it?
1992	Edit wear and read wear	We describe two applications that illustrate the idea of computational wear in the domain of document processing. By graphically depicting the history of author and reader interactions with documents, these applications offer otherwise unavailable information to guide work. We discuss how their design accords with a theory of professional work and an informational physics perspective on interface design.
1992	The computer sciences electronic magazine: translating from paper to multimedia	In this paper, we discuss issues in design and usability of the IBM Computer Sciences Electronic Magazine (CSEM). The CSEM is an interactive multimedia translation of a paper magazine. It contains articles describing Computer Sciences projects at the four IBM Research Labs. Combining aspects from print, television, and computers, it is a useful vehicle for studying what we see as a completely new communication medium. We report both our design rationale in creating the magazine and the results of several user studies which helped us understand our successes and failures. These studies are a part of an iterative process through which we have redesigned and improved the CSEM.
1992	Realizing a video environment: EuroPARC's RAVE system	At EuroPARC, we have been exploring ways to allow physically separated colleagues to work together effectively and naturally. In this paper, we briefly discuss several examples of our work in the context of three themes that have emerged: the need to support the full range of shared work; the desire to ensure privacy without giving up unobtrusive awareness; and the possibility of creating systems which blur the boundaries between people, technologies and the everyday world.
1992	Evaluating video as a technology for informal communication	Collaborations in organizations thrive on communication that is informal because informal communication is frequent, interactive, and expressive. Informal communication is crucial for the coordination of work, learning an organization's culture, the perpetuation of the social relations that underlie collaboration, and, in general, any situation that requires communication to resolve ambiguity. Informal communication is traditionally mediated by physical proximity, but physical proximity cannot mediate in geographically distributed organizations. The research described here evaluates the adequacy of a version of a desktop video/audio conferencing system for supporting informal communication in a research and development laboratory. The evaluation took place during a trial in which the system was used by summer employees and their supervisor-mentors. While the system was used frequently, the most common uses and users' assessments suggest that it was used more like a telephone or electronic mail than like physically mediated face-to-face communication. However, some features of its use transcended traditional media and allowed users to gain awareness of their work environment. The paper concludes with a discussion of requirements for successful technology to support informal communication.
1992	Speech patterns in video-mediated conversations	This paper reports on the first of a series of analyses aimed at comparing same room and video-mediated conversations for multiparty meetings. This study compared patterns of spontaneous speech for same room versus two video-mediated conversations. One video system used a single camera, monitor and speaker, and a picture-in-a-picture device to display multiple people on one screen. The other system used multiple cameras, monitors, and speakers in order to support directional gaze cues and selective listening. Differences were found between same room and video-mediated conversations in terms of floor control and amount of simultaneous speech. While no differences were found between the video systems in terms of objective speech measures, other important differences are suggested and discussed.
1992	Human-computer interaction research at Georgia Institute of Technology	HCI research at Georgia Tech is found in three cooperating groups: the Engineering Psychology and Experimental Psychology Programs in the School of Psychology, the Center for Human-Machine Systems Research in the School of Industrial and Systems Engineering, and the interdisciplinary Graphics, Visualization and Usability (GVU) Center. We cooperate via cross-listed courses, having students in one area take a minor in another area, collaborative research projects, serving on Ph. D. committees, joint colloquia and brown bag lunches, and joint appointments. The GVU Center (housed in the College of Computing) and Cognitive Science Program (sponsored by Psychology, Industrial and Systems Engineering, and the College of Computing) involves a number of the same faculty, further enhancing our collaborations.
1992	An interface for interactive spatial reasoning and visualization	An interface for software that creates a natural environment for engineering graphics students to improve their spatial reasoning and 3D visualization skills is described. The skills of interest involve spatial transformations and rotations, specifically those skills that engineers use to reason about 3D objects based on 2D representations. The software uses an intuitive and interactive interface allowing direct manipulation of objects. Animation capability is provided to demonstrate the relationship between arbitrary positions of an object and standard orthographic views. A second skill of interest requires visualization of a cutting-plane intersection of an object. An interface is developed which allows intuitive positioning of the cutting-plane utilizing the metaphor of a “pool of water” in which the object is partially submerged. The surface of the water represents the cutting plane. Adjustment of the pool depth combined with direct manipulation of the object provides for arbitrary positioning of the cutting-plane. Subjective evaluation of the software thus far indicates that students enjoy using it and find it helpful. A formal testing plan to objectively evaluate the software and interface design is underway.
1992	Graphical fisheye views of graphs	A fisheye lens is a very wide angle lens that shows places nearby in detail while also showing remote regions in successively less detail. This paper describes a system for viewing and browsing planar graphs using a software analog of a fisheye lens. We first show how to implement such a view using solely geometric transformations. We then describe a more general transformation that allows hierarchical, structured information about the graph to modify the views. Our general transformation is a fundamental extension to the previous research in fisheye views.
1992	A magnifier tool for video data	We describe an interface prototype, the Hierarchical Video Magnifier, which allows users to work with a video source at fine-levels of detail while maintaining an awareness of temporal context. The technique allows the user to recursively magnify the temporal resolution of a video source while preserving the levels of magnification in a spatial hierarchy. We discuss how the ability to inspect and manipulate hierarchical views of temporal magnification affords a powerful tool for navigating, analyzing and editing video streams.
1992	A research program to assess user perceptions of group work support	Computer support for group work is a technological innovation receiving considerable attention from developmental researchers. This paper reports the preliminary results from two surveys which assessed user perceived needs for various types of group work support. The instruments, distributed to managers and professionals in a variety of organizations, described group support scenarios and associated functions/tools and asked for an assessment of their usefulness to one of the respondent's organizational work groups. Support for between meetings group work was perceived to be more useful than support for either face to face or electronic meetings. Common single user tools were generally perceived to be more useful than multi-user group tools. Individual differences and implications are addressed.
1992	Gardeners and gurus: patterns of cooperation among CAD users	We studied CAD system users to find out how they use the sophisticated customization and extension facilities offered by many CAD products. We found that users of varying levels of expertise collaborate to customize their CAD environments and to create programmatic extensions to their applications. Within a group of users, there is at least one local expert who provides support for other users. We call this person a local developer . The local developer is a fellow domain expert, not a professional programmer, outside technical consultant or MIS staff member. We found that in some CAD environments the support role has been formalized so that local developers are given official recognition, and time and resources to pursue local developer activities. In general, this formalization of the local developer role appears successful. We discuss the implications of our findings for work practices and for software design.
1992	Beyond being there	A belief in the efficacy of imitating face-to-face communication is an unquestioned presupposition of most current work on supporting communications in electronic media. In this paper we highlight problems with this presupposition and present an alternative proposal for grounding and motivating research and development that frames the issue in terms of needs, media, and mechanisms. To help elaborate the proposal we sketch a series of example projects and respond to potential criticisms.
1992	Evaluating two aspects of direct manipulation in advanced cockpits	Increasing use of automation in computer systems, such as advanced cockpits, presents special challenges in the design of user interfaces. The challenge is particularly difficult when automation is intermittent because the interface must support smooth transitions from automated to manual mode. A theory of direct manipulation predicts that this interface style will smooth the transition. Interfaces were designed to test the prediction and to evaluate two aspects of direct manipulation, semantic distance and engagement. Empirical results supported the theoretical prediction and also showed that direct engagement can have some adverse effects on another concurrent manual task. Generalizations of our results to other complex systems are presented.
1992	Iterative design of an interface for easy 3-D direct manipulation	Although computer tools for 3-D design applications are now widely available for use on personal computers, they are unnecessarily difficult to use. Conventions for establishing and manipulating views of 3-D objects require engineering-oriented dialogues that are foreign to most users. This paper describes the iterative design and testing of a new mechanism for moving 3-D objects with a mouse-controlled cursor in a space planning application prototype. Emphasis was placed on developing a design which would make 3-D interaction more intuitive by preserving users' experiences with moving objects in the real, physical world. Results of an informal user test of the current interface prototype are presented and implications for the development of a more general direct manipulation mechanism are discussed.
1992	Computing for users with special needs and models of computer-human interaction	Models of human-computer interaction (HCI) can provide a degree of theoretical unity for diverse work in computing for users with special needs. Example adaptations for special users are described in the context of both implementation-oriented and linguistic models of HCI. It is suggested that the language of HCI be used to define standards for special adaptations. This would enhance reusability, modifiability, and compatibility of adaptations, inspire new innovations, and make it easier for developers of standard interfaces to incorporate adaptations. The creation of user models for subgroups of users with special needs would support semantic and conceptual adaptations.
1992	Prototyping an instructible interface: Moctec	Moctec is a set of interactive mockups of an interface for programming search and replace tasks by example. The user guides inference by pointing at relevant features of data.
1992	The art of search: a study of art directors	We formulated a model of visual search by conducting a work flow study and task analysis of art directors as they searched for images to use in an advertisement. The analysis revealed the presence of artistic and image concepts, flexible structures which guide the search and are molded by them. Analysis results were used to build a model-based interface for visual search. Results from presenting the interface to users indicate that the interface has the potential to make significant contributions to the visual search task, both in time savings and as an aid to the creative process.
1992	Browser-Soar: a computational model of a highly interactive task	Browser-Soar models the perceptual, cognitive, and motor operators of a user searching for information in an on-line help browser. The model accounts for 90\% of the browsing behavior observed in ten episodes. This result suggests that much of browsing behavior is a routine cognitive task, describably by GOMS, and extends the boundary of tasks to which GOMS applies to include highly interactive tasks. Further, it also suggests that GOMS analyses can be used to evaluate text-editors and other computer applications, and to help focus design effort.
1992	Towards task models for embedded information retrieval	This paper investigates to what extent task-oriented user support based on plan recognition is feasible in a highly situation-driven domain like information retrieval (IR) and discusses requirements for appropriate task models. It argues that information seeking tasks which are embedded in some higher-level external task context (e.g. travel planning) often exhibit procedural dependences; that these dependences are mainly due to external task; and that they can be exploited for inferring the users' goals and plans. While there is a clear need for task models in IR to account for situational determinants of user behaviour, what is required are hybrid models that take account of both is “planned” and “situated” aspects. Empirical evidence for the points made is reported from a probabilistic analysis of retrieval sessions with a fact database and from experience with plan-based and state-based methods for user support in an experimental travel planning system
1992	Knowledge-based evaluation as design support for graphical user interfaces	The motivation for our work is that even though user interface guidelines and style guides contain much useful knowledge, they are hard for user interface designers to use. We want to investigate ways of bringing the human factors knowledge closer to the design process, thus making it more accesible to designers. To this end, we present a knowledge-based tool, containing design knowledge drawn from general guideline documents and toolkit-specific style guides, capable of evaluating a user interface design produced in a UIMS. Our assessment shows that part of what the designers consider relevant design knowledge is related to the user's tasks and thus cannot be applied to the static design representation of the UIMS. The final section of the paper discusses ways of using this task-related knowledge.
1992	Controlling user interface objects through pre- and postconditions	We have augmented user interface objects (i.e. windows, menus, buttons, sliders, ets.) with preconditions that determine their visibility and their enabled/disabled status and postconditions that are asserted when certain actions are performed on the object. Postconditions are associated with each functionally different action on the object. Attaching pre- and postconditions to interface objects provides several useful features, such as selective enabling of controls, rapid prototyping, and automatic generation of explanations and help text.
1992	Survey on user interface programming	This paper reports on the results of a survey of user interface programming. The survey was widely distributed, and we received 74 responses. The results show that in today's applications, an average of 48\% of the code is devoted to the user interface portion. The average time spent on the user interface portion is 45\% during the design phase, 50\% during the implementation phase, and 37\% during the maintenance phase. 34\% of the systems were implemented using a toolkit, 27\% used a UIMS, 14\% used an interface builder, and 26\% used no tools. This appears to be because the toolkit systems had more sophisticated user interfaces. The projects using UIMSs or interface builders spent the least percent of time and code on the user interface (around 41\%) suggesting that these tools are effective. In general, people were happy with the tools they used, especially the graphical interface builders. The most common problems people reported when developing a user interface included getting users' requirements, writing help text, achieving consistency, learning how to use the tools, getting acceptable performance, and communicating among various parts of the program.
1992	Orderable dimensions of visual texture for data display: orientation, size and contrast	Vision research relating to the human perception of texture is briefly reviewed with a view to arriving at the principal dimensions of visual texture useful for data display. The conclusion is that orientation, size (1/spatial frequency), and contrast (amplitude) are the primary orderable dimensions of texture. Data displayed using these texture parameters will be subject to similar distortions to those found when color is used. Textures synthesized using Gabor function primitives can be modulated along the three primary dimensions. Some preliminary results from a study using Gabor functions to modulate luminance are presented which suggest that: perceived texture size difference are approximately logarithmic, a 5\% change in texton size is detectable 50\% of the time, and large perceived size differences do not predict small (just noticeable) size differences.
1992	The perceptual structure of multidimensional input device selection	Concepts such as the logical device, taxonomies, and other descriptive frameworks have improved understanding of input devices but ignored or else treated informally their pragmatic qualities, which are fundamental to selection of input devices for tasks. We seek the greater leverage of a predictive theoretical framework by basing our investigation of three-dimensional vs. two-dimensional input devices on Garner's theory of processing of perceptual structure in multidimensional tasks. Two three-dimensional tasks may seem equivalent, but if they involve different types of perceptual spaces, they should be assigned correspondingly different input devices. Our experiment supports this hypothesis and thus both indicates when to use three-dimensional input devices and gives credence to our theoretical basis for this indication.
1992	Extending Fitts' law to two-dimensional tasks	Fitts' law, a one-dimensional model of human movement, is commonly applied to two-dimensional target acquisition tasks on interactive computing systems. For rectangular targets, such as words, it is demonstrated that the model can break down and yield unrealistically low (even negative!) ratings for a task's index of difficulty (ID). The Shannon formulation is shown to partially correct this problem, since ID is always ? 0 bits. As well, two alternative interpretations “target width” are introduced that accommodate the two-dimensional nature of tasks. Results of an experiment are presented that show a significant improvement in the model's performance using the suggested changes.
1992	When TVs are computers are TVs (panel)	This panel brings together experts from TV production with those in the computer multimedia business. They will discuss what is likely to happen when the two media coexist. An exciting opportunity exists in merging the strengths of both media together synergistically to create pervasive and powerful Interactive Television.
1992	Transportable Applications Environment (TAE) Plus user interface designer WorkBench	TAE Plus was built at NASA's Goddard Space Flight Center to support the building of GUI user interfaces for highly interactive applications, such as realtime processing systems and scientific analysis system. TAE Plus is designed as a productivity tool for the user interface designer. Human factor experts and user interface designers frequently do not want to have to learn the programming details of the windowing environment before they use a GUI development tool to prototype and/or develop an application's user interface. TAE Plus has been developed with this user in mind. TAE Plus is a user interface management system that supports (1) interactively constructing the visual layout of an application screen, (2) rehearsing the UI, (3) generating the application source code to manage the UI, (3) generating the application source code to manage the UI, and (4) providing run-time services to manage the UI during application execution.
1992	The art of the obvious	In addition to normal reading, knowledge can be gained from a paper document by pattern recognition and encoding of characteristics of the information media. There are reasons to believe that this can be done automatically with very little attentional demand. The knowledge gained is accessible to consciousness and can be used for task components like orientation, navigation, detection of changes and as a complement to normal reading. When information is computerized, and is read from a screen instead of from a paper, the conditions for automaticity are often radically changed. In most cases the reader has to gain the corresponding knowledge by effortful cognitive processes. This means adding to the cognitive load leaving less attentional capacity for the main task at hand. This problem can be avoided by a careful analysis of a reading task into its automatic and non-automatic components, followed by a dedicated user interface design where information relevant for orientation, navigation, etc. is presented in a way that the reader can perceive rather than read.
1992	A computational model of skilled use of a graphical user interface	This paper describes a computational model of skilled use of a graphical user interface based on Kintsch's construction-integration theory [4, 8]. The model uses knowledge of a detailed representation of information on the display, a user's goals and expectations, knowledge about the interface, and knowledge about the application domain to compute actions necessary to accomplish the user's current goal. The model provides a well-motivated account of one kind of errors, action slips [14], made by skilled users. We show how information about the intermediate state of a task on the display plays a critical role in skilled performance, i.e., display-based problem solving.
1992	A GOMS analysis of a graphic machine-paced, highly interactive task	A GOMS analysis was used to predict the behavior of an expert in a graphic, machine-paced, highly interactive task. The analysis was implemented in a computational model using the Soar cognitive architecture. Using only the information available in an instruction booklet and some simple heuristics for selecting between operators, the functional-level behavior of the expert proved to be virtually dictated by the objects visible on the display. At the keystroke-level, the analysis predicted about 60\% of the behavior, in keeping with similar results in previous GOMS research. We conclude that GOMS is capable of predicting expert behavior in a broader range of tasks than previously demonstrated.
1992	Coupling application design and user interface design	Building an interactive application involves the design of both a data model and a graphical user interface (GUI) to present that model to the user. These two design activities are typically approached as separate tasks and are frequently undertaken by different individuals or groups. Our apporach eliminated redundant specification work by generating an interface directly from the data model itself. An inference engine using style rules for selecting and placing GUI controls (i.e., widgets) is integrated with an interface design tool to generate a user interface definition. This approach allows a single data model to be mapped onto multiple GUI's by substituting the appropriate rule set and thus represents a step toward a GUI-independent run-time layout facility.
1992	Workspaces: an architecture for editing collections of objects	Many tools create new user interfaces by compositing them out of smaller pieces. This usually leads to variations on the dialog box to edit a single composite object. Workspaces are a model for compositing together various editors to manipulate sets of objects and their attributes. The workspace components communicate in terms of a selected set and the attributes possessed by objects in that set. This model has been implemented as part of the Sushi UIMS.
1992	Selectors: going beyond user-interface widgets	Most UI toolkits and UIMSs make use of widgets, e.g., buttons, text fields, sliders, menus. Designers construct user interfaces by choosing and laying out widgets, then connectimg them to application semantics. This approach has four problems. First, most widgets are too low-level; constructing interfaces from them takes too much work. Second, working with widgets focuses attention on appearance and layout issues, rather than on more important semantic design issues. Third, designers can easily make poor widget choices, yielding poor interfaces. Fourth, widgets do not mesh well with application semantics; they know nothing about the variables they control. We are developing an application construction environment in which designers and implementers work with semantic-based controls called Selectors rather than with widgets. Selectors are classified according to their interface semantics (e.g., mutually-exclusive choice), rather than their appearance. Each type of Selector can be presented in a variety of ways; this may be chosen semi-automatically. Selectors mesh well with application semantics: their values are application data-types and their views determine how to present valid values automatically.
1992	A performance model of system delay and user strategy selection	This study lays the ground work for a predictive, zero-parameter engineering model that characterizes the relationship between system delay and user performance. This study specifically investigates how system delays affects a user's selection of task strategy. Strategy selection is hypothesized to be based on a cost function combining two factors: (1) the effort required to synchronize input system availability and (2) the accuracy level afforded. Results indicate that users, seeking to minimize effort and maximize accuracy, choose among three strategies – automatic performance, pacing, and monitoring. These findings provide a systematic account of the influence of system delay on user performance, based on adaptive strategy choice drive by cost.
1992	Method engineering: from data to model to practice	This paper explores the behavior of experts choosing among various methods to accomplish tasks. Given the results showing that methods are not chosen solely on the basis of keystroke efficiency, we recommend a technique to help designers assess whether they should offer multiple methods for some tasks, and if they should, how to make them so that they are chosen appropriately.
1992	The decoupled simulation model for virtual reality systems	The Virtual Reality user interface style allows the user to manipulate virtual objects in a 3D environment using 3D input devices. This style is best suited to application areas where traditional two dimensional styles fall short, but the current programming effort required to produce a VR application is somewhat large. We have built a toolkit called MR, which facilitates the development of VR applications. The toolkit provides support for distributed computing, head-mounted displays, room geometry, performance monitoring, hand input devices, and sound feedback. In this paper, the architecture of the toolkit is outlined, the programmer's view is described, and two simple applications are described.
1992	Interactive simulation in a multi-person virtual world	A multi-user Virtual World has been implemented combining a flexible-object simulator with a multisensory user interface, including hand motion and gestures, speech input and output, sound output, and 3-D stereoscopic graphics with head-motion parallax. The implementation is based on a distributed client/server architecture with a centralized Dialogue Manager. The simulator is inserted into the Virtual World as a server. A discipline for writing interaction dialogues provides a clear conceptual hierarchy and the encapsulation of state. This hierarchy facilitates the creation of alternative interaction scenarios and shared multiuser environment.
1992	The abstraction-link-view paradigm: using constraints to connect user interfaces to applications	The goal of the RENDEZVOUS project is to build interactive systems that are used by multiple users from multiple workstations, simultaneously. This goal caused us to choose an architecture that requires a clean run-time separation of user interfaces from applications. Such a separation has long been state goal of UIMS researchers, but it is difficult to achieve. A key technical reason for the difficulty is that modern direct manipulation interfaces require extensive communication between the user interface and the application to provide semantic feedback. We discuss several communications mechanisms that have been used in the past, and present our approach — the Abstraction-Link-View paradigm. Links are objects whose sole responsibility is to facilitate communication between the abstraction objects (application) and the view objects (user interfaces). The Abstraction-Link-View paradigm relies on concurrency and a fast but powerful constraint system.
1992	Grace meets the “real world”: tutoring COBOL as a second language	Grace is an intelligent tutoring system for COBOL which has been used to teach both novice and experienced programmers. While the tutor was quite effective in several classes and was designed with cognitive and interface principles in mind, we discuss a number of interesting issues that we have discovered when novice and experienced programmers used the tutor. Most of these problems are related to incompatibilities between the tutor interactions and the students' expectations in two areas: (1) the interactions with the tutor versus the interactions in their usual work environment and (2) the way in which experienced programmers solve problems. We describe these issues along with our solutions in the revised version of the tutor.
1992	Evocative agents and multi-media interface design	This paper describes research which focusses on the issue of possible roles for computerized agents within multimedia educational software.
1992	Graphic StoryWriter: an interactive environment for emergent storytelling	The Graphic StoryWriter (GSW) is an interactive system that enables its users to create structurally complete stories through the manipulation of graphic objects in a simulated storybook. A rule-based story engine manages character and prop interaction, guides story development, and generates text. Through the simple interface and story writing engine, the Graphic StoryWriter provides an environment for early readers to learn about story structures, to experience the relationship between pictures and text, and to experiment with causal effects. This paper describes the motivation for and design of the Graphic StoryWriter, and reports on an empirical comparison of childrens' stories generated orally and using the GSW.
1992	Finding usability problems through heuristic evaluation	Usability specialists were better than non-specialists at performing heuristic evaluation, and “double experts” with specific expertise in the kind of interface being evaluated performed even better. Major usability problems have a higher probability than minor problems of being found in a heuristic evaluation, but more minor problems are found in absolute numbers. Usability heuristics relating to exits and user errors were more difficult to apply than the rest, and additional measures should be taken to find problems relating to these heuristics. Usability problems that relate to missing interface elements that ought to be introduced were more difficult to find by heuristic evaluation in interfaces implemented as paper prototypes but were as easy as other problems to find in running systems.
1992	Applying cognitive walkthroughs to more complex user interfaces: experiences, issues, and recommendations	The Cognitive Walkthrough methodology was developed in an effort to bring cognitive theory closer to practice; to enhance the design and evaluation of use interfaces in industrial settings. For the first time, small teams of professional developers have used this method to critique three complex software systems. In this paper we report evidence about how the methodology worked for these evaluations. We focus on five core issues: (1) task selection, coverage, and evaluation, (2) the process of doing a Cognitive Walkthrough, (3) requisite knowlege for the evaluators, (4) group walkthroughs, and (5) the interpretation of results. Our findings show that many variables can affect the success of the technique; we believe that if the Cognitive Walkthrough is ultimately to be successful in industrial settings, the method must be refined and augmented in a variety of ways.
1992	The cognitive jogthrough: a fast-paced user interface evaluation procedure	Walkthrough techniques have been shown to be an effective supplement to empirical testing methods for evaluating the usability of software systems [3, 4]. Unfortunately, structured walkthrough procedures tend to be time-consuming and unpopular with evaluators when used on substantial tasks. To maximize the useful information obtained from walkthroughs while minimizing the overhead of the procedure itself, a fast-paced methodology was developed and used within the constraints of a real-world product development environment. By using video recording equipment and an informal, interactive evaluation session, the “cognitive jogthrough” procedure revealed significant user interface problems that could then be studied using other techniques.
1992	Comparison of empirical testing and walkthrough methods in user interface evaluation	We investigated the relative effectiveness of empirical usability testing and individual and team walkthrough methods in identifying usability problems in two graphical user interface office systems. The findings were replicated across the two systems and show that the empirical testing condition identified the largest number of problems, and identified a significant number of relatively severe problems that were missed by the walkthrough conditions. Team walkthroughs achieved better results than individual walkthroughs in some areas. About a third of the significant usability problems identified were common across all methods. Cost-effectiveness data show that empirical testing required the same or less time to identify each problem when compared to walkthroughs.
1992	One dimensional motion tailoring for the disabled: a user study	The Tailor project allows physically disabled users to provide real-time analog input to computer applications. We use a Polhemus tracking device and create a custom tailored mapping from each user's best range and type of motion into the analog control signal. The application is a simple video game based on Pong , where the analog input controls the position of the player's paddle. A group of able-bodied subjects was able to correctly hit the ball with the paddle 77\% of the time, and a comparison group of children with Cerebral Palsy performed at the 50\% level. More than half the disabled users were able to perform at a higher level than the worst able-bodied user.
1992	Working with audio: integrating personal tape recorders and desktop computers	Audio data is rarely used on desktop computers today, although audio is otherwise widely used for communication tasks. This paper describes early work aimed at creating computer tools that support the ways users may want to work with audio data. User needs for the system were determined by intervieweing people already working with audio data, using existing devices such as portable tape recorders. A preliminary prototype system – consisting of a personal tape recorder for recording and simultaneously marking audio and a Macintosh application for browsing these recordings – was built. Informal field user tests of this prototype system have indicated areas for improvement and directions for future work.
1992	Skip and scan: cleaning up telephone interface	The current generation of telephone interfaces is frustrating to use, in part because callers have to wait through the recitation of long prompts in order to find the options that interest them. In a visual medium, users would shift their gaze in order to skip uninteresting prompts and scan through large pieces of text. We present skip and scan , a new telephone interface style in which callers issue explicit commands to accomplish these same skipping and scanning activities. In a laboratory experiment, subjects made selections using skip and scan menus more quickly than using traditional, numbered menus, and preferred the skip and scan menus in subjective ratings. In a field test of a skip and scan interface, the general public successfully added and retrieved information without using any written instructions.
1992	Designing collaborative, knowledge-building environments for tomorrow's schools	The notion that children learn by constructing their own knowledge is highly popular these days among educational theorists. But what are the particular abilities that enable learners to be successful? And how must computer systems, and in particular their user interfaces, be designed to foster and support those abilities? The panel members represent several nationally-recognized education projects, all designed to give children control over their own learning while, at the same time, providing supports for effective learning strategies. They will discuss the unique design issues–resolved and unresolved–that arise as cognitive theories meet classroom realities. CSILE, a collaborative, user-constructed database, JASPER, a video-based mathematics program, and MediaText, a multi-media authoring environment, are available for use and review by CHI92 attendees prior to the panel presentation.
1992	Integrated data capture and analysis tools for research and testing on graphical user interfaces	Our on-line data capture and analysis tools include an event capture program, event data filtering programs, a multimedia data analyzer, and a retrospective verbal protocal recorder for use with the multimedia data analyzer. Off-line observation logging is also supported. Additional plans for development include the integration of an online time-synchronized observation logger, and time-synchronized eyetracking data recording. The tool set provides an integrated multi-source data collection, processing, and analysis system for: 1) comparing and evaluating software applications and prototypes; 2) evaluating software documentation and instructional materials; and 3) evaluating on-line training. The tools currently run on Macintosh computers and under Microsoft Windows. Plans are to port the tools to run under Presentation manager and Motif.
1992	Sci-fi at CHI: Cyberpunk novelists predict future user interfaces	This plenary panel will explore ideas about future user interfaces, their technology support, and their social context as proposed in the work of leading authors of science fiction characterized as the Cyberpunk movement. Respondents will react to and comment upon the authors' presentations.
1992	Participatory design of a portable torque-feedback device	Customer-driven design processes such as participatory design can be used to develop new presence, or virtual reality, technology. Chemists worked together with computer company engineers to develop scenarios for how present technology could be used to support future molecular modeling work in drug design. These scenarios led to the development of a portable torque-feedback device which can be used with either workstation or virtual reality technology. This paper discusses both the experience with the participatory design process and the novel features of the portable torque-feedback device.
1992	User centered development of a general practice medical workstation: the PEN&PAD experience	The goal of the PEN&PAD project is to design and develop a useful and usable medical workstation for day–to–day use in patient care. The project has adopted a user centred approach and direct observations of doctors, participative design and Formative Evaluation have therefore been an integral part of the process of software development. Indeed, doctors have been involved from the earliest stages of the project. The project has focussed on British General Practitioners, but the methods which have been evolved are general. This paper describes the strategy by which doctors can be involved in the successful design and development of a medical workstation.
1992	Retrospective on a year of participatory design using the PICTIVE technique	PICTIVE is a participatory design technique for increasing the direct and effective involvement of users and other stakeholders in the design of software. This paper reviews a year of the use of PICTVE on products and research prototypes at Bellcore. What we have learned is illustrated through five brief case studies. The paper concludes with a summary of our current PICTIVE practice, expressed as three developing, interrelated models: an object model, a process model, and a participation model.
1992	Evolving task oriented systems	This paper describes an approach to developing systems which can be summarised as ‘analyse top-down, design middle-out, and build bottom-up’. A case study is described in which this approach is used to develop a system to support staff who select new products for a major UK company. The novelty of the approach lies in its use of task analysis to define an appropriate domain for the system and then the use of a working prototype to grow a system from the bottom up. The project involved using simple development tools which allowed the users to start getting business benefit from the system right from the start. Their use could therefore develop as the system evolved.
1992	A visit to a very small database: lessons from managing the review of papers submitted for CHI'91	Many of the principles that guide user-interface design for commercial systems do not scale down to simple applications developed on personal computers. These “very small systems” are typicaly designed within a high-level application such as a database or a spreadsheet. The entire development process may take no more than a few days. In this restricted context, iterative design and usability testing are unaffordable luxuries, while detailed task analysis and early focus on users fail because the task and users will not coalesce until the system is in place. We describe our experiences with developing and using a very small sytem. We present suggestions for successful design in similar situations.
1992	Designing theory-based systems: a case study	In this paper, we discuss principles for designing and testing computer systems intended to support users' thinking as they perform open-ended or ill-defined tasks. We argue that such systems inherently and inevitably implement a model of users' cognitive behaviors. Making that model explicit can provide system developers with guidance in taking design decisions. However, both model and system must be tested and refined. We discuss these principles in relation to a case study in which our group developed a hypertext-based writing environment and then tested that system in a series of experimental studies of writers' strategies.
1992	Towards a model of cognitive process in logical design: comparing object-oriented and traditional functional decomposition software methodologies	This study aims at developing and empirically testing hypotheses about professional designers' cognitive activities when using object-oriented methodology (OOD) versus using traditional functional decomposition methodologies (TFD). Our preliminary results indicate that OOD may achieve substantial time savings over TFD in logical design. The verbal protocols from a pilot study show that OOD may achieve these time savings: 1) by simplifying rule induction processes used in functional decomposition; 2) by guiding designers on how to build more effective problem spaces; and 3) by allowing designers to run mental simulation more efficiently and more effectively.
1992	Requirements and design of DesignVision and object-oriented graphical interface to an intelligent software design assistant	Key findings from empirical studies—early design is opportunistic; critical role of pictures in design conception; impact of various cognitive limitations—have very effectively determined requirements and design for a set of tools to support early design. Key design features of the tools include respectively: (1) The (simultaneous) display of any software modules at arbitrary levels of abstraction and from any subsystems. The unrestricted, smooth navigation between these software modules. (2) Multiple design notations—pictorial and symbolic— cross-referenced, editable, and maintained consistent across all views. Integrated views of control flow, data flow, and functional decomposition. (3) Automatic layout at arbitrary levels of nesting. Visual display of execution paths in the solution. Automatic completeness and consistency check. Automatic visual indication and listing of modules with constraint violations.
1992	Facilitating the exploration of interface design alternatives: the HUMANOID model of interface design	HUMANOID is a user interface design tool that lets designers express abstract conceptualizations of an interface in an executable form, allowing designers to experiment with scenarios and dialogues even before the application model is completely worked out. Three properties of the HUMANOID approach allow it to do so: a modularization of design issues into independent dimensions, support for multiple levels of specificity in mapping application models to user interface constructs, and mechanisms for constructing executable default user interface implementations from whatever level of specificity has been provided by the designer.
1992	ClearBoard: a seamless medium for shared drawing and conversation with eye contact	This paper introduces a novel shared drawing medium called ClearBoard. It realizes (1) a seamless shared drawing space and (2) eye contact to support realtime and remote collaboration by two users. We devised the key metaphor: “talking through and drawing on a transparent glass window” to design ClearBoard. A prototype of ClearBoard is implemented based on the “Drafter-Mirror” architecture. This paper first reviews previous work on shared drawing support to clarify the design goals. We then examine three methaphors that fulfill these goals. The design requirements and the two possible system architectures of ClearBoard are described. Finally, some findings gained through the experimental use of the prototype, including the feature of “gaze awareness”, are discussed.
1992	Spatial workspace collaboration: a SharedView video support system for remote collaboration capability	Collaboration in three-dimensional space: “spatial workspace collaboration” is introduced and an approach supporting its use via a video mediated communication system is described. Verbal expression analysis is primarily focused on. Based on experiment results, movability of a focal point, sharing focal points, movability of a shared workspace, and the ability to confirm viewing intentions and movements were determined to be system requirements necessary to support spatial workspace collaboration. A newly developed SharedView system having the capability to support spatial workspace collaboration is also introduced, tested, and some experimental results described.
1992	Portholes: supporting awareness in a distributed work group	We are investigating ways in which media space technologies can support distributed work groups through access to information that supports general awareness. Awareness involves knowing who is “around”, what activities are occurring, who is talking with whom; it provides a view of one another in the daily work environments. Awareness may lead to informal interactions, spontaneous connections, and the development of shared cultures—all important aspects of maintaining working relationships which are denied to groups distributed across multiple sites. The Portholes project, at Rank Xerox EuroPARC in Cambridge, England, and Xerox PARC in Palo Alto, California, demonstrates that awareness can be supported across distance. A data network provides a shared database of image information that is regularly updated and available at all sites. Initial experiences of the system in use at EuroPARC and PARC suggest that Portholes both supports shared awareness and helps to build a “sense of community”.
1992	A method for (recruiting) methods: facilitating human factors input to system design	The paper proposes that some current problems in recruiting human factors methods to system design might be alleviated by means of a structured human factors design framework. The explicit stage-wise design scope of such a framework would support the assignment of appropriate human factors methods to specific system design needs. As an illustration, the design framework of an in-house structured human factors methodology is reviewed followed by the assignment of a set of existing human factors methods against its design stages. Subsequent steps to develop the assigned methods into a similar methodology are then described. The potential of such a methodology for facilitating human factors input is discussed.
1992	Teaching experienced developers to design graphical user interfaces	Five groups of developers with experience in the design of character-based user interfaces were taught graphical user interface design through a short workshop with a focus on practical design exercises using low-tech tools derived from the PICTIVE method. Several usability problems were found in the designs by applying the heuristic evaluation method, and feedback on these problems constituted a way to make the otherwise abstract usability principles concrete for the designers at the workshop. Based on these usability problems and on observations of the design process, we conclude that object-oriented interactions are especially hard to design and that the developers were influenced by the graphical interfaces of personal computers with which they had interacted as regular users.
1992	Integrating human factors on a large scale: product usability champions	This paper describes how a software development division in a large corporate environment found a creative way to integrate human factors techniques into their development processes. It discusses the limitations of a single Human Factors Engineer, the needs of a typical engineer on a software project, and how these limitations and needs produced the Product Usability Champion Program. Product Usability Champions are representatives from each software project in the division who act as usability watchdogs for their respective projects. The Human Factors Engineer's responsibility is to provide support to these Champions. This support includes access to a Usability Lab, technical advice, references, consulting, classroom training, hands-on training, Usability Champion program facilitation and support, and specific project team involvement. This paper describes the program's structure, implementation, and success.
1992	Overview of the institute for research on learning	The Institute for Research on Learning (IRL) is a non-profit organization founded in 1986 in Palo Alto, California, committed to understanding what leads to successful learning in the schools, the workplace, and everyday life. A basic premise of IRL research, that people learn best when they are engaged with others, leads IRL's researchers to perceive schools and workplaces as communities of learners and to focus on the design of environments, technology, and activities that support learning as a collaborative activity. IRL pursues its research in collaboration with schools, universities, corporations, and government agencies—in the actual settings in which learning takes place.
1992	YAPO: yet another preview ODA	The production of documents aimed at supporting the flow of information in an office environment is experiencing an evolution based on the most advanced automation systems which concerns substantially four aspects: 1) the production of manipulable documents showing a high quality of representation; 2) the production of documents that can be integrated (or exported) with other workstation formats on the basis of varying approaches (for instance the ISO standards); 3) the production of processable documents for storage or subsequent post-production; 4) the production of immaterial documents, i.e. documents that do not necessarily need a visual medium (paper, screen) representation for their informative content.
1992	A desk supporting computer-based interaction with paper documents	Before the advent of the personal workstation, office work practice revolved around the paper document. Today the electronic medium offers a number of advantages over paper, but it has not eradicated paper from the office. A growing problem for those who work primarily with paper is lack of direct access to the wide variety of interactive functions available on personal workstations. This paper describes a desk with a computer-controlled projector and camera above it. The result is a system that enables people to interact with ordinary paper documents in ways normally possible only with electronic documents on workstation screens. After discussing the motivation for this work, this paper describes the system and two sample applications that can benefit from this style of interaction: a desk calculator and a French to English translation system. We describe the design and implementation of the system, report on some user tests, and conclude with some general reflections on interacting with computers in this way.
1992	Object-oriented video: interaction with real-world objects through live video	Graphics and live video are widely employed in remotely-controlled systems like industrial plants. Interaction with live video is, however, more limited compared with graphics as users cannot interact with objects being observed in the former. Object-Oriented Video techniques are described allowing object-oriented interactions, including the use of real-world objects in live video as reference cues, direct manipulation of them, and graphic overlays based on them, which enable users to work in a real spatial context conveyed by the video. Users thereby understand intuitively what they are operating and see the result of their operation.
1992	Liveboard: a large interactive display supporting group meetings, presentations, and remote collaboration	This paper describes the Liveboard, a large interactive display system. With nearly one million pixels and an accurate, multi-state, cordless pen, the Liveboard provides a basis for research on user interfaces for group meetings, presentations and remote collaboration. We describe the underlying hardware and software of the Liveboard, along with several software applications that have been developed. In describing the system, we point out the design rationale that was used to make various choices. We present the results of an informal survey of Liveboard users, and describe some of the improvements that have been made in response to user feedback. We conclude with several general observations about the use of large public interactive displays.
1992	Interactive constraint-based search and replace	We describe enhancements to graphical search and replace that allow users to extend the capabilities of a graphical editor. Interactive constraint-based search and replace can search for objects that obey user-specified sets of constraints and automatically apply other constraints to modify these objects. We show how an interactive tool that employs this technique makes it possible for users to define sets of constraints graphically that modify existing illustrations or control the creation of new illustrations. The interace uses the same visual language as the editor and allows users to understand and create powerful rules without conventional programming. Rules can be saved and retrieved for use alone or in combination. Examples, generated with a working implementation, demonstrate applications to drawing beautification and transformation.
1992	Dynamic queries for information exploration: an implementation and evaluation	We designed, implemented and evaluated a new concept for direct manipulation of databases, called dynamic queries , that allows users to formulate queries with graphical widgets, such as sliders. By providing a graphical visualization of the database and search results, users can find trends and exceptions easily. Eighteen undergraduate chemistry students performed statistically significantly faster using a dynamic queries interface compared to two interfaces both providing form fill-in as input method, one with graphical visualization output and one with all-textual output. The interfaces were used to explore the periodic table of elements and search on their properties.
1992	A “pile” metaphor for supporting casual organization of information	A user study was conducted to investigate how people deal with the flow of information in their workspaces. Subjects reported that, in an attempt to quickly and informally manage their information, they created piles of documents. Piles were seen as complementary to the folder filing system, which was used for more formal archiving. A new desktop interface element–the pile– was developed and prototyped through an iterative process. The design includes direct manipulation techniques and support for browsing, and goes beyond physical world functionality by providing system assistance for automatic pile construction and reorganization. Preliminary user tests indicate the design is promising and raise issues that will be addressed in future work.
1992	The Ircam Signal Processing Workstation prototyping environment	This demo shows the prototyping environment of the Ircam Signal Processing Workstation. The environment is oriented toward rapid prototyping of DSP and Musical applications.
1992	Building user interfaces interactively using pre- and postconditions	A tool is presented which allows graphic layout of a user interface integrated with specification of behavior using pre- and postconditions.
1992	A case study of a multimedia co-working task and the resulting interface design of a collaborative communication tool	The Video Viewer is a communication tool that allows two users to share video information across a network. The design of this tool was based on the results of a case study involving two multimedia, collaborative workstations situated in two separate rooms. Users performed several tasks collaboratively using different media in an unstructured environment (i.e., there were four monitors to increase screen space and there was no specific interface for guidance). This video outlines the case study, the preliminary case study results and how these results effected the interface design of the Video Viewer.
1992	An active task manual	The Active Manual is an extension of previous work on task oriented manuals. The techniques used for improvement are based on several concepts. While these concepts are not novel, in themselves being well-grounded in psychological research, the combination of these concepts is unique. The work has moved task manuals into the windowed on-line world of the computer to accommodate the extensions.
1992	Evaluation criterion for computer-based training courseware	To investigate if a life-cycle model exists for Human-Computer Interface (HCI) principles and integrate this into courseware design for Computer-Based Training (CBT). To develop a suitable model for the design of the user interface looking at ways of evaluating usability of HCI's for CBT courseware. A model centred upon the use of high quality and creative instructional design embracing the changing technologies coupled with clear principles of learning and cognitive psychology which enables usability evaluation is therefore desirable. The Multimedia Interactive Design Aided System (MIDAS) model presented in this paper is a formulation based upon such criteria. The implementation of the model presented is centred on the following application - The training of pilots and engineers on the braking system of the British Aerospace Jetstream Aircraft. The multimedia authoring tool used for the implementation is Authorware Professional, and the courseware application is presented on a Macintosh environment, which can be converted to a Windows environment. Macromind Director has been used to create the animation, sound, and graphic windows and imported into Authorware. <i>The need for a practical method for accessing usability of CBT courseware.</i> The ultimate aim in producing guidance for well-designed user interfaces must be to improve usability of the system for the user. However, guidelines rarely concern the <i>needs</i> and <i>requirements</i> imposed on the interface by the tasks which an end-user carries out in a particular context. In addition, the presentation of guidelines generally includes very little guidance concerning where, when and how to use them, and how to apply them in a particular situation. In CBT courseware evaluation, guidelines therefore have a limited use as a means of evaluating the effectiveness of a user interface when carrying out tasks. In order to enable the research findings emerging in this area to be applied in assessing usability, a method is needed which goes beyond lists of design guidelines, but which utilizes relevant material existing within them. The principles presented outline how my research contributes and provides a better understanding to the development of a new approach to the evaluation of CBT courseware. The method, and the nature of the checklist, enables an interface to be evaluated by a variety of people, with differing expertise and backgrounds, including, for example, CBT trainers, developers, interface designers and other experts, and most importantly, representative end-users, who may, or will, actually use the system in practice. <i>The method does not aim to solve problems, or to enable a quantitative assessment of usability. It provides a means of identifying problem areas, of extracting information on problems, difficulties, weaknesses, areas for improvement, etc.</i> The evaluation criterion headings are: Visual Clarity •Consistency •Compatibility •Informative feedback •Explicitness •Appropriate functionality •Flexibility and control •Error prevention and correction •User guidance and support •System usability The results and conclusions drawn from the experimentation carried out during the past year will be summarised in graphical form. The potential financial benefits of using the method will be summarised. Finally a set of Practical guidelines for the production of a user-interface for CBT courseware will be presented, based on the MIDAS model, which will take into account changes to the initial design model which have come to light as a result of the evaluation process.
1992	Automated expert advisor interfaces	Automated expert advisors should provide real time information that allows assessment of the advisor's response instead of providing explanation facilities that add to the operator's workload. In system control environments, an automated expert advisor applies established rules to system data, arriving at an assessment of the system status. The processing of data results in information being either conserved, reduced, or created. Automated advisors typically reduce or create information thereby reducing operator workload. In a system where the human operator retains final control, the primary goal is for the operator to be able to maintain the system, using the advisor's assessment in a manner consistent with the accuracy of that assessment.
1992	Tutorial: a tool for teaching graphics programming	Tutorial is an interactive exploratory learning tool designed to aid programmers in learning graphics programming and Silicon Graphics Inc.'s Graphics Library (GL) in particular. Tutorial is driven by four demo programs that present <i>simulated source code</i> to the student. The student uses Tutorial by executing each line of code and noticing its effects on the graphics state, representations of the internal hardware, and the final output. We intend that the exploratory nature of the system will result in deep learning of graphics programming concepts. The user interacts with Tutorial by modifying parameters to GL function calls, choosing lines of source code to execute, and modifying the graphics state directly. Nearly all aspects of the graphics state are both inspectable and modifiable, with these changes propagated throughout the entire system. This interaction aids in: determining what are reasonable parameters for GL functions; observing how GL functions interrelate; observing how the functions modify the graphics state; and observing how the graphics state determines what is presented in the final window. The poster describes Tutorial and presents four scenarios of Tutorial in use. Each scenario is a series of pictures which show the modification of function parameters and the effect of the modification on the final image. The scenarios we will show are: the use of the perspective and lookat to define the viewpoint and viewing volume; orthographic projection and how it relates to the viewport and the hardware zbuffer; how the 2-dimensional orthographic projection, viewport and charstr interact; and using the overlay and underlay framebuffers. Each scenario demonstrates how Tutorial enables the user to come to a deeper understanding of the effects of various graphics library functions. For instance, the relationship between the orthographic projection area and the viewport (screen) area is explained. The scenarios also demonstrates the different ways the user can interact with Tutorial. These include modifying function parameters, altering the simulated source code, changing the <i>state</i> of the system directly (bypassing the simulated source code), and inspecting various parts of the graphics pipeline. As well the features of the interface and the control of the simulated source code will become apparent from the scenarios.
1992	Design strategies in object-oriented programming and expertise	The goal of the present study is to analyse the design activity followed by professional programmers using an object-oriented programming (OOP) language. An issue is to define which characteristics of the design strategies are common or different according to the experience the programmers have in the OOP language in question. Another related issue is to describe programming schemas related to OOP.
1992	Comparing procedural and object-oriented design	Many companies employ programmers who use traditional procedural methods for software design. A new approach, object-oriented design, which allows for easy extensibility and reuse of previous designs, has recently been developed (Wirfs-Brock, Wilkerson, & Wiener, 1990). Major claims are made about the benefits of object-oriented design (Gibson, 1990). However, anecdotal evidence indicates that people who know procedural design have difficulty learning object-oriented design. Unfortunately, the benefits of object-oriented design will be lost if programmers have problems switching paradigms.
1992	Participatory video prototyping	At U S WEST Advanced Technologies, we have been using a method we call Video Prototyping to simulate interface ideas for over a dozen software design projects. It is similar to the work described by Curtis and Vertelney [1], because we create a simple stop-motion animation depicting user interface design concepts. However, Video Prototyping requires no post-production editing or any special expertise in video production. In this way it is more like Muller's PICTIVE work [2], where multi-disciplinary design teams use it in informal brainstorming sessions. Unlike PICTIVE, we do not simply record design ideas but create an evocative simulation of the proposed interface.
1992	SUIT: the simple user interface toolkit	User interface support software, such as UI toolkits, UIMSs, and interface builders, are currently too complex for undergraduates. Tools typically require a learning period of several weeks, which is impractical in a semester course. Most tools are also limited to a specific platform, usually either Macintosh, DOS, or UNIX/X. This is problematic for students who switch from DOS or Macintosh machines to UNIX machines as they move through the curriculum. The situation is similar to programming languages before the introduction of Pascal, which provided an easily ported, easily learned language for undergraduate instruction.
1992	Agentsheets: a tool for building visual programming environments	Visual programming systems are supposed to simplify programing by capitalizing on innate human spatial reasoning skills. We claim (a) that good visual programing environments should be oriented toward their application domains and (b) tools to build such domain-oriented environments are needed because building them from scratch is very difficult. The poster describes a system called Agentsheets addressing these issues and illustrates how the system was applied to a real-world application helping professional telephone voice dialog designers.
1992	Iterative design of a voice dialog design environment	In this project, we successfully applied iterative prototyping and participatory design to the design of a complex system --- a voice dialog design environment. The success case for this project is really a story about how we got "this far this fast." In less than four months, a mixed team of professional voice dialog designers and academic researchers were able to design and build a substantial core design environment. There were several unique aspects of our approach that contributed to the project's success. These include selection of the right high-level system substrate on which to build our design environment and creation of a participatory context conducive to iterative design methods.
1992	User interfaces for distributed control systems: the HYPERFACE UIMS	The poster illustrates an advanced User Interface Management System called HYPERFACE, which is being developed in the framework of the Esprit II Project 5391 ("HYPERFACE"), by a Consortium composed by Etnoteam (Italy, Coordinating Contractor), CESI (Italy), Ensidesa (Spain), Eritel (Spain), INESC (Portugal), Istituto di Macchine Utensili del CNR (Italy), Non Standard Logics (France), University of Milano - Dipartimento di Scienze dell'Informazione (Italy).
1992	Designing graphical user interfaces by direct composition	The User Interface Management System (UIMS) SX/Tools allows the development of interactive graphical user interfaces following the principle of Direct Composition. The UIMS has been designed with specific consideration of requirements arising from industrial automation and control applications.
1992	Taxonomy of participatory design practices: a participatory poster	This poster surveys and classifies Participatory Design (PD) practices within a space defined by (a) the extent of direct user involvement in the design process, and (b) the temporal position of the practice in the development cycle or iteration. Surveyed practices include structured conferences, ethnographic methods, hands-on/mock-up techniques, various approaches to prototyping, and others. The poster is intended to be participatory: viewers are encouraged to use structured templates and blank areas of the poster to propose other PD practices for inclusion.
1992	Developing a design method: task analyses in user interface design	Research by Gould et al. [3] and Bellotti [2] shows that design methods do not seem to be used as often as expected by the developers of these methods.
1992	Determining 'characteristic interactions' for early prototyping	Evaluation of user interfaces in the early stages of design process requires the use of simulations or prototypes. However, building prototypes with extensive functionality could take up lot of time and efforts. Several strategies can be adopted to cut down the complexity of prototypes. Nielsen [2] introduced two kinds of prototypes namely horizontal prototypes that include various system features and vertical prototypes that reduce the number of features but implement the full functionality of those features chosen. Virzi [3] proposed a third dimension similarity of interaction to Nielsen's model. Similarity essentially means the proximity of the prototype to the actual system and takes into account any distortions created due to prototyping tools, representation etc.
1992	Using the cognitive walkthrough in iterative design	The primary goal of the Cognitive Walkthrough (CW) is to make a formal user interface evaluation method accessible to individuals who are directly involved in the design process of a new system, but do not necessarily have expertise in UI issues. As such the CW needs to be easy to understand and apply. It was originally developed to evaluate the usability of 'walk-up-and-use' interfaces, such as ATM's (Lewis, Polson, Wharton, and Rieman, 1990, and Polson, Lewis, Rieman, and Wharton, in press). The CW was used to evaluate the user interface of an existing support system for sales representatives (REPS), which is a fairly complex system that provides access to various databases and a limited editing capability. Its interface consists of a multitude of different screens, each only used for a few basic functions. Therefore this evaluation of REPS with the help of the Cognitive Walkthrough was seen as a reasonable test of the breadth of the Cognitive Walkthrough's applicability. The poster describes the effectiveness of the method and the effort needed to use it.
1992	Usability testing: is the whole test greater than the sum of its parts?	Usability testing is often employed to evaluate specific problem areas in a user interface. In this approach, users perform tasks that address the specific issues of concern. Use of the feature in isolation is assumed to provide results that would be valid if the features were used in the context of all other features. The present poster evaluates this assumption and describes the importance of an integrated approach to testing. We suggest that usability testers should construct test scenarios that require integration across different system features to obtain an accurate evaluation of the product and the individual features.
1992	TelePICTIVE groupware for collaborative GUI design	The design of Graphical User Interfaces (GUIs) requires collaborative effort by a group of diverse co-designers. This group is typically constrained to meet in the same time and place. In this poster, we describe TelePICTIVE, an experimental groupware prototype that supports this design process by users at multiple, dispersed, geographical and temporal locations.
1992	The design of the conversation board	Out work focuses on improving the interaction between people at a distance by providing them with shared electronic props. The Conversation Board is a prototype multi-person drawing tool intended as a medium for the introduction and manipulation of props during conversation. Props such as sketches, digitized photographs, editable text, and sound clips can be placed onto the shared canvas, moved around, modified, and annotated with colored marker tools. We envision it being used in situations such as informal office meetings, distance education and training, and medical consulting.Our design was motivated by conducting an informal study of how people used their office whiteboards for communication. We asked people to explain the contents of their whiteboards and the conversations that led to them. We found that their drawings often represented objects, such as text and block diagrams, which have specific semantic properties that we attempt to support in our electronic tool.The Conversation Board was built in the RENDEZVOUS™ system, an experimental toolkit designed at Bellcore to support multi-user applications. This poster also briefly describes the capabilities of our toolkit and the applications we've built with it.
1992	GROUPKIT: a groupware toolkit	Groupware development has been characterized by many exciting breakthroughs, and we are finally beginning to see these innovations replicated by research and commercial outfits. Yet groupware replicated is tedious and painful, and great efforts are spent re-inventing the wheel. Part of the problem is the paucity of tools specifically supporting groupware development. To this end, we are constructing GROUPKIT, a groupware toolkit that provides the building blocks common to a variety of real-time distributed conferencing systems.
1992	Collection and analysis of data about group processes in computer supported meetings	The purpose of this interactive poster is to encourage the exchange of information about techniques for gathering and analyzing data relevant to the evaluation of software used by a group. As more software is created for the use of group meetings, we must be able to evaluate that software, its interface and its effects within the meeting. Experimental evaluation of group software is more complex than that of single-user software. To evaluate the changes caused by the meeting software, it is necessary to collect data on the group process and its outcome.
1992	The introduction of GDSS in Bulgaria	In the Fall of 1991 the University of Arizona installed GroupSystems, a group decision support system (GDSS), in a new facility in Sofia, Bulgaria. Fall 1991 marked two years since Bulgaria separated from the (then) USSR and was synchronous with the installation of a democratic government. The GDSS facility in Sophia is located at the University of National and World Economics. The facility contains eight user stations, a facilitator station, and a network server. A large monitor is available at the front of the room to allow individual screens to be publicly projected. The facility's GroupSystems software features modules for: brainstorming, stakeholder identification, voting. questionnaire design and administration, group editing. and topic discussion. The software can be run using either the Latin or Cyrillic alphabets. Anonymity is available in all modules and subgroups of participants can be created. Initial group experiences in the facility indicate that Bulgarians are receptive to GDSS technology, particularly modules allowing anonymous discussion. The current research proposes to compare the implementation of a GDSS technology for Bulgarian business people government officials with the implementation of the same technology for American foreign service officers serving in Bulgaria.
1992	An empirical examination of software-mediated information exchange and communication richness	We report on a two-part longitudinal study of computer-supported cooperative work. It focuses on the impact of coordinating and enabling technologies through an examination of computer-supported information exchange patterns. Colleagues were required to work together to complete a project within a specified time frame. The patterns of information exchange observed in this environment provide evidence as to which aspects of groupware are perceived as helpful by users, and provide an impetus for further research. The objectives of this research are to: 1) examine patterns of information exchange in order to provide descriptive data on the process of using groupware; and 2) identify factors that need to be considered for effective and efficient use of groupware in a CSCW environment. The two studies allow for an investigation of the difference between 1) small novice-user groups formed across class sections (locations) with each group responsible for developing a complete proposal and 2) a large experienced-user group formally divided into subgroups, with each subgroup responsible for developing a portion of a proposal. In the first study, participants were graduate students in an advanced information systems course. The research task was to develop a proposal for a company with inventory data control and other related problems (inefficient production layouts and machine utilization) in a simulated business information systems consulting environment. There were six teams with four or five participants on each team. Each team was split across two sections of the course. Differential information was provided to each section and team members were encouraged to use the groupware for communications concerning the project. The participants were novice users of the software. In the second study, participants were graduate students in a data communications and networking course. All nine had taken the previous course and were experienced with the groupware. The research task was a team network analysis and design project. Participants were encouraged to use the groupware for communications as in Study 1. They were divided into three teams of three, with one team responsible for the LAN portion of the proposal, the second team responsible for the WAN portion, and the third team responsible for the integration of the LAN and WAN material, and for the development of the proposal package. A graduate student who had previously taken the course acted as project manager. After participants had completed the two projects, the messages were categorized using a previously developed coding scheme. The message frequency and type yielded descriptive information regarding the impact of the technology on interactions among participants, and the relationship between decision outcomes and patterns of information exchange. The findings include: 1) the groupware used needs to be matched to the task, group structure, and environment; 2) minimal social use of the system occurred over time; 3) the message mix tended to shift from scheduling and coordinating efforts to task-related efforts as deadlines loomed; and 4) the system provided descriptive information on team work habits. These patterns and other qualitative data gathered from participants provide insight into the use of the groupware, group behavior, and the importance of group structure, task, and environment.
1992	The evolution of linking facilities in OISE's CSILE system	The goal of the Computer-Supported Intentional Learning Environments (CSILE) Project at OISE is to build (a) an instructional theory driven by cognitive science research into collaborative learning processes and expert knowledge organization and (b) a collaborative educational hypermedia system. The design of the system is based on the theory, and in turn provides support for classroom experiments to test its predictions. Every school day for the last six years, two classes of grade five and six public elementary school students have been using the CSILE System prototype as a tool to support deep understanding of their usual curriculum. In the last three years, we have also introduced the system in classrooms with students from grades one to four and seven to thirteen.
1992	Designs to encourage discourse in the OISE CSILE system	Every school day for the last six years, two classes of grade five and six public elementary school students have been using OISE's Computer-Supported Intentional Learning Environment (CSILE) as a tool to support deep understanding of their usual curriculum. The design of this innovative collaborative educational hypermedia system, the first that we know of to be in daily classroom use, is driven by cognitive science research into expert learning and knowledge organization. A cornerstone of the CSILE approach is that students construct the contents of their database from scratch. They use CSILE's tools to construct linked textual and graphical database "notes" which are available to all members of the classroom community. They are browsed (via keywords, links, and other means of navigation), read, evaluated, built upon, and, commented on. A note's author is informed of all comments and all comments are available to all users of the database. This work, pioneered by Scardamalia and Bereiter [2], was the subject of two previous CHI posters.
1992	An interface design for learning spelling through integrated intentional spell-checking	OISE's Computer Support-Intentional Learning Environments (CSILE) is an innovative collaborative educational hypermedia system designed to facilitate student-centred knowledge-building through the collaborative construction of computerized knowledge bases. Previous CHI posters have described results of the last six years of classroom use [1]. Throughout the school year, students enter their work into a common database of text and graphics which is available to all students through browsing and searching based on topics, keywords, and other links. Through this work, students are encouraged to formulate their own problems, develop their own theories, and construct their own knowledge. Thus, the main design challenge for CSILE is to support the development of cognitive skills required for self-directed (intentional) learning. This poster focuses on the continuing development of facilities that require students to take intentional control of and responsibility for the process and content of their spelling and vocabulary learning.
1992	Introducing the suitware project	The Suitware project was established to explore methods and tools for the design of adaptive user interfaces. The name Suitware was created as a synonym for "software which suits the users needs". The poster introduces some basic ideas and the overall research goals of the project. As a result of preparatory work, a taxonomy of adaptive user interfaces (AUI) is presented.
1992	Who adapts what in HCI?	The acceptance of a system as a whole strongly depends on the quality and appropriateness of its user interface in a certain working environment. Especially in the medical environment particular conditions - such as heavy workload on physicians and nurses, the patient's health as the overall objective and lack of time for training - have to be taken into account; these conditions demand for sophisticated adaptation strategies.
1992	The utility of various windowing capabilities for single-task and multi-task environments	Computer systems offering windowing environments have been readily embraced by the computer user community. These capabilities have become so popular in recent years, that even the more traditional command-line systems such as IBM PCs are offering windowing environments. The question arises as to whether or not a windowing environment is appropriate for any and all user environments. This question has particular importance for computer systems that control complex processes and hazardous environments, such as Nuclear Power Plants or Space Station Freedom. Both of these examples represent multitasking environments where there is a large cognitive load on the user. It has been argued that the task of window management poses additional processing loads on the user. In fact, during the early definition of the Space Station Freedom human-computer interface, NASA's astronaut office strongly opposed a windowing environment, partially for "safety" reasons. It was felt that the windowing capabilities were dangerous in an environment where critical information could be accidently hidden, "lost", etc. It was also felt that managing the display of information was an unnecessary additional task.
1992	Developing an error prevention methodology based on cognitive error models	A long-term program is in progress at JPL to reduce cost and risk of flight mission operations through a defect/error prevention program. The goal of this program is the reduction and ultimately the prevention of human errors. The main thrust of this program is to create an environment in which the performance of both the human operator and the computer system is optimized. Systems must be designed to enhance normal human performance; training programs must be designed to alleviate likely errors; and functions that are human-error prone should be automated. To successfully design and implement this program requires a theoretically motivated model of human problem solving and decision making based on current theories of human cognition. Further, such a model must be data-validated to ensure its ultimate applicability. Principles of cognitive psychology, human-computer interaction, and Total Quality Management (TQM) are used to analyze past errors and make changes to end-user applications and training requirements to prevent these errors in the future.
1992	Modeling system evolution: a means of cutting through obstacles to desirable change to large business (information) systems, their many computer-human interfaces, and user/operator responsibilities	Too often, attempted change and change planning suffers from inadequate insight, coordination, and involvement. Decision makers frequently get caught up in power/political contests, utilize and are impacted by cognitive (Anderson, 1991) or organizational (Grudin, 1991) structures and procedures that hinder beneficial cooperation/participation, and focus excessively on visible technology end-states and inadequately on business and human processes, underlying infrastructure, and enabling intermediate-states. Hence, resulting change, if achieved at all, is often change without readiness, buy-in, or gain.
1992	The Xerox work practices project	The Interactive Poster consists of the following Design Process and Group Work themes:A graphic representation of the Work Practices/Participatory Design Process defining methodology and tools on an, iterative timeline.A graphic representation that defines Understanding and Designing for Work Practices.A 10 minute videotape elaborating on a pilot study which incorporates the concepts graphically illustrated on the poster.
1992	User acceptance of computer applications with speech, handwriting and keyboard input devices	There is a growing movement toward designing more natural user interfaces that take advantage of an individual's experiential knowledge of speech and handwriting interaction. One disadvantage of these natural interfaces is that the system may not always interpret the user input accurately. No study has attempted to determine what impact these accuracy rates have on the user's acceptance or preference of a particular application. Given that handwriting and speech have a lower input accuracy rate than keyboard input, are there certain applications that individuals would prefer not to use with either a speech or handwriting input device?
1992	Of mice and children	The purpose of the study was to explore elementary school children's preferences for computer mice of different shapes and sizes. A user-centered approach was employed to elicit children's input about alternative designs. The intent was to indentify shapes that constitute a better ergonomic fit for children's smaller hands and to establish whether different shapes are suitable for different age groups.
1992	The multi-modal integrative mouse: a mouse with tactile display	In natural situations, we can obtain sensory information in different modalities such as visual, auditory and tactile from an object. The human-computer interface with a mouse can give us both visual and kinesthetic information. However, the tactile information that occurs when we touch an object in a natural situation is not available from a mouse. In psychophysical studies, it has been shown that tactile information added to visual information helps to increase the velocity of finger movements and reduces the dependence on vision [1]. It is, therefore, expected that an interface device capable of presenting tactile information would improve the efficiency of operation and reduce the visual load. Thus, we have developed a human-computer interface device based on a mouse that gives tactile and force sensations to the operator in addition to visual information. This interface device can be defined as a multi-modal integrative mouse.
1992	Contextual motor feedback in cursor control	Contextual Motor Feedback (CMF). For user-system interaction, most existing equipment uses mechanical input devices and visual and auditory output devices. Contextual motor feedback employs other modalities to provide feedback about the state of the system: the human motor system. Users can detect changes in the mechanical behaviour of a system by their tactile and kinesthetic senses. Contextual motor feedback lets user and system communicate over the same physical parameters: position, speed and force.
1992	Finger-pointer: a glove free interface	Many gesture interfaces such as "Put-That-There" require operators to wear special devices such as "Data-Glove" to make the system recognize hand gestures. However, wearing such devices prevents the realization of a natural interface. We have developed the "Finger-Pointer" experimental system, which can recognize pointing actions and simple hand forms in realtime by image processing. The operator is not required to physically contact any control devices. We present the details of the image processing techniques employed, and a principle for stable measurement of pointing direction. We also solved the time lag problem with multi-channel integration.
1992	A graphic object manipulation system using hand gestures	People use gestures to communitcate with other people without difficutlty. As a method of computer/human interaction, gestures are more intuitive and more direct than existing input devices, such as keyboards, mice, etc., and futhermore, are more functional. Using hand gestures, which are important human gestures, is a key technique to build a friendly user interface.Some gestures are considered to be simbols, such as "OK" gesture, American sign language. Others have numerical meaning, i.e. how long, how large, how fast. etc. To deal with both kinds of hand gestures, we propose a hand shape representation method.The method represents a hand shape with 15 dimensional data of 5 finger tip positions in 3D. To implement both static and dynamic hand gestures in a graphic object manipulation system, at each measurement time the current hand shape is classified into 10 classes of hand shapes using subspace method and the hand movement is evaluated using recurrnet neural network.The system allows a user to manipulate graphic objects intuitively and directly.
1992	HyperMark: issuing commands by drawing marks in HyperCard	Pen-based interfaces that use markings to issue commands are becoming more popular every day. The advantages of markings as commands can also be used in traditional mouse-based interfaces. We have developed a system called "HyperMark" which allows markings to be used in Apple's HyperCard. For example, if HyperMarks are added to a screen button, not only does a button react to a mouse press, but marks can also be drawn on the button which trigger other actions. This results in fewer buttons and faster interactions in some cases. In effect, HyperMarks are similar to pop-menus where additional functions are "hidden" under a button until popped up. However, with HyperMarks, a user does not have to wait for menu pop-up, visually search the menu and point to an item. Instead, a mark triggers the item directly and quickly. Our intention is that ordinary HyperCard users/programmers can incorporate markings into their own HyperCard stacks. Two types of marking recognition systems can be used in HyperMark. One system is a user trainable gesture recognizer developed by Rubine (1991) which we have ported to HyperCard. In Rubine's system a user can create their own vocabulary of markings and train the recognizer with several examples of each marking. The other recognition technique called "marking menus", developed by Kurtenbach (1991), has a preset vocabulary of markings. This vocabulary of marks consists of straight stroke marks distinguished by the angle of the stroke. Although this marking set is very limited, pie menus (Callahan, Hopkins, Weiser, & Shneiderman, 1988) are used in conjunction to help a user learn and remember the associations between marks and commands. This poster presents the design issues concerning user programming and use of either of these systems in the context of HyperMark. Furthermore, we examine how these design issues apply to marking based interfaces in general. The major issues are: how much programming effort is required by a user to make use of one of these systems? How easy to use is each system? How self explanatory are they? How easily and successfully can marks be drawn in either system? We have found that either system has its advantages and disadvantages and that the systems can successfully be used together. The advantage of the Rubine's system is that user can create one's own custom set of markings. However the disadvantage is that it is then the user's responsibility to design an unambiguous mark set and provide examples to train the system. Also, because markings are not self-revealing like buttons or menus, some sort of user built explanation must also be created. In contrast, with marking menus, because the marking set is preset, no marking set need be designed and ambiguity is not a problem. Furthermore, the pie menu aspect of marking menus provides built in help. Adding a marking menu is as simple as adding a pop-up menu. Thus for very little implementation overhead a user can obtain the benefits of using marks.
1992	Remote manipulation interfaces the case of a telepathology workstation	Telemedicine is the practice of medicine over communication links. The physician being consulted and the patient are in two different locations. A first telepathology system has been developed by Corabi Telemetrics. It allows a pathologist to render a diagnosis by examining tissue samples or body fluids under a remotely located microscope.
1992	DispLayers: multi-layer display technique to enhance selective looking of overlaid images	In order to support remote collaboration, we designed TeamWorkStation[1]. The system provides distributed users with a shared workspace image and face images. Initially, we displayed these images using a tiling window strategy as shown in Fig. 1(a). However, the screen space was too small to display both the workspace window and face windows at sizes large enough for effective use. To solve this problem, we devised the ClearFace technique that overlays the translucent face image onto the workspace image (Fig. 1(b))[2]. Although the quality of overlaid images is somewhat degraded, users can easily switch their attention between the workspace image and the face images. This human ability to selectively see one of two mixed images is accounted by the theory of "selective looking "[3]. However, we realized that there still remained some difficulties in separating the mixed images in ClearFace.
1992	Design techniques for scientific visualization	This poster illustrates examples from a work in progress and is presented with the intention of receiving feedback from conference attendees. The work is a collaborative effort in which we are investigating various visual design techniques for scientific visualization that we believe will maximize the flow of information from the video or computer monitor to the viewer.
1992	An image synthesizing method based on human motion recognition from stereo images	An image synthesizing method for the conference system with realistic sensations is discribed. In this conference system, a human image in virtual space has to be synthesized by tracing the motion of human in real space.But it is difficult to detect positions of all human joints from real image. We proposed a new image synthesizing method using an associative memory. This is memorized human representative motion patterns to conpensate insufficiency of detected information from real image.The human body region can easily be detected from each images of stereo by using deffrences between input image and background image, and also skin color regions can easily be detected by color information. 3D-positions of few points of human body(head, face, hands) are obtainable by stereo matching of a representative point in detected regions. By an associative memory memorized relation of standerd motion patterns with parameter that is independent from a human direction and an initial horizontal position, a motion is recognized from time-sequential 3D-positions of few points of human body. After motion recognition, a human direction is detected by matching the head movement of recognition result s and the movement of detected head position. At last 3D-positions of parts of representative motion in virtual space are adjusted to detected 3D-positions of parts by using Jacobian matrix.Simulation results are presented to show an effectiveness of this method.
1992	Voice-reactive facial expression graphics feedback for improved human-to-machine speech input	When people talk to each other, they nod and change their facial expression while listening to each other in response to what the other says. Neonates are also observed to respond to their mother's voice in this way. Facial reactions to speech therefore appear to be an essential part of communication, and this reaction mechanism is adaptable to facilitate human-computer information exchange. We have reported a voice-reactive system that, with timing that simulates a human being's nodding, turns a level meter lamp on and off in response to speech input, demonstrating that visual feedback can be effective in assisting smooth speech input.
1992	Integrating animation with interfaces	Most studies about the tools for building user interfaces consider an interface as a set of graphical objects that react to the user's actions. As a consequence, such tools produce mostly static interfaces. Introducing animation by bringing graphical objects to life would allow the building of more dynamic interfaces.
1992	Maintaining legibility, structure, and style of information layout in dynamic display environments	LIGA (Layout Intelligence for Graphics Automation) is a prototype system that contains graphic design knowledge about text and image layout. The goal of the program is to produce layouts that reflect the logical structure of the content, are legible for the given viewing context, and are consistent in style. The system can generate effective layouts of information as well as adapt layouts on the fly to accommodate changes in the presentation environment.
1992	Minimalism in graphics	Two experiments examined Tufte's rule that graphs should use minimal "ink" (or filled pixels) to display data [2]. Experiment 1 showed that the time to answer questions using a graph constructed according to Tufte's rule (no axes and minimal indicators) was 13\% faster than for a more traditional graph with axes and full indicators. Experiment 2 demonstrated that (a) the advantage of the minimal graph was due to eliminating the Y-axis, (b) the ink in the indicators had no effect and, (c) the presence of an X-axis improved performance.
1992	Audio cues for graphic design	Rockit is a system for the inference of graphical constraints, embedded within a graphical editor as part of larger project on applications development. The graphical editor allows the application designer to draw application-domain-specific objects and define constraints among them. On the basis of direct manipulation techniques, Rockit can infer the most likely graphical constraints as the designer manipulates the objects. Both graphical and audio feedback are used to guide the designer towards their choices. In this short document, we present our experience in designing and using audio, as a complement to graphical feedback, for this purpose.
1992	Three-dimensional algorithm animation	Algorithm animation is the process of abstracting a program's data, operations, and semantics, and creating dynamic graphical views of those abstractions[Sta90]. Algorithm animation systems have been used for both instructional purposes such as augmenting classroom lectures and for "visually documenting" complex programs. To now, algorithm animation systems have supported only 2-D black-and-white or color views. Our work extends algorithin animation to three-dimensional computer graphics.
1992	Programming with characters	Programs are hard to build, and even harder to understand after they are built. We lack intuitive interfaces for visualizing and manipulating many parts of programs and the ways in which these parts interact. Constraint systems have addressed these problems. We generalize some of the notions inherent in constraint systems to agent-based systems, and explore the use of animated characters as interface representations of agents. In particular, conflict detection and resolution is dramatized by the use of characters and their emotions. The history of their interactions is presented as a narrative using video and storyboard techniques. Building programs out of agents and enabling users to manipulate program parts by interacting with simple animated characters can aid relatively unskilled users in understanding and modifying complex systems.
1992	Rough and ready prototypes: lessons from graphic design	This paper argues that interface design can be made more effective by borrowing techniques from graphic design. User interface designers often explore interface ideas through coded prototypes, which do not facilitate quick turnaround and require a complete interface definition. This method of prototyping is too detailed and laborious to appropriately facilitate early design decisions, such as brainstorming about the task the interface will support.
1992	Digitized speech's serial position effect	Speech is becoming a more important user interface with the advent of multimedia capable video game systems, personal computers and workstations. Speech can be synthetically generated or natural speech can be digitized for storage and replay. Several studies have shown that synthetic speech is not understood as well as natural speech [2]. Synthetic speech lacks prosodic (timing) and acoustical cues to phonetic segments in comparison to natural speech. Luce et. al. [2] attributed the difficulty with synthetic speech to increased processing time requirements to encode the degraded sound. Waterworth and Thomas [3] replicated Luce et. al. serial position effect experiment and reported additional support for the encoding hypothesis by having subjects repeat words. When they adjusted for correct word encoding, the synthetic speech was similar to natural speech.
1992	Semi-structured display of telephone conversations	People spend much of their work day talking, yet the time spent talking has been out of reach of computer technology. Indeed, computer applications of stored voice are in their infancy, despite technological advances that have enabled ordinary workstations to provide audio digitization and playback. Current stored voice applications are limited to two distinct styles of audio data. The first consists of short message segments that are not meant to be listened to repeatedly, as in voice mail systems. The second is highly structured audio segments, such as in hypemedia systems, where the author creates the links and the application provides navigation.
1992	3-D Video Modeling	Motion picture studios and equipment are out of reach for most people putting together presentations that include moving imagery. Fortunately, the presentation designer can draw upon a vast and constantly growing pool of film and video footage. 3-D Video Modeling augments the footage with a 3D structural model of the set where the footage was filmed. The model can be used as a description of the footage to aid in cataloging, referencing and retrieving the footage. The footage and model together can be used to create new footage, freeing the designer from decisions made by the film maker. Objects can be altered (such as by colorization) or entirely replaced, the camera's position can be changed, the lighting can be modified, and the depth of field can be narrowed, creating a focus pull in post-production.
1992	Salient stills	The transformation of a sequence of moving images to a still image presents several problems: a loss of perceived image quality when looking at a single video frame; and a loss of context, since no individual frame captures everything conveyed in a sequence of images. We address these problems by developing a structured representation of moving image data. Using this representation we manipulate the video signal to build salient still frames, including some images with enhanced resolution. We discuss methods of automatically building a structured representation, methods for building salient stills and the potential applications of these images.
1992	Bioelectric input devices: an example: BIOLINK	As new input devices for interactive systems appear (e.g., eye pointing devices, data gloves, motion detection systems, speech recognition systems), devices based on bioelectric signals are emerging. They are still very few and mainly used for electronic music systems. This development, which have been pioneered by Rosenboom (1976), originates from the desire to control electronic music by biofeedback techniques. For example, he designed sophisticated systems which allow one to control music by the brain waves.
1992	Physically-grounded interface architecture for human-robot cooperation	Under the banner of CSCW, human to human cooperation has been studied by using computer as media. But human cooperation such as in an office environment, communication between humans is interaction not only by electronic information, but also by physical information such as physical equipments, paper documents, etc. which can not be replaced only by electronic information.
1992	Overcoming touchscreen user fatigue by workplace design	The effect of touchscreen inclination and elbow support on arm fatigue was studied in a factorial design. Inclinations were 0°, 22.5°, 30° 45°, 60° and 90° from horizontal. The subjects could or could not rest the elbow on the desk. Results indicated that an inclination of 22.5° was least fatiguing. The inclination of 30° got the highest preference ratings, however, 90° was the poorest inclinations with respect to both fatigue and precision. For all inclinations elbow support reduced arm fatigue.
1992	Natural dialog in a time-sensitive setting: a study of telephone operators	For economic reasons, the task performed by telephone operators is very time-sensitive, and the task has been studied extensively. Most of the work however has concerned the human-computer interaction between the operator and the workstation and not the human-human interaction between the operator and the customer. GOMS analyses of operators handling toll calls (1), found that conversation was on the "critical path" of the call most of the time. That is, during most of a call, verbally exchanged information was necessary for the next step. We are conducting exploratory analyses of operator-customer dialogs to learn how dialog variables might affect the speed or outcome of a call. In preliminary interviews with operators about their jobs, operators seldom mentioned the workstation, but rather talked about their job as dealing with customers in a time-sensitive way that balanced the demands of the job with the needs of the customer. The first study has focused on Directory Assistance calls, in which a customer asks for a telephone number (and/or possibly an address). The analysis focuses on what makes a long vs a short call and what makes a faster vs slower operator.
1992	Accuracy of MHP/GOMS predictions for the task of issuing recurrent commands	This short talk examines the accuracy of MHP/GOMS predictions for a task involving new and revised estimates of several MHP operators. The study consists of a cognitive modelling component to generate predicted task performance times and an experiment to collect actual task performance times. I examine prediction errors, the extent to which the predictions meet the accuracy goal (i.e., predict performance times to an accuracy of 80\% or more), and the suitability of the MHP estimates used. I also compare the predictions errors from this study with those from two other studies.
1992	Can mental models be considered harmful?	This paper deals with mental models of interactive systems and their role in human - computer interaction. In the first section, mental models are differentiated from two other kinds of cognitive phenomena: production rules and "functional cognitive maps". Next, an experiment is described, in which an interactive system was presented to students with the help of a state transition diagram or a set of "production rules". The use of production rules was found to be an advantage in this experiment. The paper concludes with a discussion of mental models in the context of skill automatization and user interface transparency problems.
1992	Virtual open office: supporting effective open contact	Media spaces such as CAVECAT[6] and RAVE[3] have been designed to facilitate collaborative work at a distance, but they have primarily focused on the use of computer managed audio and video as mechanisms to support meetings and video phone calls. Research has shown that frequent and spontaneous informal communication is crucial for project coordination and that the amount of communication that occurs varies directly with the proximity of co-workers[2, 4]. However, proximity is not always possible or desirable in today's work world. We suggest that a large amount of communication among co-workers is not from actual intentional communication contact but from opportunistic contact and environmental scanning in which each individual is picking up valuable coordination information. In an open office, proximal co-workers can overhear relevant conversations, view levels of partner progress, perceive changes in project direction, note co-worker's skill advantages and disadvantages, etc. on a real time basis. We propose that it is this aspect of the constant contact of an open office environment which provides the closeness and cohesion necessary for effective work coordination. The environment we want to create with the multi-media tools is not one of supporting meetings but one of supporting constant and continuous contact among co-workers. We want to simulate a shared office and have co-workers who may be miles apart or a simple corridor away working together in the environment to maintain a sense of group. We do not suggest that meeting support by media spaces is inappropriate, but rather, that it is insufficient for the type and amount of communication needed in complex detailed work assignments.
1992	Rules of thumb for designing effective external aids	Even with good design, users' needs differ and users change over time. Users' own practices in designing external aids were studied in four domains: a focused analysis of how general aviation pilots remember to perform a task that is commonly forgotten, special activities performed by commercial airplane pilots, warnings and notes posted around copy machines, and ways people get around problems in their homes with devices such as VCRs. I will present design principles based on common occurrences across these studies. It is valuable to study such aids as a guide for redesign.
1992	The electronic receptionist: a knowledge-based approach to personal communications	The phenomenal increase in the use of pagers, car phones, cordless telephones, and other personal communications devices testifies to the fact that communications is an essential element of life in the 1990's. Even with these devices many people are still effectively out of reach, however, because at any given time callers do not know which of the many numbers associated with an individual to try.
1992	WeMet: progress report on a pen-based meeting support tool	WeMet (Window Environment Meeting Enhancement Tool), is a prototype pen-based meeting support tool which allows meeting participants in the same or different room to share a work-space for sketching and writing or for the presentation of images. In addition to facilitating real-time communication among participants. WeMet enables the review and selective retrieval of meeting information, during or after the meeting. This presentation describes the rationale for key functionality and interface decisions in the design of WeMet, and reports on the experiences of users with the prototype to date.
1992	IDEAL: a tool to enable user-centered design	While UIMSs and other tools are advancing as cost-effective ways of producing interfaces, attention to usability is rarely incorporated. Producing interfaces more rapidly without addressing their quality is of limited worth. We present a tool, IDEAL (Interface Design Environment and Analysis Lattice), that encourages and enables user-centered design as an integral part of the interface development process. IDEAL integrates usability engineering techniques and behavioral task representations with a graphical hierarchy of associated benchmark tasks to support formative evaluation of an evolving user interface. Empirical evaluation showed IDEAL to be useful for managing the formative evaluation techniques currently performed manually.
1992	A seeded design environment for service creation	We are building and testing a set of computer-based design tools for creating telephone operator services. Currently at NYNEX, operator services are created by a small team of skilled developers using a programming language called SCL (Service Creation Language).The tools we are developing are part of a domain-oriented design environment for operator services. This environment will empower people who are knowledgeable in the domain to create services directly rather than requiring the task to be delegated to SCL developers. Our approach toward achieving this is twofold: (1) understanding the language of the operator services domain, and (2) representing this language in a seeded design environment.
1992	The music methodology for usability measurement	NPL is developing a rigorous methodology for usability measurement and specification as part of the collaborative European ESPRIT project MUSIC (Metrics for Usability Standards in Computing). The methodology, being developed in conjunction with the HUSAT Research Institute, will enable a procurer to specify usability requirements for a product, so that the product can subsequently be assessed to find whether it meets these requirements. The project builds on and extends existing work in the area (eg [10]).
1992	What is gained and lost when using methods other than empirical testing	Traditional laboratory usability testing is frequently not performed due to a company's lack of funds, planning, or human factors expertise. Consequently, there is increasing interest in finding alternative usability testing methods that are easier and cheaper to implement than traditional laboratory usability testing. Recent studies are beginning to study and compare such techniques. These methods include Heuristic Evaluation (Nielsen and Molich, 1990), and Cognitive Walkthrough (Polson, Lewis, Rieman, & Wharton, 1990). For Heuristic Evaluation, Nielsen (1991) found that human-factors Experts were the best at finding an interface's usability problems, especially Experts who were also expert in the interface domain. Desurvire, Lawrence, & Atwood (1991) found Experts' evaluations were the most reliable, and their best guess predictions were predictive of laboratory performance. Karat, Campbell, & Fiegel (1992) similarly found that heuristic results were reliable and significantly predictive of laboratory data, yet empirical laboratory testing identified four and five times as many problems. Jeffries, Miller, Wharton, and Uyeda (1991) found that via Heuristic Evaluation, more severe problems were found than with laboratory testing or the Cognitive Walkthrough. This comparison study did, however, only utilize Experts in the heuristic condition, and System Designers in the Cognitive Walkthrough.
1992	Observer accuracy in usability testing: the effects of obviousness and prior knowledge of usability problems	Usability testing is often employed for evaluating user interfaces. Rosenbaum (1989) stated that usability evaluators require both an in-depth understanding of experimental design and methodology, and familiarity with an existing body of literature in human factors and usability. While many people, particularly in the social sciences, meet the first criteria, few have combined their experimental methodology training with human factors training. Psychologists and other social scientists without human factors training are, therefore, often hired to conduct usability tests. The accuracy of these observers, and the factors that affect observer performance in usability testing are unknown. A study was conducted to examine trainee observer performance in usability testing. Two factors that may affect observer performance, obviousness of usability problems and prior knowledge of problems, were examined.
1992	Reliability of severity estimates for usability problems found by heuristic evaluation	Ratings from single evaluators are very unreliable when usability specialists judge the severity of usability problems found by heuristic evaluation, but the mean severity rating from four evaluators gets within half a rating point of the true severity 95\% of the time. Also, the evaluators do agree that usability problems found by heuristic evaluation are all real problems even though each rater had originally only identified a small proportion of the problems.
1992	Knowledge structure and subject access	Previous studies of library on-line catalogs [5], have identified subject searching as both the most popular method of access as well as the most problematic. These findings have stimulated a large amount of research on subject or topical access, most focusing on the <u>vocabulary</u> of the subject headings list and ways to improve its richness (e.g. [4]) There have been fewer explorations of the problems inherent in the <u>structure</u> of the Library of Congress Subject Headings (LCSH) and how this structure combined with user's knowledge structure contributes to the subject searching problem. Because knowledge structure has been shown to differentiate between novices and experts [2], and because expertise affects success in searching online catalogs [1], knowledge structure may play a role in subject searching. Results from a previous field study have confirmed these expectations. Therefore, to further test this hypothesis, this study examines how the knowledge structures of experts and novices in a given field differ from the structures of librarians and the LCSH for that field.
1992	Personalized information delivery: an analysis of filtering methods	Increasing amounts of information in electronic form are becoming available. With this overload, it is not often possible to keep up to date with the current literature. Thus, automatic methods to filter out the non-relevant information have become more important and can serve a practical purpose. Information filtering methods could, for example, deliver personalized lists describing research that is relevant to any particular person's interests.
1992	IRMail: a minimal interface for a retrieval system	One of the primary problems with using information retrieval systems are problems of access. The access problems for IR can be categorized into: problems of physically accessing the IR system, problems of using the correct retrieval syntax to access the stored information, and problems of using the correct keywords to access the stored information. The goals for this project were to develop a simple retrieval system that would contain much of the functionality of existing retrieval systems, while minimizing the problems of access. Thus, it serves as a system that can be easily accessed and used with minimal effort or instruction. This poster provides a brief description of the motivation for, and implementation of IRMail, and then describes how HCI researchers may perform searches on the HCIBIB archives with IRMail.
1992	Strategy for managing metaphor mismatching	In this poster, we propose a new strategy for designing the interface metaphor. We show that metaphor mismatching dynamically occurs during user task execution. Then, we show a strategy for detecting the occurrence of metaphor mismatching and for managing problems which are caused by this mismatching.
1992	The electronic scrapbook: knowledge representation and interface design for desktop video	Video is increasingly being manipulated on computer systems. Can an interface for video manipulation be made sufficiently simple and powerful to free the user's attention to focus on creative aspects of the medium? How are images to be described so that they can be retrieved? How is this representation to be presented to the user? Issues of knowledge representation and interface design are tightly linked. The Electronic Scrapbook is an environment designed to encourage people to use home video as a creative medium. This work addresses issues of knowledge representation, narrative structure, and interface design. To date, I have: •Developed the metaphor of a scrapbook as an interface for a video manipulation environment. •Applied a semantic network to video logging. •Implemented a pane-based video logging interface, which keeps information organized and minimizes screen clutter (see Figure 1). •Used inheritance to save the user work in logging video. •Created a library of story models, which help the user to tell home-video stories. •Applied the use of specific domain knowledge to help the user. •Focused on viewing the computer and the user as partners in a creative process. •Implemented a working system. Issues still to be solved include: •Designing an interface to allow the user to create new story models. •Extending the logging interface to allow the user to modify the underlying ontology. •Creating ontologies for additional subject domains. •Integrating object and stream representations of video to maintain simplicity while better accounting for video's temporal nature. •Testing the design on real users. Computer technology promises to make video more accessible to the non-specialist. However, careful interface design is needed to hide technical complexities and free the user's attention to learn about narrative structures and the creative potential of the medium. Using detailed color screen shots of the interface, I will be able to discuss the solutions I have obtained so far and the challenges that remain for incorporating video in the interface.
1992	Why can't I adjust my refrigerator's temperature?: or What's wrong with my mental model?	Have you ever had difficulty adjusting your refrigerator temperature, setting your VCR program, or transferring a call to another extension? The source of these difficulties is often a failed mapping between the designers' and the users' models of a system (Norman, 1988); in brief, user's have flawed mental models (or devices have flawed designs). This study examined how providing explicit models to users or allowing them to explore the system's functioning could serve as a bridge between designer and user device images. Using a simple device, the temperature controls in a refrigerator, we compared performance on temperature adjustment using an explicit model, an implicit model, and a no model condition. Exploration was introduced as an alternative to explicit presentation of a model; subjects could try out the simulated device before beginning a specific task. Although this type of exploration has gained increased popularity as a training strategy, there appear to be substantial individual differences in the utility of that approach. Some people enjoy the assimilation of information and focus on the question rather than on any specific resolution ("perceivers"), and these people are likely to enjoy exploration. Other people, in contrast, are focussed on answers and prefer closure ("judgers"); an exploratory environment is likely to be less useful for that group. We analyzed whether these general differences in cognitive style would influence the utility of exploration as a learning tool in our task.
1992	A self-promoting and explanatory audio control panel	This poster describes our involvement in the design of the user interface for a hi-fi audio set. The "life cycle" of a consumer-electronics product can, for the owner, roughly be divided into four phases: (1) first impression, (2) initial use, (3) long-term use and (4) replacement. During each of these phases different aspects of the user interface of the product are important. The first two phases, first impression and initial use, normally take place in the store where the product has to compete with other brands and models. The first-impression phase starts when potential buyers are shopping around and a product catches their eyes. During this phase it is important how the product promotes itself among competing products ( self-promotion ) and what kind of expectations the product elicits, i.e. the perceived potential. After some time the potential buyer selects the product for a closer inspection, and will typically start to perform some baseline tasks, starting the initial-use phase. Then it is important how the product's features are recognized ( self-explanation ). After the purchase decision has been made, the product enters the home where it has to comfort the owner. That is when the transition from initial to long-term use takes place. During long-term use, classical usability issues are dominant. The expectations that the user has acquired of the product are checked. Eventually the product will be replaced or become obsolete.
1992	Home networks: the RACE DCPN project	This paper reports on the development of a user interface to a home system network intended to provide the domestic user with easier usage of domestic devices and access to external services. The work has been conducted under the CEC RACE (Research and Development in Advanced Communications Technologies in Europe) programme which addresses the delivery of future electronic services both to the business world and to the home.
1992	IBC systems and services usability engineering: the RACE issue project	This paper reports on a human factors project investigating the usability of videocommunications and multimedia services that will be developed for the emerging Integrated Broadband Communications (IBC) Networks of the future. The first three years of this four year project were spent conducting basic human factors research, for example, how would people like to control full motion video at the computer interface? What is the smallest image size at which facial gestures can be accurately determined on a high definition TV display? The final year of the project is to be spent in compiling various guidelines for the designers of IBC systems and services. This work has been conducted under the CEC RACE (Research and Development in Advanced Communications Technologies in Europe) programme.
1992	Specialized methods do not always increase efficiency	The current research is a complex, 5 day, training experiment investigating several questions about the learning and use of software methods. Central issues concern the situation in which a software user knows more than one obvious method for accomplishing a task at hand. We call this situation "multiple methods". Multiple methods seem to arise most often from the creation of commands or functions specialized for a subclass of tasks. For example, in a word processing application there are often several ways to move the cursor, with arrow keys, by word, by line, by page, to end of line, to start of line, to top of document, and to bottom, to name some common methods. Designers and users typically assume that the existence and use of multiple methods in an application increases user efficiency. We tested that assumption directly. In this experiment we investigated the effects of multiple methods during learning and performance measuring task time, planning time, and error rates and types. In addition, we also investigated strategies subjects employed when choosing between their methods. In a rigorous training regime using the spreadsheet software Lotus 123, subjects learned one or two ways to move the cursor and one or two ways to sum the contents in a section of cells. During the 5 day experiment, subjects repeatedly moved the cursor to an indicated location and entered a formula summing an adjacent group of numbers. Cursor movements were of varying distances and sums involved various numbers of addends. On the first day, subjects were taught their method set which they practiced to a criterion of 24 consecutive correct repetitions. On days 2 and 3 (practice), subjects performed tasks comprised of 128 repetitions of their method set. On every task, the best method was assigned in the instructions and used by the subjects. The best method was determined by constructing theoretical keystroke models of the methods (see Olson & Nilsen, 1988) and assigning the most rapid method. During practice, the order in which the methods were used was counter-balanced. On days 4 and 5 (testing), subjects performed 338 similar tasks but selected the method themselves on every task. These 338 tasks were comprised of thirteen different cursor task distances and thirteen sizes of sums sampled thirteen times each. During both practice and testing, subjects used the <enter> key to toggle between task instructions and the spreadsheet on which the tasks were performed. During a cursor task, the target cell was not indicated until the subject removed the instruction screen stating: "move the cursor to the target cell using the X method". Similarly, during a summation task, the addends were apparent only after the instruction screen was removed. This allowed partitioning of the total task time into planning time and typing times. During both practice and testing, and on both cursor and summation tasks, subjects who knew two methods for a task made more errors on that task type (matched tasks) only. That is, knowing two sum methods increased the number of sum task errors, but did not increase the number of cursor task errors. Similarly, knowing two cursor movement methods increased the number of cursor task errors, but not summation task errors. In addition, two method subjects were no faster on matched tasks than were one method subjects, despite their specialized methods. In fact, the two method subjects had <u>longer</u> planning times on matched tasks than did one method subjects. Once again, these effects of knowing two methods were segregated to matched tasks. It is interesting to compare the two groups of subjects that each knew three methods as a way of controlling for effects of workload imposed purely by the number of methods known. The subjects with two cursor methods and one sum method (2-1 subjects) were compared to those with one cursor method and two sum methods (1-2 subjects). Consonant with the results above, 2-1 subjects made more cursor task errors than did the 1-2 subjects who made more sum task errors. Increases in planning time at the start of the task followed this same pattern. Although error rates were low and task time differences modest ---between 500 to 3000 msec---in a population of "real users" who know more commands and do not undergo such rigorous practice the differences are expected to be much larger. These results contradict the common assumption that specialized methods for subclasses of tasks increase a user's efficiency. In addition, these results demonstrate the costs of multiple methods even in an impoverished repertoire of only four commands.
1992	A comparison of direct-manipulation, selection, and data-entry techniques for re-ordering fields in a table	A common type of display in many computer systems is a table that shows values of several different properties for a list of files. In designing such a display for a forthcoming product, we thought it would be helpful to allow the user to change the order in which the fields appear in the columns of the table. The specific fields that the user could re-order were file name, number, size, and creation date. Seven different approaches to re-ordering the fields were studied in the Microsoft Windows environment. Due to constraints imposed by the application, it was necessary to have the user do the re-ordering in a dialog box separate from the main display of the files.
1992	Does the user interface make interruptions disruptive?: a study of interface style and form of interruption	This experiment examined the influence of the style of the computer user interface on the extent to which performance was decreased by task interruption. Performance on data entry of a personnel database was compared using two different styles of interfaces, under three different forms of interruption. Ten subjects were given a graphical user interface with a mouse and screen buttons; and ten were given a character-based interface with tab and function keys. Interruptions came at unexpected times. Each subject was interrupted three times, once with each form of interruption: telephone call, visitor, and on-screen message. During each interruption, the subject was asked to answer a simple question. The number of fields entered minus the number of fields in error, per minute, was measured during the two-minute post-interruption period. Eye motion data was analyzed in terms of the amount of time and the average durations of eye fixations on the screen. An exit questionnaire solicited the subjects' perceptions of their performance. Compared to the control, the screen interruption was disruptive, the telephone interruption was not, and the walk-in visitor interruption produced intermediate performance. Performance was worse in the first minute than in the second minute immediately following the interruptions. Lower performance was directly related to looking more at the screen. The duration of the interruption was weakly correlated to the performance. Subjects' perceptions of their performance did not correlate with performance measures. The disruptive effect of the screen interruption compared to the lack of disruption after the telephone interruption was a surprise. This result is contrary to the commonly held belief that telephone interruptions are a problem to computer users. It may be important to avoid disruption caused by screen windows popping up in design of multi-window user interfaces. Trends in office automation have the screen being used for more and more functions, with demands on screen displays being further aggravated by information available through integrated networks. The disruption of the screen interruption may be due to the abruptness of the on-set of the interruption which prohibited the subject from completing the current action. The message box locked out the main task until the subject responded to the question. This differed from the onset of the walk-in and telephone interruptions which did not lock out interaction with the main task. Another possible explanation for the disruption of the screen interruption compared to the telephone interruption may be the similarity in sense modality. This work is seen as preliminary to further study.
1992	Computer-based workstation design evaluations	Future Space Station crewmembers will be working at the computer-based workstations. Command and control critical mission objectives will be conducted from these multi-monitor workstations with direct manipulation interfaces. It is important to determine the workstation design requirements for safe and effective crew interfaces. When developing the design criteria, individual capabilities and limitations such as viewing requirements, head clearances, reach and body size must be considered as well as the tasks to be performed, and resources (i.e., displays and controls) available. The dominant factor in space affecting the crew is "weightlessnes" which creates a challenge for establishing workstation microgravity design requirements.
1992	Interface design for individuals with mild learning disabilities from traumatic brain injury	Learning disabilities involve a disruption to one or more aspects of cognitive processing. Because CHI relies so heavily on cognitive processes for interface designs, the learning disabilities area presents challenges to the interface designer. Individuals with learning disabilities score in the bottom 5 th percentile on one or more cognitive dimension involving perception, memory, concentration, problem solving, functional integration, etc.
1992	Eloquent video expressions (ELVES): a communication system design for people with linguistic or neurological limitations	ELoquent Video ExpressionS (ELVES) is a communication system for people who have difficulty expressing complex ideas because of linguistic or neurological limitations. Users employ a simple gesture-based video editor to construct expressions that demonstrate their ideas visually. ELVES includes an extensive scenario library that contains detailed depictions of common activities. The user chooses scenarios with subsections that are useful for expressing a particular idea and then combines the subsections into a new video expression. The underlying technology is digital video, which is stored and transmitted electronically. Users can therefore create correspondence in addition to expressions that are used for immediate communication.
1992	Realtime graphical display of intonation for speech training	A realtime visual intonation-display system for the teaching of intonation is presented. This system can be used for the teaching of intonation of foreign languages to second-language learners and of intonation of native language to deaf persons. In contrast to other visual-display systems, the visual feedback on intonation is given as a continuous representation of the pitch contour. The pitch contour contains only the perceptually relevant variations in pitch. That is, the course of the pitch contour is approximated with the help of a small number of straight lines resulting in the so-called stylized pitch contour.
1992	On-line help: are we tossing the users a life saver or an anchor?	On-line Help is a necessary part of today's software applications. The challenge of creating an effective online Help system faces most every development team. Unfortunately, the users and the developers frequently differ in their opinions about the usefulness of the on-line Help information.
1993	From “folklore” to “living design memory”	We identify an important type of software design knowledge that we call community specific folklore and show problems with current approaches to managing it. We built a tool that serves as a living design memory for a large software development organization. The tool delivers knowledge to developers effectively and is embedded in organizational practice to ensure that the knowledge it contains evolves as necessary. This work illustrates important lessons in building knowledge management systems, integrating novel technology into organizational practice, and managing research-development partnerships.
1993	Where did you put it? Issues in the design and use of a group memory	Collaborating teams of knowledge workers need a common repository in which to share information gathered by individuals or developed by the team. This is difficult to achieve in practice, because individual information access strategies break down with group information—people can generally find things that are on their own messy desks and file systems, but not on other people's. The design challenge in a group memory is thus to enable low-effort information sharing without reducing individuals' finding effectiveness. This paper presents the lessons from our design and initial use of a hypertext-based group memory, TeamInfo . We expose the serious cognitive obstacles to a shared information structure, discuss the uses and benefits we have experienced, address the effects of technology limitations and highlight some unexpected social work impacts of our group memory.
1993	Facile 3D direct manipulation	An experimental 3D interface is described, including rendering acceleration hardware, a 3D mouse, and 3D interaction techniques. A 3D cursor, controlled by the augmented mouse, allows direct manipulation of 3D objects. Objects are selected by placing the tip of the cursor inside. Objects can be moved in 3D, or simultaneously moved and rotated using a technique called “tail-dragging.” A method called “snap-to” helps users align objects. The interface is designed without using explicit modes or commands. Sounds accentuate the interaction. Details of the implementation and informal user observations are described, as well as topics for future work.
1993	Fish tank virtual reality	The defining characteristics of what we call “Fish Tank Virtual Reality” are a stereo image of a three dimensional (3D) scene viewed on a monitor using a perspective projection coupled to the head position of the observer. We discuss some of the relative merits of this mode of viewing as compared to head mounted stereo displays. In addition, we report the experimental investigation of the following variables: 1) whether or not the perspective view is coupled to the actual viewpoint of the observer, 2) whether stereopsis is employed. Experiment 1 involved the subjective comparison of pairs of viewing conditions and the results suggest that head coupling may be more important than stereo in yielding a strong impression of three dimensionality. Experiment 2 involved subjects tracing a path from a leaf of a 3D tree to the correct root (there were two trees intermeshed). The error rates ranged from 22\% in the pictorial display, to 1.3\% in the head coupled stereo display. The error rates for stereo alone and head coupling alone were 14.7\% and 3.2\% respectively. We conclude that head coupling is probably more important than stereo in 3D visualization and that head coupling and stereo combined provide an important enhancement to monitor based computer graphics.
1993	HCI in the school of computer science at Carnegie Mellon University	People use computers to accomplish tasks. Consequently, understanding human capabilities and tasks is as important to the design of computer systems as understanding computer technologies. The School of Computer Science (SCS) at Carnegie Mellon University (CMU) has become home to an interdisciplinary community that performs research on HCI issues, develops systems using HCI methods of design and evaluation, and trains students in the theory and skills necessary to become HCI professionals.
1993	A space based model for user interaction in shared synthetic environments	In a distributed shared synthetic environment with provisions for high quality 3D visualization and interaction, it is possible to implement a powerful variant of a rooms/space metaphor based on the concept of presence or proximity between participants in 3D space. This kind of model can be used as an interface between the user and the computer, for overview and control of applications, file systems, networks and other computer resources, as well as for communication and collaboration with other users in the networked environment. We model proximity with a geometric volume of the immediate surroundings, the aura , of the participant's representation in the synthetic environment. This proximity, or aura, is used to establish presence at meetings, to establish communication channels and to provide interaction.
1993	Software for the usability lab: a sampling of current tools	This panel brings together usability professionals throughout the computer industry to demonstrate and discuss their usability lab software tools. These tools are specifically designed to improve the data collection and analysis process for usability labs. Their capabilities range from simple to complex and the panel will not only discuss the benefits of using the tools but also share the lessons learned during the design and development process.
1993	Do algorithm animations assist learning?: an empirical study and analysis	Algorithm animations are dynamic graphical illustrations of computer algorithms, and they are used as teaching aids to help explain how the algorithms work. Although many people believe that algorithm animations are useful this way, no empirical evidence has ever been presented supporting this belief. We have conducted an empirical study of a priority queue algorithm animation, and the study's results indicate that the animation only slightly assisted student understanding. In this article, we analyze those results and hypothesize why algorithm animations may not be as helpful as was initially hoped. We also develop guidelines for making algorithm animations more useful in the future.
1993	Reducing the variability of programmers' performance through explained examples	A software tool called EXPLAINER has been developed for helping programmers perform new tasks by exploring previously worked-out examples. EXPLAINER is based on cognitive principles of learning from examples and problem solving by analogy. The interface is based on the principle of making examples accessible through multiple presentation views and multiple representation perspectives. Empirical evaluation has shown that programmers using EXPLAINER exhibit less variability in their performance compared to programmers using a commercially available, searchable on-line manual. These results are related to other studies of programmers and to current methodologies in software engineering.
1993	Integrating theoreticians' and practitioners' perspectives with design rationale	QOC design rationale represents argumentation about design alternatives and assessments. It can be used to generate design spaces which capture and integrate information from design discussions and diverse kinds of theoretical analyses. Such design spaces highlight how different theoretical approaches can work together to help solve design problems. This paper describes an example of the generation of a multi-disciplinary QOC design space which shows how designers' deliberations can be augmented with design contributions from a combination of different theoretical HCI approaches.
1993	Management of interface design in humanoid	Today's interface design tools either force designers to handle a tremendous number of design details, or limit their control over design decisions. Neither of these approaches taps the true strengths of either human designers or computers in the design process. This paper presents a human-computer collaborative system that uses a model-based approach for interface design to help designers on decision making, and utilizes the bookkeeping capabilities of computers for regular and tedious tasks. We describe (a) the underlying modeling technique and an execution environment that allows even incompletely-specified designs to be executed for evaluation and testing purposes, and (b) a tool that decomposes high-level design goals into the necessary implementation steps, and helps designers manage the myriad of details that arise during design.
1993	The evolution of an interface for choreographers	This paper describes the evolution of the interface to Life Forms , a compositional tool for the creation of dance choreography, and highlights some of the important lessons we have learned during a six year design and implementation period. The lessons learned can be grouped into two categories: 1) Process, and 2) Architecture of the Interface. Our goal in developing a tool for choreography has been to provide computer-based creative design support for the conception and development of dance. The evolution was driven by feedback from the choreographers and users who were members of the development team, combined with our knowledge of current thinking on design and composition. Although the interface evolved in a relatively unconstrained way, the resulting system has many of the features that theoretical discussion in human interface design has projected necessary. The Life Forms interface has evolved incrementally with one major discontinuity where adoption of a new compositional primitive required a completely new version.
1993	Human-machine perceptual cooperation	The Human-Machine Perceptual Cooperation (HMPC) paradigm combines a human operator's high level reasoning with machine perception to solve spatio-perceptual intensive problems. HMPC defines two channels of interaction: the focus of attention (FOA) by which the user directs the attention of machine perception, and context . As the user moves the FOA across a display via a pointing device, a smart cursor operates proactively on the data, highlighting objects which satisfy the current contest. The FOA permits foveal emphasis, enabling the user to vary motor precision with image clutter. HMPC provides for contexts at four levels of abstraction. This permits the efficiency of the system to degrade gracefully as data quality worsens. We describe a document analysis application to which HMPC is applied. In this project, a human operator works with a machine to convert scanned raster maps into vector format.
1993	VideoMAP and VideoSpaceIcon: tools for anatomizing video content	A new approach to interacting with stored video is proposed. The approach utilizes VideoMAP and VideoSpaceIcon. VideoMAP is the interface that shows the essential video features in an easy to perceive manner. VideoSpaceIcon represents the temporal and spatial characteristics of a video shot as an intuitive icon. A video indexing method supports both tools. These tools allow the user's creativity to directly interact with the essential features of each video by offering spatial and temporal clues. This paper introduces the basic concept and describes prototype versions of the tools as implemented in a video handling system. VideoMAP and VideoSpaceIcon are effective for video handling functions such as video content analysis, video editing, and various video applications which need an intuitive visual interface.
1993	Automatic structure visualization for video editing	We developed intelligent functions for the automatic description of video structure, and visualization methods for temporal-spatial video structures obtained by these functions as well as for the functions. The functions offer descriptions of cut separations, motion of the camera and filmed objects, tracts and contour lines of objects, existence of objects, and periods of existence. Furthermore, identical objects are automatically linked. Thus the visualization methods supported by object-links allow users to freely browse and directly manipulate the structure including descriptions and raw video data.
1993	Agentsheets: a tool for building domain-oriented visual programming environments	Visual programming systems are supposed to simplify programming by capitalizing on innate human spatial reasoning skills. I argue that: (i) good visual programming environments should be oriented toward their application domains, and (ii) tools to build domain-oriented environments are needed because building such environments from scratch is very difficult. The demonstration illustrates how the visual programming system builder called Agentsheets addresses these issues and demonstrates several applications built using Agentsheets.
1993	Mondrian: a teachable graphical editor	Mondrian is an object-oriented graphical editor that can learn new graphical procedures through programming by demonstration. A user can demonstrate a sequence of graphical editing commands on a concrete example to illustrate how the new procedure should work. An interface agent records the steps of the procedure in a symbolic form, using machine learning techniques, tracking relationships between graphical objects and dependencies among the interface operations. The agent generalizes a program that can then be used on “analogous” examples. The generalization heuristics set it apart from conventional “macros” that can only repeat an exact sequence of steps. The system represents user-defined operations using pictorial “storyboards” of examples. By bringing the power of procedural programming to easy-to-use graphical interfaces, we hope to break down the “Berlin Wall” that currently exists between computer users and computer programmers.
1993	Usability measurement: its practical value to the computer industry	This panel will consider the role of usability measurement in the design process. It will address the time needed to perform usability evaluations and compare this process with that of expert assessment. This topic will be discussed in the industrial context of developing computer products within strict timescales. However it will also be seen against the traditional problem of needing to set usability goals and to measure their achievement if usability is to be given the same priority as the more technical software engineering objectives.
1993	The growth of software skill: a longitudinal look at learning & performance	This research follows a group of users over time (16 months) as they progress from novice towards expert in their use of Lotus 1-2-3. Quantitative and qualitative measures of performance are compared with expert users having over three years of experience. The results indicate that the motor aspects of performance are relatively stable over time, while improvement in the cognitive components of the skill are dependent on aspects of the menu structure and how many things must be retrieved from memory, among other things. These results imply extensions to the Keystroke Level Model of skilled performance as well as suggest ways to design the user interfaces so as to speed the acquisition of expertise.
1993	Embedding computer-based critics in the contexts of design	Computational critiquing mechanisms provide an effective form of computer-human interaction supporting the process of design. Critics embedded in domain-oriented design environments can take advantage of additional knowledge residing in these environments to provide less intrusive, more relevant critiques. Three classes of embedded critics have been designed, implemented, and studied: Generic critics use domain knowledge to detect problematic situations in the design construction. Specific critics take advantage of additional knowledge in the partial specification to detect inconsistencies between the design construction and the design specification. Interpretive critics are tied to perspective mechanisms that support designers in examining their artifact from different viewpoints.
1993	How to aid non-experts	Aiding functions may be added to a computer system, so that users with insufficient knowledge can perform their tasks. The aiding should be integrated into the task execution of such users. Empirical knowledge is lacking about the conditions for successful aiding. We evaluated the on-line help system of the statistical software package SPSS/PC. It appears that the addition of help facilities to the system worsens the task performance and learning of novices substantially. In our view, the addition of help is harmful, because communication with the system is more complex as a result, whereas the help hardly provides the task support that novices need. De Greef et al. [5] provide two design principles that result in consistent communication and aiding in correspondence with users' needs: (i) the design of aiding functions is an integrated part of interface design and (ii) aiding is based upon an expert model of the users' task. We evaluated an interface for the statistical program HOMALS, which was designed according to these principles. As a consequence of the addition of aiding functions, non-expert users perform their tasks better and learn more.
1993	A design space for multimodal systems: concurrent processing and data fusion	Multimodal interaction enables the user to employ different modalities such as voice, gesture and typing for communicating with a computer. This paper presents an analysis of the integration of multiple communication modalities within an interactive system. To do so, a software engineering perspective is adopted. First, the notion of “multimodal system” is clarified. We aim at proving that two main features of a multimodal system are the concurrency of processing and the fusion of input/output data. On the basis of these two features, we then propose a design space and a method for classifying multimodal systems. In the last section, we present a software architecture model of multimodal systems which supports these two salient properties: concurrency of processing and data fusion. Two multimodal systems developed in our team, VoicePaint and NoteBook, are used to illustrate the discussion.
1993	VoiceNotes: a speech interface for a hand-held voice notetaker	VoiceNotes is an application for a voice-controlled hand-held computer that allows the creation, management, and retrieval of user-authored voice notes —small segments of digitized speech containing thoughts, ideas, reminders, or things to do. Iterative design and user testing helped to refine the initial user interface design. VoiceNotes explores the problem of capturing and retrieving spontaneous ideas, the use of speech as data, and the use of speech input and output in the user interface for a hand-held computer without a visual display. In addition, VoiceNotes serves as a step toward new uses of voice technology and interfaces for future portable devices.
1993	Communicative facial displays as a new conversational modality	The human face is an independent communication channel that conveys emotional and conversational signals encoded as facial displays. Facial displays can be viewed as communicative signals that help coordinate conversation. We are attempting to introduce facial displays into computer-human interaction as a new modality. This will make the interaction tighter and more efficient while lessening the cognitive load. As the first step, a speech dialogue system was selected to investigate the power of communicative facial displays. We analyzed the conversations between users and the speech dialogue system, to which facial displays had been added. We found that conversation with the system featuring facial displays was more successful than that with a system without facial displays.
1993	Sign language interfaces	This panel will start to build the bridge between behavioral scientists who know deaf communities worldwide, their languages and cultures, and experts in technical disciplines relating to computers and human interfaces.
1993	Iterative methodology and designer training in human-computer interface design	One of the most promising methods for user interface design is the iterative design methodology. To this point only case study support for this method has been given. There are still many unanswered questions about the effectiveness of this method. One difficulty encountered in user interface design is knowing what set of knowledge and skill the designer must possess to ensure good user interface design. Many different people have designed user interfaces for computer systems. These people came from a variety of backgrounds and viewpoints. Two of the most common groups involved in user interface design are human factors specialists and programmers. This study investigates these two issues. One factor in this study is the iterative design methodology. An empirical evaluation of this method was conducted. The strengths and weaknesses of this method are discussed. A second factor in this study is a comparison of human factors specialists and programmers in an actual user interface design task. The results of this study indicate that iterative design methodology can improve the usability of a product. The amount of the improvement may be constrained by the original design. This study also supports the use of human factors specialists in user interface design. A significant difference between designs produced by human factors specialists and programmers was found.
1993	A mathematical model of the finding of usability problems	For 11 studies, we find that the detection of usability problems as a function of number of users tested or heuristic evaluators employed is well modeled as a Poisson process. The model can be used to plan the amount of evaluation required to achieve desired levels of thoroughness or benefits. Results of early tests can provide estimates of the number of problems left to be found and the number of additional evaluations needed to find a given fraction. With quantitative evaluation costs and detection values, the model can estimate the numbers of evaluations at which optimal cost/benefit ratios are obtained and at which marginal utility vanishes. For a “medium” example, we estimate that 16 evaluations would be worth their cost, with maximum benefit/cost ratio at four.
1993	Estimating the relative usability of two interfaces: heuristic, formal, and empirical methods compared	Two alternative user interface designs were subjected to user testing to measure user performance in a database query task. User performance was also estimated heuristically in three different ways and by use of formal GOMS modelling. The estimated values for absolute user performance had very high variability, but estimates of the relative advantage of the fastest interface were less variable. Choosing the fastest of the two designs would have a net present value more than 1,000 times the cost of getting the estimates. A software manager would make the correct choice every time in our case study if decisions were based on at least three independent estimates. User testing was 4.9 times as expensive as the cheapest heuristic method but provided better performance estimates.
1993	An evaluation of earcons for use in auditory human-computer interfaces	An evaluation of earcons was carried out to see whether they are an effective means of communicating information in sound. An initial experiment showed that earcons were better than unstructured bursts of sound and that musical timbres were more effective than simple tones. A second experiment was then carried out which improved upon some of the weaknesses shown up in Experiment 1 to give a significant improvement in recognition. From the results of these experiments some guidelines were drawn up for use in the creation of earcons. Earcons have been shown to be an effective method for communicating information in a human-computer interface.
1993	Synthesizing auditory icons	Auditory icons add valuable functionality to computer interfaces, particularly when they are parameterized to convey dimensional information. They are difficult to create and manipulate, however, because they usually rely on digital sampling techniques. This paper suggests that new synthesis algorithms, controlled along dimensions of events rather than those of the sounds themselves, may solve this problem. Several algorithms, developed from research on auditory event perception, are described in enough detail here to permit their implementation. They produce a variety of impact, bouncing, breaking, scraping, and machine sounds. By controlling them with attributes of relevant computer events, a wide range of parameterized auditory icons may be created.
1993	Computer aided conversation for severely physically impaired non-speaking people	This paper reports the development of a computer-aided conversation prosthesis which is designed for severely physically impaired non-speaking people. The research methodology was to model aspects of conversational structure derived from the field of conversation analysis within a prototype conversational prosthesis. The prototype was evaluated in empirical investigations which also suggested successful strategies for carrying out satisfying conversation using such a system. Two versions have been built and tested, one using an able-bodied operator to test the feasibility of creating conversation from prestored material, the second being used by a physically impaired non-speaking operator. The prototype demonstrated the advantages of this interface design in helping the user to carry out natural sounding and satisfying conversations.
1993	User involvement in the design process: why, when & how?	For years the CHI community has championed the importance of the user in system development. As many of us develop systems, we find that the concept of user involvement is not so easy to implement. Does one always strive to involve the user in the design process? Are there situations when the users should not be involved? What if the user is reluctant to change? How is user involvement handled when the user claims to know all the answers and wants to design the entire interface his or her way? What if the users, or even potential users are not available? How can user involvement be accomplished under these developmental restrictions? User Involvement, therefore, may be a goal - not a given, and how to effect user involvement is not as straight forward as the text books convey! To assist the process of user interface development, many techniques have been developed such as Heuristic Evaluation, Participatory Design, Cognitive Walk Throughs, Task Analysis and Rapid Prototyping. These techniques vary considerably in the extent of user involvement that they require. This panel will attempt to match the technique with the degree of user involvement that the developer is faced with or can achieve. The issues discussed in this session are important to the entire user interface community. Developers will be happy to hear that they are not alone; others have similar problems with users. They will learn which of the techniques are best suited for each development situation. Methodologists will gain greater insight into the breadth and depth of working with, and attempting to satisfy various types of users. They may be able to better refine the technologies we now have available to meet the needs of user interface developers. Members of the audience will be invited to participate as developers and methodologists.
1993	Exploding the interface: experiences of a CSCW network	The development of human computer interaction has been dominated by the interface both as a design concept and as an artefact of computer systems. However, recently researchers have been re-examining the role of the interface in the user's interaction with the computer. This paper further examines the notion of the interface in light of the experiences of the authors in establishing a network to support cooperative work. The authors argue that the concept of the single interface which provides a focus for interaction with a computer system is no longer tenable and that richer conceptions of the inter-relationships between users and computer systems are needed.
1993	Searching for unity among diversity: exploring the “interface” concept	Despite widespread interest in the human-computer interaction (HCI) field, there remains much debate as to appropriate conceptual frameworks for the field, and even confusion surrounding the meaning of basic terms in the field. HCI is seen by many as focusing on the design of interfaces to computer systems, yet exactly what is implied by this focus on “interfaces” is unclear. In this paper we show how a better understanding of what is meant by the interface is possible via the concept of abstraction levels. We show how this levels approach can clarify some ambiguities, and also how it can be related to different phases in the evolution of the human-computer interaction field itself. In this context, we are able to account for the recent interest in activity theory as a possible alternative framework for HCI work, while stressing the need for HCI research and design to consider each of the separate, but related, levels.
1993	The cost structure of sensemaking	Making sense of a body of data is a common activity in any kind of analysis. Sensemaking is the process of searching for a representation and encoding data in that representation to answer task-specific questions. Different operations during sensemaking require different cognitive and external resources. Representations are chosen and changed to reduce the cost of operations in an information processing task. The power of these representational shifts is generally under-appreciated as is the relation between sensemaking and information retrieval. We analyze sensemaking tasks and develop a model of the cost structure of sensemaking. We discuss implications for the integrated design of user interfaces, representational tools, and information retrieval systems.
1993	Prototyping an intelligent agent through Wizard of Oz	Turvy is a simulated prototype of an instructible agent. The user teaches it by demonstrating actions and pointing at or talking about relevant data. We formalized our assumptions about what could be implemented, then used the Wizard of Oz to flesh out a design and observe users' reactions as they taught several editing tasks. We found: a) all users invent a similar set of commands to teach the agent; b) users learn the agent's language by copying its speech; c) users teach simple tasks with ease and complex ones with reasonable effort; and d) agents cannot expect users to point to or identify critical features without prompting. In conducting this rather complex simulation, we learned some lessons about using the Wizard of Oz to prototype intelligent agents: a) design of the simulation benefits greatly from prior implementation experience; b) the agent's behavior and dialog capabilities must be based on formal models; c) studies of verbal discourse lead directly to an implementable system; d) the designer benefits greatly by becoming the Wizard; and e) qualitative data is more valuable for answering global concerns, while quantitative data validates accounts and answers fine-grained questions.
1993	A synergistic approach to specifying simple number independent layouts by example	A grid-based technique to specify simple number independent layouts by example is described. This technique was originally developed to support layout specification for a parallel program visualization system but can be applied to aid other simple graphical layout tasks as well. The technique works by allowing the user to construct an example layout using a grid-based interaction technique. This example can then be generalized into a layout algorithm which can be applied to create layouts of any size. However, rather than simply choosing the “best” generalization, the system described here takes a synergistic approach. New examples from a set of alternative generalizations are presented to the user so that they can guide and control the generalization process. This provides more understanding and control of the generalization to be constructed from only one small example.
1993	Marquise: creating complete user interfaces by demonstration	Marquise is a new interactive tool that allows virtually all of the user interfaces of graphical editors to be created by demonstration without programming. A “graphical editor” allows the user to create and manipulate graphical objects with a mouse. This is a very large class of programs and includes drawing programs like MacDraw, graph layout editors like MacProject, visual language editors, and many CAD/CAM programs. The primary innovation in Marquise is to allow the designer to demonstrate the overall behavior of the interface. To implement this, the Marquise framework contains knowledge about palettes for creating and specifying properties of objects, and about operations such as selecting, moving, and deleting objects. The interactive tool uses the framework to allow the designer to demonstrate most of the end user's actions without programming, which means that Marquise can be used by non-programmers.
1993	LogoMedia: a sound-enhanced programming environment for monitoring program behavior	Even for the programmer, computer software can be a mysterious black box. But what if the programmer were able to give the box a good shake and listen to things rattle inside? Are there tools like the doctor's stethoscope that can help programmers listen to the heartbeat of their software? These are the kinds of questions we decided to explore by building LogoMedia, a sound-enhanced programming environment. LogoMedia supports the ability to associate non-speech audio with program events while the code is being developed. These associations cause subsequent test runs of the program to generate and manipulate sounds which can aid in the comprehension and analysis of the program's behavior.
1993	Heuristics in real user interfaces	It is the conventional wisdom in user interface design that direct manipulation is best and that interfaces should be predictable. This tends to argue against having a system “guess” or use heuristics or other AI approaches. However, an increasing number of today's successful software products do use heuristics in their interfaces. The heuristics are used to help guide the user and to perform tasks that would be too difficult to specify by conventional direct manipulation approaches. We believe that user interface designers will increasingly need to consider using heuristic techniques in their interfaces. This panel discusses a number of today's successful products using heuristics and the important HCI design issues such as feedback.
1993	Exploring the applications of user-expertise assessment for intelligent interfaces	An adaptive user interface relies, to a large extent, upon an adequate user model (e.g., a representation of user-expertise). However, building a user model may be a tedious and time consuming task that will render such an interface unattractive to developers. We thus need an effective means of inferring the user model at low cost. In this paper, we describe a technique for automatically inferring a fine-grain model of a user's knowledge state based on a small number of observations. With this approach, the domain of knowledge to be evaluated is represented as a network of nodes (knowledge units—KU) and links (implications) induced from empirical user profiles. The user knowledge state is specified as a set of weights attached to the knowledge units that indicate the likelihood of mastery. These weights are updated every time a knowledge unit is reassigned a new weight (e.g., by a question-and-answer process). The updating scheme is based on the Dempster-Shafer algorithm. A User Knowledge Assessment Tool (UKAT) that employs this technique has been implemented. By way of simulations we explore an entropy-based method of choosing questions, and compare the results with a random sampling method. The experimental results show that the proposed knowledge assessment and questioning methods are useful and efficient in inferring detailed models of user-expertise, but the entropy-based method can induce a bias in some circumstances.
1993	Planning for multiple task work: an analysis of a medical reception worksystem	This paper presents an investigation of interactive worksystem planning in the multiple task work domain of medical reception. In an observational study of a medical reception worksystem, three different types of plan were identified: the task plan, the procedure plan and the activity plan. These three types of plan were required for effective working in the domain of medical reception, because of the many similar concurrent tasks, the frequency of behaviour switching between tasks, the frequency of behaviour switching between tasks and the need for consistency within the worksystem. It is proposed, therefore, that to design effective interactive human-computer worksystems for the domain of medical reception (and possibly for other work domains of a similar nature), the designer must specify the three different types of plan and the relationships between them. The three types of plan in medical reception are discussed in the context of design issues such as the allocation of planning structures.
1993	The diary study: a workplace-oriented research tool to guide laboratory efforts	Methods for studying user behavior in HCI can be informally divided into two approaches: experimental psychology in the laboratory and observations in the workplace. The first approach has been faulted for providing results that have little effect on system usability, while the second can often be accused of yielding primarily anecdotal data that do not support general conclusions. This paper describes two similar approaches in another field, the study of animal behavior, and shows how they produce complementary results. To support similar complementary interactions between research approaches in the HCI field, the paper describes the diary study technique, a tool for research in the workplace that achieves a relatively high standard of objectivity. A diary study is reported that focuses on exploratory learning.
1993	Turning away from talking heads: the use of video-as-data in neurosurgery	Studies of video as a support for collaborative work have provided little hard evidence of its utility for either task performance or fostering telepresence, i.e. the conveyance of a face-to-face like social presence for remotely located participants. To date, most research on the value of video has concentrated on “talking heads” video in which the video images are of remote participants conferring or performing some task together. In contrast to talking heads video, we studied video-as-data in which video images of the workspace and work objects are the focus of interest, and convey critical information about the work. The use of video-as-data is intended to enhance task performance, rather than to provide telepresence. We studied the use of video during neurosurgery within the operating room and at remote locations away from the operating room. The workspace shown in the video is the surgical field (brain or spine) that the surgeon is operating on. We discuss our findings on the use of live and recorded video, and suggest extensions to video-as-data including its integration with computerized time-based information sources to educate and co-ordinate complex actions among distributed workgroups.
1993	One is not enough: multiple views in a media space	Media spaces support collaboration, but the limited access they provide to remote colleagues' activities can undermine their utility. To address this limitation, we built an experimental system in which four switchable cameras were deployed in each of two remote offices, and observed participants using the system to collaborate on two tasks. The new views allowed increased access to task-related artifacts; indeed, users preferred these views to more typical “face-to-face” ones. However, problems of establishing a joint frame of reference were exacerbated by the additional complexity, leading us to speculate about more effective ways to expand access to remote sites.
1993	How fluent is your interface?: designing for international users	To successfully build bridges between worlds, user interface designers must increase their awareness of cross-cultural differences, and make changes to the traditional software development process. Creating fluent interfaces for international markets goes beyond translating text and date, time, and number formats. This paper presents and explains a cross-cultural checklist of issues including text, local formats, images, symbols, colors, flow, and product functionality. Suggestions for an effective international product development cycle are provided. The suggested development cycle incorporates international design feedback and usability testing before the initial product is released.
1993	Representation in virtual space: visual convention in the graphical user interface	The graphical user interface (GUI) typically provides a multi-windowed environment within a flat workspace or “desktop.” Simultaneously, however, controls for executing commands within this interface are increasingly being rendered three-dimensionally. This paper explores ways in which the space of the GUI desktop might be literally and figuratively deepened through the incorporation of visual devices that have emerged during the history of art—specifically, perspective and light effects. By enriching the visual vocabulary of the GUI, greater semantic complexity becomes sustainable.
1993	Principles, techniques, and ethics of stage magic and their application to human interface design	Magicians have been designing and presenting illusions for 5000 years. They have developed principles, techniques and ethical positions for their craft that this paper argues are applicable to the design of human/computer interfaces. The author presents a number of specific examples from magic and discusses their counterparts in human interface design, in hopes that human interface practitioners and researchers will, having recognized the applicability of magic, go further on their own to explore its domain.
1993	Perceptual vs. hardware performance in advanced acoustic interface design	This panel brings together experts in the field of non-speech auditory displays with points of view ranging from long-term basic research in human perception to the timely production of useable tools in commercial systems. The panel will examine issues of perceptual validity and engineering performance from several different perspectives representative of current work in the field, and discuss how such issues can or should impact decisions made during technology development. Panelists' perspectives include: levels of analysis in designing and using auditory interfaces (Gaver), an example of what can be learned about implementation requirements for low-level psychophysical studies (Wenzel), designing integrated systems to encompass sonification in a three-dimensional environment (Foster), issues in the study of information transfer in representational acoustic signals (Levkowitz), and the design of a generalized technology platform for acoustic signal presentation (Powell).
1993	Separations of concerns in the Chiron-1 user interface development and management system	The development of user interfaces for large applications is subject to a series of well-known problems including cost, maintainability, and sensitivity to changes in the operating environment. The Chiron user interface development system has been built to address these software engineering concerns. Chiron introduces a series of layers that insulate components of an application from other components that may experience change. To separate application code from user interface code, user interface agents called artists are attached to application abstract data types. Operations on abstract data types within the application implicitly trigger user interface activities. Chiron also provides insulation between the user interface layer and the underlying system; artist code is written in terms of abstract depiction libraries that insulate the code from the specifics of particular windowing systems and toolkits. Concurrency is pervasive in the Chiron architecture. Inside an application there can be multiple execution threads; there is no requirement for a user interface listening/dispatching routine to have exclusive control. Multiple artists can be attached to a single application abstract data type, providing alternative forms of access by a single user or coordinated access and manipulation by multiple users.
1993	A second generation user interface design environment: the model and the runtime architecture	Several obstacles exist in the user interface design process which distract a developer from designing a good user interface. One of the problems is the lack of an application model to keep the designer in perspective with the application. The other problem is having to deal with massive user interface programming to achieve a desired interface and to provide users with correct help information on the interface. In this paper, we discuss an application model which captures information about the application to specifications of a desired interface. The application model is then used to control the dialogues at runtime and can be used by a help component to automatically generate animated and textual help. Specification changes in the application model will automatically result in behavioral changes in the interface.
1993	Tivoli: an electronic whiteboard for informal workgroup meetings	This paper describes Tivoli, an electronic whiteboard application designed to support informal workgroup meetings and targeted to run on the Xerox Liveboard, a large screen, pen-based interactive display. Tivoli strives to provide its users with the simplicity, facile use, and easily understood functionality of conventional whiteboards, while at the same time taking advantage of the computational power of the Liveboard to support and augment its users' informal meeting practices. The paper presents the motivations for the design of Tivoli and briefly describes the current version in operation. It then reflects on several issues encountered in designing Tivoli, including the need to reconsider the basic assumptions behind the standard desktop GUI, the use of strokes as the fundamental object in the system, the generalized wipe interface technique, and the use of meta-strokes as gestural commands.
1993	The user-centered iterative design of collaborative writing software	This paper presents the user-centred iterative design of software that supports collaborative writing. The design grew out of a study of how people write together that included a survey of writers and a laboratory study of writing teams linked by a variety of communications media. The resulting taxonomy of collaborative writing is summarized in the paper, followed by a list of design requirements for collaborative writing software suggested by the work. The paper describes two designs of the software. The first prototype supports synchronous writing and editing from workstations linked over local area and wide area networks. The second prototype also supports brainstorming, outlining, and document review, as well as asynchronous work. Lessons learned from the user testing and actual usage of the two systems are also presented.
1993	Take CoVer: exploiting version support in cooperative systems	Current CSCW applications support one or more modes of cooperative work. The selection of and transition between these modes is usually placed on the users. At IPSI we built the SEPIA cooperative hypermedia authoring environment supporting a whole range of situations arising during collaborative work and the smooth transitions between them. While early use of the system shows the benefits of supporting smooth transitions between different collaborative modes, it also reveals some deficits regarding parallel work, management of alternative documents, or reuse of document parts. We propose to integrate version support to overcome these limitations. This leads to a versioned data management and an extended user interface enabling concurrent users to select a certain state of their work, to be aware of related changes, and to cooperate with others either asynchronously or synchronously.
1993	Comparative design review: an exercise in parallel design	Three user interface designers were asked to design interfaces for a given problem. These designs were made available to a group of usability specialists for heuristic evaluation. The reviewers will lead off the panel with specific questions to the designers regarding the usability aspects of their designs. The panel will feature a lively discussion of the designers' various approaches and solutions.
1993	Generating user interfaces from data models and dialogue net specifications	A method and a set of supporting tools have been developed for an improved integration of user interface design with software engineering methods and tools. Animated user interfaces for database-oriented applications are generated from an extended data model and a new graphical technique for specifying dialogues. Based on views defined for the data model, an expert system uses explicit design rules derived from existing guidelines for producing the static layout of the user interface. A petri net based technique called dialogue nets is used for specifying the dynamic behaviour. Output is generated for an existing user interface management system. The approach supports rapid prototyping while using the advantages of standard software engineering methods.
1993	Encapsulating knowledge for intelligent automatic interaction objects selection	TRIDENT is a set of interactive tools that automatically generates a user interface for highly-interactive business-oriented applications. It includes an intelligent interaction objects selection based on three different concepts. First, on object oriented typology classifies abstract interaction objects to allow a presentation independent selection. Second, guidelines are translated into automatic rules to select abstract interaction objects from both an application data model and a dialog model. Third, these guidelines are encapsulated in a decision tree technique to make the reasoning obvious to the user. This approach guarantees a target environment independent user interface. Once this specified, abstract interaction objects are mapped into concrete interaction objects to produce the observable interface.
1993	Providing high-level control and expert assistance in the user interface presentation design	Current user interface builders provide only low-level assistance, because they have knowledge of neither the application, nor the principles by which interface elements are combined effectively. We have developed a framework that unites the knowledge components essential for effective user interface presentation design. The framework consists of an application model (both a data model and a control model), a design process model that supports top-down iterative development, and graphic design knowledge that is used both to place dialog box elements such that their application dependent logical relationships are visually reinforced and to control design symmetry and balance. To demonstrate the framework's viability, we have constructed a tool based on encapsulated design knowledge that establishes high-level style preferences and provides expert assistance for the dialog box presentation design and menu structuring.
1993	Orienteering in an information landscape: how information seekers get from here to there	We studied the uses of information search results by regular clients of professional intermediaries. The clients in our study engaged in three different types of searches: (1) monitoring a well-known topic or set of variables over time, (2) following an information-gathering plan suggested by a typical approach to the task at hand, and (3) exploring a topic in an undirected fashion. In most cases, a single search evolved into a series of interconnected searches, usually beginning with a high-level overview. We identified a set of common triggers and stop conditions for further search steps. We also observed a set of common operations that clients used to analyze search results. In some settings, the number of search iterations was reduced by restructuring the work done by intermediaries. We discuss the implications of the interconnected search pattern, triggers and stop conditions, common analysis techniques, and intermediary roles for the design of information access systems.
1993	Using icons to find documents: simplicity is critical	A common task at almost any computer interface is that of searching for documents, which GUIs typically represent with icons. Oddly, little research has been done on the processes underlying icon search. This paper outlines the factors involved in icon search and proposes a model of the process. An experiment was conducted which suggests that the proposed model is sound, and that the most important factor in searching for files is the type of icons used. In general, simple icons (those discriminable based on a few features) seem to help users, while complex icons are no better than simple rectangles.
1993	Queries-R-Links: graphical markup for text navigation	In this paper we introduce a style of interaction (interactive querying) that combines features of hypertext with Boolean querying, using direct markup of text to launch queries. We describe two experiments that compare the relative ease of expressing Boolean queries as text versus a graphical equivalent. The results of these experiments show that the expression of queries in the graphical format is no more difficult than the textual equivalent. We then describe the Queries-R-Links system that we have developed at the University of Toronto. Queries-R-Links uses the graphical markup method to launch Boolean queries interactively using direct markup of text. This work represents significant progress towards information exploration systems that combine the useful features of information retrieval querying and hypertext browsing.
1993	Information design methods and the applications of virtual worlds technology at WORL D ESIGN, Inc.	Information design is a new professional practice that systematically applies the lessons of human-computer interaction and human factors studies, communication theory, and information science to the presentation of complex data. WORLDESIGN, Inc., an information design with an emphasis on virtual worlds technology in the service of its corporate, mostly industrial customers.
1993	From undo to multi-user applications: the demo	The object-oriented history mechanism of the GINA application framework and its relevance for multi-user applications are demonstrated. The interaction history of a document is represented as a tree of command objects. Synchronous cooperation is supported by replicating the document state and exchanging command objects. Asynchronous cooperation leads to different branches of the history tree which can later be merged.
1993	Common elements in today's graphical user interfaces: the good, the bad, and the ugly	This panel will identify some of the similarities amongst the different familiar graphical user interfaces that make them seem so indistinguishable. This panel will then identify some of the similarities that don't belong in any modern user interface.
1993	Human performance using computer input devices in the preferred and non-preferred hands	Subjects' performance was compared in pointing and dragging tasks using the preferred and non-preferred hands. Tasks were tested using three different input devices: a mouse, a trackball, and a tablet-with-stylus. The trackball had the least degradation across hands in performing the tasks, however it remained inferior to both the mouse and stylus. For small distances and small targets, the preferred hand was superior. However, for larger targets and larger distances, both hands performed about the same. The experiment shows that the non-preferred hand is more than a poor approximation of the preferred hand. The hands are complementary, each having its own strength and weakness. One design implication is that the non-preferred hand is well suited for tasks that do not require precise action, such as scrolling.
1993	The limits of expert performance using hierarchic marking menus	A marking menu allows a user to perform a menu selection by either popping-up a radial (or pie) menu, or by making a straight mark in the direction of the desired menu item without popping-up the menu. A hierarchic marking menu uses hierarchic radial menus and “zig-zag” marks to select from the hierarchy. This paper experimentally investigates the bounds on how many items can be in each level, and how deep the hierarchy can be, before using a marking to select an item becomes too slow or prone to errors.
1993	Lag as a determinant of human performance in interactive systems	The sources of lag (the delay between input action and output response) and its effects on human performance are discussed. We measured the effects in a study of target acquisition using the classic Fitts' law paradigm with the addition of four lag conditions. At the highest lag tested (225 ms), movement times and error rates increased by 64\% and 214\% respectively, compared to the zero lag condition. We propose a model according to which lag should have a multiplicative effect on Fitts' index of difficulty. The model accounts for 94\% of the variance and is better than alternative models which propose only an additive effect for lag. The implications for the design of virtual reality systems are discussed.
1993	Computer image retrieval by features: suspect identification	Correct suspect identification of known offenders by witnesses deteriorates rapidly as more are examined in mugshot albums. Feature approaches, where mugshots are displayed in order of similarity to witnesses' descriptions, attempt to increase identification success by reducing this number. A methodology is proposed for system design and evaluation based on experiments, computer simulations, and four classes of system performance measures: identification performance, retrieval rank, tolerance performance, and feature quality. This was used to develop a system for 640 mugshots of known offenders. In three empirical tests, over 90\% of witness searches resulted in suspects retrieved in the first eight mugshots.
1993	Empirically-based re-design of a hypertext encyclopedia	This paper reports on the processes used and guidelines discovered in re-designing the user interface of the hypertext encyclopedia, HyperHolmes. The re-design was based on the outcomes of a previous experiment and was evaluated experimentally. Results showed that the new system resulted in superior performance and somewhat different styles of navigation compared to the old system and to paper. The study provides empirical support for design guidelines relating to tiled windows, navigation tools, graphics and hierarchical navigation.
1993	Bridging the paper and electronic worlds: the paper user interface	Since its invention millenia ago, paper has served as one of our primary communications media. Its inherent physical properties make it easy to use, transport, and store, and cheap to manufacture. Despite these advantages, paper remains a second class citizen in the electronic world. In this paper, we present a new technology for bridging the paper and the electronic worlds. In this new technology, the user interface moves beyond the workstation and onto paper itself. We describe paper user interface technology and its implementation in a particular system called XAX.
1993	The human guidance of automated design	This 5-minute video describes the potential of automated design (optimisation) and identifies associated difficulties which can be overcome by an interface allowing the designer to guide the automated design process. Within the context of electronic circuit design the video then shows a system, called CoCo, for the c&barbelow;ontrol and o&barbelow;bservation of c&barbelow;ircuit o&barbelow;ptimisation. Illustrations focus on graphical interfaces used for (a) describing the circuit, (b) describing the required performance and (c) the human guidance of the automated design of that circuit. Jargon has been suppressed so that workers in related fields can see the implications of the idea.
1993	Hyperspeech	Hyperspeech is a speech-only hypermedia application that explores issues of speech user interfaces, navigation, and system architecture in a purely audio environment without a visual display. The system uses speech recognition input and synthetic speech feedback to aid in navigating through a database of digitally recorded speech segments.
1994	Marquee: a tool for real-time video logging	We describe Marquee, a pen-based video logging tool which enables users to correlate their personal notes and keywords with a videotape during recording. We present our observations about coordinating the task of logging in real time and describe the three phase, user-centered approach we took in designing the tool. Our early work explored the functionalities needed by users to successfully create a log. In the second phase we focused on testing our intuitions about logging by conducting user studies with paper mock-ups. In the final phase, we implemented a working prototype system and placed it in a setting to see if it supported people logging in real time.
1994	Library information access client	We present an approach to control information flow in object-oriented systems. The decision of whether an informatin flow is permitted or denied depends on both the authorizations specified on the objects and the process by which information is obtained and transmitted. Depending on the specific computations, a process accessing sensitive information could still be allowed to release information to users who are not allowed to directly acces it. Exceptions to the permissions and restrictions stated by the authorizations are specified by means of exceptions associated with methods. Two kinds of exceptions are considered: invoke exceptions, applicable during a method executin, and reply exceptins , applicable to the infomation returned by a method. Information flowing form one object into another or returned to the user is subject to the different exceptions specified for the methods enforcing the transmission. We formally characterized information transmission and flow in a transaction and define the conditins for safe information flow. We define security specifications and characterize safe information flows. We propose an approach to control unsafe flows and present an algorithm to enforce it. We also illustrate an efficient implementation of our controls and present some experimental results evaluating its performance.
1999	An empirical study of how people establish interaction: implications for CSCW session management models	In this paper, we report the results of an empirical study of how people, as part of their daily work activities, go about to establish collaboration. We examine the empirical findings and relate them to existing research on CSCW session management models, i.e., the mechanisms in CSCW systems that define the way in which people can join together in collaboration. Existing models leave a lot to be desired, in particular because they tend to assume that indexical elements of interaction management are substitutable by objective representation of artifacts. Based on the empirical findings, we derive three principles to consider in the design of CSCW session management models.
1999	Chat circles	Although current online chat environments provide new opportunities for communication, they are quite constrained in their ability to convey many important pieces of social information, ranging from the number of participants in a conversation to the subtle nuances of expression that enrich face to face speech. In this paper we present Chat Circles, an abstract graphical interface for synchronous conversa-tion. Here, presence and activity are made manifest by changes in color and form, proximity-based filtering intuitively breaks large groups into conversational clusters, and the archives of a conversation are made visible through an integrated history interface. Our goal in this work is to create a richer environment for online discussions.
1999	Social, individual and technological issues for groupware calendar systems	Designing and deploying groupware is difficult. Groupware evaluation and design are often approached from a single perspective, with a technologically-, individually-, or socially-centered focus. A study of Groupware Calendar Systems (GCSs) highlights the need for a synthesis of these multiple perspectives to fully understand the adoption challenges these systems face. First, GCSs often replace existing calendar artifacts, which can impact users calendaring habits and in turn influence technology adoption decisions. Second, electronic calendars have the potential to easily share contextualized information publicly over the computer network, creating opportunities for peer judgment about time allocation and raising concerns about privacy regulation. However, this situation may also support coordination by allowing others to make useful inferences about ones schedule. Third, the technology and the social environment are in a reciprocal, co-evolutionary relationship: the use context is affected by the constraints and affordances of the technology, and the technology also co-adapts to the environment in important ways. Finally, GCSs, despite being below the horizon of everyday notice, can affect the nature of temporal coordination beyond the expected meeting scheduling practice.
1999	The design and evaluation of a high-performance soft keyboard	The design and evaluation of a high performance soft keyboard for mobile systems are described. Using a model to predict the upper-bound text entry rate for soft keyboards, we designed a keyboard layout with a predicted upper-bound entry rate of 58.2 wpm. This is about 35\% faster than the predicted rate for a QWERTY layout. We compared our design (OPTI) with a QWERTY layout in a longitudinal evaluation using five participants and 20 45-minute sessions of text entry. Average entry rates for OPT1 increased from 17.0 wpm initially to 44.3 wpm at session 20. The average rates exceeded those for the QWERTY layout after the 10 session (about 4 hours of practice). A regression equation (R = .997) in the form of the power-law of learning predicts that our upper-bound prediction would be reach at about session 50.
1999	Non-keyboard QWERTY touch typing: a portable input interface for the mobile user	Using traditional mobile input devices results in decreased effectiveness and efficiency. To improve usability issues a portable Non-Keyboard QWERTY touch-typing paradigm that supports the mobile touch-typing user is presented and investigated. It requires negligible training time. Pressure sensors strapped to the fingertips of gloves detect which finger is depressed. A language model based on lexical and syntactic knowledge transforms the depressed finger stroke sequence into real words and sentences. Different mobile input QWERTY paradigms (miniaturised, floating and Non-Keyboard) have been compared with full-size QWERTY. Among the mobile input paradigms, the Non-Keyboard fared significantly better, both regarding character error rate and subjective ratings.
1999	Implications for a gesture design tool	Interest in pen-based user interfaces is growing rapidly. One potentially useful feature of pen-based user interfaces is gestures, that is, a mark or stroke that causes a command to execute. Unfortunately, it is difficult to design gestures that are easy 1) for computers to recognize and 2) for humans to learn and remember. To investigate these problems, we built a prototype tool typical fo those used for designing gesture sets. An experiment was then performed to gain insight into the gesture design process and to evaluate this style of tool. The experiment confirmed that gesture design is very difficult and suggested several ways in which current tools can be improved. The most important improvement is to make the tools more active and provide more guidance for designers. This paper describes the gesture design tool, the experiment, and its results.
1999	Object manipulation in virtual environments: relative size matters	An experiment was conducted to systematically investigate combined effects of controller, cursor and target size on multidimensional object manipulation in a virtual environment. It was found that it was the relative size of controller, cursor and target that significantly affe&d object transportation and orientation processes. There were significant interactions between controller size and cursor size as well as between cursor size and target size on the total task completion time, transportation time, orientation time and spatial errors. The same size of controller and cursor improved object manipulation speed, and the same size of cursor and target generally facilitated object manipulation accuracy, regardless of their absolute sizes. Implications of these findings for human-computer interaction design are discussed.
1999	Exploring bimanual camera control and object manipulation in 3D graphics interfaces	We explore the use of the non-dominant hand to control a virtual camera while the dominant hand performs other tasks in a virtual 3D scene. Two experiments and an informal study are presented which evaluate this interaction style by comparing it to the status-quo unimanual interaction. In the first experiment, we find that for a target selection task, performance using the bimanual technique was 20\% faster. Experiment 2 compared performance in a more complicated object docking task. Performance advantages are shown, however, only after practice. Free-form 3D painting was explored in the user study. In both experiments and in the user study participants strongly preferred the bimanual technique. The results also indicate that user preferences concerning bimanual interaction may be driven by factors other than simple time-motion performance advantages.
1999	Towards usable VR: an empirical study of user interfaces for immersive virtual environments	This paper reports empirical results from a study into the use of 2D widgets in 3D immersive virtual environments. Several researchers have proposed the use of 2D interaction techniques in 3D environments, however little empirical work has been done to test the usability of such approaches. We present the results of two experiments conducted on low-level 2D manipulation tasks within an immersive virtual environment. We empirically show that the addition of passive-haptic feedback for use in precise UI manipulation tasks can significantly increase user performance. Furthermore, users prefer interfaces that provide a physical surface, and that allow them to work with interface widgets in the same visual field of view as the objects they are modifying.
1999	Socially translucent systems: social proxies, persistent conversation, and the design of “babble”	We take as our premise that it is possible and desirable to design systems that support social processes. We describe Loops, a project which takes this approach to supporting computer-mediated communication (CMC) through structural and intemctive properties such as persistence and a minimalist graphical representation of users and their activities that we call a social proxy. We discuss a prototype called Babble that has been used by our group for over a year, and has been deployed to six other groups at the Watson labs for about two months. We describe usage experiences, lessons learned, and next steps.
1999	The elements of computer credibility	Given the importance of credibility in computing products, the research on computer credibility is relatively small. To enhance knowledge about computers and credibility, we define key terms relating to computer credibility, synthesize the literature in this domain, and propose three new conceptual frameworks for better understanding the elements of computer credibility. To promote further research, we then offer two perspectives on what computer users evaluate when assessing credibility. We conclude by presenting a set of credibility-related terms that can serve in future research and evaluation endeavors.
1999	A better mythology for system design	The past decades have seen huge improvements in computer systems but these have proved difficult to translate into comparable improvements in the usability and social integration of computers. We believe that the problem is a deeply rooted set of assumptions about how computer systems should be designed, and about who should be doing that design. Human organizations are continually evolving to meet changing circumstances of resource and need. In contrast, computers are quite rigid, incapable of adaptation on their own. Therefore when computer systems are incorporated into human organizations, those organizations must adapt the computers to changing circumstances. This adaptation is another human activity that technology should support, but our design philosophies are oddly silent about it. This paper explores the origins of these problems in the norms developed for managing human organizations, proposes partial solutions that can be implemented with current systems technology, and speculates about the long-term potential for radical improvements in system design.
1999	Nomadic radio: scaleable and contextual notification for wearable audio messaging	Mobile workers need seamless access to communication and information services on portable devices. However current solutions overwhelm users with intrusive and ambiguous notifications. In this paper, we describe scaleable auditory techniques and a contextual notification model for providing timely information, while minimizing interruptions. Users actions influence local adaptation in the model. These techniques are demonstrated in Nomadic Radio, an audio-only wearable computing platform.
1999	Tangible progress: less is more in Somewire audio spaces	We developed four widely different interfaces for users of Somewire, a prototype audio-only media space. We informally studied users experiences with the two screen- based interfaces. We prototyped a non-screen-based interface as an example of a novel tangible interface for a communication system. We explored the conflict between privacy and simplicity of representation, and identified two unresolved topics: the role of audio quality and the prospects for scsiling audio spaces beyond a single Workgroup. Finally, we formulated a set of design guidelines for control and representation in audio spaces, as follows: GUIs are not well-suited to audio spaces, users do not require control over localization or other audio attributes, and awareness of other users presence is desirable.
1999	Whisper: a wristwatch style wearable handset	Whisper is a new wrist-worn handset, which is used by inserting the fingertip into the ear canal. A received signal is conveyed from a wrist-mounted actuator to the ear canal via the hand and a finger by bone conduction. The users voice is captured by a microphone mounted on the inside of the wrist. All components of Whisper can be mounted on the wrist, and usability does not de- crease if the size of components is miniaturized. So, both wearability and usability can be achieved together. The way Whisper is operated is similar to that of an ordinary telephone handset. Thus, onlookers may not look upon Whispers operation as talking to oneself, even if the associated PDA is controlled by voice commands. Whis- per is especially effective in a noisy environment. Signals received via bone conduction can be heard clearly in the presence of noise without raising the volume (-12 dB at noise = 90 dB(A) in comparison to cellular phone hand- set). Whisper is also effective in avoiding the annoying problem of the users voice being raised in a noisy situa- tion. Feedback of the users utterance is boosted by bone conduction when covering the ear canal with a fingertip, then the users voice does not need to raised in the pres- ence of noise (-6 dB at noise = 90 dB(A) in comparison to cellular phone handset). Whisper is useful as a voice interface for a wrist-worn PDA and cellular phone.
1999	i-LAND: an interactive landscape for creativity and innovation	We describe the i-LAND environment which constitutes an example of our vision of the workspaces of the future, in this case supporting cooperative work of dynamic teams with changing needs. i-LAND requires and provides new forms of human-computer interaction and new forms of computer-supported cooperative work. Its design is based on an integration of information and architectural spaces, implications of new work practices and an empirical requirements study informing our design. i-LAND consists of several roomware components, i.e. computer-aug- mented objects integrating room elements with information technology. We present the current realization of i-LAND in terms of an interactive electronic wall, an interactive table, two computer-enhanced chairs, and two bridges for the Passage-mechanism. This is complemented by the description of the creativity support application and the technological infrastructure. The paper is accompanied by a video figure in the CHI99 video program.
1999	Logjam: a tangible multi-person interface for video logging	This paper describes the evolution, implementation, and use of logjam, a system for video logging. The system features a game-board that senses the location and identities of pieces placed upon it. The board is the interface that enables a group of people to log video footage together. We report on some of the surprising physical and social dynamics that we have observed in multi-person logging sessions using the system.
1999	Time-compression: systems concerns, usage, and benefits	With the proliferation of online multimedia content and the popularity of multimedia streaming systems, it is increasingly useful to be able to skim and browse multimedia quickly. A key technique that enables quick browsing of multimedia is time-compression. Prior research has described how speech can be time-compressed (shortened in duration) while preserving the pitch of the audio. However, client-server systems providing this functionality have not been available. In this paper, we first describe the key tradeoffs faced by designers of streaming multimedia systems deploying time-compression. The implementation tradeoffs primarily impact the granularity of time-compression supported (discrete vs. continuous) and the latency (wait-time) experienced by users after adjusting degree of time-compression. We report results of user studies showing impact of these factors on the average- compression-rate achieved. We also present data on the usage patterns and benefits of time compression. Overall, we show significant time-savings for users and that considerable flexibility is available to the designers of client-server streaming systems with time compression.
1999	SWEETPEA: software tools for programmable embodied agents	Programmable Embodied Agents are portable, wireless, interactive devices embodying specific, differentiable, interactive characteristics. They take the form of identifiable characters who reside in the physical world and interact directly with users. They can act as an out-of-band communication channel between users, as proxies for system components or other users, or in a variety of other roles. Traditionally, research into such devices has been based on costly custom hardware. In this paper, we report on our explorations of the space of physical character-based interfaces built on recently available stock consumer hardware platforms, structured around an initial framework of applications.
1999	Sympathetic interfaces: using a plush toy to direct synthetic characters	We introduce the concept of a sympathetic inter$ace for controlling an animated synthetic character in a 3D virtual environment. A plush doll embedded with wireless sensors is used to manipulate the virtual character in an iconic and intentional manner. The interface extends from the novel physical input device through interpretation of sensor data to the behavioral brain of the virtual character. We discuss the design of the interface and focus on its latest instantiation in the Swamped! exhibit at SIGGRAPH 98. We also present what we learned from hundreds of casual users, who ranged from young children to adults.
1999	Principles of mixed-initiative user interfaces	Recent debate has centered on the relative promise of focusing user-interface research on developing new metaphors and tools that enhance users abilities to directly manipulate objects versus directing effort toward developing interface agents that provide automation. In this paper, we review principles that show promise for allowing engineers to enhance human-computer interaction through an elegant coupling of automated services with direct manipulation. Key ideas will be highlighted in terms of the Lookout system for scheduling and meeting management.
1999	An exploration into supporting artwork orientation in the user interface	Rotating a piece of paper while drawing is an integral and almost subconscious part of drawing with pencil and paper. In a similar manner, the advent of lightweight pen-based computers allow digital artwork to be rotated while drawing by rotating the entire computer. Given this type of manipulation we explore the implications for the user interface to support artwork orientation. First we describe an exploratory study to further motivate our work and characterize how artwork is manipulated while drawing. After presenting some possible UI approaches to support artwork orientation, we define a new solution called a rotating user interface (RUIs). We then discuss design issues and requirements for RUIs based on our exploratory study.
1999	An alternative way of drawing	Current object-oriented drawing programs have an established way of drawing in which the shape of an object is controlled by manipulating control points. While the control points are intuitive in their basic use, it is not clear whether they make more complex drawing tasks manageable for the average user. In this paper we describe an alternative way of drawing and editing a drawing using new direct manipulation tools. Our approach resembles sculpting in two dimensions: the user begins with a large block and uses different tools to give it the desired shape. We also present a user evaluation in which the users could try our new tools and compare them to their previous experience of control points, The users claimed to understand the operations better with our tools than if they had needed to use curves and control points. However, our tools were better suited for sketching the artwork than for making very detailed drawings.
1999	The strategic use of CAD: an empirically inspired, theory-based course	The inefficient use of complex computer systems has been widely reported. These studies show the persistence of inefficient methods despite many years of experience and formal training. To counteract this phenomenon, we present the design of a new course, called the Strategic Use of CAD. The course aims at teaching students efficient strategies to use a computer-aided drafting system through a two-pronged approach. Learning to See teaches students to recognize opportunities to use efficient strategies by studying the nature of the task, and Learning to Do teaches students to implement the strategies. Results from a pilot experiment show that this approach had a positive effect on the strategic behavior of students who did not exhibit knowledge of efficient strategies before the class, and had no effect on the strategic behavior of those who did. Strategic training can thus assist users in recognizing opportunities to use efficient strategies. We present the ramifications of these results on the design of training and future experiments.
1999	Implementing interface attachments based on surface representations	This paper describes an architecture for supporting interface attuchments - small interactive programs which are designed to augment the functionality of other applications. This architecture is designed to work with a diverse set of conventional applications, but require only a minimal set of hooks into those applications. In order to achieve this, the work described here concentrates on what we will call observational attachments, a subclass of attachments that operate primarily by observing and manipulating the surface representations of applications - that is the visual information that applications would normally display on the screen or print. These attachments can be thought of as looking over the shoulder of the user to assist with various tasks. By requiring very little modification to, or help from, the applications they augment, this approach supports the creation of a set of uniform services that can be applied across a more diverse set of applications than traditional approaches.
1999	A visual medium for programmatic control of interactive applications	The VisMap system provides for visual manipulation of arbitrary off-the-shelf applications, through an applications graphical user interface. VisMaps API-independent control has advantages for tasks that can benefit from direct access to the functions of the user interface. We describe the design goals and architecture of the system, and we discuss two applications, a user-controlled visual scripting program and an autonomous solitaire-playing program, which together demonstrate some of the capabilities and limitations of the approach.
1999	Should we leverage natural-language knowledge? An analysis of user errors in a natural-language-style programming language	Should programming languages use natural-language-like syntax? Under what circumstances? What sorts of errors do novice programmers make? Does using a natural- language-like programming language lead to user errors? In this study, we read the entire online interactions of sixteen children who issued a total of 35,047 commands on MOOSE Crossing, an educational MUD for children, We counted and categorized the errors made. A total d 2,970 errors were observed. We define natural-language errors as those errors in which the user failed to distinguish between English and code, issuing an incorrect command that was more English-like than the correct one. A total of 314 natural-language errors were observed. In most of those errors, the child was able to correct the problem either easily (41.1\% of the time) or with some effort (20.7\%). Natural-language errors were divided into five categories. In order from most to least frequent, they are: syntax errors, guessing a command name by supplying an arbitrary English word, literal interpretation of metaphor, assuming the system is keeping more state information than is actually the case, and errors of operator precedence and combination. We believe that these error rates are within acceptable limits, and conclude that leveraging users natural-language knowledge is for many applications an effective strategy for designing end-user-programming languages.
1999	Testing pointing device performance and user assessment with the ISO 9241, Part 9 standard	The IS0 9241, Part 9 Draft International Standard for testing computer pointing devices proposes an evaluation of performance and comfort. In this paper we evaluate the scientific validity and practicality of these dimensions for two pointing devices for laptop computers, a finger-controlled isometric joystick and a touchpad. Using a between-subjects design, evaluation of performance using the measure of throughput was done for one-direction and multi-directional pointing and selecting. Results show a significant difference in throughput for the multi-directional task, with the joystick 27\% higher; results for the one-direction task were non-significant. After the experiment, participants rated the device for comfort, including operation, fatigue, and usability. The questionnaire showed no overall difference in the responses, and a significant statistical difference in only the question concerning force required to operate the device - the joystick requiring slightly more force. The paper concludes with a discussion of problems in implementing the IS0 standard and recommendations for improvement.
1999	Touch-sensing input devices	We can touch things, and our senses tell us when our hands are touching something. But most computer input devices cannot detect when the user touches or releases the device or some portion of the device. Thus, adding touch sensors to input devices offers many possibilities for novel interaction techniques. We demonstrate the TouchTrackball and the Scrolling TouchMouse, which use unobtrusive capacitance sensors to detect contact from the users hand without requiring pressure or mechanical actuation of a switch. We further demonstrate how the capabilities of these devices can be matched to an implicit interaction technique, the On-Demand Interface, which uses the passive information captured by touch sensors to fade in or fade out portions of a display depending on what the user is doing; a second technique uses explicit, intentional interaction with touch sensors for enhanced scrolling. We present our new devices in the context of a simple tax- onomy of tactile input technologies. Finally, we discuss the properties of touch-sensing as an input channel in general.
1999	The Hotbox: efficient access to a large number of menu-items	The proliferation of multiple toolbars and UI widgets around the perimeter of application windows is an indication that the traditional GUI design of a single menubar is not sufficient to support large scale applications with numerous functions. In this paper we describe a new widget which is an enhancement of the traditional menubar which dramatically increases menu-item capacity. This widget, called the Hotbox combines several GUI techniques which are generally used independently: accelerator keys, modal dialogs, pop-up/pull down menus, radial menus, marking menus and menubars. These techniques are fitted together to create a single, easy to learn yet fast to operate GUI widget which can handle significantly more menu-items than the traditional GUI menubar . We describe the design rationale of the Hotbox and its effectiveness in a large scale commercial application. While the Hotbox was developed for a particular application domain, the widget itself and the design rationale are potentially useful in other domains.
1999	Combining observations of intentional and unintentional behaviors for human-computer interaction	Human interfaces are usually designed to respond only to intentional human behaviors. However, humans show unintentional behaviors as well. They can convey useful information to realize user-friendly human interfaces. This paper presents how to combine observations of both types of behaviors by taking two human- machine systems: a gesture-based interface and an intelligent wheelchair. In the first system, intentional hand gestures are chosen using unintentional behaviors. In the second system, near unintentional behaviors following intentional behaviors can be used to control the wheelchair motion. Experimental systems working in real time have been developed. Operational experiments prove our approach promising.
1999	Manual and gaze input cascaded (MAGIC) pointing	This work explores a new direction in utilizing eye gaze for computer input. Gaze tracking has long been considered as an alternative or potentially superior pointing method for computer input. We believe that many fundamental limitations exist with traditional gaze pointing. In particular, it is unnatural to overload a perceptual channel such as vision with a motor control task. We therefore propose an alternative approach, dubbed MAGIC (Manual And Gaze Input Cascaded) pointing. With such an approach, pointing appears to the user to be a manual task, used for fine manipulation and selection. However, a large portion of the cursor movement is eliminated by warping the cursor to the eye gaze area, which encompasses the target. Two specific MAGIC pointing techniques, one conservative and one liberal, were designed, analyzed, and implemented with an eye tracker we developed. They were then tested in a pilot study. This early- stage exploration showed that the MAGIC pointing techniques might offer many advantages, including reduced physical effort and fatigue as compared to traditional manual pointing, greater accuracy and naturalness than traditional gaze pointing, and possibly faster speed than manual pointing. The pros and cons of the two techniques are discussed in light of both performance data and subjective reports.
1999	Inferring intent in eye-based interfaces: tracing eye movements with process models	While current eye-based interfaces offer enormous potential for efficient human-computer interaction, they also manifest the difficulty of inferring intent from user eye movements. This paper describes how fixation tracing facilitates the interpretation of eye movements and improves the flexibility and usability of eye-based interfaces. Fixation tracing uses hidden Markov models to map user actions to the sequential predictions of a cognitive process model. In a study of eye typing, results show that fixation tracing generates significantly more accurate interpretations than simpler methods and allows for more flexibility in designing usable interfaces. Implications for future research in eye-based interfaces and multimodal interfaces are discussed.
1999	Direct combination	This paper reports on Direct Combination, a new user interaction technique. Direct Combination may be viewed variously as: a systematic extension to Direct Manipulation; a concise navigational framework to help users find the operations they need; and as a framework to make a greater range and variety of operations available to the user, without overburdening user or interface designer. While Direct Combination may be seen as an extension of Direct Manipulation, it may also be applied to a wide range of user interaction styles, including even command line interfaces. Examples from various hypothetical systems and from an implemented system are presented. This paper argues that Direct Combination is applicable not just to problem seeking or design oriented domains (where the technique originated) but is generally applicable. A variety of new interaction styles for Direct Combination are presented. The generalisation of Direct Combination to the n-dimensional case is presented.
1999	Footprints: history-rich tools for information foraging	Inspired by Hill and Hollans original work [7], we have been developing a theory of interaction history and building tools to apply this theory to navigation in a complex information space. We have built a series of tools - map, paths, annota- tions and signposts - based on a physical-world navigation metaphor. These tools have been in use for over a year. Our user study involved a controlled browse task and showed that users were able to get the same amount of work done with significantly less effort.
1999	Design guidelines for landmarks to support navigation in virtual environments	Unfamiliar, large-scale virtual environments are difficult to navigate. This paper presents design guidelines to ease navigation in such virtual environments. The guidelines presented here focus on the design and placement of landmarks in virtual environments. Moreover, the guidelines are based primarily on the extensive empirical literature on navigation in the real world. A rationale for this approach is provided by the similarities between navigational behavior in real and virtual environments.
1999	Single display groupware: a model for co-present collaboration	We introduce a model for supporting collaborative work between people that are physically close to each other. We call this model Single Display Groupware (SDG). In this paper, we describe the model, comparing it to more traditional remote collaboration, We describe the requirements that SDG places on computer technology, and our understanding of the benefits and costs of SDG systems. Finally, we describe a prototype SDG system that we built and the results of a usability test we ran with 60 elementary school children.
1999	The GAZE groupware system: mediating joint attention in multiparty communication and collaboration	In this paper, we discuss why, in designing multiparty mediated systems, we should focus first on providing non-verbal cues which are less redundantly coded in speech than those normally conveyed by video. We show how conveying one such cue, gaze direction, may solve two problems in multiparty mediated communication and collaboration: knowing who is talking to whom, and who is talking about what. As a candidate solution, we present the GAZE Groupware System, which combines support for gaze awareness in multiparty mediated communication and collaboration with small and linear bandwidth requirements. The system uses an advanced, desk- mounted eyetracker to metaphorically convey gaze awareness in a 3D virtual meeting room and within shared documents.
1999	Video helps remote work: speakers who need to negotiate common ground benefit from seeing each other	More and more organizations are forming teams that are not co-located. These teams communicate via email, fax, telephone and audio conferences, and sometimes video. The question often arises whether the cost of video is worth it. Previous research has shown that video makes people more satisfied with the work, but it doesnt help the quality of the work itself. There is one exception; negotiation tasks are measurably better with video. In this study, we show that the same effect holds for a more subtle form of negotiation, when people have to negotiate meaning in a conversation. We compared the performance and communication of people explaining a map route to each other. Half the pairs have video and audio connections, half only audio. Half of the pairs were native speakers of English; the other half were non-native speakers, those presumably who have to negotiate meaning more. The results showed that non-native speaker pairs did benefit from the video; native speakers did not. Detailed analysis of the conversational strategies showed that with video, the non-native speaker pairs spent proportionately more effort negotiating common ground.
1999	Designing multimedia for learning: narrative guidance and narrative construction	Narrative is fundamental to the ways we make sense of texts of all kinds because it provides structure and coherence, but it is difficult to see how this works in the context of multimedia interactive learning environments (MILES). We tested our hypotheses about the form and function of narrative in MILES by developing three versions of material on CD-ROM which had different narrative structures and analysed the impact of the different versions on learner behaviour. We present a theoretical framework in which we explain the concepts of narrative guidance and narrative construction and their application to the design of MILES.
1999	Interactive 3D sound hyperstories for blind children	Interactive software is currently used for learning and entertainment purposes. This type of software is not very common among blind children because most computer games and electronic toys do not have appropriate interfaces to be accessible without visual cues. This study introduces the idea of interactive hyperstories carried out in a 3D acoustic virtual world for blind children. We have conceptualized a model to design hyperstories. Through AudioDoom we have an application that enables testing cognitive tasks with blind children. The main research question underlying this work explores how audio- based entertainment and spatial sound navigable experiences can create cognitive spatial structures in the minds of blind children. AudioDoom presents first person experiences through exploration of interactive virtual worlds by using only 3D aural representations of the space.
1999	Designing PETS: a personal electronic teller of stories	We have begun the development of a new robotic pet that can support children in the storytelling process. Children can build their own pet by snapping together the modular animal parts of the PETS robot. After their pet is built, children can tell stories using the My Pets software. These stories can then be acted out by their robotic pet. This video paper describes the motivation for this research and the design process of our intergenerational design team in building the first PETS prototypes. We will discuss our progress to date and our focus for the future .
1999	Visual profiles: a critical component of universal access	This research focuses on characterizing visually impaired computer users performance on graphical user interfaces by linking clinical assessments of low vision with visual icon identification. This was accomplished by evaluating user performance on basic identification and selection tasks within a graphical user interface, comparing partially sighted user performance with fully sighted user performance, and linking task performance to specific profiles of visual impairment. Results indicate that visual acuity, contrast sensitivity, visual field and color perception were significant predictors of task performance. In addition, icon size and background color significantly influenced performance. Suggestions for future research are provided. Keywords
1999	NotePals: lightweight note sharing by the group, for the group	NotePals is a lightweight note sharing system that gives group members easy access to each others experiences through their personal notes. The system allows notes taken by group members in any context to be uploaded to a shared repository. Group members view these notes with browsers that allow them to retrieve all notes taken in a given context or to access notes from other related notes or documents. This is possible because NotePals records the context in which each note is created (e.g., its author, subject, and creation time). The system is lightweight because it fits easily into group members regular note- taking practices, and uses informal, ink-based user interfaces that run on portable, inexpensive hardware. In this paper we describe NotePals, show how we have used it to share our notes, and present our evaluations of the system.
1999	Flatland: new dimensions in office whiteboards	Flatland is an augmented whiteboard interface designed for informal office work. Our research investigates approaches to building an augmented whiteboard in the context of continuous, long term office use. In particular, we pursued three avenues of research based on input from user studies: techniques for the management of space on the board, the ability to flexibly apply behaviors to support varied application semantics, and mechanisms for managing history on the board. Unlike some previously reported whiteboard systems, our design choices have been influenced by a desire to support long-term, informal use in an individual office setting.
1999	Palette: a paper interface for giving presentations	The Palette is a digital appliance designed for intuitive control of electronic slide shows. Current interfaces demand too much of our attention to permit effective computer use in situations where we can not give the technology our fullest concentration. The Palette uses index cards that are printed with slide content that is easily identified by both humans and computers. The presenter controls the presentation by directly manipulating the cards. The Palette design is based on our observation of presentations given in a real work setting. Our experiences using the system are described, including new practices (e.g., collaborative presentation, enhanced notetaking) that arise from the affordances of this new approach. This system is an example of a new interaction paradigm called tacit interaction that supports users who can spare very little attention to a computer interface.
1999	TouchCounters: designing interactive electronic labels for physical containers	We present TouchCounters, an integrated system of electronic modules, physical storage containers, and shelving surfaces for the support of collaborative physical work. Through physical sensors and local displays, TouchCounters record and display usage history information upon physical storage containers, thus allowing access to this information during the performance of real-world tasks. A distributed communications network allows this data to be exchanged with a server, such that users can access this information from remote locations as well. Based upon prior work in ubiquitous computing and tangible interfaces, TouchCounters incorporate new techniques, including usage history tracking for physical objects and multi-display visualization. This paper describes the components, interactions, implementation, and conceptual approach of the TouchCounters system.
1999	Bridging physical and virtual worlds with electronic tags	The role of computers in the modern office has divided our activities between virtual interactions in the realm of the computer and physical interactions with real objects within the traditional office infrastructure. This paper extends previous work that has attempted to bridge this gap, to connect physical objects with virtual representations or computational functionality, via various types of tags. We discuss a variety of scenarios we have implemented using a novel combination of inexpensive, unobtrusive and easy to use RFID tags, tag readers, portable computers and wireless networking. This novel combination demonstrates the utility of invisibly, seamlessly and portably linking physical objects to networked electronic services and actions that are naturally associated with their form.
1999	Augmented surfaces: a spatially continuous work space for hybrid computing environments	This paper describes our design and implementation of a computer augmented environment that allows users to smoothly interchange digital information among their portable computers, table and wall displays, and other physical objects. Supported by a camera-based object recognition system, users can easily integrate their portable computers with the pre-installed ones in the environment. Users can use displays projected on tables and walls as a spatially continuous extension of their portable computers. Using an interaction technique called hyperdragging, users can transfer information from one computer to another, by only knowing the physical relationship between them. We also provide a mechanism for attaching digital data to physical objects, such as a videotape or a document folder, to link physical and digital spaces.
1999	Urp: a luminous-tangible workbench for urban planning and design	We introduce a system for urban planning - called Urp -that integrates functions addressing a broad range of the fields concerns into a single, physically based workbench setting. The I/O Bulb infrastructure on which the application is based allows physical architectural models placed on an ordinary table surface to cast shadows accurate for arbitrary times of day; to throw reflections off glass facade surfaces; to affect a real-time and visually coincident simulation of pedestrian-level windflow; and so on. We then use comparisons among Urp and several earlier I/O Bulb applications as the basis for an understanding of luminous-tangible interactions, which result whenever an interface distributes meaning and functionality between physical objects and visual information projectively coupled to those objects. Finally, we briefly discuss two issues common to all such systems, offering them as informal thought-tools for the design and analysis of luminous-tangible interfaces.
1999	PingPongPlus: design of an athletic-tangible interface for computer-supported cooperative play	This paper introduces a novel interface for digitally-augmented cooperative play. We present the concept of the athletic-tangible interface, a new class of interaction which uses tangible objects and full-body motion in physical spaces with digital augmentation. We detail the implementation of PingPongPlus, a reactive ping-pong table, which features a novel sound-based ball tracking technology. The game is augmented and transformed with dynamic graphics and sound, determined by the position of impact, and the rhythm and style of play. A variety of different modes of play and initial experiences with PingPongPlus are also described.
1999	Eye tracking the visual search of click-down menus	Click-down (or pull-down) menus have long been a key component of graphical user interfaces, yet we know surprisingly little about how users actually interact with such menus. Nilsens [8] study on menu selection has led to the development of a number of models of how users perform the task [6, 21. However, the validity of these models has not been empirically assessed with respect to eye movements (though [l] presents some interesting data that bear on these models). The present study is an attempt to provide data that can help refine our understanding of how users interact with such menus.
1999	Cognitive modeling demonstrates how people use anticipated location knowledge of menu items	This research presents cognitive models of a person selecting an item from a familiar, ordered, pull-down menu. Two different models provide a good fit with human data and thus two different possible explanations for the low- level cognitive processes involved in the task. Both models assert that people make an initial eye and hand movement to an anticipated target location without waiting for the menu to appear. The first model asserts that a person knows the exact location of the target item before the menu appears, but the model uses nonstandard Fitts law coefficients to predict mouse pointing time. The second model asserts that a person would only know the approximate location of the target item, and the model uses Fitts law coefficients better supported by the literature. This research demonstrates that people can develop considerable knowledge of locations in a visual task environment, and that more work regarding Fitts law is needed.
1999	Learning and performing by exploration: label quality measured by latent semantic analysis	Models of learning and performing by exploration assume that the semantic similarity between task descriptions and labels on display objects (e.g., menus, tool bars) controls in part the users search strategies. Nevertheless, none of the models has an objective way to compute semantic similarity. In this study, Latent Semantic Analysis (LSA) was used to compute semantic similarity between task descriptions and labels in an applications menu system. Participants performed twelve tasks by exploration and they were tested for recall after a l-week delay. When the labels in the menu system were semantically similar to the task descriptions, subjects performed the tasks faster. LSA could be incorporated into any of the current models, and it could be used to automate the evaluation of computer applications for ease of learning and performing by exploration.
1999	MOBILE: user-centered interface building	Interfhce builders are popular tools for designing and developing graphical user interfaces. These tools, however, are engineering-centered; they operate mainly on windows and widgets. A typical interface builder does not offer any specific support for user-centered interface design, a methodology recognized as critical for effective user interface design. We present MOBILE (Model-Based Inter&xx Layout Editor) an interface building tool that iidly supports user-centered design and that guides the htafhce building process by using user-task models and a knowledge base of interface design guidelines. The approach in MOBILE has the important added benefit of being useful in both top-down and bottom-up interface design strategies.
1999	The context toolkit: aiding the development of context-enabled applications	Context-enabled applications are just emerging and promise richer interaction by taking environmental context into account. However, they are difficult to build due to their distributed nature and the use of unconventional sensors. The concepts of toolkits and widget libraries in graphical user interfaces has been tremendously successtil, allowing programmers to leverage off existing building blocks to build interactive systems more easily. We introduce the concept of context widgets that mediate between the environment and the application in the same way graphical widgets mediate between the user and the application. We illustrate the concept of context widgets with the beginnings of a widget library we have developed for sensing presence, identity and activity of people and things. We assess the success of our approach with two example context-enabled applications we have built and an existing application to which we have added context-sensing capabilities.
1999	Getting more out of programming-by-demonstration	Programming-by-demonstration (PBD) can be used to create tools and methods that eliminate the need to learn difficult computer languages. Gamut is a PBD tool that nonprogrammers can use to create a broader range of interactive software, including games, simulations, and educational software, than they can with other PBD tools. To do this, Gamut provides advanced interaction techniques that make it easier for a developer to express all aspects of an application. These techniques include a simplified way to demonstrate new examples, called nudges, and a way to highlight objects to show they are important. Also, Gamut includes new objects and metaphors like the deck-of-cards metaphor for demonstrating collections of objects and randomness, guide objects for demonstrating relationships that the system would find too difficult to guess, and temporal ghosts which simplify showing relationships with the recent past. These techniques were tested in a formal setting with nonprogrammers to evaluate their effectiveness.
1999	Navigation as multiscale pointing: extending Fitts' model to very high precision tasks	Fitts pointing model has proven extremely useful for understanding basic selection in WIMP user interfaces. Yet todays interfaces involve more complex navigation within electronic environments. As navigation amounts to a form of multi-scale pointing, Fitts model can be applied to these more complex tasks. We report the results of a preliminary pointing experiment that shows that users can handle higher levels of task difficulty with two-scale rather than traditional one-scale pointing control. Also, in tasks with very high-precision hand movements, performance is higher with a stylus than with a mouse.
1999	Authoring animated Web pages using “contact points”	This paper explores how contact points or co-references between an animation and text should be designed in web pages. Guidelines are derived from an eye tracking study. A dynamic HTML authoring tool is described which supports these requirements. An evaluation study is reported in which four designs of animation in web pages were tested.
1999	Performance evaluation of input devices in trajectory-based tasks: an application of the steering law	Choosing input devices for interactive systems that best suit users needs remains a challenge, especially consid- ering the increasing number of devices available. The choice often has to be made through empirical evalua- tions. The most frequently used evaluation task hitherto is target acquisition, a task that can be accurately modeled by Fitts law. However, todays use of computer input devices has gone beyond target acquisition alone. In particular, we often need to perform trajectory-based tasks, such as drawing, writing, and navigation. This paper illustrates how a recently discovered model, the steering law, can be applied as an evaluation paradigm complementary to Fitts law. We tested five commonly used computer input devices in two steering tasks, one linear and one circular. Results showed that subjects performance with the five devices could be generally classified into three groups in the following order: 1. the tablet and the mouse, 2. the trackpoint, 3. the touch- pad and the trackball. The steering law proved to hold for all five devices with greater than 0.98 correlation. The ability to generalize the experimental results and the limitations of the steering law are also discussed.
1999	Symphony: a case study in extending learner-centered design through process space analysis	We are exploring a new class of tools for learners: scaffolded integrated tool environments (or SITES), which address the needs of learners trying to engage in new, complex work processes. A crucial phase within a learner-centered design approach for SITE design involves analyzing the work process to identify areas where learners need support to engage in the process. Here we discuss the design of Symphony, a SITE for high-school science students. Specifically, we discuss how the process-space model helped us analyze the science inquiry process to help us identify a detailed set of learner needs, leading to a full set of process scaffolding strategies for Symphony.
1999	The reader's helper: a personalized document reading environment	Over the last two centuries, reading styles have shifted away from the reading of documents from beginning to end and toward the skimming of documents in search of relevant information. This trend continues today where readers, often confronted with an insurmountable amount of text, seek more efficient methods of extracting relevant information from documents. In this paper, a new document reading environment is introduced called the Readers HelperTM, which supports the reading of electronic and paper documents. The Readers Helper analyzes documents and produces a relevance score for each of the readers topics of interest, thereby helping the reader decide whether the document is actually worth skimming or reading. Moreover, during the analysis process, topic of interest phrases are automatically annotated to help the reader quickly locate relevant information. A new information visualization tool, called the ThumbarTM, is used in conjunction with relevancy scoring and automatic annotation to portray a continuous, dynamic thumb-nail representation of the document. This further supports rapid navigation of the text.
1999	VR's frames of reference: a visualization technique for mastering abstract multidimensional information	This paper describes a research study that investigated how designers can use frames of reference (egocentric, exocentric, and a combination of the two) to support the mastery of abstract multidimensional information. The primary focus of this study was the relationship between FORs and mastery; the secondary focus was on other factors (individual characteristics and interaction experience) that were likely to influence the relationship between FORs and mastery. This studys outcomes (1) clarify how FORs work in conjunction with other factors in shaping mastery, (2) highlight strengths and weaknesses of different FORs, (3) demonstrate the benefits of providing multiple FORs, and (4) provide the basis for our recommendations to HCI researchers and designers.
1999	FotoFile: a consumer multimedia organization and retrieval system	FotoFile is an experimental system for multimedia organization and retrieval, based upon the design goal of making multimedia content accessible to non-expert users. Search and retrieval are done in terms that are natural to the task. The system blends human and automatic annotation methods. It extends textual search, browsing, and retrieval technologies to support multimedia data types.
1999	Hyper Mochi Sheet: a predictive focusing interface for navigating and editing nested networks through a multi-focus distortion-oriented view	Multi-focus distortion-oriented views are useful in viewing large information on a small screen, but still have problems in managing multiple foci during editing. The user may have to navigate information space by focusing and defocusing multiple parts to obtain multi-focus layouts that change according to various editing situations. As a result, it becomes haphazard to navigate and edit large nested networks such as hypertexts. We propose a user interface for quickly obtaining desirable layouts. The interface uses two techniques: focus size prediction and predictive focus selection. These techniques are based on a user test and experiences in applications. We also describe two example applications.
1999	Excentric labeling: dynamic neighborhood labeling for data visualization	The widespread use of information visualization is hampered by the lack of effective labeling techniques. An informal taxonomy of labeling methods is proposed. We then describe excentric labeling, a new dynamic technique to label a neighborhood of objects located around the cursor. This technique does not intrude into the existing interaction, it is not computationally intensive, and was easily applied to several visualization applications. A pilot study with eight subjects indicates a strong speed benefit over a zoom interface for tasks that involve the exploration of large numbers of objects. Observations and comments from users are presented.
1999	Embodiment in conversational interfaces: Rea	In this paper, we argue for embodied corrversational characters as the logical extension of the metaphor of human - computer interaction as a conversation. We argue that the only way to fully model the richness of human I&+ to-face communication is to rely on conversational analysis that describes sets of conversational behaviors as fi~lfilling conversational functions, both interactional and propositional. We demonstrate how to implement this approach in Rea, an embodied conversational agent that is capable of both multimodal input understanding and output generation in a limited application domain. Rea supports both social and task-oriented dialogue. We discuss issues that need to be addressed in creating embodied conversational agents, and describe the architecture of the Rea interface.
1999	Emotional interfaces for interactive aardvarks: designing affect into social interfaces for children	Character-based social interfaces present a unique opportunity to integrate emotion into technology interactions. The present paper reports on the use of three emotional interactions (humor, praise, and affection) in the audio interfaces for two character-based interactive learning toys. The reasons for selecting the emotions used, the design rationale for their application, and findings from usability testing are reviewed. It is suggested that as a form of pretend play-acting akin to puppetry, social interfaces can engage the emotions of users in a variety of beneficial ways.
1999	Bridging strategies for VR-based learning	A distributed immersive virtual environment was deployed as a component of a pedagogical strategy for teaching third grade children that the Earth is round. The displacement strategy is based on the theory that fundamental conceptual change requires an alternative cognitive starting point which doesnt invoke the features of pre-existing models. While the VR apparatus helped to establish that alternative framework, conceptual change was strongly influenced by the bridging activities which related that experience to the target domain. Simple declarations of relevance proved ineffective. A more articulated bridging process involving physical models was effective for some children, but the multiple representations employed required too much model-matching for others.
1999	The tangled Web we wove: a taskonomy of WWW use	A prerequisite to the effective design of user interfaces is an understanding of the tasks for which that interface will actually be used. Surprisingly little task analysis has appeared for one of the most discussed and fastest-growing computer applications, browsing the World-Wide Web (WWW). Based on naturally-collected verbal protocol data, we present a taxonomy of tasks undertaken on the WWW. The data reveal that several previous claims about browsing behavior are questionable, and suggests that that widget-centered approaches to interface design and evaluation may be incomplete with respect to good user interfaces for the Web.
1999	An empirical evaluation of user interfaces for topic management of Web sites	Topic management is the task of gathering, evaluating, organizing, and sharing a set of web sites for a specific topic. Current web tools do not provide adequate support for this task. We created the TopicShop system to address this need. TopicShop includes (1) a webcrawler that discovers relevant web sites and builds site profiles, and (2) user interfaces for exploring and organizing sites. We conducted an empirical study comparing user performance with TopicShop vs. YahooTM. TopicShop subjects found over 80\% more high-quality sites (where quality was determined by independent expert judgements) while browsing only 8 1\% as many sites and completing their task in 89\% of the time. The site profile data that TopicShop provides - in particular, the number of pages on a site and the number of other sites that link to it - was the key to these results, as users exploited it to identify the most promising sites quickly and easily.
1999	Visualizing implicit queries for information management and retrieval	In this paper, we describe the use of similarity metrics in a novel visual environment for storing and retrieving favorite web pages. The similarity metrics, called Implicit Queries, are used to automatically highlight stored web pages that are related to the currently selected web page. Two experiments explored how users manage their personal web information space with and without the Implicit Query highlighting and later retrieve their stored web pages. When storing and organizing web pages, users with Implicit Query highlighting generated slightly more categories. Implicit Queries also led to faster web page retrieval time, although the results were not statistically significant.
1999	Patterns of entry and correction in large vocabulary continuous speech recognition systems	A study was conducted to evaluate user performance and satisfaction in completion of a set of text creation tasks using three commercially available continuous speech recognition systems. The study also compared user performance on similar tasks using keyboard input. One part of the study (Initial Use) involved 24 users who enrolled, received training and carried out practice tasks, and then completed a set of transcription and composition tasks in a single session. In a parallel effort (Extended Use), four researchers used speech recognition to carry out real work tasks over 10 sessions with each of the three speech recognition software products. This paper presents results from the Initial Use phase of the study along with some preliminary results from the Extended Use phase. We present details of the kinds of usability and system design problems likely in current systems and several common patterns of error correction that we found.
1999	Mutual disambiguation of recognition errors in a multimodel architecture	As a new generation of multimodal/media systems begins to define itself, researchers are attempting to learn how to combine different modes into strategically integrated whole systems. In theory, well designed multimodal systems should be able to integrate complementary modalities in a manner that supports mutual disambiguation (MD) of errors and leads to more robust performance. In this study, over 2,000 multimodal utterances by both native and accented speakers of English were processed by a multimodal system, and then logged and analyzed. The results confirmed that multimodal systems can indeed support significant levels of MD, and also higher levels of MD for the more challenging accented users. As a result, although speech recognition as a stand-alone performed far more poorly for accented speakers, their multimodal recognition rates did not differ from those of native speakers. Implications are discussed for the development of future multimodal architectures that can perform in a more robust and stable manner than individual recognition technologies. Also discussed is the design of interfaces that support diversity in tangible ways, and that function well under challenging real-world usage conditions,
1999	Model-based and empirical evaluation of multimodal interactive error correction	Our research addresses the problem of error correction in speech user interfaces. Previous work hypothesized that switching modality could speed up interactive correction of recognition errors (so-called multimodal error correction). We present a user study that compares, on a dictation task, multimodal error correction with conventional interactive correction, such as speaking again, choosing Tom a list, and keyboard input. Results show that multimodal correction is faster than conventional correction without keyboard input, but slower than correction by typing for users with good typing skills. Furthermore, while users initially prefer speech, they learn to avoid ineffective correction modalities with experience. To extrapolate results from this user study we developed a performance model of multimodal interaction that predicts input speed including time needed for error correction. We apply the model to estimate the impact of recognition technology improvements on correction speeds and the influence of recognition accuracy and correction method on the productivity of dictation systems. Our model is a first step towards formalizing multimodal (recognition-based) interaction.
1999	Cooperative inquiry: developing new technologies for children with children	In todays homes and schools, children are emerging as frequent and experienced users of technology [3, 14]. As this trend continues, it becomes increasingly important to ask if we are fulfilling the technology needs of our children. To answer this question, I have developed a research approach that enables young children to have a voice throughout the technology development process. In this paper, the techniques of cooperative inquiry will be described along with a theoretical framework that situates this work in the HCI literature. Two examples of technology resulting from this approach will be presented, along with a brief discussion on the design-centered learning of team researchers using cooperative inquiry.
1999	Projected realities: conceptual design for cultural effect	As a part of a European Union sponsored project, we have proposed a system which aggregates peoples expressions over a widening network of public electronic displays in a massive Dutch housing development. Reflecting ideas from contemporary arts as well as from research on media spaces, this is an example of a conceptual design intended to produce meaningful effects on a local culture. In this paper, we describe the methods and ideas that led to this proposal, as an example of research on technologies from the traditions of artist-designers.
1999	Customer-focused design data in a large, multi-site organization	Qualitative user-centered design processes such as contextual inquiry can generate huge amounts of data to be organized, analyzed, and represented. When you add the goal of spreading the resultant understanding to the far reaches of a large, multi-site organization, many practical barriers emerge. In this paper we describe experience creating and communicating representations of contextually derived user data in a large, multi-site product development organization. We describe how we involved a distributed team in data collection and analysis and how we made the data representations portable. We then describe how we have engaged over 200 people from five sites in thinking through the user data and its implications on product design.
